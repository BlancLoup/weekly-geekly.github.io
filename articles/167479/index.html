<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Pocketsphinx. Speech Recognition and Voice Control in Linux</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="- Is everything alright, Leon? 
 The speakers are adjusted to the maximum, I frown, I answer: 
 - Yes. Hush sound. 
 ‚ÄúThe sound is quieter,‚Äù Vindous-H...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Pocketsphinx. Speech Recognition and Voice Control in Linux</h1><div class="post__text post__text-html js-mediator-article"><blockquote>  - Is everything alright, Leon? <br>  The speakers are adjusted to the maximum, I frown, I answer: <br>  - Yes.  Hush sound. <br>  ‚ÄúThe sound is quieter,‚Äù Vindous-Home agrees, ‚Äúquieter, quieter ...‚Äù <br>  - Enough, Vika <br>  S.Lukyanenko, "Labyrinth of reflections" </blockquote><br><h4>  Introduction </h4><br>  In 1997, Lukyanenko predicted for the desktop a combination of CLI and voice control.  However, now voice control is a fairly narrow niche. <br>  Voice control - interaction with the device using sound commands.  Do not confuse this concept with speech recognition.  For voice control, it is enough that the device responds to the only command you need (because your dog cannot work as a typist?).  Speech recognition is a much more global problem: in this case, the device must convert all words spoken by you into text format.  As it is easy to guess, speech recognition is currently implemented superficially in relation to human capabilities. <br>  The functionality discussed in the article can be used, for example, for organizing a smart home now or just computer control.  Frankly, a couple of paragraphs would suffice to describe computer management, but I will try to show you the basics of working with CMU Sphinx. <br>  <i>By the way, 70 percent of the description described here is suitable for Windows users.</i> <br><a name="habracut"></a><br>  For Linux, two developed speech recognition projects are most often mentioned: <a href="http://en.wikipedia.org/wiki/CMU_Sphinx">CMU Sphinx</a> and <a href="http://en.wikipedia.org/wiki/Julius_(software)">Julius</a> . <br><div class="spoiler">  <b class="spoiler_title">Links to articles on the subject (you can preview the subject)</b> <div class="spoiler_text">  <a href="http://habrahabr.ru/post/157333/">Using google-service</a> <br>  <a href="http://www.xakep.ru/magazine/xa/133/082/1.asp">Hacker article on using Julius</a> <br>  <a href="http://isaleksey.blogspot.com/2011/05/blog-post.html">Linux Recognition Systems List</a> <br>  <a href="http://wiki.linuxformat.ru/index.php/LXF116:%25D0%259A%25D0%25BE%25D0%25BC%25D0%25BF%25D1%258C%25D1%258E%25D1%2582%25D0%25B5%25D1%2580_%25D1%2581%25D0%25BB%25D1%2583%25D1%2588%25D0%25B0%25D0%25B5%25D1%2582%2521">A small review from LinuxFormat.</a>  <a href="http://wiki.linuxformat.ru/index.php/LXF116:%25D0%259A%25D0%25BE%25D0%25BC%25D0%25BF%25D1%258C%25D1%258E%25D1%2582%25D0%25B5%25D1%2580_%25D1%2581%25D0%25BB%25D1%2583%25D1%2588%25D0%25B0%25D0%25B5%25D1%2582%2521">Part 1</a> <br>  <a href="http://wiki.linuxformat.ru/index.php/LXF117:%25D0%259A%25D0%25BE%25D0%25BC%25D0%25BF%25D1%258C%25D1%258E%25D1%2582%25D0%25B5%25D1%2580_%25D1%2581%25D0%25BB%25D1%2583%25D1%2588%25D0%25B0%25D0%25B5%25D1%2582">A small review from LinuxFormat.</a>  <a href="http://wiki.linuxformat.ru/index.php/LXF117:%25D0%259A%25D0%25BE%25D0%25BC%25D0%25BF%25D1%258C%25D1%258E%25D1%2582%25D0%25B5%25D1%2580_%25D1%2581%25D0%25BB%25D1%2583%25D1%2588%25D0%25B0%25D0%25B5%25D1%2582">Part 2</a> <br></div></div><br>  In this article, I will not touch Julius, because there are enough guides on its use (including on the Runet).  It will be about CMU Sphinx. <br><br><h4>  Description and Installation </h4><br>  On the <a href="http://cmusphinx.sourceforge.net/">official site, the</a> latest version of pocketsphinx and sphinxbase is 0.8.  In the repository of my Debian Squeeze there is only an obsolete sphinx2 branch.  So, we will build (check the repositories of your distributions: in recent versions of Ubuntu and Fedora there must be current versions).  If necessary, instead of pocketsphinx, written in C, you can use Sphinx4 in Java ( <a href="http://cmusphinx.sourceforge.net/wiki/tutorialbeforestart">more</a> ). <br>  Download <a href="http://cmusphinx.sourceforge.net/wiki/download/">from here the</a> source code of pocketsphinx and sphinxbase ("support library required by Pocketsphinx and Sphinxtrain") and collect. <br><div class="spoiler">  <b class="spoiler_title">Problems should not arise</b> <div class="spoiler_text"><pre><code class="bash hljs">./configure make checkinstall</code> </pre> <br>  Do not forget to run after installation: <br><pre> <code class="bash hljs">ldconfig</code> </pre><br></div></div><br><div class="spoiler">  <b class="spoiler_title">Finished Debian Squeeze x86 Packages</b> <div class="spoiler_text">  <a href="">sphinxbase</a> <br>  <a href="">pocketsphinx</a> <br>  <a href="">sphinxtrain</a> <br>  <a href="">cmuclmtk</a> <br></div></div><br>  To work with / dev / dsp, install the oss-compat package according to the <a href="http://cmusphinx.sourceforge.net/wiki/faq">FAQ</a> . <br><br><h4>  Basic use </h4><br>  The project offers us to test performance on a basic example: to recognize the phrase in English ‚Äúgo forward ten meters‚Äù. <br>  Well, we try. <br>  We will use the pocketsphinx_batch batch recognition utility (read the man before using it).  There is also a recognition tool "from the microphone" - pocketsphinx_continuous (its syntax is similar to pocketsphinx_batch). <br>  We will work in a separate directory, for example ~ / sphinx. <br>  The syntax of our team is: <br><pre> <code class="bash hljs">pocketsphinx_batch -argfile argfile 2&gt;./errors</code> </pre><br>  -argflie: the name of the file in the current directory containing all the arguments. <br>  For convenience, we will redirect stderr to a file. <br>  Content argfile: <br><pre> <code class="bash hljs">-hmm /usr/<span class="hljs-built_in"><span class="hljs-built_in">local</span></span>/share/pocketsphinx/model/hmm/en_US/hub4wsj_sc_8k -lm /usr/<span class="hljs-built_in"><span class="hljs-built_in">local</span></span>/share/pocketsphinx/model/lm/en/turtle.DMP -dict /usr/<span class="hljs-built_in"><span class="hljs-built_in">local</span></span>/share/pocketsphinx/model/lm/en/turtle.dic -cepdir /home/saint/sphinx -ctl ctlfile -cepext .raw -adcin <span class="hljs-literal"><span class="hljs-literal">true</span></span> -hyp outname</code> </pre><br>  -hmm: path to the directory containing the acoustic model files (templates for individual sounds). <br>  -lm: path to the file of the trigram language model (you can read <a href="http://www.intsys.msu.ru/invest/speech/articles/rus_lm.htm">here</a> ). <br>  -dict: path to the pronunciation dictionary file. <br>  -cepdir: path to the directory with sound files.  Be careful: if you enter -cepdir into the argument file, the shortcut ~ / sphinx is not processed correctly: you have to write the full path.  If you prescribe the argument after the command, you can use an abbreviated path. <br>  -ctl: file with the names of the files being processed.  We will take the goforward.raw file from the source set of pocketsphinx (there are a couple of * .raw files there too - you can recognize them). <br>  -cepext: file extension <br>  -adcin: pointer to the raw file to be processed. <br>  -hyp: the name of the file to which the recognized text will be displayed. <br>  Arguments with paths to model files must be specified.  Remember that many parameters are set by default (see stderr).  Therefore, to work with the * .raw file, it is necessary to force the extension, otherwise the default parameter will be used - the .mfc extension (of course, we don‚Äôt have such files in the base example - errors will occur). <br>  As a result of execution, we will have the following contents in the outname file: <br><pre> <code class="bash hljs">go forward ten meters (goforward -26532)</code> </pre><br>  At the same time, you can view, compile and run a <a href="http://cmusphinx.sourceforge.net/wiki/tutorialpocketsphinx">similar</a> C <a href="http://cmusphinx.sourceforge.net/wiki/tutorialpocketsphinx">program</a> in the directory with the goforward.raw file (example from the developers). <br>  To check on my examples, I decided not to be philosophical and took advantage of <i>sox</i> (check if you have this package installed). <br>  We will write the sound as follows (you can read <code>man sox</code> ): <br>  - for raw <br><pre> <code class="bash hljs">rec -r 16k -e signed-integer -b 16 -c 1 filename.raw</code> </pre><br>  - for wav <br><pre> <code class="bash hljs">rec -r 16k -e signed-integer -b 16 -c 1 filename.wav</code> </pre><br>  End of recording by <code>Ctrl+C</code> <br>  My sox at the same time cursed the impossibility of using the sampling rate: <code>can't set sample rate 16000; using 48000</code>  <code>can't set sample rate 16000; using 48000</code> .  Consider: brazenly lying - in fact, everything is in order. <br>  I wrote and recognized raw and wav on various examples from connected dictionaries - <i>everything was recognized quite acceptable</i> . 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h4>  Adapt the sound model </h4><br>  Adapting a sound model should improve recognition for a particular voice, pronunciation, accent, or environment.  Consider this process. <br><div class="spoiler">  <b class="spoiler_title">Links</b> <div class="spoiler_text">  <a href="http://cmusphinx.sourceforge.net/wiki/tutorialadapt">Official site</a> <br>  <a href="http://forum.sources.ru/index.php%3Fshowtopic%3D367628">Approximate translation</a> <br></div></div><br>  We download the suggested files to the separate directory in the first link, in which we will work. <br>  Now let's dictate the sentences from the arctic20.txt file according to the sample: you should have twenty files named in order according to the <code>arctic_0001.wav</code> ... <code>arctic_0020.wav</code> . <br>  To simplify the recording, use the proposed script: <br><pre> <code class="bash hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> `seq 1 20`; <span class="hljs-keyword"><span class="hljs-keyword">do</span></span> fn=`<span class="hljs-built_in"><span class="hljs-built_in">printf</span></span> arctic_%04d <span class="hljs-variable"><span class="hljs-variable">$i</span></span>`; <span class="hljs-built_in"><span class="hljs-built_in">read</span></span> sent; <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-variable"><span class="hljs-variable">$sent</span></span>; rec -r 16000 -e signed-integer -b 16 -c 1 <span class="hljs-variable"><span class="hljs-variable">$fn</span></span>.wav 2&gt;/dev/null; <span class="hljs-keyword"><span class="hljs-keyword">done</span></span> &lt; arctic20.txt</code> </pre><br>  Accordingly, in order to listen to the received, run: <br><pre> <code class="bash hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> *.wav; <span class="hljs-keyword"><span class="hljs-keyword">do</span></span> play <span class="hljs-variable"><span class="hljs-variable">$i</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">done</span></span></code> </pre><br>  Copy the acoustic model (with which we worked) from <code>/usr/local/share/pocketsphinx/model/hmm/en_US/hub4wsj_sc_8k</code> to our working directory. <br>  Now we will create acoustic features files (I remind you: we work in a directory with * .wav files). <br><pre> <code class="bash hljs">sphinx_fe -argfile hub4wsj_sc_8k/feat.params -samprate 16000 -c arctic20.listoffiles -di . -<span class="hljs-keyword"><span class="hljs-keyword">do</span></span> . -ei wav -eo mfc -mswav yes</code> </pre><br>  As a result, we obtain * .mfc files. <br>  Download <a href="http://cmusphinx.svn.sourceforge.net/viewvc/cmusphinx/trunk/pocketsphinx-extra/%3Fview%3Dtar">extra pack</a> (89.0 MB);  a file called <code>mixture_weights</code> from it, located in <code>pocketsphinx-extra/model/hmm/en_US/hub4_wsj_sc_3s_8k.cd_semi_5000</code> placed in the directory with the acoustic model. <br>  You also need to convert the mdef file of the acoustic model into a text format: <br><pre> <code class="bash hljs">pocketsphinx_mdef_convert -text hub4wsj_sc_8k/mdef hub4wsj_sc_8k/mdef.txt</code> </pre><br>  Now, according to the adaptation guideline terminology, we will collect the accumulated data.  Copy the <code>bw</code> utility from <code>/usr/local/libexec/sphinxtrain/bw</code> to the working directory (before that do not forget to install sphinxtrain!). <br><pre> <code class="bash hljs">./bw -hmmdir hub4wsj_sc_8k -moddeffn hub4wsj_sc_8k/mdef.txt -ts2cbfn .semi. -feat 1s_c_d_dd -svspec 0-12/13-25/26-38 -cmn current -agc none -dictfn arctic20.dic -ctlfn arctic20.fileids -lsnfn arctic20.transcription -accumdir .</code> </pre><br>  Run and see: <br> <code>SYSTEM_ERROR: "corpus.c", line 339: Unable to open arctic20.fileids for reading: No such file or directory</code> <br>  Obviously, the right hand of the developers does not know what the left is doing (I‚Äôm not even talking about the irrelevance of the documentation). <br>  Rename <code>arctic20.listoffiles</code> to <code>arctic20.fileids</code> in the working directory <br>  Now everything works. <br>  We produce MLLR-adaptation (effective for a limited amount of data in the model): <br><pre> <code class="bash hljs">cp /usr/<span class="hljs-built_in"><span class="hljs-built_in">local</span></span>/libexec/sphinxtrain/mllr_solve /your/work/dir/mllr_solve</code> </pre><br><pre> <code class="bash hljs">./mllr_solve -meanfn hub4wsj_sc_8k/means -varfn hub4wsj_sc_8k/variances -outmllrfn mllr_matrix -accumdir .</code> </pre><br>  This command will create an adaptation data file <code>mllr_matrix</code> . <br>  Now, when recognizing with the adapted model, you can add the parameter <code>-mllr /path/to/mllr_matrix</code> . <br>  In parallel, we produce another adaptation method: MAP. <br><pre> <code class="bash hljs">cp /usr/<span class="hljs-built_in"><span class="hljs-built_in">local</span></span>/libexec/sphinxtrain/map_adapt /your/work/dir/map_adapt</code> </pre><br>  Make a copy of the model: <br><pre> <code class="bash hljs">cp -a hub4wsj_sc_8k hub4wsj_sc_8kadapt</code> </pre><br>  And we will make MAP-adaptation: <br><pre> <code class="bash hljs">./map_adapt -meanfn hub4wsj_sc_8k/means -varfn hub4wsj_sc_8k/variances -mixwfn hub4wsj_sc_8k/mixture_weights -tmatfn hub4wsj_sc_8k/transition_matrices -accumdir . -mapmeanfn hub4wsj_sc_8kadapt/means -mapvarfn hub4wsj_sc_8kadapt/variances -mapmixwfn hub4wsj_sc_8kadapt/mixture_weights -maptmatfn hub4wsj_sc_8kadapt/transition_matrices</code> </pre><br>  Now we will create a <code>sendump</code> file that has a smaller size: <br><pre> <code class="bash hljs">cp /usr/<span class="hljs-built_in"><span class="hljs-built_in">local</span></span>/libexec/sphinxtrain/mk_s2sendump /your/work/dir/mk_s2sendump</code> </pre><br><pre> <code class="bash hljs">./mk_s2sendump -pocketsphinx yes -moddeffn hub4wsj_sc_8kadapt/mdef.txt -mixwfn hub4wsj_sc_8kadapt/mixture_weights -sendumpfn hub4wsj_sc_8kadapt/sendump</code> </pre><br>  Adaptation is complete. <br><br><h4>  Adaptation testing </h4><br>  The essence of the experiment: we record several samples on which the original acoustic model stumbles, and process them with the help of adapted acoustic models. <br>  Create a subdirectory <code>test</code> in the working directory.  In it we create a subdirectory <code>wav</code> , in which there will be our test records. <br>  Here, to confirm the result of the experiment, I post my samples and two adapted acoustic models. <br><div class="spoiler">  <b class="spoiler_title">Links</b> <div class="spoiler_text">  <a href="">dl.dropbox.com/u/22130570/cmusphinx/wav/test1.wav</a> <br>  <a href="">dl.dropbox.com/u/22130570/cmusphinx/wav/test2.wav</a> <br>  <a href="">dl.dropbox.com/u/22130570/cmusphinx/wav/test3.wav</a> <br>  <a href="">dl.dropbox.com/u/22130570/cmusphinx/hub4wsj_sc_8k.7z</a> <br>  <a href="">dl.dropbox.com/u/22130570/cmusphinx/hub4wsj_sc_8kadapt.7z</a> <br></div></div><br>  Checking (remember that the adaptation will not lead to one hundred percent correct result: the adapted models will make the same mistake; plus that they will do it less often. My quite visual notes were made far from the first attempt: there were enough records where they were wrong all models): <br>  1. Recognition using the base model: <br><pre> <code class="bash hljs">pocketsphinx_batch -hmm /usr/<span class="hljs-built_in"><span class="hljs-built_in">local</span></span>/share/pocketsphinx/model/hmm/en_US/hub4wsj_sc_8k -lm /usr/<span class="hljs-built_in"><span class="hljs-built_in">local</span></span>/share/pocketsphinx/model/lm/en/turtle.DMP -dict /usr/<span class="hljs-built_in"><span class="hljs-built_in">local</span></span>/share/pocketsphinx/model/lm/en/turtle.dic -cepdir wav -ctl adaptation-test.fileids -cepext .wav -adcin yes -hyp adaptation-test.hyp</code> </pre><br>  Result: <br><pre> <code class="bash hljs">hello halt say forty (test1 -27391) go forward ten meter (test2 -35213) hall doing home (test3 -30735)</code> </pre><br>  2. Recognition using the model with MLLR adaptation: when specifying the -mllr parameter to the path to my matrix, a segmentation error occurred (I did not dig).  In case of recognition without this option, the result is completely identical to the result of the original model. <br>  However, the manual stated that the MLLR-adaptation is best suited for a continuous model (ie, for Sphinx4). <br>  3. Recognition using the model with MAP-adaptation: <br><pre> <code class="bash hljs">pocketsphinx_batch -hmm ../hub4wsj_sc_8kadapt -lm /usr/<span class="hljs-built_in"><span class="hljs-built_in">local</span></span>/share/pocketsphinx/model/lm/en/turtle.DMP -dict /usr/<span class="hljs-built_in"><span class="hljs-built_in">local</span></span>/share/pocketsphinx/model/lm/en/turtle.dic -cepdir wav -ctl adaptation-test.fileids -cepext .wav -adcin yes -hyp adaptation-test.hyp</code> </pre><br>  Result: <br><pre> <code class="bash hljs">hello rotate display (test1 -28994) go forward ten meters (test2 -33877) lost window (test3 -29293)</code> </pre><br><br>  As you can see, the result is completely identical to the record.  Adaptation really works! <br><br><h4>  Russian language in Pocketsphinx </h4><br>  Download <a href="http://sourceforge.net/projects/cmusphinx/files/Acoustic%2520and%2520Language%2520Models/Russian%2520Voxforge/">from here the</a> Russian models created on <a href="http://www.voxforge.org/">voxforge</a> .  A variety of models can be viewed <a href="http://www.repository.voxforge1.org/downloads/Russian/Trunk/Audio/">here</a> and just on the Internet. <br><br>  We will implement the example of voice control of a computer in Russian, which means we need our own language model and our own vocabulary (most likely, parts of our words in common examples will not be). <br><br><h5>  Creating your own static language model </h5><br>  In general, for a small number of words, a jsgf dictionary can be used instead of a static language model.  However, this is a special case and we will consider it below. <br>  A guide to creating a language model is <a href="http://cmusphinx.sourceforge.net/wiki/tutoriallm">here</a> . <br>  We will create using CMUCLMTK. <br>  <a href="">Download</a> , collect. <br>  First, create a text file with suggestions for our language model. <br><div class="spoiler">  <b class="spoiler_title">lmbase.txt</b> <div class="spoiler_text"><pre> <code class="bash hljs">&lt;s&gt;     &lt;/s&gt; &lt;s&gt;      &lt;/s&gt; &lt;s&gt;     &lt;/s&gt; &lt;s&gt;      &lt;/s&gt; &lt;s&gt;     &lt;/s&gt; &lt;s&gt;      &lt;/s&gt; &lt;s&gt;    &lt;/s&gt; &lt;s&gt;     &lt;/s&gt; &lt;s&gt;     &lt;/s&gt; &lt;s&gt;    &lt;/s&gt; &lt;s&gt;     &lt;/s&gt; &lt;s&gt;     &lt;/s&gt; &lt;s&gt;    &lt;/s&gt; &lt;s&gt;       &lt;/s&gt; &lt;s&gt;        &lt;/s&gt; &lt;s&gt;     &lt;/s&gt; &lt;s&gt;     &lt;/s&gt; &lt;s&gt;    &lt;/s&gt; &lt;s&gt;    &lt;/s&gt; &lt;s&gt;    &lt;/s&gt; &lt;s&gt;   &lt;/s&gt; &lt;s&gt;    &lt;/s&gt; &lt;s&gt;    &lt;/s&gt; &lt;s&gt;    &lt;/s&gt; &lt;s&gt;   &lt;/s&gt; &lt;s&gt;    &lt;/s&gt; &lt;s&gt;    &lt;/s&gt; &lt;s&gt;      &lt;/s&gt; &lt;s&gt;    &lt;/s&gt; &lt;s&gt;   &lt;/s&gt; &lt;s&gt;     &lt;/s&gt; &lt;s&gt;    &lt;/s&gt; &lt;s&gt;    &lt;/s&gt; &lt;s&gt;   &lt;/s&gt;</code> </pre><br></div></div><br>  Next, create a dictionary file: <br><pre> <code class="bash hljs">text2wfreq &lt;lmbase.txt | wfreq2vocab&gt; lmbase.tmp.vocab cp lmbase.tmp.vocab lmbase.vocab</code> </pre><br>  Create a language model in arpa-format: <br><pre> <code class="bash hljs">text2idngram -vocab lmbase.vocab -idngram lmbase.idngram &lt; lmbase.txt idngram2lm -vocab_type 0 -idngram lmbase.idngram -vocab lmbase.vocab -arpa lmbase.arpa</code> </pre><br>  And create a DMP model. <br><pre> <code class="bash hljs">sphinx_lm_convert -i lmbase.arpa -o lmbase.lm.DMP</code> </pre><br><br><h5>  Creating your own vocabulary </h5><br>  Dragging the utility from the githab: <br><pre> <code class="bash hljs">git <span class="hljs-built_in"><span class="hljs-built_in">clone</span></span> https://github.com/zamiron/ru4sphinx/ yourdir</code> </pre><br>  Go to the directory ./yourdir/text2dict and create there a text file <i>my_dictionary</i> with your word list (each new word - from a new paragraph). <br><div class="spoiler">  <b class="spoiler_title">Example my_dictionary</b> <div class="spoiler_text">  browser <br>  louder <br>  shut down <br>  run <br>  window <br>  post office <br>  expand <br>  roll up <br>  roll up <br>  terminal <br>  hush <br></div></div><br>  Then we execute: <br><pre> <code class="bash hljs">perl dict2transcript.pl my_dictionary my_dictionary_out</code> </pre><br>  And your dictionary is created. <br><br>  Now we try to recognize the words present in the dictionary (the blessing, in our example there are some of them).  Do not forget to specify your own language model and vocabulary in the arguments - everything should work.  If you wish, you can adapt the acoustic model (I‚Äôm warning you right away that when using the bw utility, the <code>-svspec</code> option <code>-svspec</code> not needed for the adaptation of most acoustic models). <br><br><h5>  Using Grammar File JavaScript instead of static language model </h5><br>  <a href="http://homepages.abdn.ac.uk/k.vdeemter/pages/teaching/NLP/practicals/JSGFGrammar.html">Read here.</a> <br>  Syntax: <br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#JSGF V1.0; grammar test; public &lt;test&gt; = ( &lt;a&gt; | &lt;a&gt; &lt;b&gt; ); &lt;a&gt; = (  |  |  |  ); &lt;b&gt; = [  ];</span></span></code> </pre><br>  "|"  denotes a selection condition.  Those.  we can say "quieter" or "close the window."  True, compared to using the language model, there is one drawback: we need to speak much more articulately. <br>  We specify the created jsgf file with the -jsgf parameter (the -lm parameter is not needed in this case). <br><br><h4>  Implementation of voice control </h4><br>  My goal was not to implement a cool management interface: everything will be very primitive here (if you have the desire and opportunity, you can look at the abandoned <a href="https://live.gnome.org/GnomeVoiceControl">Gnome Voice Control</a> project). <br>  We will act as follows: <br>  1. We write a command, we recognize it. <br>  2. We transfer the recognized text to a file, in accordance with it we execute the command. <br>  As test commands we will use the decrease and increase the volume of the sound. <br><br>  After carefully reading the manual to sox, I decided to finish the recording after a second of silence with a silence threshold of 3.8% (the threshold is clearly a purely individual value and depends on your microphone and environment). <br>  Unfortunately, I did not find the output parameter for recognized words only in pocketsphinx_batch, so I will use the <code>sed</code> tool: <br><pre> <code class="bash hljs">cat ~/sphinx/rus/outname | sed <span class="hljs-string"><span class="hljs-string">'s/\( (.*\)//'</span></span></code> </pre><br>  This construction will remove from the line like "our team (audio -4023)" the space before the opening bracket, its own and all subsequent content.  As a result, we get a line like ‚Äúour team‚Äù, which is what we need. <br>  Here is the script itself: <br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#!/bin/bash rec -r 16k -e signed-integer -b 16 -c 1 test.wav silence 0 1 00:01 3.8% pocketsphinx_batch -argfile argfile 2&gt;./errors a=$(cat ~/sphinx/rus/outname | sed 's/\( (.*\)//') case $a in ) amixer -q sset Master 10- a=$(amixer sget Master | grep "Mono: Playback") notify-send "$a" ;; ) amixer -q sset Master 10+ a=$(amixer sget Master | grep "Mono: Playback") notify-send "$a" ;; *) ;; esac</span></span></code> </pre><br>  The script in response to the "quieter" or "louder" commands performs the appropriate actions with the alarm via notify-send. <br>  Unfortunately, it will work only when it is launched from the terminal (otherwise the sound is not written).  However, he gives an idea of ‚Äã‚Äãvoice control (you may suggest the best method). <br><br><h4>  A few words as a conclusion </h4><br>  When I started writing this article, I just wanted to tell you that with free recognition, now everything is far from being as dull as it seems.  There are engines, work is being done on acoustic models on <a href="http://www.voxforge.org/">www.voxforge.org</a> (you can help them with vocabulary reading).  At the same time, work with recognition is not something difficult for a simple user. <br>  A few days ago <a href="http://vasilisc.com/hud-2">it was announced</a> that Pocketsphinx or Julius would be used in Ubuntu for tablets.  I hope in this light this topic looks a little more relevant and interesting. <br>  In the article I tried to consider the main points of working with Pocketsphinx, speaking more about theory than about practice.  However, you could see that recognition is not a fiction, it works. <br>  Remember that I have touched on only superficial aspects: the documentation on official websites and various forums describes a lot more.  Try, tell in the comments about your experience, share ideas, good thoughts and ready-made solutions for voice control. </div><p>Source: <a href="https://habr.com/ru/post/167479/">https://habr.com/ru/post/167479/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../167469/index.html">SXB: MySQL incremental backup</a></li>
<li><a href="../167471/index.html">Why free business software is bad. Based on disabling free Google Apps subscriptions</a></li>
<li><a href="../167473/index.html">RIM & Lenovo: there will be no alliance, but it would be cool!</a></li>
<li><a href="../167475/index.html">Just like two two four</a></li>
<li><a href="../167477/index.html">What I learned from Jason Fried (37signals)</a></li>
<li><a href="../167483/index.html">Your opinion is important to us</a></li>
<li><a href="../167485/index.html">ImageCMS 4.2: Pat—Åh</a></li>
<li><a href="../167487/index.html">Notification Hubs - cloud notification service for millions of iOS and Windows users</a></li>
<li><a href="../167489/index.html">In the rhythm of modern life</a></li>
<li><a href="../167491/index.html">Critical Rails vulnerability. Again</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>