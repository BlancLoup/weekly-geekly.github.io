<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Statistical verification of randomness of binary sequences using NIST methods</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Anyone who, in one way or another, has come across cryptography, knows that you cannot do without random number generators. One of the possible applic...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Statistical verification of randomness of binary sequences using NIST methods</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/files/408/034/cce/408034cced804225823d4de717072edf.jpg"><br><br>  Anyone who, in one way or another, has come across cryptography, knows that you cannot do without random number generators.  One of the possible applications of such generators, for example, is the generation of keys.  But not everyone thinks at the same time, but how ‚Äúgood‚Äù a particular generator is.  And if he thought about it, he came across the fact that there is no single ‚Äúofficial‚Äù set of criteria in the world that would assess how much random number data is applicable for this particular field of cryptography.  If a sequence of random numbers is predictable, then even the strongest encryption algorithm in which this sequence will be used turns out to be vulnerable ‚Äî for example, the space of possible keys that an attacker needs to ‚Äúbite‚Äù to get some information, through which he can ‚Äúcrack‚Äù ¬ªThe whole system.  Fortunately, various organizations are still trying to bring order here, in particular, the American Institute for Standards NIST has developed a set of tests to assess the randomness of a sequence of numbers.  About them will be discussed in this article.  But first - a bit of theory (I will try to explain not boring). <br><br><a name="habracut"></a>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h2>  Random binary sequences </h2><br>  First, by random number generation is meant to obtain a sequence of binary characters 0 and 1, and not bytes, no matter how much the programmers would like.  An ideal similar generator is to toss a ‚Äúperfect‚Äù coin (a flat coin with equal probabilities of each side), which would be thrown as many times as necessary, but the problem is that there is nothing ideal, and the performance of such a generator would leave the best (one grown up coin = one bit).  Nevertheless, all the tests described below assess how much the random number generator under study ‚Äúlooks like‚Äù or ‚Äúdoes not look like‚Äù on an imaginary ideal coin (not in the rate of receiving ‚Äúrandom‚Äù signs, but their ‚Äúquality‚Äù). <br><br>  Secondly, all random number generators are divided into 2 types ‚Äî truly random ‚Äî physical random number generators / sensors (DSSH / FDSCH) and pseudo-random ‚Äî software sensors / random number generators (PDDSH).  The first take on the input some random endless process, and on the output they give an infinite (depending on the observation time) sequence 0 and 1. The second ones represent the deterministic function set by the developer, which is initialized by the so-called.  grain, after which the output also produces the sequence 0 and 1. Knowing this grain, you can predict the entire sequence.  A good PDRCh is one for which it is impossible to predict subsequent values, having the entire history of previous values, having no grain.  This property is called direct unpredictability.  There is also the reverse unpredictability - the inability to calculate the grain, knowing any number of generated values. <br><br>  It would seem the easiest way to take truly random / physical RNTS and not think about any predictability.  However, there are problems: <br><br><ul><li>  A random phenomenon / process that is taken as a basis may not be able to produce numbers at the desired speed.  If you remember the last time you generated a pair of 2048bit keys, then do not flatter yourself.  Does this happen very rarely?  Then imagine yourself a server accepting hundreds of requests for SSL connections per second (SSL handshake involves generating a pair of random numbers). </li><li>  In appearance, random phenomena may not be as random as they would seem.  For example, electromagnetic noise can be a superposition of several more or less uniform periodic signals. </li></ul><br><br>  Each of the tests offered by NIST receives the final sequence as input.  Further, the statistics characterizing a certain property of a given sequence is calculated ‚Äî it can be a single value or a set of values.  After that, these statistics are compared with the standard statistics, which will give a perfectly random sequence.  Reference statistics are derived mathematically, many theorems and scientific papers are devoted to this.  At the end of the article will be given all references to the sources where the necessary formulas are displayed. <br><br><h2>  Zero and Alternative Hypotheses </h2><br>  The test is based on the concept of the <i>null hypothesis</i> .  I'll try to explain what it is.  Suppose we have gathered some statistical information.  For example, let it be the number of people who develop lung cancer in a group of 1000 people.  And let it be known that some people from this group are smokers, and others are not, and it is known which ones are specific.  The next task is to understand whether there is a relationship between smoking and disease.  The null hypothesis is the assumption that there is no relationship between the two facts.  In our example, this is the assumption that smoking <u>does not cause</u> lung cancer.  There is also <i>an alternative hypothesis</i> , which refutes the null hypothesis: i.e.  there is a relationship between the phenomena (smoking <u>causes</u> lung cancer).  If we proceed to the terms of random numbers, then the null hypothesis is the assumption that the sequence is truly random (the signs of which appear equiprobable and independent of each other).  Consequently, if the null hypothesis is true, then our generator produces fairly ‚Äúgood‚Äù random numbers. <br><br>  How is the hypothesis tested?  On the one hand, we have statistics calculated on the basis of actually collected data (i.e., by measured sequence).  On the other hand, there is a standard statistics obtained by mathematical methods (theoretically calculated), which <u>would have</u> had a truly random sequence.  It is obvious that the collected statistics cannot be equal to the standard one - no matter how good our generator is, it is still not perfect.  Therefore, a certain error is introduced, for example, 5%.  It means that if, for example, the collected statistics deviates from the reference one by more than 5%, then it is concluded that the null hypothesis is not true with <i>high reliability</i> . <br><br>  Since we are dealing with hypotheses, there are 4 options for the development of events: <br><ol><li>  It is concluded that the sequence is random, and this is the correct conclusion. </li><li>  It is concluded that the sequence is not random, although it was in fact random.  Such errors are called <i>errors of the first kind.</i> </li><li>  The sequence is recognized as random, although in fact it is not.  Such errors are called <i>errors of the second kind.</i> </li><li>  Sequence rightly rejected </li></ol><br><br>  The probability of an error of the first kind is called the <i>level of statistical significance</i> and is designated as Œ±.  Those.  Œ± is the probability of rejecting a ‚Äúgood‚Äù random sequence.  This value is determined by the application.  In cryptography, Œ± is taken from 0.001 to 0.01. <br><br>  In each test is calculated so-called.  <i>P-value</i> : this is the probability that the experimental generator will produce a sequence <i>no worse</i> than the hypothetical true one.  If P value = 1, then our sequence is ideally random, and if it = 0, then the sequence is completely predictable.  Further, the P-value is compared with Œ±, and if it is greater than Œ±, then the null hypothesis is accepted and the sequence is considered random.  Otherwise, it is rejected. <br><br>  In tests, Œ± = 0.01 is taken.  It follows that: <br><ul><li>  If the P-value is ‚â• 0.01, the sequence is considered random with a confidence level of 99%. </li><li>  If the P-value is &lt;0.01, the sequence is rejected with a confidence level of 99%. </li></ul><br><br>  So, we proceed directly to the tests. <br><br><h2>  Bitwise Frequency Test </h2><br>  Obviously, the more random the sequence, the closer this ratio to 1. This test evaluates how close this ratio is to 1. <br><br>  We accept each ‚Äú1‚Äù for +1, and each ‚Äú0‚Äù for -1, and count the sum of the entire sequence.  This can be written as: <br>  S <sub>n</sub> = X <sub>1</sub> + X <sub>2</sub> +‚Ä¶ + X <sub>n</sub> , where X <sub>i</sub> = 2x <sub>i</sub> - 1. <br>  By the way, it is said that the distribution of the number of ‚Äúsuccesses‚Äù in a series of experiments, where <i>success</i> or <i>failure</i> with a given probability is possible in each experiment, has a <i>binomial</i> distribution. <br><br>  Take the following sequence: 1011010101 <br><br>  Then S = 1 + (-1) + 1 + 1 + (-1) + 1 + (-1) + 1 + (-1) + 1 = 2 <br><br>  Calculate statistics: <br><img src="https://habrastorage.org/files/96f/6ce/1bb/96f6ce1bb45f4969a7e975358440643b.png" height="40"><br><br>  We calculate the P-value through the <i>additional error function</i> : <br><img src="https://habrastorage.org/files/3a2/37e/b39/3a237eb390e34ceea7abb201956aaf10.png" height="40"><br><br>  The complementary error function is defined as: <br><img src="https://habrastorage.org/files/d98/e29/102/d98e2910202a40168f01da91fca26750.png" height="40"><br><br>  We see that the result is&gt; 0.01, which means our sequence passed the test.  It is recommended to test sequences with a length of at least 100 bits. <br><br><h2>  Frequency block test </h2><br>  This test is made on the basis of the previous one, only now the values ‚Äã‚Äãof the proportion "1" / "0" for each block are analyzed by the chi-square method.  It is clear that this ratio should be approximately equal to 1. <br><br>  For example, let the sequence be given 0110011010. Divide it into blocks of 3 bits each (‚Äúownerless‚Äù 0 at the end is dropped): <br>  011 001 101 <br><br>  We calculate the proportions œÄ <sub>i</sub> for each block: œÄ <sub>1</sub> = 2/3, œÄ <sub>2</sub> = 1/3, œÄ <sub>3</sub> = 1/3.  Next, we calculate statistics using the Chi-square method with N degrees of freedom (here N is the number of blocks): <br><img src="https://habrastorage.org/files/65c/d1a/b43/65cd1ab43e9b4cb09c1ea4419ac1a46e.png" height="40"><br><br>  We calculate the P-value through a special function <i>Q</i> : <br><img src="https://habrastorage.org/files/834/b3c/f9b/834b3cf9ba854fa98ce7cf4f4759c745.png" height="40"><br><br>  Q is so-called.  <i>incomplete upper gamma function</i> , defined as: <br><img src="https://habrastorage.org/files/bf1/768/265/bf1768265cfe49979ae898871584c628.png" height="40"><br><br>  At the same time, function G is the standard gamma function: <br><img src="https://habrastorage.org/files/25e/728/e71/25e728e710b141ff81494ba413252210.png" height="40"><br><br>  A sequence is considered random if the P-value is&gt; 0.01.  It is recommended to analyze sequences with a length of at least 100 bits, and the relations M&gt; = 20, M&gt; 0.01n, and N &lt;100 should also be satisfied. <br><br><h2>  Test for the same consecutive bits </h2><br>  The test searches for all sequences of the same bits, and then analyzes how the number and size of these sequences correspond to the number and size of a truly random sequence.  The point is that if a change of 0 to 1 (and vice versa) occurs too rarely, then such a sequence ‚Äúdoes not pull‚Äù on a random one. <br><br>  Let the sequence be 1001101011. First, we calculate the proportion of units in the total mass: <br><img src="https://habrastorage.org/files/1b5/325/1df/1b53251df4c940278bafdd9157d9e761.png" height="30"><br><br>  Further condition is checked: <br><img src="https://habrastorage.org/files/d02/395/436/d0239543662d4d1bacd2cf96e76be4b3.png" height="30"><br><br>  If it is not satisfied, then the whole test is considered unsuccessful and that‚Äôs the end of it.  In our case, 0.63246&gt; 0.1, which means we go further. <br><br>  Calculate the total number of sign-changing V: <br><img src="https://habrastorage.org/files/3ee/46c/da4/3ee46cda4c474954aa8aaecd17a0bbd8.png" height="30"><br><br>  Where <img src="https://habrastorage.org/files/839/1ba/862/8391ba862f1846b3b21b86a6c42d25b1.png" height="14">  if a <img src="https://habrastorage.org/files/dd1/e47/087/dd1e47087f594dc5ba4ee1fe4d24b6f1.png" height="14">  , or <img src="https://habrastorage.org/files/a38/2e5/401/a382e54010c14f10a8ba7a75eabe91ff.png" height="14">  otherwise. <br><br><img src="https://habrastorage.org/files/6f4/cb8/c62/6f4cb8c627564eb583a4e413aebb4657.png" height="20"><br><br>  We calculate the P-value through the error function: <br><img src="https://habrastorage.org/files/342/ff3/7f3/342ff37f36a24fa3808cf081c0846d68.png"><br><br>  If the result is&gt; = 0.01 (as in our example), the sequence is considered random. <br><br><h2>  Test for the longest sequence of units in a block </h2><br>  The initial sequence of n bits is divided into N blocks, each by M bits, after which each block is searched for the longest sequence of ones, and then it is estimated how close the indicator is to the same indicator for a truly random sequence.  Obviously, a similar test for zeros is not required, since if the units are <i>well</i> distributed, then the zeros will also be <i>well</i> distributed. <br><br>  What is the length of the block?  NIST recommends several reference values, how to break into blocks: <br><table><tbody><tr><th>  Total length, n </th><th>  Block length, M </th></tr><tr><td>  128 </td><td>  eight </td></tr><tr><td>  6272 </td><td>  128 </td></tr><tr><td>  750000 </td><td>  10,000 </td></tr></tbody></table><br>  Let the sequence be given: <br>  11001100 00010101 01101100 01001100 11100000 00000010 <br>  01001101 01010001 00010011 11010110 10000000 11010111 <br>  11001100 11100110 11011000 10110010 <br><br>  We divide it into blocks of 8 bits (M = 8), then we calculate the maximum sequence of units for each block: <br><table><tbody><tr><th>  Block </th><th>  Unit length </th></tr><tr><td>  11001100 </td><td>  2 </td></tr><tr><td>  00010101 </td><td>  one </td></tr><tr><td>  01101100 </td><td>  2 </td></tr><tr><td>  01001100 </td><td>  2 </td></tr><tr><td>  11100000 </td><td>  3 </td></tr><tr><td>  00000010 </td><td>  one </td></tr><tr><td>  01001101 </td><td>  2 </td></tr><tr><td>  01010001 </td><td>  one </td></tr><tr><td>  00010011 </td><td>  2 </td></tr><tr><td>  11010110 </td><td>  2 </td></tr><tr><td>  10,000,000 </td><td>  one </td></tr><tr><td>  11010111 </td><td>  3 </td></tr><tr><td>  11001100 </td><td>  2 </td></tr><tr><td>  11100110 </td><td>  3 </td></tr><tr><td>  11011000 </td><td>  2 </td></tr><tr><td>  10110010 </td><td>  2 </td></tr></tbody></table><br>  Next, we consider statistics for different lengths based on the following table: <br><table><tbody><tr><th>  v <sub>i</sub> </th><th>  M = 8 </th><th>  M = 128 </th><th>  M = 10,000 </th></tr><tr><td>  v <sub>0</sub> </td><td>  ‚â§1 </td><td>  &amp; le4 </td><td>  &amp; le10 </td></tr><tr><td>  v <sub>1</sub> </td><td>  2 </td><td>  five </td><td>  eleven </td></tr><tr><td>  v <sub>2</sub> </td><td>  3 </td><td>  6 </td><td>  12 </td></tr><tr><td>  v <sub>3</sub> </td><td>  ‚â•4 </td><td>  7 </td><td>  13 </td></tr><tr><td>  v <sub>4</sub> </td><td></td><td>  eight </td><td>  14 </td></tr><tr><td>  v <sub>5</sub> </td><td></td><td>  ‚â•9 </td><td>  15 </td></tr><tr><td>  v <sub>6</sub> </td><td></td><td></td><td>  ‚â•16 </td></tr></tbody></table><br>  How to use this table: we have M = 8, therefore we are looking at only one corresponding column.  Consider v <sub>i</sub> : <br>  v <sub>0</sub> = { <i>number of blocks with max.</i>  <i>length ‚â§ 1</i> } = 4 <br>  v <sub>1</sub> = { <i>number of blocks with max.</i>  <i>length = 2</i> } = 9 <br>  v <sub>2</sub> = { <i>number of blocks with max.</i>  <i>length = 3</i> } = 3 <br>  v <sub>3</sub> = { <i>number of blocks with max.</i>  <i>length ‚â• 4</i> } = 0 <br><br>  Calculate the chi-square: <br><img src="https://habrastorage.org/files/db5/e8b/16b/db5e8b16b6c74cf09a5f5ff6b1cd1568.png" height="40"><br><br>  Where the values ‚Äã‚Äãof K and R are taken from this table: <br><table><tbody><tr><th>  M </th><th>  K </th><th>  R </th></tr><tr><td>  eight </td><td>  3 </td><td>  sixteen </td></tr><tr><td>  128 </td><td>  five </td><td>  49 </td></tr><tr><td>  10,000 </td><td>  6 </td><td>  75 </td></tr></tbody></table><br>  Theoretical probabilities œÄ <sub>i</sub> are given by constants.  For example, for K = 3 and M = 8, it is recommended to take œÄ <sub>0</sub> = 0.2148, œÄ <sub>1</sub> = 0.3672, œÄ <sub>2</sub> = 0.2305, œÄ <sub>3</sub> = 0.1875.  (Values ‚Äã‚Äãfor other K and M are given in [2]). <br><img src="https://habrastorage.org/files/9f6/f98/888/9f6f988887734812b8a8a322d6772a70.png" height="40"><br><br>  Next, we calculate the P-value: <br><img src="https://habrastorage.org/files/b9d/1c3/200/b9d1c32008e94a07b3f364616cb11940.png" height="40"><br><br>  If it is&gt; 0.01, as in our example, then the sequence is considered to be quite random. <br><br><h2>  Test of binary matrices </h2><br>  The test analyzes the matrices that are composed of the original sequence, namely, it calculates the ranks of disjoint submatrices constructed from the initial binary sequence.  The test is based on Kovalenko‚Äôs research [6], where the scientist investigated random matrices consisting of 0 and 1. He showed that it is possible to predict the probabilities that the matrix M x Q will have the rank R, where R = 0, 1, 2 ... min (M, Q).  These probabilities are equal: <br><br><img src="https://habrastorage.org/files/88d/150/e00/88d150e002f3445c92cf474e7d378d34.png" height="36"><br><br>  NIST recommends taking M = Q = 32, as well as the sequence length n = M ^ 2 * N. But for example we take M = Q = 3. Next, we need the probabilities P <sub>M</sub> , P <sub>M-1</sub> and P <sub>M-2</sub> .  With a small degree of error, the formula can be simplified, and then these probabilities are equal: <br><br><img src="https://habrastorage.org/files/703/b93/8a5/703b938a50fa4c388a56af26b0b8dd5c.png" height="30"><br><br><img src="https://habrastorage.org/files/88b/c3d/937/88bc3d937c5d449db0bb52c9bd44f7d4.png" height="20"><br><br><img src="https://habrastorage.org/files/938/b6c/9d4/938b6c9d43864221b5dc06f736afa1dd.png" height="30"><br><br><img src="https://habrastorage.org/files/eb2/585/49f/eb258549fa9b4ef1909c70c453fba0d9.png" height="14"><br><br>  So, let the sequence 01011001001010101101 be given. "We decompose" it by matrices - enough for 2 matrices: <br><img src="https://habrastorage.org/files/49a/794/fda/49a794fda4ea4e3c9d120dbc9ac14af7.png" height="60"><img src="https://habrastorage.org/files/496/28a/aa3/49628aaa385e4f40a0d0748cd6820307.png" height="60"><br><br>  We determine the rank of the matrices: it turns out R <sub>1</sub> = 2, R <sub>2</sub> = 3. For the test you need 3 numbers: <br><ul><li>  F <sub>M</sub> = { <i>number of matrices with rank M</i> } = { <i>number of matrices with rank 3</i> } = 1 </li><li>  F <sub>M-1</sub> = 1 (similarly) </li><li>  N - F <sub>M</sub> - F <sub>M-1</sub> = 2 - 1 - 1 = 0 </li></ul>  Calculate the chi-square: <br><img src="https://habrastorage.org/files/daf/46b/25c/daf46b25cd6242bda161e94359c61707.png" height="40"><img src="https://habrastorage.org/files/374/a08/fc0/374a08fc04bb4a10a8c848630bde1da9.png" height="40"><br><br>  Calculate p-value: <br><img src="https://habrastorage.org/files/45c/9dd/3f8/45c9dd3f85fc4536b0cd82c7ef72957e.png" height="40"><br><br>  If the result is&gt; 0.01, the sequence is considered random.  NIST recommends that the total sequence length be&gt; = 38MQ. <br><br><h2>  Spectral test </h2><br>  The experimental sequence is considered as a discrete signal for which spectral decomposition is performed in order to identify frequency peaks.  Obviously, such peaks will indicate the presence of periodic components, which is not gut.  In short, the test reveals peaks exceeding the 95% barrier, after which it checks whether the proportion of these peaks does not exceed 5%. <br><br>  As you might guess, to represent the sequence as a sum of periodic components, we will use the discrete Fourier transform.  It looks like this: <br><img src="https://habrastorage.org/files/14b/7ed/0d9/14b7ed0d9a1d4c59bd78460e52c914e9.png" height="40"><br><br>  Here x <sub>k</sub> is the initial sequence, in which 1 corresponds to +1, and -1 to zero, X <sub>j</sub> - the obtained values ‚Äã‚Äãof the complex amplitudes (complex means that they contain both the real value of the amplitude and the phase). <br><br>  You ask, where is the periodicity here?  The answer is that the exponent can be expressed in terms of trigonometric functions: <br><img src="https://habrastorage.org/files/6a3/3e4/99f/6a33e499f118440c91563d9625d4b482.png" height="30"><img src="https://habrastorage.org/files/622/8d2/77c/6228d277c9de45f38bbdeba687e00d4d.png" height="16"><br><br>  For our test, it is not the phases that are interesting, but the absolute values ‚Äã‚Äãof the amplitudes.  And if we calculate these absolute values, then it turns out that they are symmetric (this is a well-known fact when moving from complex to real values), so for further consideration we will take only half of these values ‚Äã‚Äã(from 0 to n / 2) - the rest do not carry additional information. <br><br>  Let us show all this with an example.  Let the sequence be 1001010011. <br>  Then x = {1, -1, -1, 1, -1, 1, -1, -1, 1, 1}. <br><br>  Here's how Fourier decomposition can be done, for example, in the GNU Octave program: <br><pre><code class="bash hljs">octave:1&gt; x = [1, -1, -1, 1, -1, 1, -1, -1, 1, 1] x = 1 -1 -1 1 -1 1 -1 -1 1 1 octave:2&gt; abs(fft(x)) ans = 0.0000 2.0000 4.4721 2.0000 4.4721 2.0000 4.4721 2.0000 4.4721 2.0000</code> </pre>  We see that there is symmetry.  Therefore, five values ‚Äã‚Äãare enough for us: 0, 2, 4.4721, 2, 4.4721. <br><br>  Next, we calculate the boundary value by the formula <br><img src="https://habrastorage.org/files/af4/b2f/e02/af4b2fe021544fe1897b1813cadecc77.png" height="40"><br><br>  It means that if the sequence is truly random, then 95% of the peaks should not exceed this limit. <br><br>  Calculate the maximum number of peaks, which must be less than T: <br><img src="https://habrastorage.org/files/189/e3b/be0/189e3bbe01934f5ab7adeeb1a988e152.png" height="30"><br><br>  Next, we look at the result of the decomposition and see that all our 4 peaks are less than the boundary value.  Further we estimate this difference: <br><img src="https://habrastorage.org/files/54b/245/f5b/54b245f5b0cd470085feeac04e77bf22.png" height="40"><br><br>  Calculate p-value: <br><img src="https://habrastorage.org/files/5a7/d6a/ff7/5a7d6aff768441768db980ca9ccd0ac7.png" height="36"><br><br>  It turned out&gt; 0.01, so the hypothesis of randomness is accepted.  And yes, for the test it is recommended to take at least 1000 bits. <br><br><h2>  Test for non-intersecting patterns </h2><br>  The experimental sequence is divided into blocks of the same length.  For example: <br> <code>1010010010 1110010110</code> <br> <br>  In each block we will look for some pattern, for example, ‚Äú001‚Äù.  The word <i>disjoint</i> means that if a pattern is found within a sequence, the following comparison will not capture a single bit of the pattern found.  As a result of the search for each i-th block will be found the number of W <sub>i</sub> equal to the number of cases found. <br><br>  So, for our blocks, W <sub>1</sub> = 2 and W <sub>2</sub> = 1: <br>  101 <b>001</b> <b>001</b> 0 <br>  111 <b>001</b> 0110 <br><br>  We calculate the expectation and variance, as if our sequence was truly random.  Below are the formulas.  Here N = 2 (number of blocks), M = 10 (block length), m = 3 (sample length). <br><br><img src="https://habrastorage.org/files/a2d/c4b/f90/a2dc4bf9069f46438b754dff80d9c607.png" height="40"><br><br><img src="https://habrastorage.org/files/a81/e2e/e17/a81e2ee17594457d957cb2bf04c18ac0.png" height="40"><br><br>  Calculate the chi-square: <br><br><img src="https://habrastorage.org/files/d92/991/496/d929914966ee42609033948a324d5603.png" height="50"><br><br>  Calculate the final P-value through an incomplete gamma function: <br><br><img src="https://habrastorage.org/files/f3b/b68/7ff/f3bb687ff244454287f4cc3babc667c1.png" height="50"><br><br>  We see that the P-value is&gt; 0.1, which means that the sequence is quite random. <br><br>  We only rated one template.  In fact, you need to check all the combinations of templates, and besides, for different lengths of these templates.  How much is needed is determined on the basis of specific requirements, but usually <i>m</i> takes 9 or 10. To get meaningful results, you should take N &lt;100 and M&gt; 0.01 * n. <br><br><h2>  Test for intersecting patterns </h2><br>  This test differs from the previous one in that when the search pattern is found, the search window shifts not by the pattern length, but only by 1 bit.  In order not to clutter the article, we will not give an example of calculation by this method.  It is completely analogous. <br><br><h2>  Mauer Universal Test </h2><br>  The test assesses how far away the patterns within the sequence are from each other.  The meaning of the test is to understand how the sequence is compressible (of course, I mean lossless compression).  The more compressible the sequence, the less random it is.  The algorithm of this test is very cumbersome for the Habra-format, so we omit it. <br><br><h2>  Linear complexity test </h2><br>  The test is based on the assumption that the experimental sequence was obtained through a <i>linear</i> feedback shift register (or LFSR, Linear feedback shift register).  This is a well-known method of obtaining an infinite sequence: here each next bit is obtained as a certain function of the bits "sitting" in the register.  The minus of the LFSR is that it always has a finite period, i.e.  the sequence will be repeated sooner or later.  The greater the length of the LFSR, the <i>better the</i> random sequence. <br><br>  The initial sequence is divided into equal blocks of length M. Further, for each block using the Berlekamp ‚Äì Massey algorithm [10], its linear complexity (L <sub>i</sub> ) is found, i.e.  length lfsr.  Then for all found L <sub>i</sub> , the Chi-square distribution with 6 degrees of freedom is estimated.  We show by example. <br><br>  Let block 1101011110001 (M = 13) be given, for which the Berlekamp ‚Äì Massey algorithm issued L = 4. Make sure that this is so.  Indeed, it is not difficult to guess that for this block each next bit is obtained as the sum (modulo 2) of the 1st and 2nd bits (numbering from 1): <br>  x <sub>5</sub> = x <sub>1</sub> + x <sub>2</sub> = 1 + 1 = 0 <br>  x <sub>6</sub> = x <sub>2</sub> + x <sub>3</sub> = 1 + 0 = 1 <br>  x <sub>7</sub> = x <sub>3</sub> + x <sub>4</sub> = 1 + 0 = 1 <br>  etc. <br><br>  Calculate the expectation of the formula <br><img src="https://habrastorage.org/files/3af/500/c6e/3af500c6e5664146946c6b93d66ded3a.png" height="36"><br><br>  For each block, we calculate the value of T <sub>i</sub> : <br><img src="https://habrastorage.org/files/eaa/2dd/eff/eaa2ddeff55a46498404b69c2bfd3759.png" height="28"><br><br>  Further, on the basis of the set T, we calculate the set v <sub>0</sub> , ..., v <sub>6</sub> in the following way: <br><ul><li>  if T <sub>i</sub> &lt;= -2.5, then v <sub>0</sub> ++ </li><li>  if -2.5 &lt;T <sub>i</sub> &lt;= -1.5, then v <sub>1</sub> ++ </li><li>  if -1.5 &lt;T <sub>i</sub> &lt;= -0.5, then v <sub>2</sub> ++ </li><li>  if -0.5 &lt;T <sub>i</sub> &lt;= 0.5, then v <sub>3</sub> ++ </li><li>  if 0.5 &lt;T <sub>i</sub> &lt;= 1.5, then v <sub>4</sub> ++ </li><li>  if 1.5 &lt;T <sub>i</sub> &lt;= 2.5, then v <sub>5</sub> ++ </li><li>  if T <sub>i</sub> &gt; 2.5, then v <sub>6</sub> ++ </li></ul><br><br>  We have 7 possible outcomes, and therefore we calculate Chi-square with the number of degrees of freedom 7 - 1 = 6: <br><img src="https://habrastorage.org/files/1f3/36a/dd7/1f336add747d45178aeb4b6ad0414ea7.png" height="40"><br>  The probabilities œÄ <sub>i</sub> in the test are rigidly set and equal, respectively: 0.010417, 0.03125, 0.125, 0.5, 0.25, 0.0625, 0.020833.  (œÄ <sub>i</sub> for a larger number of degrees of freedom can be calculated by the formulas given in [2]). <br><br>  Calculate p-value: <br><img src="https://habrastorage.org/files/414/d5f/883/414d5f883a7c45e483c9911cbbd9495e.png" height="30"><br><br>  If the result is&gt; 0.01, the sequence is considered random.  For real tests, it is recommended to take n&gt; = 10 ^ 6 and M in the range from 500 to 5000. <br><br><h2>  Subsequence test </h2><br>  The frequency of finding all possible sequences of length ‚Äúm‚Äù bits within the original sequence is analyzed.  In addition, each sample is searched independently, i.e.  It is possible, as it were, to ‚Äúsuperimpose‚Äù one found sample on another.  Obviously, the number of all possible samples will be 2 <sup>m</sup> .  If the sequence is large enough and random, then the probability of finding each of these samples is the same.  (By the way, if m = 1, then this test "degenerates" into the already described test for the ratio of "0" or "1"). <br><br>  The basis of the test is the work [8] and [11].  It describes 2 indicators (‚àáœà <sup>2</sup> <sub>m</sub> and ‚àá <sup>2</sup> <sup>2</sup> <sub>m</sub> ), which characterize how much the frequency of appearance of samples correspond to the same frequencies for a truly random sequence.  We show the algorithm by example. <br><br>  Let sequence 0011011101 be given with length n = 10 and also m = 3. <br><br>  First, 3 new sequences are formed, each of which is obtained by adding m-1 first bits of the sequence to its end.  It turns out: <br><ul><li>  For m = 3: 0011011101 00 (added 2 bits to the end) </li><li>  For m-1 = 2: 0011011101 0 (added 1 bit to the end) </li><li>  For m-2 = 1: 0011011101 (source sequence) </li></ul>  Next we find the frequency of occurrence of all blocks of length m, m-1 and m-2, respectively: <br><ul><li>  v <sub>000</sub> = 0, v <sub>001</sub> = 1, v <sub>010</sub> = 1, v <sub>011</sub> = 2, v <sub>100</sub> = 1, v <sub>101</sub> = 2, v <sub>110</sub> = 2, v <sub>111</sub> = 0 </li><li>  v <sub>00</sub> = 1, v <sub>01</sub> = 3, v <sub>10</sub> = 3, v <sub>11</sub> = 3 </li><li>  v <sub>0</sub> = 4, v <sub>1</sub> = 6 </li></ul>  We calculate the necessary statistics by the formulas: <br><img src="https://habrastorage.org/files/969/bde/c40/969bdec40a904d1c93444c1fe6f8f37e.png" height="30"><img src="https://habrastorage.org/files/e91/6a9/244/e916a9244e154ab09a6b397c7bb4e4e9.png" height="30"><img src="https://habrastorage.org/files/8d2/94c/339/8d294c3398764b5ab9a9e854265021d9.png" height="30"><br><br>  Substitute: <br><img src="https://habrastorage.org/files/184/0f5/025/1840f50259ce4b488d8c04c3657c0215.png" height="24"><img src="https://habrastorage.org/files/683/01d/ecb/68301decba654b078e7806e22693b8d5.png" height="30"><img src="https://habrastorage.org/files/fa0/50a/61b/fa050a61b69045b19af753c38c9202e2.png" height="30"><br><br>  Then: <br><br><img src="https://habrastorage.org/files/d9a/bbe/966/d9abbe9665014675b25366384ee441da.png" height="24"><br><br><img src="https://habrastorage.org/files/b4a/413/40e/b4a41340ea064f4ea6fa613fe0480fd1.png" height="24"><br><br>  Totals: <br><img src="https://habrastorage.org/files/8a8/cfe/017/8a8cfe01751e43d29226fe20e2eb8e71.png" height="30"><img src="https://habrastorage.org/files/28b/922/09b/28b92209b54f4e4d9c1341fc5ad4601d.png" height="30"><br><br>  So, both P-values ‚Äã‚Äãare&gt; 0.01, which means the sequence is considered random. <br><br><h2>  Approximate entropy </h2><br>  The method of approximate entropy (Approximate Entropy) initially manifested itself in medicine, especially in cardiology.  In general, according to the classical definition, entropy is a measure of chaos: the higher it is, the more unpredictable phenomena.  Good or bad depends on the context.  For random sequences used in cryptography, it is important to have high entropy - this means that it will be difficult to predict subsequent random bits based on what we already have.  But, for example, if we take the heart rate measured with a given period as a random variable, the situation is different: there are many studies (for example, [12]) that prove that the lower the heart rate variability, the less likely the likelihood of heart attacks and other unpleasant phenomena .  It is obvious that a person‚Äôs heart cannot beat with a constant frequency.  However, some die from heart attacks, while others do not.  Therefore, the method of approximate entropy allows us to estimate how seemingly random phenomena <i>really are random</i> . <br><br>  Specifically, the test calculates the frequency of occurrence of various samples of a given length (m), and then similar frequencies, but already for samples of length m + 1.  The frequency distribution is then compared to the reference Chi-squared distribution.  As in the previous test, the samples may overlap. <br><br>  We show by example.  Let the sequence 0100110101 (length n = 10) be given, and take m = 3. <br><br>  To begin with, we complement the sequence with the first m-1 bits.  It turns out 0100110101 01. <br><br>  Calculate the occurrence of each of the 8 different blocks.  It turns out: <br>  k <sub>000</sub> = 0, k <sub>001</sub> = 1, k <sub>010</sub> = 3, k <sub>011</sub> = 1, k <sub>100</sub> = 1, k <sub>101</sub> = 3, k <sub>110</sub> = 1, k <sub>111</sub> = 0. <br><br>  Calculate the corresponding frequencies according to the formula C <sub>i</sub> <sup>m</sup> = k <sub>i</sub> / n: <br>  C <sub>000</sub> <sup>3</sup> = 0, C <sub>001</sub> <sup>3</sup> = 0.1, C <sub>010</sub> <sup>3</sup> = 0.3, C <sub>011</sub> <sup>3</sup> = 0.1, C <sub>100</sub> <sup>3</sup> = 0.1, C <sub>101</sub> <sup>3</sup> = 0.3, C <sub>110</sub> <sup>3</sup> = 0.1, C <sub>111</sub> <sup>3</sup> = 0. <br><br>  Similarly, we assume the frequency of occurrence of sub-blocks of length m + 1 = 4.  There are already 2 <sup>4</sup> = 16: <br>  C <sub>0011</sub> <sup>4</sup> = C <sub>0100</sub> <sup>4</sup> = C <sub>0110</sub> <sup>4</sup> = C <sub>1001</sub> <sup>4</sup> = C <sub>1101</sub> <sup>4</sup> = 0.1, C <sub>0101</sub> <sup>4</sup> = 0.2, C <sub>1010</sub> <sup>4</sup> = 0.3.  Remaining frequencies = 0. <br><br>  Calculate œÜ <sup>3</sup> and œÜ <sup>4</sup> (note that the natural logarithm is here): <br><br><img src="https://habrastorage.org/files/e7b/0d9/859/e7b0d98590ce4d049694b35b289843de.png" height="60"><br><br><img src="https://habrastorage.org/files/472/586/d86/472586d86d2c4575a4c2e13bf085c568.png" height="60"><br><br>  Calculate the chi-square: <br><img src="https://habrastorage.org/files/ef9/ead/00f/ef9ead00fc5541f286fadcc5e1a71e68.png" height="30"><br><br>  P-value: <br><img src="https://habrastorage.org/files/de2/2a4/c24/de22a4c240f443bd8c40d73a82eacadf.png" height="40"><br><br>  The resulting value is&gt; 0.01, which means the sequence is considered random. <br><br><h2>  Cumulative test </h2><br>  We take each zero bit of the original sequence for -1, and each one - for +1, after which we calculate the sum.  Intuitively, the more random the sequence, the faster this amount will tend to zero.  On the other hand, imagine that a sequence is given, consisting of 100 zeros and 100 units, running in a row: 00000 ... 001111 ... 11.  Here, the amount will be equal to 0, but it is obvious that to call <i>such a</i> sequence a random "hand will not rise."  Therefore, a deeper criterion is needed.  And this criterion is partial amounts.  We will gradually calculate the amounts starting from the first element: <br>  S <sub>1</sub> = x <sub>1</sub> <br>  S <sub>2</sub> = x <sub>1</sub> + x <sub>2</sub> S <sub>3</sub> = x <sub>1</sub> + x <sub>2</sub> + x <sub>3</sub> ... <br>  S <sub>n</sub> = x <sub>1</sub> + x <sub>2</sub> + x <sub>3</sub> +‚Ä¶ + x <sub>n</sub> <br><br>  Next is the number z = maximum among these sums. <br><br>  Finally, the P-value is calculated according to the following formula (see its derivation in [9]): <br><img src="https://habrastorage.org/files/50a/723/071/50a723071c9e42c9902636b6cd597750.png" height="20"><br><br>  Where: <br><img src="https://habrastorage.org/files/cb1/1b5/264/cb11b526407b4485aaf902ac26422a3c.png" height="50"><br><br><img src="https://habrastorage.org/files/9a6/d30/862/9a6d30862ecb4c88938dd4c313c9ad54.png" height="50"><br><br>  Here Œ¶ is the distribution function of the standard normal random variable.  We recall that the standard normal distribution is the well-known Gaussian distribution (in the shape of a bell), whose expectation is 0 and variance 1. It looks like this: <br><img src="https://habrastorage.org/files/b33/c64/008/b33c6400861b4dd9a3de217a47d9e504.png" height="40"><br><br>  If the resulting P-value&gt; 0.01, then the sequence is considered random. <br><br>  By the way, this test has 2 modes: the first one we just reviewed, and the second amount is calculated starting from the last element. <br><br><h2>  Random deviation test </h2><br>  This test is similar to the previous one: in a similar way, partial sums of a normalized sequence (ie, consisting of -1 and 1) are considered.  Let sequence 0110110101 be given and let S (i) be the partial sum from 1 to the i-th element.  Put these points on the graph, preliminarily adding ‚Äú0‚Äù to the beginning and end of the sequence S (i) - this is necessary for the integrity of the further calculations: <br><img src="https://habrastorage.org/files/79a/ce6/8d0/79ace68d036d4a4093ff0e7f5f0d6ca9.png"><br>  Note the points where the graph intersects the horizontal axis - these points will divide the sequence into so-called.  <i>cycles</i> .  Here we have 3 cycles: {0, -1, 0}, {0, 1, 0} and {0, 1, 2, 1, 2, 1, 2, 0}.  Further, it is said that each of these cycles successively takes on different <i>states</i> .  For example, the first cycle 2 times takes the state "0" and 1 time the state "-1".  For this test, the states from -4 to 4 are of interest. Add all the occupations in these states to the following table: <br><table><tbody><tr><th>  State (x) </th><th>  Cycle number 1 </th><th>  Cycle number 2 </th><th>  Cycle number 3 </th></tr><tr><td>  -four </td><td>  0 </td><td>  0 </td><td>  0 </td></tr><tr><td>  -3 </td><td>  0 </td><td>  0 </td><td>  0 </td></tr><tr><td>  -2 </td><td>  0 </td><td>  0 </td><td>  0 </td></tr><tr><td>  -one </td><td>  one </td><td>  0 </td><td>  0 </td></tr><tr><td>  one </td><td>  0 </td><td>  one </td><td>  3 </td></tr><tr><td>  2 </td><td>  0 </td><td>  0 </td><td>  3 </td></tr><tr><td>  3 </td><td>  0 </td><td>  0 </td><td>  0 </td></tr><tr><td>  four </td><td>  0 </td><td>  0 </td><td>  0 </td></tr></tbody></table><br>  On the basis of this table, we form another table: in it horizontally, the <u>number of</u> cycles will go, taking a given state: <br><table><tbody><tr><th>  State (x) </th><th>  Never </th><th>  1 time </th><th>  2 times </th><th>  3 times </th><th>  4 times </th><th>  5 times </th></tr><tr><td>  -four </td><td>  3 </td><td>  0 </td><td>  0 </td><td>  0 </td><td>  0 </td><td>  0 </td></tr><tr><td>  -3 </td><td>  3 </td><td>  0 </td><td>  0 </td><td>  0 </td><td>  0 </td><td>  0 </td></tr><tr><td>  -2 </td><td>  3 </td><td>  0 </td><td>  0 </td><td>  0 </td><td>  0 </td><td>  0 </td></tr><tr><td>  -one </td><td>  2 </td><td>  one </td><td>  0 </td><td>  0 </td><td>  0 </td><td>  0 </td></tr><tr><td>  one </td><td>  one </td><td>  one </td><td>  0 </td><td>  one </td><td>  0 </td><td>  0 </td></tr><tr><td>  2 </td><td>  2 </td><td>  0 </td><td>  0 </td><td>  one </td><td>  0 </td><td>  0 </td></tr><tr><td>  3 </td><td>  3 </td><td>  0 </td><td>  0 </td><td>  0 </td><td>  0 </td><td>  0 </td></tr><tr><td>  four </td><td>  3 </td><td>  0 </td><td>  0 </td><td>  0 </td><td>  0 </td><td>  0 </td></tr></tbody></table><br>  Then, for each of the eight states, a Chi-square of statistics is calculated using the formula <br><img src="https://habrastorage.org/files/9b7/084/90f/9b708490f7d64884a130581a524c8914.png" height="40"><br><br>  Where v <sub>k</sub> (x) is the values ‚Äã‚Äãin the table for a given state, J is the number of cycles (we have 3), œÄ <sub>k</sub> (x) are the probabilities that the state ‚Äúx‚Äù will occur k times in a truly random distribution (they are known). <br><br>  For example, for x = 1 we get: <br><img src="https://habrastorage.org/files/8b6/55a/b15/8b655ab151c3466cbb6e460a1e9ea285.png" height="80"><br><br>  The values ‚Äã‚Äãof œÄ for the remaining <i>x are given</i> in [2]. <br><br>  Calculate p-value: <br><img src="https://habrastorage.org/files/32f/5fb/e0a/32f5fbe0a9584c6f8861314ce3ffe482.png" height="40"><br><br>  If it is&gt; 0.01, then the conclusion is made about randomness.  As a result, it is necessary to calculate 8 P-values.  Some may be more than 0.01, some - less.  In this case, the final decision on the sequence is made on the basis of other tests. <br><br><h2>  Variety test for arbitrary deviations </h2><br>  It is almost similar to the previous test, but a wider set of states is taken: -9, -8, -7, -6, -5, -4, -3, -2, -1, +1, +2, +3, + 4, +5, +6, +7, +8, +9.  But the main difference is that here the P-value is calculated not through the gamma function (igamc) and Chi-square, but through the error function (erfc).  For exact formulas the reader can refer to the original document. <br><br>  Below is a list of sources that you can see if you want to delve into the topic: <br><br><ol><li>  <a href="http://csrc.nist.gov/groups/ST/toolkit/rng/stats_tests.html">csrc.nist.gov/groups/ST/toolkit/rng/stats_tests.html</a> </li><li>  <a href="http://csrc.nist.gov/groups/ST/toolkit/rng/documents/SP800-22rev1a.pdf">csrc.nist.gov/groups/ST/toolkit/rng/documents/SP800-22rev1a.pdf</a> </li><li>  <a href="https://ru.wikipedia.org/wiki/%25D0%25A6%25D0%25B5%25D0%25BD%25D1%2582%25D1%2580%25D0%25B0%25D0%25BB%25D1%258C%25D0%25BD%25D0%25B0%25D1%258F_%25D0%25BF%25D1%2580%25D0%25B5%25D0%25B4%25D0%25B5%25D0%25BB%25D1%258C%25D0%25BD%25D0%25B0%25D1%258F_%25D1%2582%25D0%25B5%25D0%25BE%25D1%2580%25D0%25B5%25D0%25BC%25D0%25B0">Central limit theorem</a> </li><li>  Anant P. Godbole and Stavros G. Papastavridis, (ed), Runs and patterns in probability: Selected papers.  Dordrecht: Kluwer Academic, 1994 </li><li>  Pal Revesz, Random Walk in Random and Non-Random Environments.  Singapore: World Scientific, 1990 </li><li>  I. N. Kovalenko, Theory of probability and its applications, 1972 </li><li>  O. Chrysaphinou, S. Papastavridis, ‚ÄúA Limit Theorem‚Äù on the Sequence of Independent Trials. ‚ÄùFields, Vol.  79, 1988 </li><li>  IJ Good, ‚ÄúThe serial test for sampling numbers,‚Äù Cambridge, 1953 </li><li>  A. Rukhin, ‚ÄúApproximate entropy for testing randomness,‚Äù Journal of Applied Probability, 2000 </li><li>  <a href="https://ru.wikipedia.org/wiki/%25D0%2590%25D0%25BB%25D0%25B3%25D0%25BE%25D1%2580%25D0%25B8%25D1%2582%25D0%25BC_%25D0%2591%25D0%25B5%25D1%2580%25D0%25BB%25D0%25B5%25D0%25BA%25D1%258D%25D0%25BC%25D0%25BF%25D0%25B0_%25E2%2580%2594_%25D0%259C%25D1%258D%25D1%2581%25D1%2581%25D0%25B8">Berlekampa - Massey Algorithm</a> </li><li>  DE Knuth, The Art of Computer Programming.  Vol.  2 &amp; 3, 1998 </li><li>  <a href="http://www.ncbi.nlm.nih.gov/pubmed/8466069">www.ncbi.nlm.nih.gov/pubmed/8466069</a> </li></ol></div><p>Source: <a href="https://habr.com/ru/post/237695/">https://habr.com/ru/post/237695/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../237685/index.html">New service from Fortumo.com for carrier billing of purchases in Windows Phone and Windows applications</a></li>
<li><a href="../237687/index.html">Mobile HTML5</a></li>
<li><a href="../237689/index.html">How-to: Creating trading robots in TradeScript vol. 2</a></li>
<li><a href="../237691/index.html">The little robot controls the plane like a real pilot.</a></li>
<li><a href="../237693/index.html">We check Oracle VM VirtualBox. Part 2</a></li>
<li><a href="../237697/index.html">Some interesting and useful things for web developer # 29</a></li>
<li><a href="../237699/index.html">Professions of the future: 3D printing in medicine</a></li>
<li><a href="../237701/index.html">Why can't I reset my password?</a></li>
<li><a href="../237703/index.html">From smart glass to smart home - the wonders of Chinese startups</a></li>
<li><a href="../237705/index.html">The relationship of UX and optimization: how to do it correctly</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>