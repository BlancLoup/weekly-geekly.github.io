<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>An example of solving a credit scoring problem using a python + pandas + scikit-learn bundle</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Introduction 
 Good afternoon, dear readers. 
 Recently, wandering through the expanses of the global web, I stumbled upon a tournament that was held ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>An example of solving a credit scoring problem using a python + pandas + scikit-learn bundle</h1><div class="post__text post__text-html js-mediator-article"><h4>  Introduction </h4><br>  Good afternoon, dear readers. <br>  Recently, wandering through the expanses of the global web, I stumbled upon a <a href="https://www.tcsbank.ru/tournament/">tournament</a> that was held by TCS at the beginning of this year.  After reviewing the tasks, I decided to test my skills in analyzing data on them. <br>  I decided to start checking with the scoring problem (Task ‚Ññ3).  To solve it, I, as always, used Python with analytical modules <a href="http://pandas.pydata.org/pandas-docs/stable/">pandas</a> and <a href="http://scikit-learn.org/stable/index.html">scikit-learn</a> . <br><a name="habracut"></a><br><h4>  Data Description and Problem Statement </h4><br>  The bank requests the applicant's credit history at the three largest Russian credit bureaus.  A selection of Bank clients is provided in the <a href="">SAMPLE_CUSTOMERS.CSV</a> file.  The sample is divided into parts ‚Äútrain‚Äù and ‚Äútest‚Äù.  From the ‚Äútrain‚Äù sample, we know the value of the target variable bad - the presence of a ‚Äúdefault‚Äù (assuming the client has delayed 90 days or more during the first year of using the loan).  The <a href="">SAMPLE_ACCOUNTS.CSV</a> file <a href="">contains</a> data from the responses of credit bureaus to all inquiries about the relevant clients. <br>  Data format <b>SAMPLE_CUSTOMERS</b> - information about the possibility of default of a certain person. <br>  Description of the format of the dataset <b>SAMPLE_ACCOUNTS</b> : <br><div class="spoiler">  <b class="spoiler_title">Kit Description</b> <div class="spoiler_text"><table><tbody><tr><th>  Name </th><th>  Description </th></tr><tr><td>  <i>TCS_CUSTOMER_ID</i> </td><td>  Customer ID </td></tr><tr><td>  <i>BUREAU_CD</i> </td><td>  Bureau code from which the invoice is received </td></tr><tr><td>  <i>BKI_REQUEST_DATE</i> </td><td>  Date on which the request was made to the bureau </td></tr><tr><td>  <i>CURRENCY</i> </td><td>  Currency of contract (ISO letter code of currency) </td></tr><tr><td>  <i>RELATIONSHIP</i> </td><td>  Type of relationship to the contract </td></tr><tr><td rowspan="5"></td><td>  1 - Individual </td></tr><tr><td>  2 - Additional card / Authorized user </td></tr><tr><td>  4 - Joint </td></tr><tr><td>  5 - Guarantor </td></tr><tr><td>  9 - Legal entity </td></tr><tr><td>  <i>OPEN_DATE</i> </td><td>  Date of opening of the contract </td></tr><tr><td>  <i>FINAL_PMT_DATE</i> </td><td>  Date of final payment (scheduled) </td></tr><tr><td>  <i>TYPE</i> </td><td>  Contract Type Code </td></tr><tr><td rowspan="11"></td><td>  1 - Car loan </td></tr><tr><td>  4 - Leasing </td></tr><tr><td>  6 - Mortgage </td></tr><tr><td>  7 - Credit Card </td></tr><tr><td>  9 - Consumer credit </td></tr><tr><td>  10 - Business Development Credit </td></tr><tr><td>  11 - Loan for replenishment of working capital </td></tr><tr><td>  12 - Credit for the purchase of equipment </td></tr><tr><td>  13 - Real estate construction loan </td></tr><tr><td>  14 - Credit for the purchase of shares (for example, margin lending) </td></tr><tr><td>  99 - Other </td></tr><tr><td>  <i>PMT_STRING_84M</i> </td><td>  Discipline (timeliness) of payments.  The string is made up of account status codes at the time the bank sends data on the account to the bureau, the first character is the state as of date PMT_STRING_START, then successively in descending order of dates. <br></td></tr><tr><td rowspan="11"></td><td>  0 - New, evaluation is not possible </td></tr><tr><td>  X - No information </td></tr><tr><td>  1 - Payment without delay </td></tr><tr><td>  A - Delay from 1 to 29 days </td></tr><tr><td>  2 - Delay from 30 to 59 days </td></tr><tr><td>  3 - Delay from 60 to 89 days </td></tr><tr><td>  4 - Delay from 90 to 119 days </td></tr><tr><td>  5 - Delay more than 120 days </td></tr><tr><td>  7 - Regular consolidated payments </td></tr><tr><td>  8 - Loan repayment using collateral </td></tr><tr><td>  9 - Bad debt / transferred for collection / missed payment </td></tr><tr><td>  <i>STATUS</i> </td><td>  Contract status </td></tr><tr><td rowspan="7"></td><td>  00 - Active </td></tr><tr><td>  12 - Paid by collateral </td></tr><tr><td>  13 - Account is closed </td></tr><tr><td>  14 - Transferred to another bank for service </td></tr><tr><td>  21 - Dispute </td></tr><tr><td>  52 - Overdue </td></tr><tr><td>  61 - Return Problems </td></tr><tr><td>  <i>OUTSTANDING</i> </td><td>  Remaining outstanding debt.  Amount in rubles at the rate of the Central Bank of the Russian Federation </td></tr><tr><td>  <i>NEXT_PMT</i> <br></td><td>  The amount of the next payment.  Amount in rubles at the rate of the Central Bank of the Russian Federation </td></tr><tr><td>  <i>INF_CONFIRM_DATE</i> </td><td>  Date of confirmation of account information </td></tr><tr><td>  <i>FACT_CLOSE_DATE</i> <br></td><td>  Account closure date (actual) <br></td></tr><tr><td>  <i>TTL_DELQ_5</i> <br></td><td>  Number of delinquency up to 5 days <br></td></tr><tr><td>  <i>TTL_DELQ_5_29</i> <br></td><td>  The number of delinquencies from 5 to 29 days <br></td></tr><tr><td>  <i>TTL_DELQ_30_59</i> <br></td><td>  The number of delinquencies from 30 to 59 days <br></td></tr><tr><td>  <i>TTL_DELQ_60_89</i> <br></td><td>  The number of delinquencies from 60 to 89 days <br></td></tr><tr><td>  <i>TTL_DELQ_30</i> <br></td><td>  Number of delinquency up to 30 days <br></td></tr><tr><td>  <i>TTL_DELQ_90_PLUS</i> <br></td><td>  90+ days overdue <br></td></tr><tr><td>  <i>PMT_FREQ</i> <br></td><td>  Payment Rate Code <br></td></tr><tr><td rowspan="9"></td><td>  1 - Weekly <br></td></tr><tr><td>  2 - Every other week <br></td></tr><tr><td>  3 - Monthly <br></td></tr><tr><td>  A - Once every 2 months <br></td></tr><tr><td>  4 - Quarterly <br></td></tr><tr><td>  B - Once every 4 months <br></td></tr><tr><td>  5 - Every six months <br></td></tr><tr><td>  6 - Annually <br></td></tr><tr><td>  7 - Other <br></td></tr><tr><td>  <i>CREDIT_LIMIT</i> <br></td><td>  Credit limit.  Amount in rubles at the rate of the Central Bank of the Russian Federation <br></td></tr><tr><td>  <i>DELQ_BALANCE</i> <br></td><td>  Current arrears.  Amount in rubles at the rate of the Central Bank of the Russian Federation <br></td></tr><tr><td>  <i>MAX_DELQ_BALANCE</i> <br></td><td>  The maximum amount of arrears.  Amount in rubles at the rate of the Central Bank of the Russian Federation <br></td></tr><tr><td>  <i>CURRENT_DELQ</i> <br></td><td>  The current number of days overdue <br></td></tr><tr><td>  <i>PMT_STRING_START</i> <br></td><td>  Start date of the line PMT_STRING_84M <br></td></tr><tr><td>  <i>INTEREST_RATE</i> <br></td><td>  Loan interest rate <br></td></tr><tr><td>  <i>CURR_BALANCE_AMT</i> <br></td><td>  The total amount paid, including the amount of principal, interest, penalties and fines.  Amount in rubles at the rate of the Central Bank of the Russian Federation <br></td></tr></tbody></table><br></div></div><br><br>  The task is to build a model that determines the probability of "default" on <i>the train</i> sample and put its probabilities on clients from <i>the test</i> sample.  To evaluate the model, the <b>Area Under ROC Curve</b> characteristic will be used (also indicated in the problem conditions). <br><br><h4>  Preliminary data processing </h4><br>  First, download the source files and look at them: <br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> pandas <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> read_csv, DataFrame <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.metrics <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> roc_curve <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.ensemble <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> RandomForestClassifier, GradientBoostingClassifier <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.cross_validation <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> train_test_split <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.naive_bayes <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> GaussianNB <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.neighbors <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> KNeighborsClassifier <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.decomposition <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> PCA <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> ml_metrics, string, re, pylab <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> pl SampleCustomers = read_csv(<span class="hljs-string"><span class="hljs-string">"https://static.tcsbank.ru/documents/olymp/SAMPLE_CUSTOMERS.csv"</span></span>, <span class="hljs-string"><span class="hljs-string">';'</span></span>) SampleAccounts = read_csv(<span class="hljs-string"><span class="hljs-string">"https://static.tcsbank.ru/documents/olymp/SAMPLE_ACCOUNTS.csv"</span></span>,<span class="hljs-string"><span class="hljs-string">";"</span></span>,decimal =<span class="hljs-string"><span class="hljs-string">','</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> SampleAccounts</code> </pre> <br><img src="https://habrastorage.org/getpro/habr/post_images/428/028/3df/4280283df2545a36cc1c3220e32badea.png" alt="image">
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <pre> <code class="python hljs">SampleCustomers.head()</code> </pre> <br><table><tbody><tr><th></th><th>  tcs_customer_id </th><th>  bad </th><th>  sample_type </th></tr><tr><th>  0 </th><td>  one </td><td>  NaN </td><td>  test </td></tr><tr><th>  one </th><td>  2 </td><td>  0 </td><td>  train </td></tr><tr><th>  2 </th><td>  3 </td><td>  one </td><td>  train </td></tr><tr><th>  3 </th><td>  four </td><td>  0 </td><td>  train </td></tr><tr><th>  four </th><td>  five </td><td>  0 </td><td>  train </td></tr></tbody></table><br><br>  From the conditions of the problem, we can assume that the SampleAccounts set contains several records for one borrower, let's check this: <br><br><pre> <code class="python hljs">SampleAccounts.tcs_customer_id.drop_duplicates().count(), SampleAccounts.tcs_customer_id.count()</code> </pre> <br>  Our assumption turned out to be true.  Unique borrowers 50000 of 280942 records.  This is due to the fact that one borrower has several credits and for each of them there will be different information in different bureaus.  Therefore, you need to perform transformations on SampleAccounts to match one line to one borrower. <br>  Now let's get a list of all unique loans for each borrower: <br><br><pre> <code class="python hljs">SampleAccounts[[<span class="hljs-string"><span class="hljs-string">'tcs_customer_id'</span></span>,<span class="hljs-string"><span class="hljs-string">'open_date'</span></span>,<span class="hljs-string"><span class="hljs-string">'final_pmt_date'</span></span>,<span class="hljs-string"><span class="hljs-string">'credit_limit'</span></span>,<span class="hljs-string"><span class="hljs-string">'currency'</span></span>]].drop_duplicates()</code> </pre> <br>  Therefore, when we received a list of credits, we will be able to display any general information on each element of the list.  Those.  it would be possible to take a bundle of the above fields and make it an index with respect to which we would perform further manipulations, but, unfortunately, there is one unpleasant moment that lies in wait for us.  It lies in the fact that the 'final_pmt_date' field in the data set has blank values.  Let's try to get rid of them. <br>  We have an actual closing date of the loan in the set, therefore, if it is, and the 'final_pmt_date' field is not filled, then we can write this value into it.  For the rest, just write 0. <br><br><pre> <code class="python hljs">SampleAccounts.final_pmt_date[SampleAccounts.final_pmt_date.isnull()] = SampleAccounts.fact_close_date[SampleAccounts.final_pmt_date.isnull()].astype(float) SampleAccounts.final_pmt_date.fillna(<span class="hljs-number"><span class="hljs-number">0</span></span>, inplace=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)</code> </pre><br>  Now that we‚Äôve gotten rid of empty values, let's get the most recent date for contacting any of the bureaus for each of the loans.  It is useful for us to determine its attributes, such as contract status, type, etc. <br><br><pre> <code class="python hljs">sumtbl = SampleAccounts.pivot_table([<span class="hljs-string"><span class="hljs-string">'inf_confirm_date'</span></span>], [<span class="hljs-string"><span class="hljs-string">'tcs_customer_id'</span></span>,<span class="hljs-string"><span class="hljs-string">'open_date'</span></span>,<span class="hljs-string"><span class="hljs-string">'final_pmt_date'</span></span>,<span class="hljs-string"><span class="hljs-string">'credit_limit'</span></span>,<span class="hljs-string"><span class="hljs-string">'currency'</span></span>], aggfunc=<span class="hljs-string"><span class="hljs-string">'max'</span></span>) sumtbl.head(<span class="hljs-number"><span class="hljs-number">15</span></span>)</code> </pre><br><table><tbody><tr><th></th><th></th><th></th><th></th><th></th><th>  inf_confirm_date </th></tr><tr><th>  tcs_customer_id </th><th>  open_date </th><th>  final_pmt_date </th><th>  credit_limit </th><th>  currency </th><th></th></tr><tr><td rowspan="8">  one </td><td>  39261 </td><td>  39629 </td><td>  19421 </td><td>  RUB </td><td>  39924 </td></tr><tr><td>  39505 </td><td>  39870 </td><td>  30,000 </td><td>  RUB </td><td>  39862 </td></tr><tr><td>  39644 </td><td>  40042 </td><td>  11858 </td><td>  RUB </td><td>  40043 </td></tr><tr><td>  39876 </td><td>  41701 </td><td>  300,000 </td><td>  RUB </td><td>  40766 </td></tr><tr><td>  39942 </td><td>  40308 </td><td>  19691 </td><td>  RUB </td><td>  40435 </td></tr><tr><td>  40421 </td><td>  42247 </td><td>  169,000 </td><td>  RUB </td><td>  40756 </td></tr><tr><td>  40428 </td><td>  51386 </td><td>  10,000 </td><td>  RUB </td><td>  40758 </td></tr><tr><td>  40676 </td><td>  41040 </td><td>  28967 </td><td>  RUB </td><td>  40764 </td></tr><tr><td rowspan="2">  2 </td><td>  40472 </td><td>  40618 </td><td>  7551 </td><td>  RUB </td><td>  40661 </td></tr><tr><td>  40652 </td><td>  40958 </td><td>  21186 </td><td>  RUB </td><td>  40661 </td></tr><tr><td rowspan="2">  3 </td><td>  39647 </td><td>  40068 </td><td>  22694 </td><td>  RUB </td><td>  40069 </td></tr><tr><td>  40604 </td><td>  0 </td><td>  20,000 </td><td>  RUB </td><td>  40624 </td></tr><tr><td rowspan="3">  four </td><td>  38552 </td><td>  40378 </td><td>  75,000 </td><td>  RUB </td><td>  40479 </td></tr><tr><td>  39493 </td><td>  39797 </td><td>  5000 </td><td>  RUB </td><td>  39823 </td></tr><tr><td>  39759 </td><td>  40123 </td><td>  6023 </td><td>  RUB </td><td>  40125 </td></tr></tbody></table><br>  Now add the dates we received to the main set: <br><br><pre> <code class="python hljs">SampleAccounts = SampleAccounts.merge(sumtbl, <span class="hljs-string"><span class="hljs-string">'left'</span></span>, left_on=[<span class="hljs-string"><span class="hljs-string">'tcs_customer_id'</span></span>,<span class="hljs-string"><span class="hljs-string">'open_date'</span></span>,<span class="hljs-string"><span class="hljs-string">'final_pmt_date'</span></span>,<span class="hljs-string"><span class="hljs-string">'credit_limit'</span></span>,<span class="hljs-string"><span class="hljs-string">'currency'</span></span>], right_index=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, suffixes=(<span class="hljs-string"><span class="hljs-string">''</span></span>, <span class="hljs-string"><span class="hljs-string">'_max'</span></span>))</code> </pre> <br>  So, then we divide the columns in which the parameters are strictly defined, so that each value from these fields corresponds to a separate column.  By condition, the columns with the specified values ‚Äã‚Äãwill be: <br><ul><li>  pmt_string_84m </li><li>  pmt_freq </li><li>  type </li><li>  status </li><li>  relationship </li><li>  bureau_cd </li></ul><br>  The code for converting them is shown below: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#  pmt_string_84m vals = list(xrange(10)) + ['A','X'] PMTstr = DataFrame([{'pmt_string_84m_%s' % (str(j)): str(i).count(str(j)) for j in vals} for i in SampleAccounts.pmt_string_84m]) SampleAccounts = SampleAccounts.join(PMTstr).drop(['pmt_string_84m'], axis=1) #  pmt_freq SampleAccounts.pmt_freq.fillna(7, inplace=True) SampleAccounts.pmt_freq[SampleAccounts.pmt_freq == 0] = 7 vals = list(range(1,8)) + ['A','B'] PMTstr = DataFrame([{'pmt_freq_%s' % (str(j)): str(i).count(str(j)) for j in vals} for i in SampleAccounts.pmt_freq]) SampleAccounts = SampleAccounts.join(PMTstr).drop(['pmt_freq'], axis=1) #  type vals = [1,4,6,7,9,10,11,12,13,14,99] PMTstr = DataFrame([{'type_%s' % (str(j)): str(i).count(str(j)) for j in vals} for i in SampleAccounts.type]) SampleAccounts = SampleAccounts.join(PMTstr).drop(['type'], axis=1) #  status vals = [0,12, 13, 14, 21, 52,61] PMTstr = DataFrame([{'status_%s' % (str(j)): str(i).count(str(j)) for j in vals} for i in SampleAccounts.status]) SampleAccounts = SampleAccounts.join(PMTstr).drop(['status'], axis=1) #  relationship vals = [1,2,4,5,9] PMTstr = DataFrame([{'relationship_%s' % (str(j)): str(i).count(str(j)) for j in vals} for i in SampleAccounts.relationship]) SampleAccounts = SampleAccounts.join(PMTstr).drop(['relationship'], axis=1) #  bureau_cd vals = [1,2,3] PMTstr = DataFrame([{'bureau_cd_%s' % (str(j)): str(i).count(str(j)) for j in vals} for i in SampleAccounts.bureau_cd]) SampleAccounts = SampleAccounts.join(PMTstr).drop(['bureau_cd'], axis=1)</span></span></code> </pre><br>  The next step is to transform the 'fact_close_date' field, which contains the date of the last actual payment, so that it contains only 2 values: <br><ul><li>  0 - there was no last payment </li><li>  1 - last payment was </li></ul><br>  I made this replacement because the field was originally half filled. <br><br><pre> <code class="python hljs">SampleAccounts.fact_close_date[SampleAccounts.fact_close_date.notnull()] = <span class="hljs-number"><span class="hljs-number">1</span></span> SampleAccounts.fact_close_date.fillna(<span class="hljs-number"><span class="hljs-number">0</span></span>, inplace=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)</code> </pre><br>  Now from our data set we need to pull out the latest data on all loans.  The <i>‚Äúinf_confirm_date_max‚Äù</i> field obtained above will help us in this.  In it, we added the deadline for updating loan information in all bureaus: <br><br><pre> <code class="python hljs">PreFinalDS = SampleAccounts[SampleAccounts.inf_confirm_date == SampleAccounts.inf_confirm_date_max].drop_duplicates()</code> </pre> <br>  After the above actions, our sample was significantly reduced, but now we need to summarize all the information on the loan and the borrower obtained earlier.  To do this, we group our data set: <br><br><pre> <code class="python hljs">PreFinalDS = PreFinalDS.groupby([<span class="hljs-string"><span class="hljs-string">'tcs_customer_id'</span></span>,<span class="hljs-string"><span class="hljs-string">'open_date'</span></span>,<span class="hljs-string"><span class="hljs-string">'final_pmt_date'</span></span>,<span class="hljs-string"><span class="hljs-string">'credit_limit'</span></span>,<span class="hljs-string"><span class="hljs-string">'currency'</span></span>]).max().reset_index()</code> </pre> <br>  Our data is almost ready to start the analysis.  It remains to perform a few more actions: <br><ol><li>  Remove unwanted columns </li><li>  Bring all credit limits in rubles </li><li>  Calculate how many credits each borrower has from bureau information </li></ol><br>  Let's start by clearing the table of unnecessary columns: <br><br><pre> <code class="python hljs">PreFinalDS = PreFinalDS.drop([<span class="hljs-string"><span class="hljs-string">'bki_request_date'</span></span>, <span class="hljs-string"><span class="hljs-string">'inf_confirm_date'</span></span>, <span class="hljs-string"><span class="hljs-string">'pmt_string_start'</span></span>, <span class="hljs-string"><span class="hljs-string">'interest_rate'</span></span>, <span class="hljs-string"><span class="hljs-string">'open_date'</span></span>, <span class="hljs-string"><span class="hljs-string">'final_pmt_date'</span></span>, <span class="hljs-string"><span class="hljs-string">'inf_confirm_date_max'</span></span>], axis=<span class="hljs-number"><span class="hljs-number">1</span></span>)</code> </pre><br>  Further we will transfer all credit limits to rubles.  For simplicity, I took the current exchange rates.  Although probably it would be more correct to take a course at the time of opening an account.  Another caveat is that for analysis we need to remove the <i>‚Äúsurrency‚Äù</i> text field, so after converting currencies to rubles, we will <i>perform the</i> manipulation with this field, which we did with the fields above: <br><br><pre> <code class="python hljs">curs = DataFrame([<span class="hljs-number"><span class="hljs-number">33.13</span></span>,<span class="hljs-number"><span class="hljs-number">44.99</span></span>,<span class="hljs-number"><span class="hljs-number">36.49</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>], index=[<span class="hljs-string"><span class="hljs-string">'USD'</span></span>,<span class="hljs-string"><span class="hljs-string">'EUR'</span></span>,<span class="hljs-string"><span class="hljs-string">'GHF'</span></span>,<span class="hljs-string"><span class="hljs-string">'RUB'</span></span>], columns=[<span class="hljs-string"><span class="hljs-string">'crs'</span></span>]) PreFinalDS = PreFinalDS.merge(curs, <span class="hljs-string"><span class="hljs-string">'left'</span></span>, left_on=<span class="hljs-string"><span class="hljs-string">'currency'</span></span>, right_index=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) PreFinalDS.credit_limit = PreFinalDS.credit_limit * PreFinalDS.crs <span class="hljs-comment"><span class="hljs-comment">#     vals = ['RUB','USD','EUR','CHF'] PMTstr = DataFrame([{'currency_%s' % (str(j)): str(i).count(str(j)) for j in vals} for i in PreFinalDS.currency]) PreFinalDS = PreFinalDS.join(PMTstr).drop(['currency','crs'], axis=1)</span></span></code> </pre><br>  So before the final grouping, add to our set a field filled with units.  Those.  when we perform the last grouping, the amount on it will give the number of loans from the borrower: <br><br><pre> <code class="python hljs">PreFinalDS[<span class="hljs-string"><span class="hljs-string">'count_credit'</span></span>] = <span class="hljs-number"><span class="hljs-number">1</span></span></code> </pre> <br>  Now that we have all the quantitative data in the data set, we can fill in the gaps in data 0 and perform the final grouping by customer: <br><pre> <code class="python hljs">PreFinalDS.fillna(<span class="hljs-number"><span class="hljs-number">0</span></span>, inplace=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) FinalDF = PreFinalDS.groupby(<span class="hljs-string"><span class="hljs-string">'tcs_customer_id'</span></span>).sum() FinalDF</code> </pre><br><br><h4>  Preliminary analysis </h4><br><br>  Well, the primary data processing is completed and you can begin to analyze them.  To begin with, we divide our data into training and test samples.  The column <i>‚Äúsample_type‚Äù</i> from SampleCustomers will help us with this; this division is made just by it. <br>  In order to break our processed DataFrame, it is enough to combine it with SampleCustomers to play around with filters: <br><br><pre> <code class="python hljs">SampleCustomers.set_index(<span class="hljs-string"><span class="hljs-string">'tcs_customer_id'</span></span>, inplace=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) UnionDF = FinalDF.join(SampleCustomers) trainDF = UnionDF[UnionDF.sample_type == <span class="hljs-string"><span class="hljs-string">'train'</span></span>].drop([<span class="hljs-string"><span class="hljs-string">'sample_type'</span></span>], axis=<span class="hljs-number"><span class="hljs-number">1</span></span>) testDF = UnionDF[UnionDF.sample_type == <span class="hljs-string"><span class="hljs-string">'test'</span></span>].drop([<span class="hljs-string"><span class="hljs-string">'sample_type'</span></span>], axis=<span class="hljs-number"><span class="hljs-number">1</span></span>)</code> </pre><br>  Next, let's see how the signs correlate with each other, for this we construct a matrix with the coefficients correlation coefficients.  With pandas, this can be done with one command: <br><br><pre> <code class="python hljs">CorrKoef = trainDF.corr()</code> </pre> <br>  After the action above, CorrKoef will contain a matrix of sizes 61x61. <br>  The rows and columns will be the corresponding field names, and at their intersection the value of the correlation coefficient.  For example: <br><table><tbody><tr><td></td><th>  fact_close_date </th></tr><tr><th>  status_13 </th><td>  0.997362 </td></tr></tbody></table><br>  It is possible that there is no correlation coefficient.  This means that these fields are most likely filled with only one identical value and can be omitted in the analysis.  Check: <br><br><pre> <code class="python hljs">FieldDrop = [i <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> CorrKoef <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> CorrKoef[i].isnull().drop_duplicates().values[<span class="hljs-number"><span class="hljs-number">0</span></span>]]</code> </pre><br>  At the exit, we received a list of fields that can be deleted: <br><ul><li>  pmt_string_84m_6 </li><li>  pmt_string_84m_8 </li><li>  pmt_freq_5 </li><li>  pmt_freq_A </li><li>  pmt_freq_B </li><li>  status_12 </li></ul><br>  The next step is to find the fields that correlate with each other (whose correlation coefficient is more than 90%) using our matrix: <br><br><pre> <code class="python hljs">CorField = [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> CorrKoef: <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> j <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> CorrKoef.index[CorrKoef[i] &gt; <span class="hljs-number"><span class="hljs-number">0.9</span></span>]: <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> i &lt;&gt; j <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> j <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> CorField <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> CorField: CorField.append(j) <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> <span class="hljs-string"><span class="hljs-string">"%s--&gt;%s: r^2=%f"</span></span> % (i,j, CorrKoef[i][CorrKoef.index==j].values[<span class="hljs-number"><span class="hljs-number">0</span></span>])</code> </pre><br>  At the output we get the following: <br><br>  fact_close_date -&gt; status_13: r ^ 2 = 0.997362 <br>  ttl_delq_5_29 -&gt; ttl_delq_30: r ^ 2 = 0.954740 <br>  ttl_delq_5_29 -&gt; pmt_string_84m_A: r ^ 2 = 0.925870 <br>  ttl_delq_30_59 -&gt; pmt_string_84m_2: r ^ 2 = 0.903337 <br>  ttl_delq_90_plus -&gt; pmt_string_84m_5: r ^ 2 = 0.978239 <br>  delq_balance -&gt; max_delq_balance: r ^ 2 = 0.986967 <br>  pmt_freq_3 -&gt; relationship_1: r ^ 2 = 0.909820 <br>  pmt_freq_3 -&gt; currency_RUB: r ^ 2 = 0.910620 <br>  pmt_freq_3 -&gt; count_credit: r ^ 2 = 0.911109 <br><br>  So, based on the links we got in the previous step, we can add the following fields to the delete list: <br><br><pre> <code class="python hljs">FieldDrop =FieldDrop + [<span class="hljs-string"><span class="hljs-string">'fact_close_date'</span></span>,<span class="hljs-string"><span class="hljs-string">'ttl_delq_30'</span></span>, <span class="hljs-string"><span class="hljs-string">'pmt_string_84m_5'</span></span>, <span class="hljs-string"><span class="hljs-string">'pmt_string_84m_A'</span></span>, <span class="hljs-string"><span class="hljs-string">'pmt_string_84m_A'</span></span>, <span class="hljs-string"><span class="hljs-string">'max_delq_balance'</span></span>, <span class="hljs-string"><span class="hljs-string">'relationship_1'</span></span>, <span class="hljs-string"><span class="hljs-string">'currency_RUB'</span></span>, <span class="hljs-string"><span class="hljs-string">'count_credit'</span></span>] newtr = trainDF.drop(FieldDrop, axis=<span class="hljs-number"><span class="hljs-number">1</span></span>)</code> </pre><br><br><h4>  Build and select models </h4><br><br>  Well, the primary data is processed and now you can proceed to the construction of the model. <br>  Let's separate the class attribute from the training sample: <br><br><pre> <code class="python hljs">target = newtr.bad.values train = newtr.drop(<span class="hljs-string"><span class="hljs-string">'bad'</span></span>, axis=<span class="hljs-number"><span class="hljs-number">1</span></span>).values</code> </pre><br>  Now let's reduce the dimension of our sample in order to take only significant parameters.  To do this, we use <a href="http://www.machinelearning.ru/wiki/index.php%3Ftitle%3D%25D0%259C%25D0%25B5%25D1%2582%25D0%25BE%25D0%25B4_%25D0%25B3%25D0%25BB%25D0%25B0%25D0%25B2%25D0%25BD%25D1%258B%25D1%2585_%25D0%25BA%25D0%25BE%25D0%25BC%25D0%25BF%25D0%25BE%25D0%25BD%25D0%25B5%25D0%25BD%25D1%2582">the principal component method</a> and its implementation of <a href="http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html">PCA ()</a> in the <i>sklearn</i> module.  In the parameter, we pass the number of components that we want to save (I chose 20, since with them the results of the models practically did not differ from the results on the initial data) <br><br><pre> <code class="python hljs">coder = PCA(n_components=<span class="hljs-number"><span class="hljs-number">20</span></span>) train = coder.fit_transform(train)</code> </pre><br>  The time has come to define classification models.  Take several different algorithms and compare the results of their work using the characteristics of the <a href="http://ru.wikipedia.org/wiki/ROC-%25D0%25BA%25D1%2580%25D0%25B8%25D0%25B2%25D0%25B0%25D1%258F">Area Under ROC Curve</a> ( <b>auc</b> ).  The following algorithms will be considered for modeling: <br><ul><li>  <a href="http://ru.wikipedia.org/wiki/Random_forest">Random forest</a> </li><li>  <a href="http://en.wikipedia.org/wiki/Gradient_boosting">Gradient boosting</a> </li><li>  <a href="http://www.machinelearning.ru/wiki/index.php%3Ftitle%3DKNN">Nearest Neighbor Method</a> </li><li>  <a href="http://ru.wikipedia.org/wiki/%25D0%259D%25D0%25B0%25D0%25B8%25D0%25B2%25D0%25BD%25D1%258B%25D0%25B9_%25D0%25B1%25D0%25B0%25D0%25B9%25D0%25B5%25D1%2581%25D0%25BE%25D0%25B2%25D1%2581%25D0%25BA%25D0%25B8%25D0%25B9_%25D0%25BA%25D0%25BB%25D0%25B0%25D1%2581%25D1%2581%25D0%25B8%25D1%2584%25D0%25B8%25D0%25BA%25D0%25B0%25D1%2582%25D0%25BE%25D1%2580">"Naive" Bayes classifier</a> </li></ul><br><br><pre> <code class="python hljs">models = [] models.append(RandomForestClassifier(n_estimators=<span class="hljs-number"><span class="hljs-number">165</span></span>, max_depth=<span class="hljs-number"><span class="hljs-number">4</span></span>, criterion=<span class="hljs-string"><span class="hljs-string">'entropy'</span></span>)) models.append(GradientBoostingClassifier(max_depth =<span class="hljs-number"><span class="hljs-number">4</span></span>)) models.append(KNeighborsClassifier(n_neighbors=<span class="hljs-number"><span class="hljs-number">20</span></span>)) models.append(GaussianNB())</code> </pre><br>  So the models are selected.  Let's now break down our training sample into 2 subsamples: test and training.  This action is necessary so that we can calculate the characteristic auc for our models.  The splitting can be performed <a href="http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.train_test_split.html">using the train_test_split ()</a> function from the <i>sklearn</i> module: <br><br><pre> <code class="python hljs">TRNtrain, TRNtest, TARtrain, TARtest = train_test_split(train, target, test_size=<span class="hljs-number"><span class="hljs-number">0.3</span></span>, random_state=<span class="hljs-number"><span class="hljs-number">0</span></span>)</code> </pre> <br>  It remains to train our models and evaluate the result. <br>  To calculate the characteristics of <b>auc</b> there are 2 ways: <br><ol><li>  Standard means of the <i>sklearn</i> module using the <a href="http://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html">roc_auc_score</a> or <a href="http://scikit-learn.org/stable/modules/generated/sklearn.metrics.auc.html">auc</a> function </li><li>  Using the third-party package <a href="https://github.com/benhamner/Metrics">ml_metrics</a> and auc () function </li></ol><br>  I will use the second method, because  The first was shown in a previous article.  The <b>ml_metrics</b> package is a very useful addition to sklearn, since  it contains some metrics that are not in sklearn. <br>  So, we will construct ROC curves and we will count their areas: <br><br><pre> <code class="python hljs">plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">10</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>)) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> model <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> models: model.fit(TRNtrain, TARtrain) pred_scr = model.predict_proba(TRNtest)[:, <span class="hljs-number"><span class="hljs-number">1</span></span>] fpr, tpr, thresholds = roc_curve(TARtest, pred_scr) roc_auc = ml_metrics.auc(TARtest, pred_scr) md = str(model) md = md[:md.find(<span class="hljs-string"><span class="hljs-string">'('</span></span>)] pl.plot(fpr, tpr, label=<span class="hljs-string"><span class="hljs-string">'ROC fold %s (auc = %0.2f)'</span></span> % (md, roc_auc)) pl.plot([<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>], [<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>], <span class="hljs-string"><span class="hljs-string">'--'</span></span>, color=(<span class="hljs-number"><span class="hljs-number">0.6</span></span>, <span class="hljs-number"><span class="hljs-number">0.6</span></span>, <span class="hljs-number"><span class="hljs-number">0.6</span></span>)) pl.xlim([<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>]) pl.ylim([<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>]) pl.xlabel(<span class="hljs-string"><span class="hljs-string">'False Positive Rate'</span></span>) pl.ylabel(<span class="hljs-string"><span class="hljs-string">'True Positive Rate'</span></span>) pl.title(<span class="hljs-string"><span class="hljs-string">'Receiver operating characteristic example'</span></span>) pl.legend(loc=<span class="hljs-string"><span class="hljs-string">"lower right"</span></span>) pl.show()</code> </pre><br><img src="https://habrastorage.org/getpro/habr/post_images/e76/550/a20/e76550a20afe303651244c1ff6d82eb4.png" alt="image"><br>  So, according to the analysis of our models, we can say that the gradient boosting showed itself best, its accuracy is about 69%.  Accordingly, for learning a test sample, we will select it.  Let's fill in the information in the test sample, having previously processed it to the required format: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#      FieldDrop.append('bad') test = testDF.drop(FieldDrop, axis=1).values test = coder.fit_transform(test) #  model = models[1] model.fit(train, target) #  testDF.bad = model.predict(test)</span></span></code> </pre><br><h4>  Conclusion </h4><br>  As a conclusion, I would like to note that the resulting accuracy of the model in 69% is not good enough, but I could not achieve greater accuracy.  I would like to note the fact that when building a model on the full dimension, i.e.  without taking into account correlated columns and reducing the dimension, it also gave 69% accuracy (this can be easily checked using the trainDF kit to train the model) <br>  In this article, I tried to show all the main stages of data analysis from the primary processing of raw data to the construction of the classifier model.  In addition, I would like to note that the reference vector method was not included in the analyzed models, this is due to the fact that after normalizing the data, the accuracy of the model dropped to 51% and the best result I was able to get with it was around 60%, with significant time consuming. <br>  I would also like to note that, unfortunately on the test sample, the result could not be verified, since  did not meet the timing of the tournament. </div><p>Source: <a href="https://habr.com/ru/post/204500/">https://habr.com/ru/post/204500/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../204486/index.html">Admin tale about the economic aspects of information security</a></li>
<li><a href="../204488/index.html">Extract 3D models in O2C format from dat file</a></li>
<li><a href="../204490/index.html">Domain servers.com sold at auction for $ 300,000</a></li>
<li><a href="../204494/index.html">GameDev as a hobby</a></li>
<li><a href="../204496/index.html">TeamCity as a Debian repository</a></li>
<li><a href="../204504/index.html">From version database migration to database change management</a></li>
<li><a href="../204506/index.html">kidomi: building DOM objects on the fly</a></li>
<li><a href="../204508/index.html">Optimal DDoS protection with netstat and iptables</a></li>
<li><a href="../204510/index.html">How we did the API for the social network (REST API for WEB)</a></li>
<li><a href="../204512/index.html">Introduction to Windows 8.1 Upgrade</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>