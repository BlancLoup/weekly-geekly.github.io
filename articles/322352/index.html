<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>As I made the fastest resize of images. Part 1, general optimizations</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="In the pilot part, I talked about the task in as much detail as possible. The story turned out long and pointless - there was not a single line of cod...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>As I made the fastest resize of images. Part 1, general optimizations</h1><div class="post__text post__text-html js-mediator-article"><p>  In the <a href="https://habrahabr.ru/post/321744/">pilot part,</a> I talked about the task in as much detail as possible.  The story turned out long and pointless - there was not a single line of code in it.  But without an understanding of the problem it is very difficult to do optimization.  Of course, some techniques can be used with only the code.  For example, cache calculations, reduce branching.  But it seems to me that some things simply never do without an understanding of the task.  This is what distinguishes a person from an optimizing compiler.  Therefore, manual optimization still plays a huge role: the compiler has only code, and the person has an understanding of the problem.  The compiler can not decide that the value "4" is quite random, but a person can. </p><br><p><img src="https://habrastorage.org/files/025/911/39b/02591139b661489e923dc1dbe2e58179.png"></p><br><p>  Let me remind you that we will discuss the optimization of the image resize operation using the convolution method in the actually existing <a href="https://python-pillow.org/">Pillow</a> library.  I will talk about the changes that I did a few years ago.  But it will not be a word-for-word repetition: the optimization will be described in a convenient way for the narration.  For these articles, I made a <a href="https://github.com/uploadcare/pillow-simd/commits/opt/scalar">separate thread</a> in the repository from version 2.6.2 - from this point on, the story will follow. </p><a name="habracut"></a><br><h2 id="testirovanie">  Testing </h2><br><p>  If you want to not only read, but also experiment on your own, you need the <a href="https://github.com/python-pillow/pillow-perf">pillow-perf</a> test package. </p><br><pre><code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#        $ sudo apt-get install -y build-essential ccache \ python-dev libjpeg-dev $ git clone -b opt/scalar https://github.com/uploadcare/pillow-simd.git $ git clone --depth 10 https://github.com/python-pillow/pillow-perf.git $ cd ./pillow-simd/ # ,     $ git checkout bf1df9a #    Pillow $ CC="ccache cc" python ./setup.py develop # -   $ ../pillow-perf/testsuite/run.py scale -n 3</span></span></code> </pre> <br><p>  Since Pillow consists of multiple modules and does not know how to compile incrementally, the ccache utility is used to significantly accelerate repeated builds.  With pillow-perf you can test many operations, but we are interested in <code>scale</code> .  <code>-n 3</code> sets the number of operation starts.  As long as the code is slow, you can take a smaller number in order not to fall asleep.  At the start, the performance is as follows: </p><br><pre> <code class="markdown hljs">Scale 2560√ó1600 RGB image to 320x200 bil 0.08927 s 45.88 Mpx/s to 320x200 bic 0.13073 s 31.33 Mpx/s to 320x200 lzs 0.16436 s 24.92 Mpx/s to 2048x1280 bil 0.40833 s 10.03 Mpx/s to 2048x1280 bic 0.45507 s 9.00 Mpx/s to 2048x1280 lzs 0.52855 s 7.75 Mpx/s to 5478x3424 bil 1.49024 s 2.75 Mpx/s to 5478x3424 bic 1.84503 s 2.22 Mpx/s to 5478x3424 lzs 2.04901 s 2.00 Mpx/s</code> </pre> <br><p>  <i>Result for <a href="https://github.com/uploadcare/pillow-simd/commit/bf1df9a04f0f92124a18789871f43391e9a00f01">commit bf1df9a</a> .</i> </p><br><p>  These results are slightly different from those obtained in the <a href="https://python-pillow.org/pillow-perf/">official benchmark</a> for version 2.6.  There are several reasons for this: </p><br><ol><li>  The official benchmark uses 64-bit Ubuntu 16.04 with GCC 5.3.  I will use 32-bit Ubuntu 14.04 with GCC 4.8, on which I did all these optimizations for the first time.  At the end of the article it becomes clear why. </li><li>  In the articles, I start the story with a commit in which a bug is fixed that is not related to optimization, but affects performance. </li></ol><br><h2 id="struktura-koda">  Code structure </h2><br><p>  Most of the code that interests us <a href="">is in the Antialias.c file</a> , in the <code>ImagingStretch</code> function.  The code for this function can be divided into three parts: </p><br><pre> <code class="cpp hljs"><span class="hljs-comment"><span class="hljs-comment">//  if (imIn-&gt;xsize == imOut-&gt;xsize) { //   } else { //   }</span></span></code> </pre> <br><p>  As I said earlier, resize images with convolutions can be done in two passes: on the first one, only the width of the image changes, on the second one - the height, or vice versa.  The <code>ImagingStretch</code> function can do either one or the other in one call.  Here <a href="">you can see</a> that it is actually called twice during each resize.  In the function, a general prolog is performed, and further, depending on the parameters, this or that operation.  A rather unusual approach to getting rid of repetitive code, which in this case is the prologue. </p><br><p>  Inside, both aisles look about the same, adjusted for the changing direction of processing.  For brevity, I will give only one: </p><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (yy = <span class="hljs-number"><span class="hljs-number">0</span></span>; yy &lt; imOut-&gt;ysize; yy++) { <span class="hljs-comment"><span class="hljs-comment">//   if (imIn-&gt;image8) { //     8  } else { switch(imIn-&gt;type) { case IMAGING_TYPE_UINT8: //      8  case IMAGING_TYPE_INT32: //     32  case IMAGING_TYPE_FLOAT32: //     float } }</span></span></code> </pre> <br><p>  There is branching into several pixel formats supported by Pillow: single-channel 8 bits (shades of gray), multi-channel 8 bits (RGB, RGBA, LA, CMYK, some others), single-channel 32 bits and float.  We will be interested in the loop body for several channels of 8 bits each, since this is the most common image format. </p><br><h2 id="optimizaciya-1-effektivno-ispolzuem-kesh">  Optimization 1: effectively use the cache </h2><br><p>  Although I said above that the two passes are similar, there is an obvious difference between them.  Look at the vertical passage: </p><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (yy = <span class="hljs-number"><span class="hljs-number">0</span></span>; yy &lt; imOut-&gt;ysize; yy++) { <span class="hljs-comment"><span class="hljs-comment">//   for (xx = 0; xx &lt; imOut-&gt;xsize*4; xx++) { //    //    imOut-&gt;image8[yy][xx] } }</span></span></code> </pre> <br><p>  To horizontal pass: </p><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (xx = <span class="hljs-number"><span class="hljs-number">0</span></span>; xx &lt; imOut-&gt;xsize; xx++) { <span class="hljs-comment"><span class="hljs-comment">//   for (yy = 0; yy &lt; imOut-&gt;ysize; yy++) { //    //    imOut-&gt;image8[yy][xx] } }</span></span></code> </pre> <br><p>  At the vertical passage in the inner loop, the columns of the final image are iterated, and at the horizontal - the rows.  Horizontal pass is a serious problem for the processor cache.  At each step of the inner loop, one line is addressed below, which means that a value is requested from the memory, which lies far away from the value needed at the previous step.  This is bad with a small amount of convolution.  The fact is that on modern processors, the cache line, which the processor can request from RAM, is always 64 bytes.  This means that if less than 16 pixels are involved in the convolution, then part of the data is being chased from memory to cache.  Now imagine that the cycles are reversed and the next pixel collapses not the line below, but the next one in the same line.  Then most of the required pixels would already be in the cache. </p><br><p>  The second negative factor of such an organization of the code is manifested with a long line for convolution (i.e., with a strong decrease).  The fact is that for neighboring convolutions, the original pixels intersect quite significantly, and it would be nice if this data remained in the cache.  But when we move from top to bottom, the data for the old bundles gradually begin to be crowded out of the cache with the data for the new ones.  As a result, when the full internal cycle passes and the next external step begins, the upper lines are no longer in the cache, they are all pushed out by the lower lines, they need to be recalled again from memory.  And when it comes to the lower ones, everything is already superseded by the upper ones in the cache.  It turns out the cycle, as a result of which the necessary data is never in the cache. </p><br><p>  Why is the detour done this way?  In the pseudocode above, it can be seen that the second line in both cases is the calculation of the coefficients for convolution.  For a vertical pass, the coefficients depend only on the row of the final image (on the <code>yy</code> value), and for the horizontal one on the current column (on the <code>xx</code> value).  That is, in the horizontal passage one cannot simply interchange two cycles - the calculation of the coefficients must be inside the cycle of xx.  If we start counting the coefficients inside the inner loop, it will kill all the performance.  Especially when the Lanczos filter is used to calculate the coefficients, in which there are trigonometric functions. </p><br><p>  It is impossible to calculate the coefficients at each step, but nevertheless they are the same for all pixels of one column.  So you can calculate all the coefficients in advance for all columns, and in the inner loop you can take the already calculated ones.  Let's do it. </p><br><p>  The code has a memory allocation for the coefficients: </p><br><pre> <code class="cpp hljs">k = <span class="hljs-built_in"><span class="hljs-built_in">malloc</span></span>(kmax * <span class="hljs-keyword"><span class="hljs-keyword">sizeof</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">float</span></span>));</code> </pre> <br><p>  Now we need an array of such arrays.  But you can simplify - select a flat piece of memory and emulate a two-dimensional addressing. </p><br><pre> <code class="cpp hljs">kk = <span class="hljs-built_in"><span class="hljs-built_in">malloc</span></span>(imOut-&gt;xsize * kmax * <span class="hljs-keyword"><span class="hljs-keyword">sizeof</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">float</span></span>));</code> </pre> <br><p>  You also need to store somewhere <code>xmin</code> and <code>xmax</code> , which also depend on xx.  We will also make an array for them so as not to recalculate. </p><br><pre> <code class="cpp hljs">xbounds = <span class="hljs-built_in"><span class="hljs-built_in">malloc</span></span>(imOut-&gt;xsize * <span class="hljs-number"><span class="hljs-number">2</span></span> * <span class="hljs-keyword"><span class="hljs-keyword">sizeof</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">float</span></span>));</code> </pre> <br><p>  Also inside the loop, some <code>ww</code> value is used, which is needed to normalize the value of convolution.  ww = 1 / ‚àëk [x].  It is possible not to store it at all, and to normalize the coefficients themselves, and not the result of the convolution.  That is, after we calculated the coefficients, we need to go over them once again and divide them by their sum, as a result of which the sum of all the coefficients will be equal to 1: </p><br><pre> <code class="cpp hljs">k = &amp;kk[xx * kmax]; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (x = (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span>) xmin; x &lt; (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span>) xmax; x++) { <span class="hljs-keyword"><span class="hljs-keyword">float</span></span> w = filterp-&gt;filter((x - center + <span class="hljs-number"><span class="hljs-number">0.5</span></span>) * ss); k[x - (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span>) xmin] = w; ww = ww + w; } <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (x = (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span>) xmin; x &lt; (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span>) xmax; x++) { k[x - (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span>) xmin] /= ww; }</code> </pre> <br><p>  Now you can finally deploy a 90 ¬∞ pixel bypass: </p><br><pre> <code class="cpp hljs"><span class="hljs-comment"><span class="hljs-comment">//    for (yy = 0; yy &lt; imOut-&gt;ysize; yy++) { for (xx = 0; xx &lt; imOut-&gt;xsize; xx++) { k = &amp;kk[xx * kmax]; xmin = xbounds[xx * 2 + 0]; xmax = xbounds[xx * 2 + 1]; //    //    imOut-&gt;image8[yy][xx] } }</span></span></code> </pre> <br><pre> <code class="markdown hljs">Scale 2560√ó1600 RGB image to 320x200 bil 0.04759 s 86.08 Mpx/s 87.6 % to 320x200 bic 0.08970 s 45.66 Mpx/s 45.7 % to 320x200 lzs 0.11604 s 35.30 Mpx/s 41.6 % to 2048x1280 bil 0.24501 s 16.72 Mpx/s 66.7 % to 2048x1280 bic 0.30398 s 13.47 Mpx/s 49.7 % to 2048x1280 lzs 0.37300 s 10.98 Mpx/s 41.7 % to 5478x3424 bil 1.06362 s 3.85 Mpx/s 40.1 % to 5478x3424 bic 1.32330 s 3.10 Mpx/s 39.4 % to 5478x3424 lzs 1.56232 s 2.62 Mpx/s 31.2 %</code> </pre> <br><p>  <i>Result for <a href="https://github.com/uploadcare/pillow-simd/commit/d35755c5faf3ec8ea25ffb9b6249deaa16b3b2f5">commit d35755c</a> .</i> </p><br><p>  The fourth column shows the acceleration relative to the previous version, and under the table there is a link to a commit where the changes made are clearly visible. </p><br><h2 id="optimizaciya-2-ogranichenie-vyhodnyh-znacheniy">  Optimization 2: Output Limitations </h2><br><p>  In the code, we see the following structure in several places: </p><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (ss &lt; <span class="hljs-number"><span class="hljs-number">0.5</span></span>) imOut-&gt;image[yy][xx*<span class="hljs-number"><span class="hljs-number">4</span></span>+b] = (UINT8) <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (ss &gt;= <span class="hljs-number"><span class="hljs-number">255.0</span></span>) imOut-&gt;image[yy][xx*<span class="hljs-number"><span class="hljs-number">4</span></span>+b] = (UINT8) <span class="hljs-number"><span class="hljs-number">255</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> imOut-&gt;image[yy][xx*<span class="hljs-number"><span class="hljs-number">4</span></span>+b] = (UINT8) ss;</code> </pre> <br><p>  This is the limitation of the pixel value within [0, 255], if the result of the calculation goes beyond 8 bits.  Indeed, the sum of all positive convolution factors can be greater than one, and the sum of all negative ones can be less than zero.  So with a certain original image we can get an overflow.  This overflow is the result of compensating for sudden changes in brightness and is not an error. </p><br><p>  Take a look at the code.  It has one input variable <code>ss</code> and exactly one output <code>imOut-&gt;image[yy]</code> , the value of which is assigned in several places.  The bad thing here is that floating point numbers are compared.  It would be faster to convert everything into integers and then compare, since all the same in the end we need a whole result.  The result is such a function: </p><br><pre> <code class="cpp hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">static</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">inline</span></span></span><span class="hljs-function"> UINT8 </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">clip8</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> in)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> out = (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span>) in; <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (out &gt;= <span class="hljs-number"><span class="hljs-number">255</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-number"><span class="hljs-number">255</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (out &lt;= <span class="hljs-number"><span class="hljs-number">0</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> (UINT8) out; }</code> </pre> <br><p>  Using: </p><br><pre> <code class="cpp hljs">imOut-&gt;image[yy][xx*<span class="hljs-number"><span class="hljs-number">4</span></span>+b] = clip8(ss);</code> </pre> <br><p>  This also gives a performance boost, albeit small. </p><br><pre> <code class="markdown hljs">Scale 2560√ó1600 RGB image to 320x200 bil 0.04644 s 88.20 Mpx/s 2.5 % to 320x200 bic 0.08157 s 50.21 Mpx/s 10.0 % to 320x200 lzs 0.11131 s 36.80 Mpx/s 4.2 % to 2048x1280 bil 0.22348 s 18.33 Mpx/s 9.6 % to 2048x1280 bic 0.28599 s 14.32 Mpx/s 6.3 % to 2048x1280 lzs 0.35462 s 11.55 Mpx/s 5.2 % to 5478x3424 bil 0.94587 s 4.33 Mpx/s 12.4 % to 5478x3424 bic 1.18599 s 3.45 Mpx/s 11.6 % to 5478x3424 lzs 1.45088 s 2.82 Mpx/s 7.7 %</code> </pre> <br><p>  <i>Result for <a href="https://github.com/uploadcare/pillow-simd/commit/54d3b9d7bc9971f01d4fc409d2bc4d60c185e778">commit 54d3b9d</a> .</i> </p><br><p>  As you can see, this optimization has a greater effect for filters with a smaller window and with a large output resolution (the only exception is 320x200 Bilinear, but I don‚Äôt presume to say why).  Indeed, the smaller the filter window and the greater the final resolution, the greater the contribution to performance is made by trimming the values, which we optimized. </p><br><h2 id="optimizaciya-3-razvorot-ciklov-c-postoyannym-kolichestvom-iteraciy">  Optimization 3: Cycle reversal with a constant number of iterations </h2><br><p>  If you look at the horizontal step again, you can count as many as 4 nested loops: </p><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (yy = <span class="hljs-number"><span class="hljs-number">0</span></span>; yy &lt; imOut-&gt;ysize; yy++) { <span class="hljs-comment"><span class="hljs-comment">// ... for (xx = 0; xx &lt; imOut-&gt;xsize; xx++) { // ... for (b = 0; b &lt; imIn-&gt;bands; b++) { // ... for (x = (int) xmin; x &lt; (int) xmax; x++) { ss = ss + (UINT8) imIn-&gt;image[yy][x*4+b] * k[x - (int) xmin]; } } } }</span></span></code> </pre> <br><p>  Each row and each column of the output image is iterated (that is, each pixel), and each pixel of the original image that needs to be minimized inside.  But what is <code>b</code> ?  <code>b</code> is an iteration over image channels.  Obviously, the number of channels during the operation of the function does not change and never exceeds 4 (due to the method of storing the image in Pillow).  Therefore, there may be only 4 possible cases.  And given the fact that single-channel 8-bit images are stored in a different way, there are three cases.  Accordingly, three separate internal cycles can be made: for two, three and four channels.  And make a branch on the desired number of channels.  I will show only the code of the three-channel case in order not to take up too much space. </p><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (xx = <span class="hljs-number"><span class="hljs-number">0</span></span>; xx &lt; imOut-&gt;xsize; xx++) { <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (imIn-&gt;bands == <span class="hljs-number"><span class="hljs-number">4</span></span>) { <span class="hljs-comment"><span class="hljs-comment">//   4  } else if (imIn-&gt;bands == 3) { ss0 = 0.0; ss1 = 0.0; ss2 = 0.0; for (x = (int) xmin; x &lt; (int) xmax; x++) { ss0 = ss0 + (UINT8) imIn-&gt;image[yy][x*4+0] * k[x - (int) xmin]; ss1 = ss1 + (UINT8) imIn-&gt;image[yy][x*4+1] * k[x - (int) xmin]; ss2 = ss2 + (UINT8) imIn-&gt;image[yy][x*4+2] * k[x - (int) xmin]; } ss0 = ss0 * ww + 0.5; ss1 = ss1 * ww + 0.5; ss2 = ss2 * ww + 0.5; imOut-&gt;image[yy][xx*4+0] = clip8(ss0); imOut-&gt;image[yy][xx*4+1] = clip8(ss1); imOut-&gt;image[yy][xx*4+2] = clip8(ss2); } else { //       } }</span></span></code> </pre> <br><p>  You can not stop there and move the branch one more level up to the xx loop: </p><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (imIn-&gt;bands == <span class="hljs-number"><span class="hljs-number">4</span></span>) { <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (xx = <span class="hljs-number"><span class="hljs-number">0</span></span>; xx &lt; imOut-&gt;xsize; xx++) { <span class="hljs-comment"><span class="hljs-comment">//   4  } } else if (imIn-&gt;bands == 3) { for (xx = 0; xx &lt; imOut-&gt;xsize; xx++) { //   3  } } else { for (xx = 0; xx &lt; imOut-&gt;xsize; xx++) { //       } }</span></span></code> </pre> <br><pre> <code class="markdown hljs">Scale 2560√ó1600 RGB image to 320x200 bil 0.03885 s 105.43 Mpx/s 19.5 % to 320x200 bic 0.05923 s 69.15 Mpx/s 37.7 % to 320x200 lzs 0.09176 s 44.64 Mpx/s 21.3 % to 2048x1280 bil 0.19679 s 20.81 Mpx/s 13.6 % to 2048x1280 bic 0.24257 s 16.89 Mpx/s 17.9 % to 2048x1280 lzs 0.30501 s 13.43 Mpx/s 16.3 % to 5478x3424 bil 0.88552 s 4.63 Mpx/s 6.8 % to 5478x3424 bic 1.08753 s 3.77 Mpx/s 9.1 % to 5478x3424 lzs 1.32788 s 3.08 Mpx/s 9.3 %</code> </pre> <br><p>  <i>Result for <a href="https://github.com/uploadcare/pillow-simd/commit/95a9e3009df1ccdd5088ea7560860c953d2ed94d">commit 95a9e30</a> .</i> </p><br><p>  Something similar can be done for a vertical passage.  There is now such a code: </p><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (xx = <span class="hljs-number"><span class="hljs-number">0</span></span>; xx &lt; imOut-&gt;xsize*<span class="hljs-number"><span class="hljs-number">4</span></span>; xx++) { <span class="hljs-comment"><span class="hljs-comment">/* </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">FIXME:</span></span></span><span class="hljs-comment"> skip over unused pixels */</span></span> ss = <span class="hljs-number"><span class="hljs-number">0.0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (y = (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span>) ymin; y &lt; (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span>) ymax; y++) ss = ss + (UINT8) imIn-&gt;image[y][xx] * k[y-(<span class="hljs-keyword"><span class="hljs-keyword">int</span></span>) ymin]; ss = ss * ww + <span class="hljs-number"><span class="hljs-number">0.5</span></span>; imOut-&gt;image[yy][xx] = clip8(ss); }</code> </pre> <br><p>  There is no separate iteration over the channels; instead, <code>xx</code> iterated along the width multiplied by 4. That is, <code>xx</code> passes through each channel regardless of their number in the image.  FIXME in the comment just says that it needs to be fixed.  It is fixed in the same way - by branching the code for a different number of channels in the original image.  I will not give the code here, a link to the commit below. </p><br><pre> <code class="markdown hljs">Scale 2560√ó1600 RGB image to 320x200 bil 0.03336 s 122.80 Mpx/s 16.5 % to 320x200 bic 0.05439 s 75.31 Mpx/s 8.9 % to 320x200 lzs 0.08317 s 49.25 Mpx/s 10.3 % to 2048x1280 bil 0.16310 s 25.11 Mpx/s 20.7 % to 2048x1280 bic 0.19669 s 20.82 Mpx/s 23.3 % to 2048x1280 lzs 0.24614 s 16.64 Mpx/s 23.9 % to 5478x3424 bil 0.65588 s 6.25 Mpx/s 35.0 % to 5478x3424 bic 0.80276 s 5.10 Mpx/s 35.5 % to 5478x3424 lzs 0.96007 s 4.27 Mpx/s 38.3 %</code> </pre> <br><p>  <i>Result for <a href="https://github.com/uploadcare/pillow-simd/commit/f227c3532e81569e2b9f195558fd897f9e91d95e">commit f227c35</a> .</i> </p><br><p>  As you can see, the horizontal passage gave more performance to reduce the picture, while the vertical - to increase. </p><br><h2 id="optimizaciya-4-celochislennye-schetchiki">  Optimization 4: Integer Counters </h2><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (y = (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span>) ymin; y &lt; (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span>) ymax; y++) { ss0 = ss0 + (UINT8) imIn-&gt;image[y][xx*<span class="hljs-number"><span class="hljs-number">4</span></span>+<span class="hljs-number"><span class="hljs-number">0</span></span>] * k[y-(<span class="hljs-keyword"><span class="hljs-keyword">int</span></span>) ymin]; ss1 = ss1 + (UINT8) imIn-&gt;image[y][xx*<span class="hljs-number"><span class="hljs-number">4</span></span>+<span class="hljs-number"><span class="hljs-number">1</span></span>] * k[y-(<span class="hljs-keyword"><span class="hljs-keyword">int</span></span>) ymin]; ss2 = ss2 + (UINT8) imIn-&gt;image[y][xx*<span class="hljs-number"><span class="hljs-number">4</span></span>+<span class="hljs-number"><span class="hljs-number">2</span></span>] * k[y-(<span class="hljs-keyword"><span class="hljs-keyword">int</span></span>) ymin]; }</code> </pre> <br><p>  If you look at the innermost loop, you can see that the variables <code>ymax</code> and <code>ymax</code> declared as float, but are <code>ymax</code> to the integer at each step.  Moreover, outside the loop, <code>floor</code> and <code>ceil</code> functions are used to assign values ‚Äã‚Äãto them.  That is, in fact, variables always store integers, but for some reason they are declared as float.  The same goes for <code>xmin</code> and <code>xmax</code> .  We change and measure. </p><br><pre> <code class="markdown hljs">Scale 2560√ó1600 RGB image to 320x200 bil 0.03009 s 136.10 Mpx/s 10.9 % to 320x200 bic 0.05187 s 78.97 Mpx/s 4.9 % to 320x200 lzs 0.08113 s 50.49 Mpx/s 2.5 % to 2048x1280 bil 0.14017 s 29.22 Mpx/s 16.4 % to 2048x1280 bic 0.17750 s 23.08 Mpx/s 10.8 % to 2048x1280 lzs 0.22597 s 18.13 Mpx/s 8.9 % to 5478x3424 bil 0.58726 s 6.97 Mpx/s 11.7 % to 5478x3424 bic 0.74648 s 5.49 Mpx/s 7.5 % to 5478x3424 lzs 0.90867 s 4.51 Mpx/s 5.7 %</code> </pre> <br><p>  <i>Result for <a href="https://github.com/uploadcare/pillow-simd/commit/57e8925b3bff7ff79eb8e4625f43e3e363b87bc9">commit 57e8925</a> .</i> </p><br><h2 id="final-pervogo-akta-i-boss">  The finale of the first act and the boss </h2><br><p>  I admit, I was very pleased with the results.  It was possible to overclock the code by an average of 2.5 times.  Moreover, to obtain this acceleration, the library user did not need to install additional equipment, resizing, as before, runs on the same core of the same processor as before.  It was necessary only to update the Pillow version to version 2.7. </p><br><p>  But until release 2.7 there was still some time left, but I was eager to check the new code on the server on which it was supposed to work.  I moved the code, compiled it, and at first thought that I had messed up something: </p><br><pre> <code class="markdown hljs">Scale 2560√ó1600 RGB image 320x200 bil 0.08056 s 50.84 Mpx/s 320x200 bic 0.16054 s 25.51 Mpx/s 320x200 lzs 0.24116 s 16.98 Mpx/s 2048x1280 bil 0.18300 s 22.38 Mpx/s 2048x1280 bic 0.31103 s 13.17 Mpx/s 2048x1280 lzs 0.43999 s 9.31 Mpx/s 5478x3424 bil 0.75046 s 5.46 Mpx/s 5478x3424 bic 1.22468 s 3.34 Mpx/s 5478x3424 lzs 1.70451 s 2.40 Mpx/s</code> </pre> <br><p>  <i>Result for <a href="https://github.com/uploadcare/pillow-simd/commit/57e8925b3bff7ff79eb8e4625f43e3e363b87bc9">commit 57e8925</a> .</i>  <i>Received on another machine and is not involved in the comparison.</i> </p><br><p>  LOL what?  The results are almost the same as before the optimization.  I have rechecked everything 10 times, put the prints to make sure that the necessary code works.  It was not some side effect from Pillow or the environment, the difference was reproduced even in the minimal example of 30 lines.  I <a href="http://stackoverflow.com/q/26585977/253146">asked a question on the Stack Overflow</a> , and in the end I managed to find an obvious regularity: the code was executed slowly if it was compiled with GCC for a 64-bit platform.  And that was exactly the difference between local Ubuntu and on the server: it was locally 32-bit. </p><br><p>  Well, thank Moore, I'm not crazy, this is a real bug in the compiler.  Moreover, the bug was fixed in GCC 4.9, but GCC 4.8 was included in the current at that time Ubuntu 14.04 LTS, i.e., it was most likely installed by the majority of library users.  It was impossible to ignore this: what is the point of optimization if it does not work for the majority, including the production for which it was made.  I updated the question on SO and threw a cry on tweeter.  Vyacheslav Egorov came to him, one of the developers of the V8 engine and the genius of optimization, who helped to get to the bottom of the essence and found a solution. </p><br><p>  To understand the essence of the problem, you need to delve into the history of processors and their current architecture.  Once upon a time, x86 processors did not know how to work with floating point numbers, a co-processor with the x87 instruction set was invented for them.  He executed instructions from the same thread as the central processor, but was installed on the motherboard as a separate device.  Pretty quickly, the coprocessor was built into the central one, and physically it became one device.  How long is it short? In the third Pentium there appeared a set of instructions SSE (Streaming SIMD Extensions).  By the way, about SIMD instructions will be the second part of the series of articles.  Despite the name, SSE contained not only SIMD commands for working with floating-point numbers, but also their equivalents for scalar calculations.  That is, SSE contained a set of instructions, a duplicate set of x87, but encoded differently and with slightly different behavior. </p><br><p>  However, the compilers were in no hurry to generate SSE code for floating-point calculations, but continued to use the obsolete x87 set.  After all, the presence of SSE in the processor, no one guaranteed, unlike x87, which has been built since time immemorial.  Everything changed with the arrival of the 64-bit mode of the processor.  In the 64-bit mode, the SSE2 instruction set was required.  That is, if you are writing a 64-bit program for x86, at least SSE2 instructions are available to you.  This is what compilers use, generating SSE instructions for floating-point calculations in 64-bit mode.  Let me remind you that this has nothing to do with vectorization, it‚Äôs about ordinary scalar calculations. </p><br><p>  This is exactly what happens in our case: different sets of instructions for 32-bit and 64-bit mode are used.  But so far this does not explain why the more modern SSE-code is several times slower than the outdated x87 set.  To explain this phenomenon, you need to figure out exactly how the processor executes instructions. </p><br><p>  Once the processors really "carried out" instructions.  They took the instruction, decoded it, executed it completely, put the result where it was said.  The processors were pretty dumb.  Modern processors are much smarter and more complex, they consist of dozens of different subsystems.  Even on one core, without any parallel processing, the processor executes several instructions at one time, in one clock cycle.  It simply happens at different stages: some instruction is just being decoded, some is requesting something from the cache, some is being passed to the arithmetic unit.  Each processor subsystem does its part.  This is called the conveyor. </p><br><p><img src="https://habrastorage.org/files/d60/f13/eb8/d60f13eb86184af4a4383c63ca86fcba.png"></p><br><p>  In the picture, different subsystems are marked with different colors.  It can be seen that although the command requires from 4 to 5 cycles for execution, thanks to the pipeline, each cycle selects one new command and one completes its execution. </p><br><p>  The conveyor works the more efficiently, the more evenly it is filled and the less subsystems are idle.  The processor even has subsystems that plan for optimal filling of the conveyor: swap instructions, split up one instruction into several, combine several into one. </p><br><p>   ,        ‚Äî   .     -          ,      . </p><br><p><img src="https://habrastorage.org/files/cf7/402/14b/cf740214bd8545f08e85dfabdd2f1dc9.png"></p><br><p>   ,   2     1.      .        . </p><br><p>  ,    ,    <a href="https://software.intel.com/sites/landingpage/IntrinsicsGuide/"> </a> ,        : </p><br><pre> <code class="markdown hljs">Instruction: cvtsi2ss xmm, r32 dst[31:0] := Convert<span class="hljs-emphasis"><span class="hljs-emphasis">_Int32_</span></span>To_FP32(b[31:0]) dst[127:32] := a[127:32]</code> </pre> <br><p>   32    .    ,   <code>dst</code>    -  <code>a</code> ,     ,       xmm ,   <code>dst</code>  <code>a</code> ‚Äî      ,   96   ,   .       .    ,     ,            ,    .            ,       32- float.   ,      ,      .      . </p><br><p>  ,     .       <code>cvtsi2ss</code>   ,    <code>xorps</code> .            .  ,     ,  ,     ,   <code>xorps</code> + <code>cvtsi2ss</code>  -     : </p><br><pre> <code class="markdown hljs">dst[31:0] := Convert<span class="hljs-emphasis"><span class="hljs-emphasis">_Int32_</span></span>To_FP32(b[31:0]) dst[127:32] := 0</code> </pre> <br><p>  ,   GCC 4.8  ,        ,    .    ,   ,  ,   .    64- . </p><br><pre> <code class="markdown hljs">Scale 2560√ó1600 RGB image 320x200 bil 0.02447 s 167.42 Mpx/s 320x200 bic 0.04624 s 88.58 Mpx/s 320x200 lzs 0.07142 s 57.35 Mpx/s 2048x1280 bil 0.08656 s 47.32 Mpx/s 2048x1280 bic 0.12079 s 33.91 Mpx/s 2048x1280 lzs 0.16484 s 24.85 Mpx/s 5478x3424 bil 0.38566 s 10.62 Mpx/s 5478x3424 bic 0.52408 s 7.82 Mpx/s 5478x3424 lzs 0.65726 s 6.23 Mpx/s</code> </pre> <br><p> <i>  <a href="https://github.com/uploadcare/pillow-simd/commit/81fc88e1b69a19fd21bcfa11ee36e4ac8448b2fb"> 81fc88e</a> .         .</i> </p><br><p> ,  ,   . ,         ,      ,     .   ImageMagick    : 64- ,  GCC 4.9   40%      .   ,        SSE. </p><br><p> : <a href="https://habrahabr.ru/post/326900/"> 2, SIMD</a> </p></div>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <p>Source: <a href="https://habr.com/ru/post/322352/">https://habr.com/ru/post/322352/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../322340/index.html">Determine the best place to live in the United States with your own application on IBM Bluemix</a></li>
<li><a href="../322344/index.html">Salyut-EL24D1: debug board on the Russian processor 1892BM14Ya for harsh operating conditions</a></li>
<li><a href="../322346/index.html">Heuristic network - analogue of the recurrent neural network for chat bot program</a></li>
<li><a href="../322348/index.html">Escape analysis and scalarization: let GC rest</a></li>
<li><a href="../322350/index.html">Personal experience: TeamCity and character server integration</a></li>
<li><a href="../322354/index.html">Manage application state with Vuex</a></li>
<li><a href="../322360/index.html">Interesting features of Python, which you could not guess</a></li>
<li><a href="../322362/index.html">Red Hat acquires 3scale, which develops API management systems, and intends to open source code of products</a></li>
<li><a href="../322364/index.html">RTM Cybergroup specializes in stealing funds from Russian companies</a></li>
<li><a href="../322366/index.html">Analytical data outside Wrike analytics</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>