<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>AI Google learned to recognize the voices of people from the random crowd chorus</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="The person has the ability to distinguish the voice of the interlocutor from the noise, for example, in a place where there is a large crowd of people...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>AI Google learned to recognize the voices of people from the random crowd chorus</h1><div class="post__text post__text-html js-mediator-article">  The person has the ability to distinguish the voice of the interlocutor from the noise, for example, in a place where there is a large crowd of people.  This ability is called the "cocktail party effect".  Our brain loads unnecessary sounds.  Automatic separation of sounds into individual tracks by computer has also been studied, but so far such work remains a challenge for the machine. <br><br>  A team from Google introduced a self-learning system capable of ‚Äúsnatching‚Äù a person‚Äôs speech using simultaneous recognition of audio and video sequences, separating other voices and extraneous noise.  The study is called ‚ÄúLooking to hear at a cocktail party‚Äù (‚ÄúLooking to Listen at the Cocktail Party‚Äù). <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/Z_ogAiVoE1g" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><a name="habracut"></a><br>  A person is able to highlight the voice of the interlocutor he needs from the crowd, and if necessary, ignore the familiar voice and tune in to someone else.  <a href="http://journals.sagepub.com/doi/abs/10.1177/0956797613482467">A</a> 2013 <a href="http://journals.sagepub.com/doi/abs/10.1177/0956797613482467">study by a</a> team of scientists at the University of Queens in Ontario (Canada) in practice proved the ‚Äúcocktail party effect‚Äù with the help of a test for married couples aged 44 to 79 who were married for at least 18 years at the time of the study.  Over the years of living together, people tune in to each other, are able to highlight the information spoken in the voice of the spouse in audio, or ignore that voice if necessary.  Couples familiar for less than five years are able to recognize the voice of their half worse, but this does not exclude the possibility of <a href="http://ogrik2.ru/b/eliezer-shternberg/nejrologika-chem-obyasnyayutsya-strannye-postupki-kotorye-my-sovershaem-neozhidanno-dlya-sebya/28657/effekt-koktejlnoj-vecherinki/62">focusing</a> on any individual speaker in a noisy room or hearing their own name in the general flow of information. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      The technology developed by Google Research allows you to edit video, amplifying the voice of the main speaker and eliminating background noise.  The method works with regular videos with one audio track.  The user is only required to select the face of the person to be heard, or to let the program do it automatically, focusing on the situation.  The method can be applied in improving sound and voice recognition from audio to text, in conference applications, to improve hearing aids, as well as in other situations in which a large number of people simultaneously participate. <br><br><img src="https://habrastorage.org/webt/wv/ma/ua/wvmauammd_wcjm8aczhbuwlzazw.jpeg"><br><br>  A feature of the technology is the simultaneous use of audio tracks and video sequences.  The movement of the lips of the speaker must match his speech.  The visual signal allows not only to highlight and strengthen the desired voice, but also to perform the reverse process - to compare the speech with a specific person in the video. <br><br>  The program works with a video that is spoken simultaneously by several people.  At the output, the method allows you to get two audio tracks - the desired voice and other sounds with noise. <br><br><img src="https://habrastorage.org/webt/h7/iz/6g/h7iz6g1xfs1b0125c4a6nik6fxa.jpeg"><br><br>  For training the specialists used 100 thousand high quality videos with lectures and monologues on YouTube.  Segments with pure speech, without sounds and music in the background, in which the speaker is in the frame, were taken from the commercials.  The result was about 2000 hours of video fragments. <br><br><img src="https://habrastorage.org/webt/gz/f8/pw/gzf8pwcvbjwjqe5gyjp4p1x_zym.jpeg"><br><br>  The materials used to create "artificial cocktail parties" along with the extraneous noise that they took from <a href="https://research.google.com/audioset/">Audioset</a> .  The result was a video sequence, which many people speak at the same time.  During training, the network compared separate audio tracks with individuals and made up a ‚Äúmask‚Äù for each of the speakers. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/uKwUL7vt03M" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><iframe width="560" height="315" src="https://www.youtube.com/embed/OBLiJ0N9ac4" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Among the possible applications of technology, Google Research offers the use of more accurate automatic subtitling for video. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/_7aMiqXubWo" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  The work is <a href="https://arxiv.org/abs/1804.03619">published</a> on the website of the Cornell University Library. </div><p>Source: <a href="https://habr.com/ru/post/374421/">https://habr.com/ru/post/374421/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../374409/index.html">Red Hogwarts. Series 3. Major</a></li>
<li><a href="../374411/index.html">Apple has completely switched to renewable energy in 43 countries</a></li>
<li><a href="../374413/index.html">Apple will be forced to pay $ 500 million patent troll</a></li>
<li><a href="../374415/index.html">The experience of using a pedestrian helmet to protect against low temperatures in the winter in the Far East of Russia</a></li>
<li><a href="../374419/index.html">Solution FizzBuzz on FPGA with video generation</a></li>
<li><a href="../374423/index.html">Sega announced the release of a miniature Sega MegaDrive</a></li>
<li><a href="../374425/index.html">DTEK starts construction of the largest solar power station in Ukraine</a></li>
<li><a href="../374427/index.html">Why networks are torn</a></li>
<li><a href="../374429/index.html">Mechanical scanning + afterglow =?</a></li>
<li><a href="../374431/index.html">Hyperloop plans to build the first branch in Abu Dhabi in 2019</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>