<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Face Recognition. Create and try on masks</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="While the community of iOS developers is arguing how to write projects, while trying to decide whether to use MVVM or VIPER, while trying to subprojec...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Face Recognition. Create and try on masks</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/webt/sv/p2/wg/svp2wgbhfcqqccft_ktbvndir3g.png"><br><br><p>  While the community of iOS developers is arguing how to write projects, while trying to decide whether to use MVVM or VIPER, while trying to subproject a project or add a jet turbine there, I will try to break away from this and consider how another technology works from the hood under the hood <a href="http://www.gartner.com/smarterwithgartner/top-trends-in-the-gartner-hype-cycle-for-emerging-technologies-2017/">Driven-Development</a> . </p><br><p>  In 2017, machine learning is at the top of the HYIP chart.  And it is clear why: </p><br><ul><li>  There are more open data sets. </li><li>  Appeared the appropriate hardware.  Including cloud solutions. </li><li>  Technologies from this area began to be used in production-projects. </li></ul><br><p>  Machine learning is a broad topic, focusing on face recognition and trying to figure out what technologies were before Christmas. <del>  Christ's </del>  CoreML, and what appeared after the release of the Apple framework. </p><a name="habracut"></a><br><h2 id="teoriya-raspoznavaniya-lic">  Face recognition theory </h2><br><p>  The task of face recognition is part of the practical application of pattern recognition theory.  It consists of two subtasks: identification and classification ( <a href="https://habrahabr.ru/post/317798/">here the differences are detailed</a> ).  Personal identification is actively used in modern services such as Facebook, iPhoto.  Face recognition is used everywhere, ranging from FaceID to the iPhone X, ending with the use of hovering in military technology. </p><br><p>  A person recognizes the faces of other people due to the area of ‚Äã‚Äãthe brain at the border of the occipital and temporal lobes - the fusiform gyrus.  We recognize different people from 4 months.  The key features that the brain identifies are eye, nose, mouth, and eyebrows.  Also, the human brain restores the entire face even in half and can identify a person only by part of the face.  The brain averages all seen faces, and then finds differences from this average variant.  Therefore, it seems to people of the Caucasian race that everyone who belongs to the Mongoloid race is like one person.  It‚Äôs hard for Mongoloids to distinguish Europeans.  Internal recognition is tuned to the spectral range of faces in the head, therefore, if some part of the spectrum lacks data, the face is considered to be the same. </p><br><p>  Face recognition tasks have been solved for over 40 years.  They include: </p><br><ul><li>  Search and recognition of several persons in the video stream. </li><li>  Resistance to changes in the face, hair, beard, glasses, age and turn of the face. </li><li>  Scalable data to identify a person. </li><li>  Work in real time. </li></ul><br><p>  One of the optimal algorithms for finding a face in a picture and its selection is a <a href="https://ru.wikipedia.org/wiki/%25D0%2593%25D0%25B8%25D1%2581%25D1%2582%25D0%25BE%25D0%25B3%25D1%2580%25D0%25B0%25D0%25BC%25D0%25BC%25D0%25B0_%25D0%25BD%25D0%25B0%25D0%25BF%25D1%2580%25D0%25B0%25D0%25B2%25D0%25BB%25D0%25B5%25D0%25BD%25D0%25BD%25D1%258B%25D1%2585_%25D0%25B3%25D1%2580%25D0%25B0%25D0%25B4%25D0%25B8%25D0%25B5%25D0%25BD%25D1%2582%25D0%25BE%25D0%25B2">histogram of directional gradients</a> . <br>  There are other algorithms.  It describes in detail how the search for a zone with a face follows <a href="https://habrahabr.ru/post/133826/">the Viola-Jones algorithm</a> .  It is less accurate and works worse with turns of the face. </p><br><h2 id="kratkiy-ekskurs-v-tehnologii-i-resheniya-raspoznavaniya-obrazov">  A brief excursion into technology and pattern recognition solutions </h2><br><p>  There are many solutions that include algorithms for pattern recognition.  The list of popular libraries that are used in iOS: </p><br><img src="https://habrastorage.org/webt/tb/xy/ee/tbxyeelsljodpim-ydrflwie4nu.png" width="650"><br><p>  <em>Figure 1. DLIB library structure</em> </p><br><p>  <a href="http://dlib.net/"><strong>DLIB</strong></a> </p><br><ul><li>  Pros: <br>  - Open source solution, you can participate in the development and watch current trends. <br>  - Written in C ++.  It has support for iOS in the form of cocoapods: pod 'dlib'. <br>  - Can also be integrated as a C ++ library.  Works on Windows, Linux, MacOS.  You can work in swift applications by writing a wrapper on objective-c ++. </li><li>  Minuses: <br>  - Large size of the connected library.  40 megabytes in the form of pod. <br>  - High entry threshold.  A large number of internal algorithms, each of which will have to write a wrapper on Objective-C. </li></ul><br><img src="https://habrastorage.org/webt/1x/y8/5r/1xy85r3qhtvw_h_kdymaipbnec8.png"><br><p>  <em>Figure 2. The structure of the library OpenCV</em> </p><br><p>  <a href="http://opencv.org/"><strong>OpenCV</strong> (Open Source Computer Vision Library)</a> </p><br><ul><li>  Pros: <br>  - The largest community that regularly participates in support. <br>  - Written in C ++.  It has support for iOS in the form of cocoapods: pod 'OpenCV'. </li><li>  Minuses: <br>  - High entry threshold. <br>  - Large size of the connected library.  77 megabytes in the form of pod, 180 megabytes in the form of a C ++ library. </li></ul><br><img src="https://habrastorage.org/webt/jb/1-/s7/jb1-s7cuuuktbpqgawykk49igsg.png"><br><p>  <em>Figure 3. CoreML structure</em> </p><br><p>  <a href="https://developer.apple.com/documentation/vision"><strong>iOS Vision Framework</strong></a> </p><br><ul><li>  Pros: <br>  - Easy integration into the app. <br>  - Contains a handy converter that supports several different models of other frameworks (Keras, Caffe, scikit-learn). <br>  - Boxed solution with a small size. <br>  - Powered by GPU. </li><li>  Minuses: <br>  - It is part of CoreML, therefore it supports a limited number of model types of other existing frameworks. <br>  - No support for TensorFlow, one of the most popular machine learning solutions.  You have to spend a lot of time on self-made converters. <br>  - It is a high-level abstraction.  All implementation is closed, hence the impossibility of control. <br>  - iOS 11+. </li></ul><br><p>  There are paid platforms that provide solutions for the problem of pattern recognition.  Most develop their own algorithms and technologies.  Of course, these technologies are being actively developed and used by the military, so some solutions are classified and do not have open source. </p><br><h2 id="chto-takoe-landmarks">  What is landmarks </h2><br><img src="https://habrastorage.org/webt/lv/kp/bc/lvkpbcfm8_6_ra7bq7o7l_ep2dg.png" width="400"><br><p>  <em>Figure 4. Visual display of facial structures.</em> </p><br><p>  The purpose of landmarks is to find face points.  The first step in the algorithm is to determine the location of the face in the picture.  After receiving the location of the person looking for <strong>key contours</strong> : </p><br><ul><li>  The contour of the face. </li><li>  Left eye. </li><li>  Right eye. </li><li>  Left eyebrow. </li><li>  Right eyebrow. </li><li>  Left pupil. </li><li>  Right pupil. </li><li>  Nose. </li><li>  Lips. </li></ul><br><p>  Each of these contours is an array of points in the plane. </p><br><img src="https://habrastorage.org/webt/lz/m9/zu/lzm9zud3oysraft5epv9-wjfla4.jpeg" width="400"><br><p>  <em>pic 5. dlib 68 landmarks</em> </p><br><p>  In the picture you can clearly see the structure of the face.  However, depending on the library chosen, the number of landmarks is different.  Developed solutions for 4 landmarks, 16, 64, 124 and more. </p><br><h2 id="triangulyaciya-delone-dlya-postroeniya-maski">  Delaunay triangulation to build a mask </h2><br><p>  Let's move on to the practical part.  Let's try to build a simple mask on the face of the landmarks obtained.  The expected result will be a view mask: </p><br><img src="https://habrastorage.org/webt/tb/ti/r2/tbtir2cmcfdvkic-gh1mizwpnl0.jpeg"><br><p>  <em>Figure 6. Mask visualizing the Delaunay triangulation algorithm</em> </p><br><p>  <strong>Delaunay</strong> triangulation - triangulation for a set of points S on a plane, in which for any triangle all points from S except for the points that are its vertices lie outside the circle described around the triangle.  First described in 1934 by the Soviet mathematician Boris Delone. </p><br><img src="https://habrastorage.org/webt/ie/mu/mv/iemumvh0eei2x5jhbrm5e7wlxga.png"><br><p>  <em>Figure 7. An example of the Delaunay triangulation.</em>  <em>A circle is generated from each point, passing through the two nearest ones in the Euclidean metric</em> </p><br><h2 id="prakticheskaya-realizaciya-algoritma">  Practical implementation of the algorithm </h2><br><p>  We implement the Delaunay triangulation algorithm for our face in the camera. </p><br><p>  Step 1. Inside you will see a wrapper that takes an array of points in two-dimensional space and returns an array of triangles. </p><br><pre><code class="hljs swift"><span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-keyword"><span class="hljs-keyword">final</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Triangle</span></span></span><span class="hljs-class"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> vertex1: <span class="hljs-type"><span class="hljs-type">Vertex</span></span> <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> vertex2: <span class="hljs-type"><span class="hljs-type">Vertex</span></span> <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> vertex3: <span class="hljs-type"><span class="hljs-type">Vertex</span></span> <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-keyword"><span class="hljs-keyword">init</span></span>(vertex1: <span class="hljs-type"><span class="hljs-type">Vertex</span></span>, vertex2: <span class="hljs-type"><span class="hljs-type">Vertex</span></span>, vertex3: <span class="hljs-type"><span class="hljs-type">Vertex</span></span>) { <span class="hljs-keyword"><span class="hljs-keyword">self</span></span>.vertex1 = vertex1 <span class="hljs-keyword"><span class="hljs-keyword">self</span></span>.vertex2 = vertex2 <span class="hljs-keyword"><span class="hljs-keyword">self</span></span>.vertex3 = vertex3 } }</code> </pre> <br><p>  And vertex is a wrapper for CGPoint, additionally containing the number of a specific landmark. </p><br><pre> <code class="hljs pgsql"><span class="hljs-built_in"><span class="hljs-built_in">public</span></span> final <span class="hljs-keyword"><span class="hljs-keyword">class</span></span> Vertex { <span class="hljs-built_in"><span class="hljs-built_in">public</span></span> let <span class="hljs-type"><span class="hljs-type">point</span></span>: CGPoint //  .  <span class="hljs-number"><span class="hljs-number">0</span></span>  <span class="hljs-number"><span class="hljs-number">67.</span></span>  <span class="hljs-number"><span class="hljs-number">68</span></span>   dlib.  <span class="hljs-number"><span class="hljs-number">65</span></span>  vision <span class="hljs-built_in"><span class="hljs-built_in">public</span></span> let identifier: <span class="hljs-type"><span class="hljs-type">Int</span></span> <span class="hljs-built_in"><span class="hljs-built_in">public</span></span> init(<span class="hljs-type"><span class="hljs-type">point</span></span>: CGPoint, id: <span class="hljs-type"><span class="hljs-type">Int</span></span>) { self.point = <span class="hljs-type"><span class="hljs-type">point</span></span> self.identifier = id } }</code> </pre> <br><p>  Step 2. We proceed to the drawing of polygons on the face.  Turn on the camera and show the image from the camera on the screen: </p><br><pre> <code class="hljs swift"><span class="hljs-keyword"><span class="hljs-keyword">final</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">ViewController</span></span></span><span class="hljs-class">: </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">UIViewController</span></span></span><span class="hljs-class"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> session: <span class="hljs-type"><span class="hljs-type">AVCaptureSession?</span></span> <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> faceDetection = <span class="hljs-type"><span class="hljs-type">VNDetectFaceRectanglesRequest</span></span>() <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> faceLandmarks = <span class="hljs-type"><span class="hljs-type">VNDetectFaceLandmarksRequest</span></span>() <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> faceLandmarksDetectionRequest = <span class="hljs-type"><span class="hljs-type">VNSequenceRequestHandler</span></span>() <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> faceDetectionRequest = <span class="hljs-type"><span class="hljs-type">VNSequenceRequestHandler</span></span>() <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> <span class="hljs-built_in"><span class="hljs-built_in">lazy</span></span> <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> previewLayer: <span class="hljs-type"><span class="hljs-type">AVCaptureVideoPreviewLayer?</span></span> = { <span class="hljs-keyword"><span class="hljs-keyword">guard</span></span> <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> session = <span class="hljs-keyword"><span class="hljs-keyword">self</span></span>.session <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-literal"><span class="hljs-literal">nil</span></span> } <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> previewLayer = <span class="hljs-type"><span class="hljs-type">AVCaptureVideoPreviewLayer</span></span>(session: session) previewLayer.videoGravity = .resizeAspectFill <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> previewLayer }() <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> <span class="hljs-built_in"><span class="hljs-built_in">lazy</span></span> <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> triangleView: <span class="hljs-type"><span class="hljs-type">TriangleView</span></span> = { <span class="hljs-type"><span class="hljs-type">TriangleView</span></span>(frame: view.bounds) }() <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> frontCamera: <span class="hljs-type"><span class="hljs-type">AVCaptureDevice?</span></span> = { <span class="hljs-type"><span class="hljs-type">AVCaptureDevice</span></span>.<span class="hljs-keyword"><span class="hljs-keyword">default</span></span>(<span class="hljs-type"><span class="hljs-type">AVCaptureDevice</span></span>.<span class="hljs-type"><span class="hljs-type">DeviceType</span></span>.builtInWideAngleCamera, <span class="hljs-keyword"><span class="hljs-keyword">for</span></span>: <span class="hljs-type"><span class="hljs-type">AVMediaType</span></span>.video, position: .front) }() <span class="hljs-keyword"><span class="hljs-keyword">override</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">func</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">viewDidLoad</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span></span> { <span class="hljs-keyword"><span class="hljs-keyword">super</span></span>.viewDidLoad() sessionPrepare() session?.startRunning() <span class="hljs-keyword"><span class="hljs-keyword">guard</span></span> <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> previewLayer = previewLayer <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> } view.layer.addSublayer(previewLayer) view.insertSubview(triangleView, at: <span class="hljs-type"><span class="hljs-type">Int</span></span>.<span class="hljs-built_in"><span class="hljs-built_in">max</span></span>) } <span class="hljs-keyword"><span class="hljs-keyword">override</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">func</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">viewDidLayoutSubviews</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span></span> { <span class="hljs-keyword"><span class="hljs-keyword">super</span></span>.viewDidLayoutSubviews() previewLayer?.frame = view.frame } <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">func</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">sessionPrepare</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span></span> { session = <span class="hljs-type"><span class="hljs-type">AVCaptureSession</span></span>() <span class="hljs-keyword"><span class="hljs-keyword">guard</span></span> <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> session = session, <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> captureDevice = frontCamera <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> } <span class="hljs-keyword"><span class="hljs-keyword">do</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> deviceInput = <span class="hljs-keyword"><span class="hljs-keyword">try</span></span> <span class="hljs-type"><span class="hljs-type">AVCaptureDeviceInput</span></span>(device: captureDevice) session.beginConfiguration() <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> session.canAddInput(deviceInput) { session.addInput(deviceInput) } <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> output = <span class="hljs-type"><span class="hljs-type">AVCaptureVideoDataOutput</span></span>() output.videoSettings = [ <span class="hljs-type"><span class="hljs-type">String</span></span>(kCVPixelBufferPixelFormatTypeKey): <span class="hljs-type"><span class="hljs-type">Int</span></span>(kCVPixelFormatType_420YpCbCr8BiPlanarFullRange) ] output.alwaysDiscardsLateVideoFrames = <span class="hljs-literal"><span class="hljs-literal">true</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> session.canAddOutput(output) { session.addOutput(output) } session.commitConfiguration() <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> queue = <span class="hljs-type"><span class="hljs-type">DispatchQueue</span></span>(label: <span class="hljs-string"><span class="hljs-string">"output.queue"</span></span>) output.setSampleBufferDelegate(<span class="hljs-keyword"><span class="hljs-keyword">self</span></span>, queue: queue) <span class="hljs-built_in"><span class="hljs-built_in">print</span></span>(<span class="hljs-string"><span class="hljs-string">"setup delegate"</span></span>) } <span class="hljs-keyword"><span class="hljs-keyword">catch</span></span> { <span class="hljs-built_in"><span class="hljs-built_in">print</span></span>(<span class="hljs-string"><span class="hljs-string">"can't setup session"</span></span>) } } }</code> </pre> <br><p>  Step 3. Next we get frames from the camera </p><br><img src="https://habrastorage.org/webt/_y/xg/kk/_yxgkkinu23lrhbd-yxmi0bd1g8.png" width="250"><br><p>  <em>Figure 8. An example of the received frame from the camera</em> </p><br><pre> <code class="hljs swift"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">extension</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">ViewController</span></span></span><span class="hljs-class">: </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">AVCaptureVideoDataOutputSampleBufferDelegate</span></span></span><span class="hljs-class"> </span></span>{ <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">func</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">captureOutput</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">_</span></span></span></span><span class="hljs-function"><span class="hljs-params"> output: AVCaptureOutput, didOutput sampleBuffer: CMSampleBuffer, from connection: AVCaptureConnection)</span></span></span></span> { <span class="hljs-keyword"><span class="hljs-keyword">guard</span></span> <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> pixelBuffer = <span class="hljs-type"><span class="hljs-type">CMSampleBufferGetImageBuffer</span></span>(sampleBuffer) <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> } <span class="hljs-keyword"><span class="hljs-keyword">guard</span></span> <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> attachments = <span class="hljs-type"><span class="hljs-type">CMCopyDictionaryOfAttachments</span></span>(kCFAllocatorDefault, sampleBuffer, kCMAttachmentMode_ShouldPropagate) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span>? [<span class="hljs-type"><span class="hljs-type">String</span></span>: <span class="hljs-type"><span class="hljs-type">Any</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> } <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> ciImage = <span class="hljs-type"><span class="hljs-type">CIImage</span></span>(cvImageBuffer: pixelBuffer, options: attachments) <span class="hljs-comment"><span class="hljs-comment">// leftMirrored for front camera let ciImageWithOrientation = ciImage.oriented(forExifOrientation: Int32(UIImageOrientation.leftMirrored.rawValue)) detectFace(on: ciImageWithOrientation) } }</span></span></code> </pre> <br><p>  Step 4. Looking for faces on the frame </p><br><pre> <code class="hljs pgsql"> fileprivate func detectFace(<span class="hljs-keyword"><span class="hljs-keyword">on</span></span> image: CIImage) { try? faceDetectionRequest.<span class="hljs-keyword"><span class="hljs-keyword">perform</span></span>([faceDetection], <span class="hljs-keyword"><span class="hljs-keyword">on</span></span>: image) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> let results = faceDetection.results <span class="hljs-keyword"><span class="hljs-keyword">as</span></span>? [VNFaceObservation] { <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> !results.isEmpty { faceLandmarks.inputFaceObservations = results detectLandmarks(<span class="hljs-keyword"><span class="hljs-keyword">on</span></span>: image) } } }</code> </pre> <br><p>  Step 5. Looking for landmarks on the face </p><br><img src="https://habrastorage.org/webt/ve/l-/xz/vel-xzqx_9uld-1chovtmfpeau4.png" width="250"><br><p>  <em>Figure 9. Example of landmarks found on the face.</em> </p><br><pre> <code class="hljs swift"> <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">func</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">detectLandmarks</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(on image: CIImage)</span></span></span></span> { <span class="hljs-keyword"><span class="hljs-keyword">try</span></span>? faceLandmarksDetectionRequest.perform([faceLandmarks], on: image) <span class="hljs-keyword"><span class="hljs-keyword">guard</span></span> <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> landmarksResults = faceLandmarks.results <span class="hljs-keyword"><span class="hljs-keyword">as</span></span>? [<span class="hljs-type"><span class="hljs-type">VNFaceObservation</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> } <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> observation <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> landmarksResults { <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> boundingBox = faceLandmarks.inputFaceObservations?.first?.boundingBox { <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> faceBoundingBox = boundingBox.scaled(to: <span class="hljs-type"><span class="hljs-type">UIScreen</span></span>.main.bounds.size) <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> maparr = [<span class="hljs-type"><span class="hljs-type">Vertex</span></span>]() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (index, element) <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> convertPointsForFace(observation.landmarks?.allPoints, faceBoundingBox).enumerated() { <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> point = <span class="hljs-type"><span class="hljs-type">CGPoint</span></span>(x: (<span class="hljs-type"><span class="hljs-type">Double</span></span>(<span class="hljs-type"><span class="hljs-type">UIScreen</span></span>.main.bounds.size.width - element.point.x)), y: (<span class="hljs-type"><span class="hljs-type">Double</span></span>(<span class="hljs-type"><span class="hljs-type">UIScreen</span></span>.main.bounds.size.height - element.point.y))) maparr.append(<span class="hljs-type"><span class="hljs-type">Vertex</span></span>(point: point, id: index)) } triangleView.recalculate(vertexes: maparr) } } } <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">func</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">convertPointsForFace</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">_</span></span></span></span><span class="hljs-function"><span class="hljs-params"> landmark: VNFaceLandmarkRegion2D?, </span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">_</span></span></span></span><span class="hljs-function"><span class="hljs-params"> boundingBox: CGRect)</span></span></span></span> -&gt; [<span class="hljs-type"><span class="hljs-type">Vertex</span></span>] { <span class="hljs-keyword"><span class="hljs-keyword">guard</span></span> <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> points = landmark?.normalizedPoints <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> [] } <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> faceLandmarkPoints = points.<span class="hljs-built_in"><span class="hljs-built_in">map</span></span> { (point: <span class="hljs-type"><span class="hljs-type">CGPoint</span></span>) -&gt; <span class="hljs-type"><span class="hljs-type">Vertex</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> pointX = point.x * boundingBox.width + boundingBox.origin.x <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> pointY = point.y * boundingBox.height + boundingBox.origin.y <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-type"><span class="hljs-type">Vertex</span></span>(point: <span class="hljs-type"><span class="hljs-type">CGPoint</span></span>(x: <span class="hljs-type"><span class="hljs-type">Double</span></span>(pointX), y: <span class="hljs-type"><span class="hljs-type">Double</span></span>(pointY)), id: <span class="hljs-number"><span class="hljs-number">0</span></span>) } <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> faceLandmarkPoints }</code> </pre> <br><p>  Step 6. Next, draw on top of our mask.  We take the obtained triangles from the Delone algorithm and draw in the form of layers. </p><br><img src="https://habrastorage.org/webt/oz/ae/la/ozaela1fx_04_grzvw10gfzb6i0.png" width="250"><br><p>  <em>Figure 10. The final result is the simplest mask over the face.</em> </p><br><p>  Full implementation of the Delaunay triangulation algorithm on Swift <a href="https://github.com/NikAshanin/Swift-Triangulation-Delaunay">here</a> . </p><br><p>  And a couple of optimization tips for the sophisticated.  Drawing new layers every time is an expensive operation.  Constantly calculate the coordinates of the triangles using the Delaunay algorithm is also expensive.  Therefore, we take a face in high resolution and good quality, which looks into the camera, and we run once the Delaunay triangulation algorithm in this photo.  The resulting triangles are saved in a text file, and then we use these triangles and change their coordinates. </p><br><h2 id="chto-predstavlyayut-soboy-maski">  What are masks </h2><br><p>  MSQRD, Snapchat, VK, even Avito - everyone uses masks. </p><br><img src="https://habrastorage.org/webt/-t/y_/le/-ty_lelu5c2w50mvjcafzr3b92c.png" width="200"><br><img src="https://habrastorage.org/webt/o7/yd/8y/o7yd8y8gdixa-n2zmgdn2oyvm_a.png" width="200"><br><br><p>  <em>rice 11. Examples of snapchat masks</em> </p><br><p>  To implement the <a href="https://github.com/marsbroshok/face-replace">simplest version of the mask is easy</a> .  Take the landmarks that got higher.  Select the mask you want to apply and place our landmarks on it.  At the same time, there are simplest 2D projections, and there are more complex 3D masks.  For them, calculate the conversion points, which will translate the vertices of the mask on the frame.  To landmarks, responsible for the ears, were responsible for the ears of our mask.  Next, just keep track of the new position landmarks of the face and change our mask. </p><br><p> <a href="https://www.youtube.com/watch%3Fv%3D%26feature%3Dyoutu.be" title="Original face"><img src="https://habrastorage.org/getpro/habr/post_images/9a4/d96/3de/9a4d963defdc09c44179f81babe8d839.jpg" alt="Original face"></a> </p><br><p> <a href="https://www.youtube.com/watch%3Fv%3D6X2vD8vt1t4%26feature%3Dyoutu.be" title="Mask in the form of a stretched face of Arnold Schwarzenegger"><img src="https://habrastorage.org/getpro/habr/post_images/03c/6a1/a4c/03c6a1a4c441ecc72515c89255b4925f.jpg" alt="Mask in the form of a stretched face of Arnold Schwarzenegger"></a> </p><br><p>  In this area there are difficult tasks that are solved when creating masks.  For example, the complexity of rendering.  Even more difficult are the moments of landmarks jumps, as in this case masks are distorted and will behave unpredictably.  And since the capture of frames from a mobile phone camera is a chaotic process involving a rapid change of light, shadows, sharp jerks, and so on, the task becomes very time consuming.  Another challenge is building complex masks. <br>  As entertainment or solving a simple problem, this is interesting.  But as in other areas, if you want to solve cool problems, you will have to spend time learning. </p><br><h2 id="v-sleduyuschey-state">  In the next article </h2><br><p>  The task of recognizing images, faces, car numbers, gender, age is becoming increasingly popular.  IT companies in this market introduce technologies to solve such problems gradually and imperceptibly to the user.  <a href="https://www.cnbc.com/2017/07/21/china-ai-world-leader-by-2030.html">China will invest 150 billion in machine learning in the coming years</a> to be the first in this area. </p><br><p>  In the next article I will tell you how to identify a specific person by the selected person and filter fuzzy photos before identification. </p></div>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <p>Source: <a href="https://habr.com/ru/post/343514/">https://habr.com/ru/post/343514/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../343504/index.html">Slower, Smoother: Understanding React Fiber</a></li>
<li><a href="../343506/index.html">MSA and more: how we create high-load services for the bank</a></li>
<li><a href="../343508/index.html">Yes, PVS-Studio can detect memory leaks</a></li>
<li><a href="../343510/index.html">Olympiad "I am a professional" track "Information and cyber security"</a></li>
<li><a href="../343512/index.html">Is it possible to push number recognition in any tamagotchi?</a></li>
<li><a href="../343516/index.html">Developers on the dirtiest software tricks in games</a></li>
<li><a href="../343518/index.html">How we rewrote the Yandex.Pogoda architecture and made a global forecast on maps</a></li>
<li><a href="../343522/index.html">Setting up a WEB system - testing based on headless chromium-browser, chromedriver, nightwatch and node.js on Ubuntu</a></li>
<li><a href="../343524/index.html">Network JTAG programmer for Altera Quartus Prime from Raspberry Pi3</a></li>
<li><a href="../343526/index.html">Two geometric tasks that came across at the interview, and where they live</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>