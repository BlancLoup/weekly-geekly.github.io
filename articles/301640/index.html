<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>IPython notebook data processing for SEO tasks</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="In performing the analytical tasks of SEO, SMM, marketing, we are faced with an excessively growing amount of data processing tools. Each is tailored ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>IPython notebook data processing for SEO tasks</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/files/c1e/b5f/287/c1eb5f287a574d1682177ab79a5f07ed.jpg" alt="image"><br><br>  In performing the analytical tasks of SEO, SMM, marketing, we are faced with an excessively growing amount of data processing tools.  Each is tailored to its capabilities or accessibility for the user: Excel and VBA, third-party SEO tools, PHP and MySQL, Python, C, Hive, and others.  Various systems and data sources add problems: counters, advertising systems, CRM, webmaster tools of Yandex and Google, social networks, HDFS.  A tool is needed that combines ease of setup and use, modules for receiving, processing and visualizing data, as well as working with various types of sources.  The choice fell on iPython notebook (more recently Jupyter notebook), which is a platform for working with scripts in 40 programming languages.  The platform is widely used for scientific computing, among specialists in data processing and machine learning.  Unfortunately, Jupyter notebook is rarely used to automate and process marketing data. <br><a name="habracut"></a><br><br>  For tasks of web analytics and data processing for SEO, Jupyter notebook is suitable for several reasons: <br>  - easy setup <br>  - processing and visualization of data without the need to write code <br>  - with a lack of personal computer resources, you can simply run notebook on a more powerful virtual machine (for example, using Amazon Web Services) and calculate the necessary data without changing the script code 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      In this article, we will look at three examples that will help you start using Jupyter notebook for solving practical problems: <br><br>  <b>Yandex Metrics API</b> <br>  Often there are tasks of preparing reports on site visits, data for these reports can be collected automatically by setting up the system once.  The time gain is obvious.  In the example, let's see how to download the statistics of all search phrases for several projects from Yandex Metrics (in this case, getting all the statistics from the web interface is rather difficult). <br><br>  <b>Word2vec</b> <br>  There are complex algorithms for automatic processing of textual data, let's see how you can simply use them to analyze specifically your data.  Tasks that can be solved using word2vec - search for typos in words, search for synonyms, search for "similar" words. <br><br>  <b>PageRank calculation</b> <br>  SMO specialists will be interested in how to use the PR calculation algorithm to find the most authoritative community members.  Slightly changing the script settings as well you can find the page with the highest PageRank on your site.  We will also see how to visualize users of the VKontakte group using D3js. <br><br>  The report was presented at the first SEO Meetup ‚ÄúData Driven SEO‚Äù on February 4 in Rambler &amp; Co ( <a href="http://www.youtube.com/watch%3Fv%3DzgxFDMdCZZU">link to video</a> ). <br><br>  Ready-made codes of these examples can be taken on <a href="https://github.com/kpimaker/meetup">GitHub</a> . <br><br>  <b>Install Jupyter notebook</b> <br>  For installation on a personal computer, only 2 actions are required: <br>  1. Install <a href="https://www.continuum.io/downloads">the Anaconda python distribution</a> <br><br>  2. On the command line, run: conda install jupyter <br><br>  To run notebook on the command line, run: jupyter notebook <br><br>  In case of a successful installation in the browser, a view window will open: <br><img src="https://habrastorage.org/files/57d/b43/e5c/57db43e5cba940bfb18dd8a8f08747d2.jpg" alt="image"><br><br>  <b>Downloading reports from Yandex Metrics</b> <br>  ( <a href="https://github.com/kpimaker/meetup/blob/master/Yandex_metrika_example.ipynb">example code</a> ) <br>  Let's see how to automatically unload data from the ‚ÄúSearch phrases‚Äù report.  The problems of manual unloading of such a report are quite obvious: Yandex Metrica cannot always unload the entire table at once (for large projects, the number of lines is in the hundreds of thousands), and regular uploading for several projects is, in principle, quite tiresome.  For those who are unfamiliar with the python syntax, let‚Äôs analyze this example in detail. <br>  <a href="">habrastorage.org/files/385/ae6/980/385ae698096d4b7b9df4e116ede90525.jpg</a> <br><br>  We import the necessary library for requests to the API and working with the JSON format: <br><pre><code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># -*- coding: utf-8 -*- import requests import json</span></span></code> </pre> <br><br>  Ctrl + Enter - execute the line.  Shift + Enter - execute the line and go to the next. <br><br>  We get a token for requests to our counters: <br>  1. On the page <a href="https://oauth.yandex.ru/">https://oauth.yandex.ru/ we</a> start the application and give it permission to get statistics Yandex Metrics.  Screenshots can be viewed in the article <a href="https://habrahabr.ru/post/265383/">https://habrahabr.ru/post/265383/</a> <br><br>  2. Substitute the application ID in the URL <a href="https://oauth.yandex.ru/authorize%3Fresponse_type%3Dtoken%26client_id%3D">https://oauth.yandex.ru/authorize?response_type=token&amp;client_id=</a> <br>  As a result, we obtain an authorization token, which we will use in each request to Yandex Metric.  Copy the received token to the token script variable. <br><br>  We set the parameters of our upload: <br>  project - a list of your counters, which will get the data (eight-digit number in the list of meters metrika.yandex.ru) <br>  startDate and endDate - the date of the beginning and end of the unloading period in the format 'YYYY-MM-DD'.  For example, startDate = '2016-01-31' <br>  limit - how many lines will be unloaded per request.  For example, if we have 500,000 rows in a report, then with the limit value = 10000 (the maximum value for the current API version), the script will make 50 queries to unload the entire table. <br><br>  We clean the file in which the data will be written (so as not to do it manually with each new upload).  The file name can be set by any: <br><pre> <code class="python hljs">f = open(<span class="hljs-string"><span class="hljs-string">'search phrases.txt'</span></span>, <span class="hljs-string"><span class="hljs-string">'w'</span></span>) f.close()</code> </pre><br><br>  Further in the cycle we go through all the numbers of the meters listed in the projects list: <br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> project <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> projects:</code> </pre><br><br>  For each number of the project counter, we start unloading from the first line (offset = 1), and in each cycle we increase this value by limit.  Parameters in API requests (link to <a href="https://tech.yandex.ru/metrika/doc/api2/api_v1/intro-docpage/">tech.yandex.ru/metrika/doc/api2/api_v1/intro-docpage</a> documentation): <br>  oauth_token - the token we received <br>  id - counter number <br>  accuracy = full - accuracy, the value of 'full' corresponds to the position of the slider 100% <br>  dimensions and metrics - measurements (rows of the table) and metrics (columns) <br><br>  The result (how to work with JSON <a href="https://docs.python.org/2/library/json.html">https://docs.python.org/2/library/json.html</a> ) is added to the delimited tab file (\ t).  The final upload is copy-paste into familiar reports and tools like Excel. <br><br>  <b>Word2vec</b> <br>  ( <a href="https://github.com/kpimaker/meetup/blob/master/Word2Vec_query.ipynb">example code</a> ) <br>  To use the <a href="https://code.google.com/archive/p/word2vec/">Word2Vec</a> library <a href="https://code.google.com/archive/p/word2vec/">,</a> first additionally install gensim <a href="https://pypi.python.org/pypi/gensim">pypi.python.org/pypi/gensim</a> (not included in the Anaconda distribution by default).  At the input of the model is a list of sentences from the original list of search phrases.  That is, a sheet of the form [['watch', 'movies', 'online'], ['rate', 'ruble'], ...]. <br><br>  Next, set the model parameters: <br>  - num_features - the dimension of the space of vectors.  The larger the value, the more ‚Äúaccurate‚Äù the model will take into account the input data (sometimes increasing the dimension does not improve the quality of the model).  Usually use values ‚Äã‚Äãfrom 10 to several hundred.  Accordingly, the larger the dimension, the more computing resources will be required. <br>  - min_word_count - allows to take into account only frequently encountered words in the final dictionary of the model.  Most often, values ‚Äã‚Äãfrom 5 to 100 are taken. As a result, we will significantly reduce the size of the dictionary, leaving only words that have a practical meaning. <br>  - num_workers - how many processes in parallel will build a model <br>  - context - how many words in the context should be taken into account by the algorithm.  Searches are very short "sentences" <br>  - downsampling - exclude frequently occurring words in the text.  Google recommends values ‚Äã‚Äãfrom .00001 to .001 <br><br>  In this example, the model was built on 5 million.  searches about 40 minutes on a laptop with 2GB of free RAM.  This amount of data can be used for SEO tasks: <br><br>  1. Search for typos and semantically close words (opposite to the word, the cosine measure of proximity of the corresponding vectors is indicated): <br><br>  Types of typos and semantically close words for the query 'yandex' in the Russian layout: <br><img src="https://habrastorage.org/files/f60/2e0/0d2/f602e00d29984a738ff413b1aabe991e.jpg" alt="image"><br><br>  An example of close words to the query 'Syria + Asad': <br><img src="https://habrastorage.org/files/2c4/ea0/442/2c4ea044287f4bc6afd49bcf45bc7294.jpg" alt="image"><br><br>  In phrases, you can distinguish requests for "meaning" (in terms of proximity of the corresponding vectors).  Issuance for door and car locks will differ from the windows of Switzerland: <br><img src="https://habrastorage.org/files/a3b/063/ced/a3b063ced17a4cdeb6e6cedcde5d40b2.jpg" alt="image"><br><br>  2. Finding relationships of entities.  This model query will show words that apply to Russia as well as the dollar relates to the United States.  It is logical that these should be the currencies related to Russia from search queries: <br><img src="https://habrastorage.org/files/4de/896/b9c/4de896b9c24144739da2151835cc0edd.jpg" alt="image"><br><br>  3. Definition of "extra" words in the list <br>  The words "forex", "oil" and "gold" will be much closer to each other in the vector space from search queries than "odnushka": <br><img src="https://habrastorage.org/files/fb8/d67/370/fb8d67370a9f42659a6ac937a114ecfc.jpg" alt="image"><br><br>  Similarly, from the list "cat", "man", "elephant", "chinchilla" a request without an "animal" attribute will be superfluous: <br><img src="https://habrastorage.org/files/ed7/4f2/8fa/ed74f28fa20a4bcca30bf630eb1f6a91.jpg" alt="image"><br><br>  4. Automatic content clustering <br>  Having a model built using Word2Vec, you can automatically cluster words in a vector space using popular clustering algorithms.  For example, using the KMeans algorithm for the Lenta.ru model for 1000 texts, we obtain the main news items: <br>  - embargo against Ukraine <br><img src="https://habrastorage.org/files/6c6/46c/155/6c646c155e6f468ea660c9b4ac1ebd73.jpg" alt="image"><br><br>  - terrorist attacks in Paris (the word ‚Äúbataklat‚Äù was obtained as a result of stemmer‚Äôs processing of the name of the theater ‚ÄúBataclan‚Äù) <br><img src="https://habrastorage.org/files/d96/0d7/7cd/d960d77cd8fb4dd99936f2e37be204da.jpg" alt="image"><br><br>  - C-400 in Syria <br><img src="https://habrastorage.org/files/832/12d/744/83212d7441ce49908981781bd5ff0a7f.jpg" alt="image"><br><br>  <b>Working with graphs in Neworkx</b> <br>  (code for <a href="https://github.com/kpimaker/meetup/blob/master/get_VK_data.ipynb">uploading data by API Vkontakte</a> , <a href="https://github.com/kpimaker/meetup/blob/master/VK_group_pagerank.ipynb">processing and visualization</a> ) <br>  In technical terms, graphs are a set of nodes interconnected by edges.  In practice, users of a social network or a group of a site‚Äôs page can act as nodes.  As edges - the presence of friendship between a couple of users, messages, marks like in the posts of the group, links to other pages of the site.  The Networkx library allows you to build such graphs and count various graph characteristics.  Let's look at the example of the VKontakte group how to calculate the PageRank of each user and visualize it in the browser. <br><br>  As an example, one of the relatively small groups of 660 participants was taken (for visual visualization), in which many participants are familiar with each other.  To build a graph, it‚Äôs enough to upload a list of group members (VKontakte groups.getMembers method), and then for each member, get a list of his friends (friends.get method).  The result of the upload is recorded in a text file in the format: <br>  { <br>  User ID, <br>  [friend list] <br>  } <br><br>  As a result, the nodes of the graph g are the IDs of the group members, and the edges are the IDs of the friends of this user.  To calculate the PageRank, we use the function: x = networkx.pagerank (g).  We display the top members of the group: <br><img src="https://habrastorage.org/files/9e4/615/49a/9e461549a0914e46a3c2101b2a39f870.jpg" alt="image"><br><br>  For visualization we use the library <a href="http://mbostock.github.io/d3/talk/20111116/force-collapsible.html">D3.js, force-collapcible</a> .  As the size of the node take its pagerank: <br><img src="https://habrastorage.org/files/499/773/0eb/4997730eb8444ec7b53d74d3ca042c22.jpg" alt="image"><br><br>  When hovering over a node, we can see which ID it belongs to.  You can view detailed information about users by their ID using the users.get method: <a href="">https://api.vk.com/method/users.get?user_id=12345</a> </div><p>Source: <a href="https://habr.com/ru/post/301640/">https://habr.com/ru/post/301640/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../301624/index.html">New virtual servers OVH in comparison with domestic state employees</a></li>
<li><a href="../301626/index.html">Static analyzer HuntBugs: check IntelliJ IDEA</a></li>
<li><a href="../301628/index.html">I have long wanted to tell you something</a></li>
<li><a href="../301632/index.html">How Microsoft implemented Yammer (Part I)</a></li>
<li><a href="../301636/index.html">Add dependencies to CDI. Part 1</a></li>
<li><a href="../301642/index.html">Positive Hack Days VI WAF Bypass Contest</a></li>
<li><a href="../301644/index.html">We are testing asynchronous code.</a></li>
<li><a href="../301646/index.html">Template Description Language Snakeskin</a></li>
<li><a href="../301648/index.html">Dependency Injection Container from PHPixie</a></li>
<li><a href="../301650/index.html">Every vacancy on ‚ÄúMy Circle‚Äù is qualified by specialists</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>