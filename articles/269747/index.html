<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Why google voice neural nets search?</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Have you ever wondered how voice search works? What magic translates your words into a search query, and almost in real time? Today, we‚Äôll tell you ho...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Why google voice neural nets search?</h1><div class="post__text post__text-html js-mediator-article">  Have you ever wondered how voice search works?  What magic translates your words into a search query, and almost in real time?  Today, we‚Äôll tell you how ‚ÄúOk, Google!‚Äù Has become closer to you by 300 milliseconds and what exactly allows you to talk to your phone in simple human language. <br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/83a/759/001/83a759001f1ffa3535bbd0705593045f.gif"></div><br>  The basis of the current version of Google voice search is an improved algorithm for training neural networks, created specifically for the analysis and recognition of acoustic models.  The basis of new, <a href="https://ru.wikipedia.org/wiki/%25D0%25A0%25D0%25B5%25D0%25BA%25D1%2583%25D1%2580%25D1%2580%25D0%25B5%25D0%25BD%25D1%2582%25D0%25BD%25D0%25B0%25D1%258F_%25D0%25BD%25D0%25B5%25D0%25B9%25D1%2580%25D0%25BE%25D0%25BD%25D0%25BD%25D0%25B0%25D1%258F_%25D1%2581%25D0%25B5%25D1%2582%25D1%258C">Recurrent Neural Networks</a> ( <font color="#444444">English:</font> recurrent neural networks - RNN), formed the <a href="https://ru.wikipedia.org/wiki/%25D0%25A0%25D0%25B5%25D0%25BA%25D1%2583%25D1%2580%25D1%2580%25D0%25B5%25D0%25BD%25D1%2582%25D0%25BD%25D0%25B0%25D1%258F_%25D0%25BD%25D0%25B5%25D0%25B9%25D1%2580%25D0%25BE%25D0%25BD%25D0%25BD%25D0%25B0%25D1%258F_%25D1%2581%25D0%25B5%25D1%2582%25D1%258C">Neural Network</a> Temporal Classification ( <em><font color="#444444">English:</font></em> <a href="http://gitxiv.com/posts/9hLxYvJLCu9Z9N4pK/ctc-connectionist-temporal-classification">Connectionist Temporal Classification</a> - CTC) and discriminant analysis for sequences, adapted for the training of such structures.  RNN data is much more accurate, especially in conditions of extraneous noise, and most importantly - they work faster than all previous speech recognition models. <br><a name="habracut"></a><br>  We'll have to start with a little insight into history.  For almost 30 years (by the standards of the IT industry, it is an eternity!) Speech recognition was used for speech recognition.  ‚ÄúModels of a mixture of (multidimensional) normal distributions‚Äù ( <em><font color="#444444">eng .:</font></em> Gaussian Mixture Model - GMM).  At first, Google‚Äôs voice search also worked with this technology until we developed a new approach to translating sound waves into a meaningful set of characters with which a ‚Äúclassic‚Äù text search can operate. <br><br>  At that time (this happened in 2012) the transfer of Google‚Äôs voice search to <a href="https://ru.wikipedia.org/wiki/%25D0%2593%25D0%25BB%25D1%2583%25D0%25B1%25D0%25BE%25D0%25BA%25D0%25BE%25D0%25B5_%25D0%25BE%25D0%25B1%25D1%2583%25D1%2587%25D0%25B5%25D0%25BD%25D0%25B8%25D0%25B5">Deep Neural Networks</a> technology ( <em><font color="#444444">Eng .:</font></em> Deep Neural Networks - DNN) made a real breakthrough in speech recognition.  DNNs were better suited for recognizing individual sounds uttered by the user than GMM, making the speech recognition accuracy significantly higher. <br><br><h1>  <font color="#2196F3">As it was before: the work of DNN</font> </h1><br>  In the classical voice recognition system, the recorded audio signal is divided into short (10 ms) fragments, each of which is then analyzed for the frequencies contained in it.  The resulting vector of characteristics is driven through an acoustic model (for example, such as DNN), which produces a set of probability distributions among all possible phonemes.  <a href="https://ru.wikipedia.org/wiki/%25D0%25A1%25D0%25BA%25D1%2580%25D1%258B%25D1%2582%25D0%25B0%25D1%258F_%25D0%25BC%25D0%25B0%25D1%2580%25D0%25BA%25D0%25BE%25D0%25B2%25D1%2581%25D0%25BA%25D0%25B0%25D1%258F_%25D0%25BC%25D0%25BE%25D0%25B4%25D0%25B5%25D0%25BB%25D1%258C">The hidden Markov model</a> (often used in pattern recognition algorithms) helps to identify successive structures in this set of probability distributions. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      After this, the analysis data is combined with other data from alternative sources of information.  One of them is the Pronunciation Model ( <em><font color="#444444">English:</font></em> Pronunciation Model), which connects a sequence of sounds into certain words of the intended language.  (approx .: Under the "intended" language refers to the language that was selected as the "main" in the voice search settings).  Another source is the Language Model: it processes the words obtained and analyzes the whole phrase, trying to assess how likely such a sequence of words is in the target language. <br><br>  Then all the information goes into the recognition system, which matches all the information to determine the phrase that the user utters.  For example, if a user pronounces the word ‚Äúmuseum‚Äù, then his phonetic record would look like this: / mjuzi @ m /. <br><br>  It can be difficult to say exactly where the sound / j / ended and / u / began, but in fact it does not matter for the algorithm: the main thing is that all these sounds were uttered. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d2c/1f1/83d/d2c1f183d89fc5f6e9e12354ab1333ce.png"><br><br><h1>  <font color="#2196F3">What has changed in the voice search?</font> </h1><br>  Our improved acoustic model is based on <a href="https://ru.wikipedia.org/wiki/%25D0%25A0%25D0%25B5%25D0%25BA%25D1%2583%25D1%2580%25D1%2580%25D0%25B5%25D0%25BD%25D1%2582%25D0%25BD%25D0%25B0%25D1%258F_%25D0%25BD%25D0%25B5%25D0%25B9%25D1%2580%25D0%25BE%25D0%25BD%25D0%25BD%25D0%25B0%25D1%258F_%25D1%2581%25D0%25B5%25D1%2582%25D1%258C">Recurrent Neural Networks</a> (RNN).  Their advantage is that they have feedback loops in their topology, allowing them to simulate temporal dependencies: when the user pronounces / u / in the previous example, his speech machine leaves the pronunciation process of the previous sounds / j / and / m / at the same time.  Try to say out loud - ¬´museum¬ª.  The word comes out instantly, on one exhalation, and the RNN can recognize it. <br><br>  RNNs are of different types, and for speech recognition we used special RNNs with ‚Äúlong short-term memory‚Äù ( <em><font color="#444444">English:</font></em> Long Short-Term Memory - <a href="https://en.wikipedia.org/wiki/Long_short-term_memory">LSTM</a> ).  These memory cells and the complicated mechanism of the gates allow the LSTM RNN to memorize information better than other neural networks. <br><br>  The use of these models alone has already significantly improved the quality of our recognition system, but we did not stop there.  The next step was the training of neural networks to recognize phonemes in a phrase without the need to constantly distinguish individual ‚Äúassumptions‚Äù about the probability distribution of each of them. <br><br>  With the Neural Network Temporal Classification (CTC), the models learned to derive peculiar ‚Äúpeaks‚Äù, which represent a sequence of different sounds in the sound wave.  They can distinguish different phonemes in the correct sequence of sounds from a language point of view. <br><blockquote>  <b>Note:</b> RNNs can recognize the word ‚Äúhydroelectric power station‚Äù, but they will not be able to correctly single out individual sounds in the meaningless sequence of ‚Äúyukuchenfyprolij‚Äù in terms of language. <br></blockquote><br>  The most difficult was the question ‚ÄúHow to make the recognition happen in real time?‚Äù.  After many attempts, we were able to teach streaming unidirectional models to process longer audio intervals than those used in ‚Äúclassical‚Äù speech recognition models.  While the calculations themselves occur with less frequency.  At the same time, the cost of computing resources has actually decreased, and the speed of the recognition system has increased many times over. <br><br><h1>  <font color="#2196F3">Transition from horse-spherical conditions to actual operation</font> </h1><br>  In the laboratory, it is easy to recognize speech: in complete silence, you get a high-quality sound track, which you then analyze.  Unfortunately, the actual operating conditions of voice search are significantly different from the reference.  Someone is talking in the background, cars are passing by, a TV is buzzing somewhere in the distance, a gust of wind flies into the microphone of the smartphone ... All these noises make it difficult for neural networks to process speech, so we taught them to work even in such difficult conditions. <br><br>  In the process of learning RNN, we mixed artificial noise, reverb, echo, and other typical ‚Äúpollution‚Äù in the daily use of the training samples, which helped to make the recognition system more resistant to background noise. <br><br>  Now we had a fast and accurate resolver and we were ready to launch it on real voice requests, however, we had to solve another problem. <br><br><h1>  <font color="#2196F3">How Voice Search Goes Closer to User</font> </h1><br>  The model predicted phonemes with a delay of about 300 milliseconds, since the neural network "realized" that it would be able to better recognize phonemes by listening to the signal for a little longer.  Here is the process of recognition in visual form: <br><br><iframe width="560" height="315" src="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://www.youtube.com/embed/5_9Soz3D41g%3Ffeature%3Doembed&amp;xid=17259,15700019,15700186,15700190,15700248,15700253&amp;usg=ALkJrhhZXedMCE0g1HWmO64K18BInTshZg" frameborder="0" allowfullscreen=""></iframe><br>  <sup>Neural network temporal classification is trying to recognize the phrase "How cold it is outside"</sup> <br><br>  This behavior was logical and worked fine, but it led to slower system responses, which we didn‚Äôt want at all.  We solved this problem by means of a long training of the neural network to select individual phonemes as close as possible to the ‚Äúcutoff‚Äù of the signal.  As a result, speech recognition takes place almost in real time.  The current model based on CTC allocates "peaks" of individual phonemes (displayed in different colors) as soon as it identifies them in the incoming audio stream. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d2c/1f1/83d/d2c1f183d89fc5f6e9e12354ab1333ce.png"><br><br>  The X-axis shows the phonemes defined at each time instant, and the Y-axis shows the <a href="https://ru.wikipedia.org/wiki/%25D0%2590%25D0%25BF%25D0%25BE%25D1%2581%25D1%2582%25D0%25B5%25D1%2580%25D0%25B8%25D0%25BE%25D1%2580%25D0%25BD%25D0%25B0%25D1%258F_%25D0%25B2%25D0%25B5%25D1%2580%25D0%25BE%25D1%258F%25D1%2582%25D0%25BD%25D0%25BE%25D1%2581%25D1%2582%25D1%258C">posterior probabilities of the</a> distribution of one or another phoneme.  The dashed lines mark the variants that the algorithm decided not to single out / recognize as separate sounds. <br><br>  Now our new algorithm is used in voice control and dictation of the text on your smartphones (so far only on the basis of Android) and the Google application on <a href="https://play.google.com/store/apps/details%3Fid%3Dcom.google.android.googlequicksearchbox%26hl%3Dru">Android</a> and <a href="https://itunes.apple.com/ru/app/google-search/id284815942">iOS</a> .  It not only uses less computational resources, but more precisely, it works faster, and is still resistant to noise and interference.  Try it, hope you enjoy it! </div><p>Source: <a href="https://habr.com/ru/post/269747/">https://habr.com/ru/post/269747/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../269737/index.html">Secure crypto programming. Part 2, final</a></li>
<li><a href="../269739/index.html">Conference on web analytics and internet marketing CONVERT.2015 will be held in Yekaterinburg on December 7</a></li>
<li><a href="../269741/index.html">Swift + VK.API, or the story of SwiftyVK</a></li>
<li><a href="../269743/index.html">We continue to fight the frontend-routine</a></li>
<li><a href="../269745/index.html">Learning machine learning</a></li>
<li><a href="../269751/index.html">Attackers exploit a vulnerability in the Ksoft Uploader software! for installing Gh0st RAT</a></li>
<li><a href="../269753/index.html">Testing the functionality of Symantec Backup Hot-Add. Increased speed of copying and restoring data</a></li>
<li><a href="../269755/index.html">Control modes using the mouse and the touch screen in Windows 10 and Windows 8</a></li>
<li><a href="../269757/index.html">The book "Minecraft. Program your world "</a></li>
<li><a href="../269759/index.html">Pytest</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>