<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Neural Network for C ++ Developers</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hello. 

 He wrote a library for learning neural network. Who cares, please. 

 I have long wanted to make myself a tool of this level. C summer took ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Neural Network for C ++ Developers</h1><div class="post__text post__text-html js-mediator-article">  Hello. <br><br>  He wrote a library for learning neural network.  Who cares, please. <br><a name="habracut"></a><br>  I have long wanted to make myself a tool of this level.  C summer took up the case.  Here's what happened: <br><br><ul><li>  the library is written from scratch in C ++ (only STL + OpenBLAS for calculation), C-interface, win / linux; </li><li>  The network structure is set in JSON; </li><li>  base layers: fully connected, convolutional, pooling.  Additional: resize, crop ..; </li><li>  basic chips: batchNorm, dropout, scales optimizers - adam, adagrad ..; </li><li>  OpenBLAS is used for calculation on the CPU, CUDA / cuDNN for the video card.  Laid another implementation on OpenCL, while for the future; </li><li>  for each layer there is an opportunity to separately set on what to count - CPU or GPU (and which one); </li><li>  the size of the input data is not rigidly specified, may vary in the process of work / training; </li><li>  made interfaces for C ++ and Python.  C # will be later too. </li></ul><br>  The library called "SkyNet".  (All is difficult with the names, others were options, but something is all wrong ..) 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <p><br>  Comparing with ‚ÄúPyTorch‚Äù using the MNIST example: <br><br>  PyTorch: Accuracy: 98%, Time: 140 sec <br>  SkyNet: Accuracy: 95%, Time: 150 sec <br><br>  Machine: i5-2300, GF1060.  <a href="https://github.com/Tyill/skynet/tree/master/example/mnist/compare_PyTorch">Test code</a> <br></p><p><br></p><p><br></p><h3>  Software architecture </h3><br><img src="https://habrastorage.org/webt/tr/la/_c/trla_cgwa2qpi9npoxwfduihjss.png" width="700" height="400"><br><br>  The basis of the operations graph is created dynamically once after analyzing the network structure. <br>  For each branch - a new stream.  Each network node (Node) is a calculation layer. <br><br>  There are features of work: <br><br><ul><li>  activation function, batch normalization, dropout ‚Äî they are all implemented as parameters of specific layers, in other words, these functions do not exist as separate layers.  Perhaps batchNorm should be separated into a separate layer in the future; </li><li>  The softMax function is also not a separate layer, it belongs to the special layer ‚ÄúLossFunction‚Äù.  In which is used when choosing a specific type of error calculation; </li><li>  the ‚ÄúLossFunction‚Äù layer is used to automatically calculate the error, those obviously can not use the steps forward / backward (below is an example of working with this layer); </li><li>  there is no ‚ÄúFlatten‚Äù layer, it is not needed because the ‚ÄúFullyConnect‚Äù layer itself pulls the input array; </li><li>  Weights optimizer must be set for each weight layer, by default 'adam' is used for all. </li></ul><br><h3>  Examples </h3><br><h4>  MNIST </h4><br><img src="https://habrastorage.org/webt/ws/2a/q4/ws2aq4ubw8slpu1rvmkzaeagpdq.jpeg" width="600" height="300"><br><br><div class="spoiler">  <b class="spoiler_title">C ++ code looks like this:</b> <div class="spoiler_text"><pre><code class="cpp hljs"><span class="hljs-comment"><span class="hljs-comment">//   sn::Net snet; snet.addNode("Input", sn::Input(), "C1") .addNode("C1", sn::Convolution(15, 0, sn::calcMode::CUDA), "C2") .addNode("C2", sn::Convolution(15, 0, sn::calcMode::CUDA), "P1") .addNode("P1", sn::Pooling(sn::calcMode::CUDA), "FC1") .addNode("FC1", sn::FullyConnected(128, sn::calcMode::CUDA), "FC2") .addNode("FC2", sn::FullyConnected(10, sn::calcMode::CUDA), "LS") .addNode("LS", sn::LossFunction(sn::lossType::softMaxToCrossEntropy), "Output"); ............. // -  //   for (int k = 0; k &lt; 1000; ++k){ targetLayer.clear(); srand(clock()); //   for (int i = 0; i &lt; batchSz; ++i){ ............. } //     float accurat = 0; snet.training(lr, inLayer, outLayer, targetLayer, accurat); }</span></span></code> </pre> <br></div></div><br>  The full code is available <a href="https://github.com/Tyill/skynet/tree/master/example/mnist">here</a> .  Some pictures added to the repository, are next to the example.  I used opencv for reading images, it did not include it in the kit. <br><br>  Another network of the same plan, more difficult. <br><br><img src="https://habrastorage.org/webt/uu/gv/ge/uugvge3bk3zddp_pqas0jpoqy7k.png" width="600" height="300"><br><br><div class="spoiler">  <b class="spoiler_title">The code for creating such a network is:</b> <div class="spoiler_text"><pre> <code class="cpp hljs"> <span class="hljs-comment"><span class="hljs-comment">//   sn::Net snet; snet.addNode("Input", sn::Input(), "C1 C2 C3") .addNode("C1", sn::Convolution(15, 0, sn::calcMode::CUDA), "P1") .addNode("P1", sn::Pooling(sn::calcMode::CUDA), "FC1") .addNode("C2", sn::Convolution(12, 0, sn::calcMode::CUDA), "P2") .addNode("P2", sn::Pooling(sn::calcMode::CUDA), "FC3") .addNode("C3", sn::Convolution(12, 0, sn::calcMode::CUDA), "P3") .addNode("P3", sn::Pooling(sn::calcMode::CUDA), "FC5") .addNode("FC1", sn::FullyConnected(128, sn::calcMode::CUDA), "FC2") .addNode("FC2", sn::FullyConnected(10, sn::calcMode::CUDA), "LS1") .addNode("LS1", sn::LossFunction(sn::lossType::softMaxToCrossEntropy), "Summ") .addNode("FC3", sn::FullyConnected(128, sn::calcMode::CUDA), "FC4") .addNode("FC4", sn::FullyConnected(10, sn::calcMode::CUDA), "LS2") .addNode("LS2", sn::LossFunction(sn::lossType::softMaxToCrossEntropy), "Summ") .addNode("FC5", sn::FullyConnected(128, sn::calcMode::CUDA), "FC6") .addNode("FC6", sn::FullyConnected(10, sn::calcMode::CUDA), "LS3") .addNode("LS3", sn::LossFunction(sn::lossType::softMaxToCrossEntropy), "Summ") .addNode("Summ", sn::Summator(), "Output"); .............</span></span></code> </pre><br></div></div><br>  In the examples it is not, you can copy from here. <br><br><div class="spoiler">  <b class="spoiler_title">In Python, the code also looks</b> <div class="spoiler_text"><pre> <code class="python hljs"> //   snet = snNet.Net() snet.addNode(<span class="hljs-string"><span class="hljs-string">"Input"</span></span>, Input(), <span class="hljs-string"><span class="hljs-string">"C1 C2 C3"</span></span>) \ .addNode(<span class="hljs-string"><span class="hljs-string">"C1"</span></span>, Convolution(<span class="hljs-number"><span class="hljs-number">15</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, calcMode.CUDA), <span class="hljs-string"><span class="hljs-string">"P1"</span></span>) \ .addNode(<span class="hljs-string"><span class="hljs-string">"P1"</span></span>, Pooling(calcMode.CUDA), <span class="hljs-string"><span class="hljs-string">"FC1"</span></span>) \ .addNode(<span class="hljs-string"><span class="hljs-string">"C2"</span></span>, Convolution(<span class="hljs-number"><span class="hljs-number">12</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, calcMode.CUDA), <span class="hljs-string"><span class="hljs-string">"P2"</span></span>) \ .addNode(<span class="hljs-string"><span class="hljs-string">"P2"</span></span>, Pooling(calcMode.CUDA), <span class="hljs-string"><span class="hljs-string">"FC3"</span></span>) \ .addNode(<span class="hljs-string"><span class="hljs-string">"C3"</span></span>, Convolution(<span class="hljs-number"><span class="hljs-number">12</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, calcMode.CUDA), <span class="hljs-string"><span class="hljs-string">"P3"</span></span>) \ .addNode(<span class="hljs-string"><span class="hljs-string">"P3"</span></span>, Pooling(calcMode.CUDA), <span class="hljs-string"><span class="hljs-string">"FC5"</span></span>) \ \ .addNode(<span class="hljs-string"><span class="hljs-string">"FC1"</span></span>, FullyConnected(<span class="hljs-number"><span class="hljs-number">128</span></span>, calcMode.CUDA), <span class="hljs-string"><span class="hljs-string">"FC2"</span></span>) \ .addNode(<span class="hljs-string"><span class="hljs-string">"FC2"</span></span>, FullyConnected(<span class="hljs-number"><span class="hljs-number">10</span></span>, calcMode.CUDA), <span class="hljs-string"><span class="hljs-string">"LS1"</span></span>) \ .addNode(<span class="hljs-string"><span class="hljs-string">"LS1"</span></span>, LossFunction(lossType.softMaxToCrossEntropy), <span class="hljs-string"><span class="hljs-string">"Summ"</span></span>) \ \ .addNode(<span class="hljs-string"><span class="hljs-string">"FC3"</span></span>, FullyConnected(<span class="hljs-number"><span class="hljs-number">128</span></span>, calcMode.CUDA), <span class="hljs-string"><span class="hljs-string">"FC4"</span></span>) \ .addNode(<span class="hljs-string"><span class="hljs-string">"FC4"</span></span>, FullyConnected(<span class="hljs-number"><span class="hljs-number">10</span></span>, calcMode.CUDA), <span class="hljs-string"><span class="hljs-string">"LS2"</span></span>) \ .addNode(<span class="hljs-string"><span class="hljs-string">"LS2"</span></span>, LossFunction(lossType.softMaxToCrossEntropy), <span class="hljs-string"><span class="hljs-string">"Summ"</span></span>) \ \ .addNode(<span class="hljs-string"><span class="hljs-string">"FC5"</span></span>, FullyConnected(<span class="hljs-number"><span class="hljs-number">128</span></span>, calcMode.CUDA), <span class="hljs-string"><span class="hljs-string">"FC6"</span></span>) \ .addNode(<span class="hljs-string"><span class="hljs-string">"FC6"</span></span>, FullyConnected(<span class="hljs-number"><span class="hljs-number">10</span></span>, calcMode.CUDA), <span class="hljs-string"><span class="hljs-string">"LS3"</span></span>) \ .addNode(<span class="hljs-string"><span class="hljs-string">"LS3"</span></span>, LossFunction(lossType.softMaxToCrossEntropy), <span class="hljs-string"><span class="hljs-string">"Summ"</span></span>) \ \ .addNode(<span class="hljs-string"><span class="hljs-string">"Summ"</span></span>, LossFunction(lossType.softMaxToCrossEntropy), <span class="hljs-string"><span class="hljs-string">"Output"</span></span>) .............</code> </pre><br></div></div><br><h4>  CIFAR-10 </h4><br><img src="https://habrastorage.org/webt/nu/aq/pg/nuaqpg1htotp-dd-cnm2dp0b-8o.png" width="600" height="300"><br><br>  Here I had to turn on batchNorm.  This grid learns up to 50% accuracy over 1000 iterations, batch 100. <br><br><div class="spoiler">  <b class="spoiler_title">This code turned out</b> <div class="spoiler_text"><pre> <code class="cpp hljs">sn::Net snet; snet.addNode(<span class="hljs-string"><span class="hljs-string">"Input"</span></span>, sn::Input(), <span class="hljs-string"><span class="hljs-string">"C1"</span></span>) .addNode(<span class="hljs-string"><span class="hljs-string">"C1"</span></span>, sn::Convolution(<span class="hljs-number"><span class="hljs-number">15</span></span>, <span class="hljs-number"><span class="hljs-number">-1</span></span>, sn::calcMode::CUDA, sn::batchNormType::beforeActive), <span class="hljs-string"><span class="hljs-string">"C2"</span></span>) .addNode(<span class="hljs-string"><span class="hljs-string">"C2"</span></span>, sn::Convolution(<span class="hljs-number"><span class="hljs-number">15</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, sn::calcMode::CUDA, sn::batchNormType::beforeActive), <span class="hljs-string"><span class="hljs-string">"P1"</span></span>) .addNode(<span class="hljs-string"><span class="hljs-string">"P1"</span></span>, sn::Pooling(sn::calcMode::CUDA), <span class="hljs-string"><span class="hljs-string">"C3"</span></span>) .addNode(<span class="hljs-string"><span class="hljs-string">"C3"</span></span>, sn::Convolution(<span class="hljs-number"><span class="hljs-number">25</span></span>, <span class="hljs-number"><span class="hljs-number">-1</span></span>, sn::calcMode::CUDA, sn::batchNormType::beforeActive), <span class="hljs-string"><span class="hljs-string">"C4"</span></span>) .addNode(<span class="hljs-string"><span class="hljs-string">"C4"</span></span>, sn::Convolution(<span class="hljs-number"><span class="hljs-number">25</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, sn::calcMode::CUDA, sn::batchNormType::beforeActive), <span class="hljs-string"><span class="hljs-string">"P2"</span></span>) .addNode(<span class="hljs-string"><span class="hljs-string">"P2"</span></span>, sn::Pooling(sn::calcMode::CUDA), <span class="hljs-string"><span class="hljs-string">"C5"</span></span>) .addNode(<span class="hljs-string"><span class="hljs-string">"C5"</span></span>, sn::Convolution(<span class="hljs-number"><span class="hljs-number">40</span></span>, <span class="hljs-number"><span class="hljs-number">-1</span></span>, sn::calcMode::CUDA, sn::batchNormType::beforeActive), <span class="hljs-string"><span class="hljs-string">"C6"</span></span>) .addNode(<span class="hljs-string"><span class="hljs-string">"C6"</span></span>, sn::Convolution(<span class="hljs-number"><span class="hljs-number">40</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, sn::calcMode::CUDA, sn::batchNormType::beforeActive), <span class="hljs-string"><span class="hljs-string">"P3"</span></span>) .addNode(<span class="hljs-string"><span class="hljs-string">"P3"</span></span>, sn::Pooling(sn::calcMode::CUDA), <span class="hljs-string"><span class="hljs-string">"FC1"</span></span>) .addNode(<span class="hljs-string"><span class="hljs-string">"FC1"</span></span>, sn::FullyConnected(<span class="hljs-number"><span class="hljs-number">2048</span></span>, sn::calcMode::CUDA, sn::batchNormType::beforeActive), <span class="hljs-string"><span class="hljs-string">"FC2"</span></span>) .addNode(<span class="hljs-string"><span class="hljs-string">"FC2"</span></span>, sn::FullyConnected(<span class="hljs-number"><span class="hljs-number">128</span></span>, sn::calcMode::CUDA, sn::batchNormType::beforeActive), <span class="hljs-string"><span class="hljs-string">"FC3"</span></span>) .addNode(<span class="hljs-string"><span class="hljs-string">"FC3"</span></span>, sn::FullyConnected(<span class="hljs-number"><span class="hljs-number">10</span></span>, sn::calcMode::CUDA), <span class="hljs-string"><span class="hljs-string">"LS"</span></span>) .addNode(<span class="hljs-string"><span class="hljs-string">"LS"</span></span>, sn::LossFunction(sn::lossType::softMaxToCrossEntropy), <span class="hljs-string"><span class="hljs-string">"Output"</span></span>);</code> </pre><br></div></div><br>  I think it is clear that you can substitute any classes of pictures. <br><p><br></p><p><br></p><h4>  U net tyni </h4><br>  Last example.  Simplified the native U-Net for demonstration. <br><br><img src="https://habrastorage.org/webt/kt/rm/em/ktrmemfgc-vzluhnzarc4i9wamu.png"><br><br>  I'll explain a little bit: DC1 layers ... - reverse convolution, Concat1 layers ... - layers of addition of channels, <br>  Rsz1 ... - are used to match the number of channels at the reverse step, because an error on the sum of the channels comes back from the Concat layer. <br><br><div class="spoiler">  <b class="spoiler_title">C ++ code.</b> <div class="spoiler_text"><pre> <code class="cpp hljs"> sn::Net snet; snet.addNode(<span class="hljs-string"><span class="hljs-string">"In"</span></span>, sn::Input(), <span class="hljs-string"><span class="hljs-string">"C1"</span></span>) .addNode(<span class="hljs-string"><span class="hljs-string">"C1"</span></span>, sn::Convolution(<span class="hljs-number"><span class="hljs-number">10</span></span>, <span class="hljs-number"><span class="hljs-number">-1</span></span>, sn::calcMode::CUDA), <span class="hljs-string"><span class="hljs-string">"C2"</span></span>) .addNode(<span class="hljs-string"><span class="hljs-string">"C2"</span></span>, sn::Convolution(<span class="hljs-number"><span class="hljs-number">10</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, sn::calcMode::CUDA), <span class="hljs-string"><span class="hljs-string">"P1 Crop1"</span></span>) .addNode(<span class="hljs-string"><span class="hljs-string">"Crop1"</span></span>, sn::Crop(sn::rect(<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">487</span></span>, <span class="hljs-number"><span class="hljs-number">487</span></span>)), <span class="hljs-string"><span class="hljs-string">"Rsz1"</span></span>) .addNode(<span class="hljs-string"><span class="hljs-string">"Rsz1"</span></span>, sn::Resize(sn::diap(<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>), sn::diap(<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>)), <span class="hljs-string"><span class="hljs-string">"Conc1"</span></span>) .addNode(<span class="hljs-string"><span class="hljs-string">"P1"</span></span>, sn::Pooling(sn::calcMode::CUDA), <span class="hljs-string"><span class="hljs-string">"C3"</span></span>) .addNode(<span class="hljs-string"><span class="hljs-string">"C3"</span></span>, sn::Convolution(<span class="hljs-number"><span class="hljs-number">10</span></span>, <span class="hljs-number"><span class="hljs-number">-1</span></span>, sn::calcMode::CUDA), <span class="hljs-string"><span class="hljs-string">"C4"</span></span>) .addNode(<span class="hljs-string"><span class="hljs-string">"C4"</span></span>, sn::Convolution(<span class="hljs-number"><span class="hljs-number">10</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, sn::calcMode::CUDA), <span class="hljs-string"><span class="hljs-string">"P2 Crop2"</span></span>) .addNode(<span class="hljs-string"><span class="hljs-string">"Crop2"</span></span>, sn::Crop(sn::rect(<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">247</span></span>, <span class="hljs-number"><span class="hljs-number">247</span></span>)), <span class="hljs-string"><span class="hljs-string">"Rsz2"</span></span>) .addNode(<span class="hljs-string"><span class="hljs-string">"Rsz2"</span></span>, sn::Resize(sn::diap(<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>), sn::diap(<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>)), <span class="hljs-string"><span class="hljs-string">"Conc2"</span></span>) .addNode(<span class="hljs-string"><span class="hljs-string">"P2"</span></span>, sn::Pooling(sn::calcMode::CUDA), <span class="hljs-string"><span class="hljs-string">"C5"</span></span>) .addNode(<span class="hljs-string"><span class="hljs-string">"C5"</span></span>, sn::Convolution(<span class="hljs-number"><span class="hljs-number">10</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, sn::calcMode::CUDA), <span class="hljs-string"><span class="hljs-string">"C6"</span></span>) .addNode(<span class="hljs-string"><span class="hljs-string">"C6"</span></span>, sn::Convolution(<span class="hljs-number"><span class="hljs-number">10</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, sn::calcMode::CUDA), <span class="hljs-string"><span class="hljs-string">"DC1"</span></span>) .addNode(<span class="hljs-string"><span class="hljs-string">"DC1"</span></span>, sn::Deconvolution(<span class="hljs-number"><span class="hljs-number">10</span></span>, sn::calcMode::CUDA), <span class="hljs-string"><span class="hljs-string">"Rsz3"</span></span>) .addNode(<span class="hljs-string"><span class="hljs-string">"Rsz3"</span></span>, sn::Resize(sn::diap(<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>), sn::diap(<span class="hljs-number"><span class="hljs-number">10</span></span>, <span class="hljs-number"><span class="hljs-number">20</span></span>)), <span class="hljs-string"><span class="hljs-string">"Conc2"</span></span>) .addNode(<span class="hljs-string"><span class="hljs-string">"Conc2"</span></span>, sn::Concat(<span class="hljs-string"><span class="hljs-string">"Rsz2 Rsz3"</span></span>), <span class="hljs-string"><span class="hljs-string">"C7"</span></span>) .addNode(<span class="hljs-string"><span class="hljs-string">"C7"</span></span>, sn::Convolution(<span class="hljs-number"><span class="hljs-number">10</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, sn::calcMode::CUDA), <span class="hljs-string"><span class="hljs-string">"C8"</span></span>) .addNode(<span class="hljs-string"><span class="hljs-string">"C8"</span></span>, sn::Convolution(<span class="hljs-number"><span class="hljs-number">10</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, sn::calcMode::CUDA), <span class="hljs-string"><span class="hljs-string">"DC2"</span></span>) .addNode(<span class="hljs-string"><span class="hljs-string">"DC2"</span></span>, sn::Deconvolution(<span class="hljs-number"><span class="hljs-number">10</span></span>, sn::calcMode::CUDA), <span class="hljs-string"><span class="hljs-string">"Rsz4"</span></span>) .addNode(<span class="hljs-string"><span class="hljs-string">"Rsz4"</span></span>, sn::Resize(sn::diap(<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>), sn::diap(<span class="hljs-number"><span class="hljs-number">10</span></span>, <span class="hljs-number"><span class="hljs-number">20</span></span>)), <span class="hljs-string"><span class="hljs-string">"Conc1"</span></span>) .addNode(<span class="hljs-string"><span class="hljs-string">"Conc1"</span></span>, sn::Concat(<span class="hljs-string"><span class="hljs-string">"Rsz1 Rsz4"</span></span>), <span class="hljs-string"><span class="hljs-string">"C9"</span></span>) .addNode(<span class="hljs-string"><span class="hljs-string">"C9"</span></span>, sn::Convolution(<span class="hljs-number"><span class="hljs-number">10</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, sn::calcMode::CUDA), <span class="hljs-string"><span class="hljs-string">"C10"</span></span>); sn::<span class="hljs-function"><span class="hljs-function">Convolution </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">convOut</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">1</span></span></span></span><span class="hljs-function"><span class="hljs-params">, </span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0</span></span></span></span><span class="hljs-function"><span class="hljs-params">, sn::calcMode::CUDA)</span></span></span></span>; convOut.act = sn::active::sigmoid; snet.addNode(<span class="hljs-string"><span class="hljs-string">"C10"</span></span>, convOut, <span class="hljs-string"><span class="hljs-string">"Output"</span></span>);</code> </pre><br></div></div><br>  Full code and images are <a href="https://github.com/Tyill/skynet/tree/master/example/unet">here</a> . <br><br><p><br>  Open source math like <a href="http://cs231n.github.io/">this</a> . <br>  All layers tested on MNIST, TF served as a benchmark for error estimation. <br><br></p><p><br>  <b>What's next</b> <br><br>  The library will not grow in width, that is, no opencv, sockets and so on, so as not to inflate. <br>  The library interface will not be changed / expanded, I will not say that in general and never, but last. <br><br>  Only in depth: I will do the calculation on OpenCL, the interface for C #, the RNN network can be ... <br>  I think it makes no sense to add MKL, because the network is a bit deeper - it's still faster on a video card, and the average performance map is not a deficit at all. <br><br>  Import / export of scales with other frameworks - via Python (not yet implemented).  Roadmap will be if interest arises from people. <br><br>  Who can support the code, please.  But there are <a href="">limitations</a> to not break the current architecture. <br><br>  The interface for a python can be expanded to impossibility, also docks and examples are necessary. <br><br>  To install from Python: <br><br>  * pip install libskynet - CPU <br>  * pip install libskynet-cu - CPU + CUDA9.2 <br>  * pip install libskynet-cudnn - CPU + cuDNN7.3.1 <br><br>  If your network is not deep, use the CPU + CUDA implementation; memory consumption is orders of magnitude smaller compared to cuDNN. <br><br>  <a href="https://github.com/Tyill/skynet/wiki">Wiki</a> user guide <br><br>  <a href="https://github.com/Tyill/skynet">Software is distributed freely, MIT license.</a> <br><br>  Thank. </p></div><p>Source: <a href="https://habr.com/ru/post/425717/">https://habr.com/ru/post/425717/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../425707/index.html">Notification system from the console to Telegram</a></li>
<li><a href="../425709/index.html">We made a memo for the Chinese who came to you</a></li>
<li><a href="../425711/index.html">Losses in mismatched line</a></li>
<li><a href="../425713/index.html">Integration of HTML engine in native Windows application - choice and architecture</a></li>
<li><a href="../425715/index.html">Educational program in chemistry: acid reversing of microcircuits (how to expose a crystal of a microcircuit for its subsequent photographing)</a></li>
<li><a href="../425719/index.html">Celery in busy projects: some practice</a></li>
<li><a href="../425723/index.html">Facebook is actively developing a service for finding work and hiring employees in a social network.</a></li>
<li><a href="../425725/index.html">Nintendo patents case - Game Boy</a></li>
<li><a href="../425727/index.html">To new meetings</a></li>
<li><a href="../425729/index.html">Hackathon Pro Welcome: how was the first charity SmartMail Hack</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>