<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>INS-based interlocutor: recurrent networks</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Earlier in the article ‚ÄúNegotiating a neuro-based interlocutor‚Äù I considered the use of direct-distribution neural networks for creating an interlocut...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>INS-based interlocutor: recurrent networks</h1><div class="post__text post__text-html js-mediator-article">  Earlier in the article <a href="https://habrahabr.ru/post/321996/">‚ÄúNegotiating a neuro-based interlocutor‚Äù</a> I considered the use of direct-distribution neural networks for creating an interlocutor-robot.  As a result of the experiments, it became clear that using such networks for generating texts is a bad idea.  Thanks <a href="https://habrahabr.ru/users/roman_kh/" class="user_link">Roman_Kh</a> , <a href="https://habrahabr.ru/users/daiver19/" class="user_link">daiver19</a> , <a href="https://habrahabr.ru/users/vladshow/" class="user_link">vladshow</a> , that showed how to change the network and in which direction to move. <br><br>  The next stage of testing is recurrent LSTM networks. <br><a name="habracut"></a><br>  As before, in the latest experiments with networks of direct distribution, the dictionary is created with the Word2Vec tool with a uniform distribution of words in the vector space.  Each word is represented by a length vector <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-1-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>D</mi><mo>=</mo><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo>$</mo></mrow><mn>5</mn></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="7.348ex" height="2.298ex" viewBox="0 -832 3163.6 989.6" role="img" focusable="false" style="vertical-align: -0.366ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/323788/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjPlDzi1Nt2es4Nqw1LQlKc-GTOiQ#MJMATHI-44" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/323788/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjPlDzi1Nt2es4Nqw1LQlKc-GTOiQ#MJMAIN-3D" x="1106" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/323788/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjPlDzi1Nt2es4Nqw1LQlKc-GTOiQ#MJMAIN-24" x="2162" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/323788/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjPlDzi1Nt2es4Nqw1LQlKc-GTOiQ#MJMAIN-35" x="2663" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>D</mi><mo>=</mo><mrow class="MJX-TeXAtom-ORD"><mo>$</mo></mrow><mn>5</mn></math></span></span><script type="math/tex" id="MathJax-Element-1"> D = $ 5</script>  . <br><br><h2>  Preparation for sequence generation </h2><br><h3>  Offer Coding </h3><br>  Recurrent networks can generate sequences, so the appropriate encoding method is applicable.  We will ask the network for a suggestion-question to word-by-word to generate an offer-response. <br>  In text form, the training base is stored as a set of ‚ÄúQuestion = Answer‚Äù sentences, for example: 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <pre> 1 HELLO = HELLO (2 words)
 2 LON'T SEE DON'T SEE = HELLO FRIEND (5 words)
 3 GOOD DAY = EXCELLENT DAY (4 words)
 4 WHAT DAY IS TODAY = TODAY IS A GREAT DAY (6 words)
 5 LET'S FRIEND = LET'S BE FRIENDS (5 words)
 6 BE YOUR FRIEND = WELL WHEN MANY FRIENDS (7 words)
 7 SEEING = SEEING (4 words)
</pre><br>  The following service tags are used to control the generation of sequences, which are encoded with Word2Vec along with other words: <br><br><ul><li>  # GEN # - the end of the sentence-question, you can begin to generate an answer; </li><li>  # BOS # - start generating response; </li><li>  # EOS # - stop generating response. </li></ul><br>  For training the neural network, two matrices TrainX and TrainY are formed as follows.  Each matrix has a size <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-2-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>N</mi><mtext>&amp;#xA0;</mtext><mi>t</mi><mi>i</mi><mi>m</mi><mi>e</mi><mi>s</mi><mi>T</mi><mtext>&amp;#xA0;</mtext><mi>t</mi><mi>i</mi><mi>m</mi><mi>e</mi><mi>s</mi><mi>D</mi></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="18.498ex" height="2.057ex" viewBox="0 -780.1 7964.5 885.9" role="img" focusable="false" style="vertical-align: -0.246ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/323788/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjPlDzi1Nt2es4Nqw1LQlKc-GTOiQ#MJMATHI-4E" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/323788/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjPlDzi1Nt2es4Nqw1LQlKc-GTOiQ#MJMATHI-74" x="1138" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/323788/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjPlDzi1Nt2es4Nqw1LQlKc-GTOiQ#MJMATHI-69" x="1500" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/323788/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjPlDzi1Nt2es4Nqw1LQlKc-GTOiQ#MJMATHI-6D" x="1845" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/323788/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjPlDzi1Nt2es4Nqw1LQlKc-GTOiQ#MJMATHI-65" x="2724" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/323788/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjPlDzi1Nt2es4Nqw1LQlKc-GTOiQ#MJMATHI-73" x="3190" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/323788/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjPlDzi1Nt2es4Nqw1LQlKc-GTOiQ#MJMATHI-54" x="3660" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/323788/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjPlDzi1Nt2es4Nqw1LQlKc-GTOiQ#MJMATHI-74" x="4614" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/323788/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjPlDzi1Nt2es4Nqw1LQlKc-GTOiQ#MJMATHI-69" x="4976" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/323788/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjPlDzi1Nt2es4Nqw1LQlKc-GTOiQ#MJMATHI-6D" x="5321" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/323788/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjPlDzi1Nt2es4Nqw1LQlKc-GTOiQ#MJMATHI-65" x="6200" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/323788/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjPlDzi1Nt2es4Nqw1LQlKc-GTOiQ#MJMATHI-73" x="6666" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/323788/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjPlDzi1Nt2es4Nqw1LQlKc-GTOiQ#MJMATHI-44" x="7136" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>N</mi><mtext>&nbsp;</mtext><mi>t</mi><mi>i</mi><mi>m</mi><mi>e</mi><mi>s</mi><mi>T</mi><mtext>&nbsp;</mtext><mi>t</mi><mi>i</mi><mi>m</mi><mi>e</mi><mi>s</mi><mi>D</mi></math></span></span><script type="math/tex" id="MathJax-Element-2"> N \ times T \ times D </script>  where <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-3-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>N</mi></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.064ex" height="2.057ex" viewBox="0 -780.1 888.5 885.9" role="img" focusable="false" style="vertical-align: -0.246ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/323788/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjPlDzi1Nt2es4Nqw1LQlKc-GTOiQ#MJMATHI-4E" x="0" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>N</mi></math></span></span><script type="math/tex" id="MathJax-Element-3"> N </script>  - the number of sentences in the database ( <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-4-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>N</mi><mo>=</mo><mn>7</mn></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="6.325ex" height="2.057ex" viewBox="0 -780.1 2723.1 885.9" role="img" focusable="false" style="vertical-align: -0.246ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/323788/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjPlDzi1Nt2es4Nqw1LQlKc-GTOiQ#MJMATHI-4E" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/323788/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjPlDzi1Nt2es4Nqw1LQlKc-GTOiQ#MJMAIN-3D" x="1166" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/323788/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjPlDzi1Nt2es4Nqw1LQlKc-GTOiQ#MJMAIN-37" x="2222" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>N</mi><mo>=</mo><mn>7</mn></math></span></span><script type="math/tex" id="MathJax-Element-4"> N = 7 </script>  in this example); <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-5-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>T</mi></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.636ex" height="2.057ex" viewBox="0 -780.1 704.5 885.9" role="img" focusable="false" style="vertical-align: -0.246ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/323788/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjPlDzi1Nt2es4Nqw1LQlKc-GTOiQ#MJMATHI-54" x="0" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>T</mi></math></span></span><script type="math/tex" id="MathJax-Element-5"> T </script>  - the largest number of words in the sentence + 3 (for # GEN #, # BOS #, # EOS #), in this example <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-6-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>T</mi><mo>=</mo><mn>7</mn><mo>+</mo><mn>3</mn><mo>=</mo><mn>10</mn></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="15.323ex" height="2.178ex" viewBox="0 -780.1 6597.6 937.7" role="img" focusable="false" style="vertical-align: -0.366ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/323788/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjPlDzi1Nt2es4Nqw1LQlKc-GTOiQ#MJMATHI-54" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/323788/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjPlDzi1Nt2es4Nqw1LQlKc-GTOiQ#MJMAIN-3D" x="982" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/323788/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjPlDzi1Nt2es4Nqw1LQlKc-GTOiQ#MJMAIN-37" x="2038" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/323788/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjPlDzi1Nt2es4Nqw1LQlKc-GTOiQ#MJMAIN-2B" x="2761" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/323788/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjPlDzi1Nt2es4Nqw1LQlKc-GTOiQ#MJMAIN-33" x="3762" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/323788/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjPlDzi1Nt2es4Nqw1LQlKc-GTOiQ#MJMAIN-3D" x="4540" y="0"></use><g transform="translate(5596,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/323788/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjPlDzi1Nt2es4Nqw1LQlKc-GTOiQ#MJMAIN-31"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/323788/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjPlDzi1Nt2es4Nqw1LQlKc-GTOiQ#MJMAIN-30" x="500" y="0"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>T</mi><mo>=</mo><mn>7</mn><mo>+</mo><mn>3</mn><mo>=</mo><mn>10</mn></math></span></span><script type="math/tex" id="MathJax-Element-6"> T = 7 + 3 = 10 </script>  ; <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-7-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>D</mi></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.924ex" height="2.057ex" viewBox="0 -780.1 828.5 885.9" role="img" focusable="false" style="vertical-align: -0.246ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/323788/&amp;xid=17259,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjPlDzi1Nt2es4Nqw1LQlKc-GTOiQ#MJMATHI-44" x="0" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>D</mi></math></span></span><script type="math/tex" id="MathJax-Element-7"> D </script>  - the length of the word vector (50). <br><br>  All sequences are reduced to the longest in the number of words.  In this example, the longest is the sequence number 6, then all sentences are supplemented to seven words, the empty places at the end are filled with # EOS #: <br><br><pre>		 t = 0 t = 1 t = 2 t = 3 t = 4 t = 5 t = 6 t = 7 t = 8 t = 9				
 TrainX [0] [t] = HELLO # GEN # # BOS # HELLO # EOS # # EOS # # EOS # # EOS # # EOS # # EOS #
 TrainY [0] [t] = NULL # BOS # HELLO # EOS # # EOS # # EOS # # EOS # # EOS # # EOS # # EOS #

		 t = 0 t = 1 t = 2 t = 3 t = 4 t = 5 t = 6 t = 7 t = 8 t = 9 t = 10
 TrainX [1] [t] = FOR A LONG TIME DID NOT SEE # BOS # HELLO EACH OTHER # EOS # # EOS # # EOS # # EOS # # EOS #
 TrainY [1] [t] = NULL NULL NULL HELLO FRIEND # EOS # # EOS # # EOS # # EOS # # EOS # # EOS #
</pre><br>  <b>NULL</b> - the network response does not matter, when encoding words is filled with zeros. <br><br><h3>  Network response generation </h3><br>  After learning to input the neural network, all words of the question and the tag # GEN # are given word by word.  After that, we ask the network to predict the next word on the previously transmitted previous one, until the # EOS # tag is encountered.  Eliminating service tags from the response, we get the answer. <br><br><h2>  Architecture testing </h2><br><p>  Now for experiments I use the Python language and the Keras library. </p><br><h3>  Option 1. Single LSTM cell, 65,450 parameters </h3><br>  The experiment involved: <br><br><ul><li>  Layer 1: LSTM with D neurons at the input and 2D at the output; </li><li>  Layer 2: Direct propagation layer with D neurons. </li></ul><br>  After learning and memorizing 109 sentences, you can get these answers. <br><br><pre> - HELLO
 - HELLO

 - WHAT IS YOUR NAME?
 - ME NAME IS NETWORK

 - HELLO NET
 - HELLO

 - HELLO, YOU ME KNOW?
 - I AM JUST LEARNING

 - DO YOU CALL OLEG?
 - NICE TO MEET YOU

 - DO YOU CALL THE NET?
 - ME NAME IS NETWORK

 - YOU ARE NICE?
 - I THINK YOU

 - YOU ANYTHING LIKE?
 - I LIKE TO LISTEN

 - WANT TO TALK?
 - I WILL BE RADA OF INTERESTING TALK

 - ABOUT WHAT?
 - LET'S TALK ABOUT
</pre><br><br><h3>  Option 2. Two cells LSTM, 93 150 parameters </h3><br>  The experiment involved: <br><br><ul><li>  Layer 1: LSTM with D neurons at the input and 2D at the output; </li><li>  Layer 2: LSTM with 2D neurons at the input and D at the output; </li></ul><br>  Ask the same questions: <br><br><pre> - HELLO
 - HELLO

 - WHAT IS YOUR NAME?
 - ME NAME IS NETWORK

 - HELLO, NETWORK
 - THIS IS A FRIEND

 - HELLO, YOU ME KNOW?
 - I AM JUST LEARNING

 - DO YOU CALL OLEG?
 - MY NAME IS

 - DO YOU CALL THE NET?
 - ME NAME IS NETWORK

 - YOU ARE NICE?
 - I THINK LEARN

 - YOU ANYTHING LIKE?
 - I LIKE TO LISTEN TO MUSIC

 - WANT TO TALK?
 - I WILL BE RADA OF INTERESTING TALK

 - ABOUT WHAT?
 - LET'S TALK ABOUT
</pre><br><br><h3>  Option 3. Three cells LSTM, 63 150 parameters </h3><br>  The experiment involved: <br><br><ul><li>  Layer 1: LSTM with D neurons at the input and D at the output; </li><li>  Layer 2: LSTM with D neurons at the input and D at the output; </li><li>  Layer 3: LSTM with D neurons at the input and D at the output. </li></ul><br>  And such a dialogue: <br><pre> - Hello
 - HELLO

 - WHAT IS YOUR NAME?
 - ME NAME IS NETWORK

 - HELLO, NETWORK
 - THIS IS FOR YOU

 - HELLO, YOU ME KNOW?
 - I AM JUST LEARNING

 - DO YOU CALL OLEG?
 - ME TO MEET

 - DO YOU CALL THE NET?
 - ME NAME IS NETWORK

 - YOU ARE NICE?
 - I THINK IN

 - YOU ANYTHING LIKE?
 - I LIKE TO LISTEN TO MUSIC

 - WANT TO TALK?
 - I WILL BE RADA OF INTERESTING TALK

 - ABOUT WHAT?
 - LET'S BE FRIENDS
</pre><br><h2>  Total </h2><br>  For testing, specially selected questions that are not in the training database (except the first), to check the "rationality" of the constructed models.  It seemed to me that recurrent networks work much better, they are not strongly affected by the absence of some words in a question or the order of words in a sentence (the answer to ‚ÄúWhat is your name?‚Äù, ‚ÄúWhat is your name?‚Äù Is the same).  Of course, this result is still far from ‚Äúgood‚Äù. <br><p>  Interestingly, the first model of the three most adequately responds to the greeting, it does not knock down your own name in the sentence.  However, she still does not exactly know her name.  The second model, on the contrary, to the greeting, different from the student, responds as awfully as you like.  But, unlike the first model, she tried to answer the question about her name correctly (‚ÄúIs your name Oleg?‚Äù - ‚ÄúMy name is‚Äù).  Although this implementation does not presuppose memorization of the context of the dialogue and previous answers, the choice of the topic of conversation in the first two models looks more adequate. <br><br>  <b>Conclusion:</b> Of the entire test base, the first models respond adequately to one part of the questions, wonderfully failing the test for the rest.  Other models answer the second part of the questions and do not brilliantly cope with the first.  It is a pity that you can not create a set of neural networks that would be able to answer all the questions of the test set correctly ... <br><br>  Therefore, the further task is to study the influence of types and the number of layers of an ANN on the quality of its answers with constant training and test sets in order to construct such a model of a neural network that passes my test. </p></div><p>Source: <a href="https://habr.com/ru/post/323788/">https://habr.com/ru/post/323788/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../323776/index.html">Functional safety, part 6 of 7. Evaluation of indicators of functional safety and reliability</a></li>
<li><a href="../323778/index.html">[NeoQuest2017] ‚ÄúIn Search of Earthlings‚Äù and not only ...</a></li>
<li><a href="../323780/index.html">How programs are designed: from UML to automata</a></li>
<li><a href="../323784/index.html">Magento U has published a free course Fundamentals of Magento 2 Development</a></li>
<li><a href="../323786/index.html">Excursion to the Moscow production of components for communication networks. Part one</a></li>
<li><a href="../323790/index.html">Asynchronous vs delayed javascript</a></li>
<li><a href="../323792/index.html">Why play getKanban: experience Tutu.ru</a></li>
<li><a href="../323794/index.html">GUID-like primary keys in SQLite on Android</a></li>
<li><a href="../323796/index.html">Overview of data bootcamps abroad</a></li>
<li><a href="../323798/index.html">HR-technologies in Russia: expectation and reality</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>