<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>How HPE SimpliVity 380 for VDI will work: hard load tests</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="The customer wanted VDI. I was looking very much at a bunch of SimpliVity + VDI Citrix Virtual Desktop. For all operators, office staff in cities and ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>How HPE SimpliVity 380 for VDI will work: hard load tests</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/webt/_c/-f/ze/_c-fze90jo2wiz1tnxiharmlfde.jpeg" alt="image"><br><br>  The customer wanted VDI.  I was looking very much at a bunch of SimpliVity + VDI Citrix Virtual Desktop.  For all operators, office staff in cities and so on.  There are five thousand users only in the first wave of migration, and therefore they insisted on load testing.  VDI can start to slow down, it can safely lie down - and this does not always happen due to problems with the channel.  We bought a very powerful testing package specifically for VDI and loaded the infrastructure until it went to disk and processor. <br><br>  So, we need a plastic bottle, LoginVSI software for advanced VDI tests.  We have it with licenses for 300 users.  Then they took HPE SimpliVity 380 hardware in a package that is suitable for the task of maximal user density per server, cut virtual machines with a good oversubscription, put on them office software on Win10 and started testing. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      <b>Go!</b> <a name="habracut"></a><br><br><h2>  System </h2><br>  Two nodes (servers) HPE SimpliVity 380 Gen10.  On each: <br><br><ul><li>  2 x Intel Xeon Platinum 8170 26c 2.1Ghz. </li><li>  RAM: 768GB, 12 x 64GB LRDIMMs DDR4 2666MHz. </li><li>  Main disk controller: HPE Smart Array P816i-a SR Gen10. </li><li>  Hard drives: 9 x 1.92 TB SATA 6Gb / s SSD (in the configuration RAID6 7 + 2, that is, this is the Medium model in terms of HPE SimpliVity). </li><li>  Network cards: 4 x 1Gb Eth (user data), 2 x 10Gb Eth (SimpliVity and vMotion backend). </li><li>  Special embedded FPGA cards in each node for deduplication / compression. </li></ul><br>  The nodes are interconnected by interconnect 10Gb Ethernet directly without an external switch, which is used as a SimpliVity backend and for transferring virtual machine data over NFS.  Virtual machine data in a cluster is always mirrored between two nodes. <br><br>  Nodes are clustered in a Vmware vSphere cluster running vCenter. <br><br>  For testing, deployed a domain controller and Citrix connection broker.  The domain controller, broker and vCenter are placed on a separate cluster. <br><img src="https://habrastorage.org/webt/iy/2f/cm/iy2fcmya1kwnjrngq2hsdg-0dcs.png" alt="image"><br><img src="https://habrastorage.org/webt/_w/wm/uw/_wwmuwksqxifn3xvsjqxqg8mbj0.png" alt="image"><br>  As a test infrastructure, 300 virtual desktops are deployed in a Dedicated - Full Copy configuration, that is, each desktop is a complete copy of the original virtual machine image and saves all changes made by users. <br><br>  Each virtual machine has 2vCPU and 4GB RAM: <br><br><img src="https://habrastorage.org/webt/6s/un/ru/6sunrupu_e3qtrv0ozkzjhdz1ti.png" alt="image"><br><br><img src="https://habrastorage.org/webt/3z/tp/cg/3ztpcgbgkwhbjqiypygrcvq7t9o.png" alt="image"><br><br>  The following software required for testing was installed on the virtual machines: <br><br><ul><li>  Windows 10 (64-bit), version 1809. </li><li>  Adobe Reader XI. </li><li>  Citrix Virtual Delivery Agent 1811.1. </li><li>  Doro PDF 1.82. </li><li>  Java 7 Update 13. </li><li>  Microsoft Office Professional Plus 2016. </li></ul><br>  Between nodes - synchronous replication.  Each data block in a cluster has two copies.  That is, now a complete set of data on each of the nodes.  With a cluster of three or more nodes - copies of the blocks in two different places.  When creating a new VM, an additional copy is created on one of the cluster nodes.  When a single node fails, all VMs previously running on it are automatically restarted on other nodes, where they have replicas.  If the node fails for a long time, then a gradual restoration of redundancy begins, and the cluster returns to the N + 1 reservation again. <br><br>  Balancing and data storage occurs at the level of software storage of SimpliVity itself. <br><br>  Virtual machines run a virtualization cluster, it also locates them in the software storage.  The desktops themselves were taken according to a standard pattern: the tables of financiers and tellers stopped at the test (these are two different templates). <br><br><h3>  Testing </h3><br>  For testing, the LoginVSI 4.1 test software was used.  The LoginVSI complex consisting of the management server and 12 machines for test connections were deployed on a separate physical host. <br><img src="https://habrastorage.org/webt/a9/tg/a8/a9tga8ijvirliv42fkcqld9yvma.png" alt="image"><br><br>  Testing was conducted in three modes: <br><br>  Benchmark mode - load options for 300 Knowledge workers and 300 Storage workers. <br><br>  Standard mode is a variant of the load of 300 Power workers. <br><br>  To enable Power workers to work and increase the load diversity, a library of additional Power Library files was added to the LoginVSI complex.  To ensure repeatability of results, all test bench settings were left Default. <br><br>  Knowledge and Power workers tests imitate the real workload of users working on virtual workstations. <br><br>  The Storage workers test is designed specifically for testing storage systems, is far from real workloads and for the most part consists of a user working with a large number of files of different sizes. <br><br>  In the process of testing, users log into workstations within 48 minutes for approximately one user every 10 seconds. <br><br><h2>  results </h2><br>  The main result of the LoginVSI test is the VSImax metric, which is composed of the execution time of various tasks that are started by the user.  For example: file opening time in notepad, file compression time in 7-Zip, etc. <br><br>  A detailed description of the calculation of metrics is available in the official documentation at the <a href="https://www.loginvsi.com/documentation/index.php%3Ftitle%3DLogin_VSI_VSImax">link</a> . <br><br>  In other words, LoginVSI repeats a typical load pattern, simulating user actions in an office suite, reading a PDF, and so on, and measures various delays.  There is a critical level of delays "everything slows down, it is impossible to work"), before reaching which it is considered that the maximum of users is not dialed.  If the response time by 1,000 ms is faster than this ‚Äúeverything slows down‚Äù state, then it is considered that the system is working properly and you can add more users. <br><br>  Here are the main metrics: <br><table><tbody><tr><td width="78"><p>  <b>Metrics</b> </p><br></td><td width="191"><p>  <b>Produced actions</b> </p><br></td><td width="301"><p>  <b>Detailed</b> <b>description</b> </p><br></td><td width="142"><p>  <b>Loadable components</b> </p><br></td></tr><tr><td width="78"><p>  <b>NSLD</b> </p><br></td><td width="191"><p>  Text opening time <br>  a file weighing 1,500 KB </p><br></td><td width="301"><p>  Starts the notebook and <br>  opens a random document weighing 1,500 KB that is copied from the pool <br>  resources </p><br></td><td width="142"><p>  CPU and I / O </p><br></td></tr><tr><td width="78"><p>  <b>Nfo</b> </p><br></td><td width="191"><p>  Opening time dialog <br>  windows in a notebook </p><br></td><td width="301"><p>  Opening the file VSI-Notepad [Ctrl + O] </p><br></td><td width="142"><p>  CPU, RAM and I / O </p><br><p></p><br></td></tr><tr><td width="78"><p>  <b>ZHC *</b> </p><br></td><td width="191"><p>  Time to create a zip file with strong compression </p><br></td><td width="301"><p>  Local compression <br>  a random 5MB .pst file that is copied from <br>  resource pool </p><br></td><td width="142"><p>  CPU and I / O </p><br></td></tr><tr><td width="78"><p>  <b>ZLC *</b> </p><br></td><td width="191"><p>  Time to create a zip file with weak compression </p><br></td><td width="301"><p>  Local compression <br>  a random 5MB .pst file that is copied from <br>  resource pool </p><br></td><td width="142"><p>  I / o </p><br><p></p><br></td></tr><tr><td width="78"><p>  <b>CPU</b> </p><br></td><td width="191"><p>  Calculating big <br>  array of random data </p><br></td><td width="301"><p>  Creating a large array <br>  random data that will be used in the I / O timer (I / O timer) </p><br></td><td width="142"><p>  CPU </p><br></td></tr></tbody></table><br>  When testing is performed, the VSIbase base metric is initially calculated, which shows the speed at which tasks are completed without the system load.  Based on this, the VSImax Threshold is determined, which is equal to VSIbase + 1,000ms. <br><br>  Conclusions about system performance are made on the basis of two metrics: VSIbase, which determines the speed of the system, and VSImax threshold, which determines the maximum number of users that the system can withstand without significant degradation. <br><br><h3>  300 Knowledge workers benchmark </h3><br>  Knowledge workers are users who regularly load memory, processor, and IO with various small peaks.  The software emulates the load from demanding office users, as if they are constantly poking at something (PDF, Java, office suite, photo viewing, 7-Zip).  As users are added from zero to 300, the delay for each increases smoothly. <br><br>  VSImax statistics data: <br><img src="https://habrastorage.org/webt/yr/pg/u-/yrpgu-lqswmvwsxousflbpiid0e.png" alt="image"><br>  VSIbase = 986ms, VSI Threshold was not reached. <br><br>  Statistics of the load on the storage system from monitoring SimpliVity: <br><img src="https://habrastorage.org/webt/hi/ki/x4/hikix4jqp5ujbqkeff-taxzp_z0.png" alt="image"><br><br>  With this type of load, the system can withstand the increase in load almost without degradation of performance.  The execution time of user tasks grows smoothly, the system response time does not change during testing and is up to 3 ms for writing and up to 1 ms for reading. <br><br>  <b>Conclusion:</b> 300 knowledge users work without any problems on the current cluster and do not interfere with each other, reaching pCPU / vCPU 1 to 6 oversubscription. The total delays with the load increase evenly, but the conditioned limit was not reached. <br><br><h3>  300 Storage workers benchmark </h3><br>  These are users who constantly write and read in the proportion of 30 to 70, respectively.  This test was conducted rather for the sake of experiment.  VSImax statistics data: <br><img src="https://habrastorage.org/webt/ib/2h/ga/ib2hgacipsoa5r2w2qk-giyd_74.png" alt="image"><br><br>  VSIbase = 1673, VSI Threshold reached on 240 users. <br><br>  Statistics of the load on the storage system from monitoring SimpliVity: <br><img src="https://habrastorage.org/webt/h3/5e/dl/h35edlal4qoqlm50xovdrm0skjm.png" alt="image"><br>  This type of load is essentially a stress test of the storage system.  When it is executed, each user writes to the disk a lot of random files of different sizes.  In this case, it can be seen that if a certain load threshold is exceeded for a part of users, the time taken to write files increases.  At the same time, the load on the storage system, the processor and the memory of the hosts does not change significantly, so it‚Äôs impossible to determine exactly what is causing the delays. <br><br>  Conclusions about system performance using this test can only be made in comparison with the test results on other systems, since such loads are synthetic and unrealistic.  However, in general, the test went well.  Up to 210 sessions, everything went well, and then incomprehensible responses began, which were not monitored anywhere except Login VSI. <br><br><h3>  300 power workers </h3><br>  These are users who love processor, memory and high IO.  These "advanced users" regularly run complex tasks with long peaks, such as installing new software and unpacking large archives.  VSImax statistics data: <br><img src="https://habrastorage.org/webt/ai/v4/m0/aiv4m093szu4euojw1le0djqqvg.png" alt="image"><br><br>  VSIbase = 970, VSI Threshold was not reached. <br><br>  Statistics of the load on the storage system from monitoring SimpliVity: <br><img src="https://habrastorage.org/webt/01/61/tj/0161tj6hzex9d4yfjqati65jb8q.png" alt="image"><br><br>  During testing, the processor load threshold was reached at one of the system nodes, but this did not have a significant impact on its operation: <br><br><img src="https://habrastorage.org/webt/s0/2q/z3/s02qz3amd1xazzhdk8hmh12rdpk.png" alt="image"><br><br><img src="https://habrastorage.org/webt/wn/yf/6s/wnyf6swpmuwerwvw6xxu881scni.png" alt="image"><br><br>  In this case, the system can withstand the increase in load without significant degradation of performance.  The execution time of user tasks grows smoothly, the system response time does not change during testing and is up to 3 ms for writing and up to 1 ms for reading. <br><br>  The usual tests were not enough for the customer, and we went further: we increased the characteristics of the VM (the number of vCPUs to evaluate the oversubscription increase and the size of the disk) and added additional load. <br><br>  When conducting additional tests, the following stand configuration was used: <br>  Deployed 300 virtual desktops in 4vCPU configuration, 4GB RAM, 80GB HDD. <br><br>  Configuration of one of the test machines: <br><img src="https://habrastorage.org/webt/qf/ws/mj/qfwsmjptnkubxctz0-1gcx9u0si.png" alt="image"><br><br>  The machines are deployed in the version Dedicated - Full Copy: <br><br><img src="https://habrastorage.org/webt/tm/jz/0u/tmjz0uxhrw_adxqzttt2rgcboh8.png" alt="image"><br><br><img src="https://habrastorage.org/webt/qp/zz/iw/qpzziw9qrafmmvz5aeqs4aa26ru.png" alt="image"><br><br><h3>  300 Knowledge workers benchmark with oversubscription 12 </h3><br>  VSImax statistics data: <br><img src="https://habrastorage.org/webt/1f/wq/kg/1fwqkg1fm42iqsjuvmll4cym7p4.png" alt="image"><br><br>  VSIbase = 921 ms, VSI Threshold was not reached. <br><br>  Statistics of the load on the storage system from monitoring SimpliVity: <br><img src="https://habrastorage.org/webt/v8/d1/ko/v8d1kocafexbhemlivrcfog9cy8.png" alt="image"><br><br>  The results obtained are similar to testing the previous VM configuration. <br><br><h3>  300 Power workers with oversubscription 12 </h3><br>  VSImax statistics data: <br><img src="https://habrastorage.org/webt/dv/tz/gk/dvtzgkj-bpuanvk5ffguz65qmr0.png" alt="image"><br><br>  VSIbase = 933, VSI Threshold was not reached. <br><br>  Statistics of the load on the storage system from monitoring SimpliVity: <br><img src="https://habrastorage.org/webt/gw/gi/bo/gwgibojmbld7r6ztpoe6ss0y8bo.png" alt="image"><br><br>  With this testing, the processor load threshold was also reached, but this did not have a significant impact on performance: <br><br><img src="https://habrastorage.org/webt/5m/ny/te/5mnyteugxst3_7osvcklrg2adxi.png" alt="image"><br><br><img src="https://habrastorage.org/webt/60/ha/eu/60haeutmt3k6bn2ywn70e7_d6bu.png" alt="image"><br><br>  The results obtained are similar to testing the previous configuration. <br><br><h3>  What happens if you run the load for 10 hours? </h3><br>  Now we are looking at whether there will be an ‚Äúaccumulation effect‚Äù, and let us run tests for 10 hours in a row. <br><br>  Long tests and the description of the section should be aimed at what we wanted to check whether there will be any problems with the farm with a long load on it. <br><br><h3>  300 Knowledge workers benchmark + 10 hours </h3><br>  Additionally, testing of the load of 300 knowledge workers was carried out with the subsequent work of users for 10 hours. <br><br>  VSImax statistics data: <br><img src="https://habrastorage.org/webt/1m/bk/jc/1mbkjcthbgggrycwnjrqu56rwww.png" alt="image"><br><br>  VSIbase = 919 ms, VSI Threshold was not reached. <br><br>  Statistics VSImax Detailed: <br><img src="https://habrastorage.org/webt/wy/lb/cs/wylbcstsir7bxiw9lua3m7xi2_c.png" alt="image"><br><br>  The graph shows that no degradation of performance was observed during the whole test. <br><br>  Statistics of the load on the storage system from monitoring SimpliVity: <br><img src="https://habrastorage.org/webt/gl/r4/g0/glr4g0s7zaeev1k1zq5turro40k.png" alt="image"><br><br>  The performance of the storage system remains at the same level throughout the test. <br><br><h3>  Additional testing with the addition of synthetic load </h3><br>  The customer asked to add wild load to the disk.  To do this, a task was added to the storage system in each of the users' virtual machines to run the synthetic load on the disk when the user logs on.  The load was provided by the fio utility, which allows you to limit the load on the disk by the number of IOPS.  In each machine, a task was launched to launch an additional load in the amount of 22 IOPS 70% / 30% Random Read / Write. <br><br><h3>  300 Knowledge workers benchmark + 22 IOPS per user </h3><br>  During initial testing, it was discovered that fio creates a significant additional load on the processor of virtual machines.  This led to a rapid overload of hosts on the CPU and greatly affected the operation of the system as a whole. <br><br>  The load on the CPU hosts: <br><img src="https://habrastorage.org/webt/w6/gz/wt/w6gzwt7zok77j_mrtclbzur7sfc.png" alt="image"><br><br><img src="https://habrastorage.org/webt/_m/n7/dw/_mn7dwrbhicgrgllc9cnb_gzxkm.png" alt="image"><br><br>  The storage latency also naturally increased: <br><img src="https://habrastorage.org/webt/vp/uz/e7/vpuze7bmzsbvpsskg_3rcsyxlrk.png" alt="image"><br><br>  The lack of computing power has become critical to about 240 users: <br><img src="https://habrastorage.org/webt/uq/nr/e7/uqnre7iobieo2zcqosxmadyl7ca.png" alt="image"><br><br>  Due to the obtained results, it was decided to conduct a test, less loading CPU. <br><br><h3>  230 Office workers benchmark + 22 IOPS per user </h3><br>  To reduce the load on the CPU, the type of workload of Office workers was selected, and 22 IOPS synthetic loads were also added to each session. <br><br>  The test was limited to 230 sessions in order not to exceed the maximum CPU load. <br><br>  The test was launched with the subsequent work of users for 10 hours to check the stability of the system during long-term work at a load close to the maximum. <br><br>  VSImax statistics data: <br><img src="https://habrastorage.org/webt/ne/vz/nh/nevznhbzamx-9idqqcsmkaip6j4.png" alt="image"><br><br>  VSIbase = 918 ms, VSI Threshold was not reached. <br><br>  Statistics VSImax Detailed: <br><img src="https://habrastorage.org/webt/e6/3b/2g/e63b2g_qhey5o9vmzuanqfidqhe.png" alt="image"><br><br>  The graph shows that no degradation of performance was observed during the whole test. <br><br>  CPU load statistics: <br><img src="https://habrastorage.org/webt/mt/tn/jo/mttnjo09trs9shnvuelmutmkjaw.png" alt="image"><br><br><img src="https://habrastorage.org/webt/at/bv/im/atbvim4noi3ehoqwcpw_nkuk5hu.png" alt="image"><br><br>  When performing this test, the CPU load on the hosts was almost maximum. <br><br>  Statistics of the load on the storage system from monitoring SimpliVity: <br><img src="https://habrastorage.org/webt/qc/_z/bd/qc_zbdfztexr5yw6s2xh2pe_evy.png" alt="image"><br><br>  The performance of the storage system remains at the same level throughout the test. <br><br>  The load on the storage system during the test was approximately 6,500 IOPS at a ratio of 60/40 (3,900 IOPS - per read, 2,600 IOPS - per write), which is approximately 28 IOPS per work station. <br><br>  The average response time was 3 ms per write and up to 1 ms per read. <br><br><h2>  Total </h2><br>  When modeling the real loads on the HPE SimpliVity infrastructure, the results were obtained, confirming the ability of the system to provide virtual desktops of at least 300 Full Clone-machines on a pair of SimpliVity nodes.  At the same time, the response time of the storage system was maintained at an optimal level throughout the entire test period. <br><br>  We are very impressed with the approach about long-term tests and comparison of solutions before implementation.  We can test the performance for your loads if you want.  Including other hyperconvergent solutions.  The said customer is now completing tests on another solution in parallel.  Its current infrastructure is just a PC park, domain and software at every workplace.  Moving to VDI without tests is, of course, quite difficult.  It is particularly difficult to understand the real possibilities of the VDI farm without migrating real users to it.  And these tests allow you to quickly assess the real capabilities of a system without the need to attract ordinary users.  This is where the study came from. <br><br>  The second important approach - the customer immediately laid down on the correct scaling.  Here you can buy a server and add a farm, for example, per 100 users, everything is predictable at the price of the user.  For example, when they need to add 300 more users, they will know that they need two servers in an already defined configuration, and not to reconsider the possibilities of upgrading their infrastructure as a whole. <br><br>  The possibilities of the HPE SimpliVity federation are interesting.  Business is geographically separated, so it makes sense to put your separate VDI hardware in the far office.  In SimpliVity federation, each virtual machine is replicated according to a schedule with the ability to do between geographically distant clusters very quickly and without load on the channel - this is a built-in backup of a very good level.  When a VM is replicated between sites, the channel is activated as minimally as possible, and this makes it possible to build very interesting DR architectures with a single control center and a heap of decentralized storage sites. <br><img src="https://habrastorage.org/webt/iu/zm/mo/iuzmmojtdcsyhteccn2fvq4bxbi.png" alt="image"><br>  <a href="https://h20195.www2.hpe.com/v2/Getdocument.aspx%3Fdocname%3Da00015201ENW">Federation</a> <br><br>  All this together makes it possible to evaluate the financial side in great detail and impose VDI costs on the company's growth plans, and understand how quickly the solution will pay for itself and how it will work.  Because any VDI is a solution that ultimately saves a lot of resources, but at the same time, most likely, without a cost-effective opportunity to change it within 5-7 years of use. <br><br>  In general, if there are questions not for comments, write to me at mk@croc.ru. </div><p>Source: <a href="https://habr.com/ru/post/449210/">https://habr.com/ru/post/449210/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../44920/index.html">Minor cross-platform issues</a></li>
<li><a href="../449200/index.html">Highlights of the past Moscow Python Conf ++ 2019: transformation into a platform for communication</a></li>
<li><a href="../449202/index.html">As an IT specialist, move to the US: a comparison of work visas, useful services and links to help</a></li>
<li><a href="../449204/index.html">How we consider the metrics of development and support of documentation. Yandex report</a></li>
<li><a href="../449208/index.html">How to create successful teams and manage them</a></li>
<li><a href="../449214/index.html">KlusterKit</a></li>
<li><a href="../449216/index.html">Cheating automated surveillance cameras</a></li>
<li><a href="../44922/index.html">Image Optimization, Part 3: 4 steps to reduce file size</a></li>
<li><a href="../449220/index.html">DrumHero: As I did the first game in my life</a></li>
<li><a href="../449224/index.html">About the bias of artificial intelligence</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>