<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Portrait Habra-tutorial</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="In our age only useless things and are necessary for man. Oscar Wilde, Portrait of Dorian Gray ( source ) 
 Have you ever wondered what an ordinary po...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Portrait Habra-tutorial</h1><div class="post__text post__text-html js-mediator-article"><blockquote>  In our age only useless things and are necessary for man.  Oscar Wilde, Portrait of Dorian Gray ( <a href="http://ru.wikiquote.org/wiki/%25D0%259E%25D1%2581%25D0%25BA%25D0%25B0%25D1%2580_%25D0%25A3%25D0%25B0%25D0%25B9%25D0%25BB%25D1%258C%25D0%25B4">source</a> ) </blockquote><br>  Have you ever wondered what an ordinary post on Habr√© (ordinary powder <sup><i>TM</i></sup> ) differs from tutorial?  And how can this ‚Äúdifferent‚Äù be measured?  Are there any regularities here and is it possible to predict the label from them: <img src="https://habrastorage.org/getpro/habr/post_images/e0d/bd7/bbf/e0dbd7bbf597a0e574bd7559f14c162a.png"><br><br>  In this article we will discuss the so-called <a href="http://www.itl.nist.gov/div898/handbook/eda/section1/eda11.htm">exploratory data analysis</a> or briefly EDA ( <i>research data analysis</i> ) in relation to the Habrahabr articles, and in particular we will pay special attention to the tutorial.  First of all, EDA is aimed at a detailed study of the data, and is necessary for understanding what we are working with.  The important part is the collection and cleaning of data and the choice of what data to collect.  A feature of the method is to visualize and search for important characteristics and trends. <br><br>  Exploratory data analysis is the first step in studying and understanding data, without it we can push ourselves into the numerous traps described by the author in the article: " <a href="http://habrahabr.ru/post/217545/">How to lie with the help of statistics</a> ". 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h3>  How does the usual habra-tutorial </h3><a name="intro"></a><br>  As a simple demonstration, consider the simplest picture of three parameters: views, favorites (favorite) and rating (number of pluses), for three classes: all articles together, a regular post (non-tutorial) and tutorial. <br><img src="https://habrastorage.org/getpro/habr/post_images/782/6e9/213/7826e92137e560059df1bc6fc2acf8d5.png"><br>  Even in such a simplified picture, the difference between the classes is noticeable.  Our intuition and common sense tell us that on average, the tutorial is more often added to favorites, but intuition doesn‚Äôt tell how much more often, and that they gain fewer pluses and views.  These and many other interesting questions will be discussed further in the article. <br><br>  Article structure <br><ol><li>  <a href="http://habrahabr.ru/post/218607/">How does the usual habra-tutorial</a> </li><li>  <a href="http://habrahabr.ru/post/218607/">We collect data</a> </li><li>  <a href="http://habrahabr.ru/post/218607/">Habra data</a> </li><li>  <a href="http://habrahabr.ru/post/218607/">Explore the tutorials</a> </li><li>  <a href="http://habrahabr.ru/post/218607/">Parse interesting examples</a> </li><li>  <a href="http://habrahabr.ru/post/218607/">Predict label tutorial</a> </li><li>  <a href="http://habrahabr.ru/post/218607/">How to make a data set better</a> </li><li>  <a href="http://habrahabr.ru/post/218607/">Conclusion</a> </li><li>  <a href="http://habrahabr.ru/post/218607/">Further reading</a> </li></ol><br><a name="habracut"></a><br><br><h3>  We collect data </h3><a name="dataCollecting"></a><br>  One of the most important properties of research and experiment is its <a href="http://en.wikipedia.org/wiki/Reproducibility">reproducibility</a> and transparency.  Therefore, it is incredibly important to provide all the source materials that come with the work ‚Äî the data, the algorithm for collecting them, the counting algorithm, the implementation, the visualization, and the output characteristics.  All code, data and scripts for analysis and visualization are attached to this article - they are available through <a href="https://github.com/SergeyParamonov/HabraData">github</a> .  Separate links are provided for graphs and scripts, the most important and interesting parts of the code are also available in the article in the form of a drop-down text ("spoilers"). <br><br>  This allows you to check the authenticity of data, visualization and correctness of calculations.  For example, the original image of the histograms at the beginning of the article is made using the histograms_into.R script on dataset <a href="">all.csv</a> (the description is given below). <br><br>  Let's begin with the high-level description of data collection algorithm on habr-articles <br><img src="https://habrastorage.org/getpro/habr/post_images/d02/618/162/d02618162c7c94c2f52212984c6655d5.png"><br>  We simply go through each link and parse the page. <br><br>  One of the possible implementations of sorting articles by id (as well as collecting articles from the best) is shown here, the whole algorithm consists of three components: sorting pages of articles (given above in the form of a pseudo-code), parsing pages ( <code>processPage</code> ) and writing (class) Habra article ( <i>habra-article</i> ). <br><div class="spoiler">  <b class="spoiler_title">Implementation of sorting articles in python</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> __future__ <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> print_function <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> time <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> habraPageParser <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> HabraPageParser <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> article <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> HabraArticle <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">HabraPageGenerator</span></span></span><span class="hljs-class">:</span></span> @staticmethod <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">generatePages</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(rooturl)</span></span></span><span class="hljs-function">:</span></span> articles = [] suffix = <span class="hljs-string"><span class="hljs-string">"page"</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">101</span></span>): <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> i &gt; <span class="hljs-number"><span class="hljs-number">1</span></span>: url = rooturl+suffix+str(i) <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: url = rooturl print(url) pageArticles = HabraPageParser.parse(url) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> pageArticles <span class="hljs-keyword"><span class="hljs-keyword">is</span></span> <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>: articles = articles + pageArticles <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">break</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> articles @staticmethod <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">generateTops</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> WEEK_URL = <span class="hljs-string"><span class="hljs-string">'http://habrahabr.ru/posts/top/weekly/'</span></span> MONTH_URL = <span class="hljs-string"><span class="hljs-string">'http://habrahabr.ru/posts/top/monthly/'</span></span> ALLTIME_URL = <span class="hljs-string"><span class="hljs-string">'http://habrahabr.ru/posts/top/alltime/'</span></span> articles = [] articles = articles + HabraPageGenerator.generatePages(ALLTIME_URL) articles = articles + HabraPageGenerator.generatePages(MONTH_URL) articles = articles + HabraPageGenerator.generatePages(WEEK_URL) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> articles @staticmethod <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">generateDataset</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(dataset_name)</span></span></span><span class="hljs-function">:</span></span> FIRST_TUTORIAL = <span class="hljs-number"><span class="hljs-number">152563</span></span> LAST_INDEX = <span class="hljs-number"><span class="hljs-number">219000</span></span> BASE_URL = <span class="hljs-string"><span class="hljs-string">'http://habrahabr.ru/post/'</span></span> logname = <span class="hljs-string"><span class="hljs-string">"log-test-alive.txt"</span></span> logfile = open(logname, <span class="hljs-string"><span class="hljs-string">"w"</span></span>) datafile = HabraArticle.init_file(dataset_name) print(<span class="hljs-string"><span class="hljs-string">"generate all pages"</span></span>, file=logfile) print(time.strftime(<span class="hljs-string"><span class="hljs-string">"%H:%M:%S"</span></span>), file=logfile) logfile.flush() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> postIndex <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(FIRST_TUTORIAL, LAST_INDEX): url = BASE_URL + str(postIndex) print(<span class="hljs-string"><span class="hljs-string">"test: "</span></span>+url, file=logfile) <span class="hljs-keyword"><span class="hljs-keyword">try</span></span>: article = HabraPageParser.parse(url) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> article: print(<span class="hljs-string"><span class="hljs-string">"alive: "</span></span>+url, file=logfile) <span class="hljs-keyword"><span class="hljs-keyword">assert</span></span>(len(article) == <span class="hljs-number"><span class="hljs-number">1</span></span>) article[<span class="hljs-number"><span class="hljs-number">0</span></span>].write_to_file(datafile) <span class="hljs-keyword"><span class="hljs-keyword">except</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">continue</span></span> logfile.flush() logfile.close() datafile.close()</code> </pre><br></div></div><br><br>  Code <i>habra-article</i> : <br><div class="spoiler">  <b class="spoiler_title">Implementation of a class of habr-article</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> __future__ <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> print_function <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">HabraArticle</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self,post_id,title,author,score,views,favors,isTutorial)</span></span></span><span class="hljs-function">:</span></span> self.post_id = post_id self.title = title self.author = author self.score = score self.views = views self.favors = favors <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> isTutorial: self.isTutorial = <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: self.isTutorial = <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">printall</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self)</span></span></span><span class="hljs-function">:</span></span> print(<span class="hljs-string"><span class="hljs-string">"id: "</span></span>, self.post_id ) print(<span class="hljs-string"><span class="hljs-string">"title: "</span></span>, self.title) print(<span class="hljs-string"><span class="hljs-string">"author: "</span></span>, self.author ) print(<span class="hljs-string"><span class="hljs-string">"score: "</span></span>, self.score ) print(<span class="hljs-string"><span class="hljs-string">"views: "</span></span>, self.views ) print(<span class="hljs-string"><span class="hljs-string">"favors: "</span></span>, self.favors ) print(<span class="hljs-string"><span class="hljs-string">"isTutorial: "</span></span>, self.isTutorial) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">get_csv_line</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> self.post_id+<span class="hljs-string"><span class="hljs-string">","</span></span>+self.title+<span class="hljs-string"><span class="hljs-string">","</span></span>+self.author+<span class="hljs-string"><span class="hljs-string">","</span></span>+ self.score+<span class="hljs-string"><span class="hljs-string">","</span></span>+self.views+<span class="hljs-string"><span class="hljs-string">","</span></span>+self.favors+<span class="hljs-string"><span class="hljs-string">","</span></span>+str(self.isTutorial) +<span class="hljs-string"><span class="hljs-string">"\n"</span></span> @staticmethod <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">printCSVHeader</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-string"><span class="hljs-string">"id, title, author, score, views, favors, isTutorial"</span></span> @staticmethod <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">init_file</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(filename)</span></span></span><span class="hljs-function">:</span></span> datafile = open(filename, <span class="hljs-string"><span class="hljs-string">'w'</span></span>) datafile.close() datafile = open(filename, <span class="hljs-string"><span class="hljs-string">'a'</span></span>) print(HabraArticle.printCSVHeader(), file=datafile) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> datafile <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">write_to_file</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self,datafile)</span></span></span><span class="hljs-function">:</span></span> csv_line = self.get_csv_line() datafile.write(csv_line.encode(<span class="hljs-string"><span class="hljs-string">'utf-8'</span></span>)) datafile.flush()</code> </pre><br></div></div><br><br>  Code (beautifulsoup) function: <code>processPage</code> : <br><div class="spoiler">  <b class="spoiler_title">processPage</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> urllib2 <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> bs4 <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> BeautifulSoup <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> re <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> article <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> HabraArticle <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">HabraPageParser</span></span></span><span class="hljs-class">:</span></span> @staticmethod <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">parse</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(url)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">try</span></span>: response = urllib2.urlopen(url) <span class="hljs-keyword"><span class="hljs-keyword">except</span></span> urllib2.HTTPError, err: <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> err.code == <span class="hljs-number"><span class="hljs-number">404</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-keyword"><span class="hljs-keyword">None</span></span> <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">raise</span></span> html = response.read().decode(<span class="hljs-string"><span class="hljs-string">"utf-8"</span></span>) soup = BeautifulSoup(html) <span class="hljs-comment"><span class="hljs-comment">#print(soup.decode('utf-8')) #if the post is closed, return None cyrillicPostIsClosed = '\xd0\xa5\xd0\xb0\xd0\xb1\xd1\x80\xd0\xb0\xd1\x85\xd0\xb0\xd0\xb1\xd1\x80 \xe2\x80\x94 \xd0\x94\xd0\xbe\xd1\x81\xd1\x82\xd1\x83\xd0\xbf \xd0\xba \xd1\x81\xd1\x82\xd1\x80\xd0\xb0\xd0\xbd\xd0\xb8\xd1\x86\xd0\xb5 \xd0\xbe\xd0\xb3\xd1\x80\xd0\xb0\xd0\xbd\xd0\xb8\xd1\x87\xd0\xb5\xd0\xbd' if soup.title.text == cyrillicPostIsClosed.decode('utf-8'): return None articles = soup.find_all(class_="post shortcuts_item") habraArticles = [] for article in articles: isScoreShown = article.find(class_="mark positive ") #if the score is published already, then article is in, otherwise we go on to next one if not isScoreShown: continue post_id = article["id"] author = article.find(class_="author") if author: author = author.a.text title = article.find(class_="post_title").text score = article.find(class_="score" ).text views = article.find(class_="pageviews" ).text favors = article.find(class_="favs_count").text tutorial = article.find(class_="flag flag_tutorial") #we need to escape the symbols in the title, it might contain commas title = re.sub(r',', " comma ", title) #if something went wrong skip this article if not post_id or not author or not title: return None habraArticle = HabraArticle(post_id,title,author,score,views,favors,tutorial) habraArticles.append(habraArticle) return habraArticles</span></span></code> </pre><br></div></div><br><br><img src="https://habrastorage.org/getpro/habr/post_images/9ac/9b7/ec6/9ac9b7ec62a68c1e72550f67071472ef.png"><br>  (obtained by using the <a href="">scale_id.R</a> script on the first 6.5k points of the <a href="">alive_test_id.csv dataset</a> ) <br><br>  You need to read the graph as follows: take 250 consecutive id values ‚Äã‚Äãand write them out in a line; if the page is live, we mark it with red, otherwise with blue.  Take the next 250 values ‚Äã‚Äãand write them down to the next line, etc. <br><br>  The real density of live links since the publication of the first tutorial (September 27, 2012) is 23%.  If we assume that id is issued sequentially for each draft, three fourth Habra articles are either hidden or have not been added. <br><br>  But (!) Most likely the real density is underestimated in measurements.  This is due to the lack of the method of collecting articles: problems with the connection, page parsing or short-term inaccessibility of habrabra.  Manual data verification showed (on all.csv) that in a small number of cases &lt;= 5-10%, actual pages were not processed.  Given this error, it is rational to assume that the actual density lies in the range of 30 + -5%.  We will work to reduce the error in the next series. <br><br><h5>  Additional data </h5><br>  In addition to listing all articles by id (for a specified period), the following data was also collected: <br><ol><li>  The best of all time </li><li>  Best month </li><li>  The best of the week </li></ol><br><br>  For the collection, the algorithm described above was used, which bypassed the links: <br>  <a href="http://habrahabr.ru/posts/top/alltime/page">habrahabr.ru/posts/top/alltime/page</a> $ i <br>  <a href="http://habrahabr.ru/posts/top/monthly/page">habrahabr.ru/posts/top/monthly/page</a> $ i <br>  <a href="http://habrahabr.ru/posts/top/weekly/page">habrahabr.ru/posts/top/weekly/page</a> $ i <br>  for $ i from 1 to 100 <br><br><h3>  Habra data </h3><a name="aboutDataset"></a><br>  The collected data is stored in csv ( <a href="http://creativyst.com/Doc/Articles/CSV/CSV01.htm">comma separated values</a> ) format and has the following form: <br><img src="https://habrastorage.org/getpro/habr/post_images/1bc/0f2/082/1bc0f2082b517c84a7c54fcf68a0181e.png"><br><br>  Altogether, along with the article datasets are available (downloaded on April 7, 2014): <br><ol><li>  All articles: <a href="">all.csv</a> </li><li>  Best of all time: <a href="">dataset_top_all_time.csv</a> </li><li>  Best of the month: <a href="">habra_dataset_monthly.csv</a> </li><li>  Best of the week: <a href="">habra_dataset_weekly.csv</a> </li><li>  Log of live pages by id: <a href="">alive_test_id.csv</a> </li></ol><br>  All graphs and results presented in the article are based on the above data.  Mostly we will work with the file all.csv. <br><br><h3>  Explore the tutorials </h3><a name="digIntoData"></a><br>  Consider the distribution of articles on the main parameters collected separately for the two classes: the tutorial and the usual post (non-tutorial).  On the Y axis, the share of articles with the corresponding parameter values ‚Äã‚Äãon the X axis. We have three main parameters: views, favorites, and the number of entries in the favorites. <br><img src="https://habrastorage.org/getpro/habr/post_images/3db/a77/261/3dba772611ce57eeb164f66716228ada.png"><br>  (obtained using <a href="">histograms_tutorial_vs_normal.R</a> script on <a href="">all.csv</a> ) <br><br>  If you always waited for a convenient moment to read about <a href="http://ru.wikipedia.org/wiki/%25D0%2597%25D0%25B0%25D0%25BA%25D0%25BE%25D0%25BD_%25D0%25A6%25D0%25B8%25D0%25BF%25D1%2584%25D0%25B0">Zipf's Law</a> , then it has arrived.  On the right, we see something well resembling this distribution (and I think we will see it more than once in the future). <br><br>  In general, we see that the distribution of votes (pluses) and views of the tutorial is shifted to the left - relative to the distribution of ordinary posts and also resembles Zipf's law, although it is noticeable that the correspondence here is not so obvious.  So on average, regular posts are gaining more pluses and views.  And the distribution of favorites is already significantly shifted to the right of the tutorial and does not at all resemble Zipf's law.  On average, we see that readers are much more actively adding the tutorial to their favorites.  Almost the entire distribution of the tutorial dominates the usual posts twice, we give a short table of quantiles of the two distributions: <br><img src="https://habrastorage.org/getpro/habr/post_images/bc1/bed/83d/bc1bed83d61c9a4d1e000f36f9e2d70e.png"><br>  The table reads as follows: if the 20% quantile of a regular post is 16, this means that 20% of all the posts of ordinary posts gain no more than 16 entries to your favorites.  The median is 50% quantile, the tutorial has 109, and the usual posts have 49. <br><br>  It is also worth considering the distribution of parameters together.  From the graphs above, we see that favorites play a special role for the training material and therefore we will give them special attention in the article. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/eba/b97/42a/ebab9742a820f65c9a7e42ba48a0da55.png"><br>  (Obtained using the script <a href="">joint_favours_score_view.R</a> on <a href="">all.csv</a> ) <br><br>  The graph above shows the general trend in the data among tutorial, one plus has an average of several favorites, the median ratio for tutorials is 2.6 times higher than a regular post, and one view has an average (by median) 2.7 times more favourites than at the usual post. <br><br>  This allows us to outline the area of ‚Äã‚Äãinterest to us, where most of the training material without labels is most likely located - the blue dots in the upper boundary of the red area.  We can form queries to our data and test this guess.  And it is possible to derive some rules that allow us to automatically "correct" or remind the authors of this label. <br><br>  (The plots of the distributions are cut off in the graphs; a very small number of points fall outside the specified limits. But the inclusion of these points would increase the scale and make the other points virtually indistinguishable and unreadable.) <br><br><h3>  Parse interesting examples </h3><a name="examples"></a><br>  In this part we will talk about some typical examples that are found in the data and that will help us better understand the existing potential patterns in the articles and their properties. <br><h5>  Many favorites - few advantages </h5><br>  Request: <br><img src="https://habrastorage.org/getpro/habr/post_images/f6a/217/438/f6a2174389e8b87e4d14a9add3ef1600.png"><br><br><div class="spoiler">  <b class="spoiler_title">Request in R language</b> <div class="spoiler_text"> <code>query1 &lt;- subset(data, favors &gt; 1000 &amp; score &lt; 50 &amp; isTutorial == FALSE) <br></code> <br></div></div><br><br>  Result: <br><img src="https://habrastorage.org/getpro/habr/post_images/292/fe6/488/292fe6488ab46240a936611f98fd1bd3.png"><br><br>  As we can see, the first article is a pure training material without a label, the second one can also claim to be a teaching material.  We can notice the following trend from the graphs above: all distributions show that on average, the tutorial is gaining less advantages and much more favourites than a regular article.  Coupled with the fact that a large number of tutorial for some reason do not have a label, we assume that the article has a small number of pluses and a large number of entries in the favorites, according to general data trends has a good chance of being a teaching material. <br><br><h5>  Favorites are 10 times more than pluses (and at least 25 pluses) </h5><br>  Request: <br><img src="https://habrastorage.org/getpro/habr/post_images/8a6/aaf/8b2/8a6aaf8b22c201a1406a461dc84606cb.png"><br><br><div class="spoiler">  <b class="spoiler_title">Request in R language</b> <div class="spoiler_text"> <code>query2 &lt;- subset(data, favors &gt; 10*score &amp; score &gt; 25) <br></code> <br></div></div><br><br>  Result: <br><img src="https://habrastorage.org/getpro/habr/post_images/d5d/0e8/134/d5d0e81348d2a38c4f419fae6f04eb1d.png"><br><br>  A slightly complicated version of the previous request, we are looking for articles where favorites are ten times more than the advantages and at the same time the number of advantages is at least 25. Under these conditions, we find articles that have retained large numbers of people, which may serve as some indicator that The article will be useful in the future, which means it is a good candidate for educational material. <br><br>  The disadvantage of this request is that half of the tutorial is gaining 18 or less pros, which means this rule cuts off a large number of potential tutorial articles. <br><br>  The script with queries <a href="">queries.R</a> , dataset <a href="">all.csv</a> . <br><br><h3>  Predict label tutorial </h3><a name="predictingTutorial"></a><br>  The tutorial tag in the article corresponds to the isTutorial binary attribute.  So we can formulate the task of defining the <i>tutorial</i> label by the parameters of <i>score</i> , <i>view</i> and <i>favourites</i> , as searching for some predicate (a function that returns 1 or 0) <i>f</i> such that for the entire data set it is true that <br><img src="https://habrastorage.org/getpro/habr/post_images/9d0/286/766/9d0286766978f1689abaaecc9415dfb6.png"><br>  (the author admits that he is now simplifying everything and generally actively waving his hands - but this should give the general reader what to do) <br><br>  In fact, classical <a href="http://en.wikipedia.org/wiki/Machine_learning">machine learning</a> methods (such as SVM, Random Forest, Recursive Trees, etc) will not show qualitative results on the collected data for the following reasons: <br><ul><li>  Incredibly poor features space i.  only three parameters that are not well distinguished tutorial from the usual post - this is written below </li><li>  A significant number of articles not marked as tutorial, but in fact they are - see the first request and the article: "Setting up a Nginx + LAMP server at home" - this is a classic tutorial, but it is marked as a regular post! </li><li>  The subjectivity of the mark itself, the presence and / or its absence is largely determined solely by the author's opinion </li></ul><br><br>  What can we do in this situation?  According to the existing data, we can try to derive some <i>sufficient</i> conditions and look at their feasibility on the existing data.  If the rules match the data, then by induction we can create some rule that would allow us to find and mark the tutorial without a label.  Simple, interpretable and tasteful. <br><br>  For example, the following rule is in good agreement with the data and will allow revising some labels (given for the sake of example only) <br><img src="https://habrastorage.org/getpro/habr/post_images/d42/242/f3d/d42242f3d387451eb15e556ffffdd13d.png"><br>  and the first entries in the answer: <br><img src="https://habrastorage.org/getpro/habr/post_images/7a9/d16/f0b/7a9d16f0baff8101d9823624e21cf6e4.png"><br><div class="spoiler">  <b class="spoiler_title">Request in R language</b> <div class="spoiler_text"> <code>query3 &lt;- subset(data, favors &gt;= 10*score, favors &gt;= views/100) <br></code> <br></div></div><br><br>  As you can see, despite the fact that most of the entries do not have a tutorial tag, articles actually are (despite the small score values ‚Äã‚Äãin the first 6 entries; although more than half of the tutorial have less than 18 pluses).  Thus, we can conduct the so-called <a href="http://en.wikipedia.org/wiki/Co-training">co-training</a> , that is, by a small amount of data with labels, we can derive rules that allow us to mark the remaining data and create conditions for the application of classical machine learning methods. <br><br>  But no matter what clever learning algorithms we use, the main problem in the classification of the tutorial is the proper construction of the attribute space, i.e.  mapping an article to some vector of numerical or nominative (having a number of final values, for example, the color can be blue, red or green) variables. <br><br><h3>  How to make a data set better </h3><a name="howToImprove"></a><br>  The collected data set is far from ideal, so it's best to start criticizing it yourself, until others have done it.  Certainly, only by the parameters, views, rating, favorites, it is not possible to unambiguously predict whether this article is a tutorial or not.  However, we need to get a rule, or rather a classifier, that would work <i>quite</i> accurately.  To do this, consider a few typical features of articles that may be useful. <br><br>  Consider the first example: <br><img src="https://habrastorage.org/getpro/habr/post_images/937/91b/6be/93791b6beead24e530a6dcc82a2c8d90.png"><br>  What is striking is that in many tutorial, there are images, and often in large quantities - yes, they can also be found in ordinary posts, but this can be a valuable attribute in combination with other parameters.  It is also worth not to discount the fact that many hubs are thematically much better suited for training material than others - perhaps this should also be taken into account. <br><br>  Consider the second example: <br><img src="https://habrastorage.org/getpro/habr/post_images/9bd/65c/237/9bd65c2378f4499c9c3b374febff193d.png"><br>  Here, the most important is the presence of code and structure, it is natural to assume that these factors may well discriminate between classes and therefore, in principle, they can be taken into account in the model.  We can also enter such a parameter as the availability of training materials among similar posts. <br><br>  Hypothetically, this would give us a new dataset (and a new parameter space for classification), which could better distinguish classes of articles among themselves. <br><img src="https://habrastorage.org/getpro/habr/post_images/dc2/303/f5a/dc2303f5ae274000c38321178b489572.png"><br><br>  The space of features for classification can actually be huge: the number of comments, the presence of a video, keywords in the title, and many others.  Space selection is key to building a successful classifier. <br><br><h5>  Why you should use the current cut of articles </h5><br>  Why for an assessment not to use all available articles from a habr?  Doesn't this increase the accuracy of the classifier?  Why do we take only the current cut?  The width of the window is also really worth choosing wisely and this may require additional analysis. <br><br>  But it is impossible to take a sample of all articles in general for the entire life of the resource for the following reason: the resource is constantly evolving and the characteristics of the articles change accordingly: if we consider the very first articles, eg <a href="http://habrahabr.ru/post/171/">171</a> , <a href="http://habrahabr.ru/post/2120/">2120</a> , <a href="http://habrahabr.ru/post/18709/">18709</a> , we will see that their characteristics change significantly and they already should not be included in a representative sample of current articles, because, on average, we do not expect such parameters in new articles.  In many ways, because the audience has changed, the articles themselves have changed and the channels for distributing articles on the Internet have changed. <br><br><h3>  Conclusion </h3><a name="conclusions"></a><br>  We reviewed and analyzed the most basic parameters of articles.  The idea that the label ‚Äútutorial‚Äù can be automatically predicted led us to the idea that we understood how to expand the data sets and in which direction it is worth looking.  We also looked at the main differences between regular posts and training material in terms of: views, favorites, and rankings.  Found that the main difference is the presence of substantially large records in the favorites and set the numerical estimates of this difference. <br><br>  Only 2.8% in the top are labeled ‚Äútraining material‚Äù, with a total share of 9.1% for the entire time since its introduction (September 27, 2012), possibly due to the fact that a sufficient amount of material came to the top before the label appeared or the use of the ‚Äútutorial‚Äù label was not yet available immediately after its introduction.  In favor of this hypothesis, he says that the total share of the tutorial at the best in a week and month practically does not differ from the share among all posts (8.1% per month and 7.8% per week; <a href="">relativeFractionOfTutorials.R</a> ). <br><br>  Perhaps using the extended data set, we will be able to predict quite effectively (using various methods of machine learning) and inform the author: "You may have forgotten the tutorial label."  This task will be primarily interesting because it will allow you to create a complete list with a selection of interesting training material that can be sorted or evaluated by parameters other than pluses, eg the number of people who added an article to your favorites. <br><br><h3>  Further reading </h3><a name="links"></a><br>  If the topic of data analysis seemed interesting, then below is a list of useful material. <br><ul><li>  Udacity - <a href="https://www.udacity.com/course/ud651">Exploratory Data Analysis</a> and <a href="https://www.udacity.com/course/ud359">Data Science</a> </li><li>  Caltech - <a href="http://work.caltech.edu/telecourse.html">Learning from Data</a> </li><li>  Coursera - <a href="https://www.coursera.org/specialization/jhudatascience/1%3Futm_medium%3DcourseDescripTop">Data Science Track</a> (just started!) </li><li>  If you live in St. Petersburg, you can take courses at <a href="http://dmlabs.org/">DMLabs</a> </li><li>  If you live in Moscow, then you probably already heard about the <a href="http://shad.yandex.ru/">SHAD</a> </li></ul></div><p>Source: <a href="https://habr.com/ru/post/218607/">https://habr.com/ru/post/218607/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../218595/index.html">RuTracker does not work due to DDOS attack</a></li>
<li><a href="../218597/index.html">Build Systems - Local Repository</a></li>
<li><a href="../218599/index.html">Review of the transformer ASUS Transformer Book T300LA</a></li>
<li><a href="../218601/index.html">Review of the JPoint 2014 conference reports</a></li>
<li><a href="../218603/index.html">8 programming traps</a></li>
<li><a href="../218609/index.html">Critical vulnerability in OpenSSL 1.0.1 and 1.0.2-beta</a></li>
<li><a href="../218611/index.html">Iron sample for HD FPV *</a></li>
<li><a href="../218613/index.html">PVS-Studio and 3DO emulators</a></li>
<li><a href="../218617/index.html">The biggest Tetris in the world: playing on the wall of a skyscraper</a></li>
<li><a href="../218619/index.html">Video encoding using Intel HD integrated video</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>