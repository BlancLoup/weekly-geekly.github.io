<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Let's process the sound on Go</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Disclaimer: I do not consider any algorithms and APIs for working with sound and speech recognition. This article is about audio issues and how to sol...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Let's process the sound on Go</h1><div class="post__text post__text-html js-mediator-article"><blockquote>  Disclaimer: I do not consider any algorithms and APIs for working with sound and speech recognition.  This article is about audio issues and how to solve them with Go. </blockquote><p><img src="https://habrastorage.org/webt/gg/cf/7i/ggcf7ihwchhcfrbsnrwdpohwczg.png" alt="gopher"></p><br><p> <code>phono</code> - application framework for working with sound.  Its main function is to create a pipeline of different technologies that will process the sound. <del>  for you </del>  the way you want. </p><br><p>  What does the conveyor, besides, from different technologies, and why another framework?  Now we will understand. </p><a name="habracut"></a><br><h2 id="otkuda-zvuk">  Where does the sound come from? </h2><br><p>  By 2018, sound has become the standard way for human interaction with technology.  Most IT giants <a href="https://www.predictiveanalyticstoday.com/top-intelligent-personal-assistants-automated-personal-assistants/">have created</a> their voice assistant or are doing it right now.  Voice control is already in most operating systems, and voice messaging is a typical feature of any messenger.  In the world, <a href="https://angel.co/natural-language-processing">about a thousand</a> startups are working on the processing of natural language and <a href="https://angel.co/speech-recognition">about two hundred</a> on speech recognition. </p><br><p>  With music, a similar story.  It plays from any device, and sound recording is available to anyone who has a computer.  <a href="https://www.pluginboutique.com/manufacturers">Hundreds of companies</a> and <a href="https://www.kvraudio.com/marketplace/brands">thousands of enthusiasts</a> around the world are developing music software. </p><br><h2 id="a-nametasksa-obschie-zadachi">  Common tasks </h2><br><p>  If you had to work with sound, then the following conditions should sound familiar: </p><br><ul><li>  Audio must be <strong>obtained</strong> from a file, device, network, etc. </li><li>  Audio needs to be <strong>processed</strong> : add effects, transcode, analyze, etc. </li><li>  Audio must be <strong>transferred</strong> to a file, device, network, etc. </li><li>  Data is transmitted in small buffers. </li></ul><br><p>  It turns out the usual pipeline - there is a data stream that goes through several stages of processing. </p><br><h2 id="resheniya">  Solutions </h2><br><p>  For clarity, we take the problem from real life.  For example, you need to convert a voice to text: </p><br><ul><li>  We record audio from the device </li><li>  Remove noise </li><li>  Equalize </li><li>  Passing a signal to the speech recognition API </li></ul><br><p>  Like any other problem, this one has several solutions. </p><br><h3 id="v-lob">  Head-on </h3><br><p>  Only for hardcore <del>  cyclists </del>  programmers.  We record sound directly through the sound card driver, we write a smart noise and multiband equalizer.  This is very interesting, but you can forget about your original task for a few months. </p><br><p>  Long and very difficult. </p><br><h3 id="po-normalnomu">  In a normal way </h3><br><p>  The alternative is to use existing APIs.  You can record audio using ASIO, CoreAudio, PortAudio, ALSA and others.  For processing, there are also several types of plug-ins: AAX, VST2, VST3, AU. </p><br><p>  A rich choice does not mean that you can use everything at once.  The following restrictions usually apply: </p><br><ol><li>  Operating system.  Not all APIs are available on all operating systems.  For example, AU is a native OS X technology and is only available there. </li><li>  Programming language.  Most audio libraries are written in C or C ++.  In 1996, Steinberg released the first version of the VST SDK, which is still the most popular plug-in standard.  After 20 years, it is not necessary to write in C / C ++: for VST there are wrappers for Java, Python, C #, Rust and who knows what else.  Although the language remains a limitation, but now the sound is processed even in JavaScript. </li><li>  Functional.  If the task is simple and clear, it is not necessary to write a new application.  The same FFmpeg can do a lot. </li></ol><br><p>  In this situation, the complexity depends on your choice.  In the worst case, you will have to deal with several libraries.  And if you are not lucky at all, with complex abstractions and completely different interfaces. </p><br><h3 id="chto-v-itoge">  What is the result? </h3><br><p>  You need to choose between <strong>very complex</strong> and <strong>complex</strong> : </p><br><ul><li>  either deal with multiple low-level APIs to write your bikes </li><li>  either deal with multiple APIs and try to befriend them </li></ul><br><p>  No matter which method is chosen, the task always comes down to the pipeline.  The technologies used may vary, but the essence is the same.  The problem is that again, instead of solving a real problem, you have to write <del>  bicycle </del>  conveyor. </p><br><p>  But there is a way out. </p><br><h2 id="phono">  phono </h2><br><p><img src="https://habrastorage.org/webt/ym/fw/h6/ymfwh6c8hjwgig8hzksgbut2ifm.jpeg" alt="phono"></p><br><p>  <code>phono</code> designed to solve common problems - to " <strong>receive, process and transmit</strong> " sound.  For this, he uses the pipeline as the most natural abstraction.  There is <a href="https://blog.golang.org/pipelines">an article</a> in the <a href="https://blog.golang.org/">official blog</a> Go that describes the pattern pipeline.  The main idea of ‚Äã‚Äãthe pipeline is that there are several stages of data processing that operate independently of each other and exchange data through channels.  That is necessary. </p><br><p>  Why go? </p><br><p>  First, most audio programs and libraries are written in C, and Go is often mentioned as its successor.  In addition, there are <a href="https://golang.org/cmd/cgo/">cgo</a> and <a href="https://github.com/avelino/awesome-go">quite a lot of bindings</a> for existing audio libraries.  You can take and use. </p><br><p>  Secondly, in my personal opinion, Go is a good language.  I will not go deep, but I will note its <a href="https://www.golang-book.com/books/intro/10">multithreading</a> .  Channels and gorutiny greatly simplify the implementation of the pipeline. </p><br><h3 id="abstrakcii">  Abstractions </h3><br><p>  The heart of <code>phono</code> is the type of <code>pipe.Pipe</code> (English pipe).  That it implements the pipeline.  As in the <a href="https://blog.golang.org/pipelines">sample from the blog</a> , there are three types of stages: </p><br><ol><li>  <code>pipe.Pump</code> (English pump) - <strong>receiving</strong> sound, only output channels </li><li>  <code>pipe.Processor</code> (English handler) - sound <strong>processing</strong> , input and output channels </li><li>  <code>pipe.Sink</code> (English sink) - sound <strong>transmission</strong> , input channels only </li></ol><br><p>  Inside <code>pipe.Pipe</code> data is transmitted by buffers.  The rules by which you can build the pipeline: </p><br><p><img src="https://habrastorage.org/webt/go/ym/ep/goymepjg4pds_picireejjsshnq.png" alt="pipe_diagram"></p><br><ol><li>  One <code>pipe.Pump</code> </li><li>  Several <code>pipe.Processor</code> , placed one after another </li><li>  One or more <code>pipe.Sink</code> , placed in parallel </li><li>  All <code>pipe.Pipe</code> components must have the same: <br><ul><li>  Buffer size (messages) </li><li>  Sampling rate </li><li>  Number of channels </li></ul></li></ol><br><p>  The minimum configuration is Pump and one Sink, the rest is optional. </p><br><p>  Let us examine a few examples. </p><br><h3 id="prostoy">  Plain </h3><br><p>  <strong>Task:</strong> play wav file. </p><br><p>  Let's <strong>bring</strong> it to the form " <strong>to receive, process, transfer</strong> ": </p><br><ol><li>  <strong>Get</strong> audio from wav file </li><li>  <strong>We transfer</strong> audio to portaudio device </li></ol><br><p><img src="https://habrastorage.org/webt/qz/5p/qg/qz5pqgxqfydujch359ei8fsp0pg.png"></p><br><p>  Audio is read and immediately played. </p><br><div class="spoiler">  <b class="spoiler_title">Code</b> <div class="spoiler_text"><pre> <code class="go hljs"><span class="hljs-keyword"><span class="hljs-keyword">package</span></span> example <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> ( <span class="hljs-string"><span class="hljs-string">"github.com/dudk/phono"</span></span> <span class="hljs-string"><span class="hljs-string">"github.com/dudk/phono/pipe"</span></span> <span class="hljs-string"><span class="hljs-string">"github.com/dudk/phono/portaudio"</span></span> <span class="hljs-string"><span class="hljs-string">"github.com/dudk/phono/wav"</span></span> ) <span class="hljs-comment"><span class="hljs-comment">// Example: // Read .wav file // Play it with portaudio func easy() { wavPath := "_testdata/sample1.wav" bufferSize := phono.BufferSize(512) // wav pump wavPump, err := wav.NewPump( wavPath, bufferSize, ) check(err) // portaudio sink paSink := portaudio.NewSink( bufferSize, wavPump.WavSampleRate(), wavPump.WavNumChannels(), ) // build pipe p := pipe.New( pipe.WithPump(wavPump), pipe.WithSinks(paSink), ) defer p.Close() // run pipe err = p.Do(pipe.Run) check(err) }</span></span></code> </pre> </div></div><br><p>  First, we create elements of the future pipeline: <code>wav.Pump</code> and <code>portaudio.Sink</code> and transfer them to the constructor <code>pipe.New</code> .  The <code>p.Do(pipe.actionFn) error</code> function starts the pipeline and waits for completion. </p><br><h3 id="slozhnee">  More difficult </h3><br><p>  <strong>Task:</strong> split the wav file into samples, compose a track from them, save the result and simultaneously play back. </p><br><p>  A track is a sequence of samples, and a sample is a small piece of audio.  To cut audio, you must first load it into memory.  To do this, use the type <code>asset.Asset</code> from the <code>phono/asset</code> package.  We divide the task into standard steps: </p><br><ol><li>  <strong>Get</strong> audio from wav file </li><li>  <strong>We transfer</strong> audio to memory </li></ol><br><p>  Now we make samples with our hands, add them to the track and finish off the task: </p><br><ol><li>  <strong>Get</strong> audio from the track </li><li>  <strong>We transfer</strong> audio to <br><ul><li>  wav file </li><li>  portaudio device </li></ul></li></ol><br><p><img src="https://habrastorage.org/webt/r3/q7/yv/r3q7yvccvkpjxbho7s3iwr2zisc.png" alt="example_normal"></p><br><p>  Again, without processing stage, but as many as two pipeline! </p><br><div class="spoiler">  <b class="spoiler_title">Code</b> <div class="spoiler_text"><pre> <code class="go hljs"><span class="hljs-keyword"><span class="hljs-keyword">package</span></span> example <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> ( <span class="hljs-string"><span class="hljs-string">"github.com/dudk/phono"</span></span> <span class="hljs-string"><span class="hljs-string">"github.com/dudk/phono/asset"</span></span> <span class="hljs-string"><span class="hljs-string">"github.com/dudk/phono/pipe"</span></span> <span class="hljs-string"><span class="hljs-string">"github.com/dudk/phono/portaudio"</span></span> <span class="hljs-string"><span class="hljs-string">"github.com/dudk/phono/track"</span></span> <span class="hljs-string"><span class="hljs-string">"github.com/dudk/phono/wav"</span></span> ) <span class="hljs-comment"><span class="hljs-comment">// Example: // Read .wav file // Split it to samples // Put samples to track // Save track into .wav and play it with portaudio func normal() { bufferSize := phono.BufferSize(512) inPath := "_testdata/sample1.wav" outPath := "_testdata/example4_out.wav" // wav pump wavPump, err := wav.NewPump(inPath, bufferSize) check(err) // asset sink asset := &amp;asset.Asset{ SampleRate: wavPump.WavSampleRate(), } // import pipe importAsset := pipe.New( pipe.WithPump(wavPump), pipe.WithSinks(asset), ) defer importAsset.Close() err = importAsset.Do(pipe.Run) check(err) // track pump track := track.New(bufferSize, asset.NumChannels()) // add samples to track track.AddFrame(198450, asset.Frame(0, 44100)) track.AddFrame(66150, asset.Frame(44100, 44100)) track.AddFrame(132300, asset.Frame(0, 44100)) // wav sink wavSink, err := wav.NewSink( outPath, wavPump.WavSampleRate(), wavPump.WavNumChannels(), wavPump.WavBitDepth(), wavPump.WavAudioFormat(), ) // portaudio sink paSink := portaudio.NewSink( bufferSize, wavPump.WavSampleRate(), wavPump.WavNumChannels(), ) // final pipe p := pipe.New( pipe.WithPump(track), pipe.WithSinks(wavSink, paSink), ) err = p.Do(pipe.Run) }</span></span></code> </pre> </div></div><br><p>  Compared to the previous example, there are two <code>pipe.Pipe</code> .  The first transmits data into memory so that samples can be cut.  The second has just two recipients at the end: <code>wav.Sink</code> and <code>portaudio.Sink</code> .  With this scheme, the sound is simultaneously recorded in a wav file and played. </p><br><h3 id="esche-slozhnee">  Even harder </h3><br><p>  <strong>Task:</strong> read two wav files, mix, process the vst2 plugin and save to a new wav file. </p><br><p>  The <code>phono/mixer</code> package has a simple mixer <code>mixer.Mixer</code> .  You can <strong>send</strong> signals from multiple sources to it and <strong>get</strong> one mixed.  For this, it simultaneously implements <code>pipe.Pump</code> and <code>pipe.Sink</code> . </p><br><p>  Again the task consists of two subtasks.  The first one looks like this: </p><br><ol><li>  <strong>Get</strong> audio wav file </li><li>  <strong>We transfer</strong> audio to the mixer </li></ol><br><p>  The second: </p><br><ol><li>  <strong>Get</strong> audio from the mixer </li><li>  <strong>We process</strong> audio plugin </li><li>  <strong>We transfer</strong> audio to the wav file </li></ol><br><p><img src="https://habrastorage.org/webt/xw/hj/ad/xwhjadlajgapbhjufym72qjgssq.png" alt="example_hard"></p><br><div class="spoiler">  <b class="spoiler_title">Code</b> <div class="spoiler_text"><pre> <code class="go hljs"><span class="hljs-keyword"><span class="hljs-keyword">package</span></span> example <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> ( <span class="hljs-string"><span class="hljs-string">"github.com/dudk/phono"</span></span> <span class="hljs-string"><span class="hljs-string">"github.com/dudk/phono/mixer"</span></span> <span class="hljs-string"><span class="hljs-string">"github.com/dudk/phono/pipe"</span></span> <span class="hljs-string"><span class="hljs-string">"github.com/dudk/phono/vst2"</span></span> <span class="hljs-string"><span class="hljs-string">"github.com/dudk/phono/wav"</span></span> vst2sdk <span class="hljs-string"><span class="hljs-string">"github.com/dudk/vst2"</span></span> ) <span class="hljs-comment"><span class="hljs-comment">// Example: // Read two .wav files // Mix them // Process with vst2 // Save result into new .wav file // // </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">NOTE:</span></span></span><span class="hljs-comment"> For example both wav files have same characteristics ie: sample rate, bit depth and number of channels. // In real life implicit conversion will be needed. func hard() { bs := phono.BufferSize(512) inPath1 := "../_testdata/sample1.wav" inPath2 := "../_testdata/sample2.wav" outPath := "../_testdata/out/example5.wav" // wav pump 1 wavPump1, err := wav.NewPump(inPath1, bs) check(err) // wav pump 2 wavPump2, err := wav.NewPump(inPath2, bs) check(err) // mixer mixer := mixer.New(bs, wavPump1.WavNumChannels()) // track 1 track1 := pipe.New( pipe.WithPump(wavPump1), pipe.WithSinks(mixer), ) defer track1.Close() // track 2 track2 := pipe.New( pipe.WithPump(wavPump2), pipe.WithSinks(mixer), ) defer track2.Close() // vst2 processor vst2path := "../_testdata/Krush.vst" vst2lib, err := vst2sdk.Open(vst2path) check(err) defer vst2lib.Close() vst2plugin, err := vst2lib.Open() check(err) defer vst2plugin.Close() vst2processor := vst2.NewProcessor( vst2plugin, bs, wavPump1.WavSampleRate(), wavPump1.WavNumChannels(), ) // wav sink wavSink, err := wav.NewSink( outPath, wavPump1.WavSampleRate(), wavPump1.WavNumChannels(), wavPump1.WavBitDepth(), wavPump1.WavAudioFormat(), ) check(err) // out pipe out := pipe.New( pipe.WithPump(mixer), pipe.WithProcessors(vst2processor), pipe.WithSinks(wavSink), ) defer out.Close() // run all track1Done, err := track1.Begin(pipe.Run) check(err) track2Done, err := track2.Begin(pipe.Run) check(err) outDone, err := out.Begin(pipe.Run) check(err) // wait results err = track1.Wait(track1Done) check(err) err = track2.Wait(track2Done) check(err) err = out.Wait(outDone) check(err) }</span></span></code> </pre> </div></div><br><p>  There are already three <code>pipe.Pipe</code> , all connected to each other through a mixer.  To run, use the <code>p.Begin(pipe.actionFn) (pipe.State, error)</code> function <code>p.Begin(pipe.actionFn) (pipe.State, error)</code> .  Unlike <code>p.Do(pipe.actionFn) error</code> , it does not block the call, but simply returns a state, which can then be waited with the help of <code>p.Wait(pipe.State) error</code> . </p><br><h2 id="chto-dalshe">  What's next? </h2><br><p>  I want <code>phono</code> become the most convenient application framework.  If there is a problem with sound, you do not need to understand complex APIs and waste time studying standards.  All that is needed is to build a pipeline of suitable elements and start it. </p><br><p>  For half a year, the following packages were washed down: </p><br><ul><li>  <code>phono/wav</code> - read / write wav files </li><li>  <code>phono/vst2</code> - incomplete binding of the VST2 SDK, while you can only open the plugin and call its methods, but not all structures </li><li>  <code>phono/mixer</code> - mixer, adds N signals, without balance and volume </li><li>  <code>phono/asset</code> - buffers sampling </li><li>  <code>phono/track</code> - sequential reading of samples (layered layered) </li><li>  <code>phono/portaudio</code> - reproduction of a signal, while experiments </li></ul><br><p>  In addition to this list, there is a constantly gaining backlog of new ideas and ideas, including: </p><br><ul><li>  Countdown </li><li>  Changeable on the fly pipeline </li><li>  HTTP pump / sink </li><li>  Automation of parameters </li><li>  Ramping processor </li><li>  Balance and volume in the mixer </li><li>  Real-time pump </li><li>  Synchronized pump for multiple tracks </li><li>  Full vst2 </li></ul><br><p>  In the following articles I will analyze: </p><br><ul><li>  <code>pipe.Pipe</code> life cycle - due to the complex structure, its state is controlled by the final atom </li><li>  how to write your pipeline stages </li></ul><br><p>  This is my first open-source project, so I will be grateful for any help and recommendations.  Welcome. </p><br><h2 id="ssylki">  Links </h2><br><ul><li>  <a href="https://github.com/dudk/phono">phono</a> </li><li>  <a href="https://blog.golang.org/pipelines">Go concurrency patterns: Pipelines and Cancellation</a> </li></ul></div>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <p>Source: <a href="https://habr.com/ru/post/424623/">https://habr.com/ru/post/424623/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../424611/index.html">How to create an employee from a freelancer</a></li>
<li><a href="../424613/index.html">Experience of using redux without reducers</a></li>
<li><a href="../424615/index.html">Outputting the curve function for smoothly limiting parameters, signals and not only in Wolfram Mathematica</a></li>
<li><a href="../424619/index.html">Yandex will launch an open top runet site before the end of the year</a></li>
<li><a href="../424621/index.html">Non-carved superheroes. Who and how protects the construction site of Lakhta Center from fires?</a></li>
<li><a href="../424625/index.html">The leak of the source code of web services "Aeroflot"</a></li>
<li><a href="../424627/index.html">Alteration of cash registers. Part 1</a></li>
<li><a href="../424629/index.html">How can a startup increase its chances of investing when communicating with an investor?</a></li>
<li><a href="../424633/index.html">How STACKLEAK Improves Linux Kernel Security</a></li>
<li><a href="../424635/index.html">Welcome to Sberbank Data Science Journey 2018 - a race for machine learning algorithms</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>