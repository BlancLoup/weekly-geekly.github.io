<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Program on PYTHON to determine the authorship of the text by the frequency of occurrence of new words</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Short history of the method 
 In a short publication [1] entitled ‚ÄúAuthorship of Writers Can Be Recognized by a Special Formula‚Äù, it was reported that...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Program on PYTHON to determine the authorship of the text by the frequency of occurrence of new words</h1><div class="post__text post__text-html js-mediator-article"><h3>  Short history of the method </h3><br>  In a short publication [1] entitled ‚ÄúAuthorship of Writers Can Be Recognized by a Special Formula‚Äù, it was reported that in the scientific journal New Journal of Physics, a group of Swedish physicists from Ume√• University, under the guidance of Sebastian Berngardson, described a new method that allows identify the author of the text.  Researchers tested how in the texts of three writers - Thomas Hardy, Henry Melville and David Lawrence - the so-called Zipf's law is implemented.  The researchers found that the frequency of the emergence of new words with the growth of the volume of the text varies from different authors in different ways, and this pattern does not depend on the specific text, but only on the author. <br><br>  This message was published on December 11, 2009, and more than twenty years ago, John Charles Baker [2] introduced a unit to measure the author's ability to use new words (here the term "new" is interpreted as not previously used in this text).  John proved that this unit is an individual characteristic of the author. <br><br>  In periodicals and online there is no information on the implementation of the Zipf law to determine authorship.  Therefore, my work is the first scientific research in this area. <br><a name="habracut"></a><br><h3>  Full program code </h3><br><pre><code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#!/usr/bin/python # -*- coding: utf-8 -*- import nltk from nltk import * from nltk.corpus import brown stop_words= nltk.corpus.stopwords.words('english') import numpy as np import matplotlib.pyplot as plt import matplotlib as mpl mpl.rcParams['font.family'] = 'fantasy' mpl.rcParams['font.fantasy'] = 'Comic Sans MS, Arial' from nltk.stem import SnowballStemmer stop_symbols = '.,!?:;"-\n\r()' def comor_text(): #   NLTK -     stemmer = SnowballStemmer('english') #    if len(txt.get(1.0,END))!=1 and len(txt1.get(1.0,END))!=1 and len(txt2.get(1.0,END))!=1: mrus=[txt.get(1.0,END),txt1.get(1.0,END),txt2.get(1.0,END)] mr=3 #      elif len(txt.get(1.0,END))!=1 and len(txt1.get(1.0,END))!=1 and len(txt2.get(1.0,END))==1: mrus=[txt.get(1.0,END),txt1.get(1.0,END)] mr=2 elif len(txt.get(1.0,END))!=1 and len(txt1.get(1.0,END))==1 and len(txt2.get(1.0,END))==1: mrus=[txt.get(1.0,END)] mr=1 else: txt3.insert(END,"There are no all texts") return # ,        for text in mrus: v=([stemmer.stem(x) for x in [y.strip(stop_symbols) for y in text.lower().split()] if x and (x not in stop_words)]) #     -  my_dictionary=dict([]) z=[] for w in v: if w in my_dictionary: my_dictionary[w]+=1 else: my_dictionary[w]=1 max_count=int(txt5.get(1.0,END)) min_count=int(txt4.get(1.0,END)) if len(my_dictionary)&lt;max_count: txt3.insert(END,"It is not enough of words for the analysis ") return #     -   my_dictionary_z=dict([]) for key,val in my_dictionary.items(): if val in my_dictionary_z: my_dictionary_z[val]+=1 else: my_dictionary_z[val]=1 z.append(val) z.sort(reverse=True) #         e=z[ min_count:max_count] ee=[my_dictionary_z[val] for val in z][ min_count:max_count] ee=np.arange(len(my_dictionary))[ min_count:max_count] if text==mrus[0]: #    -a,b    + %   zz=round((float(len(my_dictionary))*100)/(float(len(v))),0) tt=('In total of words (Text-1) --%i. New words --%i. Percen new words-- %i'%( len(v),len( my_dictionary),int(zz))) xData1 = ee yData1 = e z=[1/w for w in ee] z1=[(1/w)**2 for w in ee] t=[ round(e[i]/ee[i],4) for i in range(0,len(ee)) ] a=round((sum(e)*sum(z1)-sum(z)*sum(t))/(len(ee)*sum(z1)-sum(z)**2),3) b=round((len(ee)*sum(t)-sum(z)*sum(e))/(len(ee)*sum(z1)-sum(z)**2),3) y1=[round(a+b/w ,4) for w in ee] s=[round((y1[i]-e[i])**2,4) for i in range(0,len(ee))] sko=round(round((sum(s)/(len(ee)-1))**0.5,4)/(sum(y1)/len(ee)),4) tg='Factor --a '+str(a)+' Factor--b '+str(b)+' Mistake of approximation-- '+str(sko)+"%"+"\n"+tt txt3.delete(1.0, END) txt3.insert(END,tg) txt3.insert(END,'\n') y1Data1=y1 elif text==mrus[1]:#   -a,b    + %   zz=round((float(len(my_dictionary))*100)/(float(len(v))),0) tt=('In total of words (Text-2) --%i. New words --%i. Percent new words-- %i'%( len(v),len( my_dictionary),int(zz))) xData2 = ee yData2=e z=[1/w for w in ee] z1=[(1/w)**2 for w in ee] t=[ round(e[i]/ee[i],4) for i in range(0,len(ee)) ] a=round((sum(e)*sum(z1)-sum(z)*sum(t))/(len(ee)*sum(z1)-sum(z)**2),3) b=round((len(ee)*sum(t)-sum(z)*sum(e))/(len(ee)*sum(z1)-sum(z)**2),3) y1=[round(a+b/w ,4) for w in ee] s=[round((y1[i]-e[i])**2,4) for i in range(0,len(ee))] sko=round(round((sum(s)/(len(ee)-1))**0.5,4)/(sum(y1)/len(ee)),4) tg='Factor --a '+str(a)+' Factor--b '+str(b)+' Mistake of approximation-- '+str(sko)+"%"+"\n"+tt txt3.insert(END,tg) txt3.insert(END,'\n') y1Data2=y1 elif text==mrus[2]:#   -a,b    + %   zz=round((float(len(my_dictionary))*100)/(float(len(v))),0) tt=('In total of words (Text-3) --%i. New words --%i. Percent new words-- %i'%( len(v),len( my_dictionary),int(zz))) xData3 = ee yData3=e z=[1/w for w in ee] z1=[(1/w)**2 for w in ee] t=[ round(e[i]/ee[i],4) for i in range(0,len(ee)) ] a=round((sum(e)*sum(z1)-sum(z)*sum(t))/(len(ee)*sum(z1)-sum(z)**2),3) b=round((len(ee)*sum(t)-sum(z)*sum(e))/(len(ee)*sum(z1)-sum(z)**2),3) y1=[round(a+b/w ,4) for w in ee] s=[round((y1[i]-e[i])**2,4) for i in range(0,len(ee))] sko=round(round((sum(s)/(len(ee)-1))**0.5,4)/(sum(y1)/len(ee)),4) tg='Factor --a '+str(a)+' Factor--b '+str(b)+' Mistake of approximation-- '+str(sko)+"%"+"\n"+tt txt3.insert(END,tg) txt3.insert(END,'\n') y1Data3=y1 if mr==3: #        +      r12=round(sum([abs(yData1[i]-yData2[i]) for i in range(0,len(xData1))])/len(xData1),3) txt3.insert(END,"Average distances between art products of the author K--"+ str(r12)) txt3.insert(END,'\n') r13=round(sum([abs(yData1[i]-yData3[i]) for i in range(0,len(xData1))])/len(xData1),3) txt3.insert(END,"Average distance between art products of the authors K and M--"+ str(r13)) txt3.insert(END,'\n') plt.title('Distribution of frequencies of use of words in the text', size=14) plt.xlabel('Serial number of new words', size=14) plt.ylabel('Frequency of the use of new words', size=14) plt.plot(xData1, yData1, color='r', linestyle=' ', marker='o', label='Test art product of the author -') plt.plot(xData1, y1Data1, color='r',linewidth=2, label='Approximation of hyperbola y=(b/x)+a') plt.plot(xData2, yData2, color='g', linestyle=' ', marker='o', label='Comparable art product of the author -') plt.plot(xData2, y1Data2, color='g',linewidth=2, label='Approximation of hyperbola y=(b/x)+a') plt.plot(xData3, yData3, color='b', linestyle=' ', marker='o', label='Art product of the author -') plt.plot(xData3, y1Data3, color='b',linewidth=2, label='Approximation of hyperbola y=(b/x)+a') plt.legend(loc='best') plt.grid(True) plt.show() elif mr==2:#        +      r12=round(sum([abs(yData1[i]-yData2[i]) for i in range(0,len(xData1))])/len(xData1),3) txt3.insert(END,"Average distances between art products of the author K--"+ str(r12)) txt3.insert(END,'\n') plt.title('Distribution of frequencies of use of words in the text', size=14) plt.xlabel('Serial number of new words', size=14) plt.ylabel('Frequency of the use of new words', size=14) plt.plot(xData1, yData1, color='r', linestyle=' ', marker='o', label='Test art product of the author -') plt.plot(xData1, y1Data1, color='r',linewidth=2, label='Approximation of hyperbola y=(a/x)+b') plt.plot(xData2, yData2, color='g', linestyle=' ', marker='o', label='Comparable art product of the author -') plt.plot(xData2, y1Data2, color='g',linewidth=2, label='Approximation of hyperbola y=(a/x)+b') plt.legend(loc='best') plt.grid(True) plt.show() elif mr==1: #       plt.title('Distribution of frequencies of use of words in the text', size=14) plt.xlabel('Serial number of new words', size=14) plt.ylabel('Frequency of the use of new words', size=14) plt.plot(xData1, yData1, color='r', linestyle=' ', marker='o', label='Test art product of the author -') plt.plot(xData1, y1Data1, color='r',linewidth=2, label='Approximation of hyperbola y=(a/x)+b') plt.grid(True) plt.show() def choice_text():#      try: op = askopenfilename() f=open(op, 'r') st=f.read() f.close() if len(txt.get(1.0,END))==1: txt.insert(END,st) elif len(txt1.get(1.0,END))==1: txt1.insert(END,st) elif len(txt2.get(1.0,END))==1: txt2.insert(END,st) except: pass def array_text_1 ():#       UNICODE if len(txt.get(1.0,END))!=1: u=txt.get(1.0,END) else: txt3.insert(END,"There are no text ‚Ññ1") return op=1 processing_subjects (u,op) def array_text_2 ():#       UNICODE if len(txt1.get(1.0,END))!=1: u=txt1.get(1.0,END) else: txt3.insert(END,"There are no text ‚Ññ2") return op=2 processing_subjects (u,op) def array_text_3 ():#       UNICODE if len(txt2.get(1.0,END))!=1: u=txt2.get(1.0,END) else: txt3.insert(END,"There are no text ‚Ññ3") return op=3 processing_subjects (u,op) def processing_subjects (u,op):#    ( NLTK+corpusbrown) q= nltk.word_tokenize(u) qq=[w for w in q if len(w)&gt;2] z=nltk.pos_tag(qq) m=[w[0].lower() for w in z if w[1]=="NN"] d={} for w in m: if w in d: d[w]+=1 else: d[w]=1 pairs = list(d.items()) pairs.sort(key=lambda x: x[1], reverse=True) modals=[] wq=10 for i in pairs[0:wq]: modals.append(i[0]) cfd = nltk.ConditionalFreqDist( (genre, word) for genre in brown.categories() for word in brown.words(categories=genre)) #    genres=['news', 'editorial', 'reviews', 'religion', 'hobbies', 'lore', 'belles_lettres', 'government', 'learned', 'fiction', 'mystery', 'science_fiction', 'adventure', 'romance', 'humor'] sys.stdout = open('out.txt', 'w') cfd.tabulate(conditions=genres, samples=modals) sys.stdout.close()#   f=open('out.txt', 'r') w=f.read() txt3.insert(END,w) f.close() sys.stdout = open('out.txt', 'w') cfd.tabulate(conditions=genres, samples=modals) sys.stdout.close() f=open('out.txt', 'r') b=0 u={} for i in f: b=b+1 if b&gt;=2: d=i.split() c=d[1:len(d)] e=[int(w) for w in c] u[d[0]]=sum(e) for key, val in u.items(): if val == max(u.values()): tex="Text ‚Ññ -%i- Theme-- %s. Concurrences- %i"%(op,key,val) txt3.insert(END,tex) txt3.insert(END,'\n') f.close() cfd.plot(conditions=genres, samples=modals) def close_win(): tk.destroy() #  tkinter + +   +   import tkinter as T from tkinter.filedialog import * import tkinter.filedialog import fileinput tk=T.Tk() tk.geometry('630x630') main_menu = Menu(tk) tk.config(menu=main_menu) file_menu = Menu(main_menu) main_menu.add_cascade(label="The comparative analysis of the art texts", menu=file_menu) file_menu.add_command(label="Choice of the texts", command=choice_text) file_menu.add_command(label="Definition of subjects of the text-1", command=array_text_1) file_menu.add_command(label="Definition of subjects of the text-2", command=array_text_2) file_menu.add_command(label="Definition of subjects of the text-3", command=array_text_3) file_menu.add_command(label="Definition of the author of the text", command=comor_text) file_menu.add_command(label="Exit from the program", command=close_win) lab =Label(tk, text="The text for comparison author -K ", font=("Arial", 12, "bold "),foreground='red') lab.pack() txt= Text(tk, width=66,height=5,font=("Arial", 12, "bold "),foreground='red',wrap=WORD) txt.pack() lab1 = Label(tk, text="The test author -K",font=("Arial", 12, "bold "),foreground='green') lab1.pack() txt1= Text(tk, width=66,height=5,font=("Arial", 12, "bold "),foreground='green',wrap=WORD) txt1.pack() lab2 = Label(tk, text="The text author-M", font=("Arial", 12, "bold "),foreground='blue') lab2.pack() txt2= Text(tk, width=66,height=5,font=("Arial", 12, "bold "),foreground='blue',wrap=WORD) txt2.pack() lab3 = Label(tk, text="Text results of comparison", font=("Arial", 12, "bold"),foreground='black') lab3.pack() txt3= Text(tk, width=66,height=6,font=("Arial", 12, "bold"),foreground='black',wrap=WORD) txt3.pack() lab4 = Label(tk, text="Minimum quantity of words in a window ", font=("Arial", 12, "bold"),foreground='black') lab4.pack() txt4= Text(tk, width=8,height=1,font=("Arial", 12, "bold"),foreground='black',wrap=WORD) wd=10 txt4.pack() txt4.insert(END,wd) lab5 = Label(tk, text="Maximum quantity of words in a window ", font=("Arial", 12, "bold"),foreground='black') lab5.pack() txt5= Text(tk, width=8,height=1,font=("Arial", 12, "bold"),foreground='black',wrap=WORD) wd=90 txt5.pack() txt5.insert(END,wd) tk.title('The analysis of the art text') x = (tk.winfo_screenwidth() - tk.winfo_reqwidth()) /4#  y = (tk.winfo_screenheight() - tk.winfo_reqheight()) / 16#  tk.wm_geometry("+%d+%d" % (x, y))#  tk.mainloop()</span></span></code> </pre> 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Features of the program I developed: <br><br><ol><li>  The possibility of separate analysis on the first and second Zipf law of each document. </li><li>  The ability to separately determine the genre of each document (implementation with the redistribution of data flow). </li><li>  Movable, dynamic window for selecting a site of rank or number of words directly in the process of analysis. </li><li>  Color marking of the analyzed documents with their graphic implementation. </li><li>  The ability to make changes to the document directly in the analysis process (if there are not identifiable characters in the document). </li></ol><br><br>  To test the work of the program, works of famous English-speaking writers were used. <br><br>  A comparative analysis of the works of <b>Dan Brown ‚ÄúThe Davinchi Code‚Äù and ‚ÄúAngels and Demons‚Äù and Robert Ladlam ‚ÄúBorne Identification‚Äù is given.</b> <br><br><h3>  Program interface </h3><br><br>  Grimer for comparative analysis of authorship of the works of Dan Brown and Robert Ludlam. <br><br><img src="https://habrastorage.org/files/d7c/1dd/4c7/d7c1dd4c75a0439784d7e78c298e3b16.JPG"><br><h3>  Listing of results </h3><br><img src="https://habrastorage.org/files/091/92f/06a/09192f06a27b497bb0273dc7cec1347c.JPG"><br><br><h3>  Schedule </h3><br><img src="https://habrastorage.org/files/d3f/4b0/27a/d3f4b027ae0b40f68f316adbf8b8560d.JPG"><br><br>  In the first two fields of the form we load different works of one author, and in the third of the other. <br><br>  To determine the genre of works, select from the text of the work the key nouns or modal verbs.  These can be either single words or phrases.  From a specially marked body (I used Brown).  The genre is determined by the maximum number of occurrences of the selected words. <br><br>  Making sure that all the texts of one genre can begin to analyze the authorship.  To solve particular problems, for example for analyzing technical texts, you can create your own database of topics. <br><br><img src="https://habrastorage.org/files/e8d/5a1/254/e8d5a1254619436e82b08eaa9d76caa4.JPG"><br><br><h3>  Listing of results </h3><br><pre> <code class="hljs coffeescript">Factor --a <span class="hljs-number"><span class="hljs-number">91.184</span></span> Factor--b <span class="hljs-number"><span class="hljs-number">2297.14</span></span> Mistake <span class="hljs-keyword"><span class="hljs-keyword">of</span></span> approximation-- <span class="hljs-number"><span class="hljs-number">0.0511</span></span>% In total <span class="hljs-keyword"><span class="hljs-keyword">of</span></span> words (Text<span class="hljs-number"><span class="hljs-number">-1</span></span>) -<span class="hljs-number"><span class="hljs-number">-81020.</span></span> New words -<span class="hljs-number"><span class="hljs-number">-11120.</span></span> Percent <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> words-- <span class="hljs-number"><span class="hljs-number">14</span></span> Factor --a <span class="hljs-number"><span class="hljs-number">100.21</span></span> Factor--b <span class="hljs-number"><span class="hljs-number">2869.22</span></span> Mistake <span class="hljs-keyword"><span class="hljs-keyword">of</span></span> approximation-- <span class="hljs-number"><span class="hljs-number">0.0965</span></span>% In total <span class="hljs-keyword"><span class="hljs-keyword">of</span></span> words (Text<span class="hljs-number"><span class="hljs-number">-2</span></span>) -<span class="hljs-number"><span class="hljs-number">-86079.</span></span> New words -<span class="hljs-number"><span class="hljs-number">-11868.</span></span> Percent <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> words-- <span class="hljs-number"><span class="hljs-number">14</span></span> Factor --a <span class="hljs-number"><span class="hljs-number">154.162</span></span> Factor--b <span class="hljs-number"><span class="hljs-number">4982.418</span></span> Mistake <span class="hljs-keyword"><span class="hljs-keyword">of</span></span> approximation-- <span class="hljs-number"><span class="hljs-number">0.0433</span></span>% In total <span class="hljs-keyword"><span class="hljs-keyword">of</span></span> words (Text<span class="hljs-number"><span class="hljs-number">-3</span></span>) -<span class="hljs-number"><span class="hljs-number">-128217.</span></span> New words -<span class="hljs-number"><span class="hljs-number">-10626.</span></span> Percent <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> words-- <span class="hljs-number"><span class="hljs-number">8</span></span> Average distances between art products <span class="hljs-keyword"><span class="hljs-keyword">of</span></span> the author K-<span class="hljs-number"><span class="hljs-number">-25.062</span></span> Average distance between art products <span class="hljs-keyword"><span class="hljs-keyword">of</span></span> the authors K <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> M-<span class="hljs-number"><span class="hljs-number">-138.25</span></span></code> </pre> <br><h3>  Comparison chart </h3><br><img src="https://habrastorage.org/files/89b/55e/523/89b55e523c744a77a7a09713002561eb.JPG"><br><br>  From the given printout and graphics, the authors' individuality is visible: K is green and red curves and M is a blue curve.  The average distance between the approximating hyperbolas of the author K is 25.062, and between the first work of the author K and the product of the author M - 138.25. <br><br>  The program builds a fragment for the number of words from 10 to 90 according to the second Zipf Law ‚îÄ ‚Äúquantity - frequency‚Äù [4].  Zipf found that the frequency and number of words in the text with this frequency are also related. <br><br><h3>  Special formula </h3><br><img src="https://habrastorage.org/files/85f/8e9/baa/85f8e9baab1d41629fef43c4d68825bb.JPG"><br><br><ul><li><img src="https://habrastorage.org/files/4d4/60d/189/4d460d189d6a44c1b54407e96ae83cf2.JPG">  ‚îÄ hyperbolic approximation coefficients and approximation errors for the author K; <br><br></li><li><img src="https://habrastorage.org/files/41f/7f2/f38/41f7f2f3835e466b90d0dc4ef935ab56.JPG">  ‚îÄ coefficients of hyperbolic approximation and approximation error for the author M; <br><br><img src="https://habrastorage.org/files/cf7/c81/6a4/cf7c816a44d14b75abf00c830b3ac8bb.JPG"><br><br></li><li><img src="https://habrastorage.org/files/006/253/58d/00625358dc8c407fa8e42eeb12c29f69.JPG">  ‚îÄ The range for the number of words is adjustable during the analysis of the graph. </li></ul><br>  Inequality (1) I checked on 50 triples the works of English-speaking authors.  I have no more statistics.  Those who want inequality (1) in justice can check it with their examples. <br><br><h3>  Conclusion </h3><br>  The implementation of the method of determining the authorship of texts in terms of the frequency of using new words in Python is considered.  A formula is given for a comparative analysis of three texts, two of which are by one author and the third one.  An example is given for a comparative analysis of works by Dan Brown and Robert Ludlam. <br><br><h3>  Links </h3><br><ol><li>  <a href="http://mignews.com.ua/science/nauka/2531956.html">Authorship of writers can be recognized by a special formula</a> . </li><li>  This article was published on January 1, 1988 in the Literary and Linguistic Computing Volume Report. </li><li>  <a href="https://habrahabr.ru/post/322954/">Simple Python program for hyperbolic approximation of statistical data</a> </li><li>  <a href="http://tpl-it.wikispaces.com/%25D0%2597%25D0%25B0%25D0%25BA%25D0%25BE%25D0%25BD%25D1%258B%2B%25D0%2597%25D0%25B8%25D0%25BF%25D1%2584%25D0%25B0%2B%2528%25D0%25A6%25D0%25B8%25D0%25BF%25D1%2584%25D0%25B0%2529">Zipf</a> (Zipf) <a href="http://tpl-it.wikispaces.com/%25D0%2597%25D0%25B0%25D0%25BA%25D0%25BE%25D0%25BD%25D1%258B%2B%25D0%2597%25D0%25B8%25D0%25BF%25D1%2584%25D0%25B0%2B%2528%25D0%25A6%25D0%25B8%25D0%25BF%25D1%2584%25D0%25B0%2529">Laws</a> </li></ol></div><p>Source: <a href="https://habr.com/ru/post/323206/">https://habr.com/ru/post/323206/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../323194/index.html">What are the authors of ‚ÄúHello World?‚Äù Silent</a></li>
<li><a href="../323198/index.html">Dagaz: From simple to complex</a></li>
<li><a href="../323200/index.html">Power BI Embedded, IoT and machine learning for processing brain thermograms</a></li>
<li><a href="../323202/index.html">Web scraper development to extract data from the open data portal of Russia data.gov.ru</a></li>
<li><a href="../323204/index.html">Apache Ant - quick start</a></li>
<li><a href="../323208/index.html">Nginx + PHP 7.1.1 FPM vs Node.js 7.7.1 as part 2 backend</a></li>
<li><a href="../323210/index.html">Open machine learning course. Topic 2: Data Visualization with Python</a></li>
<li><a href="../323212/index.html">Where the games go: the problem of preserving old video games. Part 1</a></li>
<li><a href="../323214/index.html">React Native - one JS is not enough</a></li>
<li><a href="../323220/index.html">Chronic Fatigue Syndrome. What it is, causes and consequences</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>