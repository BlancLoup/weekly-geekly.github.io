<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>How to expand Kubernetes</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Today we will talk about DevOps, or rather, mostly about Ops. They say that there are very few people who are satisfied with the level of automation o...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>How to expand Kubernetes</h1><div class="post__text post__text-html js-mediator-article">  Today we will talk about DevOps, or rather, mostly about Ops.  They say that there are very few people who are satisfied with the level of automation of their operations.  But it seems that the situation is fixable.  In this article, Nikolai Ryzhikov will talk about his experience in expanding Kubernetes. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b1a/4f7/1a2/b1a4f71a2809a5b098e738ed4e0b5d3f.png"><br><br>  The material was prepared on the basis of Nikolay's speech at the autumn DevOops 2017 conference. Under the cut - video and text transcript of the report. <br><a name="habracut"></a><br><iframe width="560" height="315" src="https://www.youtube.com/embed/3BMTNx2xCtQ" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      <i>At the moment, Nikolai Ryzhikov is working in the Health-IT sector to create medical information systems.</i>  <i>Member of the St. Petersburg community of functional programmers FPROG.</i>  <i>An active member of the Online Clojure community, a member of the HL7 FHIR standard for the exchange of medical information.</i>  <i>Engaged in programming for 15 years.</i> <br><hr><br>  Which side do we treat DevOps?  Our DevOps formula for the past 10 years is quite simple: developers are responsible for operations, developers are deployed, developers are mainten.  With this arrangement, which looks a bit harsh, you will in any case become DevOps.  If you want to implement DevOps quickly and painfully - make the developers responsible for your production.  If the guys are smart, they will start to get out and understand everything. <br><img src="https://habrastorage.org/getpro/habr/post_images/8f4/799/e0d/8f4799e0d6f25b897b6bd72f2ba1081a.png"><br>  Our story: long ago, when there were no Chefs and automations yet, we already deployed the automatic Capistrano.  Then they began to bore it to make it fashionable.  But then Chef appeared.  We switched to it and left for the cloud: we were tired of our data centers.  Then Ansible appeared, Docker appeared.  After that, we moved to Terraform with a hand-written supervisor for Condo dockers at Camel.  And now we are moving to Kubernetes. <br><img src="https://habrastorage.org/getpro/habr/post_images/366/af1/be8/366af1be8b4c4cf204553b48c8a76e70.png"><br>  What is the worst thing about operations?  Very few people are satisfied with the level of automation of their operations.  It's scary, I confirm: we spent a lot of resources and efforts to collect all these stacks for ourselves, and the result is unsatisfactory. <br><br>  There is a feeling that with the arrival of Kubernetes something can change.  I am an adherent of lean manufacturing and, from his point of view, operations are not beneficial at all.  Perfect operations are the absence or minimum of operations in a project.  Value is created when a developer makes a product.  When it is ready, the delivery does not add value.  But you need to reduce costs. <br><img src="https://habrastorage.org/getpro/habr/post_images/731/1a4/6e3/7311a46e3eb4d1d73d788f6ee881be3a.png"><br>  For me, the ideal has always been heroku.  We used it for simple applications, where the developer, to deploy his service, was enough to say git push and configure heroku.  It takes a minute. <br><img src="https://habrastorage.org/getpro/habr/post_images/a57/4c0/12b/a574c012ba1158086cd3578287d6d2a9.png"><br>  How to be?  You can buy NoOps - also heroku.  And I advise you to buy, otherwise there is a chance to spend more money on developing normal operations. <br><br>  There are guys Deis, they are trying to do something like heroku on Kubernetes.  There is a cloud foundry, which also provides a platform on which to work. <br><img src="https://habrastorage.org/getpro/habr/post_images/bbd/7b9/7e0/bbd7b97e07aae6af9a54663d633e3cc2.png"><br>  But if you bother with something more complex or large, you can do it yourself.  Now with Docker and Kubernetes, this becomes a task that can be accomplished in a reasonable amount of time at a reasonable cost.  Once it was too hard. <br><img src="https://habrastorage.org/getpro/habr/post_images/299/2d2/90a/2992d290a7167b9fe4a8cf2320528b8e.png"><br><h2>  A bit about Docker and Kubernetes </h2><br>  One of the problems of operations is repeatability.  The wonderful thing that the docker introduced is two phases.  We have a build phase. <br><br>  The second point that pleases docker is a universal interface for launching arbitrary services.  Someone gathered Docker, put something inside, and operations just say Docker run and run. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/0b4/ca2/5ad/0b4ca25ade4ae7d3513539aaa576d3e7.png"><br><br>  What is Kubernetes?  So we made the Docker and we need to run it somewhere, combine, configure and connect it with others.  Kubernetes allows you to do this.  He introduces a series of abstractions, which are called "resource".  We quickly go through them and even try to create. <br><br><h2>  Abstractions </h2><br>  The first abstraction is a POD or set of containers.  Properly done, what exactly is a <b>set of</b> containers, not just one.  Sets can fumble among themselves volumes that see each other through localhost.  This allows you to use such a pattern as sidecar (this is when we launch the main container, and next to it there are auxiliary containers that help it). <br><br>  For example, the ambassador approach.  This is when you do not want the container to think about where some services are located.  You put a container next to it that knows where these services lie.  And they become available to the main container on localhost.  Thus, the environment begins to look like you are working locally. <br><img src="https://habrastorage.org/getpro/habr/post_images/0b8/ab5/bda/0b8ab5bdae5f0d0e7375ff1b08efc6ee.png"><br>  Let's raise the POD and see how it is described.  You can develop minikube locally.  It eats up a bunch of CPUs, but allows you to raise a small Kubernetes cluster on the virtualbox and work with it. <br><br>  Let's close up the POD.  I said Kubernetes apply and uploaded the POD.  I can see what kind of PODs I have: I see that one POD has been captured.  This means that Kubernetes has launched these containers. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/970/862/d90/970862d90a9afea1066caa69c1af63c8.png"></div><br>  I can even go into this container. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/122/603/8f7/1226038f78d2c9593826e7f26d611853.png"></div><br>  From this point of view, Kubernetes is made for people.  Indeed, what we constantly do in operations, in the Kubernetes harness, for example, using the kubectl utility, can be done easily. <br><br>  But POD is mortal.  It runs as a docker run: if someone stops it, no one will raise it.  On top of this abstraction, Kubernetes starts building the next one ‚Äî for example, replicaset.  This is such a supervisor who watches the POD, watches their number, and if the PODs fall, it re-raises them.  This is an important self-healing concept in Kubernetes, which allows you to sleep at night. <br><br>  On top of the replicaset there is an abstraction. Deployment is also a resource that allows zero time deployment.  For example, one replicaset works.  When we deploy and change the version of the container, for example, ours, inside the deployment, another replicaset rises.  We wait for these containers to start, pass their health checks, and then we quickly switch to a new replicaset.  Also a classic and good practice. <br><img src="https://habrastorage.org/getpro/habr/post_images/02e/d07/f33/02ed07f333733af0155ee539be18c669.png"><br>  Let's raise a simple service.  For example, we have deployment.  Inside, he describes the POD template that he will raise.  We can apply this deployment, see what we have.  Cool feature Kubernetes - everything is in the database, and we can see what is happening in the system. <br><br>  Here we see one deployment.  If we try to look at the PODs, then we see that some POD has risen.  We can take and delete this POD.  What happens to PODs?  One is destroyed, and the second rises immediately.  This replicaset controller did not find the desired POD and launched another one. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/524/7f4/0d4/5247f40d4fb21eb93bda0ce14124245e.png"></div><br>  Further, if this is some kind of web service, or inside our services must be connected, service discovery is needed.  You must give the service a name and entry point.  For this Kubernetes offers a resource called service.  He may engage in load balancing and be responsible for service discovery. <br><img src="https://habrastorage.org/getpro/habr/post_images/2fa/926/6e5/2fa9266e57c6718a81241ae1ac15da8e.png"><br>  Let's see a simple service.  We associate it with deployment and POD via labels: such dynamic binding.  A very important concept in Kubernetes: the system is dynamic.  It doesn't matter in what order it will be created.  Service will try to find PODs with such labels and start their load balance. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/b48/992/f7d/b48992f7dca832fce9b45276936a4914.png"></div><br>  Applaim service, we look, what services we have.  Go to our test POD, which was raised, and do nslookup.  Kubernetes gives us a DNS, through which services can see and detect each other. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/b05/66f/01e/b0566f01e54210ea26c5b6526b0ed0de.png"></div><br>  Service is rather an interface.  There are several different implementations there, because the load balancing and service tasks are quite complex: in one way we work with regular databases, with other ones with loaded ones, and some simple ones we do in a very simple way.  This is also an important concept in Kubernetes: some things can be called interfaces rather than implementations.  They are not rigidly fixed, and different, for example, cloud providers provide different implementations.  Ie, for example, there is a persistent volume resource, which is already implemented in each specific cloud by its own standard means. <br><br>  Next, we usually want to bring the web service somewhere outside.  There is an ingress abstraction in Kubernetes.  Usually SSL is added there. <br><img src="https://habrastorage.org/getpro/habr/post_images/fc7/69e/4e7/fc769e4e7a526588c3f3ae32388d9c11.png"><br>  The simplest ingress looks something like this.  There we write the rules: by what url, by which hosts, to which internal service to redirect the request.  Similarly, we can raise and our ingress. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/69d/79c/046/69d79c046478f1fde2a073f2fe37067f.png"></div><br>  Then, having registered locally in hosts, you can see this service from here. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/73d/752/75c/73d75275c26a468f49cd192e781595db.png"></div><br>  This is such a regular task: we have deployed a web service, a little bit acquainted with Kubernetes. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/1a3/1f8/c2f/1a31f8c2f639a4758d95719ee6dca1e0.png"></div><br>  We clean out all this, remove the ingress and look at all the resources. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/c75/990/40c/c7599040cd85c2c155e8acf057be0246.png"></div><br>  There are a number of resources, such as configmap and secret.  These are purely informational resources that you can deposit into a container and transfer there, for example, the password from postgres.  You can associate this with environment variables that will be injected into the container during startup.  You can mount the file system.  Everything is quite convenient: standard tasks, nice solutions. <br><br>  There is a persistent volume - an interface that is implemented differently for different cloud providers.  It is divided into two parts: there is a persistent volume claim (request), and then some kind of EBS-ka is created, which is dragged to the container.  You can work with a stateful service. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/cd6/5c1/2f7/cd65c12f71d417ffd11e3e62c76b484c.png"><br><br>  But how does it work inside?  The concept itself is very simple and transparent.  Kubernetes consists of two parts.  One is just a database in which we have all these resources.  Resources can be represented as labels: specifically, these instances are just records in labels.  An API server is configured on top of Kubernetes.  That is, when you have Kubernetes cluster, you usually communicate with the API server (more precisely, the client communicates with it). <br><br>  Accordingly, what we created (PODs, services, etc.) is simply written to the database.  This database is implemented by ETCD, i.e.  so that it is stable at the high-available level. <br><br>  What is being done next?  Further under each type of resources there is a certain controller.  It is just a service that monitors its type of resource and does something in the outside world.  For example, does the docker run.  If we have a POD, for each Node there is a kubelet-service that monitors the PODs that are on this node.  And all he does is a Docker run after a regular periodic check, if this POD is not. <br><br>  Further, which is very important - everything happens in real time, so the power of this controller is above the minimum.  Often, the controller still removes metrics and looks at what it has launched.  Those.  removes feedback from the real world and writes it to the database so that you or other controllers can see it.  For example, the same POD status will be written back to the ETCD. <br><br>  Thus, everything is implemented in Kubernetes.  It is very cool that the information model is separated from the operating room.  In the database, through the usual CRUD interface, we declare what should be.  Then a set of controllers tries to make it all right.  True, this is not always the case. <br><br>  This is a cybernetic model.  We have a certain preset, there is some kind of machine that is trying to direct the real world or the machine into the place that is needed.  It doesn't always work that way: we should have a feedback loop.  Sometimes the machine can not do this and should appeal to the person. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/59e/0a9/1e8/59e0a91e8974351a5f0f49fd94709c9a.png"><br><br>  In real systems, we think of abstractions of the next level: we have certain services, databases, and we connect all this.  We do not think of PODs and Ingress, and we want to build some next level of abstraction. <br><img src="https://habrastorage.org/getpro/habr/post_images/77f/5cb/697/77f5cb6974c6ac85e0b5e8b13921d672.png"><br>  So that the developer was as easy as possible: so that he simply said, ‚ÄúI want to launch such a service,‚Äù and everything else happened inside. <br><br>  There is such a thing as HELM.  This is the wrong way - the template is ansible style, where we are just trying to generate a set of configured resources and throw them into the Kubernetes cluster. <br><br>  The problem, firstly, is that this is done only at the moment of rolling.  That is a lot of logic, he can not implement.  Secondly, in abstraction, this abstraction disappears.  When I go to look at my cluster, I just see the PODs and services.  I do not see that such and such a service is affected, that such a base with replication is raised there.  I just see there are dozens of pods.  Abstraction disappears in the matrix. <br><img src="https://habrastorage.org/getpro/habr/post_images/696/6e6/9bd/6966e69bd8b289229194911f62a11f84.png"><br><h2>  Internal Solution Model </h2><br>  On the other hand, Kubernetes itself already inside gives a very interesting and simple extension model.  We can announce new types of resources, such as deployment.  This is a resource built on top of a POD or replicaset.  We can write a controller to this resource, put this resource in the base and launch our cybernetic loop so that everything works.  It sounds interesting, and I think this is the right way to expand Kubernetes. <br><img src="https://habrastorage.org/getpro/habr/post_images/39e/491/c51/39e491c511ea25078eda191097d88b24.png"><br>  I would like to be able to just write a kind of manifest for my service in the heroku style.  A very simple example: I want to enclose some kind of application in my real environment.  There are already agreements, SSL, domains purchased.  I just wanted to give developers the easiest interface possible.  Manifest tells me which container to lift, what resources still need this container.  He casts this ad in the cluster, and everything starts to work. <br><img src="https://habrastorage.org/getpro/habr/post_images/a91/24e/8a8/a9124e8a8309c952cc0a65b32f28d76f.png"><br><br>  What will it look like in terms of custom resources and controllers?  Here we will have to be in the resource application database.  And the application controller will spawn three resources.  That is, he will register in ingress rules on how to route to this service, start the service for load balancing and launch the deployment with some configuration. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/807/938/d22/807938d229cb312ca761214fa30829ed.png"><br><br>  Before we create a custom resource in Kubernetes, we need to declare it.  For this, there is a meta-resource called CustomResourceDefinition. <br><br>  In order to announce a new resource in Kubernetes, we just need to zaplapit here such an ad.  Read this create table. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/09e/253/7d3/09e2537d3520f688c7029a357d9773dd.png"></div><br>  Created a table.  After that, we can look through the kubectl get to the third-party resources that we have.  As soon as we announced it, we also got an apish.  We can do, for example, kubeclt get apps.  But so far there are no apps. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/d5b/c40/9ad/d5bc409ad70866a12358ccb68ba497f8.png"></div><br>  Let's write some app.  After that we can make a custom resource instance.  Let's look at it in YAML and create it by posting to a specific URL. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/044/e55/454/044e554549dc4dc00d262ecf49d8d72d.png"></div><br>  If we run and see through kubectl, then one app appeared.  But while nothing happens, it just lies in the database.  You can, for example, take and request all app resources. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/701/234/74d/70123474de1bf62ece27d49587098368.png"></div><br>  We can create a second such resource from the same template, simply by changing the name.  Here came the second resource. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/842/a58/4b0/842a584b09631555234babcbd3c7e57c.png"></div><br>  Then our controller should do the templating, similar to what HELM does.  That is, having received the description of our app, I have to generate a resource deployment and resource service, and also make an entry in the ingress.  This is the easiest part: here in clojure, it's erlmacro.  I transfer the data structure, it jerks the deployment function, passes to the debug, which is the pipeline.  And this is a pure function: simple templating.  Accordingly, in the most naive form, I could immediately create it, turn it into a console utility and start distributing. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/b33/bf5/2cb/b33bf52cbd901d2c5e0a0641daed9161.png"></div><br>  We do the same for the service: the service function accepts the declaration and generates the Kubernetes resource for us. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/c2e/daf/e7f/c2edafe7f36d7c0db4573054991c436a.png"></div><br>  We do the same for the ingress line. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/5d0/22f/156/5d022f15612aa3dcc19f635b0dd9b403.png"></div><br>  How will this all work?  There will be something in the real world and there will be what we want.  What we want is we take an application resource and generate it for what should be.  And now we need to see what is.  What we have is requested through the REST API.  We can get all the services, all deployments. <br><br>  How will our custom controller work?  He will receive what we want and what is, take from this div and apply to Kubernetes.  This is similar to React.  I came up with a virtual DOM, when some functions simply generate a tree of JS objects.  And then a certain algorithm calculates the patch and applies it to the real DOM. <br><br>  We will do the same here.  This is done in 50 lines of code.  Want it - everything is on Github.  As a result, we should get the function reconcile-actions. <br><br>  We have a reconcile-actions function that does nothing and just computes this div.  She takes what is, plus what is needed.  And then gives what needs to be done to bring the first to the second. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/460/49b/90d/46049b90d8fa93dfe9279c02828cfa1c.png"></div><br>  Let's jerk her.  There is nothing wrong with it, you can debug it.  She says that you need to create an ingress-service, make two entries in it, create deployment 1 and 2, create service 1 and 2. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/c72/c0a/c10/c72c0ac10e4924fde59ed749339345aa.png"></div><br>  In this case, there should already be only one service.  We see by ingress that only one record remains. <br><br>  Next, all that remains is to write a function that applies this patch to the Kubernetes cluster.  To do this, we simply pass the reconcile-actions to the reconcile function, and everything will apply.  And here we see that POD has risen, deployment has become, and the service has started. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/66b/144/1a5/66b1441a56d805344c7e734d3b9b2c80.png"></div><br>  Let's add one more service: once again we will execute the function reconcile-actions.  Let's see what happened.  Everything started, all is well. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/32a/f9f/c1e/32af9fc1e444ed1c135e4bbe828a946f.png"></div><br>  How to deal with this?  We all pack it in Docker-container.  After that, we write a function that periodically wakes up, makes reconcile and falls asleep.  Speed ‚Äã‚Äãis not very important, it can sleep for five seconds and do not reconcile-actions less often. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/bec/04e/8d1/bec04e8d1791843d80aed4f2b3f2a673.png"></div><br>  Our custom controller is just a service that will wake up and periodically calculate a patch. <br><br>  Now we have two services zadeploino, let's remove one of the applications.  Let's see how our cluster responded: everything is ok.  Remove the second: everything is cleared. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/5ff/a23/96e/5ffa2396ef22187604393a9ae657edd5.png"></div><br>  Let's see through the eyes of the developer.  He just needs to say Kubernetes apply and set the name of the new service.  We do this, our controller has picked up and created everything. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/bd6/ca6/3d7/bd6ca63d77dfbadee1587b6f44a680bd.png"></div><br>  Next, we collect all of this into the deployment service, and with the standard Kubernetes tools we throw this custom controller into the cluster.  We have created an abstraction for 200 lines of code. <br><br>  It's all like HELM, but actually more powerful.  The controller works in a cluster: it sees the base, sees the outside world and can be made quite clever. <br><br><h2>  Own CI </h2><br>  Consider the examples of the Kubernetes extension.  We decided that CI should be part of the infrastructure.  This is good, it is convenient from the point of view of security - a private repository.  We tried to use jenkins, but it is an obsolete tool.  I wanted a hacker CI.  We do not need interfaces, we love ChatOps: let them just say in the chat if the build is down or not.  In addition, I wanted to debug everything locally. <br><img src="https://habrastorage.org/getpro/habr/post_images/9a4/ecf/86e/9a4ecf86e022a465ce11072352456728.png"><br>  We sat down and wrote our CI in a week.  Just as an extension to Kubernetes.  If you think about CI, then this is just a tool that runs some jobs.  As part of this job, we are building something, running tests, often deploying. <br><br>  How does all this work?  It is built on the same concept of custom controllers.  First, we drop the description of what repositories we are monitoring in Kubernetes.  The controller simply goes to the githab and adds a web hook.  We are left with introspection. <br><br>  Next comes the web-hook, whose only task is to process the incoming JSON and throw it into the custom build resource, which also adds up to the Kubernetes database.  The build resource is monitored by the build controller, which reads the manifest inside the project and starts the POD.  This POD-e runs all the necessary services. <br><br>  The POD has a very simple agent that reads a travis or circleci style declaration, and a set of steps in YAML.  He starts to perform them.  After that, at the end of the build, he casts his result in the Telegram. <br><br>  Another feature that we got together with Kubernetes is that one of the commands in the execution of your CI or continuous delivery can be put just while true sleep 10, and your POD will freeze in this step.  You do kubectl exec, you are inside your build and you can debug. <br><br>  Another feature - everything is built on dockers and you can debug the script locally by launching the docker.  It all took two weeks and 300 lines of code. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/72f/334/ec3/72f334ec33db75d3b32e4c464a24dc03.png"><br><br><h2>  Working with postgres </h2><br>  Our product is built on postgres, we use all its interesting features.  We even wrote a number of extensions.  But we can not use RDS or something else. <br><br>  We are now in the process of developing an operator for non-killed postgres.  Voiced architecture.  I want to say "Cluster, give me postgres, which cannot be killed."  Add to this that I need two asynchronous replicas, one synchronous, backups daily and up to a terabyte.  I throw it all over, the cluster controller then begins to orchestrate and expand my container.  It creates pginstance resources that are responsible for each istance postgres.  This will be cluster postgres. <br><br>  Next is the pginstance controller, simple enough, just trying to run POD or deployment there with this postgres.  The heart is a persistent volume.  This whole machine takes full control of postgres.  You give her a Docker-container in which there is only binary postgres.  Everything else: the configuration and creation of the start cluster postgres is done by the controller itself.  He does this so that we can reconfigure later, and so that he can configure replication, log levels, etc.  At the beginning, the temporary POD travels over the persistent volume and creates a postgres cluster for the master there. <br><br>  Next, deployment starts with master on top of this.  Then persistent volume is created in the same way.  Another POD travels, makes a basic backup, tightens it, and on top of this starts the deployment from the slave. <br><br>  Next, the cluster controller creates a backup resource (after it described backups).  And the backup controller already takes it and throws it into some S3. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/972/b42/457/972b42457c664d988fd8eeee0aaa603c.png"><br><br><h2>  What's next? </h2><br>  Let's imagine with you the near future.  It may happen that sooner or later we will have such interesting custom resources, custom controllers, that I will say "Give me postgres, give me kafka, leave me CI and start all this."  Everything will be easy. <br><br>  If we are not talking about the near future, then, as a declarative programmer, I believe that the above functional programming is only logical or relational.  There, we have operations semantics completely separated from information semantics.  If we look closely at our custom controllers that we did, then we have in the database, for example, a resource application.  And we derive three additional resources from it.  This is very similar to the view in the database.  This is a deduction of facts.  This is a logical or relation view. <br><br>  The next step for Kubernetes is, instead of chopped REST API, to give some illusion of a relational or logical base, where you can simply write a rule.  Since sooner or later everything runs into the database, including feedback, the rules may sound like this: ‚ÄúIf the load has increased like this, then increase the replication like this.‚Äù  We will have a small sql or logical rule.  All you need is a generic engine that will monitor this.  But this is a bright future. <br><img src="https://habrastorage.org/getpro/habr/post_images/fb4/f1e/930/fb4f1e930029011d081eeb911203d289.png"><br><br><blockquote>  More cool reports at the <b>DevOops 2018</b> conference!  All speakers and program - on the <a href="https://devoops.ru/">site</a> . <br><br>  If your home is on the shelf <a href="https://www.oreilly.com/library/view/the-devops-handbook/9781457191381/">‚ÄúThe DevOps Handbook‚Äù</a> , <a href="https://www.amazon.com/gp/product/B00PCZMAV0/ref%3Ddbs_a_def_rwt_hsch_vapi_taft_p1_i0">‚ÄúLearning Chef: A Guide to Configuration Management and Automation‚Äù</a> , <a href="https://www.oreilly.com/library/view/how-to-containerize/9781491982310/">‚ÄúHow to containerize your Go code‚Äù</a> or the new one <a href="https://www.amazon.com/Liquid-Software-Achieve-Trusted-Continuous/dp/1981855726">‚ÄúLiquid Software: How to Achieve Trusted Continuous Updates in the DevOps World ‚Äú</a> - bring them to the conference.  In the discussion areas after the reports, we will organize small autograph sessions with the authors of these books. <br><br>  Just think: a unique opportunity to get an autograph from <a href="https://devoops.ru/2018/spb/talks/3idrp7cstkccu2caecgouw/">John Willis himself</a> ! <br><br>  And another nice bonus: <b>until October 1, a</b> <a href="https://devoops.ru/tickets/">ticket</a> for DevOops 2018 can be booked at a discount. </blockquote></div><p>Source: <a href="https://habr.com/ru/post/424609/">https://habr.com/ru/post/424609/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../424599/index.html">You have to choose which software you need: written on time or in quality</a></li>
<li><a href="../424601/index.html">Information architecture on the Internet, part 1</a></li>
<li><a href="../424603/index.html">The book "Why we are wrong. Traps thinking in action. " Excerpts part 1</a></li>
<li><a href="../424605/index.html">Zuckerberg funds: Collaboration + Technology + Open Science</a></li>
<li><a href="../424607/index.html">Helidon's takeoff</a></li>
<li><a href="../424611/index.html">How to create an employee from a freelancer</a></li>
<li><a href="../424613/index.html">Experience of using redux without reducers</a></li>
<li><a href="../424615/index.html">Outputting the curve function for smoothly limiting parameters, signals and not only in Wolfram Mathematica</a></li>
<li><a href="../424619/index.html">Yandex will launch an open top runet site before the end of the year</a></li>
<li><a href="../424621/index.html">Non-carved superheroes. Who and how protects the construction site of Lakhta Center from fires?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>