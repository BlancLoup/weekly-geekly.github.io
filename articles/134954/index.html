<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Hidden Markov models in speech recognition</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="The most rapid and effective interaction between people occurs through oral communication. With the help of speech can be conveyed various feelings an...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Hidden Markov models in speech recognition</h1><div class="post__text post__text-html js-mediator-article">  The most rapid and effective interaction between people occurs through oral communication.  With the help of speech can be conveyed various feelings and emotions, and most importantly - useful information.  The need to create computer-based interfaces for audio input-output is beyond doubt, since their effectiveness is based on almost unlimited possibilities of formulation in the most diverse areas of human activity. <br><br><a name="habracut"></a>  The first electronic machine, synthesizing English speech, was presented in New York at a trade show in 1939 and was called voder, but the sound that it reproduced was extremely unclear.  The very first speech recognition device came out in 1952 in the second year and was able to recognize numbers. <br><br>  The process of speech recognition can distinguish the following difficulties: arbitrary, naive user;  spontaneous speech, accompanied by agrammatism and speech "garbage";  the presence of acoustic noise and distortion;  the presence of speech interference. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Of the variety of methods in this article, we will consider the possibility of creating a statistical model using hidden Markov models (SMM). <br><br><h4>  Part-of-speech tagging </h4><br><br>  When analyzing a natural language, the first step is to determine: to which part of the speech each of the words in the sentence refers.  In English, the task at this stage is called Part-Of-Speech tagging.  How can we determine the part of speech of an individual sentence?  Consider the sentence in English: "The can will rust."  So, the ‚Äì definite article or particle ‚Äúorder‚Äù;  can - can simultaneously be a modal verb, and a noun, and a verb;  will - modal verb, noun and verb;  rust - noun or verb.  In the statistical approach, it is necessary to construct a table of probabilities of using words in each grammatical meaning.  This problem can be solved on the basis of test texts, analyzed manually.  And one can immediately identify one of the problems: the word ‚Äúcan‚Äù is in most cases used as a verb, but sometimes it can also be a noun.  Given this shortcoming, a model was created that takes into account the fact that an adjective or noun follows after the article: <br><img src="https://habrastorage.org/getpro/habr/post_images/da7/d96/458/da7d96458e6f003aa637f2bebd1a105c.jpg" alt="formula"><br>  Where: <br>  t - tag (noun, adjective, etc.) <br>  w - word in the text (rust, can ...) <br>  p (w | t) is the probability that the word w corresponds to the tag t <br>  p (t1 | t2) is the probability that t1 comes after t2 <br><br>  From the proposed formula it is clear that we are trying to pick up tags so that the word matches the tag, and the tag matches the previous tag.  This method allows to determine that ‚Äúcan‚Äù acts as a noun, and not as a modal verb. <br><br>  This statistical model can be described as ergodic SMM: <br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/39d/2f8/0c3/39d2f80c383870bcf53acb5b5f99ebe9.jpg" alt="Ergodic Markov model."></div><br>  Ergodic Markov model <br><img src="https://habrastorage.org/getpro/habr/post_images/a65/f3d/42b/a65f3d42b9b394617cf55019a75a9d63.jpg" alt="Ergodic Markov model in practice."><br>  Ergodic Markov model in practice <br><br>  Each vertex in this scheme denotes a separate part of speech in which pairs are recorded (the word; the probability that the word refers specifically to this part of speech).  Transitions show the possible probability of following one part of speech after another.  For example, the probability that there will be 2 articles in a row, provided that the article is encountered, will be equal to 0.0016.  This stage of speech recognition is very important, as the correct definition of the grammatical structure of the sentence allows you to choose the correct grammatical structure for expressive coloring of the reproduced sentence. <br><br><h4>  N-gram models </h4><br><br>  There are also n-gram models of speech flow recognition.  They are based on the assumption that the probability of using the next word in a sentence depends only on n-1 words.  Today, the most popular bigram and trigram language models.  Search in such models occurs on the big table (case).  Despite the fast-running algorithm, such models are not able to grasp semantic and syntactic links, if the dependent words are 5 words apart.  Using the same n-gram models, where n is greater than 5, requires tremendous power. <br><br>  As noted above, the most popular model today is the trigram model.  The conditional probability of observing the sentence w1, ... wn is close to: <br><br>  P (w1, ..., wn) = Œ†P (wi | w1, ..., w2) ‚âà Œ†P (wi | wi- (n-1), ..., wi-1) <br><br>  For example, consider the sentence ‚ÄúI want to go home‚Äù.  The probability of this sentence can be calculated from the n-gram frequency count (in this example we take n = 3): <br><br>  P (I, want, to, go, home) ‚âà P (I) * P (want | I) * P (to | I, want) * P (go | want, to) * P (home | to, go ) <br><br>  It is worth noting that the long-range trigram model, in which the analysis is conducted not only by the two preceding words, but by any pair of words that are nearby.  Such a trigram model can skip low-informative words, thereby improving the predictability of compatibility in the model. </div><p>Source: <a href="https://habr.com/ru/post/134954/">https://habr.com/ru/post/134954/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../134947/index.html">The benefits of patent trolling</a></li>
<li><a href="../134948/index.html">Seagate bought Samsung HDD</a></li>
<li><a href="../134950/index.html">What Professor Ng hasn't taught us</a></li>
<li><a href="../134951/index.html">Build GNU Emacs for Ubuntu</a></li>
<li><a href="../134952/index.html">140 character idea</a></li>
<li><a href="../134956/index.html">On January 21, PHP conference of phpDev Minsk developers</a></li>
<li><a href="../134957/index.html">Competition "Holidays of the Future"</a></li>
<li><a href="../134959/index.html">Yandex.Money application for Facebook fundraising</a></li>
<li><a href="../134961/index.html">Datacenter in Yaroslavl: the realization of the dream of the last five years</a></li>
<li><a href="../134962/index.html">Mouse-baby for work "in the field" - what is it and why is it needed?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>