<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Autoencoders in Keras, Part 4: Conditional VAE</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Content 


- Part 1: Introduction 
- Part 2: Manifold learning and latent variables 
- Part 3: Variational autoencoders ( VAE ) 
- Part 4: Conditional...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Autoencoders in Keras, Part 4: Conditional VAE</h1><div class="post__text post__text-html js-mediator-article"><h3>  Content </h3><br><ul><li>  Part 1: <a href="https://habrahabr.ru/post/331382/">Introduction</a> <br></li><li>  Part 2: <a href="https://habrahabr.ru/post/331500/"><em>Manifold learning</em> and <em>latent</em> variables</a> <br></li><li>  Part 3: <a href="https://habrahabr.ru/post/331552/">Variational autoencoders ( <em>VAE</em> )</a> <br></li><li>  <strong>Part 4: Conditional VAE</strong> <br></li><li>  Part 5: <a href="https://habrahabr.ru/post/332000/"><em>GAN</em> (Generative Adversarial Networks) and tensorflow</a> <br></li><li>  Part 6: <a href="https://habrahabr.ru/post/332074/"><em>VAE</em> + <em>GAN</em></a> <br></li></ul><br>  In the <a href="https://habrahabr.ru/post/331552/">last part,</a> we met <strong>variational autoencoders (VAE)</strong> , implemented one on <em>keras</em> , and also understood how to generate images using it.  The resulting model, however, had some drawbacks: <br><br><ol><li>  Not all the numbers turned out to be well encoded in the hidden space: some of the numbers were either completely absent or were very blurry.  In between the areas in which the variants of the same figure were concentrated, there were generally some meaningless hieroglyphs. <br><br>  What is there to write, this is how the generated numbers looked like: 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <div class="spoiler">  <b class="spoiler_title">Picture</b> <div class="spoiler_text"><img src="https://habrastorage.org/web/92a/ac4/61b/92aac461bd794121874d9b307448ad2f.png" width="400"><br></div></div><br></li><li>  It was difficult to generate a picture of a given digit.  To do this, it was necessary to look into what area of ‚Äã‚Äãthe latent space the images of a particular digit fell into, and to sample it from somewhere, and even more so it was difficult to generate a digit in some given style. <br></li></ol><br>  In this part, we will see how only by slightly complicating the model to overcome both these problems, and at the same time we will be able to generate pictures of new numbers in the style of another digit - this is probably the most interesting feature of the future model. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/web/cfd/3c4/d14/cfd3c4d142f04ce4a5929272c5bb8c6c.png" width="400"></div><br><a name="habracut"></a><br><h3>  At first we will think about the reasons for the 1st shortcoming: </h3><br>  The varieties on which different numbers lie can be far apart in the space of pictures.  That is, it is difficult to imagine how, for example, to continuously display a picture of the number ‚Äú5‚Äù, into a picture of the number ‚Äú7‚Äù, while all the intermediate pictures could be called plausible.  Thus, the variety, near which the numbers lie, does not necessarily have to be linearly connected.  The autoencoder, due to the fact that it is a composition of continuous functions, can itself be displayed in the code and back only continuously, especially if it is a variational autoencoder.  In our previous example, the situation was further complicated by the fact that the autoencoder tried to search for a two-dimensional manifold. <br><br>  As an illustration, let us return to our artificial example from the 2nd part, just make the defining manifold disconnected: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/web/921/2e5/a92/9212e5a922044459b98182b6f30bd912.png" width="600"></div><br>  Here: <br><br><ul><li>  blue and green dots are sampled objects, <br></li><li>  red and yellow curves - unrelated defining manifold. <br></li></ul><br>  Let us now try to learn the defining variety using the usual deep autoencoder. <br><br><div class="spoiler">  <b class="spoiler_title">Code</b> <div class="spoiler_text"><pre><code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#    import numpy as np import matplotlib.pyplot as plt %matplotlib inline import seaborn as sns #   x1 = np.linspace(-2.2, 2.2, 1000) fx = np.sin(x1) dots1 = np.vstack([x1, fx]).T t = np.linspace(0, 2*np.pi, num=1000) dots2 = 0.5*np.array([np.sin(t), np.cos(t)]).T + np.array([1.5, -0.5])[None, :] dots = np.vstack([dots1, dots2]) noise = 0.06 * np.random.randn(*dots.shape) labels = np.array([0]*1000 + [1]*1000) noised = dots + noise #  colors = ['b']*1000 + ['g']*1000 plt.figure(figsize=(15, 9)) plt.xlim([-2.5, 2.5]) plt.ylim([-1.5, 1.5]) plt.scatter(noised[:, 0], noised[:, 1], c=colors) plt.plot(dots1[:, 0], dots1[:, 1], color="red", linewidth=4) plt.plot(dots2[:, 0], dots2[:, 1], color="yellow", linewidth=4) plt.grid(False) #    from keras.layers import Input, Dense from keras.models import Model from keras.optimizers import Adam def deep_ae(): input_dots = Input((2,)) x = Dense(64, activation='elu')(input_dots) x = Dense(64, activation='elu')(x) code = Dense(1, activation='linear')(x) x = Dense(64, activation='elu')(code) x = Dense(64, activation='elu')(x) out = Dense(2, activation='linear')(x) ae = Model(input_dots, out) return ae dae = deep_ae() dae.compile(Adam(0.001), 'mse') dae.fit(noised, noised, epochs=300, batch_size=30, verbose=2) #  predicted = dae.predict(noised) #  plt.figure(figsize=(15, 9)) plt.xlim([-2.5, 2.5]) plt.ylim([-1.5, 1.5]) plt.scatter(noised[:, 0], noised[:, 1], c=colors) plt.plot(dots1[:, 0], dots1[:, 1], color="red", linewidth=4) plt.plot(dots2[:, 0], dots2[:, 1], color="yellow", linewidth=4) plt.scatter(predicted[:, 0], predicted[:, 1], c='white', s=50) plt.grid(False)</span></span></code> </pre> <br></div></div><br><div style="text-align:center;"><img src="https://habrastorage.org/web/606/bda/644/606bda6441cf45d1a1cb9fc3cc9f10bd.png" width="600"></div><br><ul><li>  the white line is the manifold into which the blue and green data points pass after the autoencoder, that is, the autoencoder's attempt to construct the manifold that determines the most variation in the data. <br></li></ul><br>  It can be seen that a simple autoencoder failed to learn the shape of a disconnected manifold.  Instead, he slyly continued one another. <br><br>  If we know the data labels, which determine on which of the parts of the disconnected manifold these data lie (as with the numbers), then we can simply <em>condition the</em> autoencoder on these labels.  That is, just additionally with the data to feed the data to the encoder and the decoder as well.  In this case, the source of discontinuities in the data will be the label, and this will allow the autoencoder to learn each part of a linearly disconnected manifold separately. <br><br>  Let's look at the same example, only now we will transfer the label to the input and the encoder and the decoder additionally. <br><br><div class="spoiler">  <b class="spoiler_title">Code</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> concatenate <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">deep_cond_ae</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> input_dots = Input((<span class="hljs-number"><span class="hljs-number">2</span></span>,)) input_lbls = Input((<span class="hljs-number"><span class="hljs-number">1</span></span>,)) full_input = concatenate([input_dots, input_lbls]) x = Dense(<span class="hljs-number"><span class="hljs-number">64</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'elu'</span></span>)(full_input) x = Dense(<span class="hljs-number"><span class="hljs-number">64</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'elu'</span></span>)(x) code = Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'linear'</span></span>)(x) full_code = concatenate([code, input_lbls]) x = Dense(<span class="hljs-number"><span class="hljs-number">64</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'elu'</span></span>)(full_code) x = Dense(<span class="hljs-number"><span class="hljs-number">64</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'elu'</span></span>)(x) out = Dense(<span class="hljs-number"><span class="hljs-number">2</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'linear'</span></span>)(x) ae = Model([input_dots, input_lbls], out) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> ae cdae = deep_cond_ae() cdae.compile(Adam(<span class="hljs-number"><span class="hljs-number">0.001</span></span>), <span class="hljs-string"><span class="hljs-string">'mse'</span></span>) cdae.fit([noised, labels], noised, epochs=<span class="hljs-number"><span class="hljs-number">300</span></span>, batch_size=<span class="hljs-number"><span class="hljs-number">30</span></span>, verbose=<span class="hljs-number"><span class="hljs-number">2</span></span>) predicted = cdae.predict([noised, labels]) <span class="hljs-comment"><span class="hljs-comment">#  plt.figure(figsize=(15, 9)) plt.xlim([-2.5, 2.5]) plt.ylim([-1.5, 1.5]) plt.scatter(noised[:, 0], noised[:, 1], c=colors) plt.plot(dots1[:, 0], dots1[:, 1], color="red", linewidth=4) plt.plot(dots2[:, 0], dots2[:, 1], color="yellow", linewidth=4) plt.scatter(predicted[:, 0], predicted[:, 1], c='white', s=50) plt.grid(False)</span></span></code> </pre><br></div></div><br><div style="text-align:center;"><img src="https://habrastorage.org/web/e4e/238/afa/e4e238afacdc4b56a21c0af6a5451462.png" width="600"></div><br>  This time, the autoencoder managed to learn a linearly disconnected defining manifold. <br><br><h2>  CVAE </h2><br>  If you now take the <em>VAE</em> , as in the previous part, and also feed labels to the input, you get a <strong>Conditional Variational Autoencoder (CVAE)</strong> . <br><br>  With pictures of numbers it turns out like this: <br><br><img src="https://habrastorage.org/web/5aa/22a/e7f/5aa22ae7f85540b289c2f37fdafeb862.png"><br><br>  Picture above from <strong><em>[2]</em></strong> <br><br>  In this case, the <em>VAE</em> basic equation from the last part becomes simply <em>conditioned</em> on <img src="https://habrastorage.org/getpro/habr/post_images/cde/18c/a0a/cde18ca0a2ad19f25a621fa473b8f709.svg" alt="Y">  ( <img src="https://habrastorage.org/getpro/habr/post_images/cde/18c/a0a/cde18ca0a2ad19f25a621fa473b8f709.svg" alt="Y">  not required to be discrete), that is, on the label. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/2a6/61b/69e/2a661b69ea2aa2351f7493a41469c789.svg" alt="\ log P (X | Y; \ theta_2) - KL [Q (Z | X, Y; \ theta_1) || P (Z | X, Y; \ theta_2)] = E_ {Z \ sim Q} [\ log P (X | Z, Y; \ theta_2)] - KL [Q (Z | X, Y; \ theta_1) || N (0, I)]"></div><br><img src="https://habrastorage.org/getpro/habr/post_images/a22/c4e/e64/a22c4ee6461bc62c489c0bd92ab95afa.svg" alt="Q (Z | X, Y; \ theta_1)">  we again compare with <img src="https://habrastorage.org/getpro/habr/post_images/981/05d/016/98105d016f10d5a71b901afe90ec8fac.svg" alt="N (0, I)">  . <br>  This can be interpreted as: for each <img src="https://habrastorage.org/getpro/habr/post_images/cde/18c/a0a/cde18ca0a2ad19f25a621fa473b8f709.svg" alt="Y">  we have a separate <em>VAE</em> autoencoder, while they have a huge amount of common weights (almost absolute <em>weight sharing</em> ). <br><br>  The result is that <em>CVAE</em> codes in <img src="https://habrastorage.org/getpro/habr/post_images/d2d/297/e80/d2d297e8073685ab6fb84a0fb938ba3c.svg" alt="Z">  input signal properties common to all <img src="https://habrastorage.org/getpro/habr/post_images/cde/18c/a0a/cde18ca0a2ad19f25a621fa473b8f709.svg" alt="Y">  . <br><br><h2>  Style transfer </h2><br>  (Comment: this is not the same thing as transferring the style to Prisme, there is something else entirely) <br><br>  Now it becomes clear how to create new images in the style given: <br><br><ol><li>  we train <em>CVAE</em> on pictures with labels, <br></li><li>  we encode the style of the given picture in <img src="https://habrastorage.org/getpro/habr/post_images/d2d/297/e80/d2d297e8073685ab6fb84a0fb938ba3c.svg" alt="Z">  , <br></li><li>  changing labels <img src="https://habrastorage.org/getpro/habr/post_images/cde/18c/a0a/cde18ca0a2ad19f25a621fa473b8f709.svg" alt="Y">  create from coded <img src="https://habrastorage.org/getpro/habr/post_images/d2d/297/e80/d2d297e8073685ab6fb84a0fb938ba3c.svg" alt="Z">  new pictures. <br></li></ol><br><h2>  <em>Keras code</em> </h2><br>  The code is almost identical to the code from the previous part, except that now the label of the digit is transmitted to the encoder and the decoder. <br><br><div class="spoiler">  <b class="spoiler_title">Code</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> sys <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.pyplot <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> plt %matplotlib inline <span class="hljs-comment"><span class="hljs-comment"># import seaborn as sns from keras.datasets import mnist from keras.utils import to_categorical (x_train, y_train), (x_test, y_test) = mnist.load_data() x_train = x_train.astype('float32') / 255. x_test = x_test .astype('float32') / 255. x_train = np.reshape(x_train, (len(x_train), 28, 28, 1)) x_test = np.reshape(x_test, (len(x_test), 28, 28, 1)) y_train_cat = to_categorical(y_train).astype(np.float32) y_test_cat = to_categorical(y_test).astype(np.float32) num_classes = y_test_cat.shape[1]</span></span></code> </pre><br><pre> <code class="python hljs">batch_size = <span class="hljs-number"><span class="hljs-number">500</span></span> latent_dim = <span class="hljs-number"><span class="hljs-number">8</span></span> dropout_rate = <span class="hljs-number"><span class="hljs-number">0.3</span></span> start_lr = <span class="hljs-number"><span class="hljs-number">0.001</span></span></code> </pre><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Input, Dense <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> BatchNormalization, Dropout, Flatten, Reshape, Lambda <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> concatenate <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.models <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Model <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.objectives <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> binary_crossentropy <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers.advanced_activations <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> LeakyReLU <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> backend <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> K <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">create_cvae</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> models = {} <span class="hljs-comment"><span class="hljs-comment">#  Dropout  BatchNormalization def apply_bn_and_dropout(x): return Dropout(dropout_rate)(BatchNormalization()(x)) #  input_img = Input(shape=(28, 28, 1)) flatten_img = Flatten()(input_img) input_lbl = Input(shape=(num_classes,), dtype='float32') x = concatenate([flatten_img, input_lbl]) x = Dense(256, activation='relu')(x) x = apply_bn_and_dropout(x) #    #      ,    z_mean = Dense(latent_dim)(x) z_log_var = Dense(latent_dim)(x) #   Q    def sampling(args): z_mean, z_log_var = args epsilon = K.random_normal(shape=(batch_size, latent_dim), mean=0., stddev=1.0) return z_mean + K.exp(z_log_var / 2) * epsilon l = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var]) models["encoder"] = Model([input_img, input_lbl], l, 'Encoder') models["z_meaner"] = Model([input_img, input_lbl], z_mean, 'Enc_z_mean') models["z_lvarer"] = Model([input_img, input_lbl], z_log_var, 'Enc_z_log_var') #  z = Input(shape=(latent_dim, )) input_lbl_d = Input(shape=(num_classes,), dtype='float32') x = concatenate([z, input_lbl_d]) x = Dense(256)(x) x = LeakyReLU()(x) x = apply_bn_and_dropout(x) x = Dense(28*28, activation='sigmoid')(x) decoded = Reshape((28, 28, 1))(x) models["decoder"] = Model([z, input_lbl_d], decoded, name='Decoder') models["cvae"] = Model([input_img, input_lbl, input_lbl_d], models["decoder"]([models["encoder"]([input_img, input_lbl]), input_lbl_d]), name="CVAE") models["style_t"] = Model([input_img, input_lbl, input_lbl_d], models["decoder"]([models["z_meaner"]([input_img, input_lbl]), input_lbl_d]), name="style_transfer") def vae_loss(x, decoded): x = K.reshape(x, shape=(batch_size, 28*28)) decoded = K.reshape(decoded, shape=(batch_size, 28*28)) xent_loss = 28*28*binary_crossentropy(x, decoded) kl_loss = -0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1) return (xent_loss + kl_loss)/2/28/28 return models, vae_loss models, vae_loss = create_cvae() cvae = models["cvae"]</span></span></code> </pre><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.optimizers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Adam, RMSprop cvae.compile(optimizer=Adam(start_lr), loss=vae_loss)</code> </pre><br><pre> <code class="python hljs">digit_size = <span class="hljs-number"><span class="hljs-number">28</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">plot_digits</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(*args, invert_colors=False)</span></span></span><span class="hljs-function">:</span></span> args = [x.squeeze() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> x <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> args] n = min([x.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> x <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> args]) figure = np.zeros((digit_size * len(args), digit_size * n)) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(n): <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> j <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(len(args)): figure[j * digit_size: (j + <span class="hljs-number"><span class="hljs-number">1</span></span>) * digit_size, i * digit_size: (i + <span class="hljs-number"><span class="hljs-number">1</span></span>) * digit_size] = args[j][i].squeeze() <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> invert_colors: figure = <span class="hljs-number"><span class="hljs-number">1</span></span>-figure plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">2</span></span>*n, <span class="hljs-number"><span class="hljs-number">2</span></span>*len(args))) plt.imshow(figure, cmap=<span class="hljs-string"><span class="hljs-string">'Greys_r'</span></span>) plt.grid(<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) ax = plt.gca() ax.get_xaxis().set_visible(<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) ax.get_yaxis().set_visible(<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) plt.show() n = <span class="hljs-number"><span class="hljs-number">15</span></span> <span class="hljs-comment"><span class="hljs-comment">#   15x15  from scipy.stats import norm #     N(0, I),   ,    ,      grid_x = norm.ppf(np.linspace(0.05, 0.95, n)) grid_y = norm.ppf(np.linspace(0.05, 0.95, n)) def draw_manifold(generator, lbl, show=True): #     figure = np.zeros((digit_size * n, digit_size * n)) input_lbl = np.zeros((1, 10)) input_lbl[0, lbl] = 1 for i, yi in enumerate(grid_x): for j, xi in enumerate(grid_y): z_sample = np.zeros((1, latent_dim)) z_sample[:, :2] = np.array([[xi, yi]]) x_decoded = generator.predict([z_sample, input_lbl]) digit = x_decoded[0].squeeze() figure[i * digit_size: (i + 1) * digit_size, j * digit_size: (j + 1) * digit_size] = digit if show: #  plt.figure(figsize=(10, 10)) plt.imshow(figure, cmap='Greys_r') plt.grid(False) ax = plt.gca() ax.get_xaxis().set_visible(False) ax.get_yaxis().set_visible(False) plt.show() return figure def draw_z_distr(z_predicted, lbl): #   z input_lbl = np.zeros((1, 10)) input_lbl[0, lbl] = 1 im = plt.scatter(z_predicted[:, 0], z_predicted[:, 1]) im.axes.set_xlim(-5, 5) im.axes.set_ylim(-5, 5) plt.show()</span></span></code> </pre><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> IPython.display <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> clear_output <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.callbacks <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> LambdaCallback, ReduceLROnPlateau, TensorBoard <span class="hljs-comment"><span class="hljs-comment"># ,         figs = [[] for x in range(num_classes)] latent_distrs = [[] for x in range(num_classes)] epochs = [] # ,     save_epochs = set(list((np.arange(0, 59)**1.701).astype(np.int)) + list(range(10))) #       imgs = x_test[:batch_size] imgs_lbls = y_test_cat[:batch_size] n_compare = 10 #  generator = models["decoder"] encoder_mean = models["z_meaner"] # ,       def on_epoch_end(epoch, logs): if epoch in save_epochs: clear_output() #   output #      decoded = cvae.predict([imgs, imgs_lbls, imgs_lbls], batch_size=batch_size) plot_digits(imgs[:n_compare], decoded[:n_compare]) #     y   z|y draw_lbl = np.random.randint(0, num_classes) print(draw_lbl) for lbl in range(num_classes): figs[lbl].append(draw_manifold(generator, lbl, show=lbl==draw_lbl)) idxs = y_test == lbl z_predicted = encoder_mean.predict([x_test[idxs], y_test_cat[idxs]], batch_size) latent_distrs[lbl].append(z_predicted) if lbl==draw_lbl: draw_z_distr(z_predicted, lbl) epochs.append(epoch) #  pltfig = LambdaCallback(on_epoch_end=on_epoch_end) # lr_red = ReduceLROnPlateau(factor=0.1, patience=25) tb = TensorBoard(log_dir='./logs') #   cvae.fit([x_train, y_train_cat, y_train_cat], x_train, shuffle=True, epochs=1000, batch_size=batch_size, validation_data=([x_test, y_test_cat, y_test_cat], x_test), callbacks=[pltfig, tb], verbose=1)</span></span></code> </pre><br></div></div><br><h2>  results </h2><br>  (I apologize that in some places there are white numbers on a black background, and in some places black on white) <br><br>  This autoencoder translates numbers like this: <br><br><img src="https://habrastorage.org/web/ce0/46d/a33/ce046da333314c68930dede8c70fde5d.png"><br><br>  The generated digits of each label are sampled from <img src="https://habrastorage.org/getpro/habr/post_images/e3d/6b1/d29/e3d6b1d29a89a32d44eba93c5db11abf.svg" alt="N (0 | I)">  : <br><br>  (It is perfectly visible how common features are coded in coordinates <img src="https://habrastorage.org/getpro/habr/post_images/d2d/297/e80/d2d297e8073685ab6fb84a0fb938ba3c.svg" alt="Z">  ) <br><br> <a href=""><img src="https://habrastorage.org/web/0fa/285/2bf/0fa2852bfcf2450f93d6474f284e1fa0.png" width="350"></a> <a href=""><img src="https://habrastorage.org/web/320/1b8/283/3201b8283aa4410893fe0d9deadaf930.png" width="350"></a> <a href=""><img src="https://habrastorage.org/web/bad/f37/a9e/badf37a9e3b5408b80dab94bc73e9520.png" width="350"></a> <a href=""><img src="https://habrastorage.org/web/0de/d9e/499/0ded9e499e5c43619f73efa3ad3f7072.png" width="350"></a> <a href=""><img src="https://habrastorage.org/web/210/6b4/cc1/2106b4cc1ee54ea29f0d9572e18e55c3.png" width="350"></a> <a href=""><img src="https://habrastorage.org/web/1d3/359/e0f/1d3359e0ff5f46c695da7fcb66366bc8.png" width="350"></a> <a href=""><img src="https://habrastorage.org/web/ed5/6c7/94a/ed56c794af684366a03f4d98abb09f9c.png" width="350"></a> <a href=""><img src="https://habrastorage.org/web/09a/fe0/be3/09afe0be376544a3936b65bdcf326f84.png" width="350"></a> <a href=""><img src="https://habrastorage.org/web/a13/8c1/0fe/a138c10fed44416386bc94a5ed321e6b.png" width="350"></a> <a href=""><img src="https://habrastorage.org/web/f61/093/5a6/f610935a6c43440c96ed67eb57ed330a.png" width="350"></a> <br><br><h4>  Generating numbers of a given label from <img src="https://habrastorage.org/getpro/habr/post_images/d2d/297/e80/d2d297e8073685ab6fb84a0fb938ba3c.svg" alt="Z">  and distribution <img src="https://habrastorage.org/getpro/habr/post_images/d2d/297/e80/d2d297e8073685ab6fb84a0fb938ba3c.svg" alt="Z">  for each label </h4><br><div class="spoiler">  <b class="spoiler_title">Heavy gifs</b> <div class="spoiler_text"> <a href=""><img src="https://habrastorage.org/web/f02/65a/748/f0265a7485434b9b8cc76bc2324f31e7.gif" width="330"></a> <a href=""><img src="https://habrastorage.org/web/e31/1ed/e8f/e311ede8f096447aab6997bc24c154bf.gif" width="330"><br></a> <br><br> <a href=""><img src="https://habrastorage.org/web/54a/b68/9c7/54ab689c79474f2c9920aa45a4d0a2ba.gif" width="330"></a> <a href=""><img src="https://habrastorage.org/web/d25/a95/832/d25a958321414d6ea662eec2d296f8f0.gif" width="330"><br></a> <br><br> <a href=""><img src="https://habrastorage.org/web/5dc/532/ce4/5dc532ce412647108b77637806f77f58.gif" width="330"></a> <a href=""><img src="https://habrastorage.org/web/b29/d98/1f2/b29d981f2a1f43148c2ab9bf5dda44dd.gif" width="330"><br></a> <br><br> <a href=""><img src="https://habrastorage.org/web/270/949/4c1/2709494c1e1b40c9bc037f1998e62d65.gif" width="330"></a> <a href=""><img src="https://habrastorage.org/web/55d/938/465/55d938465ecd4d82bef63e821413b99b.gif" width="330"><br></a> <br><br> <a href=""><img src="https://habrastorage.org/web/042/71f/6f3/04271f6f3d3b4822b9b3c5992169029c.gif" width="330"></a> <a href=""><img src="https://habrastorage.org/web/882/66e/ac8/88266eac874140de9e4dc8433b87807d.gif" width="330"><br></a> <br><br> <a href=""><img src="https://habrastorage.org/web/640/0a7/419/6400a74192a747b087fb0919c12347d6.gif" width="330"></a> <a href=""><img src="https://habrastorage.org/web/e7d/c53/727/e7dc537272ef4420868baebdca4797a4.gif" width="330"><br></a> <br><br> <a href=""><img src="https://habrastorage.org/web/fde/44c/174/fde44c1743f64d82bd8c7b912ae5495e.gif" width="330"></a> <a href=""><img src="https://habrastorage.org/web/6d4/7b6/dba/6d47b6dba1264a688915f4aef0997be2.gif" width="330"><br></a> <br><br> <a href=""><img src="https://habrastorage.org/web/769/6bf/836/7696bf83626c434f84329dbc9850aa14.gif" width="330"></a> <a href=""><img src="https://habrastorage.org/web/096/522/cf6/096522cf6c484e9c9e99c80c9a3a58d0.gif" width="330"><br></a> <br><br> <a href=""><img src="https://habrastorage.org/web/769/e4e/180/769e4e1807bf4fc99b9b5b721e83974f.gif" width="330"></a> <a href=""><img src="https://habrastorage.org/web/c83/b0b/493/c83b0b493ae84ae8848808ea87d43da7.gif" width="330"><br></a> <br></div></div><br><h3>  Transferring the style of this model </h3><br>  As the sources of the style, we take the first ten "7" -ok, and based on their code <img src="https://habrastorage.org/getpro/habr/post_images/d2d/297/e80/d2d297e8073685ab6fb84a0fb938ba3c.svg" alt="Z">  create the remaining numbers. <br><br><div class="spoiler">  <b class="spoiler_title">Code</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">style_transfer</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(model, X, lbl_in, lbl_out)</span></span></span><span class="hljs-function">:</span></span> rows = X.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> isinstance(lbl_in, int): lbl = lbl_in lbl_in = np.zeros((rows, <span class="hljs-number"><span class="hljs-number">10</span></span>)) lbl_in[:, lbl] = <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> isinstance(lbl_out, int): lbl = lbl_out lbl_out = np.zeros((rows, <span class="hljs-number"><span class="hljs-number">10</span></span>)) lbl_out[:, lbl] = <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> model.predict([X, lbl_in, lbl_out])</code> </pre><br><br><pre> <code class="python hljs">n = <span class="hljs-number"><span class="hljs-number">10</span></span> lbl = <span class="hljs-number"><span class="hljs-number">7</span></span> generated = [] prot = x_train[y_train == lbl][:n] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(num_classes): generated.append(style_transfer(models[<span class="hljs-string"><span class="hljs-string">"style_t"</span></span>], prot, lbl, i)) generated[lbl] = prot plot_digits(*generated, invert_colors=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)</code> </pre><br></div></div><br><div style="text-align:center;"> <a href=""><img src="https://habrastorage.org/web/cfd/3c4/d14/cfd3c4d142f04ce4a5929272c5bb8c6c.png" width="600"></a> </div> <a href=""><br></a> <br>  The style has been transferred quite successfully: the slope and thickness of the stroke are preserved. <br><br>  More style properties could be transferred simply by increasing the dimension. <img src="https://habrastorage.org/getpro/habr/post_images/d2d/297/e80/d2d297e8073685ab6fb84a0fb938ba3c.svg" alt="Z">  It would also make the numbers less blurry. <br><br>  In the next part, we will look at how, using <em>generative competing networks (GAN)</em> , to generate numbers that are almost indistinguishable from the real ones, and after that, how to combine <em>GANs</em> with autoencoders. <br><br><h3>  GIF creation code </h3><br><div class="spoiler">  <b class="spoiler_title">Code</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> matplotlib.animation <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> FuncAnimation <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> matplotlib <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> cm <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">make_2d_figs_gif</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(figs, epochs, c, fname, fig)</span></span></span><span class="hljs-function">:</span></span> norm = matplotlib.colors.Normalize(vmin=<span class="hljs-number"><span class="hljs-number">0</span></span>, vmax=<span class="hljs-number"><span class="hljs-number">1</span></span>, clip=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) im = plt.imshow(np.zeros((<span class="hljs-number"><span class="hljs-number">28</span></span>,<span class="hljs-number"><span class="hljs-number">28</span></span>)), cmap=<span class="hljs-string"><span class="hljs-string">'Greys'</span></span>, norm=norm) plt.grid(<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>) plt.title(<span class="hljs-string"><span class="hljs-string">"Label: {}\nEpoch: {}"</span></span>.format(c, epochs[<span class="hljs-number"><span class="hljs-number">0</span></span>])) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">update</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(i)</span></span></span><span class="hljs-function">:</span></span> im.set_array(figs[i]) im.axes.set_title(<span class="hljs-string"><span class="hljs-string">"Label: {}\nEpoch: {}"</span></span>.format(c, epochs[i])) im.axes.get_xaxis().set_visible(<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) im.axes.get_yaxis().set_visible(<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> im anim = FuncAnimation(fig, update, frames=range(len(figs)), interval=<span class="hljs-number"><span class="hljs-number">100</span></span>) anim.save(fname, dpi=<span class="hljs-number"><span class="hljs-number">80</span></span>, writer=<span class="hljs-string"><span class="hljs-string">'imagemagick'</span></span>) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">make_2d_scatter_gif</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(zs, epochs, c, fname, fig)</span></span></span><span class="hljs-function">:</span></span> im = plt.scatter(zs[<span class="hljs-number"><span class="hljs-number">0</span></span>][:, <span class="hljs-number"><span class="hljs-number">0</span></span>], zs[<span class="hljs-number"><span class="hljs-number">0</span></span>][:, <span class="hljs-number"><span class="hljs-number">1</span></span>]) plt.title(<span class="hljs-string"><span class="hljs-string">"Label: {}\nEpoch: {}"</span></span>.format(c, epochs[<span class="hljs-number"><span class="hljs-number">0</span></span>])) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">update</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(i)</span></span></span><span class="hljs-function">:</span></span> fig.clear() im = plt.scatter(zs[i][:, <span class="hljs-number"><span class="hljs-number">0</span></span>], zs[i][:, <span class="hljs-number"><span class="hljs-number">1</span></span>]) im.axes.set_title(<span class="hljs-string"><span class="hljs-string">"Label: {}\nEpoch: {}"</span></span>.format(c, epochs[i])) im.axes.set_xlim(<span class="hljs-number"><span class="hljs-number">-5</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>) im.axes.set_ylim(<span class="hljs-number"><span class="hljs-number">-5</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> im anim = FuncAnimation(fig, update, frames=range(len(zs)), interval=<span class="hljs-number"><span class="hljs-number">100</span></span>) anim.save(fname, dpi=<span class="hljs-number"><span class="hljs-number">80</span></span>, writer=<span class="hljs-string"><span class="hljs-string">'imagemagick'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> lbl <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(num_classes): make_2d_figs_gif(figs[lbl], epochs, lbl, <span class="hljs-string"><span class="hljs-string">"./figs4/manifold_{}.gif"</span></span>.format(lbl), plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">7</span></span>,<span class="hljs-number"><span class="hljs-number">7</span></span>))) make_2d_scatter_gif(latent_distrs[lbl], epochs, lbl, <span class="hljs-string"><span class="hljs-string">"./figs4/z_distr_{}.gif"</span></span>.format(lbl), plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">7</span></span>,<span class="hljs-number"><span class="hljs-number">7</span></span>)))</code> </pre><br></div></div><br><h2>  Useful links and literature </h2><br>  The theoretical part is based on the article: <br>  [1] Tutorial on Variational Autoencoders, Carl Doersch, <a href="https://arxiv.org/abs/1606.05908">https://arxiv.org/abs/1606.05908</a> <br>  and in fact is its summary. <br><br>  Many pictures are taken from Isaac Dykeman blog: <br>  [2] Isaac Dykeman, <a href="http://ijdykeman.github.io/ml/2016/12/21/cvae.html">http://ijdykeman.github.io/ml/2016/12/21/cvae.html</a> <br><br>  Read more about the distance of Kullback-Leibler in Russian can be in <br>  [3] <a href="http://www.machinelearning.ru/wiki/images/d/d0/BMMO11_6.pdf">http://www.machinelearning.ru/wiki/images/d/d0/BMMO11_6.pdf</a> <br><br>  The code is partly based on the <em>Francois Chollet</em> article: <br>  [4] <a href="https://blog.keras.io/building-autoencoders-in-keras.html">https://blog.keras.io/building-autoencoders-in-keras.html</a> <br><br>  Other interesting links: <br>  <a href="http://blog.fastforwardlabs.com/2016/08/12/introducing-variational-autoencoders-in-prose-and.html">http://blog.fastforwardlabs.com/2016/08/12/introducing-variational-autoencoders-in-prose-and.html</a> <br>  <a href="http://kvfrans.com/variational-autoencoders-explained/">http://kvfrans.com/variational-autoencoders-explained/</a> </div><p>Source: <a href="https://habr.com/ru/post/331664/">https://habr.com/ru/post/331664/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../331652/index.html">Google Developers Group and Softline organize the first in Russia "Google Cloud Developer Meetup # 1"</a></li>
<li><a href="../331654/index.html">Warehouse management system using CQRS and Event Sourcing. Setting Requirements</a></li>
<li><a href="../331656/index.html">Protected workplace based on VDI Huawei FusionCloud Desktop Solution 6.1</a></li>
<li><a href="../331658/index.html">Ubuntu Mobile: Post-mortem Analysis</a></li>
<li><a href="../331662/index.html">Speed ‚Äã‚Äãreading: does it work or not? Part 2: parsing techniques</a></li>
<li><a href="../331666/index.html">When will they send me an offer? Tips for applicants from HR-manager</a></li>
<li><a href="../331668/index.html">How to efficiently read data from the disk (provided that you have .Net)</a></li>
<li><a href="../331670/index.html">Dlang Tour translated into Russian</a></li>
<li><a href="../331672/index.html">"Confrontation": how information security specialists try to trick each other</a></li>
<li><a href="../331674/index.html">5 stages of microservice development</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>