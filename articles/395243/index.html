<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>AI generates realistic sounds on the video</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Employees of the Laboratory of Informatics and Artificial Intelligence (CSAIL) at the Massachusetts Institute of Technology and the Google Research di...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>AI generates realistic sounds on the video</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/files/ffc/d91/c15/ffcd91c151014c829f06083223c2a1ec.jpg"><br><br>  Employees of the <a href="http://csail.mit.edu/">Laboratory of Informatics and Artificial Intelligence</a> (CSAIL) at the Massachusetts Institute of Technology and the Google Research division have designed a neural network that has learned to <a href="http://www.csail.mit.edu/visually_indicated_sounds">voice an arbitrary video series</a> , generating realistic sounds and predicting the properties of objects.  The program analyzes video, recognizes objects, their movement and the type of contact - impact, sliding, friction, and so on.  Based on this information, it generates a sound that a person in 40% of cases considers more realistic than the real one. <br><br>  Scientists suggest that this development will find wide application in cinema and on television to generate sound effects in a video series without sound.  In addition, it can be useful for learning robots to better understand the properties of the surrounding world. <br><a name="habracut"></a><br><iframe width="560" height="315" src="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://www.youtube.com/embed/0FW99AQmMc8%3Ffeature%3Doembed&amp;xid=17259,15700023,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjIMEggQFcA-xwGiPKNFy6Olf_PbQ" frameborder="0" allowfullscreen=""></iframe>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      The surrounding sounds say a lot about the properties of the surrounding objects, so in the process of self-study, future robots can act like children - touch objects, try them by touch, poke them with a stick, try to move, lift.  In this case, the robot receives feedback, recognizing the properties of the object - its weight, elasticity, and so on. <br><br>  The sound made by the object in contact also carries important information about the properties of the object.  ‚ÄúWhen you run your finger over a glass of wine, the sound that is produced corresponds to the amount of liquid poured into the glass,‚Äù explains graduate student <a href="http://andrewowens.org/">Andrew Owens</a> , the lead author of a published research paper, which is not yet ready for a scientific journal. Access at arXiv.org.  The presentation of the scientific work will take place at the annual conference on machine vision and image recognition (CVPR) in Las Vegas this month. <br><br>  Scientists have picked up 977 videos in which people perform actions with surrounding objects consisting of various materials: they scratch, beat them with a stick, etc.  In total, the videos contained 46,577 actions.  CSAIL students manually marked out all the actions, specifying the type of material, the place of contact, the type of action (impact / scratching / other) and the type of reaction of the material or object (deformation, static shape, hard movement, etc.).  Videos with sound were used to train the neural network, and manually placed tags - <b>only for analyzing</b> the learning outcome of the neural network, but <b>not for teaching it</b> . <br><br><img src="https://habrastorage.org/files/bc6/750/52a/bc675052a44746f08b569350f7b6481c.jpg"><br><br>  The neural network analyzed the characteristics of a sound that corresponds to each type of interaction with objects ‚Äî loudness, pitch, and other characteristics.  During training, the system studied the video frame by frame, analyzed the sound in this frame and found a match with the most similar sound in the already accumulated database.  The most important thing was to teach the neural network to stretch the sound into frames. <br><br><img src="https://habrastorage.org/files/5bd/97d/f05/5bd97df05e7b4df88695bbc282d8e93a.jpg"><br><br>  With each new video, the sound prediction accuracy increased. <br><br>  <b>The sound generated by the neural network for different scenes compared to the present</b> <br><img src="https://habrastorage.org/files/657/99e/efb/65799eefbb5149d2ad06460f27cdd984.jpg"><br><br>  As a result, the neural network has learned to accurately predict the most diverse sounds with all the nuances: from knocking stones to rustling ivy. <br><br>  ‚ÄúThe current approaches of artificial intelligence researchers focus on only one of the five senses: machine vision specialists study visual images, speech recognition specialists study sound, and so on,‚Äù <a href="http://news.mit.edu/2016/artificial-intelligence-produces-realistic-sounds-0613">said</a> Abhinav Gupta, associate professor at the Carnegie University Robotics Department. Mellon.  ‚ÄúThe current research is a step in the right direction, which simulates the learning process in the same way that people do, that is, integrating sound and vision.‚Äù <br><br>  To test the effectiveness of AI, scientists conducted an online study on Amazon Mechanical Turk, whose participants were asked to compare two options for the sound of a particular video and determine which sound is real and which is not. <br><br>  As a result of the experiment, AI <b>managed to deceive people in 40% of cases</b> .  However, according to <a href="https://news.ycombinator.com/item%3Fid%3D11894460">some commentators on the forums</a> , it is not so difficult to deceive a person, because a modern person gets a significant part of knowledge about the sound picture of the world from feature films and computer games.  The sound range for movies and games is made up of specialists, using collections of standard samples.  That is, we constantly hear about the same thing. <br><br>  In an online experiment in two cases out of five, people thought that the program-generated sound was more realistic than the real sound from the video.  This is a higher result than other methods of synthesizing realistic sounds. <br><br><img src="https://habrastorage.org/files/3ba/1d7/6af/3ba1d76afd8e467f8871e2a5a676442a.png"><br><br>  Most often, the AI ‚Äã‚Äãmisled the participants in the experiment with the sounds of materials such as leaves and dirt, because these sounds are more complex and not as ‚Äúpure‚Äù as emitting, for example, wood or metal. <br><br>  Returning to the neural network training, as a side effect of the study, it was found that the algorithm can distinguish between soft and hard materials with an accuracy of 67%, simply predicting their sound.  In other words, the robot can look at the asphalt path and grass in front of it - and conclude that the asphalt is hard and the grass is soft.  The robot will know this from the predicted sound, without even stepping on the asphalt and grass.  Then he can go wherever he wants - and check his feelings, checking with the database and, if necessary, making corrections in the library of sound samples.  In this way, in the future, robots will study and explore the world around them. <br><br>  However, researchers still have a lot of work to improve technology.  The neural network is now often mistaken with the rapid movement of objects, not getting into the exact moment of contact.  In addition, AI can only generate sound based on direct contact recorded on video, and there are so many sounds around us that are not based on visual contact: the noise of trees, the hum of a fan in a computer.  ‚ÄúWhat would be really great is to somehow simulate a sound that is not so closely related to the video sequence,‚Äù <a href="http://www.csail.mit.edu/visually_indicated_sounds">says</a> Andrew Owens. </div><p>Source: <a href="https://habr.com/ru/post/395243/">https://habr.com/ru/post/395243/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../395231/index.html">Lenovo's history: how ten Chinese scientists have created a leader in the PC market</a></li>
<li><a href="../395235/index.html">Russian long-term base on the Moon accommodates 12 people</a></li>
<li><a href="../395237/index.html">Kazan space</a></li>
<li><a href="../395239/index.html">Presentation at Apple Worldwide Developers Conference (WWDC) 2016 [text translation]</a></li>
<li><a href="../395241/index.html">Production of printed circuit boards using a diode laser instead of an iron. All do it yourself from beginning to end</a></li>
<li><a href="../395245/index.html">The developers of the game No Man's Sky defended the name of the company Sky</a></li>
<li><a href="../395247/index.html">"Talk Show": How to create, develop and listen to podcasts</a></li>
<li><a href="../395249/index.html">Summer Mobilization GearBest</a></li>
<li><a href="../395251/index.html">Headset with bone conduction sound Aftershokz bluez 2 and a hearing impaired person</a></li>
<li><a href="../395253/index.html">File System Apple File System (APFS)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>