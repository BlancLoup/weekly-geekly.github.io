<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Magic introduction to classification algorithms</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Translation of an article by Brian Berend. 

 When you first begin to study the theory of data analysis and processing, then one of the first you stud...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Magic introduction to classification algorithms</h1><div class="post__text post__text-html js-mediator-article">  <i>Translation of an <a href="http://blog.yhat.com/posts/harry-potter-classification.html">article by</a> Brian Berend.</i> <br><br>  When you first begin to study the theory of data analysis and processing, then one of the first you study the classification algorithms.  Their essence is simple: information about a specific observation result (data point) is taken, on the basis of which this result belongs to a particular group or class. <br><br>  A good example is spam email filter.  It should mark incoming letters (that is, the results of observations) as ‚Äúspam‚Äù or ‚Äúnot spam‚Äù, focusing on information about the letters (the sender, the number of words starting with capital letters, and so on). 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <div style="text-align:center;"><img src="https://habrastorage.org/web/420/b08/cd7/420b08cd728844a3863b0f7ae19b9ec0.png"></div><br><br>  This is a good example, but boring.  Spam classification is cited as an example in lectures, presentations and conferences, so you probably have heard about it more than once.  But what if we talk about a different, more interesting classification algorithm?  Some more weird?  More ... magic? <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/UrWu14QJU8c" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  That's right!  Today we talk about Sorting Hat from the world of Harry Potter.  Take some data from the network, analyze and create a classifier that will sort the characters into different faculties.  It should be fun! <br><a name="habracut"></a><br>  <b>Note:</b> <br>  Our classifier will not be too complicated.  So it should be considered as a ‚Äúprimary approach‚Äù to the solution of the problem, demonstrating some basic techniques for extracting text from the network and analyzing it.  In addition, given the relatively small sample size, we will not use classical teaching methods like <a href="https://ru.wikipedia.org/wiki/%25D0%259F%25D0%25B5%25D1%2580%25D0%25B5%25D0%25BA%25D1%2580%25D1%2591%25D1%2581%25D1%2582%25D0%25BD%25D0%25B0%25D1%258F_%25D0%25BF%25D1%2580%25D0%25BE%25D0%25B2%25D0%25B5%25D1%2580%25D0%25BA%25D0%25B0">cross-checking</a> .  We simply collect certain data, build a simple classifier based on the rules and evaluate the result. <br><br>  <b>Second note:</b> <br>  The idea of ‚Äã‚Äãthis post is inspired by the wonderful presentation of Brian Lang at the conference <a href="https://pydata.org/chicago2016/">PyData Chicago 2016</a> .  The video is <a href="https://www.youtube.com/watch%3Fv%3Dy8J6ggsLSfw">here</a> , the slides are <a href="https://www.slideshare.net/brianjlange/its-not-magic-explaining-classification-algorithms-pydata-chicago-2016-edition">here</a> . <br><br><h2>  Step One: Retrieve Data from the Network </h2><br>  In case you spent the last 20 years in a cave: Distributing hat is a magic hat that places incoming students in four faculties of Hogwarts: Gryffindor, Slytherin, Hufflepuff and Ravenclough.  Each faculty has its own characteristics.  When a hat is worn on the student's head, she reads his mind and determines which department suits him best.  According to this definition, Distributive hat is a multiclass classifier (sorts into more than two groups), unlike a binary classifier (sorts strictly into two groups), which is a spam filter. <br><br>  To distribute students to faculties, we need to know certain information about them.  Fortunately, enough data is available on <a href="">harrypotter.wikia.com</a> .  This site contains articles on almost all aspects of the Harry Potter universe, including descriptions of students and faculties.  A nice bonus: <a href="http://www.wikia.com/about">Fandom</a> , the site manager, provides an easy-to-use <a href="http://api.wikia.com/wiki/Quick_Start">API</a> and a lot of excellent <a href="http://api.wikia.com/wiki/Documentation">documentation</a> .  Hooray! <br><br><div style="text-align:center;"><img src="https://habrastorage.org/web/0e5/74e/63b/0e574e63bea34f24bf2c10092268e94b.gif"></div><br><br>  Let's start by importing <code>pandas</code> and <code>requests</code> .  The former will be used to organize the data, and the latter - for requests to the API to receive data. <br><br>  We also need to competently go through all the students at Hogwarts and record the faculties in which they are scattered with the distribution hat (this will be ‚Äúreal data‚Äù with which we will compare the results of our sorting).  On the site of the article are divided into categories, like "Students of Hogwarts" and "Films".  The API allows you to create lists of articles within a specific category. <br><br>  Take for example Ravenklou.  Put all the data into the <code>info</code> variable and then put it into the Pandas Data Frame. <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#   import pandas as pd import requests #      category = 'Ravenclaws' url = 'http://harrypotter.wikia.com/api/v1/Articles/List?expand=1&amp;limit=1000&amp;category=' + category requested_url = requests.get(url) json_results = requested_url.json() info = json_results['items'] ravenclaw_df = pd.DataFrame(info) print('Number of articles: {}'.format(len(info))) print('') ravenclaw_df.head()</span></span></code> </pre> <br>  Articles: 158 <br><br><img src="https://habrastorage.org/web/bc0/93b/ea1/bc093bea1c5b44e081b74514ff2451d3.png"><br>  <i>You can follow the complete analysis with <a href="https://www.yhat.com/products/rodeo">Rodeo</a> !</i> <br><br>  <b>Note:</b> <br>  If you use our Python IDE, Rodeo, then just copy and paste the above code into the Editor or Terminal.  You will see the result in the History or Terminal window.  Bonus: you can simply drag the windows with the mouse, changing their location and size. <br><br><img src="https://habrastorage.org/web/9d9/a45/cfb/9d9a45cfb2a645b2849995eba5e409cf.png"><br><br>  Based on this data we will find out: <br><br><ul><li>  The first item on the list is the ‚ÄúRavenclaw individual infobox‚Äù.  Since this is not a student, we need to filter the results by the type column. </li><li>  Unfortunately, the contents of the articles are not listed in <code>ravenclaw_df</code> ... only descriptions.  To get the content, you have to use another kind of API request and request data based on the article ID. </li><li>  We can also write a cycle, go through all the departments and get one frame with all the necessary data. </li></ul><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#   houses = ['Gryffindor', 'Hufflepuff', 'Ravenclaw', 'Slytherin'] mydf = pd.DataFrame() #  ID , URL    for house in houses: url = "http://harrypotter.wikia.com/api/v1/Articles/List?expand=1&amp;limit=1000&amp;category=" + house + 's' requested_url = requests.get(url) json_results = requested_url.json() info = json_results['items'] house_df = pd.DataFrame(info) house_df = house_df[house_df['type'] == 'article'] house_df.reset_index(drop=True, inplace=True) house_df.drop(['abstract', 'comments', 'ns', 'original_dimensions', 'revision', 'thumbnail', 'type'], axis=1, inplace=True) house_df['house'] = pd.Series([house]*len(house_df)) mydf = pd.concat([mydf, house_df]) mydf.reset_index(drop=True, inplace=True) #   print('Number of student articles: {}'.format(len(mydf))) print('') print(mydf.head()) print('') print(mydf.tail())</span></span></code> </pre> <br>  Number of articles about students: 748 <br><div style="text-align:center;"><img src="https://habrastorage.org/web/5a9/081/82c/5a908182cee04274b7d9931f8e6c48c0.png"></div><br><br><h2>  Retrieving article contents </h2><br>  Having ID articles, we can start requesting content.  But some of the articles are just HUGE, they contain an incredible amount of detail.  Just look at the articles about <a href="http://harrypotter.wikia.com/wiki/Harry_Potter">Harry Potter</a> and <a href="http://harrypotter.wikia.com/wiki/Tom_Riddle">Volan de Mort</a> ! <br><br><div style="text-align:center;"><img src="https://habrastorage.org/web/8c8/789/490/8c87894907354aa69b3125a95be90d84.gif"></div><br><br>  In articles about all key characters there is a section "Personality and Character Traits".  It would be logical to extract from this information that the Dispensing Hat will use when making decisions.  But this section is not in all articles, so if you focus only on him, then the number of characters will greatly decrease. <br><br>  The code below extracts the section ‚ÄúPersonality and Character Traits‚Äù from each article and calculates its length (number of characters).  Then, based on the ID, combines this data with our initial data frame mydf (this takes a little time). <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#        "     "    #     -    ,     #     text_dict = {} for iden in mydf['id']: url = 'http://harrypotter.wikia.com/api/v1/Articles/AsSimpleJson?id=' + str(iden) requested_url = requests.get(url) json_results = requested_url.json() sections = json_results['sections'] contents = [sections[i]['content'] for i, x in enumerate(sections) if sections[i]['title'] == 'Personality and traits'] if contents: paragraphs = contents[0] texts = [paragraphs[i]['text'] for i, x in enumerate(paragraphs)] all_text = ' '.join(texts) else: all_text = '' text_dict[iden] = all_text #    DataFrame     "   " text_df = pd.DataFrame.from_dict(text_dict, orient='index') text_df.reset_index(inplace=True) text_df.columns = ['id', 'text'] text_df['text_len'] = text_df['text'].map(lambda x: len(x)) #        mydf_all = pd.merge(mydf, text_df, on='id') mydf_all.sort_values('text_len', ascending=False, inplace=True) #   DataFrame    ,     "   " mydf_relevant = mydf_all[mydf_all['text_len'] &gt; 0] print('Number of useable articles: {}'.format(len(mydf_relevant))) print('') mydf_relevant.head()</span></span></code> </pre> <br>  Number of eligible articles: 94 <br><br><img src="https://habrastorage.org/web/c95/26c/048/c9526c04866541fcac96ffa0d162d41a.png"><br><br><h2>  Step Two: Obtain Faculty Characteristics with NLTK </h2><br>  Now we know the number of students, we must distribute them among the faculties.  To do this, make a list of characteristics of each department.  Let's start collecting from <a href="http://harrypotter.wikia.com/wiki/Main_Page">harrypotter.wikia.com</a> . <br><br><pre> <code class="python hljs">trait_dict = {} trait_dict[<span class="hljs-string"><span class="hljs-string">'Gryffindor'</span></span>] = [<span class="hljs-string"><span class="hljs-string">'bravery'</span></span>, <span class="hljs-string"><span class="hljs-string">'nerve'</span></span>, <span class="hljs-string"><span class="hljs-string">'chivalry'</span></span>, <span class="hljs-string"><span class="hljs-string">'daring'</span></span>, <span class="hljs-string"><span class="hljs-string">'courage'</span></span>] trait_dict[<span class="hljs-string"><span class="hljs-string">'Slytherin'</span></span>] = [<span class="hljs-string"><span class="hljs-string">'resourcefulness'</span></span>, <span class="hljs-string"><span class="hljs-string">'cunning'</span></span>, <span class="hljs-string"><span class="hljs-string">'ambition'</span></span>, <span class="hljs-string"><span class="hljs-string">'determination'</span></span>, <span class="hljs-string"><span class="hljs-string">'self-preservation'</span></span>, <span class="hljs-string"><span class="hljs-string">'fraternity'</span></span>, <span class="hljs-string"><span class="hljs-string">'cleverness'</span></span>] trait_dict[<span class="hljs-string"><span class="hljs-string">'Ravenclaw'</span></span>] = [<span class="hljs-string"><span class="hljs-string">'intelligence'</span></span>, <span class="hljs-string"><span class="hljs-string">'wit'</span></span>, <span class="hljs-string"><span class="hljs-string">'wisdom'</span></span>, <span class="hljs-string"><span class="hljs-string">'creativity'</span></span>, <span class="hljs-string"><span class="hljs-string">'originality'</span></span>, <span class="hljs-string"><span class="hljs-string">'individuality'</span></span>, <span class="hljs-string"><span class="hljs-string">'acceptance'</span></span>] trait_dict[<span class="hljs-string"><span class="hljs-string">'Hufflepuff'</span></span>] = [<span class="hljs-string"><span class="hljs-string">'dedication'</span></span>, <span class="hljs-string"><span class="hljs-string">'diligence'</span></span>, <span class="hljs-string"><span class="hljs-string">'fairness'</span></span>, <span class="hljs-string"><span class="hljs-string">'patience'</span></span>, <span class="hljs-string"><span class="hljs-string">'kindness'</span></span>, <span class="hljs-string"><span class="hljs-string">'tolerance'</span></span>, <span class="hljs-string"><span class="hljs-string">'persistence'</span></span>, <span class="hljs-string"><span class="hljs-string">'loyalty'</span></span>]</code> </pre> <br>  Please note that all words are nouns.  It's good.  We need consistency in describing character traits.  Some of them were not presented in the form of nouns, so we bring them to the general order: <br><br><ul><li>  "Ambitious" (adjective) - can be easily replaced by 'ambition' </li><li>  ‚ÄúHard work‚Äù, ‚Äúfair play‚Äù and ‚Äúunafraid of toil‚Äù - these phrases can also be easily replaced with single-word nouns: </li><li>  ‚ÄúHard work‚Äù -&gt; 'diligence' </li><li>  ‚ÄúFair play‚Äù -&gt; 'fairness' </li><li>  "Unafraid of toil" -&gt; 'persistence' </li></ul><br>  Having received a list of characteristics for each department, we can simply scan the ‚ÄúText‚Äù column and count the number of times the corresponding words were used in the descriptions of the characters.  Sounds easy, right? <br><br><div style="text-align:center;"><img src="https://habrastorage.org/web/55e/577/a5b/55e577a5b7e74c1699fe2994da9818e4.gif"></div><br><br>  Unfortunately, that's not all.  Here is a phrase from the section " <a href="http://harrypotter.wikia.com/wiki/Neville_Longbottom">Personality and Character Traits</a> " about Neville Longbottom: <br><br><blockquote>  When he was younger, Neville was clumsy, forgetful, shy, and many thought that he was ill suited to the Gryffindor faculty because he seemed <b>shy</b> . <br><br>  Thanks to the support of friends to whom he was very <b>devoted</b> ;  the inspiration of Professor Remus Lupine to face his fears in the third year of study;  and the fact that the torturers of his parents were walking free, Neville became <b>braver</b> , more self-confident, and <b>selfless</b> in the fight against Volan de Mort and his Death Eaters. <br><br>  (When he was younger, he was clumsy, forgetful, he was shy, <br><br>  It‚Äôs not a bad idea. ‚Äù assured, and <b>dedicated</b> to the fight against Lord Voldemort and his Death Eaters.) </blockquote><br>  Highlighted words should be counted in favor of some faculties, but they will not be counted, because they are adjectives.  Also, words like ‚Äúbravely‚Äù and ‚Äúbraveness‚Äù will not be taken into account.  In order for our classification algorithm to work correctly, you need to identify synonyms, antonyms and other word forms. <br><br><h2>  Synonyms </h2><br>  You can <code>synsets</code> synonyms using the <code>synsets</code> function from <a href="https://wordnet.princeton.edu/">WordNet</a> , the lexical database of the English language included in the <a href="http://www.nltk.org/">nltk</a> module (NLTK - Natural Language Toolkit).  ‚ÄúSynset‚Äù is ‚Äúsynonym set,‚Äù a collection of synonyms, or ‚Äúlemmas.‚Äù  The <code>synsets</code> function returns sets of synonyms that are associated with specific words. <br><br>  Puzzled?  Let's run the code, and then analyze it: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> nltk.corpus <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> wordnet <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> wn <span class="hljs-comment"><span class="hljs-comment">#      foo1 = wn.synsets('bravery') print("Synonym sets associated with the word 'bravery': {}".format(foo1)) foo2 = wn.synsets('fairness') print('') print("Synonym sets associated with the word 'fairness': {}".format(foo2)) foo3 = wn.synsets('wit') print('') print("Synonym sets associated with the word 'wit': {}".format(foo3)) foo4 = wn.synsets('cunning') print('') print("Synonym sets associated with the word 'cunning': {}".format(foo4)) foo4 = wn.synsets('cunning', pos=wn.NOUN) print('') print("Synonym sets associated with the *noun* 'cunning': {}".format(foo4)) print('') #   (""),    synset foo_list = [foo1, foo2, foo3, foo4] for foo in foo_list: for synset in foo: print((synset.name(), synset.lemma_names()))</span></span></code> </pre> <br>  Synonym sets associated with the word 'bravery': [Synset ('courage.n.01'), Synset ('fearlessness.n.01')] <br>  Synonym sets associated with the word 'fairness': [Synset (' fairness.n.01 '), Synset (' fairness.n.02 '), Synset (' paleness.n.02 '), Synset (' comeliness.n .01 ')] <br>  Synonym sets associated with the word 'wit': [Synset ('wit.n.01'), Synset ('brain.n.02'), Synset ('wag.n.01')] <br>  Synonym sets associated with the word 'cunning': [Synset ('craft.n.05'), Synset ('cunning.n.02'), Synset ('cunning.s.01'), Synset ('crafty.s .01 '), Synset (' clever.s.03 ')] <br>  Synonym sets associated with the noun 'cunning': [Synset ('craft.n.05'), Synset ('cunning.n.02')] <br>  ('courage.n.01', ['courage', 'courageousness',' bravery ',' braveness']) ('fearlessness.n.01', ['fearlessness',' bravery ']) (' fairness. n.01 ', [' fairness ',' equity ']) (' fairness.n.02 ', [' fairness ',' fair-mindedness ',' candor ',' candour ']) (' paleness.n. 02 ', [' paleness ',' blondness ',' fairness ']) (' comeliness.n.01 ', [' comeliness ',' fairness ',' loveliness ',' beauteousness ']) (' wit.n. 01 ', [' wit ',' humor ',' humor ',' witticism ',' wittiness']) ('brain.n.02', ['brain', 'brainpower', 'learning_ability', 'mental_capacity' , 'mentality', 'wit']) ('wag.n.01', ['wag', 'wit', 'card']) ('craft.n.05', ['craft', 'craftiness' , 'cunning', 'foxiness', 'guile', 'slyness', 'wiliness']) ('cunning.n.02', ['cunning']) <br><br>  So, we got a lot of output.  Consider some points and potential problems: <br><br><ul><li>  <code>wn.synsets('bravery')</code> is associated with two sets of synonyms: one for <code>courage.n.01</code> and one for <code>fearlessness.n.01</code> .  Let's see what this means: </li><li>  The first part ('courage' and 'fearlessness') is a word around which the entire concrete set of synonyms is built.  Let's call it the "central" word.  That is, all the synonyms in this set (‚Äúlemmas‚Äù) are similar in meaning to the central word. </li><li>  The second part ('n') means "noun" ("noun").  For example, the set associated with the word "cunning" includes <code>crafty.s.01</code> and <code>clever.s.03</code> (adjectives).  They appeared here because the word "cunning" can be both a noun and an adjective.  To leave only nouns, you can specify <code>wn.synsets('cunning', pos=wn.NOUN)</code> . </li><li>  The third part ('01') refers to the specific meaning of the central word.  For example, 'fairness' can mean both ‚Äúcompliance with rules and standards‚Äù and ‚Äúmaking judgments without discrimination or dishonesty‚Äù. </li></ul><br>  As you can see, the <code>synset</code> function can provide unwanted sets of synonyms.  For example, <code>paleness.n.02</code> (‚Äúhave light skin by nature‚Äù) and <code>comeliness.n.01</code> (‚Äúlook good and be attractive‚Äù) are also associated with the word ‚Äúfairness‚Äù.  These traits are clearly not associated with Hufflepuff (although <a href="https://www.pinterest.com/cherokee7743/matthew-lewis/">Neville Longbottom</a> grew up handsome), so you have to manually exclude such sets from our analysis. <br><br>  <b>Translation: getting synonyms harder than it sounds</b> <br><br><div style="text-align:center;"><img src="https://habrastorage.org/web/7a1/dd4/aec/7a1dd4aeca104de2824e5e73156a09ee.gif"></div><br><br><h2>  Antonyms and word forms </h2><br>  After we have collected all the synonyms, you need to take care of the antonyms and different word forms (for example, in relation to "bravery" - "brave", "bravely" and "braver").  A lot of hard work can be done in nltk, but you still have to manually fill out the verbiage and adjectives in a comparative / superlative degree. <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#    (),         "bravery" foo1 = wn.synsets('bravery') for synset in foo1: for lemma in synset.lemmas(): print("Synset: {}; Lemma: {}; Antonyms: {}; Word Forms: {}".format(synset.name(), lemma.name(), lemma.antonyms(), lemma.derivationally_related_forms())) print("")</span></span></code> </pre> <br>  Synset: courage.n.01;  Lemma: courage;  Antonyms: [Lemma ('cowardice.n.01.cowardice')];  Word Forms: [Lemma ('brave.a.01.courageous')] <br>  Synset: courage.n.01;  Lemma: courageousness;  Antonyms: [];  Word Forms: [Lemma ('brave.a.01.courageous')] <br>  Synset: courage.n.01;  Lemma: bravery;  Antonyms: [];  Word Forms: [] <br>  Synset: courage.n.01;  Lemma: braveness;  Antonyms: [];  Word Forms: [Lemma ('brave.a.01.brave'), Lemma ('audacious.s.01.brave')] <br>  Synset: fearlessness.n.01;  Lemma: fearlessness;  Antonyms: [Lemma ('fear.n.01.fear')];  Word Forms: [Lemma ('audacious.s.01.fearless'), Lemma ('unafraid.a.01.fearless')] <br>  Synset: fearlessness.n.01;  Lemma: bravery;  Antonyms: [];  Word Forms: [] <br><br><h2>  Putting it all together </h2><br>  The following code creates a list of synonyms, antonyms and word forms for each characteristic of the faculties.  For completeness, some of the words may be spelled incorrectly. <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#   ,    relevant_synsets = {} relevant_synsets['Ravenclaw'] = [wn.synset('intelligence.n.01'), wn.synset('wit.n.01'), wn.synset('brain.n.02'), wn.synset('wisdom.n.01'), wn.synset('wisdom.n.02'), wn.synset('wisdom.n.03'), wn.synset('wisdom.n.04'), wn.synset('creativity.n.01'), wn.synset('originality.n.01'), wn.synset('originality.n.02'), wn.synset('individuality.n.01'), wn.synset('credence.n.01'), wn.synset('acceptance.n.03')] relevant_synsets['Hufflepuff'] = [wn.synset('dedication.n.01'), wn.synset('commitment.n.04'), wn.synset('commitment.n.02'), wn.synset('diligence.n.01'), wn.synset('diligence.n.02'), wn.synset('application.n.06'), wn.synset('fairness.n.01'), wn.synset('fairness.n.01'), wn.synset('patience.n.01'), wn.synset('kindness.n.01'), wn.synset('forgivingness.n.01'), wn.synset('kindness.n.03'), wn.synset('tolerance.n.03'), wn.synset('tolerance.n.04'), wn.synset('doggedness.n.01'), wn.synset('loyalty.n.01'), wn.synset('loyalty.n.02')] relevant_synsets['Gryffindor'] = [wn.synset('courage.n.01'), wn.synset('fearlessness.n.01'), wn.synset('heart.n.03'), wn.synset('boldness.n.02'), wn.synset('chivalry.n.01'), wn.synset('boldness.n.01')] relevant_synsets['Slytherin'] = [wn.synset('resourcefulness.n.01'), wn.synset('resource.n.03'), wn.synset('craft.n.05'), wn.synset('cunning.n.02'), wn.synset('ambition.n.01'), wn.synset('ambition.n.02'), wn.synset('determination.n.02'), wn.synset('determination.n.04'), wn.synset('self-preservation.n.01'), wn.synset('brotherhood.n.02'), wn.synset('inventiveness.n.01'), wn.synset('brightness.n.02'), wn.synset('ingenuity.n.02')] # ,      def get_forms(lemma): drfs = lemma.derivationally_related_forms() output_list = [] if drfs: for drf in drfs: drf_pos = str(drf).split(".")[1] if drf_pos in ['n', 's', 'a']: output_list.append(drf.name().lower()) if drf_pos in ['s', 'a']: #  + "-ness"  +  &amp;   if len(drf.name()) == 3: last_letter = drf.name()[-1:] output_list.append(drf.name().lower() + last_letter + 'er') output_list.append(drf.name().lower() + last_letter + 'est') output_list.append(drf.name().lower()+'ness') output_list.append(drf.name().lower()+'ly') elif drf.name()[-4:] in ['able', 'ible']: output_list.append(drf.name().lower()+'r') output_list.append(drf.name().lower()+'st') output_list.append(drf.name().lower()+'ness') output_list.append(drf.name()[:-1].lower()+'y') elif drf.name()[-1:] == 'e': output_list.append(drf.name().lower()+'r') output_list.append(drf.name().lower()+'st') output_list.append(drf.name().lower()+'ness') output_list.append(drf.name().lower()+'ly') elif drf.name()[-2:] == 'ic': output_list.append(drf.name().lower()+'er') output_list.append(drf.name().lower()+'est') output_list.append(drf.name().lower()+'ness') output_list.append(drf.name().lower()+'ally') elif drf.name()[-1:] == 'y': output_list.append(drf.name()[:-1].lower()+'ier') output_list.append(drf.name()[:-1].lower()+'iest') output_list.append(drf.name()[:-1].lower()+'iness') output_list.append(drf.name()[:-1].lower()+'ily') else: output_list.append(drf.name().lower()+'er') output_list.append(drf.name().lower()+'est') output_list.append(drf.name().lower()+'ness') output_list.append(drf.name().lower()+'ly') return output_list else: return output_list #      #    ,      ,    ,      import copy new_trait_dict = copy.deepcopy(trait_dict) antonym_dict = {} #      ()   ;    (  )    for house, traits in trait_dict.items(): antonym_dict[house] = [] for trait in traits: synsets = wn.synsets(trait, pos=wn.NOUN) for synset in synsets: if synset in relevant_synsets[house]: for lemma in synset.lemmas(): new_trait_dict[house].append(lemma.name().lower()) if get_forms(lemma): new_trait_dict[house].extend(get_forms(lemma)) if lemma.antonyms(): for ant in lemma.antonyms(): antonym_dict[house].append(ant.name().lower()) if get_forms(ant): antonym_dict[house].extend(get_forms(ant)) new_trait_dict[house] = sorted(list(set(new_trait_dict[house]))) antonym_dict[house] = sorted(list(set(antonym_dict[house]))) #    print("Gryffindor traits: {}".format(new_trait_dict['Gryffindor'])) print("") print("Gryffindor anti-traits: {}".format(antonym_dict['Gryffindor'])) print("")</span></span></code> </pre> <br>  Gryffindor Characteristics: ['bold', 'bolder', 'boldest', 'boldly', 'boldness',' brass', 'brassier', 'brassiest', 'brassily', 'brassiness',' brassy ',' brave ',' bravely ',' braveness', 'braver', 'bravery', 'bravest', 'cheek', 'cheekier', 'cheekiest', 'cheekily', 'cheekiness',' cheeky ',' chivalry ', 'courage', 'courageous',' courageouser ',' courageousest ',' courageously ',' courageousness', 'daring', 'face', 'fearless',' fearlesser ',' fearlessest ',' fearlessly ',' fearlessness ',' gallantry ',' hardihood ',' hardiness', 'heart', 'mettle', 'nerve', 'nervier', 'nerviest', 'nervily', 'nerviness',' nervy ',' politesse ', 'spunk', 'spunkier', 'spunkiest', 'spunkily', 'spunkiness', 'spunky'] <br><br>  Gryffindor anti-characteristics: ['cowardice', 'fear', 'timid', 'timider', 'timidest', 'timidity', 'timidly', 'timidness'] <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># ,             from itertools import combinations def test_overlap(dict): results = [] house_combos = combinations(list(dict.keys()), 2) for combo in house_combos: results.append(set(dict[combo[0]]).isdisjoint(dict[combo[1]])) return results #   ;   "False" print("Any words overlap in trait dictionary? {}".format(sum(test_overlap(new_trait_dict)) != 6)) print("Any words overlap in antonym dictionary? {}".format(sum(test_overlap(antonym_dict)) != 6))</span></span></code> </pre> <br>  Are there any repetitions in the character traits dictionary?  False <br><br>  Repetitions in the dictionary of antonyms?  False <br><br><div style="text-align:center;"><img src="https://habrastorage.org/web/5ab/2ee/ea0/5ab2eeea087b4af1b2ce2bd965dd24c8.gif"></div><br><br><h2>  Step Three: We distribute students by faculty </h2><br>  It's time to distribute the students to the faculties!  Our classification algorithm will work as follows: <br><br><ul><li>  Passes for each word in the section "Personality and Character Traits" for each student. </li><li>  If a word is in the list of <b>features</b> characteristic of a particular faculty, then 1 is added to the points of this faculty. </li><li>  If a word is in the list of <b>anti-cricket</b> specific to a particular faculty, then 1 is subtracted from the points of this faculty. </li><li>  The student is assigned to the faculty that scores the most points. </li><li>  If there is a draw, then simply write ‚ÄúTie!‚Äù. </li></ul><br>  Suppose in the section "Personality and Character Traits" there is only the sentence "Alice was brave."  Then Alice will get 1 point for Gryffindor and 0 points for the rest of the faculties.  Accordingly, Alice will fall into Gryffindor. <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#  "word_tokenize",       from nltk import word_tokenize # ,   def sort_student(text): text_list = word_tokenize(text) text_list = [word.lower() for word in text_list] score_dict = {} houses = ['Gryffindor', 'Hufflepuff', 'Ravenclaw', 'Slytherin'] for house in houses: score_dict[house] = (sum([True for word in text_list if word in new_trait_dict[house]]) - sum([True for word in text_list if word in antonym_dict[house]])) sorted_house = max(score_dict, key=score_dict.get) sorted_house_score = score_dict[sorted_house] if sum([True for i in score_dict.values() if i==sorted_house_score]) == 1: return sorted_house else: return "Tie!" #   print(sort_student('Alice was brave')) print(sort_student('Alice was British'))</span></span></code> </pre> <br>  Gryffindor Tie! <br><br>  Looks like the function works.  Apply it to our data and see what happens! <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#   pd.options.mode.chained_assignment = None mydf_relevant['new_house'] = mydf_relevant['text'].map(lambda x: sort_student(x)) mydf_relevant.head(20)</span></span></code> </pre> <br><br><img src="https://habrastorage.org/web/caf/4a0/3f6/caf4a03f641e41febc3a4fee86e73d22.png"><br><br><pre> <code class="python hljs">print(<span class="hljs-string"><span class="hljs-string">"Match rate: {}"</span></span>.format(sum(mydf_relevant[<span class="hljs-string"><span class="hljs-string">'house'</span></span>] == mydf_relevant[<span class="hljs-string"><span class="hljs-string">'new_house'</span></span>]) / len(mydf_relevant))) print(<span class="hljs-string"><span class="hljs-string">"Percentage of ties: {}"</span></span>.format(sum(mydf_relevant[<span class="hljs-string"><span class="hljs-string">'new_house'</span></span>] == <span class="hljs-string"><span class="hljs-string">'Tie!'</span></span>) / len(mydf_relevant)))</code> </pre> <br>  Match: 0.2553191489361702 <br>  Share of draws: 0.32978723404255317 <br><br><div style="text-align:center;"><img src="https://habrastorage.org/web/5b4/d0e/300/5b4d0e300864439abaa68b606c8913aa.gif"></div><br><br>  Hm  We expected other results.  Let's find out why Volan de Mort got into Hufflepuff. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/web/770/629/e70/770629e70d094613b28917b6e86b6c07.gif"></div><br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#   -- tom_riddle = word_tokenize(mydf_relevant['text'].values[0]) tom_riddle = [word.lower() for word in tom_riddle] #        ,          words_dict = {} anti_dict = {} houses = ['Gryffindor', 'Hufflepuff', 'Ravenclaw', 'Slytherin'] for house in houses: words_dict[house] = [word for word in tom_riddle if word in new_trait_dict[house]] anti_dict[house] = [word for word in tom_riddle if word in antonym_dict[house]] print(words_dict) print("") print(anti_dict)</span></span></code> </pre> <br>  {'Slytherin': ['ambition'], 'Ravenclaw': ['intelligent', 'intelligent', 'mental', 'individual', 'mental', 'intelligent'], 'Hufflepuff': ['kind', 'loyalty', 'true', 'true', 'true', 'loyalty'], 'Gryffindor': ['brave', 'face', 'bold', 'face', 'bravery', 'brave', 'courageous', 'bravery']} <br>  {'Slytherin': [], 'Ravenclaw': ['common'], 'Hufflepuff': [], 'Gryffindor': ['fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'cowardice', 'fear', 'fear']} <br><br>  As you can see, Slytherin scored (1-0) = 1 points, Ravenclaw - (6-1) = 5, Hufflepuff - (6-0) = 6, Gryffindor - (8-9) = -1. <br><br>  It is interesting to note that in the section ‚ÄúPersonality and Character Traits‚Äù of Volan de Mort, the longest among all students, only 31 words coincided with dictionaries.  This means that the other students probably had much more coincidences.  That is, we make a decision on classification based on too little data, which explains the high proportion of errors and a large number of draws. <br><br><h2>  findings </h2><br>  The classifier we created does not work very well (a little more accurately than simple guessing), but do not forget that our approach was simplified.  Modern spam filters are very complex and do not classify only on the basis of the presence of a specific word.  So our algorithm can be improved so that it takes into account more information.  Here is a short list of ideas: <br><br><ul><li>   ,        . </li><li>    , , ¬´ ¬ª  . </li><li>                ¬´   ¬ª    ,      . </li><li>      ,  <a href="https://ru.wikipedia.org/wiki/%25D0%2590%25D0%25BD%25D0%25B0%25D0%25BB%25D0%25B8%25D0%25B7_%25D1%2582%25D0%25BE%25D0%25BD%25D0%25B0%25D0%25BB%25D1%258C%25D0%25BD%25D0%25BE%25D1%2581%25D1%2582%25D0%25B8_%25D1%2582%25D0%25B5%25D0%25BA%25D1%2581%25D1%2582%25D0%25B0">  </a> . </li></ul><br>         API  nltk,      .         ,        Python,    . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/web/211/f03/df2/211f03df24e146c5af90c353d0dc2e23.gif"></div></div><p>Source: <a href="https://habr.com/ru/post/331352/">https://habr.com/ru/post/331352/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../331342/index.html">How to competently deploy Wi-Fi at the hotel: typical questions and solutions</a></li>
<li><a href="../331344/index.html">ArrayBuffer and SharedArrayBuffer in JavaScript, Part 1: Short Memory Management Course</a></li>
<li><a href="../331346/index.html">DevOops 2017 Piter: New conference from the JUG.ru Group, let's talk about DevOps</a></li>
<li><a href="../331348/index.html">Ssh magic</a></li>
<li><a href="../331350/index.html">CodeRush for Roslyn for XAML features</a></li>
<li><a href="../331354/index.html">HelpDesk and ServiceDesk. What is it and why does your company need it</a></li>
<li><a href="../331356/index.html">Laws and projects that will change the face of Russian IT. Part II</a></li>
<li><a href="../331358/index.html">Configuring the TheOnionBox web interface to monitor Tor's relay node</a></li>
<li><a href="../331360/index.html">Useful features of Google Spreadsheet that are not in Excel</a></li>
<li><a href="../331364/index.html">Russian students dominate programming contests and American students are not surprised</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>