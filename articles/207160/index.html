<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Time Series Analysis with Python</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Good afternoon, dear readers. 
 In today's article, I will try to describe the process of analyzing time series using python and the statsmodels modul...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Time Series Analysis with Python</h1><div class="post__text post__text-html js-mediator-article">  Good afternoon, dear readers. <br>  In today's article, I will try to describe the process of analyzing time series using python and the <a href="http://statsmodels.sourceforge.net/stable/index.html">statsmodels</a> module.  This module provides a wide range of tools and methods for statistical analysis and econometrics.  I will try to show the main stages of the analysis of such series, in conclusion, we will build the <b>ARIMA</b> model. <br>  For example, we took real data on the turnover of one of the warehouse complexes in the Moscow region. <br><a name="habracut"></a><br><h4>  Loading and preliminary data processing </h4><br>  First, load the data and take a look at it: <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> pandas <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> read_csv, DataFrame <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> statsmodels.api <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> sm <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> statsmodels.iolib.table <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> SimpleTable <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.metrics <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> r2_score <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> ml_metrics <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> metrics In [<span class="hljs-number"><span class="hljs-number">2</span></span>]: dataset = read_csv(<span class="hljs-string"><span class="hljs-string">'tovar_moving.csv'</span></span>,<span class="hljs-string"><span class="hljs-string">';'</span></span>, index_col=[<span class="hljs-string"><span class="hljs-string">'date_oper'</span></span>], parse_dates=[<span class="hljs-string"><span class="hljs-string">'date_oper'</span></span>], dayfirst=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) dataset.head()</code> </pre> <br><table border="1"><tbody><tr><th></th><th>  Otgruzka </th><th>  priemka </th></tr><tr><th>  date_oper </th><th></th><th></th></tr><tr><th>  2009-09-01 </th><td>  179667 </td><td>  276712 </td></tr><tr><th>  2009-09-02 </th><td>  177670 </td><td>  164999 </td></tr><tr><th>  2009-09-03 </th><td>  152112 </td><td>  189181 </td></tr><tr><th>  2009-09-04 </th><td>  142938 </td><td>  254581 </td></tr><tr><th>  2009-09-05 </th><td>  130741 </td><td>  192486 </td></tr></tbody></table><br><br>  So, as you can see the <a href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.io.parsers.read_csv.html%3Fhighlight%3Dread_csv">read_csv ()</a> function, in this case, in addition to specifying the parameters that define the columns and index used, you can notice 3 more parameters for working with the date.  Let us dwell on them in more detail. <br>  <b>parse_dates</b> specifies the column names to be converted to a <i>DateTime</i> type.  It is worth noting that if there are empty values ‚Äã‚Äãin this column, the parsing will fail and the <i>object</i> type column will return.  To avoid this, you must add the <i><b>keep_default_na</b> = False</i> parameter. <br>  The final parameter <b>dayfirst</b> indicates the parsing function that the first in the line is the first day, not vice versa.  If you do not set this parameter, the function may not correctly convert dates and confuse the month and day in some places.  For example, <i>01/02/2013</i> will be converted to <i>02-01-2013</i> , which will be wrong. <br>  Let's separate in a separate series a time series with values ‚Äã‚Äãof shipments: 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <pre> <code class="python hljs">otg = dataset.Otgruzka otg.head()</code> </pre><br><table><tbody><tr><td colspan="2">  date_oper </td></tr><tr><td>  2009-09-01 </td><td>  179667 </td></tr><tr><td>  2009-09-02 </td><td>  177670 </td></tr><tr><td>  2009-09-03 </td><td>  152112 </td></tr><tr><td>  2009-09-04 </td><td>  142938 </td></tr><tr><td>  2009-09-05 </td><td>  130741 </td></tr><tr><td colspan="2">  Name: Otgruzka, dtype: int64 </td></tr></tbody></table><br>  So, we now have a time series and we can proceed to its analysis. <br><br><h4>  Time series analysis </h4><br>  To begin, let's look at the schedule for our series: <br><br><pre> <code class="python hljs">otg.plot(figsize=(<span class="hljs-number"><span class="hljs-number">12</span></span>,<span class="hljs-number"><span class="hljs-number">6</span></span>))</code> </pre><br><img src="https://habrastorage.org/getpro/habr/post_images/df0/23f/343/df023f343f1c2b413ba740906282a09a.png"><br>  From the graph it is clear that our series has a small amount of emissions that affect the scatter.  In addition, analyzing shipments for each day is not quite true, since, for example, at the end or beginning of the week there will be days in which the goods are shipped much more than the rest.  Therefore, it makes sense to go to the weekly interval and the average value of shipments on it, it will save us from emissions and reduce the fluctuations of our series.  In <b>pandas,</b> for this there is a convenient function <a href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.resample.html%3Fhighlight%3Dresample">resample ()</a> , as parameters it is passed the rounding period and the aggregate function: <br><br><pre> <code class="python hljs">otg = otg.resample(<span class="hljs-string"><span class="hljs-string">'W'</span></span>, how=<span class="hljs-string"><span class="hljs-string">'mean'</span></span>) otg.plot(figsize=(<span class="hljs-number"><span class="hljs-number">12</span></span>,<span class="hljs-number"><span class="hljs-number">6</span></span>))</code> </pre><br><img src="https://habrastorage.org/getpro/habr/post_images/a7f/d0e/3ee/a7fd0e3eedfd70241188a15d9eb9e099.png"><br>  As you can see, the new chart has no bright emissions and has a pronounced trend.  From this we can conclude that the series is not stationary <sup><a href="https://habr.com/ru/post/207160/">[1]</a></sup> . <br><br><pre> <code class="python hljs">itog = otg.describe() otg.hist() itog</code> </pre><br><table><tbody><tr><td>  count </td><td>  225 </td></tr><tr><td>  mean </td><td>  270858.285365 </td></tr><tr><td>  std </td><td>  118371.082975 </td></tr><tr><td>  min </td><td>  872.857143 </td></tr><tr><td>  25% </td><td>  180263.428571 </td></tr><tr><td>  50% </td><td>  277898.714286 </td></tr><tr><td>  75% </td><td>  355587.285714 </td></tr><tr><td>  max </td><td>  552485.142857 </td></tr><tr><td colspan="2">  dtype: float64 </td></tr></tbody></table><br><img src="https://habrastorage.org/getpro/habr/post_images/576/3ac/16d/5763ac16d2633ded47bdd4de1be5c0c7.png"><br><br>  As can be seen from the characteristics and the histogram, the series is more or less homogeneous and has a relatively small variation, as evidenced by the <a href="http://ru.wikipedia.org/wiki/%25D0%259A%25D0%25BE%25D1%258D%25D1%2584%25D1%2584%25D0%25B8%25D1%2586%25D0%25B8%25D0%25B5%25D0%25BD%25D1%2582_%25D0%25B2%25D0%25B0%25D1%2580%25D0%25B8%25D0%25B0%25D1%2586%25D0%25B8%25D0%25B8">coefficient of variation</a> : <img src="https://habrastorage.org/getpro/habr/post_images/4af/791/98a/4af79198a2adfb181b07286dcf7c572e.png" title="LaTeX: V = \ frac {\ sigma} {\ bar {x}}">  where <img src="https://habrastorage.org/getpro/habr/post_images/cbe/3a4/45f/cbe3a445f95d8bfc764b3683e45cc421.png" title="LaTeX: \ sigma">  - <a href="http://ru.wikipedia.org/wiki/%25D0%25A1%25D1%2580%25D0%25B5%25D0%25B4%25D0%25BD%25D0%25B5%25D0%25BA%25D0%25B2%25D0%25B0%25D0%25B4%25D1%2580%25D0%25B0%25D1%2582%25D0%25B8%25D1%2587%25D0%25B5%25D1%2581%25D0%25BA%25D0%25BE%25D0%25B5_%25D0%25BE%25D1%2582%25D0%25BA%25D0%25BB%25D0%25BE%25D0%25BD%25D0%25B5%25D0%25BD%25D0%25B8%25D0%25B5">standard deviation</a> , <img src="https://habrastorage.org/getpro/habr/post_images/2b4/40a/c3d/2b440ac3d4df6d4475d0dce66daf4bd3.png" title="LaTeX: \ bar {x}">  - arithmetic average of the sample.  In our case, it is equal to: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">print</span></span> <span class="hljs-string"><span class="hljs-string">'V = %f'</span></span> % (itog[<span class="hljs-string"><span class="hljs-string">'std'</span></span>]/itog[<span class="hljs-string"><span class="hljs-string">'mean'</span></span>])</code> </pre><br>  <i>V = 0.437022</i> <br><br>  We will carry out the Harkey <a href="http://ru.wikipedia.org/wiki/%25D0%25A2%25D0%25B5%25D1%2581%25D1%2582_%25D0%25A5%25D0%25B0%25D1%2580%25D0%25BA%25D0%25B8_%25E2%2580%2594_%25D0%2591%25D0%25B5%25D1%2580%25D0%25B0">-Bera test</a> to determine the nominal distribution, to confirm the assumption of homogeneity.  To do this, there is a function <a href="http://statsmodels.sourceforge.net/stable/generated/statsmodels.stats.stattools.jarque_bera.html">jarque_bera ()</a> , which returns the values ‚Äã‚Äãof these statistics: <br><br><pre> <code class="python hljs">row = [<span class="hljs-string"><span class="hljs-string">u'JB'</span></span>, <span class="hljs-string"><span class="hljs-string">u'p-value'</span></span>, <span class="hljs-string"><span class="hljs-string">u'skew'</span></span>, <span class="hljs-string"><span class="hljs-string">u'kurtosis'</span></span>] jb_test = sm.stats.stattools.jarque_bera(otg) a = np.vstack([jb_test]) itog = SimpleTable(a, row) <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> itog</code> </pre><br><img src="https://habrastorage.org/getpro/habr/post_images/342/703/c30/342703c3055e5b8a8dbf46ead588f886.png"><br><br>  The value of this statistic indicates that the null hypothesis of normal distribution is rejected with a small probability ( <i>probably&gt; 0.05</i> ), and, therefore, our series has a normal distribution. <br>  The <a href="http://statsmodels.sourceforge.net/stable/generated/statsmodels.iolib.table.SimpleTable.html">SimpleTable ()</a> function serves to format the output.  In our case, the input to it is an array of values ‚Äã‚Äã(dimensionality not greater than 2) and a list with the names of columns or rows. <br>  Many methods and models are based on assumptions about the stationarity of a series, but as noted earlier, our series most likely is not.  Therefore, to test the stationarity test, let's conduct a <a href="http://ru.wikipedia.org/wiki/%25D0%25A2%25D0%25B5%25D1%2581%25D1%2582_%25D0%2594%25D0%25B8%25D0%25BA%25D0%25B8_%25E2%2580%2594_%25D0%25A4%25D1%2583%25D0%25BB%25D0%25BB%25D0%25B5%25D1%2580%25D0%25B0">generalized Dickey-Fuller test</a> for the presence of unit roots.  For this, the <b>statsmodels</b> module has the <a href="http://statsmodels.sourceforge.net/stable/generated/statsmodels.tsa.stattools.adfuller.html">adfuller ()</a> function: <br><br><pre> <code class="python hljs">test = sm.tsa.adfuller(otg) <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> <span class="hljs-string"><span class="hljs-string">'adf: '</span></span>, test[<span class="hljs-number"><span class="hljs-number">0</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> <span class="hljs-string"><span class="hljs-string">'p-value: '</span></span>, test[<span class="hljs-number"><span class="hljs-number">1</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">print</span></span><span class="hljs-string"><span class="hljs-string">'Critical values: '</span></span>, test[<span class="hljs-number"><span class="hljs-number">4</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> test[<span class="hljs-number"><span class="hljs-number">0</span></span>]&gt; test[<span class="hljs-number"><span class="hljs-number">4</span></span>][<span class="hljs-string"><span class="hljs-string">'5%'</span></span>]: <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> <span class="hljs-string"><span class="hljs-string">'  ,   '</span></span> <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> <span class="hljs-string"><span class="hljs-string">'  ,  '</span></span></code> </pre><br>  <i>adf: -1.38835541357</i> <i><br></i>  <i>p-value: 0.58784577297</i> <i><br></i>  <i>Critical values: {'5%': -2.8753374677799957, '1%': -3.4617274344627398, '10% ': -2.5741240890815571}</i> <i><br></i>  <i>there are single roots, the series is not stationary</i> <i><br></i> <br><br>  The test confirmed the assumptions about the non-stationarity of the series.  In many cases, taking the difference of rows allows this. If, for example, the first differences of a row are stationary, then it is called an <i>integrated series of the first order</i> . <br>  So let's define the <i>order of the integrated series</i> for our series: <br><br><pre> <code class="python hljs">otg1diff = otg.diff(periods=<span class="hljs-number"><span class="hljs-number">1</span></span>).dropna()</code> </pre><br>  In the above code, the <a href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.diff.html%3Fhighlight%3Ddiff">diff ()</a> function calculates the difference of the original series with the specified period offset.  The offset period is passed as the <i>period</i> parameter.  Since  in difference the first value is vague, then we need to get rid of it for this and use the dropna () method. <br>  Check the resulting series for stationarity: <br><br><pre> <code class="python hljs">test = sm.tsa.adfuller(otg1diff) <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> <span class="hljs-string"><span class="hljs-string">'adf: '</span></span>, test[<span class="hljs-number"><span class="hljs-number">0</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> <span class="hljs-string"><span class="hljs-string">'p-value: '</span></span>, test[<span class="hljs-number"><span class="hljs-number">1</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">print</span></span><span class="hljs-string"><span class="hljs-string">'Critical values: '</span></span>, test[<span class="hljs-number"><span class="hljs-number">4</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> test[<span class="hljs-number"><span class="hljs-number">0</span></span>]&gt; test[<span class="hljs-number"><span class="hljs-number">4</span></span>][<span class="hljs-string"><span class="hljs-string">'5%'</span></span>]: <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> <span class="hljs-string"><span class="hljs-string">'  ,   '</span></span> <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> <span class="hljs-string"><span class="hljs-string">'  ,  '</span></span></code> </pre><br>  <i>adf: -5.95204224907</i> <i><br></i>  <i>p-value: 2.13583392404e-07</i> <i><br></i>  <i>Critical values: {'5%': -2.8755379867788462, '1%': -3.4621857592784546, '10% ': -2.574231080806213}</i> <i><br></i>  <i>there are no unit roots, the row is stationary</i> <i><br></i> <br>  As can be seen from the code above, the resulting series of first differences approached the stationary one.  For complete confidence, we divide it into several intervals and verify the mat.  expectations at different intervals: <br><br><pre> <code class="python hljs">m = otg1diff.index[len(otg1diff.index)/<span class="hljs-number"><span class="hljs-number">2</span></span>+<span class="hljs-number"><span class="hljs-number">1</span></span>] r1 = sm.stats.DescrStatsW(otg1diff[m:]) r2 = sm.stats.DescrStatsW(otg1diff[:m]) <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> <span class="hljs-string"><span class="hljs-string">'p-value: '</span></span>, sm.stats.CompareMeans(r1,r2).ttest_ind()[<span class="hljs-number"><span class="hljs-number">1</span></span>]</code> </pre><br>  <i>p-value: 0.693072039563</i> <br><br>  A high <i>p-value</i> gives us the opportunity to argue that the null hypothesis of equality of averages is correct, which indicates the stationarity of the series.  It remains to make sure that there is no trend for this. Let's build a graph of our new series: <br><br><pre> <code class="python hljs">otg1diff.plot(figsize=(<span class="hljs-number"><span class="hljs-number">12</span></span>,<span class="hljs-number"><span class="hljs-number">6</span></span>))</code> </pre> <br><img src="https://habrastorage.org/getpro/habr/post_images/bab/891/d7d/bab891d7d73a02c1772bb5270d3fd81f.png"><br>  The trend is really absent, so the series of first differences is stationary, and our initial series is an <i>integrated series of the first order</i> . <br><br><h4>  Building a time series model </h4><br>  For the simulation, we will use the <a href="http://ru.wikipedia.org/wiki/ARIMA">ARIMA</a> model, built for a number of first differences. <br>  So, to build a model, we need to know its order, consisting of 2 parameters: <br><ol><li>  <b>p</b> is the order of the <a href="http://ru.wikipedia.org/wiki/%25D0%2590%25D0%25B2%25D1%2582%25D0%25BE%25D1%2580%25D0%25B5%25D0%25B3%25D1%2580%25D0%25B5%25D1%2581%25D1%2581%25D0%25B8%25D0%25BE%25D0%25BD%25D0%25BD%25D0%25B0%25D1%258F_%25D0%25BC%25D0%25BE%25D0%25B4%25D0%25B5%25D0%25BB%25D1%258C">AR</a> component <br></li><li>  <b>d</b> - the order of the integrated series <br></li><li>  <b>q</b> - <a href="http://ru.wikipedia.org/wiki/%25D0%259C%25D0%25BE%25D0%25B4%25D0%25B5%25D0%25BB%25D1%258C_%25D1%2581%25D0%25BA%25D0%25BE%25D0%25BB%25D1%258C%25D0%25B7%25D1%258F%25D1%2589%25D0%25B5%25D0%25B3%25D0%25BE_%25D1%2581%25D1%2580%25D0%25B5%25D0%25B4%25D0%25BD%25D0%25B5%25D0%25B3%25D0%25BE">MA</a> component order <br></li></ol><br><br>  The parameter <b>d</b> is and it is equal to 1, it remains to determine <b>p</b> and <b>q</b> .  To determine them, we need to study the <a href="http://ru.wikipedia.org/wiki/%25D0%2590%25D0%25B2%25D1%2582%25D0%25BE%25D0%25BA%25D0%25BE%25D1%2580%25D1%2580%25D0%25B5%25D0%25BB%25D1%258F%25D1%2586%25D0%25B8%25D0%25BE%25D0%25BD%25D0%25BD%25D0%25B0%25D1%258F_%25D1%2584%25D1%2583%25D0%25BD%25D0%25BA%25D1%2586%25D0%25B8%25D1%258F">autocorrelation (ACF)</a> and partially autocorrelation (PACF) functions for a number of first differences. <br>  <b>ACF</b> will help us determine <b>q</b> , because by its correlogram you can determine the number of autocorrelation coefficients that are very different from 0 in the <b>MA</b> model <br>  <b>PACF</b> will help us determine <b>p</b> , because from its correlogram you can determine the maximum coefficient number that is very different from 0 in the <b>AR</b> model. <br>  To construct the corresponding correlograms, the following functions are <a href="http://statsmodels.sourceforge.net/stable/generated/statsmodels.graphics.tsaplots.plot_acf.html">included</a> in the statsmodels package: <a href="http://statsmodels.sourceforge.net/stable/generated/statsmodels.graphics.tsaplots.plot_acf.html">plot_acf ()</a> and <a href="http://statsmodels.sourceforge.net/stable/generated/statsmodels.graphics.tsaplots.plot_pacf.html">plot_pacf ()</a> .  They display <i>ACF</i> and <i>PACF plots</i> , in which the lag numbers are plotted along the X axis, and the values ‚Äã‚Äãof the corresponding functions along the Y axis.  It should be noted that the number of lags in functions determines the number of significant coefficients.  So, our functions look like this: <br><br><pre> <code class="python hljs">ig = plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">12</span></span>,<span class="hljs-number"><span class="hljs-number">8</span></span>)) ax1 = fig.add_subplot(<span class="hljs-number"><span class="hljs-number">211</span></span>) fig = sm.graphics.tsa.plot_acf(otg1diff.values.squeeze(), lags=<span class="hljs-number"><span class="hljs-number">25</span></span>, ax=ax1) ax2 = fig.add_subplot(<span class="hljs-number"><span class="hljs-number">212</span></span>) fig = sm.graphics.tsa.plot_pacf(otg1diff, lags=<span class="hljs-number"><span class="hljs-number">25</span></span>, ax=ax2)</code> </pre> <br><img src="https://habrastorage.org/getpro/habr/post_images/d53/987/229/d539872297b00b030d348bf64d2de75b.png"><br>  After studying the <i>PACF</i> correlogram, <i>we</i> can conclude that <b>p = 1</b> , since  on it only 1 lag is very different from zero.  According to the <i>ACF</i> correlogram, you can see that <b>q = 1</b> , since  after lag 1, the values ‚Äã‚Äãof the functions fall sharply. <br>  So, when all the parameters are known, you can build a model, but to build it, we will not take all the data, but only a part.  We will leave the data from the parts not included in the model to check the accuracy of the forecast of our model: <br><br><pre> <code class="python hljs">src_data_model = otg[:<span class="hljs-string"><span class="hljs-string">'2013-05-26'</span></span>] model = sm.tsa.ARIMA(src_data_model, order=(<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>), freq=<span class="hljs-string"><span class="hljs-string">'W'</span></span>).fit(full_output=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, disp=<span class="hljs-number"><span class="hljs-number">0</span></span>)</code> </pre> <br>  The <i>trend</i> parameter is responsible for the presence of a constant in the model.  Let's display information on the resulting model: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">print</span></span> model.summary()</code> </pre> <br><img src="https://habrastorage.org/getpro/habr/post_images/456/8cb/60c/4568cb60c266c0d0fda33ae587fd54be.png"><br><br>  As can be seen from this information in our model, all the coefficients are significant and you can proceed to the evaluation of the model. <br><br><h4>  Model analysis and evaluation </h4><br>  We will check the residuals of this model for compliance with <a href="http://ru.wikipedia.org/wiki/%25C1%25E5%25EB%25FB%25E9_%25F8%25F3%25EC">‚Äúwhite noise‚Äù</a> , and also analyze the residual correlogram, as this can help us in determining the regression elements important for inclusion and prediction. <br>  So the first thing we will do is conduct <a href="http://ru.wikipedia.org/wiki/Q-%25D1%2582%25D0%25B5%25D1%2581%25D1%2582_%25D0%259B%25D1%258C%25D1%258E%25D0%25BD%25D0%25B3%25D0%25B0_%25E2%2580%2594_%25D0%2591%25D0%25BE%25D0%25BA%25D1%2581%25D0%25B0">a Ljung-Box Q test</a> to test the hypothesis that the residues are random, that is, they are ‚Äúwhite noise‚Äù.  This test is conducted on the remnants of the model <b>ARIMA</b> .  Thus, we need to first obtain the remnants of the model and build an ACF for them, and then mark the test for the resulting coefficients.  With the help of <i>statsmadels</i> you can do it like this: <br><br><pre> <code class="python hljs">q_test = sm.tsa.stattools.acf(model.resid, qstat=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) <span class="hljs-comment"><span class="hljs-comment"># resid,   , qstat=True,       - print DataFrame({'Q-stat':q_test[1], 'p-value':q_test[2]})</span></span></code> </pre> <br><div class="spoiler">  <b class="spoiler_title">Result</b> <div class="spoiler_text"><table><tbody><tr><th></th><th>  Q-stat </th><th>  p-value </th></tr><tr><td>  0 </td><td>  0.531426 </td><td>  0.466008 </td></tr><tr><td>  one </td><td>  3.073217 </td><td>  0.215109 </td></tr><tr><td>  2 </td><td>  3.644229 </td><td>  0.302532 </td></tr><tr><td>  3 </td><td>  3.906326 </td><td>  0.418832 </td></tr><tr><td>  four </td><td>  4.701433 </td><td>  0.453393 </td></tr><tr><td>  five </td><td>  5.433745 </td><td>  0.489500 </td></tr><tr><td>  6 </td><td>  5.444254 </td><td>  0.605916 </td></tr><tr><td>  7 </td><td>  5.445309 </td><td>  0.709091 </td></tr><tr><td>  eight </td><td>  5.900762 </td><td>  0.749808 </td></tr><tr><td>  9 </td><td>  6.004928 </td><td>  0.814849 </td></tr><tr><td>  ten </td><td>  6.155966 </td><td>  0.862758 </td></tr><tr><td>  eleven </td><td>  6.299958 </td><td>  0.900213 </td></tr><tr><td>  12 </td><td>  12.731542 </td><td>  0.468755 </td></tr><tr><td>  13 </td><td>  14.707894 </td><td>  0.398410 </td></tr><tr><td>  14 </td><td>  20.720607 </td><td>  0.145996 </td></tr><tr><td>  15 </td><td>  23.197433 </td><td>  0.108558 </td></tr><tr><td>  sixteen </td><td>  23.949801 </td><td>  0.120805 </td></tr><tr><td>  17 </td><td>  24.119236 </td><td>  0.151160 </td></tr><tr><td>  18 </td><td>  25.616184 </td><td>  0.141243 </td></tr><tr><td>  nineteen </td><td>  26.035165 </td><td>  0.164654 </td></tr><tr><td>  20 </td><td>  28.969880 </td><td>  0.114727 </td></tr><tr><td>  21 </td><td>  28.973660 </td><td>  0.145614 </td></tr><tr><td>  22 </td><td>  29.017716 </td><td>  0.179723 </td></tr><tr><td>  23 </td><td>  32.114006 </td><td>  0.124191 </td></tr><tr><td>  24 </td><td>  32.284805 </td><td>  0.149936 </td></tr><tr><td>  25 </td><td>  33.123395 </td><td>  0.158548 </td></tr><tr><td>  26 </td><td>  33.129059 </td><td>  0.192844 </td></tr><tr><td>  27 </td><td>  33.760488 </td><td>  0.208870 </td></tr><tr><td>  28 </td><td>  38.421053 </td><td>  0.113255 </td></tr><tr><td>  29 </td><td>  38.724226 </td><td>  0.132028 </td></tr><tr><td>  thirty </td><td>  38.973426 </td><td>  0.153863 </td></tr><tr><td>  31 </td><td>  38.978172 </td><td>  0.184613 </td></tr><tr><td>  32 </td><td>  39.318954 </td><td>  0.207819 </td></tr><tr><td>  33 </td><td>  39.382472 </td><td>  0.241623 </td></tr><tr><td>  34 </td><td>  39.423763 </td><td>  0.278615 </td></tr><tr><td>  35 </td><td>  40.083689 </td><td>  0.293860 </td></tr><tr><td>  36 </td><td>  43.849515 </td><td>  0.203755 </td></tr><tr><td>  37 </td><td>  45.704476 </td><td>  0.182576 </td></tr><tr><td>  38 </td><td>  47.132911 </td><td>  0.174117 </td></tr><tr><td>  39 </td><td>  47.365305 </td><td>  0.197305 </td></tr></tbody></table><br></div></div><br>  The value of these statistics and p-values ‚Äã‚Äãindicate that the hypothesis of randomness of residuals is not rejected, and most likely this process represents ‚Äúwhite noise‚Äù. <br>  Now let's calculate the coefficient of determination <img src="https://habrastorage.org/getpro/habr/post_images/879/d5c/f0f/879d5cf0fa87faddaefd28fc0906ad27.png" title="LaTeX: R ^ 2">  To understand what percentage of observations this model describes: <br><br><pre> <code class="python hljs">pred = model.predict(<span class="hljs-string"><span class="hljs-string">'2013-05-26'</span></span>,<span class="hljs-string"><span class="hljs-string">'2014-12-31'</span></span>, typ=<span class="hljs-string"><span class="hljs-string">'levels'</span></span>) trn = otg[<span class="hljs-string"><span class="hljs-string">'2013-05-26'</span></span>:] r2 = r2_score(trn, pred[<span class="hljs-number"><span class="hljs-number">1</span></span>:<span class="hljs-number"><span class="hljs-number">32</span></span>]) <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> <span class="hljs-string"><span class="hljs-string">'R^2: %1.2f'</span></span> % r2</code> </pre> <br>  <i>R ^ 2: -0.03</i> <br><br>  The standard deviation <sup><a href="https://habr.com/ru/post/207160/">[2] of</a></sup> our model: <br><br><pre> <code class="python hljs">metrics.rmse(trn,pred[<span class="hljs-number"><span class="hljs-number">1</span></span>:<span class="hljs-number"><span class="hljs-number">32</span></span>])</code> </pre> <br>  <i>80919.057367642512</i> <br><br>  Mean absolute error <sup><a href="https://habr.com/ru/post/207160/">[2] of the</a></sup> forecast: <br><br><pre> <code class="python hljs">metrics.mae(trn,pred[<span class="hljs-number"><span class="hljs-number">1</span></span>:<span class="hljs-number"><span class="hljs-number">32</span></span>])</code> </pre> <br>  <i>63092.763277651895</i> <br><br>  It remains to draw our forecast on the chart: <br><br><pre> <code class="python hljs">otg.plot(figsize=(<span class="hljs-number"><span class="hljs-number">12</span></span>,<span class="hljs-number"><span class="hljs-number">6</span></span>)) pred.plot(style=<span class="hljs-string"><span class="hljs-string">'r--'</span></span>)</code> </pre> <br><img src="https://habrastorage.org/getpro/habr/post_images/96d/886/1ee/96d8861ee02340c0d2ccdf49c89bf365.png"><br><br><h4>  Conclusion </h4><br>  As you can see from the graph, our model is not building a very good forecast.  This is partly due to emissions in the original data that we have not completely removed, as well as the <b>ARIMA</b> module of the <i>statsmodels</i> package, <i>since</i> it is fairly new.  The article is more aimed at showing how exactly you can analyze time series in python.  I would also like to note that in the package reviewed today, various methods of regression analysis are very fully implemented (I will try to show in further articles). <br>  In general, the statsmodels package is fully suitable for small studies, but for serious scientific work it is still damp and some tests and statistics are missing in it. <br><br><h4>  Links </h4><br><ol><li>  I.I.  Eliseev.  Econometrics <br></li><li>  <a href="http://www.basegroup.ru/solutions/scripts/details/compare_model/">Comparison of time series models</a> <br></li></ol></div><p>Source: <a href="https://habr.com/ru/post/207160/">https://habr.com/ru/post/207160/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../207146/index.html">10,000,000 repositories</a></li>
<li><a href="../207148/index.html">PostgreSQL New Year Check</a></li>
<li><a href="../207152/index.html">Holiday greetings!</a></li>
<li><a href="../207154/index.html">MINIX X7 - Rockchip RK3188 high-quality media player</a></li>
<li><a href="../207156/index.html">How we integrate the SaaS solution with the customer‚Äôs accounting system</a></li>
<li><a href="../207162/index.html">IPv6 addresses in Beeline mobile network: test in Voronezh</a></li>
<li><a href="../207166/index.html">Choosing a business direction or how to win holivar</a></li>
<li><a href="../207170/index.html">Manipulations with quantization matrices. Part 2</a></li>
<li><a href="../207172/index.html">Rails 4.1 beta1 out</a></li>
<li><a href="../207174/index.html">Canonical released a preview of the Ubuntu Touch dual boot for smartphones</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>