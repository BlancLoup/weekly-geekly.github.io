<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Citymobil - a guide for startups to increase stability against the background of growth. Part 2. What are the types of accidents?</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="This is the second article from the series about how we in Citymobil increased the stability of the service (you can read the first one here ). In thi...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Citymobil - a guide for startups to increase stability against the background of growth. Part 2. What are the types of accidents?</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/getpro/habr/post_images/61f/db5/50d/61fdb550d3b183fa7f134339397e276f.png"><br><br>  This is the second article from the series about how we in Citymobil increased the stability of the service (you can read the first one <a href="https://habr.com/ru/company/mailru/blog/444818/">here</a> ).  In this article I will delve into the specifics of the analysis of accidents.  But before that, I will highlight one point that I should have thought about in advance and covered in the first article, but did not think about it.  And about which I learned from the feedback of readers.  The second article gives me a chance to eliminate this annoying flaw. <br><a name="habracut"></a><br><h2>  0. Prologue </h2><br>  One of the readers was asked a very fair question: ‚ÄúWhat is difficult in the taxi service backend?‚Äù The question is good.  I asked him myself last summer before I started working at Citymobil.  I then thought, "think a taxi, an application with three buttons."  What is difficult in it?  But it turned out that this is a very high-tech service and the most complex product.  In order to at least roughly understand what it is about and what kind of big technology is in fact, I‚Äôll tell you about several areas of Citymobil's food business: <br><br><ul><li>  Pricing.  The pricing team deals with pricing at each point and at each point in time.  The price is determined by the prediction of the balance of supply and demand based on statistics and other data.  All this makes a large, complex and constantly evolving service based on machine learning. </li><li>  Pricing.  The implementation of various payment methods, the logic of surcharges after the end of the trip, the retention of funds on bank cards, billing, interaction with partners and drivers. </li><li>  Distribution of orders.  On which machine to distribute the order of the client?  For example, the distribution option to the nearest one is not the best in terms of increasing the number of trips.  A more correct option is to match customers and cars in such a way as to maximize the number of trips, given the likelihood of cancellation by this particular client under these conditions (because it takes a long time to wait) and cancellation or sabotage of the order by this driver (because it takes too long to drive or too low check). </li><li>  Geo.  Everything related to the search and sadzhest addresses, landing points, adjusting the time of filing (our partners supplying maps and traffic jams do not always provide accurate information on ETA, taking into account traffic jams), improving the accuracy of forward and backward geocoding, improving the accuracy of the machine feed.  There is a lot of work with data, a lot of analytics, a lot of machine-based services. </li><li>  Antifraud.  The difference in the price of a trip for a passenger and for a driver (for example, on short trips) creates an economic incentive for froders who are trying to steal our money.  The fight against fraud is somewhat similar to the fight against spam in the mail service - completeness and accuracy are important.  It is necessary to block the maximum number of froders (completeness), but good users should not be taken for froders (accuracy). </li><li>  Motivation drivers.  The driver motivation team develops everything related to enhancing the usability of our platform by drivers and driver loyalty through various types of motivations.  For example, make X trips and get extra Y rubles for it.  Or buy a shift for Z rubles and ride without a fee. </li><li>  Backend driver application.  A list of orders, a demand card (a hint to where the driver should go to maximize his earnings), a roll-out of status changes, a communication system with drivers and much more. </li><li>  The backend of the client application (this is probably the most obvious part, and that is usually understood as a taxi backend): placing orders, sending statuses about changing the order status, ensuring the movement of machines on the map on the order and on the feed, backend tips and etc. </li></ul><br>  This is all the tip of the iceberg.  Functionality is much more.  Behind a simple user-friendly interface, there is a huge underwater part of the iceberg. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      And now we return to accidents.  For six months of conducting the accident history, we have compiled the following categorization: <br><br><ul><li>  bad release, 500th errors; </li><li>  bad release, non-optimal code, load on the base; </li><li>  unsuccessful manual intervention in the system; </li><li>  Easter egg; </li><li>  external causes; </li><li>  bad release, broken functionality. </li></ul><br>  Below I will write down what conclusions we did on the most common types of accidents. <br><br><h2>  1. Bad release, 500th errors </h2><br>  Almost all of our backend is written in PHP, an interpreted language with weak typing.  It happens, you roll out the code, but it falls due to an error in the name of the class or function.  And this is just one of the examples when the 500th error appears.  It may also appear in the case of a logical error in the code;  unrelated the wrong branch;  accidentally deleted the folder with the code;  left in the code temporary artifacts needed for testing;  did not change the structure of the tables according to the new code;  did not restart or stop the necessary cron-scripts. <br><br>  We struggled with this problem consistently in several stages.  Lost trips due to a bad release are obviously proportional to the time it was in operation.  That is, it is necessary to do everything possible so that a bad release is in operation as little time as possible.  Any change in the development process that reduces the average time a bad release is in operation by at least 1 second is positive for the business and should be implemented. <br><br>  A bad release, or even any accident in production, passes through two states, which we call the ‚Äúpassive stage‚Äù and ‚Äúactive stage‚Äù.  The passive stage is when we are not yet aware of the accident.  The active stage is when we already know.  The accident begins in the passive stage, and over time, when we learn about it, the accident goes into the active stage - we begin to deal with it: first we diagnose, and then we fix it. <br><br>  To reduce the duration of any accident in production, it is necessary to reduce the average duration of both the passive and active stages.  The same applies to a bad release, because it is in itself a kind of accident. <br><br>  We began to analyze our current crash repair process.  Bad releases that we encountered at the time of the analysis started resulted in an idle time (full or partial) for an average of 20-25 minutes.  The passive stage usually took 15 minutes, the active - 10 minutes.  During the passive stage, complaints from users who were processed by the contact center began, and after some threshold the contact center complained to the general chat rooms in Slack.  Sometimes one of the employees complained when he could not order a taxi.  An employee complaint was a signal to us about a serious problem.  After the transition of a bad release to the active stage, we began to diagnose the problem, analyzed the latest releases, various graphs and logs in order to establish the cause of the accident.  After finding out the reason, we rolled back the code if the bad release was pumped last, or did a new rollback with the revert of the bad release commit. <br><br>  That is the process of dealing with bad releases, we had to improve. <br><br><h3>  1.1.  Reduction of the passive stage </h3><br>  First of all, we noticed that if a bad release is accompanied by 500 errors, we can understand without complaint that a problem has occurred.  Fortunately, all the 500th errors were recorded in New Relic (this is one of the monitoring systems we use), and it remained only to fasten SMS and IVR notifications about exceeding a certain frequency of five hundred meters (the threshold was constantly reduced over time). <br><br>  This led to the fact that the active stage of the accident ‚ÄúBad release, 500th mistakes‚Äù began almost immediately after the release.  The process in the event of an accident began to look like this: <br><br><ol><li>  The programmer deploys the code. </li><li>  The release leads to an accident (massive 500-ki). </li><li>  SMS comes. </li><li>  Programmers and admins begin to understand (sometimes not immediately, but after 2-3 minutes: SMS can be delayed, the sound on the phone can be turned off, and the immediate action culture after SMS cannot appear in one day). </li><li>  The active stage of the accident begins, which lasts the same 10 minutes as before. </li></ol><br>  Thus, the passive stage was reduced from 15 minutes to 3. <br><br><h3>  1.2.  Further reduction of the passive stage </h3><br>  Despite the reduction of the passive stage to 3 minutes, even such a short passive stage strained us more than the active one, because during the active stage we already do something to solve the problem, and during the passive service does not work in whole or in part, but ‚Äú men do not know. " <br><br>  To further reduce the passive stage, we decided to donate three minutes of developer time after each release.  The idea was very simple: you roll out the code and look at New Relic, Sentry, Kibana for three minutes, are there any 500th errors.  As soon as you see a problem there, then a priori you assume that it is related to your code and you begin to understand. <br><br>  We chose three minutes on the basis of statistics: sometimes problems appeared on charts with a delay of 1-2 minutes, but there were not more than three minutes. <br><br>  This rule was entered into the do's &amp; dont's.  At first, it was not always executed, but gradually the developers got used to the rule as to basic hygiene: brushing your teeth in the morning is also a waste of time, but it is necessary to do so. <br><br>  As a result, the passive stage was reduced to 1 minute (the charts still sometimes were late).  As a pleasant surprise, it also reduced the active stage.  After all, the developer meets the problem in good shape and is ready to immediately roll back your code.  Although this does not always help, because  the problem could arise due to someone else‚Äôs parallel-rolling code.  But, nevertheless, the active stage on average was reduced to 5 minutes. <br><br><h3>  1.3.  Further reduction of the active stage </h3><br>  More or less satisfied with one minute of the passive stage, we began to think about further reducing the active stage.  First of all, we paid attention to the history of problems (it is a cornerstone in the building of our stability!) And found that in many cases we don‚Äôt roll back right away because we don‚Äôt understand which version to roll back to, because there are many parallel releases.  To solve this problem, we introduced the following rule (and recorded it in do's &amp; dont's): before release you write to the chat in Slack, what are you trying to do, and in case of an accident you write to the chat ‚Äúaccident, don‚Äôt roll!‚Äù.  In addition, we started automatically reporting via SMS about the facts of the release, in order to notify those who do not enter the chat. <br><br>  This simple rule dramatically reduced the number of releases already in the course of accidents and reduced the active stage - from 5 minutes to 3. <br><br><h3>  1.4.  An even shorter active stage </h3><br>  Despite the fact that we warned about all releases and accidents in the chat, sometimes race conditions arose - one wrote about the release, and the other at that moment was already rolling out;  or the accident started, they wrote about it in the chat, and someone just rolled out a new code.  These circumstances lengthen the diagnosis.  To solve this problem, we have implemented an automatic ban on parallel releases.  The idea is very simple: after each release, the CI / CD system prohibits everyone to roll out over the next 5 minutes, except the author of the last release (so that he can roll back or roll a hotfix if necessary) and several very experienced developers (for emergency).  In addition, the CI / CD system prohibits rolling out during an accident (that is, from the moment of receiving the notification of the beginning of the accident until the moment of receipt of the notification of its completion). <br><br>  Thus, the process has become such: the developer rolls out, he keeps track of the graphics for three minutes, and after that two more minutes no one can roll out anything.  If there is a problem, the developer rolls back the release.  This rule dramatically simplified diagnosis, and the total duration of the active and passive stages was reduced from 3 + 1 = 4 minutes to 1 + 1 = 2 minutes. <br><br>  But two minutes of an accident is a lot.  Therefore, we continued to optimize the process. <br><br><h3>  1.5.  Automatic crash detection and rollback </h3><br>  We have long thought how to reduce the duration of the accident due to bad releases.  They even tried to force themselves to look at <code>tail -f error_log | grep 500</code>  <code>tail -f error_log | grep 500</code> .  But in the end, they still settled on a cardinal automatic solution. <br><br>  In short, this auto-roll.  We started a separate web server, to which the load balancer was loaded 10 times less than other web servers.  Each release was automatically deployed by the CI / CD system to this separate server (we called it preprod, although, despite the name, there was a real load from real users).  And then the automation performed <code>tail -f error_log | grep 500</code>  <code>tail -f error_log | grep 500</code> .  If within one minute there was not a single 500th error, then CI / CD deployed a new code in production.  If errors appeared, the system immediately rolled everything away.  At the same time, at the balancer level, all requests completed with 500 errors on preprod were duplicated to one of the production servers. <br><br>  This measure reduced the impact of ‚Äúfive hundred‚Äù releases to zero.  In this case, in case of bugs in automatics, we did not cancel the rule of three minutes to follow the schedules.  That's all about bad releases and 500th mistakes.  Moving on to the next type of accidents. <br><br><h2>  2. Bad release, non-optimal code, load on the base </h2><br>  I will begin immediately with a specific example of an accident of this type.  Rolled out the optimization: added <code>USE INDEX</code> to the SQL query, while testing it accelerated short queries, as in production, but long queries slowed down.  Slowing down long requests was noticed only in production.  As a result, the flow of long queries put the entire master database for one hour.  We thoroughly figured out how <code>USE INDEX</code> works, described it in the do's &amp; dont's file and warned developers against misuse.  We also analyzed the query and realized that it returns mainly historical data, which means it can be run on a separate replica for historical queries.  Even if this replica will fall under load, the business will not stop. <br><br>  After this incident, we still ran into similar problems, and at some point decided to approach the issue systematically.  Prosherstili all code frequent comb and brought to the replica all requests that can be put there without compromising the quality of service.  At the same time, we divided the replicas themselves according to the levels of criticality so that the fall of any of them would not stop the service.  As a result, we have come to an architecture in which there are the following bases: <br><br><ul><li>  master database (for write operations and for queries that are supercritical to data freshness); </li><li>  production replica (for short queries that are slightly less critical to the data freshness); </li><li>  a replica for calculating price ratios, so-called surge pricing.  This remark can lag by 30-60 seconds - this is not critical, the coefficients change less often, and if this remark falls, the service will not stop, just the prices will not quite match the balance of supply and demand; </li><li>  a replica for the admin user and contact center (if it falls, the main business will not rise, but the support will not work and we will not be able to temporarily view and change the settings); </li><li>  many replicas for analytics; </li><li>  MPP-base for heavy analytics with full cuts based on historical data. </li></ul><br>  This architecture gave us more room to grow and reduced the number of crashes by an order of magnitude due to non-optimal SQL queries.  But she is still far from perfect.  There are plans to do sharding so that updates and deletes can be scaled, as well as short queries that are supercritical to the freshness of the data.  MySQL's margin of safety is not infinite.  Soon we will need heavy artillery in the form of Tarantool.  About this will be necessarily in the following articles! <br><br>  In the course of proceedings with non-optimal code and requests, we understood the following: it is better to eliminate any non-optimality before the release, not after.  This reduces the risk of an accident and reduces the time spent by developers on optimization.  Because if the code is already rolled out and there are new releases on top of it, then optimizing is much more difficult.  As a result, we have introduced a mandatory code check for optimality.  It is conducted by the most experienced developers, in fact, our special forces. <br><br>  In addition, we began to collect at Do's &amp; Dont's the best ways to optimize the code that work in our realities, they are listed below.  Please do not take these practices as absolute truth and do not try to blindly repeat them in yourself.  Each method makes sense only for a specific situation and a particular business.  They are given here just for example, so that the specifics are clear: <br><br><ul><li>  If the SQL query does not depend on the current user (for example, a demand card for drivers with the indication of minimum travel rates and polygon coefficients), then this query should be done by cron with a certain frequency (in our case, once per minute is sufficient).  Write the result to the cache (Memcached or Redis), which is already used in production-code. </li><li>  If the SQL query operates on data whose lag is not critical for a business, then its result should be put in the cache with some TTL (for example, 30 seconds).  And then in subsequent requests read from the cache. </li><li>  If in the context of processing a request on the web (in our case, in the context of the work of implementing a specific server method in PHP) you want to make a SQL query, then you need to make sure that this data has not ‚Äúarrived‚Äù with any other SQL query (and whether they will come further along the code).  The same applies to cache accesses: it can also be overwhelmed with requests if desired, therefore, if the data has already ‚Äúarrived‚Äù from the cache, then it is not necessary to go to the cache as if to your home and take it out of it, which is already taken away. </li><li>  If, in the context of processing a request on the web, you want to call any function, then you need to make sure that not a single extra SQL query or cache access is made to its gut.  If the call of such a function is inevitable, then you need to make sure that it cannot be modified or its logic is broken so as not to make unnecessary requests to the databases / caches. </li><li>  If you still need to go to SQL, you need to make sure that the queries that already exist in the code cannot add the required fields above or below the code. </li></ul><br><h2>  3. Unsuccessful manual intervention in the system </h2><br>  Examples of such accidents: unsuccessful ALTER (which overloaded the database or provoked the replica lag) or failed DROP (ran into a bug in MySQL, blocked the database during the drop of the fresh table);  heavy request for a master made by mistake;  did work on the server under load, although they thought that it was taken out of work. <br><br>  To minimize falls for these reasons, it is necessary, unfortunately, to understand the nature of the accident every time.  General rules we have not yet felt.  Again, let's try on examples.  Say, at some point the surge factors stopped working (they multiply the price of a trip at a place and time of increased demand).  The reason was that on the replica of the base from which the data for calculating the coefficients were taken, there was a Python script that ate all the memory, and the replica went down.  The script was launched a long time ago, it worked on a replica just for convenience.  The problem was solved by restarting the script.  The conclusions were as follows: do not run third-party scripts on the machine (recorded in do's &amp; dont's, otherwise it is a blank shot!), Monitor the end of memory on a machine with a replica and alert via SMS if the memory ends soon. <br><br>  It is very important to always draw conclusions and not to slip into a comfortable situation "they saw the problem, fixed it and forgot it."  High-quality service can only be built if conclusions are drawn.  In addition, SMS-alerts are very important - they set the quality of service at a higher level than it was, do not allow it to fall, and allow you to further increase reliability.  As a climber from each stable state pulls itself up and fixed in another stable state, but at a higher height. <br><br>  Monitoring and alertings with invisible but hard iron hooks crash into the rock of obscurity and never let us fall below the level of stability we set, which we constantly raise only upwards. <br><br><h2>  4. Easter egg </h2><br>  What we call the ‚ÄúEaster egg‚Äù is a time bomb that exists a long time ago, but which we didn‚Äôt find.  Outside of this article, this term means an undocumented feature, made specifically.  In our case, this is not a feature at all, but rather a bug, but which works as a time bomb and which is a side effect of good intentions. <br><br>  For example: overflow 32 bit <code>auto_increment</code> ;  nonoptimality in the code / configuration, which ‚Äúshot out‚Äù due to the load;  backward replica (usually either due to a suboptimal request for a replica that was triggered by a new usage pattern, or a higher load, or due to a suboptimal UPDATE on the master that was caused by a new loading pattern and loaded replica). <br><br>  Another popular type of Easter eggs is a non-optimal code, and more specifically, a non-optimal SQL query.  Previously, the table was smaller and the load was less - the query worked well.  And with the increase in the table, linear in time and increase in load, linear in time, the consumption of resources of the DBMS grew quadratically.  Usually this leads to a sharp negative effect: the type was all ‚Äúok‚Äù, and then - bang. <br><br>  More rare scenarios - a combination of bug and easter eggs.  The release with a bug led to an increase in the size of the table or an increase in the number of records in a table of a certain type, and the Easter egg that already has led to an excessive load on the database due to slower queries to this expanded table. <br><br>  Although we also had Easter eggs that were not related to the load.  For example, 32-bit <code>auto increment</code> : after two and a little billions of records into the table, inserts cease to be performed.  So the <code>auto increment</code> field in the modern world should be made 64-bit.  We learned this lesson well. <br><br>  How to deal with "Easter eggs"?  The answer sounds simple: a) look for old ‚Äúeggs‚Äù, and b) not allow new ones to appear.  We try to fulfill both points.  The search for old ‚Äúeggs‚Äù in our country is associated with constant code optimization.  We have identified two of the most experienced developers for almost-fulltime optimization.  They find in slow.log requests that consume the most database resources, optimize these requests and the code around them.  We reduce the likelihood of the emergence of new eggs through checking for the optimality of the code of each commit by the aforementioned Sensei developers.  Their task is to point out errors affecting performance;  suggest how to do better, and transfer knowledge to other developers. <br><br>  At some point after the next Easter egg we found, we realized that the search for slow queries is good, but it would be worthwhile to additionally look for queries that look like slow but work quickly.  These are just the next candidates to put everything in the event of the explosive growth of the next table. <br><br><h2>  5. External causes </h2><br>  These are reasons that we believe are poorly controlled by us.  For example: <br><br><ul><li>  Trotling by Google Maps.  It can be circumvented by monitoring the use of this service, observing a certain level of load on it, planning the growth of the load in advance and purchasing the expansion of the service. </li><li>  The fall of the network in the data center.  You can get around by placing a copy of the service in the backup data center. </li><li>  Accident payment service.  You can bypass the reservation of payment services. </li><li>  Wrong traffic blocking by the DDoS protection service.  You can get around by turning off the default DDoS protection service and turning it on only in case of a DDoS attack. </li></ul><br>  Since the removal of an external cause is a long and expensive exercise (by definition), we just started collecting statistics on accidents due to external causes and waiting for the accumulation of critical mass.  Recipe, how to determine the critical mass, no.  It works just intuition.  For example, if we were 5 times in full downtime because of problems, for example, the service to combat DDoS, then with each subsequent fall, there will be a sharper and sharper question about alternatives. <br><br>  On the other hand, if it is possible to somehow make everything work with an inaccessible external service, then we will definitely do it.  And this helps us to post-mortem-analysis of each fall.  There should always be a conclusion.  So, you always want-not-want, but you come up with a workaround. <br><br><h2>  6. Bad release, broken functionality. </h2><br>  This is the most unpleasant type of accident.  The only type of accident that is not visible for any symptoms other than user / business complaints.  Therefore, such an accident, especially if it is not large, can exist for a long time in production unnoticed. <br><br>  All other types of accidents are to some extent similar to the ‚Äúbad release, 500th mistakes‚Äù.  Just the trigger will not be a release, but a load, a manual operation or a problem on the external service side. <br><br>  To describe the method of dealing with this type of accidents, it suffices to recall the bearded anecdote: <br><br><blockquote>  Mathematics and physics was offered the same problem: boil the kettle.  Hand tools: stove, kettle, water faucet with water, matches.  Both alternately pour water into the kettle, turn on the gas, light it and put the kettle on the fire.  Then the task was simplified: a teapot filled with water and a stove with burning gas were proposed.  The goal is the same - boil water.  The physicist puts the kettle on the fire.  The mathematician pours water out of the kettle, turns off the gas and says: ‚ÄúThe task has been reduced to the previous one‚Äù.  anekdotov.net </blockquote><br>  This type of accident should be reduced to ‚Äúbad release, 500th error‚Äù by all means.  Ideally, if the bugs in the code were saved to the log as an error.  Well, or at least left traces in the database.  By these traces you can understand that a bug has occurred, and immediately alert.  How to contribute to this?  We began to analyze every major bug and propose solutions for what kind of monitoring / SMS alerting can be done so that this bug immediately manifests itself in the same way as the 500th error. <br><br><h3>  6.1.  Example </h3><br>  There were massive complaints: orders that were paid through Apple Pay are not closing.  Began to understand the problem repeated.  Found the reason: they made a revision in the <code>expire date</code> format for bank cards when interacting with acquiring, as a result of which they began to transfer it specifically for payments through Apple Pay, not in the format in which it was expected by the payment processing service (in fact, we treat one another cripple), so all payments through Apple Pay began to deviate.  Quickly fixed, rolled out, the problem disappeared.  But "lived" with a problem of 45 minutes. <br><br>  In the wake of this problem, we monitored the number of unsuccessful payments through Apple Pay, and also made an SMS / IVR alert with some non-zero threshold (because unsuccessful payments are the norm in terms of service, for example, the customer has no money on the card or the card is blocked) .  From now on, when the threshold is exceeded, we will instantly know about the problem.  If the new release introduces ANY problem into the processing of Apple Pay, which will cause the service to become inoperable, even partial, we will instantly find out about it from monitoring and roll back the release within three minutes (the above describes how the manual rollback process works).  It was 45 minutes of partial downtime, it was 3 minutes.  Profit <br><br><h3>  6.2.  Other examples </h3><br>  Rolled out the optimization of the list of orders offered to drivers.  A bug has crept into the code.  As a result, drivers in some cases did not see the list of orders (it was empty).  We found out about the bug by accident - one of the employees looked into the driver's application.  Quickly rolled back.  As a conclusion from the accident, they made a graph of the average number of orders in the list of drivers, according to the data from the database, looked back at the chart for a month, saw a failure there and made an SMS alert on the SQL query that forms this chart while reducing the average number of orders in list below the threshold selected based on the historical minimum for the month. <br><br>  Changed the logic of distribution to cashback users for trips.  Including distributed to the wrong group of users.  They fixed the problem, built a schedule of distributed cashbacks, saw a sharp increase there, also saw that there was never such growth, they made an SMS alert. <br><br>  With the release, the order closing functionality was broken (the order was closed forever, the payment on the cards did not work, the drivers demanded cash payment from the customers).  The problem was 1.5 hours (total passive and active stages).  About the problem learned from the contact center for complaints.  Made a correction, made monitoring and alert for the time of closing orders with thresholds found on the study of historical charts. <br><br>  As you can see, the approach to this type of accidents is always the same: <br><br><ol><li>  Roll out the release. </li><li>  We learn about the problem. </li><li>  We repair it. </li><li>  We determine by what tracks (in the database, logs, Kibane) you can find out the signs of a problem. </li><li>  Build a graph of these signs. </li><li>  We wind it into the past and look at the surges / falls. </li><li>  We select the correct threshold for the alert. </li><li>  When the problem arises again, we immediately find out about it through an alert. </li></ol><br>  What is pleasant in this way: a single class and an alert immediately closes a huge class of problems (examples of classes of problems: non-closing orders, extra bonuses, non-payment through Apple Pay, etc.). <br><br>  Over time, we made building alerts and monitoring for every major bug as part of the development culture.  So that this culture is not lost, we have formalized it a little bit.  For each accident, they began to demand that they themselves create a report.  The report is a completed form with answers to the following questions: root cause, method of elimination, impact on business, conclusions.  All items are required.  Therefore you do not want it, but you will write the conclusions.  This process change, of course, recorded this do's &amp; dont's. <br><br><h2>  7. Kotan </h2><br>    ,     ,    -,        .  - (  ,  )   ¬´¬ª.   ¬´¬ª.  :-) <br><br>  ¬´¬ª   : <br><br>  .          ‚Äî ,      .       ,   (  ),    (     )     ,        .      ( ,      ). <br><br>  .  ,    .   ,     :  ‚Äî   ,   ‚Äî   . , ¬´ 500-  1 %¬ª ‚Äî  .  ¬´ 500-  1 %,   - , - ,  - ¬ª ‚Äî  .         ,      .          (     ).         ,     :  ,   ¬´¬ª,   ,   ,    ,  .     ‚Äî     .      (  ,      ).      . <br><br> .      .        ,     (   ,     ,       ),   ,       :  ,  ,   , . <br><br>  .    ,   ,       ( ,   ). <br><br><h2> 8.      ? </h2><br>       ‚Äî  .    .  :   ,    .          ,    ,   .      ,  ,      , ..    ‚Äî  ,      ‚Äî !      ,     .           ,    ,  ?    ,       , .. ,    ,  . <br><br>           .      .     (    ,   ),    ,           :  ,  ,     ,   .     ,    ,        .          .           .       -,      ,    .    ,   ,      ,     ‚Äî   :          . <br><br><h2> 9.   </h2><br>      ,           . <br><br><table><tbody><tr><th>  ? </th><th>  ? </th></tr><tr><td>    . <br></td><td>        . <br></td></tr><tr><td>    (    )   post-mortem. <br></td><td>       . <br></td></tr><tr><td>    do's &amp; dont's. <br></td><td>     ,       ,   . <br></td></tr><tr><td>   ,    5 . <br></td><td>      . <br></td></tr><tr><td>        ,    . <br></td><td>      . <br></td></tr><tr><td>    . <br></td><td>      . <br></td></tr><tr><td>      <br></td><td>   . <br></td></tr><tr><td>       . <br></td><td>   . <br></td></tr><tr><td>        . <br></td><td>    . <br></td></tr><tr><td> SMS/IVR-  . <br></td><td>    . <br></td></tr><tr><td>   ( )    . <br></td><td>    . <br></td></tr><tr><td>    . <br></td><td>     -   . <br></td></tr><tr><td>    (   ‚Äî slow.log). <br></td><td>     - ¬´ ¬ª. <br></td></tr><tr><td>     . <br></td><td>       . <br></td></tr><tr><td>     . <br></td><td>        . <br></td></tr><tr><td>          . <br></td><td>   ,      ,         . <br></td></tr><tr><td> ¬´¬ª ‚Äî     . <br></td><td>   ,   . <br></td></tr><tr><td>  . <br></td><td>    . <br></td></tr></tbody></table><br>  ,    !       , , ,   ,    ! </div><p>Source: <a href="https://habr.com/ru/post/445704/">https://habr.com/ru/post/445704/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../445692/index.html">An overview of the capabilities of PlayCanvas for creating Web VR applications</a></li>
<li><a href="../445696/index.html">How are robots created that can pass in the same place as we</a></li>
<li><a href="../445698/index.html">NanoCAD licensing</a></li>
<li><a href="../445700/index.html">‚Äú33 words about design‚Äù: who and why makes a movie about design in Russia</a></li>
<li><a href="../445702/index.html">SlowPochta - messenger of non-guaranteed message delivery with indefinite forwarding time</a></li>
<li><a href="../445706/index.html">Intel GPU SGX - store your data on a video card. With warranty</a></li>
<li><a href="../445708/index.html">UICollectionView around the head: Changing the view on the fly</a></li>
<li><a href="../445710/index.html">Team climate management</a></li>
<li><a href="../445712/index.html">Six rules that will help set achievable goals</a></li>
<li><a href="../445714/index.html">The final program DUMP-2019 is ready. We meet on April 19 in Yekaterinburg</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>