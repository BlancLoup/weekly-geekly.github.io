<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Theory and practice of backups with Borg</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="To our great surprise at Habr√© there was not a single material about the wonderful Open Source-tool for data backup - Borg (not to be confused with th...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Theory and practice of backups with Borg</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/webt/xx/7w/tn/xx7wtnr5mv7mjndz-uzowsql58o.png"><br><br>  To our great surprise at Habr√© there was not a single material about the wonderful Open Source-tool for data backup - <a href="http://borgbackup.readthedocs.io/en/stable/">Borg</a> <i>(not to be confused with the Kubernetes progenitor of the same name!)</i> .  Since we have been using it in production for more than a year now, in this article I‚Äôll share our impressions of Borg. <a name="habracut"></a><br><br><h2>  Background: Experience with Bacula and Bareos </h2><br>  In 2017, we were tired of Bacula and Bareos, who used from the very beginning of their activities (ie, about 9 years in production at that time).  Why?  During the operation, we have accumulated a lot of discontent: 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <ul><li>  Hangs SD (Storage Daemon).  If you have configured parallelism, then the SD maintenance becomes more complicated, and its hangup blocks further backups on a schedule and the possibility of recovery. </li><li>  It is necessary to generate configs for both the client and the director.  Even if you automate this (in our case, Chef, Ansible, and its own development were used at different times), you need to monitor that the director after his <i>reload</i> 'actually picked up the config.  This is monitored only in the output of the <i>reload</i> command and after the <i>messages are</i> called (to get the error text itself). </li><li>  Schedule backups.  The developers of Bacula decided to go their own way and wrote their own timetable format, which cannot be simply parsed or converted to another.  Here are examples of standard backup schedules in our old installations: <ul><li>  Daily full backup on Wednesdays and incremental on other days: <br> <code>Run = Level=Full Pool="Foobar-low7" wed at 18:00 <br> Run = Level=Incremental Pool="Foobar-low7" at 18:00</code> </li> <li>  Full backup of wal-files 2 times a month and increment every hour: <br> <code>Run = Level=Full FullPool=CustomerWALPool 1st fri at 01:45 <br> Run = Level=Full FullPool=CustomerWALPool 3rd fri at 01:45 <br> Run = Level=Incremental FullPool=CustomerWALPool IncrementalPool=CustomerWALPool on hourly</code> </li> <li>  Generated <code>schedule</code> for all occasions (on different days of the week every 2 hours) we got about 1665 ... because of what Bacula / Bareos periodically went crazy. </li></ul></li><li>  At bacula-fd (and bareos-fd) on directories with a large amount of data (say, 40 TB, of which 35 TB have large files [100+ MB], and the remaining 5 TB are small [from 1 KB to 100 MB ]) a slow memory leak begins, which in production is a completely unpleasant situation. <br><br><img src="https://habrastorage.org/webt/eu/33/ao/eu33aocunyesaxcwtlyzzim_eha.png"></li><li>  On backups with a large number of files, Bacula and Bareos are very dependent on the performance of the used DBMS.  What drives it on?  How skillfully can you tailor her for these specific needs?  And in the database, by the way, one (!) Non-partisable table is created with a list of all files in all backups and a second one with a list of all paths in all backups.  If you are not ready to allocate at least 8 GB of RAM for the base + 40 GB SSD for your backup server - immediately get ready for the brakes. </li><li>  Dependence on a DB is worthy one more point.  Bacula / Bareos for each file ask the director if there was already such a file.  The director, of course, climbs into the database, into those very huge tables ... It turns out that backups can be blocked simply by the fact that several heavy backups were launched at the same time - even if there is a diff for several megabytes. </li></ul><br><img src="https://habrastorage.org/webt/nh/iw/dz/nhiwdzn69dvunjisjzcwcy1fyna.png"><br><br>  It would be unfair to say that no problems were solved at all, but we got to the point where we were really tired of various workarounds and wanted a reliable solution "here and now." <br><br>  Bacula / Bareos work fine with a small number (10-30) of uniform jobs.  Broke a trifle once a week?  Do not worry: they gave the task to the duty officer (or another engineer) - they fixed it.  However, we have projects where the number of jobs is in the hundreds, and the number of files in them is in the hundreds of thousands.  As a result, 5 minutes a week for repairing the backup (not counting several hours of adjustment before this) began to multiply.  All this led to the fact that 2 hours a day it was necessary to repair backups in all projects, because literally everywhere there was something trivial or seriously broken. <br><br>  Then someone might think that a dedicated engineer should be engaged in backups.  Certainly, he will be as bearded and stern as possible, and from his gaze backups are repaired instantly while he sips his coffee calmly.  And this idea may be true in some way ... But there is always a but.  Not everyone can afford to repair around the clock and watch backups, and even more so - the engineer selected for these purposes.  We are just sure that it is better to spend these 2 hours a day for something more productive and useful.  Therefore, we turned to the search for alternative solutions that ‚Äújust work‚Äù. <br><br><h2>  Borg as a new way </h2><br>  The search for other Open Source variants was spread over time, so it‚Äôs difficult to estimate the total costs, but at one point (last year) our attention was directed to the ‚Äú <a href="https://borgbackup.readthedocs.io/en/stable/">hero of the</a> occasion‚Äù - <a href="https://borgbackup.readthedocs.io/en/stable/">BorgBackup</a> (or simply Borg).  Partly due to the real experience of its use by one of our engineers (at the previous place of work). <br><br>  Borg is written in Python (version&gt; = 3.4.0 is required), and performance-sensitive code (compression, encryption, etc.) is implemented in C / Cython.  Distributed under the free BSD license (3-clause).  Supports many platforms including Linux, * BSD, macOS, as well as at the experimental level of Cygwin and Linux Subsystem of Windows 10. For the installation of BorgBackup, packages are available for popular Linux distributions and other operating systems, as well as source files installed, including via pip, - more information about this can be found in the <a href="https://borgbackup.readthedocs.io/en/stable/installation.html">project documentation</a> . <br><br>  Why did Borg bribe us so much?  Here are its main advantages: <br><br><ul><li>  <b>Deduplication</b> : real and very effective (examples will be below).  Files within one Borg repository (that is, a special directory in the Borg-specific format) are divided into blocks of n megabytes, and repeated Borg blocks deduplicate.  Deduplication occurs just before compression. </li><li>  <b>Compression</b> : after deduplication, the data is also compressed.  Different compression algorithms are available: lz4, lzma, zlib, zstd.  The standard feature of any backup, but no less useful for it. </li><li>  <b>Work on SSH</b> : Borg backed up to a remote server via SSH.  On the server side, you just need an installed Borg and that's it!  This immediately implies such advantages as security and encryption.  You can configure access only by keys and, moreover, Borg executes only one of his commands when entering the server.  For example: <br><br><pre> <code class="bash hljs">$ cat .ssh/authorized_keys <span class="hljs-built_in"><span class="hljs-built_in">command</span></span>=<span class="hljs-string"><span class="hljs-string">"/usr/bin/borg serve"</span></span> ssh-rsa AAAAB3NzaC1yc‚Ä¶</code> </pre> </li><li>  It is delivered both in PPA (we mainly use Ubuntu), and <b>static binary</b> .  Borg as a static binary allows you to run it almost anywhere where there is at least a minimally modern glibc.  (But not everywhere - for example, failed to run on CentOS 5.) </li><li>  Flexible <b>cleaning of old backups</b> .  You can set the storage of the last n backups, and 2 backups per hour / day / week.  In the latter case, the last backup will be left at the end of the week.  Conditions can be combined by making a storage of 7 daily backups in the last 7 days and 4 weeks. </li></ul><br>  The transition to Borg started slowly, on small projects.  At first, these were simple cron scripts that did their job every day.  Everything went on for about six months.  During this time we had to get backups many times ... and it turned out that Borg didn‚Äôt have to be repaired at all!  Why?  Because the simple principle works here: ‚ÄúThe simpler the mechanism, the fewer places where it will break.‚Äù <br><br><h2>  Practice: how to backup Borg? </h2><br>  Consider a simple backup creation example: <br><br><ol><li>  Download the latest release binary to the backup server and machine, which we will back up from the <a href="https://github.com/borgbackup/borg/releases">official repository</a> : <br><br><pre> <code class="bash hljs">sudo wget https://github.com/borgbackup/borg/releases/download/1.1.6/borg-linux64 -O /usr/<span class="hljs-built_in"><span class="hljs-built_in">local</span></span>/bin/borg sudo chmod +x /usr/<span class="hljs-built_in"><span class="hljs-built_in">local</span></span>/bin/borg</code> </pre> <br>  <i><b>Note</b> : If you use a local machine for the test, both as a source and as a receiver, then all the difference will be only in the URI that we pass, but we remember that the backup should be stored separately and not on the same machine.</i> </li><li>  On the server backups create user <code>borg</code> : <br><br><pre> <code class="bash hljs">sudo useradd -m borg</code> </pre> <br>  Simple: no groups and with a standard shell, but always with a home directory. </li><li>  An SSH key is generated on the client: <br><br><pre> <code class="bash hljs">ssh-keygen</code> </pre> </li><li>  On the server, add the generated key to the <code>borg</code> user: <br><br><pre> <code class="bash hljs">mkdir ~borg/.ssh <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">'command="/usr/local/bin/borg serve" ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDNdaDfqUUf/XmSVWfF7PfjGlbKW00MJ63zal/E/mxm+vJIJRBw7GZofe1PeTpKcEUTiBBEsW9XUmTctnWE6p21gU/JNU0jITLx+vg4IlVP62cac71tkx1VJFMYQN6EulT0alYxagNwEs7s5cBlykeKk/QmteOOclzx684t9d6BhMvFE9w9r+c76aVBIdbEyrkloiYd+vzt79nRkFE4CoxkpvptMgrAgbx563fRmNSPH8H5dEad44/Xb5uARiYhdlIl45QuNSpAdcOadp46ftDeQCGLc4CgjMxessam+9ujYcUCjhFDNOoEa4YxVhXF9Tcv8Ttxolece6y+IQM7fbDR'</span></span> &gt; ~borg/.ssh/authorized_keys chown -R borg:borg ~borg/.ssh</code> local / bin / borg serve" ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDNdaDfqUUf / XmSVWfF7PfjGlbKW00MJ63zal / E / mxm + vJIJRBw7GZofe1PeTpKcEUTiBBEsW9XUmTctnWE6p21gU / JNU0jITLx + vg4IlVP62cac71tkx1VJFMYQN6EulT0alYxagNwEs7s5cBlykeKk / QmteOOclzx684t9d6BhMvFE9w9r + c76aVBIdbEyrkloiYd + vzt79nRkFE4CoxkpvptMgrAgbx563fRmNSPH8H5dEad44 / Xb5uARiYhdlIl45QuNSpAdcOadp46ftDeQCGLc4CgjMxessam + 9ujYcUCjhFDNOoEa4YxVhXF9Tcv8Ttxolece6y + IQM7fbDR'&gt; ~ borg / .ssh <code class="bash hljs">mkdir ~borg/.ssh <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">'command="/usr/local/bin/borg serve" ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDNdaDfqUUf/XmSVWfF7PfjGlbKW00MJ63zal/E/mxm+vJIJRBw7GZofe1PeTpKcEUTiBBEsW9XUmTctnWE6p21gU/JNU0jITLx+vg4IlVP62cac71tkx1VJFMYQN6EulT0alYxagNwEs7s5cBlykeKk/QmteOOclzx684t9d6BhMvFE9w9r+c76aVBIdbEyrkloiYd+vzt79nRkFE4CoxkpvptMgrAgbx563fRmNSPH8H5dEad44/Xb5uARiYhdlIl45QuNSpAdcOadp46ftDeQCGLc4CgjMxessam+9ujYcUCjhFDNOoEa4YxVhXF9Tcv8Ttxolece6y+IQM7fbDR'</span></span> &gt; ~borg/.ssh/authorized_keys chown -R borg:borg ~borg/.ssh</code> </pre> </li><li>  Initialize <i>borg repo</i> on the server from the client: <br><br><pre> <code class="bash hljs">ssh borg@172.17.0.3 hostname <span class="hljs-comment"><span class="hljs-comment">#     borg init -e none borg@172.17.0.3:MyBorgRepo</span></span></code> </pre> <br>  The <code>-e</code> switch is used to select the repository encryption method (yes, you can additionally encrypt each repository with your password!).  In this case, because  This is an example, we do not use encryption.  <code>MyBorgRepo</code> is the name of the directory in which <i>borg repo</i> will be (you do not need to create it in advance - Borg will do everything by itself). </li><li>  We start the first backup using Borg: <br><br><pre> <code class="bash hljs">borg create --stats --list borg@172.17.0.3:MyBorgRepo::<span class="hljs-string"><span class="hljs-string">"MyFirstBackup-{now:%Y-%m-%d_%H:%M:%S}"</span></span> /etc /root</code> </pre> <br>  About the keys: <br><ul><li>  <code>--stats</code> and <code>--list</code> give us statistics on the backup and files in it; </li><li>  <code>borg@172.17.0.3:MyBorgRepo</code> - everything is clear here, this is our server and directory.  And what's next for the magic? .. </li><li>  <code>::"MyFirstBackup-{now:%Y-%m-%d_%H:%M:%S}"</code> is the name of the archive inside the repository.  It is arbitrary, but we follow the format <code>_-timestamp</code> (timestamp in Python format). </li></ul></li></ol><br>  What's next?  Of course, see what got into our backup!  List of archives inside the repository: <br><br><pre> <code class="bash hljs">borg@b3e51b9ed2c2:~$ borg list MyBorgRepo/ Warning: Attempting to access a previously unknown unencrypted repository! Do you want to <span class="hljs-built_in"><span class="hljs-built_in">continue</span></span>? [yN] y MyFirstBackup-2018-08-04_16:55:53 Sat, 2018-08-04 16:55:54 [89f7b5bccfb1ed2d72c8b84b1baf477a8220955c72e7fcf0ecc6cd5a9943d78d]</code> </pre> <br>  We see a backup with a timestamp and how Borg asks us if we really want to access an unencrypted repository, which we have never been to before. <br><br>  See the list of files: <br><br><pre> <code class="bash hljs">borg list MyBorgRepo::MyFirstBackup-2018-08-04_16:55:53</code> </pre> <br>  We get the file from the backup (you can and the whole directory): <br><br><pre> <code class="bash hljs">borg@b3e51b9ed2c2:~$ borg extract MyBorgRepo::MyFirstBackup-2018-08-04_16:55:53 etc/hostname borg@b3e51b9ed2c2:~$ ll etc/hostname -rw-r--r-- 1 borg borg 13 Aug 4 16:27 etc/hostname</code> </pre> <br>  Congratulations, your first Borg backup is ready! <br><br><h2>  Practice: automate it [with GitLab]! </h2><br>  Having wrapped all this in scripts, we set up backups manually in a similar way on about 40 hosts.  Realizing that Borg really works, they began to transfer more and larger projects to it ... <br><br>  And here we are confronted with what is in Bareos, but not at Borg!  Namely: WebUI or some centralized place for setting up backups.  And we very much hope that this is a temporary phenomenon, but so far we have had to solve something.  Googling the finished tools and gathered in a videoconference, we set to work.  There was a great idea to integrate Borg with our internal services, as we did before with Bacula (Bacula herself took the list of jobs from our central API, to which we had our own interface integrated with other project settings).  We thought about how to do it, outlined a plan, how and where it can be embedded, but ... Normal backups are needed now, and there is no place to take on grandiose time plans.  What to do? <br><br>  Questions and requirements were approximately as follows: <br><br><ul><li>  What to use as centralized backup management? </li><li>  What can any Linux administrator do? </li><li>  What can even a manager showing backups of clients be able to understand and set up? </li><li>  What does the scheduled task on your system do every day? </li><li>  What will not be difficult to configure and will not break? .. </li></ul><br>  The answer was obvious: this is the good old crond who heroically performs his duty every day.  Plain.  Does not hang.  Even the manager who is from Unix to ‚Äúyou‚Äù can fix it. <br><br>  So crontab, but where does all this hold?  Is it possible to go to the project machine every time and edit the file with your hands?  Of course not.  We can put our schedule in the Git repository and set up GitLab Runner, which will update it on the host by commit. <br><br>  <i><b>Note</b> : It was GitLab that was chosen as a means of automation, because it is convenient for the task and in our case is almost everywhere.</i>  <i>But I must say that in no case is it a necessity.</i> <br><br>  You can lay out a crontab for backups using your usual automation tool or manually (for small projects or home installations). <br><br>  So, this is what you need for simple automation: <br><br>  1. <b>GitLab and a repository</b> in which to start there will be two files: <br><br><ul><li>  <code>schedule</code> - backup schedule, </li><li>  <code>borg_backup_files.sh</code> is a simple file backup script (as in the example above). </li></ul><br>  <code>schedule</code> Example: <br><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># WARNING! CRONTAB MANAGED FROM GITLAB CI RUNNER IN ${CI_PROJECT_URL} # CI_COMMIT_SHA: ${CI_COMMIT_SHA} # Branch/tag: ${CI_COMMIT_REF_NAME} # Timestamp: ${TIMESTAMP} PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin # MyRemoteHost 0 0 * * * ${CI_PROJECT_DIR}/borg_backup_files.sh 'SYSTEM /etc,/opt'</span></span></code> </pre> <br>  CI variables are used to check the success of the crontab update, and <code>CI_PROJECT_DIR</code> is the directory in which the repository will appear after cloning with the runner.  The last line indicates that the backup is performed every day at midnight. <br><br>  Example <code>borg_backup_files.sh</code> : <br><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#!/bin/bash BORG_SERVER="borg@10.100.1.1" NAMEOFBACKUP=${1} DIRS=${2} REPOSITORY="${BORG_SERVER}:$(hostname)-${NAMEOFBACKUP}" borg create --list -v --stats \ $REPOSITORY::"files-{now:%Y-%m-%d_%H:%M:%S}" \ $(echo $DIRS | tr ',' ' ') || \ echo "borg create failed"</span></span></code> </pre> <br>  <i>The first</i> argument here is the name of the backup, and the <i>second</i> is the list of directories for backup, separated by commas.  Strictly speaking, a list may be a set of individual files. <br><br>  2. <b>GitLab Runner</b> , running on a machine that needs to be backed up, and blocked only for execution of the jobs of this repository. <br><br>  3. <b>The CI script itself</b> , implemented by the <code>.gitlab-ci.yml</code> : <br><br><pre> <code class="hljs pgsql">stages: - deploy Deploy: stage: deploy script: - export <span class="hljs-type"><span class="hljs-type">TIMESTAMP</span></span>=$(<span class="hljs-type"><span class="hljs-type">date</span></span> <span class="hljs-string"><span class="hljs-string">'+%Y.%m.%d %H:%M:%S'</span></span>) - cat schedule | envsubst | crontab - tags: - borg-backup</code> </pre> <br>  4. The <b>SSH key of</b> the <code>gitlab-runner</code> user with access to the <code>gitlab-runner</code> server (in the example, this is 10.100.1.1).  By default, it should be in the <code>.ssh/id_rsa</code> home directory ( <code>gitlab-runner</code> ). <br><br>  5. <b>The <code>borg</code> user</b> on the same 10.100.1.1 with access only to the <code>borg serve</code> command: <br><br><pre> <code class="bash hljs">$ cat .ssh/authorized_keys <span class="hljs-built_in"><span class="hljs-built_in">command</span></span>=<span class="hljs-string"><span class="hljs-string">"/usr/bin/borg serve"</span></span> ssh-rsa AAAAB3NzaC1yc2EAA...</code> </pre> <br>  Now when comming to the repository, the Runner fills the crontab contents.  And when the cron's response time comes, the <code>/etc</code> and <code>/opt</code> directories will be <code>MyHostname-SYSTEM</code> , which will be on the backup server in the <code>MyHostname-SYSTEM</code> directory of the <code>MyHostname-SYSTEM</code> server. <br><br><img src="https://habrastorage.org/webt/ud/n7/wb/udn7wbd4vqknfq6cguw5wmi7tcq.png"><br><br><h2>  Instead of a conclusion: what else can? </h2><br>  The application of Borg does not, of course, end there.  Here are some ideas for further implementation, some of which we have already implemented: <br><br><ul><li>  <b>Add universal scripts</b> for different backups, which at the end of execution run <code>borg_backup_files.sh</code> , aimed at the directory with the result of their work.  For example, you can back up PostgreSQL (pg_basebackup), MySQL (innobackupex), GitLab (built-in rake job, creating an archive). </li><li>  <b>Central host with <i>schedule</i> for backup</b> .  Do not configure the same on every GitLab Runner host?  Let it be one on the server backups, and crontab at startup transfers the backup script to the machine and runs it there.  To do this, of course, you will need the <code>borg</code> user on the client machine and <code>ssh-agent</code> in order not to spread the key to the backup server on each machine. </li><li>  <b>Monitoring</b>  Where do without him!  Alerts about incorrectly completed backup must be. </li><li>  <b>Cleaning borg repository from old archives.</b>  Despite good deduplication, old backups still have to be cleaned.  To do this, you can make a call to <code>borg prune</code> at the end of the backup script. </li><li>  <b>Web interface</b> to the schedule.  It is useful if editing crontab with your hands or in the web-interface for you does not look solid / inconvenient. </li><li>  <b>Pie charts</b> .  There are some graphs for visual representation of the percentage of successfully completed backups, their execution time, the width of the ‚Äúeaten‚Äù channel.  No wonder I already wrote that there is not enough WebUI, as in Bareos ... </li><li>  <b>Simple actions</b> that I would like to receive by the button: run backup on demand, restore to the machine, etc. </li></ul><br>  And at the very end, I would like to add an example of deduplication efficiency in a real working backup of PostgreSQL WAL files in a production environment: <br><br><pre> <code class="bash hljs">borg@backup ~ $ borg info PROJECT-PG-WAL Repository ID: 177eeb28056a60487bdfce96cfb33af1c186cb2a337226bc3d5380a78a6aeeb6 Location: /mnt/borg/PROJECT-PG-WAL Encrypted: No Cache: /mnt/borg/.cache/borg/177eeb28056a60487bdfce96cfb33af1c186cb2a337226bc3d5380a78a6aeeb6 Security dir: /mnt/borg/.config/borg/security/177eeb28056a60487bdfce96cfb33af1c186cb2a337226bc3d5380a78a6aeeb6 ------------------------------------------------------------------------------ Original size Compressed size Deduplicated size All archives: 6.68 TB 6.70 TB 19.74 GB Unique chunks Total chunks Chunk index: 11708 3230099</code> </pre> <br>  This is 65 days of backup WAL-files that were made every hour.  When using Bacula / Bareos, i.e.  without deduplication, we would get 6.7 TB of data.  Just think: we can afford to store almost 7 terabytes of data passed through PostgreSQL, just 20 GB of space actually occupied. <br><br><h2>  PS </h2><br>  Read also in our blog: <br><br><ul><li>  " <a href="https://habr.com/company/flant/blog/330406/">Theory and practice of unattended upgrades in Ubuntu</a> "; </li><li>  ‚Äú <a href="https://habr.com/company/flant/blog/330750/">Junior, who on the first day of work deleted the database from production</a> ‚Äù; </li><li>  ‚Äú <a href="https://habr.com/company/flant/blog/417509/">Accelerating the bootstrap of large databases with Kubernetes</a> .‚Äù </li></ul></div><p>Source: <a href="https://habr.com/ru/post/420055/">https://habr.com/ru/post/420055/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../420041/index.html">War of TypeScript or Conquest of Enum</a></li>
<li><a href="../420045/index.html">Bunker for the date: how I was allowed to walk on the data center RUVDS on the territory of the space plant</a></li>
<li><a href="../420049/index.html">The book "The Man Talking. Evolution and language "</a></li>
<li><a href="../420051/index.html">[DotNetBook] Span, Memory and ReadOnlyMemory</a></li>
<li><a href="../420053/index.html">Veeam Academy for C # Developers: New Season</a></li>
<li><a href="../420057/index.html">8 rules of a successful freelancer</a></li>
<li><a href="../420059/index.html">Now I am a team leader, but why is it so bad for me? Practical advice</a></li>
<li><a href="../420061/index.html">Evaluate processes in a development team based on objective data.</a></li>
<li><a href="../420063/index.html">"Holy" Timlid and his followers</a></li>
<li><a href="../420065/index.html">Communications as a performance zone</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>