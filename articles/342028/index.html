<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Space photography of the Earth</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Satellite image in false colors (green, red, near infrared) with a spatial resolution of 3 meters and superimposed mask of buildings from OpenStreetMa...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Space photography of the Earth</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/web/4cb/38c/691/4cb38c6913874c71b0e79d86f42a8f47.png"><br>  <i>Satellite image in false colors (green, red, near infrared) with a spatial resolution of 3 meters and superimposed mask of buildings from OpenStreetMap (satellite constellation PlanetScope)</i> <br><br>  Hi, Habr!  We are constantly expanding the sources of data that we use for analytics, so we decided to add more satellite imagery.  We have satellite imagery analytics useful in business and investment products.  In the first case, statistics on geo-data will help to understand where to open retail outlets, in the second case, it allows analyzing the activities of companies.  For example, for construction companies, one can calculate how many floors were built in a month, for agricultural companies, how many hectares of crop have grown, etc. <br><br>  In this article I will try to give a rough idea of ‚Äã‚Äãthe space imagery of the Earth, talk about the difficulties that can be encountered when starting work with satellite imagery: preliminary processing, algorithms for analysis and the Python library for working with satellite imagery and geodata.  So everyone who is interested in the field of computer vision, welcome under the cat! <br><a name="habracut"></a><br>  So, let us begin with the spectral regions in which the satellites perform the survey, and consider the characteristics of the imaging equipment of some satellites. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h2>  Spectral signatures, atmospheric windows and satellites </h2><br>  Different terrestrial surfaces have different spectral signatures.  For example, fresh basaltic lava and asphalt reflect different amounts of infrared light, although they are similar in visible light. <br><br><img src="https://habrastorage.org/web/100/6fd/86d/1006fd86d4c14cc8a5029b5956092024.png"><br>  <i>Reflectivity of dry grass, asphalt and fresh basalt lava</i> <br><br>  Like the surface of the Earth, gases in the atmosphere also have unique spectral signatures.  Moreover, not every radiation passes through the atmosphere of the Earth.  The spectral ranges passing through the atmosphere are called ‚Äúatmospheric windows‚Äù, and satellite sensors are configured to measure in these windows. <br><br><img src="https://habrastorage.org/web/fc8/208/df9/fc8208df970d4545977409b6b9559e45.png"><br>  <i>Atmospheric windows</i> <br><br>  Consider a satellite with one of the highest spatial resolutions - WorldView-3 <i>(Spatial resolution is a quantity characterizing the size of the smallest objects visible in the image; nadir is the direction coinciding with the direction of gravity at that point).</i> <br><br><table><caption>  WorldView-3 imaging equipment specifications </caption><tbody><tr><th>  Spectral range </th><th>  Name </th><th>  Range, nm </th><th>  Spatial resolution in nadir, m </th></tr><tr><td>  Panchromatic (1 channel; covers the visible part of the spectrum) </td><td></td><td>  450-800 </td><td>  0.31 </td></tr><tr><td rowspan="8">  Multispectral (8 channels) </td><td>  Coastal </td><td>  400-450 </td><td rowspan="8">  1.24 </td></tr><tr><td>  Blue </td><td>  450-510 </td></tr><tr><td>  Green </td><td>  510-580 </td></tr><tr><td>  Yellow </td><td>  585-625 </td></tr><tr><td>  Red </td><td>  630-690 </td></tr><tr><td>  Red edge </td><td>  705-745 </td></tr><tr><td>  Near infrared </td><td>  770-895 </td></tr><tr><td>  Near infrared </td><td>  860-1040 </td></tr><tr><td rowspan="8">  Multiband in the short infrared range (8 channels) </td><td>  SWIR-1 </td><td>  1195-1225 </td><td rowspan="8">  3.70 </td></tr><tr><td>  SWIR-2 </td><td>  1550-1590 </td></tr><tr><td>  SWIR-3 </td><td>  1640-1680 </td></tr><tr><td>  SWIR-4 </td><td>  1710-1750 </td></tr><tr><td>  SWIR-5 </td><td>  2145-2185 </td></tr><tr><td>  SWIR-6 </td><td>  2185-2225 </td></tr><tr><td>  SWIR-7 </td><td>  2235-2285 </td></tr><tr><td>  SWIR-8 </td><td>  2295-2365 </td></tr></tbody></table><br>  In addition to the above channels, WorldView-3 has 12 more channels designed specifically for atmospheric correction - CAVIS (Clouds, Aerosols, Vapors, Ice, and Snow) with a resolution of 30 m in the nadir and wavelengths from 0.4 to 2.2 microns. <br><br><img src="https://habrastorage.org/webt/kt/37/90/kt3790hm-v7rg2kimuppp4z18w4.png"><br>  <i>Sample image from WorldView-2;</i>  <i>panchromatic channel</i> <i><br><br><img src="https://habrastorage.org/webt/zp/w9/fc/zpw9fcxyvmzdd2aqniddg9-2kfi.png"><br></i>  <i>Sample images with different spatial resolution</i> <br><br>  Other interesting satellites are SkySat-1 and its twin SkySat-2.  They are interesting because they are able to shoot video up to 90 seconds over one territory with a frequency of 30 frames / sec and a spatial resolution of 1.1 m. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/fCrB1t8MncY" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  <i>SkySat satellite footage</i> <br><br>  The spatial resolution of the panchromatic channel is 0.9 m, multispectral channels (blue, green, red, near infrared) - 2 m. <br><br>  Some more examples: <br><br><ol><li>  The grouping of satellites PlanetScope performs shooting with a spatial resolution of 3 m in the red, green, blue and near infrared range; <br></li><li>  The grouping of RapidEye satellites performs surveys with a spatial resolution of 5 m in red, extreme red, green, blue and near infrared; <br></li><li>  A series of Russian satellites "Resurs-P" performs a survey with a spatial resolution of 0.7-1 m in the panchromatic channel, 3-4 m in multispectral channels (8 channels). <br></li></ol><br>  Unlike multispectral sensors, hyperspectral sensors divide the spectrum into many narrow ranges (approximately 100‚Äì200 channels) and have a spatial resolution of a different order: 10‚Äì80 m. <br><br>  Hyperspectral imagery is not as widely available as multispectral imagery.  There are few spacecraft equipped with hyperspectral sensors on board.  Among them, Hyperion aboard NASA EO-1 satellite (decommissioned), CHRIS aboard PROBA satellite owned by the European Space Agency, FTHSI aboard the MightySatII satellite of the research laboratory of the US Air Force, GSA (hyperspectral apparatus) on Russian space vehicles " Resource-P. <br><br><img src="https://habrastorage.org/web/f02/93a/397/f0293a3971074898b2af01a33e96e307.png"><br>  <i>The processed hyperspectral image from the onboard CASI 1500 sensor;</i>  <i>up to 228 channels;</i>  <i>spectral range 0.4 - 1 nm</i> <i><br><br><img src="https://habrastorage.org/web/c35/23e/54e/c3523e54e47c41b8a47de6a05d4cecce.png"><br></i>  <i>Processed image from the space sensor EO-1;</i>  <i>220 channels;</i>  <i>spectral range 0.4 - 2.5 nm</i> <br><br>  To simplify work with multichannel snapshots, there are <a href="https://speclab.cr.usgs.gov/spectral.lib04/spectral-lib.desc%2Bplots.html">libraries of</a> pure materials.  They show the reflectivity of pure materials. <br><br><h2>  Pre-processing of images </h2><br>  Before proceeding with the analysis of images, you must perform their preliminary processing: <br><br><ol><li>  Geolocation; <br></li><li>  Orthocorrection; <br></li><li>  Radiometric correction and calibration; <br></li><li>  Atmospheric correction. <br></li></ol><br>  Suppliers of satellite imagery take additional measurements to pre-process imagery, and can issue both processed images and raw ones with additional information for self-correction. <br><br>  It is also worth mentioning the <a href="https://www.planet.com/pulse/color-correction/">color correction of</a> satellite images - bringing the image in natural colors (red, green, blue) to a more familiar sight for a person. <br><br>  Approximate geolocation is calculated by the initial position of the satellite in orbit and image geometry.  Geo-referencing is performed using ground control points (GCP).  These control points are searched on the map and on the image, and knowing their coordinates in different coordinate systems, one can find the transformation parameters (conformal, affine, perspective or polynomial) from one coordinate system to another.  GCP search is performed using GPS surveys <a href="http://www.itc.nl/library/papers_2009/general/PrinciplesRemoteSensing.pdf">.</a>  <a href="http://www.itc.nl/library/papers_2009/general/PrinciplesRemoteSensing.pdf">1</a> sec.  230, <a href="http://geomatica.ru/clauses/283/">exp.</a>  <a href="http://geomatica.ru/clauses/283/">2</a> ] or by comparing two images, one of which accurately shows the coordinates of the GCP, at <a href="https://sovzond.ru/upload/iblock/220/22023bebc2f71b0a4a8626911a00ba08.pdf">key points</a> . <br><br>  Image orthocorrection is a process of geometric correction of images, which eliminates perspective distortions, reversals, distortions caused by lens distortion and others.  In this case, the image is reduced to a planned projection, that is, one in which each point of the terrain is observed strictly vertically, into the nadir. <br><br>  Since the satellites are shooting from a very high altitude (hundreds of kilometers), then when shooting in the nadir, the distortion should be minimal.  But the spacecraft can not shoot all the time in the nadir, otherwise it would take a very long time to wait for the moment when it passes over a given point.  To eliminate this drawback, the satellite is ‚Äúturned over‚Äù, and most of the frames are promising.  It should be noted that the angles of shooting can reach 45 degrees, and at high altitude this leads to significant distortions. <br><br>  Orthocorrection should be carried out if measuring and positional properties of the image are needed, since  image quality due to additional operations will deteriorate.  It is performed by reconstructing the geometry of the sensor at the time of registration for each line of the image and the representation of the relief in raster form. <br><br>  A satellite camera model is represented as generalized approximating functions (rational polynomials ‚Äî RPC coefficients), and altitude data can be obtained from ground-based measurements, using contour lines from a topographic map, stereo, radar data, or from commonly available coarse digital elevation models: SRTM ( resolution 30-90 m) and ASTER GDEM (resolution (15-90 m). <br><br>  Radiometric correction - correction at the stage of preliminary preparation of images of hardware radiometric distortion, due to the characteristics of the used shooting device. <br><br>  For scanner imaging devices, such defects are observed visually as image modulation (vertical and horizontal stripes).  Radiometric correction also removes image defects observed as failed image pixels. <br><br><img src="https://habrastorage.org/web/3cc/d7f/1e1/3ccd7f1e18ea4e218647a093d49a05d0.png"><br>  <i>Remove bad pixels and vertical bars</i> <br><br>  Radiometric correction is performed by two methods: <br><br><ol><li>  C using known parameters and settings of the shooting device (correction tables); <br></li><li>  Statistically. <br></li></ol><br>  In the first case, the necessary correction parameters are determined for the imaging instrument based on long-term ground and flight tests.  The correction by statistical method is performed by identifying the defect and its characteristics directly from the image itself, subject to correction. <br><br>  Radiometric calibration of images - transfer of ‚Äúraw values‚Äù of brightness to physical units, which can be compared with the data of other images: <br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-1-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><msub><mi>B</mi><mtext>&amp;#xA0;</mtext></msub><mi>l</mi><mi>a</mi><mi>m</mi><mi>b</mi><mi>d</mi><mi>a</mi><mo>=</mo><msub><mi>K</mi><mtext>&amp;#xA0;</mtext></msub><mi>l</mi><mi>a</mi><mi>m</mi><mi>b</mi><mi>d</mi><mi>a</mi><mspace width=&quot;thickmathspace&quot; /><mtext>&amp;#xA0;</mtext><mi>a</mi><mi>s</mi><mi>t</mi><mspace width=&quot;thickmathspace&quot; /><mi>D</mi><msub><mi>N</mi><mtext>&amp;#xA0;</mtext></msub><mi>l</mi><mi>a</mi><mi>m</mi><mi>b</mi><mi>d</mi><mi>a</mi><mo>+</mo><mspace width=&quot;thickmathspace&quot; /><msub><mi>C</mi><mtext>&amp;#xA0;</mtext></msub><mi>l</mi><mi>a</mi><mi>m</mi><mi>b</mi><mi>d</mi><mi>a</mi><mo>,</mo></math>" role="presentation" style="font-size: 100%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="54.33ex" height="2.419ex" viewBox="0 -780.1 23391.8 1041.5" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/tinkoff/blog/342028/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhidte8bnSgH_13yGvdtuk-i78X_og#MJMATHI-42" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/tinkoff/blog/342028/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhidte8bnSgH_13yGvdtuk-i78X_og#MJMATHI-6C" x="1109" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/tinkoff/blog/342028/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhidte8bnSgH_13yGvdtuk-i78X_og#MJMATHI-61" x="1408" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/tinkoff/blog/342028/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhidte8bnSgH_13yGvdtuk-i78X_og#MJMATHI-6D" x="1937" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/tinkoff/blog/342028/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhidte8bnSgH_13yGvdtuk-i78X_og#MJMATHI-62" x="2816" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/tinkoff/blog/342028/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhidte8bnSgH_13yGvdtuk-i78X_og#MJMATHI-64" x="3245" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/tinkoff/blog/342028/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhidte8bnSgH_13yGvdtuk-i78X_og#MJMATHI-61" x="3769" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/tinkoff/blog/342028/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhidte8bnSgH_13yGvdtuk-i78X_og#MJMAIN-3D" x="4576" y="0"></use><g transform="translate(5632,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/tinkoff/blog/342028/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhidte8bnSgH_13yGvdtuk-i78X_og#MJMATHI-4B" x="0" y="0"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/tinkoff/blog/342028/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhidte8bnSgH_13yGvdtuk-i78X_og#MJMATHI-6C" x="6832" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/tinkoff/blog/342028/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhidte8bnSgH_13yGvdtuk-i78X_og#MJMATHI-61" x="7130" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/tinkoff/blog/342028/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhidte8bnSgH_13yGvdtuk-i78X_og#MJMATHI-6D" x="7660" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/tinkoff/blog/342028/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhidte8bnSgH_13yGvdtuk-i78X_og#MJMATHI-62" x="8538" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/tinkoff/blog/342028/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhidte8bnSgH_13yGvdtuk-i78X_og#MJMATHI-64" x="8968" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/tinkoff/blog/342028/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhidte8bnSgH_13yGvdtuk-i78X_og#MJMATHI-61" x="9491" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/tinkoff/blog/342028/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhidte8bnSgH_13yGvdtuk-i78X_og#MJMATHI-61" x="10548" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/tinkoff/blog/342028/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhidte8bnSgH_13yGvdtuk-i78X_og#MJMATHI-73" x="11078" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/tinkoff/blog/342028/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhidte8bnSgH_13yGvdtuk-i78X_og#MJMATHI-74" x="11547" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/tinkoff/blog/342028/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhidte8bnSgH_13yGvdtuk-i78X_og#MJMATHI-44" x="12187" y="0"></use><g transform="translate(13015,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/tinkoff/blog/342028/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhidte8bnSgH_13yGvdtuk-i78X_og#MJMATHI-4E" x="0" y="0"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/tinkoff/blog/342028/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhidte8bnSgH_13yGvdtuk-i78X_og#MJMATHI-6C" x="14169" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/tinkoff/blog/342028/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhidte8bnSgH_13yGvdtuk-i78X_og#MJMATHI-61" x="14467" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/tinkoff/blog/342028/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhidte8bnSgH_13yGvdtuk-i78X_og#MJMATHI-6D" x="14997" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/tinkoff/blog/342028/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhidte8bnSgH_13yGvdtuk-i78X_og#MJMATHI-62" x="15875" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/tinkoff/blog/342028/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhidte8bnSgH_13yGvdtuk-i78X_og#MJMATHI-64" x="16305" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/tinkoff/blog/342028/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhidte8bnSgH_13yGvdtuk-i78X_og#MJMATHI-61" x="16828" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/tinkoff/blog/342028/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhidte8bnSgH_13yGvdtuk-i78X_og#MJMAIN-2B" x="17580" y="0"></use><g transform="translate(18858,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/tinkoff/blog/342028/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhidte8bnSgH_13yGvdtuk-i78X_og#MJMATHI-43" x="0" y="0"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/tinkoff/blog/342028/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhidte8bnSgH_13yGvdtuk-i78X_og#MJMATHI-6C" x="19924" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/tinkoff/blog/342028/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhidte8bnSgH_13yGvdtuk-i78X_og#MJMATHI-61" x="20222" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/tinkoff/blog/342028/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhidte8bnSgH_13yGvdtuk-i78X_og#MJMATHI-6D" x="20752" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/tinkoff/blog/342028/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhidte8bnSgH_13yGvdtuk-i78X_og#MJMATHI-62" x="21630" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/tinkoff/blog/342028/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhidte8bnSgH_13yGvdtuk-i78X_og#MJMATHI-64" x="22060" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/tinkoff/blog/342028/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhidte8bnSgH_13yGvdtuk-i78X_og#MJMATHI-61" x="22583" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/tinkoff/blog/342028/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhidte8bnSgH_13yGvdtuk-i78X_og#MJMAIN-2C" x="23113" y="0"></use></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><msub><mi>B</mi><mtext>&nbsp;</mtext></msub><mi>l</mi><mi>a</mi><mi>m</mi><mi>b</mi><mi>d</mi><mi>a</mi><mo>=</mo><msub><mi>K</mi><mtext>&nbsp;</mtext></msub><mi>l</mi><mi>a</mi><mi>m</mi><mi>b</mi><mi>d</mi><mi>a</mi><mspace width="thickmathspace"></mspace><mtext>&nbsp;</mtext><mi>a</mi><mi>s</mi><mi>t</mi><mspace width="thickmathspace"></mspace><mi>D</mi><msub><mi>N</mi><mtext>&nbsp;</mtext></msub><mi>l</mi><mi>a</mi><mi>m</mi><mi>b</mi><mi>d</mi><mi>a</mi><mo>+</mo><mspace width="thickmathspace"></mspace><msub><mi>C</mi><mtext>&nbsp;</mtext></msub><mi>l</mi><mi>a</mi><mi>m</mi><mi>b</mi><mi>d</mi><mi>a</mi><mo>,</mo></math></span></span></div><script type="math/tex;mode=display" id="MathJax-Element-1"> B_ \ lambda = K_ \ lambda \; \ ast \; DN_ \ lambda + \; C_ \ lambda, </script></p><br>  Where <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-2-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>B</mi><mtext>&amp;#xA0;</mtext></msub><mi>l</mi><mi>a</mi><mi>m</mi><mi>b</mi><mi>d</mi><mi>a</mi></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="9.984ex" height="2.298ex" viewBox="0 -780.1 4298.5 989.6" role="img" focusable="false" style="vertical-align: -0.487ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/tinkoff/blog/342028/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhidte8bnSgH_13yGvdtuk-i78X_og#MJMATHI-42" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/tinkoff/blog/342028/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhidte8bnSgH_13yGvdtuk-i78X_og#MJMATHI-6C" x="1109" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/tinkoff/blog/342028/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhidte8bnSgH_13yGvdtuk-i78X_og#MJMATHI-61" x="1408" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/tinkoff/blog/342028/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhidte8bnSgH_13yGvdtuk-i78X_og#MJMATHI-6D" x="1937" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/tinkoff/blog/342028/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhidte8bnSgH_13yGvdtuk-i78X_og#MJMATHI-62" x="2816" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/tinkoff/blog/342028/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhidte8bnSgH_13yGvdtuk-i78X_og#MJMATHI-64" x="3245" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/tinkoff/blog/342028/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhidte8bnSgH_13yGvdtuk-i78X_og#MJMATHI-61" x="3769" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>B</mi><mtext>&nbsp;</mtext></msub><mi>l</mi><mi>a</mi><mi>m</mi><mi>b</mi><mi>d</mi><mi>a</mi></math></span></span><script type="math/tex" id="MathJax-Element-2"> B_ \ lambda </script>  - energy brightness for the spectral zone <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-3-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mtext>&amp;#xA0;</mtext><mi>l</mi><mi>a</mi><mi>m</mi><mi>b</mi><mi>d</mi><mi>a</mi></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="7.987ex" height="2.057ex" viewBox="0 -780.1 3439 885.9" role="img" focusable="false" style="vertical-align: -0.246ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/tinkoff/blog/342028/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhidte8bnSgH_13yGvdtuk-i78X_og#MJMATHI-6C" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/tinkoff/blog/342028/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhidte8bnSgH_13yGvdtuk-i78X_og#MJMATHI-61" x="548" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/tinkoff/blog/342028/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhidte8bnSgH_13yGvdtuk-i78X_og#MJMATHI-6D" x="1078" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/tinkoff/blog/342028/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhidte8bnSgH_13yGvdtuk-i78X_og#MJMATHI-62" x="1956" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/tinkoff/blog/342028/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhidte8bnSgH_13yGvdtuk-i78X_og#MJMATHI-64" x="2386" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/tinkoff/blog/342028/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhidte8bnSgH_13yGvdtuk-i78X_og#MJMATHI-61" x="2909" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtext>&nbsp;</mtext><mi>l</mi><mi>a</mi><mi>m</mi><mi>b</mi><mi>d</mi><mi>a</mi></math></span></span><script type="math/tex" id="MathJax-Element-3"> \ lambda </script>  ; <br><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-4-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>D</mi><msub><mi>N</mi><mtext>&amp;#xA0;</mtext></msub><mi>l</mi><mi>a</mi><mi>m</mi><mi>b</mi><mi>d</mi><mi>a</mi></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="12.01ex" height="2.298ex" viewBox="0 -780.1 5171 989.6" role="img" focusable="false" style="vertical-align: -0.487ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/tinkoff/blog/342028/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhidte8bnSgH_13yGvdtuk-i78X_og#MJMATHI-44" x="0" y="0"></use><g transform="translate(828,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/tinkoff/blog/342028/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhidte8bnSgH_13yGvdtuk-i78X_og#MJMATHI-4E" x="0" y="0"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/tinkoff/blog/342028/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhidte8bnSgH_13yGvdtuk-i78X_og#MJMATHI-6C" x="1982" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/tinkoff/blog/342028/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhidte8bnSgH_13yGvdtuk-i78X_og#MJMATHI-61" x="2280" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/tinkoff/blog/342028/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhidte8bnSgH_13yGvdtuk-i78X_og#MJMATHI-6D" x="2810" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/tinkoff/blog/342028/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhidte8bnSgH_13yGvdtuk-i78X_og#MJMATHI-62" x="3688" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/tinkoff/blog/342028/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhidte8bnSgH_13yGvdtuk-i78X_og#MJMATHI-64" x="4118" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/tinkoff/blog/342028/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhidte8bnSgH_13yGvdtuk-i78X_og#MJMATHI-61" x="4641" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>D</mi><msub><mi>N</mi><mtext>&nbsp;</mtext></msub><mi>l</mi><mi>a</mi><mi>m</mi><mi>b</mi><mi>d</mi><mi>a</mi></math></span></span><script type="math/tex" id="MathJax-Element-4"> DN_ \ lambda </script>  - raw brightness values; <br><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-5-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>K</mi><mtext>&amp;#xA0;</mtext></msub><mi>l</mi><mi>a</mi><mi>m</mi><mi>b</mi><mi>d</mi><mi>a</mi></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="10.193ex" height="2.298ex" viewBox="0 -780.1 4388.5 989.6" role="img" focusable="false" style="vertical-align: -0.487ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/tinkoff/blog/342028/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhidte8bnSgH_13yGvdtuk-i78X_og#MJMATHI-4B" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/tinkoff/blog/342028/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhidte8bnSgH_13yGvdtuk-i78X_og#MJMATHI-6C" x="1199" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/tinkoff/blog/342028/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhidte8bnSgH_13yGvdtuk-i78X_og#MJMATHI-61" x="1498" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/tinkoff/blog/342028/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhidte8bnSgH_13yGvdtuk-i78X_og#MJMATHI-6D" x="2027" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/tinkoff/blog/342028/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhidte8bnSgH_13yGvdtuk-i78X_og#MJMATHI-62" x="2906" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/tinkoff/blog/342028/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhidte8bnSgH_13yGvdtuk-i78X_og#MJMATHI-64" x="3335" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/tinkoff/blog/342028/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhidte8bnSgH_13yGvdtuk-i78X_og#MJMATHI-61" x="3859" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>K</mi><mtext>&nbsp;</mtext></msub><mi>l</mi><mi>a</mi><mi>m</mi><mi>b</mi><mi>d</mi><mi>a</mi></math></span></span><script type="math/tex" id="MathJax-Element-5"> K_ \ lambda </script>  - calibration coefficient; <br><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-6-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>C</mi><mtext>&amp;#xA0;</mtext></msub><mi>l</mi><mi>a</mi><mi>m</mi><mi>b</mi><mi>d</mi><mi>a</mi></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="9.881ex" height="2.298ex" viewBox="0 -780.1 4254.5 989.6" role="img" focusable="false" style="vertical-align: -0.487ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/tinkoff/blog/342028/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhidte8bnSgH_13yGvdtuk-i78X_og#MJMATHI-43" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/tinkoff/blog/342028/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhidte8bnSgH_13yGvdtuk-i78X_og#MJMATHI-6C" x="1065" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/tinkoff/blog/342028/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhidte8bnSgH_13yGvdtuk-i78X_og#MJMATHI-61" x="1364" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/tinkoff/blog/342028/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhidte8bnSgH_13yGvdtuk-i78X_og#MJMATHI-6D" x="1893" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/tinkoff/blog/342028/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhidte8bnSgH_13yGvdtuk-i78X_og#MJMATHI-62" x="2772" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/tinkoff/blog/342028/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhidte8bnSgH_13yGvdtuk-i78X_og#MJMATHI-64" x="3201" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/tinkoff/blog/342028/&amp;xid=17259,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhidte8bnSgH_13yGvdtuk-i78X_og#MJMATHI-61" x="3725" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>C</mi><mtext>&nbsp;</mtext></msub><mi>l</mi><mi>a</mi><mi>m</mi><mi>b</mi><mi>d</mi><mi>a</mi></math></span></span><script type="math/tex" id="MathJax-Element-6"> C_ \ lambda </script>  - calibration constant. <br><br>  Electromagnetic radiation of the satellite, before it is recorded by the sensor, will pass through the atmosphere of the Earth twice.  There are two main effects of the atmosphere - scattering and absorption.  Scattering occurs when particles and gas molecules in the atmosphere interact with electromagnetic radiation, deflecting it from the original path.  When absorbed, a part of the radiation energy is converted into the internal energy of absorbing molecules, as a result of which the atmosphere is heated.  The effect of scattering and absorption on electromagnetic radiation changes as one passes from one part of the spectrum to another. <br><br><img src="https://habrastorage.org/web/879/c08/d8d/879c08d8d8c2497c8cefbacadd74f9ad.png"><br>  <i>Factors affecting the incidence of reflected solar radiation on satellite sensors</i> <br><br>  There are various algorithms for performing atmospheric correction (for example <a href="http://gis-lab.info/qa/atcorr-dos.html">, the Dark Object Subtraction DOS method</a> ).  The input parameters for the models are: the geometry of the location of the Sun and the sensor, the atmospheric model for gaseous components, the aerosol model (type and concentration), the optical thickness of the atmosphere, the surface reflection coefficient and spectral channels. <br>  For atmospheric correction, you can also apply the algorithm to remove the haze from the image - <a href="http://kaiminghe.com/publications/cvpr09.pdf">Single Image Haze Removal Using Dark Channel Prior</a> ( <a href="https://github.com/joyeecheung/dark-channel-prior-dehazing">implementation</a> ). <br><br><img src="https://habrastorage.org/webt/59/ef/5e/59ef5eabd9690480558000.jpeg"><br>  <i>Work Example Single Image Haze Removal Using Dark Channel Prior</i> <br><br><h2>  Index Images </h2><br>  When studying objects using multichannel images, it is often not the absolute values ‚Äã‚Äãthat are important, but the characteristic relationships between the brightness values ‚Äã‚Äãof the object in different spectral zones.  To do this, build the so-called index images.  In such images, the sought-after objects are more vividly and vividly highlighted in comparison with the original image. <br><br><table><caption>  Examples of index images </caption><tbody><tr><th>  Index name </th><th>  Formula </th><th>  Application </th></tr><tr><td>  Iron Oxide Index </td><td>  Red Blue </td><td>  To detect the content of iron oxides </td></tr><tr><td>  Clay Minerals Index </td><td>  The ratio of the brightness values ‚Äã‚Äãwithin the middle infrared channel (CIC).  CIC1 / CIC2, where CIC1 is the range from 1.55 to 1.75 microns, CIC2 is the range from 2.08 to 2.35 microns </td><td>  To identify the content of clay minerals </td></tr><tr><td>  Ferrous Minerals Index </td><td>  The ratio of the brightness value in the average infrared (SIK1; from 1.55 to 1.75 Œºm) channel to the brightness value in the near infrared channel (BIC).  SIK1 / BIK </td><td>  To detect glandular minerals </td></tr><tr><td>  Redness Index (RI) </td><td>  Based on the difference in reflectivity of red minerals in the red (K) and green (W) ranges.  RI = ( - ) / ( + ) </td><td>  To detect the content of iron oxide in the soil </td></tr><tr><td>  Normalized differential snow index (NDSI) </td><td>  NDSI is a relative value characterized by the difference in snow reflectivity in the red (K) and shortwave infrared (CIR) ranges. <br>  NDSI = (K - KIK) / (K + KIK) </td><td>  Used to highlight areas covered with snow.  For snow NDSI&gt; 0.4 </td></tr><tr><td>  Water Index (WI) </td><td>  WI = 0.90 ¬µm / 0.97 ¬µm </td><td>  It is used to determine the water content in vegetation from hyperspectral images </td></tr><tr><td>  Normalized Differential Vegetation Index (NDVI) </td><td>  Chlorophyll of plant leaves reflects radiation in the near infrared (NIR) range of the electromagnetic spectrum and absorbs it in red (K).  The ratio of brightness values ‚Äã‚Äãin these two channels allows you to clearly separate and analyze plant from other natural objects. <br>  NDVI = (BIK - K) / (BIK + K) </td><td>  Shows the presence and condition of vegetation.  NDVI values ‚Äã‚Äãrange from -1 to 1; <br>  Dense vegetation: 0.7; <br>  Sparse vegetation: 0.5; <br>  Open soil: 0.025; <br>  Clouds: 0; <br>  Snow and ice: -0.05; <br>  Water: -0.25; <br>  Artificial materials (concrete, asphalt): -0.5 <br></td></tr></tbody></table><br><h2>  Working with satellite imagery in Python </h2><br>  One of the formats in which it is customary to store satellite images is GeoTiff (we confine ourselves only to them).  To work with GeoTiff in Python, you can use the <a href="http://www.gdal.org/index_ru.html">gdal</a> library or <a href="https://mapbox.s3.amazonaws.com/playground/perrygeo/rasterio-docs/python_manual.html">rasterio</a> . <br><br>  To install gdal and rasterio it is better to use conda: <br><br><pre><code class="bash hljs">conda install -c conda-forge gdal conda install -c conda-forge rasterio</code> </pre> <br>  Other libraries for working with satellite images are easily installed via pip. <br><br>  Reading GeoTiff via gdal: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> osgeo <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> gdal <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np src_ds = gdal.Open(<span class="hljs-string"><span class="hljs-string">'image.tif'</span></span>) img = src_ds.ReadAsArray() <span class="hljs-comment"><span class="hljs-comment">#height, width, band img = np.rollaxis(img, 0, 3) width = src_ds.RasterXSize height = src_ds.RasterYSize gt = src_ds.GetGeoTransform() #    minx = gt[0] miny = gt[3] + width*gt[4] + height*gt[5] maxx = gt[0] + width*gt[1] + height*gt[2] maxy = gt[3]</span></span></code> </pre><br>  The coordinate systems for satellite images are quite a few.  They can be divided into two groups: geographical coordinate systems (GCS) and flat coordinate systems (UCS). <br><br>  In HSC, units of measurement are angular and coordinates are represented by decimal degrees.  The most famous GSK is WGS 84 (EPSG: 4326). <br><br>  In UCS, units of measure are linear and coordinates can be expressed as meters, feet, kilometers, etc., so they can be interpolated linearly.  For the transition from GSK to UCS apply map projections.  One of the most famous projections is the Mercator projection. <br><br>  It is customary to store the map (image markup) not in raster form, but in the form of points, lines and polygons.  The geocoordinates of the vertices of these geometric objects are stored inside the files with the markup of the images.  You can use the fiona and shapely libraries to read and work with them. <br><br>  Script for rasterizing polygons: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> rasterio <span class="hljs-comment"><span class="hljs-comment">#fiona       ,  shp  geojson import fiona import cv2 from shapely.geometry import shape from shapely.ops import cascaded_union from shapely.ops import transform from shapely.geometry import MultiPolygon def rasterize_polygons(img_mask, polygons):   if not polygons:       return img_mask     if polygons.geom_type == 'Polygon':       polygons = MultiPolygon([polygons])     int_coords = lambda x: np.array(x).round().astype(np.int32)   exteriors = [int_coords(poly.exterior.coords) for poly in polygons]   interiors = [int_coords(pi.coords) for poly in polygons                for pi in poly.interiors]     cv2.fillPoly(img_mask, exteriors, 255)   cv2.fillPoly(img_mask, interiors, 0)   return img_mask def get_polygons(shapefile):     geoms = [feature["geometry"] for feature in shapefile]   polygons = list()   for g in geoms:           s = shape(g)           if s.geom_type == 'Polygon':               if s.is_valid:                   polygons.append(s)               else:                   #                     polygons.append(s.buffer(0))           elif s.geom_type == 'MultiPolygon':               for p in s:                   if p.is_valid:                       polygons.append(p)                   else:                       #                         polygons.append(p.buffer(0))   mpolygon = cascaded_union(polygons)     return mpolygon #   geojson    src = rasterio.open('image.tif') shapefile = fiona.open('buildings.geojson', "r") #  (      ) left = src.bounds.left right = src.bounds.right bottom = src.bounds.bottom top = src.bounds.top height,width = src.shape #  mpolygon = get_polygons(shapefile) #    ,          mpolygon = transform(lambda x, y, z=None: (width * (x - left) / float(right - left),\                                                      height - height * (y - bottom) / float(top - bottom)), mpolygon) #  real_mask = np.zeros((height,width), np.uint8) real_mask = rasterize_polygons(real_mask, mpolygon)</span></span></code> </pre><br>  While decrypting images, you may need to intersect polygons (for example, automatically marking buildings on a map, you also want to automatically remove the markings of buildings in those places where there are clouds).  There is a Wyler-Atherton algorithm for this, but it only works with polygons without self-intersections.  To eliminate self-intersections, you need to check the intersection of all edges with other edges of the polygon and add new vertices.  These vertices will divide the corresponding edges into parts.  The shapely library has a <a href="http://toblerity.org/shapely/manual.html">method</a> for eliminating self-intersections - buffer (0). <br><br>  To translate from GSK to PSK, you can use the PyProj library (or do it in rasterio): <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#      epsg:4326      epsg:32637 (  ) def wgs84_to_32637(lon, lat):   from pyproj import Proj, transform     inProj = Proj(init='epsg:4326')   outProj = Proj(init='epsg:32637')     x,y = transform(inProj,outProj,lon,lat)     return x,y</span></span></code> </pre><br><h2>  Principal component method </h2><br>  If the snapshot contains more than three spectral channels, you can create a color image of the three main components, thereby reducing the amount of data without noticeable loss of information. <br><br>  This transformation is also carried out for a series of different-time shots, given in a single coordinate system, to identify the dynamics, which is clearly manifested in one or two components. <br><br>  Script for compression of 4-channel image to 3-channel: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> osgeo <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> gdal <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.decomposition <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> IncrementalPCA <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> preprocessing <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.pyplot <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> plt <span class="hljs-comment"><span class="hljs-comment"># ,    height, width, band    ,  PCA     src_ds = gdal.Open('0.tif') img = src_ds.ReadAsArray() img = np.rollaxis(img, 0, 3)[300:1000, 700:1700, :] height, width, bands = img.shape #   PCA data = img.reshape((height * width, 4)).astype(np.float) num_data, dim = data.shape pca = IncrementalPCA(n_components = 3, whiten = True) #c  (  ) x = preprocessing.scale(data) #         y = pca.fit_transform(x) y = y.reshape((height, width, 3)) #   for idx in range(0, 3):   band_max = y[:, :, idx].max()   y[:, :, idx] = np.around(y[:, :, idx] * 255.0 / band_max).astype(np.uint8)</span></span></code> </pre><br><img src="https://habrastorage.org/web/ec7/e3c/4b0/ec7e3c4b04c44a4d91ebb665c0ba9514.png"><br>  <i>Photo from the satellite group PlanetScope (red, green, blue without color correction)</i> <br><br><img src="https://habrastorage.org/web/4ba/1f8/562/4ba1f8562e14400c95923dff98ac6d91.png"><br>  <i>Photo from the satellite group PlanetScope (green, red, near infrared)</i> <br><br><img src="https://habrastorage.org/web/121/e8b/13c/121e8b13c2c74706a1e71df2e116f026.png"><br>  <i>Snapshot taken with the principal component method</i> <br><br><h2>  Spectral separation method (Spectral Unmixing) </h2><br>  The spectral separation method is used to recognize objects in images that are much smaller than the pixel size. <br><br>  The essence of the method is as follows: mixed spectra are analyzed by comparing them with known pure spectra, for example, from the already mentioned spectral libraries of pure materials.  There is a quantitative assessment of the ratio of this known (pure) spectrum and impurities in the spectrum of each pixel.  After performing such an assessment, an image can be obtained, colored so that the color of the pixel will mean which component prevails in the spectrum that is a pixel. <br><br><img src="https://habrastorage.org/web/958/5c0/485/9585c04853c24d3d844b1d9151305a10.png"><br>  <i>Mixed spectral curve</i> <br><br><img src="https://habrastorage.org/web/d1c/dd9/4c9/d1cdd94c9f65442992f95c7e6871f9e6.png"><br>  <i>Decrypted snapshot</i> <br><br><h2>  Segmentation of satellite images </h2><br><br>  Currently, state-of-the-art results in binary image segmentation problems show <a href="https://habrahabr.ru/company/avito/blog/325632/">modifications of the</a> <a href="https://habrahabr.ru/company/ods/blog/325096/">U-Net</a> <a href="http://blog.kaggle.com/2017/04/26/dstl-satellite-imagery-competition-1st-place-winners-interview-kyle-lee/">model</a> . <br><br><img src="https://habrastorage.org/web/77f/88b/6af/77f88b6afb4946e0a5eb86b6971b971a.png"><br>  <i>U-Net model architecture (image size at the output is smaller than the size of the input image; this is due to the fact that the network predicts worse at the edges of the image)</i> <br><br>  The author of U-Net has developed an architecture based on a different model - Fully convolutional network (FCN), a feature of which is the presence of only convolutional words (not counting max-pooling). <br>  U-Net differs from FCN in that layers are added in which max-pooling is replaced with up-convolution.  Thus, the new layers gradually increase the output resolution.  Also, signs from the encoder part are combined with features from the decoder part, so that the model can make more accurate predictions with additional information. <br><br>  A model in which there is no forwarding of signs from the encoder-part to the decoder-part is called SegNet and in practice shows results worse than U-Net. <br><br><img src="https://habrastorage.org/web/25b/f8f/337/25bf8f33769842ce9b8f6ee5bf0fc8ee.png" alt="image"><br>  <i>Max-pooling</i> <br><br><img src="https://habrastorage.org/web/648/808/0f5/6488080f58fd4e0090374a780c3ccc3f.png" alt="image"><br>  <i>Up-convolution</i> <br><br>  The absence of layers attached to the image size in U-Net, Segnet and FCN allows to feed images of different sizes to the same network input (the image size must be a multiple of the number of filters in the first convolutional layer). <br><br>  In keras, this is implemented as follows: <br><br><pre> <code class="python hljs">inputs = Input((channel_number, <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>))</code> </pre><br>  Learning, as well as prediction, can be conducted either on image fragments (crocs), or on the entire image as a whole, if GPU memory allows.  In this case, in the first case: <br>  1) more than the size of the batch, which will well affect the accuracy of the model, if the data is noisy and heterogeneous; <br>  2) less risk of retraining, because  There is much more data than when training on full-size images. <br><br>  However, when learning on the crocks, the edge effect is more pronounced - the network predicts less accurately at the edges of the image than in areas closer to the center (the closer the prediction point to the border, the less information the network has on what is next).  The problem can be solved by predicting a mask on fragments with overlaps and discarding or averaging the areas on the border. <br><br>  U-Net is a simple and powerful architecture for a binary segmentation task, on github you can find more than one implementation for any DL framework, but for segmentation of a large number of classes, this architecture loses to other architectures, for example, PSP-Net.  <a href="http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review">Here</a> you can read an interesting review on architectures for semantic image segmentation. <br><br><h2>  Determining the height of buildings </h2><br>  The height of buildings can be determined by their shadows.  To do this, you need to know: the size of the pixel in meters, the length of the shadow in pixels and the sun (solar) elevation angle (angle of the sun above the horizon). <br><br><img src="https://habrastorage.org/web/b5e/720/14d/b5e72014d5aa4e10a8989b98c641440e.png"><br>  <i>Geometry of the sun, satellite and building</i> <br><br>  The whole complexity of the task is to segment the building shadow as accurately as possible and determine the length of the shadow in pixels.  Problems are also added by the presence of clouds in the pictures. <br><br>  There are more accurate methods for determining the height of the building.  For example, you can take into account the angle of the satellite above the horizon. <br><br><div class="spoiler">  <b class="spoiler_title">An example script for determining the height of buildings by geo-coordinates</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pandas <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> pd <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> rasterio <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> math <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> cv2 <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> shapely.geometry <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Point <span class="hljs-comment"><span class="hljs-comment">#       (    ) #   remove_small_objects  remove_small_holes   skimage def filterByLength(input, length, more=True):   import Queue as queue     copy = input.copy()   output = np.zeros_like(input)     for i in range(input.shape[0]):             for j in range(input.shape[1]):           if (copy[i][j] == 255):                              q_coords = queue.Queue()               output_coords = list()                             copy[i][j] = 100                             q_coords.put([i,j])               output_coords.append([i,j])                             while(q_coords.empty() == False):                                     currentCenter = q_coords.get()                                     for idx1 in range(3):                       for idx2 in range(3):                                                     offset1 = - 1 + idx1                           offset2 = - 1 + idx2                                                     currentPoint = [currentCenter[0] + offset1, currentCenter[1] + offset2]                           if (currentPoint[0] &gt;= 0 and currentPoint[0] &lt; input.shape[0]):                                   if (currentPoint[1] &gt;= 0 and currentPoint[1] &lt; input.shape[1]):                                       if (copy[currentPoint[0]][currentPoint[1]] == 255):                                           copy[currentPoint[0]][currentPoint[1]] = 100                                           q_coords.put(currentPoint)                                           output_coords.append(currentPoint)                             if (more == True):                   if (len(output_coords) &gt;= length):                       for coord in output_coords:                           output[coord[0]][coord[1]] = 255               else:                   if (len(output_coords) &lt; length):                       for coord in output_coords:                           output[coord[0]][coord[1]] = 255                 return output #      epsg:32637      epsg:4326 def getLongLat(x1, y1):   from pyproj import Proj, transform     inProj = Proj(init='epsg:32637')   outProj = Proj(init='epsg:4326')     x2,y2 = transform(inProj,outProj,x1,y1)     return x2,y2 #      epsg:4326      epsg:32637 def get32637(x1, y1):   from pyproj import Proj, transform     inProj = Proj(init='epsg:4326')   outProj = Proj(init='epsg:32637')     x2,y2 = transform(inProj,outProj,x1,y1)     return x2,y2 #      epsg:32637   () def crsToPixs(width, height, left, right, bottom, top, coords):     x = coords.xy[0][0]   y = coords.xy[1][0]     x = width * (x - left) / (right - left)   y = height - height * (y - bottom) / (top - bottom)     x = int(math.ceil(x))   y = int(math.ceil(y))     return x,y #      def shadowSegmentation(roi, threshold = 60):     thresh = cv2.equalizeHist(roi)   ret, thresh = cv2.threshold(thresh,threshold,255,cv2.THRESH_BINARY_INV)     tmp = filterByLength(thresh, 50)     if np.count_nonzero(tmp) != 0:       thresh = tmp         return thresh # () ; x,y -     thresh def getShadowSize(thresh, x, y):     #          min_dist = thresh.shape[0]   min_dist_coords = (0, 0)     for i in range(thresh.shape[0]):       for j in range(thresh.shape[1]):           if (thresh[i,j] == 255) and (math.sqrt( (i - y) * (i - y) + (j - x) * (j - x) ) &lt; min_dist):               min_dist = math.sqrt( (i - y) * (i - y) + (j - x) * (j - x) )               min_dist_coords = (i, j) #y,x                 # ,           import Queue as queue     q_coords = queue.Queue()   q_coords.put(min_dist_coords)     mask = thresh.copy()   output_coords = list()   output_coords.append(min_dist_coords)     while q_coords.empty() == False:       currentCenter = q_coords.get()             for idx1 in range(3):           for idx2 in range(3):               offset1 = - 1 + idx1               offset2 = - 1 + idx2               currentPoint = [currentCenter[0] + offset1, currentCenter[1] + offset2]               if (currentPoint[0] &gt;= 0 and currentPoint[0] &lt; mask.shape[0]):                       if (currentPoint[1] &gt;= 0 and currentPoint[1] &lt; mask.shape[1]):                           if (mask[currentPoint[0]][currentPoint[1]] == 255):                               mask[currentPoint[0]][currentPoint[1]] = 100                               q_coords.put(currentPoint)                               output_coords.append(currentPoint)     #     mask = np.zeros_like(mask)   for i in range(len(output_coords)):       mask[output_coords[i][0]][output_coords[i][1]] = 255     # ()      erode   kernel = np.ones((3,3),np.uint8)   i = 0   while np.count_nonzero(mask) != 0:       mask = cv2.erode(mask,kernel,iterations = 1)       i += 1     return i + 1 # ,    def getNoCloudArea(b, g, r, n):     gray = (b + g + r + n) / 4.0     band_max = np.max(gray)     gray = np.around(gray * 255.0 / band_max).astype(np.uint8)   gray[gray == 0] = 255   ret, no_cloud_area = cv2.threshold(gray, 100, 255, cv2.THRESH_BINARY)   kernel = np.ones((50, 50), np.uint8)   no_cloud_area = cv2.morphologyEx(no_cloud_area, cv2.MORPH_OPEN, kernel)   kernel = np.ones((100, 100), np.uint8)   no_cloud_area = cv2.morphologyEx(no_cloud_area, cv2.MORPH_DILATE, kernel)   no_cloud_area = cv2.morphologyEx(no_cloud_area, cv2.MORPH_DILATE, kernel)   no_cloud_area = 255 - no_cloud_area     return no_cloud_area # csv   lat,long,height df = pd.read_csv('buildings.csv') # csv      image_df = pd.read_csv('geotiff.csv') #    sun_elevation = image_df['sun_elevation'].values[0] with rasterio.open('image.tif') as src:         #        #       epsg:32637       left = src.bounds.left       right = src.bounds.right       bottom = src.bounds.bottom       top = src.bounds.top             height,width = src.shape             b, g, r, n = map(src.read, (1, 2, 3, 4))             #  , ..          band_max = g.max()       img = np.around(g * 255.0 / band_max).astype(np.uint8)       #  ,          no_cloud_area = getNoCloudArea(b, g, r, n)       heights = list()             #     (size, size)       size = 30       for idx in range(0, df.shape[0]):           #              lat = df.loc[idx]['lat']           lon = df.loc[idx]['long']           build_height = int(df.loc[idx]['height'])           #       epsg:32637           #(               )           build_coords = Point(get32637(lon, lat))                     #      ,                    x,y = crsToPixs(width, height, left, right, bottom, top, build_coords)           #  ,                 if no_cloud_area[y][x] == 255:               #  ,                        #                      roi = img[y-size:y,x-size:x].copy()               shadow = shadowSegmentation(roi)               #(size, size) -    roi               #                        #(     3 )               shadow_length = getShadowSize(shadow, size, size) * 3               est_height = shadow_length * math.tan(sun_elevation * 3.14 / 180)                      est_height = int(est_height)                             heights.append((est_height, build_height))       MAPE = 0             for i in range(len(heights)):           MAPE += ( abs(heights[i][0] - heights[i][1]) / float(heights[i][1]) )                 MAPE *= (100 / float(len(heights)))</span></span></code> </pre><br></div></div><br><img src="https://habrastorage.org/web/aa0/7d6/710/aa07d67107bc4905a2a088ace7647cef.png"><br>  <i>An example of the operation of the algorithm for determining the height of buildings by the shadow</i> <br><br>  In the images from the group of satellites PlanetScope with a spatial resolution of 3 m, the error in determining the height of buildings using the MAPE (mean absolute percentage error) was ~ 30%.  A total of 40 buildings and one image were reviewed.  However, in submeter shots, the researchers <a href="http://www.sciencedirect.com/science/article/pii/S0924271616301939">received an error of only 4-5%</a> . <br><br><h2>  Conclusion </h2><br>  Remote sensing of the Earth provides many opportunities for analytics.  For example, companies such as Orbital Insight, Spaceknow, Remote Sensing Metrics, OmniEarth and DataKind, on the basis of satellite imagery, monitor production and consumption in the United States, analyze urbanization, traffic, vegetation, the economy, etc.  At the same time, the pictures themselves are becoming more accessible.  For example, images from <a href="https://lv.eosda.com/">Landsat-8 and Sentinel-2</a> satellites with a spatial resolution of more than 10m are in the public domain and are constantly being updated. <br><br>  In Russia, Sovzond, ScanEx, Racurs, Geo-Alliance and Northern Geographic Company also conduct geoanalytics using satellite images and are official distributors of satellite remote sensing operators: Russian Space Systems OJSC (Russia), DigitalGlobe (USA), Planet (USA ), Airbus Defense and Space (France-Germany), etc. <br><br>  PS Yesterday we launched an <a href="https://fintech.tinkoff.ru/contest/cv/2017/about">online satellite imagery competition</a> consisting of two tasks: <br><br><ol><li>  Segmentation of buildings and cars and car counting; <br></li><li>  Determination of building heights. <br></li></ol><br>  So, anyone who is interested in the field of computer vision and remote sensing of the Earth, join! <br><br>  We plan to hold another competition in the pictures of Roskosmos, Airbus Defense and Space and PlanetScope. <br><br><div class="spoiler">  <b class="spoiler_title">List of sources</b> <div class="spoiler_text"><ul><li>  DSTL: <br><ol><li>  <a href="http://blog.kaggle.com/2017/04/26/dstl-satellite-imagery-competition-1st-place-winners-interview-kyle-lee">Dust Satellite Imagery Competition, 1st Place Winner's Interview: Kyle Lee</a> </li><li>  <a href="http://habrahabr.ru/company/avito/blog/325632">Second honorary.</a>  <a href="http://habrahabr.ru/company/avito/blog/325632">Notes of the participant of the contest Dstl Satellite Imagery Feature Detection</a> </li><li>  <a href="http://habrahabr.ru/company/ods/blog/325096">Kaggle: British satellite imagery.</a>  <a href="http://habrahabr.ru/company/ods/blog/325096">How we took the third place</a> </li><li>  <a href="http://www.kaggle.com/lopuhin/full-pipeline-demo-poly-pixels-ml-poly">Full pipeline demo: poly -&gt; pixels -&gt; ML -&gt; poly</a> </li></ol></li><li>  Pre-processing of images: <br><ol><li>  <a href="http://gis-lab.info/qa/aster_radiocorr.html">ASTER Radiometric VNIR Data Correction</a> </li><li>  <a href="http://gis-lab.info/qa/ortho-rpc.html">Orthocorrection of space images using RPC</a> </li><li>  <a href="http://mapexpert.com.ua/index_ru.php%3Ftable%3DMenu%26id%3D26">Earth remote sensing data processing - Data processing stages</a> </li><li>  <a href="http://gis-lab.info/qa/atcorr-dos.html">Atmospheric correction method DOS</a> <br></li></ol></li><li>  Determining the height of buildings: <br><ol><li>  <a href="http://www.sciencedirect.com/science/article/pii/S0924271616301939">Satellite images analysis for shadow detection and building height</a> </li><li>  <a href="http://www.researchgate.net/publication/266755824_DETECTION_OF_BUILDINGS_HEIGHT_USING_SATELLITE_MONOSCOPIC_IMAGE">Detection of buildings height using satellite monoscopic image</a> </li></ol></li><li>  U-Net: <br><ol><li>  <a href="http://arxiv.org/abs/1505.04597">U-Net: Convolutional Networks for Biomedical Image Segmentation</a> <br></li><li>  <a href="https://github.com/ZFTurbo/ZF_UNET_224_Pretrained_Model">U-Net implementation of similar architecture on keras</a> </li></ol></li><li>  Miscellanea: <br><ol><li>  <a href="https://earthobservatory.nasa.gov/Features/FalseColor/%3Fsrc%3Deoa-features">NASA article</a> <br></li><li>  <a href="http://www.itc.nl/library/papers_2009/general/PrinciplesRemoteSensing.pdf">Principles of remote sensing</a> <br></li><li>  <a href="http://gisgeography.com/open-source-remote-sensing-software-packages/">Open Source Remote Sensing Software</a> <br></li><li>  <a href="http://speclab.cr.usgs.gov/spectral.lib04/spectral-lib04.html">Clean Materials Library</a> <br></li><li>  <a href="http://www.samspace.ru/download.php%3Ffile%3D/upload/iblock/7f4/Resurs-P2_NK2015-02.pdf">Resource-P</a> <br></li><li>  <a href="http://gis-lab.info/projects/osm-export.html">Data OpenStreetMap by region of the Russian Federation in the formats and OSM XML</a> <br></li><li>  <a href="http://planet.osm.org/pbf/">Planet.osm</a> <br></li><li>  <a href="http://kaiminghe.com/publications/cvpr09.pdf">Single Image Haze Removal Using Dark Channel Prior</a> <br></li><li>  <a href="https://sovzond.ru/upload/iblock/220/22023bebc2f71b0a4a8626911a00ba08.pdf">Practical application of key-point methods on the example of comparing images from the Kanopus-V satellite</a> <br></li><li>  <a href="http://geomatica.ru/clauses/283/">Investigation of the geometric accuracy of WorldView-2 orthos, created using the SRTM digital terrain model</a> <br></li></ol></li></ul><br></div></div></div><p>Source: <a href="https://habr.com/ru/post/342028/">https://habr.com/ru/post/342028/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../342018/index.html">Static code analyzers on the example of ClickHouse</a></li>
<li><a href="../342020/index.html">Basic installation and configuration of Puppet 4 with storage of manifests in SVN</a></li>
<li><a href="../342022/index.html">Clouds from an unknown country. Cloud FAQ</a></li>
<li><a href="../342024/index.html">Overview of the new version of Infobox hosting</a></li>
<li><a href="../342026/index.html">How black SEO-optimizers collect millions of visitors on highly relevant queries in Yandex</a></li>
<li><a href="../342030/index.html">Work with API KOMPAS-3D ‚Üí Lesson 5 ‚Üí Graphic primitives</a></li>
<li><a href="../342032/index.html">Using the KOMPAS-3D API ‚Üí Lesson 6 ‚Üí Construction of a circular arc</a></li>
<li><a href="../342036/index.html">How to build a community. Translation of the book "Social Architecture": Chapter 6. Living Systems</a></li>
<li><a href="../342038/index.html">Detecting dependencies of Android components</a></li>
<li><a href="../342040/index.html">What should be the size of a thread pool?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>