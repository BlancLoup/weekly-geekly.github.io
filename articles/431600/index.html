<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Raise IDS / NMS: Mikrotik and Suricata with a web-interface</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Apparently, I have such a karma: no matter how I undertake the implementation of any service on the open source, I will definitely find a bunch of man...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Raise IDS / NMS: Mikrotik and Suricata with a web-interface</h1><div class="post__text post__text-html js-mediator-article">  Apparently, I have such a karma: no matter how I undertake the implementation of any service on the open source, I will definitely find a bunch of manuals, each individually in my particular case will not work, the ready solution will not start or dislike it, what else will happen somebody is indigestible, and as a result you have to make your own way to the result. <br><br>  This time all the manuals were on ELK5 or even older, but I didn‚Äôt really like to install the software of the previous versions.  I wanted to take a software with the most promising terms of support: preferably the freshest of stable ones. <br><br>  As a result, in order to continue to be able to repeat the perfect feat without repeating all the torment, you have to write such step-by-step cheat sheets, which I share with you. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      So, today Mikrotik (RouterOS), Suricata 4.1, Elasticsearch + Filebeat + Kibana 6.5. <br><a name="habracut"></a><br><h3>  Instead of intro </h3><br>  Conditions: <br><br><ul><li>  Mikrotik on i386 in a virtual machine on host A. All interfaces on Mikrotik are scattered across VLANs, the host has one physical network interface. </li><li>  Available resources for IDS / IPS / NMS on host B with a single physical network interface. </li><li>  20 megabyte channel out. </li><li>  The desire to receive analytics about traffic passing through the Mikrotik interface. </li><li>  The budget in hell rubles and FIG kopeks. </li><li>  Some hassle free time. </li></ul><br>  I will not tell you here what IDS / IPS / NMS is, why it is needed and how it happens.  Everyone knows this without me, but whoever does not know will naguglit. <br><br>  Also, I will not justify my choice between Snort and Suricata in favor of the latter.  It's a matter of taste. <br><br>  But I will superficially explain how this works: <br><br>  Suricata somehow gets traffic.  There are three options: a) pass it through itself in inline-mode, b) receive a copy of the traffic from the switch port and c) analyze the dumps with traffic.  The resulting traffic Suricata analyzes and on the basis of the analysis gives data about what she found there in this traffic. <br><br>  Suricata data can be issued in JSON.  Accordingly, having structured data, they can be fed to any system for processing, systematization, analysis and visualization. <br>  For the analysis and visualization of data, as I understand it, not being an expert in this field, ELK-stack is perfect.  ELK-stack originally consisted of Elasticsearch, Logstash, Kibana.  Now Beat has been added to it (a family of program interfaces that act as an intermediary between the data source and Logstash or Elasticsearch).  Looking ahead, I will say that there was no Logstash, because the Beat gives the data directly to Elasticsearch perfectly, and Elasticsearch eats it perfectly.  Elasticsearch transfers the data to Kibana, the web interface for the entire ELK stack.  Kibana, using the templates transferred to it by Filebeat, provides the user with a visualization of the data, the so-called Dashboards.  Considering the fact that Elasticsearch, Logstash, Beat and Kibana is the fruit of the work of one producer, this whole economy is well connected with each other, and the process of binding is well documented (of course, by open-source measures). <br><br>  Thus, based on the above, the task can be described as follows: get a copy of the traffic from the router port, transfer it to Suricata, receive JSON-formatted data from Suricata, transfer it to Filebeat so that the latter in turn sends it to Elasticsearch and helped Kibana create their visual display. <br><br><h3>  Mikrotik RouterOS </h3><br>  If I had a hardware Mikrotik router, then the question of port mirroring would not be at all.  Everything would be decided by including traffic mirroring through the external interface to any free port of Mikrotik itself.  If there were no free port on Mikrotik, it would be possible to enable port mirroring on the switch.  But in my case, Mikrotik had no physical ports at all, and the port on the switch received traffic from the entire host, on which, besides Mikrotik, there were several other virtual machines. <br><br>  And then I once again mentally said: "Thank you, Mikrotik!".  Thanks for the sniffer built into RouterOS.  By tradition, we manage without screenshots, only console commands. <br><br>  Open the terminal in WinBox and turn on the sniffer: <br><br> <code>/tool sniffer set filter-interface=if-out filter-stream=yes streaming-enabled=yes streaming-server=192.168.1.253 <br> /tool sniffer start</code> <br> <br>  Instead of <i>if-out,</i> specify the name of the interface from which you plan to intercept traffic, and instead of <i>192.168.1.253</i> , <a href="https://en.wikipedia.org/wiki/TZSP">specify the</a> IP address of the machine to which intercepted traffic will be sent via the <a href="https://en.wikipedia.org/wiki/TZSP">TZSP</a> protocol. <br><br>  With Mikrotik'om everything. <br><br><h3>  Suricata </h3><br>  In general, I am not very Linux-headed, so I like pop distros most of all.  Well, except that I like the more ascetic Debian more.  That started with him.  Well, of course, by virtue of non-linear headaches, I wanted to put the binaries from the repository as well.  Build is always lazy for me.  So, if it is possible to choose Debian, <u>do not choose</u> .  Now I don‚Äôt remember exactly where I had a plug in the installation of the entire farm under Debian, but it was.  And the whole further story about installing everything under Ubunta. <br><br>  A 4-core virtual machine with 4 gigs of RAM was created, <a href="">Ubuntu Server 18.04.1 LTS (x64) was</a> downloaded and installed on it <br><br><blockquote>  <b>Agreement</b> : all further actions are performed on behalf of the superuser, so either log in as root, or add <i>sudo</i> to each command. </blockquote><br>  Since at each stage I made snapshots, and then repeatedly rolled back to them, at the end I lit up pretty glitches with an out of time sync in a virtual machine with real time. <br>  Therefore, we immediately set the correct time zone and NTP synchronization: <br><br> <code>systemctl start systemd-timesyncd <br> systemctl status systemd-timesyncd <br> dpkg-reconfigure tzdata</code> <br> <br>  To ensure that there are no dependency problems during the installation of Suricata, we add <i>universe</i> repositories in <i><b>/etc/apt/sources.list</b></i> : <br><br> <code>nano /etc/apt/sources.list</code> <br> <blockquote>  ... <br>  deb <a href="http://archive.ubuntu.com/ubuntu/">archive.ubuntu.com/ubuntu</a> bionic main universe <br>  deb <a href="http://archive.ubuntu.com/ubuntu/">archive.ubuntu.com/ubuntu</a> bionic-security main universe <br>  deb <a href="http://archive.ubuntu.com/ubuntu/">archive.ubuntu.com/ubuntu</a> bionic-updates main universe </blockquote><br>  We also add a repository, from where we will take Suricata: <br> <code>add-apt-repository ppa:oisf/suricata-stable</code> <br> <br>  Updating the package database: <br> <code>apt-get update</code> <br> <br>  Install Suricata: <br> <code>apt-get install -y suricata</code> <br> <br>  The next step is to set up the rules for Suricata and their update: <br> <code>apt-get install -y python-pip <br> pip install pyyaml <br> pip install https://github.com/OISF/suricata-update/archive/master.zip</code> <br> <br>  Run the update itself <i>suricata-update</i> : <br> <code>pip install --pre --upgrade suricata-update</code> <br> <br>  Running without additional configuration will give us Emerging Threats Open ruleset: <br> <code>suricata-update</code> <br> <br>  To view the list of sources, perform: <br> <code>suricata-update list-sources</code> <br> <br>  Update rule sources: <br> <code>suricata-update update-sources</code> <br> <br>  Let's see what was updated there in the sources, let's re-execute: <br> <code>suricata-update list-sources</code> <br> <br>  We include all free sources: <br> <code>suricata-update enable-source ptresearch/attackdetection <br> suricata-update enable-source oisf/trafficid <br> suricata-update enable-source sslbl/ssl-fp-blacklist</code> <br> <br>  And once again we update the rules: <br> <code>suricata-update</code> <br> <br>  Suricata is installed. <br><br>  Now you need to get traffic. <br><br><h3>  Trafr </h3><br>  Trafr is an application written by Mikrotik to convert TZSP traffic to pcap.  The application is 32-bit, so to start it you will need to enable support for 32-bit applications in 64-bit Ubunta: <br><br> <code>dpkg --add-architecture i386 <br> apt-get update &amp;&amp; apt-get install -y libc6:i386</code> <br> <br>  Download and unpack <i><b>trafr</b></i> : <br><br> <code>wget http://www.mikrotik.com/download/trafr.tgz <br> tar xzf trafr.tgz</code> <br> <br>  Check that traffic is caught: <br><br> <code>./trafr -s</code> <br> <br>  After such a launch, the symbolic output in graphics mode broke in the virtual machine console, I had to reboot.  When connecting remotely via ssh to PuTTY, there were no problems. <br><br>  If you see random flickering on the screen, then the traffic arrives, and <i><b>trafr</b></i> catches it.  If so, we transfer the <i><b>trafr</b></i> to the permanent residence and start it with the transfer of the caught traffic through the pipeline immediately to Suricata: <br><br> <code>mv trafr /usr/local/bin/ <br> /usr/local/bin/trafr -s | suricata -c /etc/suricata/suricata.yaml -r /dev/stdin <br></code> <br><br>  Now we check that the traffic goes to Suricata, for this we perform in the next terminal: <br><br> <code>tail -f /var/log/suricata/fast.log</code> <br> <br>  You should see a smart scrolling of meaningful text - a log of receiving meerkat traffic. <br><br>  It is also useful to make sure that Suricata not only receives traffic, but also analyzes: <br><br> <code>tail -f /var/log/suricata/eve.json</code> <br> <br>  This is exactly the same event output from Suricata in JSON format, which we will feed to Filebeat. <br><br><h3>  Elasticsearch + Filebeat + Kibana 6.5 </h3><br>  Install the PGP key required for using the Elastic repository and install the necessary dependencies: <br><br> <code>wget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo apt-key add - <br> echo "deb https://artifacts.elastic.co/packages/6.x/apt stable main" | sudo tee -a /etc/apt/sources.list.d/elastic-6.x.list <br> apt-get update &amp;&amp; apt-get install -y openjdk-8-jre apt-transport-https wget nginx</code> <br> <br>  Please note that Java version 8. Everything above 8 is not supported.  Therefore, if you have previously managed to install more recent Java, demolish it and put 8. <br><br>  Make sure that Java is installed as it should: <br><br> <code>java -version</code> <br> <br>  We get about the following conclusion: <br><blockquote>  java version "1.8.0_191" <br>  Java (TM) SE Runtime Environment (build 1.8.0_191-b12) <br>  Java HotSpot (TM) 64-Bit VM Server (build 25.191-b12, mixed mode) </blockquote><br>  Create a username and password to access Kibana.  Instead of <i>admin,</i> choose something that you prefer: <br><br> <code>echo "admin:`openssl passwd -apr1`" | sudo tee -a /etc/nginx/htpasswd.users</code> <br> <br>  Since ELK will run on localhost, configure the reverse proxy in nginx: <br><br> <code>nano /etc/nginx/sites-available/kibana</code> <br> <blockquote>  server { <br>  listen 80; <br><br>  server_name suricata.server; <br><br>  auth_basic "Restricted Access"; <br>  auth_basic_user_file /etc/nginx/htpasswd.users; <br><br>  location / { <br>  proxy_pass <a href="http://localhost/">localhost</a> : 5601; <br>  proxy_http_version 1.1; <br>  proxy_set_header Upgrade $ http_upgrade; <br>  proxy_set_header Connection 'upgrade'; <br>  proxy_set_header Host $ host; <br>  proxy_cache_bypass $ http_upgrade; <br>  } <br>  } </blockquote><br> <code>rm /etc/nginx/sites-enabled/default <br> ln -s /etc/nginx/sites-available/kibana /etc/nginx/sites-enabled/kibana <br></code> <br><br>  Restart nginx: <br><br> <code>systemctl restart nginx</code> <br> <br>  We put Elasticsearch: <br><br> <code>apt-get install -y elasticsearch</code> <br> <br>  Enable autorun when booting the OS: <br><br> <code>systemctl daemon-reload <br> systemctl enable elasticsearch.service</code> <br> <br>  Run: <br><br> <code>systemctl start elasticsearch.service</code> <br> <br>  We check whether: <br><br> <code>curl -X GET "localhost:9200/"</code> <br> <br>  Depending on the performance of your piece of hardware, running ES can take some time.  If we get <i>connection refused</i> , then we simply repeat the request and wait until we get something like a response: <br><blockquote>  { <br>  "Name": "lcZuxxm", <br>  "Cluster_name": "elasticsearch", <br>  "Cluster_uuid": "kmJHqJnlQe2Rk7F-CRi4EA", <br>  "Version": { <br>  "Number": "6.5.1", <br>  "Build_flavor": "default", <br>  "Build_type": "deb", <br>  "Build_hash": "8c58350", <br>  "Build_date": "2018-11-16T02: 22: 42.182257Z", <br>  "Build_snapshot": false, <br>  "Lucene_version": "7.5.0", <br>  "Minimum_wire_compatibility_version": "5.6.0", <br>  "Minimum_index_compatibility_version": "5.0.0" <br>  }, <br>  "Tagline": "You Know, for Search" <br>  } </blockquote><br>  We put Kibana: <br><br> <code>apt-get install -y kibana</code> <br> <br>  Enable autorun when booting the OS: <br><br> <code>systemctl daemon-reload <br> systemctl enable kibana.service</code> <br> <br>  Run: <br><br> <code>systemctl start kibana.service</code> <br> <br>  Now you can go to <a href="http://192.168.1.253/">192.168.1.253</a> (of course, the IP address is the one that was assigned to your car with meerkats).  The Kibana title page should open. <br><br>  We put Filebeat: <br><br> <code>apt-get install -y filebeat</code> <br> <br>  Enable autorun when booting the OS: <br><br> <code>systemctl daemon-reload <br> systemctl enable filebeat</code> <br> <br>  We include the Suricata module included in the Filebeat module set: <br><br> <code>filebeat modules enable suricata</code> <br> <br>  Install the Suricata plugins in Elasticsearch: <br><br> <code>/usr/share/elasticsearch/bin/elasticsearch-plugin install ingest-geoip <br> /usr/share/elasticsearch/bin/elasticsearch-plugin install ingest-user-agent</code> <br> <br>  Restart Elasticsearch: <br><br> <code>systemctl restart elasticsearch.service</code> <br> <br>  Perform the initial configuration of Filebeat, at the same time loading the templates in Kibana: <br><br> <code>filebeat setup -e</code> <br> <br>  We check that Filebeat found <i>/var/log/suricata/eve.json</i> and processes it. To do this, we start Filebeat in the mode of displaying data with the <i>publish</i> marker: <br><br> <code>filebeat -e -d "publish"</code> <br> <br>  The first is the json-formatted output of Filebeat itself, then the simple text output of its logs, and only after some time the output from Suricata, so wait and make sure that everything works.  After that, interrupt Filebeat and return to bash. <br><br>  Enable autorun when booting the OS: <br><br> <code>systemctl daemon-reload <br> systemctl enable filebeat.service</code> <br> <br>  Launch Filebeat: <br><br> <code>systemctl start filebeat.service</code> <br> <br>  Go to Kibana, select the Dashboard in the menu on the left, select the <i><b>filebeat- *</b></i> index.  Select Dashboard again, select <b>[Suricata] Alert Overview</b> from the list and should get something like this: <br><br><img src="https://habrastorage.org/webt/tb/5v/st/tb5vsthdvuyveyetcbba1p_asts.png" alt="image"><br><br><h3>  Optional </h3><br>  Do not forget the logrotate, and not that no matter how capacious the hard drive, Suricata will score it very quickly: <br><br> <code>nano /etc/logrotate.d/suricata</code> <br> <blockquote>  /var/log/suricata/*.log /var/log/suricata/*.json <br>  { <br>  weekly <br>  rotate 3 <br>  missingok <br>  nocompress <br>  create <br>  sharedscripts <br>  postrotate <br>  / bin / kill -HUP `cat /var/run/suricata.pid 2&gt; / dev / null` 2&gt; / dev / null ||  true <br>  endscript <br>  } <br></blockquote><br>  In addition, there were rumors that someone regularly has a sniffer in Mikrotik with the status of <i>running and</i> stops sending traffic.  Then we write a script to restart the sniffer and run it on a schedule: <br><br> <code>/tool sniffer stop <br> :delay 30s <br> /tool sniffer start</code> <br> <br><h3>  Conclusion </h3><br>  Frankly, I'm not quite happy with the stability of the above bundle.  Namely: it is worth rebooting, and miracles begin.  Once I stopped processing all the rules except the pair.  I had to reinstall everything.  The second time Elasticsearch stopped receiving data from Filebeat at all, and had to roll back to the snapshot state before rebooting. <br><br>  These problems have not yet decided. <br><br>  In addition, plans to implement IPS on the basis of IP-addresses of villains identified by Suricata transferred to Mikrotik. <br><br>  <b>UPD</b> : Accusations of instability are removed.  My conclusion about stopping rule processing was erroneous.  In fact, the reason for the emptiness in Dashboard after a reboot is due to the fact that Filebeat and Elasticsearch take quite a lot of time to parse a multi-gigabyte json file from meerkats.  If you open the Dashboard with events for the period, which includes the date of creation of the <i>eve.json</i> file, you can see how the columns of the chart grow as the file is processed.  Along with the processed events, alerts appear in the corresponding Dashboard.  In addition, the sniffer in RouterOS on x86 did not hang even once. </div><p>Source: <a href="https://habr.com/ru/post/431600/">https://habr.com/ru/post/431600/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../431586/index.html">How to handle errors on JVM faster</a></li>
<li><a href="../431588/index.html">The law on self-employed. Information for consideration</a></li>
<li><a href="../431590/index.html">Modernization of obsolete UK wind farms will increase energy generation by 171%</a></li>
<li><a href="../431596/index.html">Load Testing Veeam Backup & Replication</a></li>
<li><a href="../431598/index.html">We bring to the Internet a public QEMU virtual machine without a network card and try to mine</a></li>
<li><a href="../431602/index.html">Russian developers presented a virtual rehabilitation system in London</a></li>
<li><a href="../431604/index.html">Localization in Go using basic packages</a></li>
<li><a href="../431608/index.html">The American company DriveSavers first in the world launched the service of hacking iPhone for individuals</a></li>
<li><a href="../431612/index.html">Musical box and rotary encoder on FPGA board</a></li>
<li><a href="../431614/index.html">Creating Art with DCGAN on Keras</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>