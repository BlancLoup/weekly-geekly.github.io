<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Pedestrian Detection</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Pedestrian detection is mainly used in research on unmanned vehicles. The general purpose of detecting pedestrians is to prevent a car from colliding ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Pedestrian Detection</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/storage/habraeffect/de/c6/dec6fa358837e748210e2f03937af83a.png" align="left">  Pedestrian detection is mainly used in research on unmanned vehicles.  The general purpose of detecting pedestrians is to prevent a car from colliding with a person.  On Habr√© recently there was a topic about " <a href="http://habrahabr.ru/blogs/robot/99914/">smart machines</a> ".  The creation of such systems is a very popular area of ‚Äã‚Äãresearch ( <a href="http://en.wikipedia.org/wiki/DARPA_Grand_Challenge">Darpa challenge</a> ).  I am engaged in the recognition of pedestrians for a similar project of intelligent cars.  Obviously, the problem of detecting pedestrians is software, and collision avoidance is hardware.  In this article I will only mention the program part, briefly describe one method of detecting people in an image and a classification algorithm. <br><a name="habracut"></a><br><h1>  Introduction </h1><br>  In my work I use two sensors: an infrared camera and a <a href="http://ru.wikipedia.org/w/index.php%3Ftitle%3D%25D0%259B%25D0%25B8%25D0%25B4%25D0%25B0%25D1%2580%26oldid%3D26475677">lidar</a> .  The temperature of the human body is usually above the environment.  Therefore, the image from the infrared camera of a person can be easily localized.  As a rule, it is easy to detect the unclosed parts of the body: the head and hands.  But with the help of the camera alone it is difficult to determine the size of the object, it is difficult to say how far a person is from the camera.  This is where a lidar comes in.  It measures the distance to objects. <br><br>  Why do we need a lidar?  Let's look at our pictures for a start.  The whole idea of ‚Äã‚Äãpreprocessing an image comes down to localizing areas of interest.  We do not care what the whole image is.  We want to highlight several areas and work further with them.  Ideally, the area of ‚Äã‚Äãinterest should encompass images of a person entirely.  Knowing that the head of a person is warmer than the environment, we easily find it in the image.  Next we need to estimate the size of a person.  This is where the data from the lidar come to the rescue.  Knowing the distance to the object, the focal length of the camera, the size of the object in the coordinates of the real world, it is easy to calculate the size of the object in pixels.  We determined the size of the object in real-world coordinates equal to a 2 by 1 meter rectangle in the confidence that the average person fits into such a rectangle.  But in the coordinate system, the images of the region of interest are still of different sizes.  Another scale transformation and finally all areas of interest not only cover the same area of ‚Äã‚Äãthe real world, but also have the same dimensions in pixels. <br><br>  Let us consider how to combine the data of two sensors: we find the hot area in the image (we assume that this is the human head), calculate the angle at which the center of this area is located, we reduce this angle to the lidar coordinate system and get the distance to the object from this angle.  To transfer the angle from one coordinate system to another, the sensors must be calibrated.  Instead of the present calibration of sensors, their specific location is used, at which the centers of the sensors coincide in the horizontal plane: <br><img src="https://habrastorage.org/storage/habraeffect/83/1e/831e17e399e2bba4d422d78aa609b09b.png">
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      <em>Of course, on a test machine, things are a little different.</em>  <em>First, the figure below shows the location of static sensors: their position does not change with time.</em>  <em>Secondly, our test machine uses a different type of lidar - three-dimensional.</em>  <em>It is installed in the middle of the roof of the car.</em>  <em>The camera is installed in front of the roof.</em>  <em>Thus, the centers of the sensors can no longer be considered to be at one point.</em>  <em>I see two options for solving this problem: in parallel, transfer data from the coordinate system of one sensor to the coordinate system of another sensor (after measuring the distance between them), or (automatically) calibrate the sensors.</em> <br><br><h1>  Extracting areas of interest </h1><br><br>  Extracting features that are used for pattern recognition, and their classification takes a lot of time.  Processing one frame with 6‚Äì7 objects in Matlab can take a full minute.  For real-time oriented systems, such long processing is unacceptable.  The speed is strongly influenced by the number of warm objects detected, and the person is not the only warm object.  Parts of cars, windows, traffic lights can also stand out against the general temperature background.  In this paper, the emphasis is on the speed of information processing.  We need to quickly weed out a maximum of objects that are definitely not human.  It is advisable not to miss a single real person.  All remaining objects can then be classified using the full static classifier. <br><br>  Hot areas in the image are detected using a method called ‚ÄúMaximum Stable Extreme Areas‚Äù (MCPU from the English. Maximally Stable Extremal Regions [1]).  The original image is processed by a threshold function with a variable threshold value.  The result is a new image sequence, the size of which corresponds to the number of different threshold values ‚Äã‚Äã(for example, for a monochrome image with pixel values ‚Äã‚Äãfrom 0 to 255, we obtain 256 images).  The first image in the sequence will be completely white.  Black areas will appear next and the latest image in the sequence will be completely black.  The figure below shows this sequence in the form of animation: <br><img alt="Image sequence created using threshold function" src="https://habrastorage.org/storage/habraeffect/2a/7f/2a7f6899e16b4823f955e99241cef93a.gif"><br><br>  The white areas in the image are areas of extremum.  We can analyze how long this or that area of ‚Äã‚Äãextremum is present in the sequence of images.  To do this, you can use another threshold function.  For example, with a value of 10. If an extremum region is present on more than 10 sequence images, then this region is called the most stable extremum region. <br><br>  Having found the most stable areas of interest, we can filter them a little more: check the aspect ratio, discard objects far from the camera, process the overlapping areas. <br><table cellspacing="12"><tbody><tr><td><img src="https://habrastorage.org/storage/habraeffect/1c/83/1c8344837707510286fbc6d1eaaff776.jpg"><br>  Source image </td><td><img src="https://habrastorage.org/storage/habraeffect/89/99/89999f590add9223cd9aab30fafa7367.jpg"><br>  Maximum stable extremum areas </td></tr><tr><td><img src="https://habrastorage.org/storage/habraeffect/f8/1e/f81e753ba01f72e48c1065f2d2a6c88c.png"><br>  Areas of interest </td><td><img src="https://habrastorage.org/storage/habraeffect/1c/55/1c55307acdf10ac89821e8b470c44c71.png"><br>  Filtered areas of interest </td></tr></tbody></table><br><br><h1>  Dispersion </h1><br><br>  As a metric for the classification of objects used "dispersion" [2].  The calculation of this metric takes little time and, moreover, its value is invariant to the lighting conditions.  It is considered according to the formula <img src="https://habrastorage.org/getpro/habr/post_images/ece/a0f/324/ecea0f324bd7a2171a370cd3ff4f0b44.png" title="Dispersedness = \ frac {Perimiter ^ 2} {Square}">  .  In the original paper, the variance is calculated by the contour of the object.  To obtain the contour from the areas of interest, the Gauss filter and the Sobel operator are applied successively.  The decision on whether an image belongs to a particular class is made using a threshold function.  Images of people have a lower dispersion value than images of machine parts or buildings. <br><br><img src="https://habrastorage.org/storage/habraeffect/51/9d/519d63afd8293b1dc5bb536a3fec6195.png"><br><br><h1>  Conclusion </h1><br><br>  The results of the algorithm in pictures: <br><table cellspacing="1"><tbody><tr><td><img src="https://habrastorage.org/storage/habraeffect/4d/84/4d84e8da39a1cba7433ca9c8012181e1.jpg"></td><td><img src="https://habrastorage.org/storage/habraeffect/75/21/7521cc57c13268a4df45c160de91ad5b.jpg"></td></tr><tr><td><img src="https://habrastorage.org/storage/habraeffect/cb/94/cb9466c93442291ea23ac982e3f8b3a7.jpg"></td><td><img src="https://habrastorage.org/storage/habraeffect/19/f4/19f4d9be23c67932822b1209eb3cac49.jpg"></td></tr></tbody></table><br><br>  The test computer is equipped with an Intel Core 2 Duo processor with a frequency of 3 GHz, 6 MB cache, 2 GB RAM.  Tests were conducted in the system Matlab.  The average processing time per frame is 64 ms.  This means that in 1 second the system will be able to process approximately 16 frames.  This, of course, is better than 1 frame per minute. <br><br>  The following questions naturally arise: how reliable is the variance for classification, how will the time spent working on one frame increase when using a full-fledged classifier.  I have no answers to these questions yet.  Now I am working on it.  There will be results - I will inform you! <br><br><h1>  Literature </h1><br>  [1] J. Matas, O. Chum, M. Urban, and T. Pajdla, ‚ÄúRobust wide baseline stereo from maximally stable extremal regions,‚Äù in British Machine Vision Conference, 2002, pp.  384‚Äì396. <br>  [2] AL Hironobu, AJ Lipton, H. Fujiyoshi, and RS Patil, ‚ÄúMoving Target Classification and Tracking From Real-Time Video,‚Äù in Applications of Computer Vision, 1998. WACV '98.  Proceedings., Fourth IEEE Workshop on, October 1998, pp.  8‚Äì14. </div><p>Source: <a href="https://habr.com/ru/post/100820/">https://habr.com/ru/post/100820/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../100810/index.html">Application falsely accused of data theft</a></li>
<li><a href="../100812/index.html">Do I need a php new logo?</a></li>
<li><a href="../100813/index.html">Installing java applications on a Samsung phone in Ubuntu</a></li>
<li><a href="../100815/index.html">Wireless video: built-in wireless video cards</a></li>
<li><a href="../100816/index.html">Habrahabr application for iPhone</a></li>
<li><a href="../100821/index.html">Microblog about the use of English words</a></li>
<li><a href="../100822/index.html">WCG 2010 Belarus - Semifinal</a></li>
<li><a href="../100823/index.html">Microsoft Exchange Server 2010 SP1 protocol specifications published</a></li>
<li><a href="../100824/index.html">Eureka and euphoria: About scientists and their discoveries</a></li>
<li><a href="../100825/index.html">Bing Maps integrates with OpenStreetMap</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>