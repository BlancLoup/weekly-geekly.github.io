<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Deephack: hackathon for deep learning with reinforcements, or how we improved the Google Deepmind algorithm</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="From July 19 to July 25, the Deephack hackathon took place, where participants improved the learning algorithm with reinforcements based on Google Dee...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Deephack: hackathon for deep learning with reinforcements, or how we improved the Google Deepmind algorithm</h1><div class="post__text post__text-html js-mediator-article">  From July 19 to July 25, the <a href="http://deephack.me/">Deephack</a> hackathon took place, where participants improved the learning algorithm with reinforcements based on Google Deepmind.  The goal of the hackathon is to learn how to better play the classic Atari games (Space Invaders, Breakout, etc.).  We want to tell why this is important and how it was. <br><br>  Authors of the article: Ivan Lobov <a href="http://habrahabr.ru/users/ivanlobov/" class="user_link">IvanLobov</a> , Konstantin Kiselev <a href="http://habrahabr.ru/users/mrkonstantin/" class="user_link">mrKonstantin</a> , Georgy Ovchinnikov <a href="http://habrahabr.ru/users/ovchinnikoff/" class="user_link">ovchinnikoff</a> . <br>  Photos of the event: Maria Molokova, Polytechnic Museum. <br><br>  Why a reinforcement training hackathon is cool: <br><ul><li>  This is the first Russian hackathon using deep learning and reinforcement learning; </li><li>  Google's Deepmind Algorithm is one of the latest advances in reinforcement learning; </li><li>  If you are interested in artificial intelligence, then this topic is very close to this concept (although we ourselves would not like to call it AI). </li></ul><br><img src="https://habrastorage.org/files/65d/7a7/969/65d7a7969f204cedab1a6d54427fdc4b.png"><br><a name="habracut"></a><br><h1>  Where does the interest in learning research with reinforcement come from? </h1><br>  To begin with, the state of machine learning is now and what can be solved with it.  There are 3 main areas (intentionally simplified): <br><ul><li>  Teaching with a teacher is any task where the algorithm is trained using examples: gave the answer ‚Äî got the result.  This includes regressions and classifications.  Tasks from the real world: assess the value of real estate, predict sales, predict earthquakes; </li><li>  Teaching without a teacher is a task without ‚Äúanswers‚Äù, where you need to find patterns in the data, find ‚Äúsimilarity‚Äù or ‚Äúdissimilarity‚Äù.  Tasks from the real world: consumer clustering, search for association rules; </li><li>  Reinforcement learning is an intermediate type of task when learning occurs when interacting with an environment.  The algorithm (agent) performs actions in the environment and sometimes receives feedback.  Many ‚Äúinteresting‚Äù human activities fall under this class of tasks: sports competitions (every second of time you do not have the ‚Äúright‚Äù action, there is only a result - a goal is scored or not), negotiations, the process of scientific research, etc. </li></ul><br>  So, the tasks of training with a teacher have already been solved for almost all areas.  However, the next big step is the areas of machine learning, where there is no obvious and instant result of interaction.  <a href="http://spectrum.ieee.org/automaton/robotics/artificial-intelligence/facebook-ai-director-yann-lecun-on-deep-learning">It is in this direction that the field of machine learning is moving now.</a> 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h1>  How the reinforcement learning algorithms work using the example of Atari games (intuition) </h1><br>  There is an agent and environment - the game.  For an agent, the game looks like a black box - he does not know its rules and does not realize that this is a game at all.  At the start of training, the game gives the agent a set of actions (actions) that he can perform in it, while all actions for the agent look identical.  Then, at each step, the agent performs one of the actions and receives in response the state of the game (state) and points (reward).  The game state is a picture from the screen.  Points (reward) is a reward for actions performed, can be positive, negative or 0. During training, the agent chooses actions and tries them in the game, getting points.  The task of the agent is to develop a strategy that maximizes the final points. <br><br><img src="https://habrastorage.org/files/1a2/10f/8f6/1a210f8f60b844bf8555d2b6d75bc3fe.png"><br><br>  In fact, we imitate a person‚Äôs learning of the game (very rudely, since in fact we don‚Äôt know exactly how we are learning).  With some differences, for example: an adult already has a lot of experience and a wide class of associative concepts has been formed, which allows him to at a glance understand the rules of the game and quickly learn.  In our case, the agent's learning model is more like the learning of a 2-year-old child: first, he arbitrarily presses the control buttons and gradually, picking up the laws and principles of the game, he begins to play better and better. <br><br>  For training, a model is needed by which our algorithm approximates the rules of agent interaction with the environment.  One of the common techniques that DeepMind has successfully applied in Atari games is Q-learning.  This technique simulates the reward function Q. Next, when testing, the agent selects actions according to the rule: the action must maximize the reward function. <br><br>  As a model, there may be decision trees, multidimensional linear function, neural networks, etc.  When we deal with complex multidimensional data, such as pictures, convolutional neural networks have proven themselves well.  Deepmind Innovation - to combine convolutional networks and Q-learning. <br><br><h1>  What will the development of machine learning? </h1><br>  Now we manage to teach the computer to play simple games better than humans, which most people do not make a big impression.  The next step is to teach the computer to play, say in Doom, i.e.  make him learn in 3 dimensional environment.  Then gradually complicate the game.  The main task is to work out certain principles of finding optimal solutions for the tasks posed in complex environments and use these principles in the form of algorithms in the real world.  Thus, machines playing games can get an effective representation of their environment and use it to summarize past experience in new situations. <br><br><img src="https://habrastorage.org/files/116/b14/d70/116b14d702d44eca8f27b9fb764991a9.jpg"><br><br>  If you manage to force the computer to learn how to play, for example, Need For Speed, and learn how to play well, then the algorithms created with small modifications can be used in learning robots to drive real cars.  And not only the car ... It will allow you to come to the mass use of robots, ranging from personal assistants to smart self-service systems, smart urban environment in which cars under the supervision of a person independently serve the entire complex urban infrastructure. <br><br>  Now I understand why <a href="http://www.technologyreview.com/news/524026/is-google-cornering-the-market-on-deep-learning/">Google acquired Deepmind for more than $ 400 million.</a> <br><br><h1>  How did the hackathon go </h1><br>  The organizers prepared for the hackathon seriously: 7 full days with accommodation, competition for participation - 5 people per seat, lecturers from the top 10 researchers in the field of machine learning, 15 gpu-clusters, 24/7 support for participants on any issues.  Venue - MIPT campus in Dolgoprudny. <br><br>  Competition procedure: <br><ul><li>  Qualifying round (first 6 days) - who better learns to play <a href="http://www.youtube.com/watch%3Fv%3Dv_4XgpHOU14">Gopher</a> , <a href="http://www.youtube.com/watch%3Fv%3D4rMyUJi1AHU">Seaquest</a> and <a href="http://www.youtube.com/watch%3Fv%3D4FrFJoiC9Fo">Tutakham</a> .  Our team, Rockband, took 3rd place; </li><li> Finals - the Olympic system of 8 teams in 3 unknown games in advance ( <a href="http://www.youtube.com/watch%3Fv%3Dopru6qPsPa4">Space Invaders</a> , <a href="http://www.youtube.com/watch%3Fv%3DRWwfl1OUx40">Hero</a> , <a href="http://www.youtube.com/watch%3Fv%3D_AJCM-GFfrs">Kung-Fu Master</a> ). </li></ul><br><h1>  What did all this work?  (Soft) </h1><br>  Stella (Atari emulator) -&gt; <a href="https://github.com/mgbellemare/Arcade-Learning-Environment">ALE (Arcade Learning Environment)</a> -&gt; a machine learning framework to choose from. <br><br>  The basis of all decisions was taken open source Google Deepmind and <a href="http://www.nature.com/nature/journal/v518/n7540/full/nature14236.html">article 2015 in Nature</a> .  The teams solved the problem in one of the three ML frameworks: <a href="https://github.com/kuz/DeepMind-Atari-Deep-Q-Learner">Lua + Torch</a> (the original code is on it), <a href="https://github.com/spragunr/deep_q_rl">Python + Theano</a> or C ++ / Caffe.  We chose Python + Theano, since we had more experience in it.  We can not clearly identify the best framework, each had its own drawbacks.  In general, there is a feeling that the area is still fresh, so there is little proven and well-functioning code.  Much has to be rewritten, recheck and debug.  No significant advantages of one of the frameworks were found: neither in the speed of calculations (the narrow neck is still - the bundles in cuDNN), or in the convenience of prototyping. <br><br><h1>  What did all this work?  (Iron) </h1><br>  For calculations, each team was allocated a cluster with 4 GRID K520 on AWS (g2.8xlarge), so it was possible to run up to 4 calculations simultaneously.  This was enough to run a number of tests over the course of a week (a full test is trained on one GPU ~ 5 full days, however we drove short ten-hour tests), which helped to test the first hypotheses.  But it is not enough to conduct a full-fledged study, so some teams continue to develop their achievements after the end of the hackathon.  Although the question here is not so much in hardware as in real time. <br><br><h2>  Examples of how a model trained in 24 hours plays: </h2><br>  <a href="http://www.youtube.com/watch%3Ft%3D313%26v%3DzBbas_fVrVQ">Space invaders</a> <br>  <a href="http://www.youtube.com/watch%3Ft%3D221%26v%3DpDV4pjsaSFA">Kung fu master</a> <br><br><h1>  How was it (photo) </h1><br>  Still fresh, discuss ideas: <br><br><img src="https://habrastorage.org/files/dc1/f69/1a9/dc1f691a96ed44afb83cae4a493d9878.jpg"><br><br>  The first (?) Night right in coworking: <br><br><img src="https://habrastorage.org/files/0ff/b1f/1fc/0ffb1f1fc02e4b96bcb32cb50260e068.jpg"><br><br>  Despite the fatigue, everyone listens to lectures: <br><br><img src="https://habrastorage.org/files/193/72c/db5/19372cdb58d24d58941b52bfb47f71ad.jpg"><br><br>  Last days before the finals.  Some days almost without sleep.  Only the most persistent still work: <br><br><img src="https://habrastorage.org/files/3d9/4ac/d25/3d94acd252bd4ede9048b9adf254f7ec.jpg"><br><br>  Final at ENEA.  Everything has already been decided, it remains to root for the trained models: <br><br><img src="https://habrastorage.org/files/65a/514/d92/65a514d922014ffb8e06b060ad2f2a4b.jpg"><br><br>  Hackathon members: <br><br><img src="https://habrastorage.org/files/b3f/021/6c1/b3f0216c14854b5bbc7e5dbcf583ada1.jpg"><br><br><h1>  Instead of conclusion </h1><br>  We all have very different backgrounds - advertising, IT, science.  However, we are united by one thing - we see the future behind the development of machine learning and we understand that very few people in Russia do this: <br><ul><li>  Educational institutions - units with professors who publish something; </li><li>  Companies that really use something - enough for two hands to count.  And 3 fingers to recount those who use deep learning to scale; </li><li>  There are hundreds of specialists, maybe 1000 (?) People who can assemble a convolutional network. </li></ul><br>  At the same time, all knowledge, software and even hardware for deep learning are available to any student.  The level of entry into the area in terms of labor costs is also not off scale. <br><br>  Where I would like to move: <br><ul><li>  Popularization of ML opportunities among ordinary people; </li><li>  Popularization of ML and deep learning from students; </li><li>  Promotion of ML and deep learning in business; </li></ul><br>  If you have ideas or suggestions on how to do this, write in the comments. <br><br>  PS Thanks a lot to all the organizers, especially Evgeny Botvinovsky, Sergey Plis, Mikhail Burtsev, Andrei Pakosh, Elizaveta Chernyagina, Vitaly Lvovich Dunin-Barkovsky, Valeria Tsvela and others. </div><p>Source: <a href="https://habr.com/ru/post/264871/">https://habr.com/ru/post/264871/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../264861/index.html">How to replace jQuery with D3 in a project</a></li>
<li><a href="../264863/index.html">Exception catching and handling in Yii2</a></li>
<li><a href="../264865/index.html">Open source Java online chat server</a></li>
<li><a href="../264867/index.html">Finite models of reactions and shock forces in problems on the motion of systems with non-holding coupling</a></li>
<li><a href="../264869/index.html">Level Up for newbies: gulp and requirejs</a></li>
<li><a href="../264875/index.html">What do domain zone coordinators want?</a></li>
<li><a href="../264877/index.html">Yii environment. Inheritance and redefinition of configs</a></li>
<li><a href="../264881/index.html">Framework for validating data in iOS applications</a></li>
<li><a href="../264885/index.html">"Your privacy is very important to us." Read the Microsoft Privacy Statement</a></li>
<li><a href="../264891/index.html">Underground carders market. Translation of the book "Kingpin". Chapter 4. "The White Hat"</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>