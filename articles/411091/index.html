<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Data Center Technologies: General Information on QFX Switches</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="The article discusses the basic principles of networking in data centers, provides examples of hardware solutions from Juniper Networks. It does not c...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Data Center Technologies: General Information on QFX Switches</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/webt/f4/s5/z7/f4s5z7kllfw2x8i2yj_q8azb8w0.jpeg"><br><br>  The article discusses the basic principles of networking in data centers, provides examples of hardware solutions from Juniper Networks.  It does not carry a deep technical analysis, but it may be useful to those who are going to organize their first small data center, or are eyeing alternative solutions and new features in existing data centers. <br><a name="habracut"></a><br>  The topic of building communication networks in data processing centers is far from new today.  This direction is now in a stage of rapid development, which is justified by the ever-increasing needs for information storage, as well as the mass migration of services and technologies to the "cloud". <br><br>  In this regard, the requirements for data networks in the data center are increasing every day.  This forces humanity to develop new technologies for network management, traffic handling and equipment operation.  Optimize existing solutions, and of course reduce the burden on human resources, in order to eliminate errors associated with human factors. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      It was also important to change the direction of traffic in the data center - if earlier large traffic flows passed from the bottom up - vertically from servers to the outside world, now the situation is quite different, and now the servers communicate with each other, transferring large information flows to each other, which changed the proportions of volumes traffic in favor of "horizontal" exchange. <br><br>  In 1953, mathematician Charles Kloz, solved the problem of optimizing network connections for use in telegraph networks.  The connection method ‚Äúeach with each‚Äù was redundant and required a large amount of resources for implementation.  The idea of ‚Äã‚ÄãKlose was to build a network according to the scheme of three levels.  Entry - Intermediate - Exit.  In such a scheme, the number of physical connections sharply decreased, but the overall network performance was sufficient for operation. <br><br><img src="https://habrastorage.org/webt/ct/mh/gg/ctmhggpfq50gx60i2uvyozg_5js.jpeg"><br><br>  The same principle was taken as the basis for building data networks in the data center.  With a single change, the ‚Äúinput‚Äù and ‚Äúoutput‚Äù levels were combined into one, since the servers are both a source of information and its consumer.  In the end, we got a network connection scheme on the principle of Spine - Leaf. <br><br><img src="https://habrastorage.org/webt/hr/uw/wg/hruwwgrgvw7qtkd0jan9ishh0sy.gif"><br>  <i>Spine - Leaf network connection diagram</i> <br><br>  The scheme is constructed by analogy with plants in nature.  Leaf - Sheet.  The leaves are attached to the trunk.  Spine - the trunk (or ridge).  As a result, we get one common structure. <br><br>  Leaf.  Equipment access level where servers are connected in the data center.  These are the Top of Rack switches, with a high port density.  As you can see from the figure, all Leaf equipment is switched on in separate lines to each Spine level switch.  This allows you to achieve a high level of redundancy and fault tolerance. <br><br>  Spine.  ‚ÄúAggregation-level‚Äù equipment is usually high-performance equipment with a high port density of 25/40/50/100 Gbit / s.  A distinctive feature of this equipment is a wide range of supported functionality, and high performance compared with the level of Leaf. <br><br>  As a result, we get a scheme in which traffic flows through equipment at the Spine level.  This distribution of traffic flows may not seem optimal if both servers, the source and the receiver are connected to the same Leaf switch.  And this is correct, in which case the traffic passes directly through the Leaf switch without rising to a higher level. <br><br>  QFX is a series of switches for building data center networks. <br><br><img src="https://habrastorage.org/webt/ff/uf/fj/ffuffjsqxhbvwcorupaztzuuleq.jpeg"><br><br>  The abbreviation QFX does not have any logical meaning, so we will not go into the meaning of these three letters.  This equipment was developed and marketed by Juniper Networks, a leader in the design and manufacture of telecommunications equipment. <br><br>  Nowadays, any self-respecting manufacturer of telecommunications equipment, be it Cisco, Arista, Extreme or some others, is engaged in switching and routing issues in data centers. <br><br>  An interesting position is occupied by manufacturers of network software, which can be used in conjunction with equipment without pre-installed software, or directly on server platforms.  The development of this direction occurs in close cooperation with manufacturers of telecommunications equipment, creating new products and technologies. <br><br>  Returning to Juniper Networks QFX equipment.  The entire series was designed to meet the needs of data centers.  The software is written taking into account the necessary functionality, the hardware architecture takes into account the requirements for fault tolerance and redundancy. <br><br><img src="https://habrastorage.org/webt/ww/kc/yu/wwkcyupzbw37d0fqvxku25o-pvm.jpeg"><br><br>  The range of data center switches is represented by the following series: <br><br><ul><li>  QFX51xx series - Leaf level equipment. </li><li>  The QFX52xx series - equipment that can be used both at the Leaf level and at the Spine level. </li><li>  QFX10k series - equipment level Spine. </li></ul><br>  Depending on the series, the equipment is built on Broadcom chips, or on Juniper's own developments.  And he and the other option has its pros and cons. <br><br>  Consider the QFX51xx - an older model QFX5100, as well as an updated version of the QFX5110.  Both switches are based on Broadcom Trident 2+, but different versions.  As a result, we got not the same switch behavior at work, and, of course, different support for software functions, and port capacity.  As noted earlier, this equipment is positioned mainly as a Leaf-device.  It is possible to use the 51xx series as Spine devices in small data centers. <br><br>  QFX51xx supports AC / DC, AC / AC, DC / DC power supply redundancy. <br><br>  Software, equipment is built using virtualization mechanisms.  Unlike other series of company switches, Junos OS runs as a virtual machine under the KVM hypervisor that runs on the device.  Due to this, the solution supports software update technology - TISSU.  The upgrade process creates additional Junos OS virtual machines, and switches between them with minimal service interruptions. <br><br><img src="https://habrastorage.org/webt/ss/bd/b3/ssbdb3hpdypt98zxpu4ovwbfrxw.jpeg"><br><br>  The QFX5100 is built on an older version of the Trident 2+ chip and, in my humble opinion, is worthy of retirement, giving way to its older brother, QFX5110. <br><br>  QFX5100 is made in several versions: <br><br><ul><li>  QFX5100-48S - switch 48 ports SFP + 6 ports QSFP +. </li><li>  QFX5100-96S - switch 96 ports SFP + 8 ports QSFP +. </li><li>  QFX5100-24Q - switch 24 ports QSFP +. </li><li>  QFX5100-48T - switch 48 ports 10G BASE-T 6 ports QSFP +. </li></ul><br>  QFX5110 is a newer model in the 51xx series, built on an updated version of the Trident 2+ chip.  In my opinion, now this is the best available solution from Juniper to work as a Leaf-device. <br><br>  QFX5110 - a newer model in the 51xx series, built on an updated version of the Trident 2+ chip <br><br>  QFX5110 is made in several versions. <br><br><ul><li>  QFX5110-48S - switch 48 ports SFP + 4 ports QSFP28. </li><li>  QFX5110-32Q - 32 QSFP + port switch or 20 QSFP28 ports. </li></ul><br>  In general, it is possible to note a high port density of 10 Gbit / s for switching on terminal devices, and rather ‚Äúwide‚Äù uplink ports of 100 Gbit / s, which makes it possible to get the oversubscription level to uplink to ‚Äú1: 1.2‚Äù with a full 5110 switch. I think this is a good indicator. <br><br>  Small comparative table: <br><br><img src="https://habrastorage.org/webt/mp/qr/-s/mpqr-sefbd8tqy6boje9mssrj-q.png"><br><br>  Consider the QFX52xx series.  The equipment of this series is presented by two models QFX5200, and also QFX5210.  The entire series is built on the first generation Broadcom Tomahawk chip.  This imposes its own limitations on the functionality and performance of the solution.  The series is positioned as a spine device for small data centers, or as a Leaf device if you need to connect 25 Gbit / s terminal equipment. This is due to the high density of QSFP28 ports and the fact that the equipment is built on a commercial chip from Broadcom, with limited functionality. <br><br>  QFX52xx supports AC / DC, AC / AC, DC / DC power supply redundancy. <br><br>  All of the above about the operation of the software on the QFX51xx hardware is also true for the QFX52xx series.  The Junos OS operating system works the same way as a virtual machine, with the ability to conduct TISSU. <br><br>  The QFX5200 is represented by two models, the older QFX5200-32C, built on the Broadcom Tomahawk chip, and the newer model QFX5200-48Y, built on the Broadcom Tomahawk + chip: <br><br><ul><li>  QFX5200-32C - Switch 32 ports QSFP28. </li><li>  QFX5200-48Y - switch 48 ports SFP28 6 ports QSFP28. </li></ul><br>  QFX5210 is represented by one model, which is, in fact, two switches QFX5200-32C, which gives us the same restrictions. <br><br>  QFX5210-64C - Switch 64 ports QSFP28. <br><br>  In the end, we get a high port density of 100 Gbps for relatively little money, which makes this equipment a good Spine solution in small and medium data centers.  Also, I would like to note the moment that the equipment allows you to migrate the level of Leaf at a speed of 25 Gbit / s <br><br>  Let's move on to the QFX10k series.  The equipment of this series is built on Juniper's own development, the Q5 chip, with a capacity of 500 Gbit / s.  This chipset has the ability to connect external memory to store routing information RIB / FIB.  This allows you to build equipment of high performance and introduce new functionality as it appears on the market through software updates.  The QFX10k series switches are designed to meet all current market needs, for use in large data centers at the Spine level, as well as for building links between two geographically dispersed data centers - DCI - Data Center Interconnect. <br><br>  QFX10k switches are available in fixed and modular design. <br><br><img src="https://habrastorage.org/webt/an/vc/rn/anvcrnyv2cgvdllyprp_q1b5kyu.jpeg"><br><br>  QFX10002 is a 2RU fixed-size switch.  The series includes several models: <br><br><ul><li>  QFX10002-36 / 72Q switch supporting 36/72 QSFP + ports or 12/24 QSFP28 ports. </li><li>  QFX10002-60C switch with support for 60 QSFP28 ports. </li></ul><br>  QFX100xx is a modular switch.  These are large chassis with the ability to connect various types of line cards, providing support for various types of interfaces (SFP, SFP +, SFP28, QSFP +, QSFP28).  The equipment allows the use of redundancy components within a single chassis, such as control modules, line cards. <br><br>  The series includes a chassis with the ability to include 8 or 16 line cards. <br><br><img src="https://habrastorage.org/webt/f4/s5/z7/f4s5z7kllfw2x8i2yj_q8azb8w0.jpeg"><br><br>  Today, QFX10k equipment occupies a leading position in the ‚ÄúSpine-device‚Äù segment for data center networks.  Switches compete strongly with equipment from other manufacturers in this segment. <br><br>  All equipment supports NetConf remote configuration mechanisms, statistics and analytics collection using Junos Telemetry. <br><br>  In general, we conducted a review of the physical topology of building a network - in the best practice version - possible equipment from Juniper.  It should be noted that analogues of such switches are available from other equipment manufacturers.  Using our review, you can always choose what suits you best. <br><br>  In conclusion, I propose to consider the logical options for building communication networks in data centers. <br><br>  To date, I can distinguish two options for logical network construction: <br><br>  Based on private algorithms and work protocols. <br>  Based on open algorithms and work protocols. <br><br>  We are still considering the manufacturer Juniper Networks. <br><br>  In the first case, there are two main solutions for building networks in data centers: <br><br>  Virtual chassis fabric <br>  Junos fusion datacenter <br><br>  Virtual Chassis Fabric.  The solution is a development of Juniper's Virtual Chassis technology.  It uses the same principle of combining switches into one common chassis using an internal VCCP protocol.  VCCP is based on the open IS-IS protocol, and is a revised version of it.  As a result, the mechanism of the solution is hidden from the end user, and is left to the developers, which makes it difficult to solve any problems that occur during operation, but allows you to use the completed product. <br><br><ul><li>  Single point of control through the main switch. </li><li>  Spine - Leaf architecture support. </li><li>  The maximum number of devices is 20 (4 Spine and 16 Leaf). </li><li>  Maximum scaling up to 1536 access ports with 10 Gb / s support - FCoE in one factory. </li><li>  Junos Space control system. </li></ul><br>  Junos Fusion DataCenter.  The solution is a new product of the company, designed specifically for use in data centers.  Only QFX-51xx / 10k series switches are supported.  The solution is based on 802.1BR, netconf, json-rpc technologies.  A single logical structure with the ability to control from a single console.  The solution is being actively developed, and additional functionality is being introduced. <br><br><ul><li>  Based on IEEE802.1BR. </li><li>  Single point of control. </li><li>  Spine - Leaf technology support. </li><li>  The maximum number of devices is 65 pieces. </li><li>  Maximum scaling up to 6144 10 Gbit / s -FCoE ports in one factory. </li><li>  The ability to use 1 or 2 devices at the level of Spine. </li><li>  Spine level is represented by QFX10k switches. </li><li>  Leaf level is represented by switches QFX51xx. </li><li>  Support for local switching at Leaf level. </li><li>  Ability to auto-configure vlan on Leaf level ports. </li><li>  Junos Space control system. </li><li>  MC-LAG support. </li></ul><br>  In the case when the network is based on open algorithms and work protocols - only one solution is IP Fabric.  The solution allows the use of equipment from any manufacturer.  IP fabric works exclusively on the third OSI level.  It does not have any common points of management and a single console, but the possibilities of scaling, as well as troubleshooting, are quite extensive. <br><br>  Division into levels Underlay and Overlay.  As the technology used Underlay known to us the IGP protocols - such as OSPF / IS-IS, for small data centers.  If the data center has many racks and uses a large number of connected terminals, then everyone's favorite iBGP / eBGP.  In my opinion, when choosing a solution, underlay is a matter of taste and common sense. <br><br>  As an overlay solution, something like VXLAN is selected, which is supported by most manufacturers of network solutions, together with MPLS technologies or, say, EVPN.  Juniper equipment can be used to build similar solutions along with other manufacturers.  There are no features here, I think, it is impossible. <br><br><ul><li>  Wide range of deployment options. </li><li>  Spine - Leaf technology support. </li><li>  Open selection of technologies and protocols. </li><li>  The ability to use solutions from different manufacturers. </li><li>  Highest scalability compared to other solutions. </li><li>  Work only on the third level of the OSI model. </li></ul><br>  In this article, I conducted a general review of the principles of building networks for data processing centers, as well as the possibilities of using equipment and solutions from Juniper Networks for their implementation. <br><br>  All photographs courtesy of Juniper Networks, represented by engineer Bugakov Yevgeny.  What a special thanks to him. </div><p>Source: <a href="https://habr.com/ru/post/411091/">https://habr.com/ru/post/411091/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../411081/index.html">The search for new ways of teamwork for a clever swarm</a></li>
<li><a href="../411083/index.html">Sunset "Stars of Humanity"</a></li>
<li><a href="../411085/index.html">Pi-Sonos v3.0: work on the bugs or a completely new project?</a></li>
<li><a href="../411087/index.html">The nearest future of video cards</a></li>
<li><a href="../411089/index.html">How to identify a satellite in orbit</a></li>
<li><a href="../411093/index.html">Centralized remote control control of lighting sources TsPKIO-2D Rotor</a></li>
<li><a href="../411095/index.html">The Kepler telescope runs out of fuel. The final is near</a></li>
<li><a href="../411097/index.html">Standalone Mobile Messenger</a></li>
<li><a href="../411099/index.html">It is easy to estimate PPFD when the plant is illuminated with white LEDs: 1000 lx = 15 ¬µmol / s / m2</a></li>
<li><a href="../411101/index.html">Authorities in New York allowed to increase the cost of electricity for miners</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>