<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Parallel STL. Fast way to speed up C ++ STL code</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Over the past couple of decades, while computing systems have evolved from single-core scalar to multi-core vector architectures, the popularity of ma...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Parallel STL. Fast way to speed up C ++ STL code</h1><div class="post__text post__text-html js-mediator-article">  Over the past couple of decades, while computing systems have evolved from single-core scalar to multi-core vector architectures, the popularity of managed languages ‚Äã‚Äãhas grown significantly, and new programming languages ‚Äã‚Äãhave emerged.  But the good old C ++, which allows writing high-performance code, remains more than popular.  However, until recently, the language standard did not provide any tools for expressing concurrency.  The new version of the standard (C ++ 17 [1]) provides a set of parallel algorithms Parallel STL, which makes it possible to convert existing sequential C ++ code into parallel, which, in turn, allows using hardware capabilities such as multithreading and vectoring.  This article will introduce you to the basics of Parallel STL and its implementation in Intel Parallel Studio XE 2018. <br><br><img src="https://habrastorage.org/webt/lb/1v/rq/lb1vrq5mmtsrfknos1u0i1jhjxo.jpeg"><br><a name="habracut"></a><br><h3>  <font color="#0071c5">Introduction to Parallel STL</font> </h3><br>  So, the fate of supporting concurrency in C ++ was very difficult.  The picture below <br>  You can get acquainted with the available multi-level tools in different versions of C ++, including the whole "zoo" of various "external" tools for developing parallel software created by software or hardware manufacturers. <br><img src="https://habrastorage.org/webt/9g/pa/pb/9gpapbdryipxvhrquozkbelr-zu.png"><br>  <i>Figure 1. The evolution of concurrency in C ++</i> <br><br>  Parallel STL is an extension of the Standard Template Library C ++ (STL - Standard Template Library), which introduces the key concept of "execution policy". <br>  The execution policy is the C ++ class used as a unique type for overloading STL algorithms.  For ease of use, the standard also defines one object of each such class, which can be passed as an argument when calling algorithms.  They can be used with well-known algorithms (transform, for_each, copy_if), and with new algorithms that appeared in C ++ 17 (reduce, transform_reduce, inclusive_scan, etc.).  It is necessary to clarify that not all algorithms in C ++ 17 support policies. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Further, parallel execution of the algorithm is understood to be execution on several CPU cores;  By vectorization we mean execution using the processor's vector registers.  Support for parallel policies has been developed for several years as the "Technical Specification for C ++ Extensions for Parallelism *" (Parallelism TS).  Now this specification is included in the standard language C ++ 17.  Support for vector policies can enter the second version of the Parallelism TS specification (n4698 [2], p0076 [3]).  In general, these documents describe 5 different execution policies (Fig. 2): <br><br><ul><li>  <b>sequenced_policy (seq)</b> says that the algorithm can be executed sequentially [1]. </li><li>  <b>parallel_policy (par)</b> indicates that the algorithm can run in parallel [1].  User functions called while the algorithm is running should not generate a ‚Äúdata race‚Äù. </li><li>  <b>parallel_unsequenced_policy (par_unseq)</b> indicates that the algorithm can be executed in parallel and vector [1]. </li><li>  <b>unsequenced_policy (unseq)</b> is a class that is part of the Parallelism TS v2 draft [2] and shows that the algorithm can be vectorially executed.  This policy requires that all user functions, functors, passed to the algorithm as parameters, do not interfere with vectorization (do not contain data dependencies, do not cause ‚Äúdata races,‚Äù etc.). </li><li>  <b>vector_policy (vec)</b> (also from [2]) says that the algorithm can be executed vectorially, but unlike <b>unseq</b> , the <b>vec</b> policy guarantees data processing in the order in which they are processed during sequential execution (preserves associativity). </li></ul><br><img src="https://habrastorage.org/webt/n9/xv/2-/n9xv2-wbv_kuadpbopheqilxip8.png"><br>  <i>Figure 2. Execution Policies for Algorithms</i> <br><br>  The figure above demonstrates the relationship between these policies.  The higher the policy on the scheme, the greater the degree of freedom (in terms of parallelism) it allows. <br>  The following are examples of using STL and Parallel STL algorithms according to the C ++ 17 standard: <br><br><pre><code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">include</span></span></span><span class="hljs-meta"> </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;execution&gt; #include &lt;algorithm&gt; void increment_seq( float *in, float *out, int N ) { using namespace std; transform( in, in + N, out, []( float f ) { return f+1; }); } void increment_unseq( float *in, float *out, int N ) { using namespace std; using namespace std::execution; transform( unseq, in, in + N, out, []( float f ) { return f+1; }); } void increment_par( float *in, float *out, int N ) { using namespace std; using namespace std::execution; transform( par, in, in + N, out, []( float f ) { return f+1; }); }</span></span></span></span></code> </pre> <br>  Where is the record <br><br><pre> <code class="cpp hljs"><span class="hljs-built_in"><span class="hljs-built_in">std</span></span>::transform( in, in + N, out, foo );</code> </pre> <br>  equivalent to the following cycle: <br><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (x = in; x &lt; in+N; ++x) *(out+(x-in)) = foo(x);</code> </pre> <br>  and <br><br><pre> <code class="cpp hljs"><span class="hljs-built_in"><span class="hljs-built_in">std</span></span>::transform( unseq, in, in + N, out, foo );</code> </pre> <br>  can be presented in the form of the following cycle (our implementation uses <i>#pragma omp simd</i> at the lower level, other implementations of Parallel STL may use other methods of implementing <b>unseq</b> policy) <br><br><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">pragma</span></span></span><span class="hljs-meta"> omp simd for (x = in; x &lt; in+N; ++x) *(out+(x-in)) = foo(x);</span></span></code> </pre> <br>  and <br><br><pre> <code class="cpp hljs"><span class="hljs-built_in"><span class="hljs-built_in">std</span></span>::transform( par, in, in + N, out);</code> </pre> <br>  can be expressed as follows: <br><br><pre> <code class="cpp hljs">tbb::parallel_for (in, in+N, [=] (x) { *(out+(x-in)) = foo(x); });</code> </pre> <br><h3>  <font color="#0071c5">Overview of Parallel STL implementation in Intel¬Æ Parallel Studio XE 2018</font> </h3><br>  Intel Parallel STL implementation is part of <a href="https://software.intel.com/en-us/intel-parallel-studio-xe">Intel¬Æ Parallel Studio XE 2018</a> .  We offer a portable implementation of algorithms that can be executed both in parallel and vector.  The implementation is optimized and tested for Intel¬Æ processors.  We use the <a href="https://software.intel.com/en-us/intel-tbb">Intel¬Æ Threading Building Blocks (Intel TBB)</a> for the <b>par</b> and <b>par_unseq</b> policies, <b>unseq</b> and <b>par_unseq for</b> vectorization by means of OpenMP *.  The <b>vec</b> policy is not presented in Intel Parallel Studio XE 2018. <br><br>  After installing Parallel STL, you need to set the environment variables as described in <a href="https://software.intel.com/en-us/get-started-with-pstl">this document</a> .  There is also an up-to-date list of algorithms that have parallel and / or vector implementations.  For the remaining algorithms, execution policies are also applicable, but a sequential version will be invoked. <br><br>  For best results with our Parallel STL implementation, we recommend using the Intel¬Æ C ++ Compiler 2018 compiler. But you can use other compilers that support C ++ 11.  To get a positive effect from vectorization, the compiler must also support OpenMP 4.0 ( <i>#pragma omp simd</i> ).  To use the <b>par, par_unseq policies</b> , the Intel TBB library is required. <br><br>  To add Parallel STL to your application, follow these steps: <br><br><ol><li>  Add <i>#include "pstl / execution"</i> .  Then one or more of the following lines, depending on which algorithms you intend to use: <br><br>  <i>#include "pstl / algorithm"</i> <br>  <i>#include "pstl / numeric"</i> <br>  <i>#include "pstl / memory"</i> <br><br>  Note that you should not write <i>#include &lt;execution&gt;</i> , but <i>#include ‚Äúpstl / execution‚Äù</i> .  This is done specifically to avoid conflicts with the header files of the standard C ++ library. </li><li>  At the place of use of algorithms and policies, specify the namespace <i>std</i> and <i>pstl :: execution,</i> respectively. </li><li>  Compile code with support for C ++ 11 or higher.  Use the appropriate compilation option to enable OpenMP vectorization (for example, for Intel C ++ Compiler <i>-qopenmp-simd</i> ( <i>/ Qopenmp-simd</i> for Windows *). </li><li>  For best performance, specify the target platform.  For Intel¬Æ C ++ Compiler, use the appropriate options from the list: <i>-xHOST, -xCORE-AVX2, -xMIC-AVX512</i> for Linux * or <i>/ QxHOST, / QxCORE AVX2, / QxMIC-AVX512</i> for Windows. </li><li>  Link with Intel TBB.  On Windows, this will happen automatically;  on other platforms add <br>  <i>-ltbb</i> to linker options. </li></ol><br>  Intel Parallel Studio XE 2018 contains examples of using Parallel STL, which you can build and run.  You can download them <a href="https://software.intel.com/en-us/product-code-samples">here</a> . <br><br><h3>  <font color="#0071c5">Effective vectorization, parallelism and compatibility using our implementation of Parallel STL</font> </h3><br>  In theory, Parallel STL was developed as an intuitive way for C ++ developers to write programs for parallel computing systems with shared memory.  Consider an approach in which theory correlates with best practices for parallelizing nested loops, for example, an approach such as ‚ÄúVectorize the internal level, parallelize the external‚Äù (‚ÄúVectorize Innermost, Parallelize Outermost‚Äù [VIPO]) [4].  As an example, consider an image gamma correction, a non-linear operation used to change the brightness of each image pixel.  Note that we need to disable auto-vectorisation for sequential execution of algorithms in order to show the difference between sequential and vector-based execution.  (Otherwise, this difference can only be seen with compilers that do not support automatic vectorization, but support OpenMP vectorization) <br><br>  Consider an example of sequential execution: <br><br><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">include</span></span></span><span class="hljs-meta"> </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;algorithm&gt; void ApplyGamma(Image&amp; rows, float g) { using namespace std; for_each(rows.begin(), rows.end(), [g](Row &amp;r) { transform(r.cbegin(), r.cend(), r.begin(), [g](float v) { return pow(v, g); }); }); }</span></span></span></span></code> </pre> <br>  The <i>ApplyGamma</i> function <i>takes</i> an image by its reference, represented as a set of strings, and calls <i>std :: for_each</i> to <i>iterate over the</i> strings.  The lambda function, called for each row, cycles through pixels using <i>std :: transform</i> to change the brightness of each pixel. <br><br>  As described earlier, Parallel STL provides the parallel and vector versions of the <i>for_each</i> and <i>transform</i> algorithms.  In other words, the policy passed as the first argument to the algorithm leads to the execution of a parallel and / or vector version of this algorithm. <br><br>  Returning to the example above, you can see that all calculations are performed in the lambda function, which is called from the <i>transform</i> algorithm.  So let's try to ‚Äúkill two birds with one stone‚Äù and rewrite the example using the <b>par_unseq</b> policy: <br><br><pre> <code class="cpp hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">ApplyGamma</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(Image&amp; rows, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> g)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">using</span></span> <span class="hljs-keyword"><span class="hljs-keyword">namespace</span></span> pstl::execution; <span class="hljs-built_in"><span class="hljs-built_in">std</span></span>::for_each(rows.begin(),rows.end(), [g](Row &amp;r) { <span class="hljs-comment"><span class="hljs-comment">// Inner parallelization and vectorization std::transform(par_unseq, r.cbegin(), r.cend(), r.begin(), [g](float v) { return pow(v, g); }); }); }</span></span></code> </pre> <br><img src="https://habrastorage.org/webt/j7/s4/cq/j7s4cqcwowscsoupzmai4aqnzli.png"><br>  <i>Figure 3. <b>Par_unseq</b> for the inner loop</i> <br><br>  Surprisingly, the miracle did not happen (Fig. 3).  Performance with <b>par_unseq is</b> worse than sequential execution.  This is a great example of how NOT to use Parallel STL.  If you profile the code using, for example, <a href="https://software.intel.com/en-us/intel-vtune-amplifier-xe">Intel¬Æ VTune Amplifier XE</a> , you can see many cache misses caused by threads running on different cores accessing the same cache lines (this effect is known as ‚Äú false sharing of resources ‚Äù[ <a href="https://software.intel.com/en-us/articles/avoiding-and-identifying-false-sharing-among-threads">false sharing</a> ]). <br><br>  As noted earlier, Parallel STL helps us express the parallelism of the mean (using system flows) and lower (using vectorization) levels of parallelism.  In general, in order to get the greatest acceleration, estimate the execution time of the algorithm and compare it with the overhead of parallelism and vectorization.  We recommend that the sequential execution time be at least 2 times longer than the overhead at each level of parallelism.  Besides: <br><br><ul><li>  Parallelize the topmost level;  Look for the maximum amount of work to do in parallel mode. </li><li>  If this gives you sufficient parallelization efficiency, the goal is achieved.  If not, parallelize the level below. </li><li>  Make sure the algorithm effectively uses the cache. </li><li>  Try to vectorize the lowest level.  Try to reduce the number of conditional transitions in the vectorized function and observe the uniformity of memory access. </li><li>  For more recommendations, see [4]. </li></ul><br>  The recommendations suggest that the proper use of parallel and vector policies at different levels can provide better performance, namely: <br><br><pre> <code class="cpp hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">ApplyGamma</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(Image&amp; rows, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> g)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">using</span></span> <span class="hljs-keyword"><span class="hljs-keyword">namespace</span></span> pstl::execution; <span class="hljs-comment"><span class="hljs-comment">// Outer parallelization std::for_each(par, rows.begin(), rows.end(), [g](Row &amp;r) { // Inner vectorization std::transform(unseq, r.cbegin(), r.cend(), r.begin(), [g](float v) { return pow(v, g); }); }); }</span></span></code> </pre> <br><img src="https://habrastorage.org/webt/ro/gq/dc/rogqdc6x0hr9udk8l9dr5fbjie4.png"><br>  <i>Figure 4. Vectorization at the internal level, parallelism at the external</i> <br><br>  Now we have obtained efficient parallel processing of a single image (Fig. 4), but real applications, as a rule, process many images (Fig. 5).  Parallelism at a higher level can work poorly with standard algorithms.  In this case, we suggest using Parallel STL in conjunction with Intel TBB. <br><br><img src="https://habrastorage.org/webt/43/hk/li/43hkliw_vjzbt4nyuwysdr04bge.png"><br>  <i>Figure 5. Methods of processing multiple images</i> <br><br>  This allows you to apply tasks or parallel constructions (for example, a computational graph [flow graph], a pipeline [pipeline]) Intel TBB at the highest level and Parallel STL algorithms at lower levels, without worrying about creating an excess of logical flows in the system .  Example: <br><br><pre> <code class="cpp hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">Function</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>{ Image img1, img2; <span class="hljs-comment"><span class="hljs-comment">// Prepare img1 and img2 tbb::parallel_invoke( [&amp;img1] { img1.ApplyGamma(gamma1); }, [&amp;img2] { img2.ApplyGamma(gamma2); } ); }</span></span></code> </pre> <br><img src="https://habrastorage.org/webt/uc/hj/dj/uchjdjec969d_gytc_a-kscbdqy.png"><br>  <i>Figure 6. Intel TBB and Parallel STL sharing</i> <br><br>  As shown in Figure 6, simultaneous processing of two images using Intel TBB does not reduce performance, but on the contrary, even increases it slightly.  This shows that the expression of parallelism at the level below and at the lowest level makes maximum use of the CPU cores. <br><br>  Now consider the situation when we have more images for processing and more CPU cores. <br><br><pre> <code class="cpp hljs">tbb::parallel_for(images.begin(), images.end(), [](image* img) {applyGamma(img-&gt;rows(), <span class="hljs-number"><span class="hljs-number">1.1</span></span>);} );</code> </pre> <br><img src="https://habrastorage.org/webt/gs/sg/nx/gssgnxzmikyfelvfhomy7hrfchq.png"><br>  Figure 7. Intel TBB and Parallel STL sharing across more images and more CPU cores. <br><br>  The figure above shows that simultaneous processing of multiple images using Intel TBB ( <i>parallel_for</i> ) dramatically increases performance.  In fact, take a look at the first column, where we sequentially run through all the images, with each image being processed in parallel at a lower level.  Adding only parallelism at the very top level ( <i>parallel_for</i> ) without parallelism at the level below ( <b>par</b> ) significantly increases performance, but this is not enough to make the most of the resources of the CPU cores.  The third column shows that concurrency at all levels dramatically increases performance.  This shows the effectiveness of sharing Intel TBB and our implementation of Parallel STL. <br><br><h3>  <font color="#0071c5">Conclusion</font> </h3><br>  Parallel STL is a significant step in the evolution of C ++ parallelism, which makes it easily applicable to the algorithms of the standard STL library, both when upgrading code and creating new applications.  This part of the standard adds to the C ++ language the possibilities of vectorization and concurrency without the use of non-standard or custom-written extensions, and execution policies provide control over the use of such features, abstracting from hardware.  Parallel STL allows developers to focus on expressing parallelism in their applications, without worrying about low-level flow control and vector registers.  In addition to efficient, high-performance implementations of high-level algorithms, our Parallel STL implementation demonstrates efficient sharing with Intel TBB parallel patterns.  However, Parallel STL is not a panacea.  Parallel and vector policies should be used deliberately, depending on the dimension of the problem, the type and amount of data, as well as the function code, functors used in the algorithms.  To achieve high performance, we can recommend some methods described in [4]. <br><br>  You can find current versions of Parallel STL and Intel TBB, as well as additional information on the following sites: <br><br><ul><li>  Open implementation of <a href="https://github.com/intel/parallelstl">Parallel STL</a> on github </li><li>  Intel TBB <a href="http://software.intel.com/en-us/intel-tbb">Official Website</a> </li><li>  Intel TBB on <a href="https://github.com/01org/tbb/">github</a> </li><li>  Intel TBB <a href="https://www.threadingbuildingblocks.org/docs/help/index.htm">Documentation</a> </li></ul><br>  We need your feedback.  And you can leave them here: <br><br><ul><li>  <a href="https://github.com/intel/parallelstl">Project page</a> on github </li><li>  Intel TBB <a href="http://software.intel.com/en-us/forums/intel-threading-building-blocks">Forum</a> </li></ul><br><h3>  <font color="#0071c5">References:</font> </h3><br>  [1] ISO / IEC 14882: 2017, Programming Languages.  C ++ <br>  [2] N4698, <a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/n4706.html">Working Draft, Technical Specification for C ++ Extensions for Parallelism Version 2</a> , Programming Language C ++ (WG21) <br>  [3] P0076r4, <a href="http://open-std.org/JTC1/SC22/WG21/docs/papers/2017/p0076r4.pdf">Vector and Wavefront Policies</a> , Programming Language C ++ (WG21) <br>  [4] Robert Geva, <a href="https://software.intel.com/en-us/articles/idf15-webcast-code-modernization-best-practices">Code Modernization Best Practices: Multi-level Parallelism for Intel¬Æ Xeon¬Æ and Intel¬Æ Xeon Phi ‚Ñ¢ Processors</a> , IDF15 - Webcast <br><br>  * other names and brands may be declared the intellectual property of others. </div><p>Source: <a href="https://habr.com/ru/post/346822/">https://habr.com/ru/post/346822/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../346812/index.html">Frequency method of identification of linear dynamic systems: theory and practice</a></li>
<li><a href="../346814/index.html">Where the data flow: the consequences of the grand Equifax</a></li>
<li><a href="../346816/index.html">Alternative DBMS Architecture and Application Development Approach</a></li>
<li><a href="../346818/index.html">English words whose pronunciation is always confused</a></li>
<li><a href="../346820/index.html">Deciphering the KeePass Database: A Step-by-Step Guide</a></li>
<li><a href="../346824/index.html">Who is engaged in machine learning and what is now popular in Data Science? Kaggle user survey results</a></li>
<li><a href="../346826/index.html">How I returned the stolen domain of a popular site</a></li>
<li><a href="../346828/index.html">Creating the main authorization page (landing page) BigBlueButton 2.0b</a></li>
<li><a href="../346830/index.html">MageConf 2017 video and conference materials</a></li>
<li><a href="../346832/index.html">Forsyth study of blockchain technology</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>