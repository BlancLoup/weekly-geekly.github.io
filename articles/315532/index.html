<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚ÄúI will know when I see‚Äù - we study the accuracy of Google Cloud Vision using Tumblr and NSFW content</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="For small teams and technology startups, cloud services are often the only chance to establish business processes and launch a product on the market w...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>‚ÄúI will know when I see‚Äù - we study the accuracy of Google Cloud Vision using Tumblr and NSFW content</h1><div class="post__text post__text-html js-mediator-article"><p><img src="https://habrastorage.org/files/27d/e04/094/27de0409407743d28ee2b6442fb372ff.jpg" alt="image"></p><br><p>  For small teams and technology startups, cloud services are often the only chance to establish business processes and launch a product on the market within a reasonable time.  Such large players as Google, Microsoft, Amazon, Yandex offer a wide range of products to everyone.  And if there is no question of the reliability of corporate email, then sometimes machine learning services should be treated with caution. </p><br><p>  Especially when you are trying to teach the machine to distinguish objects, the difference between which is not always possible to clearly describe even a knowledgeable person.  How accurate are the algorithms underlying out-of-the-box solutions from large companies? </p><a name="habracut"></a><br><p>  In 1964, a member of the US Supreme Court stated: </p><br><blockquote>  I will not attempt now to define more precisely the material falling under this brief description [‚Äúhard pornography‚Äù];  I may never be able to give this a clear definition.  However, I know when I see. </blockquote><p>  The state machine in our country periodically falls into a state of active struggle with pornography in particular and eroticism in general.  We will not discuss the goals, content and prospects of this struggle.  But we note that sometimes the answer to the question is <em>nsfw or not nsfw?</em>  - quite difficult. <br>  The modest team of <a href="http://smmframe.com/">smmframe.com</a> has long been interested in Api reliability issues from the Good Corporation and once for running several technologies, it was decided to check the quality of Google Cloud Vision performance using the example of erotic and pseudo-erotic image recognition. </p><br><h4 id="tehnicheskaya-realizaciya-ili-skachat-foto-golyh-devushek">  Technical implementation or "Download photos of naked girls" </h4><br><p>  First question - where to get dataset?  We need a dataset satisfying three requirements: </p><br><ul><li>  Match all photos to one specific tag (for a quick start) </li><li>  the presence of neutral photos for this tag </li><li>  the presence of not neutral photos on this tag </li><li>  it is desirable to do without outright porn and nudity <del>  not sports </del></li></ul><br><p>  Our choice fell on Tumblr - a lot of suitable photos on the tag <a href="https://www.tumblr.com/search/girl">girl</a> and convenient API.  Of course, it would be better to look for a sexy girl, but the tumbler severely limits the output by nsfw tags. </p><br><p>  Collecting data to assess the quality of service performance is simple in itself.  We register on the Google Cloud Vision service, <a href="https://cloud.google.com/vision/">look at</a> pricing in the Explicit Content Detection line.  We understand with <a href="https://www.tumblr.com/docs/en/api/v2">api</a> from tumbler. </p><br><p>  We read the documentation and write a script that will cron download photos and then transfer them to Google.  We get the answer of the service - an estimate of the probability that the picture has erotic on a scale from 1 to 5. We analyze the answer of the service and save it in a file for the future. </p><br><p>  It remains the longest and most tedious stage - manually add a rating from 1 to 5 to all photos in the dataset.  For the convenience of viewing images made site: <a href="http://labs.smmframe.com/">labs.smmframe.com</a> .  The brave man, who volunteered to view all the photos, noted two points: a lot of repetition of photos and a lot of Emma Watson </p><br><h4 id="strannosti-ili-pochuvstvuy-sebya-milonovym">  Oddities or feel like Milonov </h4><br><p>  There are enough oddities in the results from the Vision API.  We note right away - the service works very well for obvious boundary cases. </p><br><p>  Safe: <br><img src="https://habrastorage.org/files/7ac/09b/820/7ac09b8204c942228a65f591e9b701e9.jpg" alt="image"></p><br><p>  Unsafe: (link to the picture itself <a href="">here</a> .) In the meantime, just a cat. </p><br><p><img src="https://habrastorage.org/files/548/9e5/a0a/5489e5a0a3744aaab222f4a7b4497783.jpg" alt="image"></p><br><p>  Almost insecure: <br><img src="https://habrastorage.org/files/e98/62a/c7e/e9862ac7e0a3444db26141ad196b73ce.jpg" alt="image"></p><br><p>  Note that the girls tag we chose quite often includes images of manicure sets, flowers or typical objects inhabiting a woman's handbag.  All this is classified as Very Unlikely, which is correct.  Naked girls are detected as Likely - which is also true. </p><br><p>  Are there frankly incorrect assessments of absolutely safe content?  Of course!  But it is difficult to describe these cases clearly. </p><br><p>  <strong>The difficulties of working with girls in underwear or a thin-thin face of what is permitted</strong> </p><br><p>  In retrospect, the reason for the appearance of the article was this image, which happened to be on a monitor in one club.  Let's say right away - two lovely ladies do not cause Google any bad associations, as evidenced by the Unlikely rating. </p><br><p><img src="https://habrastorage.org/files/949/26d/1bf/94926d1bff1e4e14b754994581a3d34f.jpg" alt="image"></p><br><p>  And this is at least strange, because the other three pictures of much more decent content were rated as close to the NSFW: </p><br><p><img src="https://habrastorage.org/files/733/1bc/00d/7331bc00d2514552bbec6c61a56353c4.jpg" alt="image"><br>  <em>From left to right: Unlikely, Likely, Likely</em> </p><br><p>  This is a very strange result, when Unlikely affixed to photos with clothed girls: </p><br><p><img src="https://habrastorage.org/files/436/ffd/1c0/436ffd1c0c0c4a4d81db6598a6044cfd.jpg" alt="image"></p><br><p>  <strong>What is Explicit Content?</strong> </p><br><p>  Here, for example, a cute picture of a severed head with horns and a fairly authentic traced anatomy of the neck. <br><img src="https://habrastorage.org/files/eb6/764/6e1/eb67646e1eb14257a872eee5c554fa35.jpg" alt="image"><br>  The question immediately arises - why <del>  tagged girls </del>  filter missed it?  Referring to the dictionary, you can learn that the concept of Explicit Content is not limited to obscene things of a sexual nature, but includes pronounced aggression, foul language, propaganda of bad habits, blood, dismemberment, and much more, which should not pay attention to particularly impressionable people. </p><br><p>  It turns out that Google Cloud Vision in this case was more likely wrong than it was right, because the picture should not be shown to children. </p><br><p>  <strong>Gifs</strong> </p><br><p>  <a href="">Here is a</a> more interesting example - a gif with iridescent colors, a cat and a bare chest.  We do not know exactly how gif files are analyzed, but for a person, the assessment of this picture as obscene is obvious.  Probably far from the standard color of the skin and atypical angle allowed the picture to deceive the filters - very Unlikely rating. </p><br><p>  Interestingly, some apparently decent and well-behaved things in movement may seem piquant.  Compare just a frame from a gif (peak below) and the <a href="">gif</a> itself </p><br><p><img src="https://habrastorage.org/files/dd6/399/d1f/dd6399d1f5474bee83e767260f84b031.png" alt="image"></p><br><p>  <strong>Difficulties of Augmented Reality</strong> </p><br><p>  Since we are discussing the pictures, let's consider this example.  Two images are taken in the same well-known application.  Here only the first is regarded as safe, and the second - Likely. </p><br><p><img src="https://habrastorage.org/files/60c/2a4/941/60c2a4941cae494eb9c39c80ab41391f.jpg" alt="image"><br>  <em>The poor guy is recognized by the NSFW.</em> </p><br><p><img src="https://habrastorage.org/files/c4c/58c/26c/c4c58c26c4194ae6868a4d3052b61bed.jpg" alt="image"><br>  <em>The girl is just having fun.</em> </p><br><p> Why is it so difficult to guess, but Cloud Vision Api has an unhealthy habit of changing the classification with relatively small changes in the facial expression or posture of people. <br>  Here are some more examples: </p><br><p><img src="https://habrastorage.org/files/479/256/858/479256858bf84723b219048a2a693481.jpg" alt="image"><br>  <em>Left - Unlikely, Right - Likely</em> </p><br><p><img src="https://habrastorage.org/files/b6a/b82/799/b6ab827990584ac4a63d67166308465a.jpg" alt="image"><br>  <em>Left - Unlikely, right - Likely.</em>  <em>There is a version that the matter is in bad focus on the left image.</em> </p><br><p><img src="https://habrastorage.org/files/73a/1b3/386/73a1b338605c4fd7b0673986db63d0c2%0A.jpg" alt="image"><br>  <em>Left - Unlikely, right - Likely.</em> </p><br><p><img src="https://habrastorage.org/files/a53/430/677/a53430677a554b739385b8b6cb19aa22.png" alt="image"><br>  <em>Left - Very Unlikely, right - Unlikely.</em> </p><br><p>  <strong>5 points or why do we need gradation?</strong> </p><br><p>  You might think that we quibble.  Indeed, it is not always possible to distinguish between a girl in a bathing suit and a sports bra.  Moreover, the tastes do not argue.  Therefore, even if Google behaves strangely with seemingly slightly different photos, then let's show where it is cool.  <a href="">Tyts</a> and <a href="">tyts</a> .  Everything is absolutely correct, it remains only to be amazed at the work done and the ability to notice the details occupying such a small area in the images. </p><br><p>  After the first few hundred photos in the dataset, we decided not to score points from 1 to 5 and go to the nsfw / non nsfw graduation.  The results of the comparison of our assessment with the assessment of Google are given in the table below.  Of the 13k photos after removing duplicates received 11246. </p><br><table><thead><tr><th>  Type of assessment </th><th>  Number of photos </th><th>  Marked as NSFW </th><th>  Share </th></tr></thead><tbody><tr><td>  VERY_LIKELY </td><td>  116 </td><td>  62 </td><td>  0.53445 </td></tr><tr><td>  LIKELY </td><td>  176 </td><td>  47 </td><td>  0.26705 </td></tr><tr><td>  POSSIBLE </td><td>  503 </td><td>  44 </td><td>  0.08748 </td></tr><tr><td>  UNLIKELY </td><td>  3709 </td><td>  112 </td><td>  0.03020 </td></tr><tr><td>  VERY_UNLIKELY </td><td>  6690 </td><td>  50 </td><td>  0.00747 </td></tr><tr><td>  ERROR </td><td>  52 </td><td>  2 </td><td>  0.03846 </td></tr></tbody></table><br><p>  <strong>Summary</strong> </p><br><p>  In the results of the work of any classifier, both false-positive and false-negative cases are always encountered.  Initially, we were faced with the task of finding images of a possibly indecent nature in a decent environment when analyzing the output of images from Instagram using a specific hash tag.  This was supposed to protect our clients from showing on the screen in any institution of frankly unattractive scenes.  In general, the API copes with its task if it is used at the level YES / NO.  Thinner gradation works well for searching for NSFW content, and it is often better to filter out the false positive results that are found than to skip - God saves your savings. </p><br><p>  And if you answer the question raised at the beginning of the article - the Corporation of Good has done an excellent job.  A small class of tasks in which you need to pay special attention to false-positive and false-negative results are relatively easy to solve by adding additional checks ‚Äî for example, estimating the area of ‚Äã‚Äãopen skin in an image. </p><br><p>  <strong>About us:</strong> </p><br><p>  <a href="http://smmframe.com/">Smmframe.com</a> is a service that allows you to organize translations from photos on a given hashtag.  With the help of our service, places of entertainment can advertise themselves in social networks.  We have developed several advanced algorithms that allow us to find the most interesting photos that will accurately hook future visitors. </p><cut></cut></div>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <p>Source: <a href="https://habr.com/ru/post/315532/">https://habr.com/ru/post/315532/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../315516/index.html">Around Citrix NetScaler ADC. Part 1</a></li>
<li><a href="../315518/index.html">ReactOS 0.4.3 released under the code name "Haters gonna hate"</a></li>
<li><a href="../315524/index.html">SDN: concept changes over 5 years</a></li>
<li><a href="../315526/index.html">Functional testing of modern web applications</a></li>
<li><a href="../315530/index.html">Etiquette and ethics of using OpenSource</a></li>
<li><a href="../315534/index.html">Opanki, I broke your life</a></li>
<li><a href="../315536/index.html">Reverse tunnel for RDP access using putty and icinga2</a></li>
<li><a href="../315538/index.html">What is Bitrix</a></li>
<li><a href="../315540/index.html">Vulnerability in VMware products allows code execution on a virtual machine host system</a></li>
<li><a href="../315542/index.html">I loved the layout after this: Zeplin in battle</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>