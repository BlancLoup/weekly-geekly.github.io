<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>One model for learning everything. Google has opened the library Tensor2Tensor</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Recent advances in depth learning and neural networks have spread to a wide range of applications and continue to spread further: from machine vision ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>One model for learning everything. Google has opened the library Tensor2Tensor</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/getpro/geektimes/post_images/8ad/0c7/8b0/8ad0c78b0c6dc60e5063f2755954b0bc.png" align="left">  Recent advances in depth learning and neural networks have spread to a wide range of applications and continue to spread further: from machine vision to speech recognition and many other tasks.  Convolutional neural networks best of all manifest themselves in vision tasks, and recurrent neural networks have shown success in natural language processing tasks, including machine translation applications.  But in each case, a specific neural network is designed for each specific task.  This approach limits the use of in-depth training, because the design must be performed again and again for each new task.  It is also different from the way the human brain works, which can learn several tasks at the same time, and it also benefits from the transfer of experience between tasks.  The authors of the scientific work ‚Äú <a href="https://arxiv.org/abs/1706.05137">One Model for Learning Everything</a> ‚Äù from the Google Brain Team asked a natural question: ‚ÄúCan we create a unified depth learning model that will solve problems from different areas?‚Äù <br><br>  It turned out that we can.  Google did it - and opened the <a href="https://github.com/tensorflow/tensor2tensor">Tensor2Tensor</a> for public use, the code is published on GitHub. <br><a name="habracut"></a><br>  The issue of creating multi-tasking models has been the subject of many scientific papers and has been raised in the literature on depth learning.  Natural language processing models have long shown an improvement in quality using a multi-tasking approach, and recently machine translation models have shown complete learning without training (zero-shot learning, when a problem is solved without providing materials for learning to solve this problem) when learning simultaneously in many languages .  Speech recognition also increased the quality of learning in such a multi-tasking mode, as well as some tasks in the field of machine vision, such as face type recognition.  But in all cases, all these models were trained on tasks from the same domain: translation tasks ‚Äî on other translation tasks (albeit from other languages), machine vision tasks ‚Äî on other computer vision tasks, speech processing tasks ‚Äî on other speech processing tasks.  But no truly multi-tasking <i>multi-</i> model model has been proposed. <br><br>  Specialists from Google managed to develop this.  In a scientific article, they describe the MultiModel architecture - a unified universal model of deep learning, which can simultaneously be trained in tasks from different domains. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/web/6f8/0e6/477/6f80e6477f554325ad14b6134cba48f9.png"><br>  <font color="gray">MultiModel Architecture</font> <br><br>  In particular, the researchers trained MultiModel to test simultaneously on eight data sets: <br><br><ul><li>  WSJ Speech Recognition Body </li><li>  ImageNet Image Base </li><li>  Base of common objects in the context of COCO </li><li>  WSJ parsing database </li><li>  English to German translation body </li><li>  Reverse previous: German to English translation corps </li><li>  Translation from English to French </li><li>  Reverse the previous: the case of translation from French to English </li></ul><br>  The model successfully studied all the listed tasks and showed a good quality of work: not outstanding at the moment, but higher than that of many specific neural networks designed for one task. <br><br><img src="https://habrastorage.org/web/1d5/f7f/b9a/1d5f7fb9ad6a495c9db8601d0eba4d4d.png"><br><br>  The illustration shows some examples of how the model works.  Obviously, she is able to describe the text that is shown in the photograph, to categorize objects and translate. <br><br>  Scientists emphasize that this is only the first step in this direction, but at the same time they draw attention to two key innovations that made it possible to create such a model in principle and what they consider their main achievement: <br><br><ol><li>  Small subnets with limited modality that turn into a unified view and back.  In order for a multimodal universal model to be trained on input data of different formats - text, sound, images, video, etc. - all of them must be transferred to a common universal space of representations of variable size. </li><li>  Computing blocks of various kinds are critical to getting good results on various problems.  For example, the <a href="https://arxiv.org/abs/1701.06538">Sparsely-Gated Mixture-of-Experts</a> block was inserted for natural language processing tasks, but it did not interfere with the performance of other tasks.  The same is true of other computational units. </li></ol><br><br><img src="https://habrastorage.org/web/9cf/26e/676/9cf26e67620d4ce98759cf6b1afb7763.png"><br><br>  The more detailed architecture of the MultiModel is shown in the illustration above. <br><br>  MultiModel learns many data and many tasks at once.  Experiments have shown that such an approach gives a huge advantage in improving the quality of work on tasks with a small amount of data.  At the same time, for problems with a large amount of data, there is only a slight deterioration, if any. <br><br>  The scientific work is <a href="https://arxiv.org/abs/1706.05137">published</a> on the site of preprints arXiv.org (arXiv: 1706.05137). </div><p>Source: <a href="https://habr.com/ru/post/373559/">https://habr.com/ru/post/373559/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../373545/index.html">Retro electromoped "Cherry". Story 1 - from concept to test drive</a></li>
<li><a href="../373549/index.html">Podcast "Rules of the Game": accounting subtleties for technological (and other) business</a></li>
<li><a href="../373553/index.html">Review PocketBook 614 Plus with E Ink Carta screen: the most budget reader in the lineup of the market leader</a></li>
<li><a href="../373555/index.html">Human Behavior Biology: Lecture # 7. Behavioral Genetics II [Robert Sapolsky, 2010. Stanford]</a></li>
<li><a href="../373557/index.html">Lenovo ThinkPad and the future library in Portsmouth</a></li>
<li><a href="../373561/index.html">Overview AirWheel Z5 - transport metropolis</a></li>
<li><a href="../373563/index.html">Solar battery on the balcony: testing battery ionistor</a></li>
<li><a href="../373565/index.html">Yromian chromosome, or why men die earlier?</a></li>
<li><a href="../373569/index.html">15 Mb white spot</a></li>
<li><a href="../373571/index.html">Created an algorithm that generates instructions for folding origami of any shape.</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>