<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Gorilla: fast, scalable in-memory time-series database</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="This is a translation of the review of the article ‚ÄúGorilla: A fast, scalable, in-memory time series database‚Äù Pelkonen et al. VLDB 2015 


 Facebook ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Gorilla: fast, scalable in-memory time-series database</h1><div class="post__text post__text-html js-mediator-article"><p>  <em>This is a translation of the review of the article ‚ÄúGorilla: A fast, scalable, in-memory time series database‚Äù Pelkonen et al.</em>  <em>VLDB 2015</em> </p><br><p>  Facebook guys made a high-performance monitoring data engine.  I liked the review of this article in the blog "The morning paper" - especially about compression algorithms, and here is the translation. </p><br><p>  <em>Style - author.</em> </p><br><blockquote>  The number of errors on one of the Facebook servers went off scale. <a name="habracut"></a>  The problem was discovered a few minutes after its appearance, when the automatic notification in Gorilla, the in-memory database for the time series, worked.  One group of engineers took up the solution to the incident, while another intended to find its immediate cause.  They launched a correlation search engine in the time series written over Gorilla, and began to look for metrics correlating with errors.  It turned out that copying the release binaries to Facebook web servers (rather a routine operation) caused an unnatural decrease in memory usage on the site ... <br><img src="https://habrastorage.org/files/9c1/3e7/30c/9c13e730c32d4ca8af44b4045513f870.png" alt="image"><br>  <strong>Figure 1. When searching for the main reason for increasing the frequency of errors on the site, the search engine for the correlation of time series in Gorilla detected anomalous events that in time corresponded to the appearance of errors, namely a sharp decrease in the memory used when copying the release binary.</strong> </blockquote><p>  18 months before the article was published, Gorilla helped Facebook engineers identify and debug several similar problems on production. </p><br><blockquote>  ‚ÄúAn important requirement for the operation of such high-load services is accurate monitoring of the performance and performance of the underlying system, as well as the rapid identification and diagnosis of problems as they arise.  Facebook uses a time series database to store system measurement data points and provides quick query functionality to them. ‚Äù </blockquote><p>  Since spring 2015, Facebook's monitoring systems have generated over 2 billion unique measurements of time series (12 million measurements per second, more than 1 trillion per day).  Since the spring of 2015, Facebook monitoring systems have generated over 2 billion unique metrics (12 million measurements per second, i.e. more than 1 trillion per day).  The following characteristics were required from Gorilla: </p><br><ul><li>  Storage of 2 billion unique time series available by string key. </li><li>  The insertion speed is 700 million data points (time stamp and floating point value) per minute. </li><li>  Data for the last 26 hours that must be stored in memory and quickly issue on request. </li><li>  Up to 40,000 requests per second at the peak. </li><li>  Successful reading in less than one millisecond. </li><li>  Time series support with details up to 15 seconds (4 data points per minute). </li><li>  Two copies of memory (not combined) for disaster recovery </li><li>  Continue reading in case the server crashes. </li><li>  Support quick scan of all data in memory. </li><li>  Manage long-term growth (up to 2 times a year) of these time series! </li></ul><br><p>  To meet these performance requirements, Gorilla is built as a TSDB completely in RAM and working as an end-to-end cache when recording monitoring data in HBase.  To keep 26 hours of data in memory, Gorilla uses a new time series compression algorithm, which gives compression 12 times.  Data structures in memory allow you to quickly and efficiently scan all data while maintaining the possibility of obtaining data from individual time series in constant time. </p><br><blockquote>  ‚ÄúThe string key is used to identify unique time series.  Each set of time data is tied to a separate host in Gorilla, by sharding all monitoring data based on these unique string keys.  Thus, we can scale Gorilla by simply adding new hosts and adjusting the sharding, so that new data falls on an extended set of hosts.  When Gorilla was launched in production 18 months ago, all our monitoring data for the last 26 hours was placed in 1.3 TB of RAM and evenly distributed on 20 machines.  Since then, due to data growth, we had to double the cluster size twice, and now they are running on 80 machines in each Gorilla cluster.  This process was simple due to the architecture of independent nodes and the focus on horizontal scalability. ‚Äù </blockquote><p>  The in-memory data structure is based on the unordered map structure from the standard C ++ library.  She proved to be effective and it gave no blocking problems.  Gorilla saves data to GlusterFS, a POSIX-compatible triple-replication distributed file system.  "HDFS or other distributed file systems would also work." </p><br><p>  For more information about data structures and how to handle errors in Gorilla, see sections 4.3 and 4.4 of the original article [ <a href="http://www.vldb.org/pvldb/vol8/p1816-teller.pdf">pdf</a> ]. </p><br><p>  Here I want to focus on those techniques that are used in Gorilla to compress time series in order to fit all this data into memory! </p><br><h2 id="szhatie-vremennyh-ryadov-v-gorilla">  Compress time series in gorilla </h2><br><blockquote>  ‚ÄúGorilla compresses data points within one time series without additional compression between different time series.  Each date point is a pair of 64-bit values ‚Äã‚Äãrepresenting a timestamp, timestamp, and its corresponding metric value.  Timestamps and values ‚Äã‚Äãare compressed separately, using information about previous values. " </blockquote><p>  As for timestamps, the key observation is that most sources write data points to the logs at fixed intervals (for example, one mark every 60 seconds).  From time to time, the data point may be recorded a little earlier or later (for example, for a second or two), but this gap is usually limited.  In our case, every bit on the account, so if we can represent consecutive timestamps, taking up as little space as possible, this gives us a memory gain ... Each data block stores 2 hours of measurements.  The block header contains the initial time stamp of a two-hour window.  The first timestamp in the block (after the start of the two-hour window) is saved as delta from the moment the block starts, using 14 bits.  14 bits is enough to hold just over 4 hours, so we know that we definitely will not need more. <br><img src="https://habrastorage.org/files/ff4/6c8/d16/ff46c8d16dce44358bf093cef2f49b3b.png" alt="image"></p><br><p>  For all subsequent timestamps, we compare the deltas.  Suppose that the block start time is at 02:00:00, and the first timestamp is 62 seconds later - 02:01:02.  The next data point is at 02:02:02, after another 60 seconds.  If we compare these two deltas, the second delta (60 seconds) is 2 seconds shorter than the first (62 seconds).  So we write down minus 2. How many bits should we use to write ‚Äú-2‚Äù?  Less is better!  We can use bit tags to indicate how many bits the value itself is encoded.  The scheme works as follows: </p><br><p>  Delta delta calculation: D = (tn - tn-1) - (tn-1 - tn-2) <br>  Deciphering values ‚Äã‚Äãin accordance with the table: <br><img src="https://habrastorage.org/files/e60/d09/6bd/e60d096bdba74acfa70d678615bf2502.png" alt="image"></p><br><p>  The specific values ‚Äã‚Äãof the time intervals were selected by selecting the series of series in real time from the production systems and selecting the ranges that showed the best compression ratios. </p><br><p>  So we get the following data stream: <br><img src="https://habrastorage.org/files/4a9/47c/b8c/4a947cb8c22f4851939e8c98a8a5ca3c.png" alt="image"></p><br><p>  ‚ÄúFigure 3. shows the result of the time stamp compression in Gorilla.  We found that 96% of all timestamps can be compressed to 1 bit. ‚Äù </p><br><p>  (i.e. 96% of all timestamps occur at regular intervals, so that the delta is zero). <br><img src="https://habrastorage.org/files/4c5/2d2/363/4c52d23632914d97b818822a216cef2d.png" alt="image"><br>  Figure 3. Distribution of compressed timestamps by ranges.  Taken from real data - 440,000 tags from Gorilla. </p><br><p>  We are discussing timestamps for so long, but what about the metric values ‚Äã‚Äãthemselves? </p><br><p>  ‚ÄúWe found that the value in most time series does not change significantly compared with the adjacent data points.  In addition, many data sources store only integers.  This allowed us to charge an expensive prediction scheme [25] to a simpler implementation that simply compares the current value with the previous value.  If the values ‚Äã‚Äãare close to each other, then the sign, the exponent, and the first few bits of the mantissa will be identical.  For this calculation, we use the XOR of the current and previous values ‚Äã‚Äãinstead of applying a delta encoding scheme. ‚Äù <br><img src="https://habrastorage.org/files/ba4/b5a/b13/ba4b5ab13e7a4d99a1291b7a390653f8.png" alt="image"><br>  Figure 4. A visual representation of how a XOR with a previous value often has zeros at the beginning and at the end, and for many rows, nonzero elements are grouped together. </p><br><p>  The values ‚Äã‚Äãare then encoded as follows: </p><br><p>  The first value is stored without compression.  For all subsequent values ‚Äã‚Äãapply XOR with the previous value.  If the result of XOR is zero (i.e., the same value), then the bit with the value ‚Äú0‚Äù is stored.  If the XOR result is not zero, then there will probably be a series of zeros before and after the ‚Äúsignificant bits‚Äù.  We calculate the number of leading zeros and the number of zeros at the end.  For example, the result is 0 √ó 0003200000000000, there are 3 leading zeros and 11 zeros at the end, so the bit with the value '1 ‚Ä≤ is stored, more ... </p><br><p>  If the previous value stored has the same or fewer zeros at the beginning and end, we know that all the significant bits of the value we want to keep fall within the range of significant bits of the previous value: <br><img src="https://habrastorage.org/files/7a9/d6c/6a7/7a9d6c6a7dc94b289c71a3c67aee5ade.png" alt="image"><br>  In the example above, the control bit "0" is saved, and then the significant value of the XOR operation (that is, 032) is stored. </p><br><p>  If the significant bits of the current value do not fall into the range of significant bits of the previous value, then the control bit with the value ‚Äú1‚Äù is stored, followed by 5 bits indicating the number of leading zeros, 6 bits with the length of the significant part of the XOR result and finally the significant bits of the XOR result. <br><img src="https://habrastorage.org/files/9d3/c1e/7ec/9d3c1e7ec3df4188a1b751ce6de73f92.png" alt="image"><br>  ‚ÄúApproximately 51% of all values ‚Äã‚Äãare compressed to one bit, since the current and previous values ‚Äã‚Äãare identical.  About 30% of the values ‚Äã‚Äãare compressed with the control bits' 10 ‚Ä≤ with an average compression size of 26.6 bits.  The remaining 19% are compressed with the control bits' 11 ‚Ä≤ with an average size of 36.9 bits due to the additional overhead that is needed to encode the length of the leading zero bits and the significant bits. ‚Äù </p><br><p>  <strong>Systems built on top of Gorilla</strong> <br>  Small delays in reading from Gorilla (more than 70 times faster than the previous system, which it replaced) allowed the Facebook team to create a number of tools on top of it.  These include horizon charts;  Aggregated rolaps, which are updated for all completed blocks every two hours;  and the correlation search engine, which, as we saw in the first example. </p><br><p> ‚ÄúThe correlation search engine calculates the Pearson correlation coefficient (PPMCC), which compares the test time series with a large set of time series.  We find that the Pearson correlation ability to find a correspondence between equally looking time series regardless of scale helps significantly automate the analysis of cause-effect relationships and answer the question ‚ÄúWhat else happened when my service broke down?‚Äù.  For us, this approach gives satisfactory answers to such a question and it turned out to be easier to implement than the similar approaches described in the literature [10, 18, 16].  To calculate the Pearson correlation, test time series is distributed to each Gorilla host along with all the keys of the time series.  Then each host independently calculates the N most correlated with the test time series, orders them according to the absolute value of the Pearson correlation, and returns the values ‚Äã‚Äãof the time series found.  In the future, we hope that Gorilla will allow using more advanced data-mining methods for our monitoring data, such as those described in the literature on clustering and anomaly detection [10, 11, 16]. ‚Äù </p><br><p>  Summing up the lessons learned, the authors highlight another 3 further rules: </p><br><p>  Prioritize new, recent, not old data.  That is why something is not working now - a more pressing question than why it did not work 2 days ago.  Low latency of read monitoring data is very important - without this, more advanced tools built on top of Gorilla would not be practical.  High availability is more important than resource efficiency. </p><br><p>  ‚ÄúWe found that building a robust, fault-tolerant system is the most time-consuming part of the project.  Although the team created a prototype of a high-performance, in-memory compressed time series database (TSDB) in a very short amount of time, it took a few more months of hard work to make it resilient.  However, the advantages of resiliency were visible when the system successfully experienced both real and simulated failures. ‚Äù </p></div>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <p>Source: <a href="https://habr.com/ru/post/327038/">https://habr.com/ru/post/327038/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../327020/index.html">TypeScript in Slack, or how to stop worrying and start trusting the compiler</a></li>
<li><a href="../327022/index.html">Forecasting financial time series with MLP in Keras</a></li>
<li><a href="../327024/index.html">List of IT companies that regularly conduct internships for students of southern Russia</a></li>
<li><a href="../327026/index.html">What programming languages ‚Äã‚Äãare popular late at night</a></li>
<li><a href="../327030/index.html">Monad transformers for practicing programmers</a></li>
<li><a href="../327042/index.html">Videos: Moscow Zabbix Meetup in the office of Badoo</a></li>
<li><a href="../327044/index.html">Critical vulnerabilities are discovered in 25 Linksys Smart Wi-Fi devices.</a></li>
<li><a href="../327046/index.html">Performance comparison of the iron server and the Amazon cloud</a></li>
<li><a href="../327048/index.html">Analysis of communication from the Tor network to the infrastructure using the ELK stack</a></li>
<li><a href="../327050/index.html">Internal mechanisms of TCP, affecting the download speed: part 2</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>