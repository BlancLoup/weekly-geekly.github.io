<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>C # or Java? TypeScript or JavaScript? Classification of machine learning based programming languages</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="GitHub features more than 300 programming languages, starting with well-known languages ‚Äã‚Äãsuch as Python, Java, and Javascript, and ending with esoter...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>C # or Java? TypeScript or JavaScript? Classification of machine learning based programming languages</h1><div class="post__text post__text-html js-mediator-article">  GitHub features more than 300 programming languages, starting with well-known languages ‚Äã‚Äãsuch as Python, Java, and Javascript, and ending with esoteric languages ‚Äã‚Äãsuch as <a href="https://en.wikipedia.org/wiki/Esoteric_programming_language">Befunge</a> , known only to small groups of people. <br><img src="https://habrastorage.org/webt/w0/if/pz/w0ifpzugdbh5pntrb1gcamd3s6c.jpeg"><br>  <i>Top 10 programming languages ‚Äã‚Äãhosted on GitHub by number of repositories</i> <br><br>  One of the problems GitHub faces is the recognition of different programming languages.  When some code is placed in the repository, it is very important to recognize its type.  This is necessary for reasons of search, vulnerability alerts, syntax highlighting, and the structural presentation of repository content to users. <br><br>  At first glance, language recognition is a simple task, but this is not entirely true.  <a href="https://github.com/github/linguist">Linguist</a> is a tool that we now use to define a programming language on GitHub.  Linguist is a Ruby application that uses various language recognition strategies, including file name and file extension information.  In addition, it takes into account the Vim or Emacs models, as well as the content at the top of the file (shebang).  Linguist processes the language ambiguity heuristically and, if it does not work out this way, it uses a naive Bayes classifier trained in a small sample of data. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Although Linguist predicts quite well at the file level (84% accuracy), everything breaks down when files are named strange, and even more so when files have no extensions.  This makes Linguist useless for content such as GitHub Gists or code snippets in README, error, and pull requests. <a name="habracut"></a><br><br>  In order to make the definition of a language clearer in the long term, we developed a machine learning classifier called OctoLingua.  It is based on the Artificial Neural Network (ANN) architecture, which can handle language prediction in non-trivial scenarios.  The current version of the model can make predictions for the top 50 programming languages ‚Äã‚Äãon GitHub and is superior to Linguist in accuracy. <br><br><h2>  More about OctoLingua </h2><br>  OctoLingua was written from scratch in Python, Keras with the TensorFlow backend - it was created to be accurate, reliable and easy to maintain.  In this part, we will talk about our data sources, model architecture and performance tests of OctoLingua.  We will also talk about the process of adding the ability to recognize a new language. <br><br><h3>  Data sources </h3><br>  The current version of OctoLingua was trained on files obtained from the <a href="http://www.rosettacode.org/wiki/Rosetta_Code">Rosetta Code</a> and from a set of internal crowdsourse repositories.  We have limited our set of languages ‚Äã‚Äãto 50 most popular on github. <br><br>  The Rosetta Code was a great starting dataset because it contained source code written for the same task, but in different programming languages.  For example, the code for generating <a href="https://github.com/acmeism/RosettaCodeData/tree/master/Task/Fibonacci-sequence/">Fibonacci numbers</a> was introduced in C, C ++, CoffeeScript, D, Java, Julia, and others.  However, the language coverage was not uniform: for some programming languages ‚Äã‚Äãthere were only a few files with code, while for others the files simply contained too little code.  Therefore, it was necessary to supplement our training data set with some additional sources and due to this, significantly improve the coverage of languages ‚Äã‚Äãand the effectiveness of the final model. <br><br>  Our process of adding a new language is not fully automated.  We programmatically collect source code from publicly available repositories on GitHub.  We select only those repositories that meet the minimum qualification criteria, such as having a minimum number of forks covering the target language and covering specific file extensions.  At this stage of data collection, we define the main language of the repository using the classification from Linguist. <br><br><h3>  Signs: Based on previous knowledge </h3><br>  Traditionally, memory-based architectures such as Recurrent Neural Networks (RNN) and Long Short Term Memory Networks (LSTM) are used to solve text-based classification problems with neural networks.  However, differences in programming languages ‚Äã‚Äãin vocabulary, file extensions, structure, library importing style, and other details forced us to come up with another approach that uses all this information, extracting some signs in a tabular form to train our classifier.  Signs are extracted as follows: <br><br><ol><li>  Top 5 special characters in the file </li><li>  Top 20 characters in the file </li><li>  File extension </li><li>  The presence of specific special characters that are used in the source code of files, such as a colon, curly braces, semicolon </li></ol><br><h3>  Model Artificial Neural Network (ANN) </h3><br>  We use the above factors as input for a two-layer neural network built using Keras with a Tensorflow backend. <br><br>  The diagram below shows that the feature extraction step creates n-dimensional table entry for our classifier.  As information travels through the layers of our network, it is ordered using dropouts, and the result is a 51-dimensional output, which represents the probability that the code is written in each of the top 50 languages ‚Äã‚Äãin GitHub.  It also shows the probability that the code is not written in any of these 50 languages. <br><br><div style="text-align:center;"><img width="600" src="https://habrastorage.org/webt/k0/dn/ny/k0dnny9or82qxddtsy7u5v3xn2q.jpeg"></div><br>  <i>ANN-structure of the original model (50 languages ‚Äã‚Äã+ 1 for ‚Äúother‚Äù)</i> <br><br>  We used 90% of our source database for training.  Also at the model training step, some of the file extensions were removed so that the model could learn exactly the vocabulary of the files, and not their extensions that predict the programming language so well. <br><br><h3>  Performance test </h3><br><h4>  OctoLingua vs Linguist </h4><br>  In the table below, we show the <a href="https://en.wikipedia.org/wiki/Precision_and_recall">F1 Score</a> (average harmonic between accuracy and completeness) for OctoLingua and Linguist counted on the same test suite (10% of the volume of our original data source). <br><br>  Three tests are shown here.  In the first test, the dataset was completely untouched;  in the second file extensions were removed;  in the third file extensions were mixed in order to confuse the classifier (for example, the Java file could have the extension ‚Äú.txt‚Äù, and the Python file extension ‚Äú.java‚Äù. <br><br>  The intuition behind mixing or deleting file extensions in our test suite is to assess the reliability of OctoLingua in classifying files when a key attribute is deleted or misleading.  A classifier that does not depend heavily on the extension would be extremely useful for classifying logs and code fragments, since in these cases people usually do not provide accurate information about the extension (for example, many code-related logs have the extension txt.) <br><br>  The table below shows how OctoLingua has a good performance in various conditions, when we assumed that the model learns mainly in the vocabulary of the code, and not in meta-information (for example, in the file extension).  At the same time, Linguist determines the language erroneously, as soon as there was no information about the correct file extension. <br><br><div style="text-align:center;"><img width="400" src="https://habrastorage.org/webt/iz/6h/im/iz6him_wx0j89fve8qcfsfedr-g.jpeg"></div>  <i>OctoLingua vs. Linguist performance on the same test suite</i> <br><br><h4>  Effect of deleting file extensions when training a model </h4><br>  As mentioned earlier, during training, we removed a certain percentage of file extensions from the data in order to force the model to learn the file vocabulary.  The table below shows the performance of our model with different shares of file extensions removed during the training. <br><br><img src="https://habrastorage.org/webt/tp/jv/9c/tpjv9cugo6qbblidgrmoc-loz8m.jpeg"><br>  <i>Efficiency of OctoLingua with different share of deleted file extensions</i> <br><br>  Please note that a model trained on files with extensions is significantly less effective on test files with no extensions or with mixed extensions than on ordinary test data.  On the other hand, when a model is trained on a dataset in which part of the file extensions are deleted, the model's performance is not greatly reduced on a modified test suite.  This confirms that removing extensions from a portion of the files during the training induces our classifier to learn more on code vocabulary.  It also shows that the file extension tended to dominate and prevented more weight being given to featured content. <br><br><h3>  New language support </h3><br>  Adding a new language to OctoLingua is a fairly simple process.  It starts with searching and receiving a large number of files in a new language (we can do it programmatically, as described in the paragraph ‚ÄúData Sources‚Äù).  These files are divided into training and test kits, and then pass through our preprocessor and tracer extractor.  A new dataset is added to the existing pool.  The testing kit allows us to make sure that the accuracy of our model remains acceptable. <br><br><div style="text-align:center;"><img width="600" src="https://habrastorage.org/webt/ty/nb/h4/tynbh4ugzowbnkn6bkcpzfabydg.jpeg"></div><br>  <i>Adding a new language to OctoLingua</i> <br><br><h2>  Our plans </h2><br>  OctoLingua is currently in an ‚Äúadvanced prototyping stage.‚Äù  Our language classification mechanism is already reliable, but it still does not support all the programming languages ‚Äã‚Äãavailable on GitHub.  In addition to expanding language support, which is not so difficult, we strive to provide language detection with different levels of code detail.  Our current implementation already allows us, with a slight modification of our machine learning mechanism, to classify code fragments.  Also, it does not seem like something difficult to take a model to a stage where it can reliably detect and classify embedded languages. <br><br>  We are also considering the possibility of publishing the source code of our model, but we need a request from the community. <br><br><h2>  Conclusion </h2><br>  Our goal in developing OctoLingua is to create a service that provides reliable definition of the source code language at different levels of detail: from the level of files or code fragments to the potential definition and classification of the language at the row level.  All our work on this service is aimed at supporting developers in their daily work on development, as well as creating conditions for writing high-quality code. <br><br>  If you are interested in contributing to our work, please feel free to contact us on Twitter <a href="https://twitter.com/github">@github</a> ! </div><p>Source: <a href="https://habr.com/ru/post/459104/">https://habr.com/ru/post/459104/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../459088/index.html">Ways of Point Segmentation in Point Clouds</a></li>
<li><a href="../459098/index.html">GitHub Package Registry will support Swift packages</a></li>
<li><a href="../4591/index.html">Baring Vostok bought the whole Ozon</a></li>
<li><a href="../45910/index.html">PHP, PREG and UTF-8</a></li>
<li><a href="../459102/index.html">Record as a gift or free music for cola lovers and breakfast cereals</a></li>
<li><a href="../459108/index.html">Tesla is going to present several surprises at once in the second half of this year.</a></li>
<li><a href="../45911/index.html">Twiddler2</a></li>
<li><a href="../459110/index.html">Writing a bot for fishing in the game Albion Online in Python</a></li>
<li><a href="../459116/index.html">One step closer to restoring the thymus</a></li>
<li><a href="../459118/index.html">How we designed and implemented a new network on Huawei in the Moscow office, part 2</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>