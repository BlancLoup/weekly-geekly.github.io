<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Recommender systems: overfitting and regularization</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Constantly declining popularity of previous publications encourages actions to help support popularity. I noticed that the popularity of the first pub...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Recommender systems: overfitting and regularization</h1><div class="post__text post__text-html js-mediator-article">  Constantly declining popularity of previous publications encourages actions to help support popularity.  I noticed that the popularity of the first publications considerably exceeds the subsequent ones;  so try to reboot. <br><br>  Throughout the previous series, we carefully considered the SVD method and even brought it to the program code;  starting with this text, I will consider more general things.  Of course, these things will always be closely connected with recommender systems, and I will talk about how they emerge in recommender systems, but I will try to focus on more general concepts of machine learning.  Today - about overfitting and regularization. <br><img src="https://habrastorage.org/storage2/34c/b30/8ea/34cb308ea0c1b1f348da6db86b88bc30.png"><br><a name="habracut"></a><br><br>  I will start with the classic, but no less illustrative example.  Let's open R (if anyone does not know, <a href="http://www.r-project.org/">R</a> is one of the best tools in the world for all sorts of statistics, machine learning and data processing in general; I highly recommend it) and generate some small simple dataset for ourselves.  I'll take a simple cubic polynomial <img src="https://habrastorage.org/getpro/habr/post_images/296/dc6/c5a/296dc6c5a5fd1bca7464779cdc187017.png">  and add normally distributed noise to its points. <br><pre><code class="matlab hljs">&gt; x &lt;- c(<span class="hljs-number"><span class="hljs-number">0</span></span>:<span class="hljs-number"><span class="hljs-number">6</span></span>) / <span class="hljs-number"><span class="hljs-number">2</span></span> &gt; y_<span class="hljs-built_in"><span class="hljs-built_in">true</span></span> &lt;- <span class="hljs-number"><span class="hljs-number">-.5</span></span>*x^<span class="hljs-number"><span class="hljs-number">3</span></span> + <span class="hljs-number"><span class="hljs-number">2</span></span>*x^<span class="hljs-number"><span class="hljs-number">2</span></span> + x ‚Äì <span class="hljs-number"><span class="hljs-number">3</span></span> &gt; err &lt;- rnorm( <span class="hljs-number"><span class="hljs-number">7</span></span>, <span class="hljs-built_in"><span class="hljs-built_in">mean</span></span>=<span class="hljs-number"><span class="hljs-number">0</span></span>, sd=<span class="hljs-number"><span class="hljs-number">0.4</span></span> ) &gt; y &lt;- y_<span class="hljs-built_in"><span class="hljs-built_in">true</span></span> + err &gt; y [<span class="hljs-number"><span class="hljs-number">1</span></span>] <span class="hljs-number"><span class="hljs-number">-2.3824664</span></span> <span class="hljs-number"><span class="hljs-number">-2.1832300</span></span> <span class="hljs-number"><span class="hljs-number">-0.7187618</span></span> <span class="hljs-number"><span class="hljs-number">1.7105423</span></span> <span class="hljs-number"><span class="hljs-number">2.1338531</span></span> <span class="hljs-number"><span class="hljs-number">4.7356023</span></span> <span class="hljs-number"><span class="hljs-number">5.0291615</span></span></code> </pre> 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      These points can now be drawn along with the ideal curve. <br><pre> <code class="matlab hljs">&gt; curve(<span class="hljs-number"><span class="hljs-number">-.5</span></span>*x^<span class="hljs-number"><span class="hljs-number">3</span></span> + <span class="hljs-number"><span class="hljs-number">2</span></span>*x^<span class="hljs-number"><span class="hljs-number">2</span></span> + x - <span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">-1</span></span>, <span class="hljs-number"><span class="hljs-number">4</span></span>, ylim=c(<span class="hljs-number"><span class="hljs-number">-5</span></span>,<span class="hljs-number"><span class="hljs-number">6</span></span>) ) &gt; points(x, y, pch=<span class="hljs-number"><span class="hljs-number">21</span></span>, bg=<span class="hljs-string"><span class="hljs-string">"red"</span></span>)</code> </pre><br>  It turns out as shown: <br><img src="https://habrastorage.org/storage2/f79/6fe/dd4/f796fedd432691cffd42c5d12e752c4c.png"><br><br>  And now let's try to train a polynomial from this data.  We will minimize the sum of squares of deviations of points from the polynomial (we will do the most usual classical regression), that is, we will look for such a polynomial p (x) that minimizes <img src="https://habrastorage.org/getpro/habr/post_images/28d/a4c/ced/28da4ccedd7f27f58ff7c5199b78cc9c.png">  . <br><br>  Of course, in R this is done by one team.  First, we teach and draw a linear polynomial: <br><pre> <code class="matlab hljs">&gt; m1 &lt;- lm ( y ~ poly(x, <span class="hljs-number"><span class="hljs-number">1</span></span>, raw=TRUE) ) &gt; pol1 &lt;- <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(x)</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">m1</span></span></span><span class="hljs-function">$</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">coefficients</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">[1]</span></span></span><span class="hljs-function"> + </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">m1</span></span></span><span class="hljs-function">$</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">coefficients</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">[2]</span></span></span><span class="hljs-function"> * </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">x</span></span></span><span class="hljs-function"> &gt; </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">curve</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(pol1, col="green", lwd=2, add=TRUE)</span></span></span></span></code> </pre><br><img src="https://habrastorage.org/storage2/077/12c/184/07712c184914ad1de34d511a6e25fec0.png"><br><br>  Then a second degree polynomial: <br><pre> <code class="matlab hljs">&gt; m2 &lt;- lm ( y ~ poly(x, <span class="hljs-number"><span class="hljs-number">2</span></span>, raw=TRUE) ) &gt; pol2 &lt;- <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(x)</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">m2</span></span></span><span class="hljs-function">$</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">coefficients</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">[1]</span></span></span><span class="hljs-function"> + </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">m1</span></span></span><span class="hljs-function">$</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">coefficients</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">[2]</span></span></span><span class="hljs-function"> * </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">x</span></span></span><span class="hljs-function"> + </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">m1</span></span></span><span class="hljs-function">$</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">coefficients</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">[3]</span></span></span><span class="hljs-function"> * </span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(x^2)</span></span></span><span class="hljs-function"> &gt; </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">curve</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(pol2, col="blue", lwd=2, add=TRUE)</span></span></span></span></code> </pre><br><img src="https://habrastorage.org/storage2/2f2/12d/b2c/2f212db2cddfeddf3b36f210102fefc3.png"><br><br>  The third degree polynomial, as expected, is already quite similar to itself: <br><img src="https://habrastorage.org/storage2/889/25a/83b/88925a83baaf4a482d96dfdc383095df.png"><br><br>  But what happens if you increase the degree further?  In practice, we most likely will not know the ‚Äútrue degree of a polynomial‚Äù, i.e.  true complexity of the model.  It may seem that, by complicating the model, we will better approximate the existing points, and the results will be better and better, just to train the model will be harder and harder.  Let's see if this is true. <br><br>  The fifth degree polynomial already looks very suspicious - it is, of course, still well-behaved between points, but it is already clear that it will not be good to extrapolate using this model - it starts to go too sharply to infinity as soon as the points end. <br><img src="https://habrastorage.org/storage2/482/628/8d9/4826288d9efb9e7eba3c77a88b02f6c3.png"><br><br>  Starting from the sixth degree, we see the undoubted epic fail of our approach.  The error that we wanted to minimize is now strictly equal to zero ‚Äî after all, a polynomial of the sixth degree can be drawn through seven points!  But the benefits of the resulting model, too, are probably strictly zero - now the polynomial not only badly extrapolates beyond the existing points, but even interpolates between them extremely strange, running far to local extremes where it is difficult to expect this from the points. <br><img src="https://habrastorage.org/storage2/4f5/f46/524/4f5f46524e4ed8b03b0ca1f4f7c8834d.png"><br><br>  What happened?  What happened in machine learning is called overfitting: we took a model in which there were too many parameters, and the model learned too well from the data, and most importantly, the predictive power ‚Äî on the contrary, it suffered. <br><br>  What to do?  In the next series I will tell you how this can turn out to be more conceptual, but now let's just take it for granted: overfitting in this case is manifested in the fact that the resulting polynomials have too large coefficients.  For example, here is a third degree polynomial that we taught: <br><img src="https://habrastorage.org/getpro/habr/post_images/d5d/350/e2f/d5d350e2f429a6a5fa81ad9e259ed137.png">  , <br>  but feel the difference - the sixth degree: <br><img src="https://habrastorage.org/getpro/habr/post_images/45a/632/c4e/45a632c4e0e75dd38e282dc64417164a.png">  . <br><br>  Accordingly, it is possible to deal with this in a rather natural way: you just need to add a penalty to the objective function that would punish the model for too large coefficients: <br><img src="https://habrastorage.org/getpro/habr/post_images/78b/148/6dd/78b1486dd3ac191968e76f03f477ca1e.png">  . <br><br>  This overfitting would often occur in SVD if we allowed it to happen.  Indeed, we introduce for each user and each product a number of free parameters equal to the number of factors (i.e. at least a few, and maybe a few dozen).  Therefore, SVD without regularization is completely inapplicable - it will certainly be good to learn, but it will most likely be practically useless for predictions. <br><br>  Regularizers in SVD work in the same way as in regular regression - we add a penalty, which is greater, the greater the size of the coefficients;  in <a href="http://habrahabr.ru/company/surfingbird/blog/140555/">one of the previous series,</a> I immediately followed the regularizers and wrote out the objective function: <br><img src="https://habrastorage.org/getpro/habr/post_images/d40/a51/533/d40a51533433a1f73faec4615808d18a.png"><br>  The formulas of the gradient lift are given in the same place - the coefficient Œª corresponds to the regularization in them. <br><br>  However, while it all looks pretty mysterious - why would suddenly large coefficients be worse than small ones?  In the future, I will talk about how you can look at this issue from a more conceptual <i>Bayesian</i> side. </div><p>Source: <a href="https://habr.com/ru/post/143455/">https://habr.com/ru/post/143455/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../143450/index.html">garage48 for the first time in Kiev!</a></li>
<li><a href="../143451/index.html">A vulnerability was found inside the HTTP server embedded in Node.</a></li>
<li><a href="../143452/index.html">Google HTML / CSS Code Guide</a></li>
<li><a href="../143453/index.html">Who are they, indie iOS developers?</a></li>
<li><a href="../143454/index.html">Solving the wrong problem</a></li>
<li><a href="../143456/index.html">Old Compaq Armada 7730MT</a></li>
<li><a href="../143457/index.html">Video demo of Tizen</a></li>
<li><a href="../143459/index.html">Google got a car license in Nevada</a></li>
<li><a href="../143460/index.html">Ubuntu plans to cover 5% of the market for new PCs</a></li>
<li><a href="../143461/index.html">Find IT Forum</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>