<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>The future of artificial intelligence</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="In the previous article, we described the past and present of artificial intelligence - what AI looks like today, the difference between strong and we...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>The future of artificial intelligence</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/files/81f/d29/4eb/81fd294eba414235827268cbaeec9fcb.jpg"><br><br>  In the <a href="https://geektimes.ru/post/286554/">previous article,</a> we described the past and present of artificial intelligence - what AI looks like today, the difference between strong and weak AI, OII, and some philosophical ideas about the nature of consciousness.  Weak AI can be found anywhere in the form of software designed to intelligently perform certain tasks.  The final goal is a strong AI, and it is the real strong AI that will resemble what is familiar to us from popular fiction. <br><br>  Generalized AI is a modern goal that many researchers devote their careers to today.  OII does not need to have some kind of consciousness, but it must cope with any task related to the data we set for it.  Of course, in the nature of people there is a desire to predict the future, and this is what we will do in this article.  What are the best guesses we can make about AI-related expectations in the near future?  What ethical and practical problems can arise with the emergence of a conscious AI?  In the expected future, should the AI ‚Äã‚Äãhave rights, or, for example, should it be feared? <br><a name="habracut"></a><br><h2>  Future AI </h2><br>  The optimism of AI researchers over the future has changed over the years, and even modern experts are arguing about it.  Trevor Sands, Lockheed Martin's AI explorer, is cautious in his assessments: 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Since the advent of OII as a concept, researchers and optimists have argued that it‚Äôs not long to wait, just a few decades.  Personally, I think that we will see the emergence of the AII in the next 50 years, because iron has been brought up to the level of theory, and more and more organizations see the potential in AI.  AIS is a natural conclusion to existing attempts at investigating AI. <br><br>  During this time, even a reasonable AI can appear, as Albert says (another AI researcher who asked us to mention him only by pseudonym): <br><br>  I hope that I will see him during his lifetime.  At the very least, I hope to see cars that are smart enough for people to argue whether they have consciousness.  And what this really means is a more complicated question.  If the mind means "self-awareness", then it is not so difficult to imagine a smart machine with a model of itself. <br><br>  Sands and Albert believe that today's research on neural networks and in-depth training is the right way, which is likely to lead to the creation of IES in the near future.  In the past, researchers either focused on ambitious attempts to create a strong AI, or on an essentially weak AI.  Between them is the OII, and so far the result of the work of neural networks looks fruitful, and most likely will lead to an even greater number of breakthroughs in the coming years.  Large companies, in particular, Google, clearly <a href="https://research.google.com/pubs/MachineIntelligence.html">believe that this will happen</a> . <br><br><h2>  Implications and ethical problems of strong AI </h2><br>  With each discussion of AI, there are always two problems: how will it affect humanity, and how do we relate to it?  Literature can always be viewed as a good indicator of thoughts and feelings, reflecting people's moods, and science fiction is full of examples of these problems.  Will sufficiently advanced AI try to eliminate humanity like <a href="http://www.imdb.com/title/tt0103064/">Skynet</a> ?  Or will the AI ‚Äã‚Äãneed to be given rights and protection in order to avoid such acts of cruelty as are found in <a href="http://www.imdb.com/title/tt0212720/">AI Artificial Intelligence</a> ? <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/097/a83/099/097a83099c3a0f0de8ccad4501ffdd67.jpg" alt="image"><br>  <i>Scary AI</i> <br><br>  In both cases, the point is that with the creation of a true AI, a <a href="http://electronics.howstuffworks.com/gadgets/high-tech-gadgets/technological-singularity.htm">technological singularity</a> will come.  Technological singularity - a period of exponential growth of technology, occurring in a small time period.  The idea is that AI can improve itself or produce more advanced AI.  Since this will happen quickly, cardinal changes can happen in one day, and as a result, an AI will appear much more perfect than the one created by mankind.  This may mean that as a result we will have a super-intelligent and unfriendly AI, or a reasonable AI, worthy to have rights. <br><br><h2>  Negative AI </h2><br>  What if this hypothetical super-intelligent AI decides that humanity does not like it?  Or will we be indifferent to him?  Do I need to be afraid of this opportunity and take precautions?  Or are these fears the results of unfounded paranoia? <br><br>  Sands says: ‚ÄúOII will make a revolution, and its application will determine whether it will be positive, or negative.  Approximately the same splitting of the atom can be considered as a double-edged sword. "  Of course, here we are talking only about OII, and not about a strong AI.  What about the possibility of the emergence of a reasonable strong AI? <br><br>  Most likely, the potential can be expected not from the malicious, but from the indifferent AI.  Albert considers an example with a simple task set by the AI: ‚ÄúThere is such a story that the owner of the factory for the production of paper clips asked the AI ‚Äã‚Äãa seemingly simple task: to maximize production.  And then OII used his intellect and figured out how to turn the entire planet into paper clips! ‚Äù <br><br>  Albert rejects the possibility described in this ridiculous thought experiment: ‚ÄúYou want to say that this OII understands human speech, is super-intelligent, but the subtleties associated with the query are not available to it?  Or that he will not be able to ask clarifying questions, or guess that turning all people into paper clips is a bad idea? ‚Äù <br><br>  That is, if the AI ‚Äã‚Äãis smart enough to understand and run a dangerous scenario for people, it must be smart enough to understand that this is not worth doing.  The three laws of Asimov‚Äôs robotics can also play a role, although the question remains: can they be implemented in such a way that the AI ‚Äã‚Äãcannot change them?  What about the well-being of the AI ‚Äã‚Äãitself? <br><br><h2>  AI rights </h2><br>  On the opposite side of the problem is the question, does the AI ‚Äã‚Äãdeserve protection and rights?  If a reasonable AI had appeared, could a person be allowed to simply turn it off?  How to treat him?  Animal rights are still very controversial, and so far there is <a href="https://en.wikipedia.org/wiki/Animal_consciousness">no agreement on whether animals possess consciousness or intelligence</a> . <br><br>  Apparently, the same disputes will unfold over creatures with AI.  Will slavery make AI work day and night for the benefit of humanity?  Should we pay him for the services?  What will AI do with this payment? <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/b31/2b7/888/b312b788859dd77c0a90f4723fc11456.jpg"><br>  <i>The film is bad, the idea is good</i> <br><br>  It is unlikely that in the near future we will have answers to these questions, in particular, answers that suit everyone.  ‚ÄúHow can we guarantee that an AI, comparable to a person, will have the same rights as a person?  Given that this intellectual system is fundamentally different from human, how can we determine the fundamental rights of AI?  In addition, if we consider AI as an artificial form of life, do we have the right to take away this life from it (turn it off)?  Before you create an OII, you need to seriously consider ethical issues, ‚Äùsays Sands. <br><br>  As the study of AI continues, these and other ethical questions will undoubtedly be controversial.  Apparently, we are still quite far from the moment when they will be relevant.  But even now, <a href="https://futureoflife.org/">conferences are being organized to</a> discuss them. <br><br><h2>  How to participate </h2><br>  Research and experiments with AI have traditionally been managed by scientists and researchers from corporate laboratories.  But in recent years, the growing popularity of free information and open source has spread even to AI.  If you are interested in doing future AI, there are several ways to do this. <br><br>  You can conduct independent experiments with AI using available software.  Google has <a href="http://playground.tensorflow.org/">a browser built-in sandbox</a> for working with simple neural networks.  Libraries are available on open source neural networks, for example, <a href="http://www.opennn.net/">OpenNN</a> and <a href="https://www.tensorflow.org/">TensorFlow</a> .  They are not so easy to use, but purposeful <a href="http://hackaday.com/2016/12/11/train-your-robot-to-walk-with-a-neural-network/">hobby lovers</a> can turn around at their base. <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/78d/633/1c8/78d6331c8bd003a4fe849cfdc721b1c6.png"><br><br>  The best way is to do everything you can to advance professional research.  In the US, this means the promotion of scientific research.  AI research, like any scientific research, depends on unforeseen circumstances.  If you believe that technological innovation has a future, then assistance in obtaining research funding is a worthy occupation. <br><br>  Over the years, optimism about the development of AI has hesitated.  Now we are at the peak, but it is quite possible that this will change.  But it can not be denied that the possibility of AI spurs the public's imagination.  This is obvious, judging by science fiction and other entertainment.  A strong AI may appear after a couple of years or a couple of centuries.  One can only be sure that we will not stop on the way to this goal. </div><p>Source: <a href="https://habr.com/ru/post/370235/">https://habr.com/ru/post/370235/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../370225/index.html">‚ÄúAvtorayzer‚Äù: password-free decentralized authorization through OAuth 2.0 on the Emercoin blockchain</a></li>
<li><a href="../370227/index.html">Gearbest checked: rumors about women are greatly exaggerated</a></li>
<li><a href="../370229/index.html">The colony. Chapter 6: Morning at a military base</a></li>
<li><a href="../370231/index.html">How it is done. Coworking</a></li>
<li><a href="../370233/index.html">Artificial intelligence and ghost in the car</a></li>
<li><a href="../370237/index.html">The future is no longer what it used to be: the virtual becomes real</a></li>
<li><a href="../370239/index.html">How to understand that before you "half-baked" blockchain</a></li>
<li><a href="../370241/index.html">"Flying midges" and "glassy worms" in the eyes, or where do "broken pixels" in the vitreous body come from</a></li>
<li><a href="../370243/index.html">Google Translate connected Russian language to translation with deep learning.</a></li>
<li><a href="../370245/index.html">The refusal to grow plants that are resistant to pests can be equated with the ban on resistant GM varieties.</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>