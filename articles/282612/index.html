<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>P2P in the browser</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Author: Alexander Trischenko 


 I will talk about my hobby - organizing video broadcasts in a browser using the WebRTC technology (Web Real-Time Comm...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>P2P in the browser</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/files/aa9/3cf/050/aa93cf050df949499b04eae09665dc91.png"><br>  Author: Alexander Trischenko <br><br><br>  I will talk about my hobby - organizing video broadcasts in a browser using the WebRTC technology (Web Real-Time Communication - real-time web communication).  Google has been actively developing this open source project since 2012, and the first stable release appeared in 2013. Now WebRTC is already well <a href="http://iswebrtcreadyyet.com/">supported by the</a> most common modern browsers, with the exception of Safari. <br><br>  The WebRTC technology allows video conferencing between two or more users using the P2P principle.  Thus, data between users is transmitted directly, and not through the server.  However, we still need the server, but I‚Äôll say this later.  First of all, WebRTC is designed to work in the browser, but there are also libraries for different platforms, which also allow you to use a WebRTC connection. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      If we use WebRTC, we solve the following problems: <br><br><ul><li>  <strong>We reduce the cost of maintaining servers.</strong>  Servers are only needed to initialize the connection and for users to share network information about each other.  They are also used to send some events, for example, alerts about connecting and disconnecting users (so that the information on each client is relevant). </li><li>  <strong>We increase the speed of data transfer</strong> and reduce the delay in transmitting video and sound - because the server is not needed for this. </li><li>  <strong>We strengthen data privacy</strong> : there is no third party through which the data flow would go (of course, with the exception of gateways, through which the data passes before the network is reached). </li></ul><br><a name="habracut"></a><br><h3>  Connection initialization </h3><br><br>  <strong>JavaScript Session Establishment Protocol</strong> <br><br>  The connection is initialized using the JavaScript Session Establishment protocol - now there is only a <a href="http://tools.ietf.org/html/draft-ietf-rtcweb-jsep-03">draft</a> that describes the specification of this solution.  It describes: <br><br><ul><li>  the process of connecting to the server; </li><li>  generation of a unique token for a new user, which will allow identifying it on the back-end; </li><li>  getting the user key to access the conversation - signaling; </li><li>  initializing RTCStreamConnection to connect two users; </li><li>  All participants receive a broadcast message about a new participant. </li></ul><br><br>  A new participant joins a video conference in the following way: we send a message to this user that we are already having a video conference, the user sends a connection request, which we satisfy by sending him all the necessary information to connect.  At the same time, we will send information to all conference participants to connect with the new user. <br><br>  How it works?  There is a browser level that allows clients to directly exchange media data, and there is a signaling server level at which the rest of the interaction between clients takes place: <br><br><img src="https://habrastorage.org/files/b6d/474/115/b6d474115a324341a5b80afae800721e.png"><br><br>  <strong>Session Description Protocol</strong> <br><br>  For the session description protocol (SDP - Session Description Protocol), which allows you to describe information about a specific user, there is already an approved <a href="https://tools.ietf.org/html/rfc4566">RFC 4556</a> specification. <br><br>  SDP describes the following parameters: <br><br><img src="https://habrastorage.org/files/d99/34f/dc9/d9934fdc90a248ae857123e2c50fbc36.png"><br><br><ul><li>  v = (protocol version; now version is always 0); </li><li>  o = (identifiers of the creator / owner and session); </li><li>  s = (session name, cannot be empty); </li><li>  i = * (information about the session); </li><li>  u = * (URL used by WWW clients, with additional information about the session); </li><li>  e = * (e-mail of the person responsible for the conference); </li><li>  p = * (telephone number of the person responsible for the conference); </li><li>  c = * (information for the connection is not required if it is in the description of all media data); </li><li>  b = * (information about the occupied bandwidth of the communication channel); </li><li>  one or more lines with description of time parameters (see example below); </li><li>  z = * (setting for the time zone); </li><li>  k = * (encryption key); </li><li>  a = * (one or more lines describing session attributes, see below). </li></ul><br><br>  SDP information about a client looks like this: <br><br>  <strong>Interactive Connectivity Establishment (ICE)</strong> <br><br>  ICE technology allows users who are behind the firewall to connect.  It includes four specifications: <br><br><ul><li>  RFC 5389: Session Traversal Utilities for NAT ( <strong>STUN</strong> ). </li><li>  RFC 5766: Traversal Using Relays around NAT ( <strong>TURN</strong> ): Relay Extensions to STUN. </li><li>  RFC 5245: Interactive Connectivity Establishment ( <strong>ICE</strong> ): A Protocol for NAT Traversal for Offer / Answer Protocols. </li><li>  RFC 6544: <strong>TCP Candidates</strong> with Interactive Connectivity Establishment (ICE) </li></ul><br><br>  STUN is a client-server protocol that is actively used for VoIP.  The STUN server is considered a priority here: it allows you to route UDP traffic.  If we cannot use the STUN server, WebRTC will try to connect to the TURN server.  Also in the list is the RFC for the ICE itself and the RFC for TCP candidates. <br><br>  The client implementation for ICE servers in WebRTC is already preinstalled, so we can simply specify multiple STUN or TURN servers.  Moreover, to do this, during initialization, it is enough just to transfer an object with the appropriate parameters (hereinafter, I will give examples). <br><br>  <strong>GetUserMedia API</strong> <br><br>  One of the most interesting parts of the WebRTC API is the GetUserMedia API, which allows you to capture audio and video information directly from the client and broadcast it to other feasts.  This API is actively promoting Google - so, since the end of 2014, Hangouts has been working entirely on WebRTC.  Also GetUserMedia fully works in Chrome, Firefox and Opera;  There is also an extension that allows you to work with WebRTC on IE.  Safari doesn‚Äôt support this technology. <br><br>  It is important to keep in mind that, according to the recently released restriction, the Chrome GetUserMedia API will work <strong>only</strong> under HTTPS on the beacon server.  Therefore, many examples that lie on the HTTP servers will not work for you. <br><br>  Interestingly, before the GetUserMedia API allowed to broadcast the screen, but now there is no such possibility - there are only custom solutions using add-ons, or you can enable the corresponding flag in Firefox during development. <br><br>  Now GetUserMedia has the following features: <br><br><ul><li>  selection of the minimum, ‚Äúideal‚Äù and maximum resolution for the video stream, which implies the ability to change the video resolution depending on the connection speed; </li><li>  the ability to choose any of the cameras on the phone; </li><li>  the ability to specify the frame rate. </li></ul><br><br>  All this is very easy to set up.  When we call the GetUserMedia API, we pass in an object that has two properties, ‚Äúaudio‚Äù and ‚Äúvideo‚Äù: <br><br><pre><code class="javascript hljs">{ <span class="hljs-attr"><span class="hljs-attr">audio</span></span>: <span class="hljs-literal"><span class="hljs-literal">true</span></span>, <span class="hljs-attr"><span class="hljs-attr">video</span></span>: { <span class="hljs-attr"><span class="hljs-attr">width</span></span>: <span class="hljs-number"><span class="hljs-number">1280</span></span>, <span class="hljs-attr"><span class="hljs-attr">height</span></span>: <span class="hljs-number"><span class="hljs-number">720</span></span> } }</code> </pre> <br><br>  Where video is, there can also be ‚Äútrue‚Äù - then the settings will be the default.  If it is ‚Äúfalse‚Äù, the audio or video will be disabled.  We can configure the video - specify the width and height.  Or we can, for example, set the minimum, ideal and maximum width: <br><br><pre> <code class="javascript hljs">width: { <span class="hljs-attr"><span class="hljs-attr">min</span></span>: <span class="hljs-number"><span class="hljs-number">1280</span></span> }</code> </pre> <br><br><pre> <code class="javascript hljs">width: { <span class="hljs-attr"><span class="hljs-attr">min</span></span>: <span class="hljs-number"><span class="hljs-number">1024</span></span>, <span class="hljs-attr"><span class="hljs-attr">ideal</span></span>: <span class="hljs-number"><span class="hljs-number">1280</span></span>, <span class="hljs-attr"><span class="hljs-attr">max</span></span>: <span class="hljs-number"><span class="hljs-number">1920</span></span> }</code> </pre> <br><br>  And this is how we choose the camera we want to use (‚Äúuser‚Äù - front, ‚Äúenvironment‚Äù - back): <br><br><pre> <code class="javascript hljs">video: { <span class="hljs-attr"><span class="hljs-attr">facingMode</span></span>: <span class="hljs-string"><span class="hljs-string">"user"</span></span> }</code> </pre> <br><br><pre> <code class="javascript hljs">video: { <span class="hljs-attr"><span class="hljs-attr">facingMode</span></span>: <span class="hljs-string"><span class="hljs-string">"environment"</span></span> }</code> </pre> <br><br>  We can also specify the minimum, ideal and maximum frame rate, which will be selected depending on the connection speed and computer resources: <br><br><pre> <code class="javascript hljs">video: { <span class="hljs-attr"><span class="hljs-attr">frameRate</span></span>: { <span class="hljs-attr"><span class="hljs-attr">ideal</span></span>: <span class="hljs-number"><span class="hljs-number">10</span></span>, <span class="hljs-attr"><span class="hljs-attr">max</span></span>: <span class="hljs-number"><span class="hljs-number">15</span></span> }</code> </pre> <br><br>  These are the features of the GetUserMedia API.  On the other hand, it clearly lacks the ability to determine the bitrate of the video and audio stream and the ability to somehow work with the stream before its actual transmission.  Also, of course, it would not hurt to return the possibility of screen broadcast, which was present earlier. <br><br><h3>  WebRTC Features </h3><br><br>  WebRTC allows us to change the audio and video codecs - you can specify them directly in the transmitted information SDP.  In general, WebRTC uses two audio codecs, G711 and OPUS (automatically selected depending on the browser), as well as the VP8 video format (Google's WebM, which works fine with HTML5 video). <br><br>  The WebRTC technology is more or less supported in Chromium 17+, Opera 12+, Firefox 22+.  For other browsers, you can use the webrtc4all extension, but I personally could not run it on Safari.  There are also C ++ libraries for WebRTC support - most likely, this suggests that in the future we will be able to see WebRTC implementations as desktop applications. <br><br>  For security purposes, DTLS is used, the transport layer security protocol, which is described in RFC 6347. And, as I said before, users who connect to NAT and firewalls use TURN and STUN servers. <br><br><h3>  Routing </h3><br><br>  Now let's take a closer look at how routing is performed using STUN and TURN. <br><br>  <a href="https://tools.ietf.org/html/rfc5766">Traversal Using Relay NAT</a> ( <strong>TURN</strong> ) is a protocol that allows a node behind a NAT or firewall to receive incoming data via TCP or UDP connections.  This is an old technology, so the priority is to use Session Traversal Utilities for NAT ( <strong>STUN</strong> ) - a network protocol that allows you to establish only a UDP connection. <br><br>  To ensure fault tolerance, it is possible to select several STUN servers, as shown in the <a href="https://www.webrtc-experiment.com/issues/on-iceserver-down.html">instructions</a> .  And you can test the connection to STUN- and TURN-servers <a href="https://webrtc.github.io/samples/src/content/peerconnection/trickle-ice">here</a> . <br><br>  STUN- and TURN-servers work as follows.  Suppose there are two clients with internal IP and external access to the network through firewalls: <br><br><img src="https://habrastorage.org/files/010/83e/ed0/01083eed0d6b4192858dd20155813187.png"><br><br>  To connect these two clients and redirect all the ports, we need to use STUN and TURN servers, after which the necessary information is transmitted to the user and a direct connection between the computers is established. <br><br>  <strong>Algorithm of working with ICE-servers</strong> <br><br><ul><li>  Provide access to the STUN server at the time of initialization RTCPeerConnection.  You can use public STUN servers (for example, from Google). </li><li>  Listen to the connection initialization event and, if successful, start streaming. </li><li>  In case of an error, make a request to the TURN server and try to connect clients through it. </li><li>  Take care of sufficient bandwidth of the TURN server. </li></ul><br><br>  <strong>Performance and speed of video streaming</strong> <br><br><ul><li>  720p at 30 FPS: 1.0 ~ 2.0 Mbps </li><li>  360p at 30 FPS: 0.5 ~ 1.0 Mbps </li><li>  180p at 30 FPS: 0.1 ~ 0.5 Mbps </li></ul><br><br>  The greatest impact on the performance of WebRTC traffic, which should be allocated to broadcast video.  If only two users participate in the broadcast, then it is possible to organize without problems even FullHD, in the case of a videoconference for 20 people we will have problems. <br><br>  Here, for example, the results obtained with the MacBook Air 2015 (4 GB of RAM, Core i processor at 2 GHz).  Simply implementing GetUserMedia loads the processor by 11%.  When the Chrome-Chrome connection is initialized, the processor is already loaded by 50%, if three Chrome are 70% loaded, four are full CPU usage, and the fifth client leads to the brakes, and WebRTC eventually crashes.  On mobile browsers, of course, it is even worse: I managed to connect only two users, and when I tried to connect a third, everything began to slow down and the connection was broken. <br><br>  How can this be handled? <br><br><h3>  Scaling and problem solving </h3><br><br>  So what do we have?  For each conference user, you must open your UDP connection and transfer data.  As a result, one user needs 1-2 mebagit to broadcast 480p video with sound, and 2-4 megabits in the case of two-way communication.  A heavy load is placed on the iron of the translator. <br><br>  The performance problem is solved by using a proxy server (relay), which will receive data from the broadcaster, if it is a conference, and distribute it to everyone else.  If necessary, for this you can use not one server, but several. <br><br>  It is also worth considering that if we conduct video broadcasting, we transmit a lot of redundant client information, which we can refuse.  For example, when conducting a course, we may need from others only sound without video or even just a message.  Also, after changing the active speaker, it may make sense to interrupt one of the connections, change the type of information that we receive in the stream, and then reconnect.  This allows you to optimize the network load. <br><br>  It is important to take into account the software limitations - we can connect up to 256 peers to a single WebRTC instance.  This makes it impossible for us to use, for example, some huge and expensive instance on Amazon for scaling, because sooner or later we will have to connect several servers to each other. <br><br>  <strong>CreateOffer API</strong> <br><br>  How does all this work?  There is a CreateOffer () API, which allows you to create SDP-data that we will send: <br><br><img src="https://habrastorage.org/files/ee3/d78/f60/ee3d78f608ad4cd99f818de3949bfa44.png"><br><br>  CreateOffer - promise, which, after creating an offer, allows you to directly receive a localDescription, place an offer in it and use it as an SDP field in the future.  sendToServer is an abstract function for a request to the server, where the name of our machine is written (name), the name of the target machine (target), the type of offer and SDP. <br><br>  I want to say a few words about the server: for these purposes it is very convenient to use WebSocket.  As soon as someone connects, we can emit an event and add a listener to it.  It will also be quite easy for us to emit our events with the client. <br><br>  <strong>GetUserMedia API in action</strong> <br><br>  In real life, everything can be done a little easier - we can refer to the GetUserMedia API.  Here is how the call initialization looks like: <br><br><img src="https://habrastorage.org/files/12e/17f/12e/12e17f12ee4449b99a2b88c65fa37112.png"><br><br>  Here we want to transmit both video and sound.  At the output, we get a promise, which takes the mediaStream object (this is the data stream). <br><br>  And this is how we answer the call: <br><br><img src="https://habrastorage.org/files/cc3/bf3/a26/cc3bf3a26ca34fd486518786f7375663.png"><br><br>  When someone wants to answer a call, he receives our offer (getRemoteOffer ‚Äî an abstract function that receives our data from the server).  Then getUserMedia initializes streaming, and I already told about onaddstream and addstream.  setRemoteDescription - we initialize this for our RTC and specify it as an offer and pass the answer.  send the answer ... ‚Üí here we simply describe the process of transferring the offer to the server, after which the connection between the browsers and the start of the broadcast take place. <br><br><h3>  Client-server architecture for WebRTC </h3><br><br>  How does all this look if we scale through the server?  As usual client-server architecture: <br><br><img src="https://habrastorage.org/files/b27/57c/e83/b2757ce83ae443ca98419c41ca65f0a0.png"><br><br>  Here, there is a WebSocket connection and an RTCPeerConnection between the broadcast and the web server that relays the stream.  The rest set up RTCPeerConnections.  Information about the translator can be obtained by pooling, you can save on the number of WebSocket-connections. <br><br>  There are not very many ways to scale such an architecture, and they are all similar.  We can: <br><br><ul><li>  Increase the number of servers. </li><li>  Place the servers in the areas with the largest concentration of the target audience. </li><li>  Provide excess performance - because the technology is still actively developing, so that malfunctions are possible. </li></ul><br><br><h3>  Increase fault tolerance </h3><br><br>  First, to improve fault tolerance, it makes sense to separate the server beacon and the relay server.  We can use a WebSocket server that will distribute network information about clients.  The relay server will communicate with the WebSocket server and broadcast the media stream through itself. <br><br>  Further, we can arrange the ability to quickly switch from one broadcasting server to another in the event of a priority failure. <br><br>  For the extreme case, it is possible to envisage the possibility of establishing a direct connection between users in case of failure of the broadcasting servers, but this is only suitable in the case when there are few people in our conference (less than 10). <br><br><h3>  Display Media Stream </h3><br><br>  Here is an example of how we can display the flow that is exchanged between clients: <br><br><img src="https://habrastorage.org/files/4c1/2ec/f9c/4c12ecf9c057496a82d3fabac0504573.png"><br><br>  onaddstream - we add a listener.  When a listener is added, we create a video element, add this element to our page, and specify the stream as the source.  That is, to see all this in the browser, simply specify the source HTML5 video as the stream that was received.  Everything is very simple. <br><br>  If the call is completed (endCall method), we go through the video elements, stop these videos and close the peer connection so that there are no artifacts and freezes.  In case of an error, we complete the call in the same way. <br><br><h3>  Useful Libraries </h3><br><br>  Finally, some libraries that you can use to work with WebRTC.  They allow you to write a simple client in a few dozen lines: <br><br><ul><li>  Simple peer - I really like this library, which solves the problem of creating a connection between two users. </li><li>  Easyrtc - allows you to create video conferences. </li><li>  SimpleWebRTC is a similar library. </li><li>  js-platform / p2p. </li><li>  node-webrtc - the library allows you to organize a server beacon. </li></ul></div><p>Source: <a href="https://habr.com/ru/post/282612/">https://habr.com/ru/post/282612/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../282602/index.html">(Why) Mail.Ru Mail includes strict DMARC</a></li>
<li><a href="../282604/index.html">Blast Wave in Unity3D (displacement shader)</a></li>
<li><a href="../282606/index.html">Spring Go to Badoo</a></li>
<li><a href="../282608/index.html">Acronis Man: First lecture at MIPT (with online broadcast)</a></li>
<li><a href="../282610/index.html">Haordic Organization Visa (Part 2)</a></li>
<li><a href="../282614/index.html">Oracle Cloud Solution Overview</a></li>
<li><a href="../282616/index.html">Congratulations on holidays and giving discounts on virtual Windows servers VPS</a></li>
<li><a href="../282618/index.html">Creating a Good Cat Gone Bad Game</a></li>
<li><a href="../282620/index.html">New high-speed access protocol on the derivatives market of the Moscow Exchange</a></li>
<li><a href="../282622/index.html">March Python Meetup: Python VS Erlang and PostgreSQL Features</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>