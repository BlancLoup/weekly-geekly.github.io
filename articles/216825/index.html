<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>The logic of thinking. Part 16. Batch presentation of information</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="This series of articles describes a wave model of the brain that is seriously different from traditional models. I strongly recommend that those who h...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>The logic of thinking. Part 16. Batch presentation of information</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/getpro/habr/post_images/362/0d4/aee/3620d4aee9a61a80e972a1e1a9d16499.gif"><br><br>  This series of articles describes a wave model of the brain that is seriously different from traditional models.  I strongly recommend that those who have just joined begin reading from the <a href="http://habrahabr.ru/post/214109">first part</a> . <br><br>  The information with which the brain operates must, on the one hand, sufficiently fully describe what is happening, on the other hand, it must be stored so as to allow the performance of the operations required by the brain.  In principle, the format for describing information and its processing algorithms are closely interconnected things.  The first largely determines the second.  Therefore, speaking about how the data stored by the brain can be organized, we, whether we like it or not, largely predetermine the system of subsequent thought processes.  Since we are going to talk about the principles of thinking later, now we will focus only on how to ensure the completeness of the current description and subsequent storage of information.  At the same time, implying that if, having come to thinking, it turns out that the chosen data format fits the required algorithms, it means that we were lucky and we took the right path. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      To understand what kind of descriptions the brain uses, let's follow the sequence of visual perception.  Looking at the image, we ‚Äúscan‚Äù it with quick eye movements, called saccades (drawing on the KDPV).  Each of them places in the center of view one of the fragments of the overall picture.  On the zones of the visual cortex, descriptions appear that correspond to what we see at this moment in the center, what the periphery sees and what the displacement is as a result of the saccade that has just been done.  Each following saccade creates a new picture.  These descriptions follow each other one by one. <br><br><a name="habracut"></a><br>  So, looking at the face, we first, for example, clearly see and recognize one eye, the one to which the eye is directed.  The remaining elements of the face that fall on the relative periphery of vision - the nose, the mouth, and so on, we learn with less, but the same high enough probability.  After each saccade, the central fragment changes, but the common set of recognized elements remains unchanged. <br><br>  In principle, each of these separate descriptions arising between saccades is enough to say that we have a face and even find out who owns it.  But each individual description reliably speaks only of the object, which for it is located in the direction of view.  The remaining objects are determined fairly approximately. <br><br>  If we want to get a more complete and detailed picture of the face, then a combination of all the descriptions that will arise during the scan will be suitable for this.  In this case, it will be important not only the description of what objects are recognized for, but also information about the accompanying glances of sight.  And here we come to a very important point.  What is the final description that the visual analyzer should produce?  Just a picture of the activity of a number of concepts?  This corresponds only to the part of the description that we see right now.  But what about the rest?  It turns out that a correct, not losing information, description is a package of simpler descriptions following each other.  Where each of the layers of such a temporary package describes only some of the information, and a complete description is obtained as their combination.  This is true provided that all the descriptions in the package correspond to one event, that is, received before the global shift of our attention. <br><br>  If you take a snapshot of the activity of the cerebral cortex, the description of what is happening can be compared with the listing of active concepts in each of its zones.  But such a description has a significant drawback.  Suppose we want to describe the still life depicted in the figure below. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/068/900/a4d/068900a4d36c994e44fb1c74c4782043.jpg"><br><br>  We can do this, for example, like this: <br><ul><li>  Vase just to the right of the center; </li><li>  Bouquet in a vase; </li><li>  Towel to the right of the vase; </li><li>  White flower on the towel; </li><li>  Bowl with raspberries on the left; </li><li>  Raspberries on the sheet to the left of the bowl; </li><li>  Three raspberries in front of a bowl; </li><li>  Raspberries to the right of the vase. </li></ul><br>  General description consists of a set of such short descriptions.  Each short description can, with some reservations, be replaced by a listing of the concepts included in it.  But if we want to collect the final description, simply adding all the concepts involved in the short transfers, then we will fail.  When adding, some of the information will disappear, since it becomes unclear what is related to what.  But, in addition, it turns out that some concepts need to be used several times.  For example, it is raspberry on the left and on the right, and in front of a bowl.  And if we want to use this ‚Äúsimply assembled‚Äù description as an analogy of how such a still life is described on the bark zones, then it turns out that the generalization of ‚Äúraspberry‚Äù is one and it cannot be ‚Äúactive three times‚Äù at the same time.  The way out of this situation, which seems to me quite logical, is to use the package description.  Each simple description can consist of a banal listing of active concepts.  The full description is obtained as a set of simple descriptions.  Since simple descriptions are spaced apart in time, then, on the one hand, it is clear what is relevant, and, on the other hand, the same concept can occur several times in different layers of a package in different contexts. <br><br>  Such a batch view is very well correlated with reasoning about the amount of attention a person has.  Psychologists, studying the properties of attention, have established that there is a limit to the number of objects on which a person can simultaneously concentrate.  Usually this limit does not exceed seven objects.  The founder of experimental psychology, Wilhelm Wundt, was the first to measure attention span using a mechanical tachistoscope. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/10f/99c/851/10f99c851e7d2ffee3960b1e4d469390.jpg"><br>  <i>Tachytoscope - a device with which you can show consistent visual stimuli</i> <br><br>  Estimate the amount of attention is very simple.  Look at the previous still life and try to count how many individual elements you are capable of, no, not remember, this is different, but keep in your head at the same time.  Or take a seven-digit phone number, for example, 1145618 and try to ‚Äúkeep‚Äù it in your head.  Most likely, that he did not disappear, you will have to loop him to repeat himself.  If there are more than seven digits in the number, there is a great chance that it will not be possible to keep them all in memory.  The maximum number of perceived objects of still life or numbers at once gives an estimate of the amount of your attention. <br><br>  The assumption we made about the batch representation of information in the cerebral cortex allows us to compare each of the objects held in attention with one of the layers of the information package. <br><br>  If we imagine a cortex consisting of a small number of concepts, capable of formulating very simple thoughts about two objects ‚ÄúA‚Äù and ‚ÄúB‚Äù, then the package corresponding to the thought: ‚Äúred object A lies on blue object B‚Äù will look like the one shown in the figure below. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d44/300/509/d44300509947fe03d8498bde1fe0ac8c.png"><br>  <i>Sample Information Pack</i> <br><br><h2>  Coding of complex descriptions </h2><br>  Let us return to the memory and try to systematize what types of information, and, accordingly, the types of descriptions our brain can handle. <br><br>  The first type is a simple description that corresponds to the picture of the instantaneous activity of the cortex.  This is a combination of those concepts that are detected by the brain right now. <br><br>  The second type is a package of simple descriptions corresponding to one event, one thought.  In the package, the order of the descriptions is irrelevant.  Rearranging the layers of a package does not change the general meaning of the statement.  Package recall is a series of simple descriptions following one after another. <br><br>  The third type is a positional description.  In such a description, the connection of some objects with others that are in a certain system of relations with them is preserved.  For example, a variation of such a description is a spatial description.  When we do not just fix our position in space, but we associate it with certain descriptions with the location of other objects. <br><br>  The fourth type is a procedural description.  Such a description, in which the sequence of changing images is important and the intervals that accompany it.  For example, speech perception is determined by the sequence of sounds, and the ratio of the intervals forms the intonation, on which the general meaning of the phrase heard strongly depends.  Recalling a procedure is the reproduction of the corresponding sequence of images. <br><br>  And the fifth type is a chronological description.  Fixation on long periods of time in which sequence and with what time intervals certain events occurred.  The opportunity to remember for chronological memory is not the reproduction of everything related to one chronology at once, but the ability to move from one description to another, associated with it a common temporal sequence. <br><br>  It is easy to see that many descriptions are somehow tied to time.  A batch description is a series of successive images.  The procedural description takes into account the sequence of events.  The chronological description requires taking into account the positioning of events in time. <br><br>  Such a dependence of descriptions on time was the reason for the emergence of the corresponding models.  The most famous of these is the concept of hierarchical temporal memory (HTM) promoted by Jeff Hawkins (Hawkins, 2011).  He and his colleagues proceed from the fact that the temporal change of events is the only thing that allows us to link together separate informational images.  From this it is concluded that the basic information element of the cortex should work not with static images, but with a time sequence.  In the concept of HTM, the element of information storage is a sequence of signals expanded in time.  Recognition is the definition of the coincidence of two sequences.  Special emphasis is placed on the predictive ability of the HTM.  As soon as a neuron recognizes the beginning of a sequence familiar to it, it becomes able to predict the continuation it remembers from its own experience.  The description of the current picture in the HTM is the activity of those neurons that responded to the current change of events. <br><br>  The complexity of this approach is quite obvious.  First, the requirement of adherence to time scales.  A slight acceleration or delay in data entry can disrupt the recognition algorithm.  Secondly, the need to translate all static images into temporary sequences before the cortex can handle them.  Etc. <br><br>  In our model, the identifier system gives us a universal tool that is equally well suited for describing all possible types of memory.  The basic idea is simple - each simple description is a composite identifier that contains everything needed to indicate the entire set, both associative and temporal relationships. <br><br>  The figure below shows the conventional image of such a simple description.  A simple description is a wave that carries several sets of identifiers of different types.  The main content is encoded by a set of identifiers of concepts that describe the essence of what is happening.  The layer identifier marks the main content, separating it from the rest of the simple descriptions.  The package identifier combines several layers belonging to the same complex description.  Identifiers of place, time, and sequence create a system of corresponding links between complex descriptions. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/5a0/a49/9be/5a0a499be5ebccc123c7c1c6bffc636d.png"><br>  <i>Simple description format</i> <br><br>  Let's take the previous example and designate the waves of identifiers corresponding to the concepts used (concepts) as C1 ... C7 (figure below). <br><br><img src="https://habrastorage.org/getpro/habr/post_images/413/736/f8a/413736f8a60c6f95266deba2dd34e869.png"><br>  <i>Concepts used to describe</i> <br><br>  Then the description of the fact that ‚Äúthe red object A lies on the blue object B‚Äù will look as shown in the figure below. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/4b9/136/05a/4b913605a3cc200a380f89045e44a874.png"><br>  <i>An example of a complex description</i> <br><br>  In this example, each of the layers of a package is a simple description with its own layer ID.  All package layers have a common package identifier p1.  When one complex description ends, the other following it has a different p2 package identifier (the concepts of the second description are not shown in the figure). <br><br>  For this design to be workable, the brain needs a fairly complex system that creates identifiers that form the packets.  Moreover, for each of the zones of the cortex may need its own set of such identifiers, appropriate for it. <br><br>  For example, take a sequence of visual perception.  The intermittent micromovements of the eyes, called microsaccades, cause the eye to scan a small portion of the image that falls on the center of the retina.  All images that are obtained in the process of such a scan, presumably can be combined with a common identifier.  The micromovements of the eyes are controlled by the upper hillocks of the quadrilateral.  We can assume that they encode such an identifier.  After several microsacades, a strong jump occurs, called a saccade (above, in the picture with the head of Nefertiti, the saccades are shown).  Each saccade causes a change in the identifier of microsacdes. <br><br>  It can be assumed that microscopes are fundamentally important for the primary visual cortex.  The common identifier informs the cortex that a series of successive images describes the same object, but in its different positions on the retina, which allows combining them into a single description and realizing the invariant to the position on the retina recognition. <br><br>  A longer event is a series of saccades.  Since the series refers to looking at a single picture, the resulting descriptions can also be linked to each other by another common identifier - saccad identifiers.  But this identifier is no longer essential for the primary, but for the secondary and deeper levels of the visual cortex, where the subsequent processing of information takes place.  The identifier informing the cortex that all that we see during the series of saccades is the same picture, allowing us to relate the same images to each other, seen in different places of the retina. <br><br>  The change of the saccade identifier should occur when the picture under consideration changes significantly.  For example, with a strong turn of the head, switching attention, a change of plan or scene in the movie.  Switching attention can be encoded by elements of the limbic system of the brain and extend to many, tied to this, areas of the cortex.  At the same time in the system of descriptions there are hippocampal identifiers encoding spatio-temporal descriptions of events.  In short, the system of identifiers that define a packet can be quite complicated, and is determined by the characteristics of the information with which each particular zone of the cortex deals. <br><br>  Using identifiers it is easy to organize the fixation of a sequence of events.  For example, if you take an identifier consisting of two fragments, then alternately changing one of them, you can get the associative connectedness of neighboring descriptions (figure below). <br><br><img src="https://habrastorage.org/getpro/habr/post_images/17d/e73/367/17de733678306a2e6af307ccb1e49565.png"><br>  <i>Sequence encoding</i> <br><br>  Each such identifier will contain an element from the previous and subsequent identifier.  Having remembered a temporal sequence of images with such identifiers, we will be able to find its two neighbors in the time scale for each image.  By simply complicating the identifier, it is possible to encode not only the general connectivity, but also the direction of the flow of time. <br><br>  It should be noted that in our model, each memory has a rich system of identifiers.  This allows access to the memory through many completely different associations.  You can recall something based on the coincidence of the descriptions.  You can associate informational pictures at the place or time of the described events.  You can play a sequence of images related to a single event.  It is easy to see that such access to memories has much in common with the approaches used to create traditional relational databases. <br><br>  <a href="http://www.aboutbrain.ru/lit/">References</a> <br><br>  <a href="http://habrahabr.ru/post/217055/">Continuation</a> <br><br>  Previous parts: <br>  <a href="http://habrahabr.ru/post/214109/">Part 1. Neuron</a> <br>  <a href="http://habrahabr.ru/post/214241/">Part 2. Factors</a> <br>  <a href="http://habrahabr.ru/post/214317/">Part 3. Perceptron, convolutional networks</a> <br>  <a href="http://habrahabr.ru/post/214525/">Part 4. Background Activity</a> <br>  <a href="http://habrahabr.ru/post/214663/">Part 5. Waves of the brain</a> <br>  <a href="http://habrahabr.ru/post/214797/">Part 6. The system of projections</a> <br>  <a href="http://habrahabr.ru/post/215023/">Part 7. Human-computer interface</a> <br>  <a href="http://habrahabr.ru/post/215151/">Part 8. Selection of factors in the wave networks</a> <br>  <a href="http://habrahabr.ru/post/215283/">Part 9. Patterns of neuron detectors.</a>  <a href="http://habrahabr.ru/post/215283/">Reverse projection</a> <br>  <a href="http://habrahabr.ru/post/215287/">Part 10. Spatial self-organization</a> <br>  <a href="http://habrahabr.ru/post/215701/">Part 11. Dynamic neural networks.</a>  <a href="http://habrahabr.ru/post/215701/">Associativity</a> <br>  <a href="http://habrahabr.ru/post/216263/">Part 12. Traces of memory</a> <br>  <a href="http://habrahabr.ru/post/216301/">Part 13. Associative memory</a> <br>  <a href="http://habrahabr.ru/post/216409/">Part 14. Hippocampus</a> <br>  <a href="http://habrahabr.ru/post/216633/">Part 15. Memory consolidation</a> <br><br>  <a href="http://www.aboutbrain.ru/">Alexey Redozubov</a> (2014) </div><p>Source: <a href="https://habr.com/ru/post/216825/">https://habr.com/ru/post/216825/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../216809/index.html">The digest of interesting news and materials from the world of PHP No. 38 (March 9 - March 23, 2014)</a></li>
<li><a href="../216811/index.html">They are cyborgs! A little bit about how the systems are arranged in HERE cartographic cars</a></li>
<li><a href="../216813/index.html">What does democracy lead to?</a></li>
<li><a href="../216815/index.html">In the LA Times earthquake news wrote a robot</a></li>
<li><a href="../216817/index.html">Payment from the account of a corporate or personal phone as from a bank account</a></li>
<li><a href="../216827/index.html">CPU Load: when to start worrying?</a></li>
<li><a href="../216829/index.html">10 slideshows with AgileDays 2014</a></li>
<li><a href="../216831/index.html">VK Friendly Link Analysis with Wolfram Mathematica</a></li>
<li><a href="../216833/index.html">Where "soap" in WPF comes from and how to deal with it</a></li>
<li><a href="../216837/index.html">Devise: login and registration in modal windows</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>