<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Recognizing objects and human emotions using the Firebase ML Kit</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="If you followed Google I / O (or at least watched Keynotes), then you may have noticed the announcement of a new product as part of the Firebase platf...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Recognizing objects and human emotions using the Firebase ML Kit</h1><div class="post__text post__text-html js-mediator-article"><p><img src="https://habrastorage.org/webt/6n/o3/xk/6no3xkgvsfzp6mlhr5ctmsuuy0c.jpeg" alt="Recognizing objects and human emotions using the Firebase ML Kit"></p><br><p>  If you followed Google I / O (or at least watched Keynotes), then you may have noticed the announcement of a new product as part of the Firebase platform called ML Kit. </p><br><p>  ML Kit provides an API with which you can add powerful machine learning functions to applications (both Android and iOS), regardless of whether you are an experienced machine learning developer or just a newcomer to this field. </p><a name="habracut"></a><br><p>  Although this product did not become the center of attention at the conference (thanks, Google Duplex), there are certainly many useful ways to use it in Android development. </p><br><p>  So let's play with it and create a small application that will look like Google Lens (almost)! </p><br><p>  Here are some screenshots from the app.  On them you can see an attempt to identify objects in the image. </p><br><p><img src="https://habrastorage.org/webt/wr/fu/wx/wrfuwxigtg5o73nuhkdjl5spvt4.png" alt="Headphone Recognition 1"></p><br><p><img src="https://habrastorage.org/webt/kf/be/cl/kfbeclb_ibimfqxu9kmkwgzalxg.png" alt="Headphone Recognition 2"></p><br><p>  Pretty accurate, huh? <br>  You can also use this API to define human emotions, such as happiness, sadness, anger, etc., which is even better. </p><br><h3 id="hvatit-boltovni-pokazhite-mne-kod">  Stop talking, show me the code !!!!! </h3><br><p>  ML Kit has 5 APIs: </p><br><ol><li>  Text recognition (we have already released <a href="https://habr.com/post/412679/">an article</a> about the application using this functionality) </li><li>  Face detection (there is such <a href="https://devcolibri.com/%25D1%2581%25D0%25BE%25D0%25B7%25D0%25B4%25D0%25B0%25D0%25BD%25D0%25B8%25D0%25B5-android-%25D0%25BF%25D1%2580%25D0%25B8%25D0%25BB%25D0%25BE%25D0%25B6%25D0%25B5%25D0%25BD%25D0%25B8%25D1%258F-%25D0%25B4%25D0%25BB%25D1%258F-%25D0%25BE%25D0%25B1%25D0%25BD%25D0%25B0%25D1%2580%25D1%2583%25D0%25B6%25D0%25B5%25D0%25BD%25D0%25B8/">an article</a> in our blog) </li><li>  Barcode scanning </li><li>  Identification of objects in the image (the one we are going to use) </li><li>  Character Recognition </li></ol><br><p>  In this article we will use the API for identifying objects in the image.  With this API, we get a list of objects that were recognized in the image: people, things, places, actions, etc. </p><br><p>  In addition, there are 2 types of this API.  The first is an <strong>API interface built into your device</strong> that works, logically, on the device itself.  It is free and can recognize over 400 different objects in images. </p><br><p>  The second is a <strong>cloud-based API</strong> that runs on Google Cloud and recognizes over 10,000 different objects.  It is paid, but the first 1000 requests per month are free. </p><br><p>  In this article, we will look at the first type of API, because  it is free (but the principle of operation of the paid is similar to free). </p><br><p>  Let's start. </p><br><ul><li> <strong>Connect Firebase to your project and add the</strong> <code>firebase-ml-vision</code> <strong>dependency</strong> <br>  How to connect a firebase, you can see in a <a href="https://firebase.google.com/docs/android/setup">good tutorial</a> from Google.  You must also add the appropriate dependencies to use this API: </li></ul><br><pre> <code class="hljs delphi"><span class="hljs-keyword"><span class="hljs-keyword">implementation</span></span> <span class="hljs-string"><span class="hljs-string">'com.google.firebase:firebase-ml-vision:15.0.0'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">implementation</span></span> <span class="hljs-string"><span class="hljs-string">'com.google.firebase:firebase-ml-vision-image-label-model:15.0.0'</span></span></code> </pre> <br><ul><li><p>  <strong>Embed the camera function into the application</strong> <br>  Vision API needs an image to receive data, so either create an application that allows you to download images from the gallery, or create an application that uses the camera to make an image and instantly analyze it. <br>  If you do not want to use the standard camera API, you can simply use the <a href="https://github.com/CameraKit/camerakit-android">convenient and simple library</a> for this functionality. </p><br></li><li><p>  <strong>Use bitmap to access Vision API</strong> <br>  The library specified above directly provides an image bitmap that can be used to access the API. </p><br></li></ul><br><pre> <code class="hljs pgsql">fab_take_photo.setOnClickListener { // cameraView <span class="hljs-keyword"><span class="hljs-keyword">is</span></span> a custom <span class="hljs-keyword"><span class="hljs-keyword">View</span></span> which provides camera preview cameraView.captureImage { cameraKitImage -&gt; // <span class="hljs-keyword"><span class="hljs-keyword">Get</span></span> the Bitmap <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> the captured shot <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> use it <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> make the API <span class="hljs-keyword"><span class="hljs-keyword">call</span></span> getLabelsFromDevice(cameraKitImage.bitmap) } } private fun getLabelsFromDevice(bitmap: Bitmap) { val image : FirebaseVisionImage = FirebaseVisionImage.fromBitmap(bitmap) val detector : FirebaseVisionLabelDetector = FirebaseVision.getInstance().visionLabelDetector detector.detectInImage(image) .addOnSuccessListener { // Task completed successfully <span class="hljs-keyword"><span class="hljs-keyword">for</span></span>(firebaseVision : FirebaseVisionLabel <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> it){ // Logging through the list <span class="hljs-keyword"><span class="hljs-keyword">of</span></span> labels returned <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> the API <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> <span class="hljs-keyword"><span class="hljs-keyword">Log</span></span> them <span class="hljs-keyword"><span class="hljs-keyword">Log</span></span>.d(TAG,"Item Name ${firebaseVision.confidence}") <span class="hljs-keyword"><span class="hljs-keyword">Log</span></span>.d(TAG,"Confidence ${firebaseVision.confidence}") } } .addOnFailureListener { // Task failed <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> an <span class="hljs-keyword"><span class="hljs-keyword">exception</span></span> Toast.makeText(baseContext,"Sorry, something went wrong!",Toast.LENGTH_SHORT).<span class="hljs-keyword"><span class="hljs-keyword">show</span></span>() } }</code> </pre> <br><p>  In the above code snippet, we first create a <code>FirebaseVisionImage</code> from bitmaps. </p><br><p>  Then we create an instance of <code>FirebaseVisionLabelDetector</code> , which passes through <code>FirebaseVisionImage</code> and finds certain <code>FirebaseVisionLabels</code> (objects) that it recognizes in the provided image. </p><br><p>  Finally, we pass the image to the <code>detectInImage()</code> method and allow the detector to analyze the image. </p><br><p>  We can set listeners to handle successful analysis and for unsuccessful ones.  There we will have access to the list of objects identified in the image and to the exception that occurred. </p><br><p>  For each recognized object you can get its <strong>name, recognition accuracy and entity id</strong> . </p><br><p>  As mentioned earlier, this API can also be used to define human emotions in an image, as can be seen in the screenshots below: </p><br><p><img src="https://habrastorage.org/webt/fu/jr/qq/fujrqqrmmpd-gx9puoir9z8_0ni.png" alt="Human emotions"></p><br><p><img src="https://habrastorage.org/webt/i8/rg/ss/i8rgss-9xmow9qblquay2o2kgpw.png" alt="Emotion Recognition 1"></p><br><p><img src="https://habrastorage.org/webt/sc/j9/ah/scj9ahvdfphvfa4qouhqsuwbqb0.png" alt="Emotion Recognition 2"></p><br><p>  The code for the <strong>cloud API is</strong> very similar to the code we wrote for <strong>the device API</strong> .  Only <strong>the detector type</strong> ( <code>FirebaseVisionCloudLabelDetector</code> versus <code>FirebaseVisionLabelDetector</code> ) and the <strong>type of identified objects</strong> ( <code>FirebaseVisionCloudLabel</code> versus <code>FirebaseVisionLabels</code> ) <code>FirebaseVisionLabels</code> : </p><br><pre> <code class="hljs kotlin"><span class="hljs-keyword"><span class="hljs-keyword">private</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">fun</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">getLabelsFromDevice</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(bitmap: </span></span><span class="hljs-type"><span class="hljs-function"><span class="hljs-params"><span class="hljs-type">Bitmap</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span></span> { ... <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> detector : FirebaseVisionCloudLabelDetector = FirebaseVision.getInstance().visionCloudLabelDetector detector.detectInImage(image) .addOnSuccessListener { <span class="hljs-keyword"><span class="hljs-keyword">for</span></span>(firebaseVision : FirebaseVisionCloudLabel <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> it){ ... } } .addOnFailureListener { ... } }</code> </pre> <br><p>  In addition to changes in the code, you also need to set up billing (payment) for your project and enable the <a href="https://cloud.google.com/vision/docs/">Google Vision API</a> in your Google Cloud Console. </p><br><p>  Please note that the API allows you to perform only <strong>1000 free requests</strong> every month, so you do not need to pay if you want to just play with it. </p><br><p>  The application shown in the screenshots can be found on the <a href="https://github.com/the-dagger/GoogleLensMLKit">GitHub repository</a> . </p></div>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <p>Source: <a href="https://habr.com/ru/post/420085/">https://habr.com/ru/post/420085/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../420075/index.html">This ingenious map explains how everything in physics fits together.</a></li>
<li><a href="../420077/index.html">New online trading opportunities</a></li>
<li><a href="../420079/index.html">Creating an interactive grass in the Unreal Engine</a></li>
<li><a href="../420081/index.html">Installing Archlinux with full system and LVM encryption on LUKS</a></li>
<li><a href="../420083/index.html">Perfect Action for Google Assistant - 8 lessons of the Moscow hackathon</a></li>
<li><a href="../420087/index.html">This is a post with reports and videos on MS SQL Server</a></li>
<li><a href="../420089/index.html">Robomobili: Platooning and Bavarian sausages</a></li>
<li><a href="../420091/index.html">Comments in the code as a way of expression</a></li>
<li><a href="../420093/index.html">GitHub opened the code of its load balancer - how their solution works</a></li>
<li><a href="../420095/index.html">Asymmetric cryptography with a one-time secret key: description of the idea and possible application</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>