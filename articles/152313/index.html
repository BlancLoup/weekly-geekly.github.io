<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Analyzing Twitter data in the cloud using Apache Hadoop and Hive</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="This guide describes the procedures for requesting, exploring and analyzing Twitter data using services based on Apache Hadoop for Windows Azure, as w...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Analyzing Twitter data in the cloud using Apache Hadoop and Hive</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/getpro/habr/post_images/363/95a/d63/36395ad63dd2c0fa773fcd4c8ba874a1.jpg" alt="image"><br><br>  This guide describes the procedures for requesting, exploring and analyzing Twitter data using services based on Apache Hadoop for Windows Azure, as well as a Hive query in Excel.  Social media is the main source of big data.  Therefore, publicly accessible APIs for social media such as Twitter provide useful information and help you better understand network trends. <br><br>  The manual consists of the following sections. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <ol><li>  Search, download, install and use Microsoft Analytics for Twitter </li><li>  Getting Twitter feeds using cURL and Twitter Streaming API </li><li>  Querying and configuring new Hadoop on a Windows Azure cluster </li><li>  Processing Twitter data using Hive to Hadoop in a Windows cluster </li><li>  Configure Hive ODBC and Hive Panel in Excel to get Hive data </li></ol><br><a name="habracut"></a><h3>  Search, download, install and use Microsoft Analytics for Twitter </h3><br>  Microsoft Analytics for Twitter is available for download at the following address: <a href="http://www.microsoft.com/download/en/details.aspx%3Fid%3D26213">http://www.microsoft.com/download/en/details.aspx?id=26213</a> . <br><br>  Excel 2010 and PowerPivot add-on (available at <a href="http://www.microsoft.com/download/en/details.aspx%3Fid%3D29074">http://www.microsoft.com/download/en/details.aspx?id=29074</a> ) are required. <br><br><img title="clip_image004 [4]" alt="clip_image004[4]" src="https://habrastorage.org/getpro/habr/post_images/cb8/632/205/cb8632205c8f71be79613c70d1112e20.jpg" width="550" height="373"><br><br>  Insert the following movie tags and accounts into the query window: <br><br>  #moneyball, @MoneyballMovie, @helpmovie, @BridesmaidsSay, @CONTAGION_movie <br><br>  Press the button <br><br><img title="clip_image006 [4]" alt="clip_image006[4]" src="https://habrastorage.org/getpro/habr/post_images/189/fb5/7e7/189fb57e743c26e531eda2fc228381ba.jpg" width="24" height="24"><br><br>  and follow the instructions on the screen. <br><br>  <b>Note.</b>  Hadoop is not used in this section.  It shows how to work with the Twitter Search API and business intelligence with self-service in Excel and PowerPivot. <br><br><h3>  Getting a Twitter feed using cURL and Twitter Streaming API </h3><br>  At this stage, you will need the application curl.exe.  Download the curl file for your OS (for example, the SSL binary file for 64-bit Windows) at <a href="http://curl.haxx.se/download.html">http://curl.haxx.se/download.html</a> <br><br><img title="clip_image008 [4]" alt="clip_image008[4]" src="https://habrastorage.org/getpro/habr/post_images/08f/78f/811/08f78f811d0a24535f76ec1f198337b4.jpg" width="608" height="85"><br><br>  and unzip <b>curl.exe</b> into a suitable folder (for example, <b>C: \ twitterdata</b> ). <br><br>  Copy the two files ‚Äî <b>get <i>twitter</i> stream.cmd</b> and <b>twitter_params.txt</b> ‚Äî from the <b>Step2GetTwitterFeedUsingCURLAndTwitterStreamingAPI</b> folder to the folder containing <b>curl.exe</b> : <br><br><img title="clip_image010 [4]" alt="clip_image010[4]" src="https://habrastorage.org/getpro/habr/post_images/5f6/33e/0e0/5f633e0e0035a8a424c86f6a87c48224.jpg" width="602" height="110"><br><br>  Modify the <b>twitter_params.txt</b> file as follows to track tweets: <br><br>  <em>track = moneyball, MoneyballMovie, helpmovie, BridesmaidsSay, CONTAGION_movie</em> <br><br>  Modify the <b>get <i>twitter</i> stream stream.cmd</b> command script by inserting your Twitter username instead of <b>USER</b> and password instead of <b>PASSWORD</b> on the following line: <br><br>  <em>curl -d @ twitter_params.txt -k <a href="">stream.twitter.com/1/statuses/filter.json</a> -uUSER: PASSWORD &gt;&gt; twitter_stream_seq.txt</em> <br><br>  Run the get <i>twitter</i> stream.cmd script from the command line as follows: <br><br><img title="clip_image012 [4]" alt="clip_image012[4]" src="https://habrastorage.org/getpro/habr/post_images/6b2/1c0/a6b/6b21c0a6ba9f50b27e17fe13fd70aabb.jpg" width="271" height="29"><br><br>  Some information will appear on the screen: <br><br><img title="clip_image014 [4]" alt="clip_image014[4]" src="https://habrastorage.org/getpro/habr/post_images/eb5/4b7/4fe/eb54b74fefd3580935a53e8c93e86806.jpg" width="639" height="42"><br><br>  To end the script, press <b>Ctrl + C.</b>  You can then rename the file and rerun the script. <br><br><h3>  Querying and configuring new Hadoop on a Windows Azure cluster </h3><br>  At this stage, you need CTP access for the Apache Hadoop service in Windows Azure.  Go to <a href="https://www.hadooponazure.com/">https://www.hadooponazure.com/</a> and click the <b>invitation</b> link.  If you have access, click the <b>Sign in</b> button. <br><br><img title="clip_image016 [4]" alt="clip_image016[4]" src="https://habrastorage.org/getpro/habr/post_images/03d/444/ae3/03d444ae378a3eaa373d01d287dda787.jpg" width="550" height="240"><br><br>  Request a new cluster.  Below is an example of a large cluster called mailboxpeak.  Enter your username and password, and then click the Request cluster button.  For any questions, refer to the ‚ÄúInstructions and Frequently Asked Questions for a Service Based on Apache Hadoop for Windows Azure. <br><br><img title="clip_image018 [4]" alt="clip_image018[4]" src="https://habrastorage.org/getpro/habr/post_images/d8d/107/20a/d8d10720a92cecd2dbbcc7dc1e6f1d67.gif" width="550" height="346"><br><br>  Open FTPS and ODBC ports to access the server. <br><br><img title="clip_image020 [4]" alt="clip_image020[4]" src="https://habrastorage.org/getpro/habr/post_images/1b4/374/7cc/1b43747cc87f93a8b7b633ad8f556c09.jpg" width="125" height="128"><br><br><img title="clip_image022 [4]" alt="clip_image022[4]" src="https://habrastorage.org/getpro/habr/post_images/738/206/3f5/7382063f590b61d826458766088ae3f3.jpg" width="360" height="208"><br><br>  Click the <b>Interactive Console</b> icon. <br><br><img title="clip_image024 [4]" alt="clip_image024[4]" src="https://habrastorage.org/getpro/habr/post_images/0bf/d9d/da7/0bfd9dda7b21a54b0c61d483bf621bb8.jpg" width="178" height="179"><br><br>  Create a directory for the Twitter text file on HDFS using the following Javascript command: <br><br>  <em>js&gt; #mkdir / example / data</em> <br><br>  To download trial text files, run the following commands: <br><br>  <em>js&gt; #put</em> <em><br></em>  <em>Source: C: \ hadoop \ example \ data \ Sample.txt</em> <em><br></em>  <em>Destination: / examples / data</em> <br><br>  To upload large (uncompressed) text files directly to HDFS, you will need the curl.exe file.  If this file does not exist, download it according to the instructions in step 2 and unpack it into a suitable folder, for example, here: C: \ hadoop \ example \ data.  Then open PowerShell, go to <b>C: \ hadoop \ example \ data</b> and paste the following FTPS PowerShell script into the SampleData text file ( <b>SampleData.txt</b> ): <br><br>  <em>C: \ hadoop \ example \ data&gt;</em> <br><br>  <em># ----- begin curl ftps to hadoop on azure powershell example -</em> <em><br></em>  <em># ------ Replace XXXXXXX with the appropriate servername / username / password</em> <br><br>  <em>$ serverName = "XXX.cloudapp.net";</em>  <em>$ userName = "XXXX";</em> <em><br></em>  <em>$ password = "XXXXXXXX";</em> <em><br></em>  <em>$ fileToUpload = "SampleData.txt";</em>  <em>$ destination = "/ example / data /";</em> <em><br></em>  <em>$ Md5Hasher = [System.Security.Cryptography.MD5] :: Create ();</em> <em><br></em>  <em>$ hashBytes = $ Md5Hasher.ComputeHash ($ ([Char []] $ password))</em> <em><br></em>  <em>foreach ($ byte in $ hashBytes) {$ passwordHash + = "{0: x2}" -f $ byte}</em> <em><br></em>  <em>$ curlCmd = ". \ curl -k --ftp-create-dirs -T $ fileToUpload -u $ userName"</em> <em><br></em>  <em>$ curlCmd + = ": $ passwordHash ftps: // $ serverName" + ": 2226 $ destination"</em> <em><br></em>  <em>invoke-expression $ curlCmd</em> <br><br>  <em># ----- end curl ftps to az on powersure example</em> <br><br><img title="clip_image026 [4]" alt="clip_image026[4]" src="https://habrastorage.org/getpro/habr/post_images/ffa/5b3/294/ffa5b3294897f3acc5bae84754112b63.jpg" width="647" height="52"><br><br>  Very large files must be compressed before downloading.  A compressed file (with a .gz extension, etc.) can be uploaded to a Windows Azure storage account.  Using CloudXplorer ( <a href="http://clumsyleaf.com/products/cloudxplorer">http://clumsyleaf.com/products/cloudxplorer</a> ), download the file as follows: <br><br>  After setting up your Windows Azure storage account and installing CloudXplorer, go to the Windows Azure portal and copy the primary access key of your storage account by clicking the <b>View</b> button in the right column. <br><br><img title="clip_image028 [4]" alt="clip_image028[4]" src="https://habrastorage.org/getpro/habr/post_images/42b/278/1ef/42b2781efdfc26c394fa2d5219cfb978.jpg" width="213" height="118"><br><br>  Then open CloudXplorer and select <b>File -&gt; Manage Accounts</b> .  A new dialog box will open.  Click <b>New</b> and select <b>Windows Azure account</b> . <br><br><img title="clip_image030 [4]" alt="clip_image030[4]" src="https://habrastorage.org/getpro/habr/post_images/49b/4ea/42e/49b4ea42e2ac038e604f61b069f32209.jpg" width="559" height="337"><br><br>  In the next dialog box, paste in the name of the storage account you specified when setting up the storage account (for example, hadoopdemo) and the copied access key. <br><br><img title="clip_image032 [4]" alt="clip_image032[4]" src="https://habrastorage.org/getpro/habr/post_images/799/162/626/79916262665a4cc09bc26ad6bb5fa447.jpg" width="342" height="413"><br><br>  Create a container in the new storage account (in Windows Azure, the directories are called <i>containers</i> ). <br><br><img title="clip_image034 [4]" alt="clip_image034[4]" src="https://habrastorage.org/getpro/habr/post_images/9a9/501/480/9a9501480249fe142d87e64ef6c84c6d.jpg" width="393" height="185"><br><br>  Download (copy) the ZIP archive into a container (in our case, the container is called <b>data</b> ). <br><br><img title="clip_image036 [4]" alt="clip_image036[4]" src="https://habrastorage.org/getpro/habr/post_images/40d/6a3/a60/40d6a3a6095bcaab18b917488b70712e.jpg" width="750" height="132"><br><br>  Set up a Windows Azure blob storage account by clicking the <b>Manage Data</b> icon <br><br><img title="clip_image038 [4]" alt="clip_image038[4]" src="https://habrastorage.org/getpro/habr/post_images/07e/bd2/96e/07ebd296e0f1012c0512b566cf7b59cb.jpg" width="163" height="163"><br><br>  next to <b>Set up ASV</b> . <br><br><img title="clip_image040 [4]" alt="clip_image040[4]" src="https://habrastorage.org/getpro/habr/post_images/ab1/df5/a2c/ab1df5a2ccbfd58a8620beb1ac814940.jpg" width="332" height="80"><br><br>  Now you need the name of the Windows Azure <b>Storage Account Name</b> (in our case, it <b>hadooopdemo</b> ) and the main access key. <br><br><img title="clip_image042 [4]" alt="clip_image042[4]" src="https://habrastorage.org/getpro/habr/post_images/53e/2ce/309/53e2ce30999a7ec5d4b0feb9b72be6de.jpg" width="750" height="206"><br><br>  Enter the Windows Azure storage account name and primary access key, and then click <b>Save settings</b> . <br><br><img title="clip_image044 [4]" alt="clip_image044[4]" src="https://habrastorage.org/getpro/habr/post_images/b7f/d37/01c/b7fd3701c8cb9dc04416339ea8dbaecb.jpg" width="750" height="279"><br><br><h3>  <b>Processing Twitter data using Hive to Hadoop in</b> <b>a Windows cluster</b> </h3><br>  Go to <a href="https://www.hadooponazure.com/">https://www.hadooponazure.com/</a> .  Connect to the Hadoop headend by clicking <b>Remote Desktop</b> . <br><br><img title="clip_image046 [4]" alt="clip_image046[4]" src="https://habrastorage.org/getpro/habr/post_images/ba6/d3c/a1c/ba6d3ca1cbafebcfe2dba5f15c361a42.jpg" width="169" height="168"><br><br>  Click the Open button. <br><br><img title="clip_image048 [4]" alt="clip_image048[4]" src="https://habrastorage.org/getpro/habr/post_images/8ea/0d5/1ef/8ea0d51eff8a428e6750cc87b557f5b9.jpg" width="750" height="42"><br><br>  Log in to the remote server with the username and password that you used when creating the cluster in step 3. <br><br>  Create a directory (for example, <b>c: \ Apps \ dist \ example \ data</b> ) on the server of the head node of the remote Hadoop (on the NTFS side) using Explorer or the command line, and then go to it. <br><br>  Copy the entire contents of the CopyToHeadnode folder to the new directory.  This includes the file <b>HiveUDFs.jar</b> (user-defined functions for Hive queries), <b>gzip</b> , and the text files for Hive queries.  In addition, copy the <b>All steps to run from the Hadoop Command Shell.txt file</b> to simplify the execution of the last part of this step. <br><br><img title="clip_image050 [4]" alt="clip_image050[4]" src="https://habrastorage.org/getpro/habr/post_images/368/3bd/102/3683bd102ef35867b35dd889bb756b6a.jpg" width="769" height="278"><br><br>  RDP supports copying between hosted and remote desktop.  Sometimes Hadoop unpacks the <b>gzip</b> file while it is being copied to HDFS. <br><br>  Open the Hadoop Command Shell on the remote desktop. <br><br><img title="clip_image052 [4]" alt="clip_image052[4]" src="https://habrastorage.org/getpro/habr/post_images/8dc/8bc/8c8/8dc8bc8c8d2dbeeaa53c11ef25451bd6.jpg" width="82" height="122"><br><br>  Change directory to <b>c: \ Apps \ dist \ example \ data</b> . <br><br><img title="clip_image054 [4]" alt="clip_image054[4]" src="https://habrastorage.org/getpro/habr/post_images/9f1/e40/f0c/9f1e40f0cb946e363c240bf24270ab84.jpg" width="543" height="414"><br><br>  Copy the <b>twitter <i>stream</i></b> file <b>seq8.gz</b> from the Windows Azure storage to the <b>c: \ Apps \ dist \ example \ data</b> folder (on the NTFS side).  The location of the file in the storage account depends on the Windows Azure storage associations specified in step 3. In our case, the container is called <b>data</b> and is displayed in the line under <b>asv: //</b> : <br><br>  <em>c: \ Apps \ dist \ example \ data&gt; hadoop fs -copyToLocal asv: //data/twitter_stream_seq8.txt.gz twitter_stream_seq8.txt.gz</em> <br><br>  Unzip the <b>twitter <i>stream</i> seq8.gz archive</b> into the <b>c: \ Apps \ dist \ example \ data</b> folder as shown below (you will need the <b>gzip.exe</b> program, which you need to download from <a href="http://www.gzip.org/">http://www.gzip.org/</a> and place to the directory from which the command is executed): <br><br>  <em>c: \ Apps \ dist \ example \ data&gt; gzip -d -N twitter_stream_seq8.txt.gz</em> <br><br>  <b>Note.</b>  Sometimes Hadoop unpacks the file when copying to HDFS, but it only works for .bz2 (bzip2) archives <a href="http://bzip.org/">http://bzip.org/</a> : <br><br>  <em>hadoop fs -copyFromLocal twitter_stream_seq8.txt.gz /example/data/twitter_stream_seq8.txt</em> <br><br>  Copy <b>twitter <i>stream</i> seq8.txt</b> from the <b>c: \ Apps \ dist \ example \</b> HDFS folder <b>with the</b> following command: <br><br>  <em>c: \ Apps \ dist \ example \ data&gt;</em> <em><br><br></em>  <em>hadoop fs -copyFromLocal twitter_stream_seq8.txt /example/data/twitter_stream_seq8.txt</em> <br><br>  1. Make sure the file on the HDFS is updated.  To do this, open <br><br><img title="clip_image056 [4]" alt="clip_image056[4]" src="https://habrastorage.org/getpro/habr/post_images/ade/388/161/ade38816118c14ca96fb6b392bb2f62d.jpg" width="70" height="89"><br><br>  and go to the folder / example / data. <br><br><img title="clip_image058 [4]" alt="clip_image058[4]" src="https://habrastorage.org/getpro/habr/post_images/107/7ab/566/1077ab5664490527f2f49daaf6c7744c.jpg" width="750" height="412"><br><br>  The following steps are contained in the All steps to run from the Hadoop Command Shell.txt file that you copied to the head node. <br><br>  Create and upload twitter_raw with the following command: <br><br>  <em>c: \ apps \ dist \ example \ data&gt; hive -v -f load_twitter_raw.txt</em> <br><br><img title="clip_image060 [4]" alt="clip_image060[4]" src="https://habrastorage.org/getpro/habr/post_images/c45/c41/2d1/c45c412d1acdede1849f76f0f38ca4d8.jpg" width="742" height="291"><br><br>  The table will be created in the / hive / warehouse directory on the HTFS side: <br><br><img title="clip_image062 [4]" alt="clip_image062[4]" src="https://habrastorage.org/getpro/habr/post_images/82a/69f/a80/82a69fa80e0dd7db1c7f3c12d4b3bc83.jpg" width="733" height="285"><br><br>  You can check this with Hive by typing <b>c: \ Apps \ dist \ example \ hive</b> and <b>Hive&gt; show tables;</b>  as shown below. <br><br><img title="clip_image064 [4]" alt="clip_image064[4]" src="https://habrastorage.org/getpro/habr/post_images/d6d/f2f/187/d6df2f1871d5dfc17e3bd15c2a9c5122.jpg" width="211" height="97"><br><br>  To exit Hive, use the command <b>hive&gt; quit;</b>  .  Create and upload <b>twitter_temp</b> as follows: <br><br>  <em>c: \ apps \ dist \ example \ data&gt; hive -v -f create_twitter_temp.txt</em> <br><br>  If there are 4 nodes, this operation will take more than 20 minutes, and if there are 8 nodes - 8 minutes 55 seconds.  Check the progress in the following window: <br><br><img title="clip_image066 [4]" alt="clip_image066[4]" src="https://habrastorage.org/getpro/habr/post_images/79c/f93/768/79cf93768b0d284612786918009de5ac.jpg" width="750" height="244"><br><br>  Click a task to view details and progress.  The operation may take more than 20 minutes. <br><br><img title="clip_image068 [4]" alt="clip_image068[4]" src="https://habrastorage.org/getpro/habr/post_images/52d/690/b3c/52d690b3cae2d6ac83707bcaabc34529.jpg" width="736" height="454"><br><br>  You can also track task execution using the Hadoop Command Shell: <br><br><img title="clip_image070 [4]" alt="clip_image070[4]" src="https://habrastorage.org/getpro/habr/post_images/09e/913/ecf/09e913ecf8ca0a0c1acf2aab710f34c2.jpg" width="750" height="220"><br><br>  You can check this with Hive by typing <b>c: \ Apps \ dist \ example \ hive</b> and <b>Hive&gt; show tables</b> : <br><br><img title="clip_image072 [4]" alt="clip_image072[4]" src="https://habrastorage.org/getpro/habr/post_images/2c2/01b/683/2c201b683a14c7311b5f538b90a5d65b.jpg" width="747" height="140"><br><br>  Create and upload <b>twitter_stream</b> as follows: <br><br>  <em>c: \ apps \ dist \ example \ data&gt; hive -v -f create_twitter_stream.txt</em> <br><br>  If there are 4 nodes, this operation will take more than 60 minutes, and if there are 8 nodes, it will take 31 minutes 54 seconds.  Track progress as described above.  Create and download the <b>twitter <i>stream</i> sample with the</b> following command: <br><br>  <em>c: \ apps \ dist \ example \ data&gt; hive -v -f create_twitter_stream_sample.txt</em> <br><br>  Track progress as described above.  Create and upload <b>twitter_movies</b> as follows: <br><br>  <em>c: \ apps \ dist \ example \ data&gt; hive -v -f create_twitter_movies.txt</em> <br><br>  Track progress as described above.  Create and download <b>twitter <i>movies</i> vw</b> with the command: <br><br>  <em>c: \ apps \ dist \ example \ data&gt; hive -v -f create_twitter_movies_vw.txt</em> <br><br>  Track progress as described above. <br><br><h3>  Configure Hive ODBC and Hive Panel in Excel to get Hive data </h3><br>  This section is taken from the <b>‚ÄúInstructions and Frequently Asked Questions for an Apache Hadoop Based Service for Windows Azure,‚Äù</b> which is on the download tile. <br><br><img title="clip_image074 [4]" alt="clip_image074[4]" src="https://habrastorage.org/getpro/habr/post_images/4b9/112/1ed/4b91121ed06611fa397399fdeb4885e3.jpg" width="162" height="163"><br><br>  in Hadoop on the Windows Azure portal. <br><br><img title="clip_image076 [4]" alt="clip_image076[4]" src="https://habrastorage.org/getpro/habr/post_images/bc8/9ae/8bd/bc89ae8bd25251b29fc875856d160923.jpg" width="728" height="602"><br><br><img title="clip_image078 [4]" alt="clip_image078[4]" src="https://habrastorage.org/getpro/habr/post_images/747/371/96f/74737196f94b43e4e18bfc0fd7fa460b.jpg" width="721" height="308"><br><br>  From there you can also download <b>HiveODBCSetup</b> for 64-bit and 32-bit versions of Excel. <br><br><h4>  How to connect to the Hive add-in for Excel in Hadoop on a Windows Azure platform using HiveODBC </h4><br>  The most important feature of the Microsoft big data processing solution is the integration of Hadoop with the components of Microsoft's business intelligence.  A good example of this is to connect Excel to the Hive data storage framework in a Hadoop cluster.  This section shows how to use Excel through the Hive ODBC driver. <br><br><h4>  Installing the Hive ODBC driver </h4><br>  To start the installation, download the 64-bit version of the Hive ODBC driver (MSI file) from Hadoop in the Windows Azure portal.  Double-click <b>HiveODBCSetupx64.msi</b> to start the installation.  Read the license agreement.  If you agree to its terms, click <b>I accept</b> and then <b>Install</b> . <br><br><img title="clip_image080 [4]" alt="clip_image080[4]" src="https://habrastorage.org/getpro/habr/post_images/f69/137/b5f/f69137b5fc968b48df81150751459902.jpg" width="509" height="395"><br><br>  After the installation is complete, click <b>Finish</b> to exit the wizard. <br><br><h4>  Installing Hive Add-in for Excel </h4><br>  To install this add-in, you need 64-bit versions of the Hive ODBC driver and Excel 2010 software. Start the 64-bit version of Excel 2010. The system will offer to install the <b>HiveExcel</b> extension.  Click <b>Install</b> .  When the extension is installed, click the <b>Data</b> tab in Microsoft Excel 2010. The Hive panel opens, as shown in the following screen shot: <br><br><img title="clip_image082 [4]" alt="clip_image082[4]" src="https://habrastorage.org/getpro/habr/post_images/4a8/028/666/4a802866620be7f5673d9131c6e772aa.jpg" width="390" height="210"><br><br><h4>  Creating a Hive ODBC Data Source for Excel </h4><br>  Select <b>Start</b> -&gt; <b>Control Panel</b> to start the Microsoft Windows <b>Control Panel</b> .  In the control panel window, select <b>System and Security</b> -&gt; <b>Administrative Tools</b> -&gt; <b>Data Sources (ODBC)</b> .  The <b>ODBC Data Source Administrator</b> dialog box <b>appears</b> . <br><br><img title="clip_image084 [4]" alt="clip_image084[4]" src="https://habrastorage.org/getpro/habr/post_images/2cc/5f8/4cf/2cc5f84cf1e5ea076a031f27aa52e11f.gif" width="471" height="390"><br><br>  In the <b>ODBC Data Source Administrator</b> dialog box, select the <b>System DSN</b> tab.  Click <b>Add</b> to create a data source.  Select the <b>HIVE</b> driver in the list of ODBC drivers. <br><br><img title="clip_image086 [4]" alt="clip_image086[4]" src="https://habrastorage.org/getpro/habr/post_images/d86/281/ee3/d86281ee312178a2a2ac2f8a9262ba9f.gif" width="478" height="358"><br><br>  Click <b>Finish</b> .  The <b>ODBC Hive Setup</b> dialog box appears, as shown in the screenshot below. <br><br><img title="clip_image088 [4]" alt="clip_image088[4]" src="https://habrastorage.org/getpro/habr/post_images/2a7/59b/8c0/2a759b8c0faaf30804b6d7b381899b8d.gif" width="450" height="503"><br><br>  Enter a name in the <b>Data Source Name</b> field.  For example, <b>MyHiveData</b> .  In the <b>Host</b> field, enter the name of the cluster node created in the portal.  For example, <b>myhadoopcluster.cloudapp.net</b> .  Specify the username for authentication on the portal. <br><br>  Click <b>OK</b> to save the Hive data source.  Click <b>OK</b> to close the <b>ODBC Data Source Administrator</b> dialog box. <br><br><h4>  Getting Hive Data in Excel </h4><br>  Start the 64-bit version of Excel 2010. Then go to the <b>Data</b> tab.  Click the <b>Hive Panel</b> to open the Hive panel in Excel.  In the <b>Select or Enter Hive Connection</b> drop-down list, specify the name of the data source created earlier. <br><br>  The system will ask you to enter a password for authentication in the cluster on the portal.  Enter your password and username.  In the <b>Select the Hive Object to Query</b> drop-down list, select <b>hivesampletable [Table]</b> .  Check all columns in the table.  The <b>Hive Query</b> panel should look something like this: <br><br><img title="clip_image090 [4]" alt="clip_image090[4]" src="https://habrastorage.org/getpro/habr/post_images/f63/ed7/c7b/f63ed7c7ba3ad96cc2caf901d53898f6.gif" width="203" height="441"><br><br>  Click <b>Execute Query</b> . <br><br><img title="clip_image092 [5]" alt="clip_image092[5]" src="https://habrastorage.org/getpro/habr/post_images/b62/3d8/d4f/b623d8d4f26855ec93770f4184c658ef.gif" width="727" height="480"><br><br>  To process the data from our example, you need to perform the following query: <br><br>  Select * from twitter <i>movies</i> vw limit 20 <br><br><h3>  findings </h3><br>  In this tutorial, we looked at how to request, explore, and analyze data from Twitter using Hadoop on Windows Azure and Hive query in Excel. </div><p>Source: <a href="https://habr.com/ru/post/152313/">https://habr.com/ru/post/152313/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../152301/index.html">Sergey Brin: You can buy a car with robotic control in five years</a></li>
<li><a href="../152305/index.html">RoboHornet: a new approach to browser performance testing</a></li>
<li><a href="../152307/index.html">AWS: Accelerated Media for RDS</a></li>
<li><a href="../152309/index.html">DariVVmeste.ru - all for one</a></li>
<li><a href="../152311/index.html">Automated OS installation on the example of Windows Embedded x64</a></li>
<li><a href="../152315/index.html">Explore the ocean with Google Maps</a></li>
<li><a href="../152317/index.html">Google maps go under water</a></li>
<li><a href="../152319/index.html">Digium G100 / G200 E1 / T1 / PRI Router</a></li>
<li><a href="../152321/index.html">Kickstarter has changed the rules for publishing projects</a></li>
<li><a href="../152325/index.html">Free course on working with Sublime Text 2</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>