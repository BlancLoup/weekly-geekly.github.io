<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>The history of a single request</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Submit your first day at the new job. The office is located in the area completely unknown to you Kurskaya metro station. Dinner time is coming. You o...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>The history of a single request</h1><div class="post__text post__text-html js-mediator-article"><div style="text-align:center;"><img src="https://habrastorage.org/webt/9q/ks/jt/9qksjtj-bhuaxl7okhilaidgqsa.png" alt="image"></div><br>  Submit your first day at the new job.  The office is located in the area completely unknown to you Kurskaya metro station.  Dinner time is coming.  You open a search application, write <b>‚Äúeat at Kurskaya‚Äù</b> and get a selection of options where you can dine. <br><br>  What is behind the request to <b>"eat at Kursk"</b> and how is it processed to find exactly what you need?  In the article I will tell you how the 2GIS Search team is doing everything possible to make life in cities more convenient and comfortable for users. <br><a name="habracut"></a><br>  It is important to understand that the text of the search query is only the tip of the iceberg, a small part of what the user directly interacts with.  The search query itself, in addition to the text, contains a lot of other data.  They include personalized information about a user's location, a map section that he sees, a set of records from his favorites and information about search modes.  For example, search on the map or in the building, and maybe search for travel.  Data - the key to success of good search functionality. <br><br>  We pay great attention to our data and their structure.  Moreover, we call the search algorithm in 2GIS itself a structural search, because it is designed for efficient and fast search in our structured data.  We specifically prepare the search index and the data from which it is built.  I won‚Äôt go into details, I‚Äôll just say that the data is organized in such a way that it is fairly simple to process, compressed well, and most importantly allow us to quickly process it even on mobile devices. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Moreover, the search is able to work offline, and therefore makes special demands on the speed and volume of the search index.  We pay great attention to this feature - we constantly compress the search index, we estimate the speed on various platforms and we speed up functionality where specific search cases exceed the set time limit.  By the way, we can boast that an ordinary search query in 2GIS on a mobile device is faster than the application draws a drop-down list of the results. <br><br>  Below, I‚Äôll open the veil of secrecy covering the magic of our search.  As an example, take the above-mentioned request <b>‚Äúto eat at Kursk‚Äù</b> .  Consider the stages of its processing and what happens at each of them.  So let's go! <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/cm/bo/ik/cmboik3cpygx88wzp2apwq7gvjq.jpeg" width="375" height="667"></div><br><br><h3>  Stage 1. Parsing </h3><br>  Input parameters: request <b>"eat at Kursk"</b> <br><br>  First of all, we need to parse the text of the request.  This is important, because after parsing we will be able to work not with the query text, but with the set of tokens of which it is composed.  Tokens are single query words.  In our case, we get a set of three tokens: <b>"eat"</b> , <b>"on"</b> , <b>"Kursk"</b> .  It would seem that everything is simple, but the devil is in the details.  And sometimes everything is not so obvious: for example, in requests for ‚Äúwi-fi‚Äù or ‚Äú2nd‚Äù we should understand that such combinations should be processed entirely. <br><br>  The tokens themselves contain information about the text of the word, about the position in the query, about the presence of a separator following the word and some characteristic of the word - the register of its characters, whether the word is a number, ordinal number, telephone number, address or other data. <br><br><h3>  Stage 2. Vocabulary search </h3><br>  Input parameters: tokens <b>"eat"</b> , <b>"on"</b> , <b>"Kursk"</b> <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/bm/nx/gs/bmnxgsmvl1wuogtxci70yebty3i.jpeg" alt="image"></div><br>  With the ready list of request tokens, we proceed to the stage of dictionary search, that is, to the stage where for each token we find the list of word forms from our data.  The word form is encoded information about the root of a word and its ending. <br><br>  We present the dictionary search as an algorithm for analyzing a dictionary represented as a graph.  The nodes in it are letters, or rather, symbols.  A graph consists of symbol nodes and transitions between these nodes.  The result of the traversal of our dictionary dictionary is a set of word forms that we can get based on the transferred tokens from the previous stage.  So we try to find in our dictionary a sequence of characters that matches the next token from the query.  In this case, as we all know, users make typos, skip letters, or even make mistakes in the keyboard layout.  Therefore, when traversing the dictionary, we apply some manipulations in order to take into account the possible human factor or try to guess what a person is typing right now.  In the course are various transformations of character chains: inserts, replacements, appending characters and the like. <br><br>  As a result, for each request token, we retrieve a set of word forms with information about the root and the end of a word, information about the number of characters in a word form, and an estimate of matching.  Assessment of finding - assessment, characterizing the dictionary distance of the found sequence of characters to the desired sequence.  The score describes how much the found string of characters differs from the request token. <br><br>  So for tokens we find the word forms: <br><br><ul><li>  13 forms for <b>"eat"</b> : "eat", "eat", "paese", "payot", ... </li><li>  3 forms for <b>"on"</b> : "na", "nu", "on" </li><li>  48 forms for <b>"Kursk"</b> : "Kursk", "Kursk", "Kursk", "Kursk", "Kurako", ... </li></ul><br>  Next, the found word forms are filtered depending on their assessment.  The best of them, that is, as close as possible to the words from the query, fall into the list of terms.  The term will be understood as a word form and assessment of findability.  Plus, in addition to the found word forms, terms obtained using the rules of morphology are added to the list.  An important stage in the processing of morphology is the addition of a morphological assessment.  The fact is that in our search we use a strong morphology processing mechanism, which allows us not only to find similar words from the dictionary, but also, according to the rules of the natural language, to more correctly find out what interests the user in meaning, not just in word similarity. <br><br>  So for tokens the following terms will be created: <br><br><ul><li>  <b>‚ÄúEat‚Äù</b> : ‚Äúeat‚Äù, ‚Äúeat‚Äù, ‚Äúeat‚Äù, ‚Äúeat‚Äù, ‚Äúeat‚Äù </li><li>  <b>"On"</b> : "on", "na", "nu" </li><li>  <b>"Kursk"</b> : "Kursk", "Kursk", "Kursk", "Kursk", "Kursk" </li></ul><br>  At this stage of vocabulary search ends.  We have processed the request and have for each token a list of terms that go to further processing.  These terms contain all the information about the word they represent, and have an estimate of how each of them was found. <br><br><h3>  Stage 3. Search for entries in the data </h3><br>  Input: term set for each part of the request <br><br><ul><li>  <b>‚ÄúEat‚Äù</b> : ‚Äúeat‚Äù, ‚Äúeat‚Äù, ‚Äúeat‚Äù, ‚Äúeat‚Äù, ‚Äúeat‚Äù </li><li>  <b>"On"</b> : "on", "na", "nu" </li><li>  <b>"Kursk"</b> : "Kursk", "Kursk", "Kursk", "Kursk", "Kursk" </li></ul><br>  Having obtained from the previous stage a set of terms for each of the parts of the query, we proceed to searching them by our index.  Each document in the data has many headers and is written in the <a href="https://ru.wikipedia.org/wiki/%25D0%2598%25D0%25BD%25D0%25B2%25D0%25B5%25D1%2580%25D1%2582%25D0%25B8%25D1%2580%25D0%25BE%25D0%25B2%25D0%25B0%25D0%25BD%25D0%25BD%25D1%258B%25D0%25B9_%25D0%25B8%25D0%25BD%25D0%25B4%25D0%25B5%25D0%25BA%25D1%2581">reverse index</a> so that we can easily find all references to the desired term in specific documents representing organizations, addresses, or any other. <br><br>  For each of the parts of the query and for each of the terms of these parts, we are looking for documents containing words encoded in terms.  So, for parts of the query for all terms, the occurrences will be found: <br><br><ul><li>  <b>"Eat"</b> : 18 occurrences </li><li>  <b>"On"</b> : 4304 occurrences </li><li>  <b>"Kursk"</b> : 79 occurrences </li></ul><br>  Obviously, the preposition <b>"to"</b> is found many times and therefore falls into a variety of document headers - "take-away coffee", "play <b>on the</b> console", "register the machine".  <b>"Eat"</b> and <b>"Kursk" are</b> also used repeatedly.  The second word with its terms is found in our data much more often than the first. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/3j/4m/da/3j4mdasko01hxwfdvyk3n_bih5a.jpeg" width="300" height="300"></div><br>  A hit is a match for a word from a search query to a word from a specific document.  These hits are saved to the list, which will be analyzed in the next step.  When adding a hit, we not only copy data from the term about the word in the document, but also calculate the best estimate of how the word could be found.  In other words, we choose the morphological assessment of the term, or an assessment of how the term was found in the dictionary, depending on which of the estimates is closer to the request token. <br><br>  This stage is a prelude to the start of the search itself.  We have prepared a set of hits in specific documents, on the basis of which the next algorithm will select and evaluate what needs to be given to the user as a result. <br><br><h3>  Stage 4. The heart of the search </h3><br>  Login: hit list <br><br><ul><li>  <b>"Eat"</b> : 18 occurrences </li><li>  <b>"On"</b> : 4304 occurrences </li><li>  <b>"Kursk"</b> : 79 occurrences </li></ul><br>  In fact, the hit list in our implementation is a tricky container.  It is important to understand that when adding hits to it, special nodes are created where the hits themselves are written, and a link to the document to which these hits fell. <br><br>  Therefore, it would be more correct to display the input data as follows: <br>  Login: document node container <br><br><ul><li>  <b>document1: {hits, ...}</b> </li><li>  <b>document2: {hits, ...}</b> </li><li>  <b>Document 3: {hits, ...}</b> </li><li>  <b>Document4: {hits, ...}</b> </li><li>  ... </li></ul><br>  First of all, the search begins to traverse the document tree and each node returns to the analyzer, which evaluates whether the document from this node is suitable to be the result for getting into the output.  To understand what volumes the analyzer has to work with, I will say that at the start the container contains more than 3000 nodes!  But the nodes can be added in the process of traversing, so it is actually processed even more.  It is no exaggeration to say that analysis is the most expensive part of the search and at the same time one of the most complex and large project functions.  Nevertheless, it runs extremely quickly, even on mobile devices. <br><br><h3>  Stage 5. Analysis </h3><br>  Input: <b>Document</b> node <b>: {hits, ...}</b> <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ak/jj/my/akjjmypuvajc-jymk3_x4o0r9vo.png"></div><br>  The analysis starts with a list of titles from the site.  The title is a title and a list of hits that fell into this title of the document.  These titles will be evaluated at the first stage.  It is important for us to know the usefulness of each title.  Utility can be good, weak and junk. <br><br>  For each of the titles selected the best of the chain of hits - the best in length and vocabulary score, made up of similarity of hits.  Based on the best chain and will assess the usefulness of the title.  To determine the utility of the chain, we also use a mechanism based on the frequency of words in the documents.  Roughly speaking, the more often a word occurs in a document, the more important it is ( <a href="https://ru.wikipedia.org/wiki/TF-IDF">TF-IDF</a> ).  So, if the chain contains a hit in an important word from the title of the document without strong morphological differences, for example, an excellent number or gender, we consider the title useful.  A title can also be useful if its hits completely cover the words in the title of the document. <br><br>  With the utility, all titles form a utility mask for the node.  This mask gives us an idea of ‚Äã‚Äãthe request tokens covered by the node being analyzed.  And with its help, we largely determine whether to analyze the node further. <br><br>  As a result, we have not just one document from the index, but a set of structural data representing a potential result with information on how it can be found. <br><br><h3>  Stage 6. Evaluation </h3><br>  Input: <b>Document</b> node <b>: {hits, ...}</b> <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/vs/ek/rs/vsekrs0bs3knmkccjj160wxpdzw.jpeg"></div><br>  Depending on the utility mask, we will either process the node, or go straight to the next one.  From the set of processed nodes, we accumulate various information about their totality.  For example, a set of node titles, the relationship of nodes among themselves, and some other data. <br><br>  Next comes the analysis of node titles interconnected with each other.  In fact, many nodes are combined into a graph of nodes, which we estimate. <br><br>  From the titles of the nodes of the graph, we obtain a list of ranked titles.  Simply put, from the set of nodes, we compile a single list of titles, in which for each element we also add an estimate and a combination of factors from the hit titles of all the participating nodes. <br><br>  Score - a structure with information about the number of words involved in a title from a query and many other factors about how a word was found and processed - starting from the stage of a dictionary search.  It is important that these ratings from the ranked title will participate in selecting the best ratings.  Some of them will be marked as selected and will contribute to the final assessment of the result that the user will see. <br><br>  The overall score provides the result with information that will be extremely important when sorting the entire issue.  It contains factors such as, for example, missing words from a query.  This measure characterizes the number of words that were not covered by the node with its structural information. <br><br>  Based on information about the usefulness of titles, the clarity of the result is determined.  Clarity can be good, weak and bad.  And it is calculated with the participation of all selected titles for the node being processed.  All these data have a dramatic impact on the further fate of the results and the order of their issuance. <br><br>  Gradually, we are approaching the end of the node analysis.  Before the node finally leaves the analyzer and becomes a potential result, we carry out several more refinement manipulations.  For example, on the compatibility of selected document headers. <br><br>  The node that has passed all the circles of the analyzer forms a result containing information about the selected headers and a document.  The result, which gives a good coverage of the search query, is sent to the post-processing. <br><br><h3>  Stage 7. Post-processing </h3><br>  Input: result constructed from the node <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ve/ue/9b/veue9bh6pkqqx7hd1pynhtyanms.jpeg"></div><br>  The analyzer filters out many records from the index before they become results.  However, the analysis can be evaluated and sent to the processing of many potential results.  To show the user only the most useful ones in order of relevance, we need to cut off the worst options found by the analyzer. <br><br>  At the previous step, a general assessment of the result was mentioned.  The overall assessment allows us to cut off the worst results at the post-processing stage.  Graduation is as follows.  The results that did not cover any request tokens are obviously worse than those results that completely cover the user's request.  Results with worse clarity are obviously less desirable than results with good clarity.  The postprocessor accumulates information about the incoming results and eliminates those that are obviously worse.  The rest adds to the list. <br><br>  Before we give the information about the cafe to the hungry user, we carry out the final processing - we sort them by relevance.  In the sorting involved many factors, calculated and aggregated at different stages of the search.  And in the end, the search results for the request <b>"to eat at Kursk"</b> is more than 500 results.  Many of them were found in the same way, and therefore have the same rating.  They will be sorted by user popularity. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ya/ml/jo/yamljowh757kha0ft1akjtwccae.jpeg" width="375" height="667"></div><br><br><h3>  Conclusion </h3><br>  We received the issue with a variety of cafes and restaurants and, joyful, we go for lunch.  All the results we got in a fraction of seconds.  Nor do we even need an internet connection. <br><br>  The application stores search indexes on the device.  This scheme provides us with non-trivial tasks to optimize data compression and processing speed - because the search should work quickly on a variety of mobile devices!  However, this is a completely different story. <br><br>  Today I tried to open the hood of our search engine and show how we help users find what they need in the city, and do it quickly and conveniently.  I hope it was informative. </div><p>Source: <a href="https://habr.com/ru/post/433696/">https://habr.com/ru/post/433696/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../433682/index.html">How to merge file contents into PowerShell. And do not suffer</a></li>
<li><a href="../433686/index.html">Amazon starts selling Apple products directly on its website.</a></li>
<li><a href="../433688/index.html">How the annual review of events on YouTube began a civil war</a></li>
<li><a href="../433692/index.html">To solve the most difficult optimization tasks, just add lasers</a></li>
<li><a href="../433694/index.html">Enter on "My Circle" search by users "Toaster"</a></li>
<li><a href="../433698/index.html">CSS philosophy</a></li>
<li><a href="../433700/index.html">Filter Bloom in Java using Guava</a></li>
<li><a href="../433704/index.html">An excerpt from the novel "Endless Joke" about videophones and masks for photo and video - years before their real appearance</a></li>
<li><a href="../433706/index.html">Sandbox in Windows</a></li>
<li><a href="../433708/index.html">Welcome to the fifth Industrial Cybersecurity Meetup</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>