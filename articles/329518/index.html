<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Experiments with malloc and neural networks</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="More than a year ago, when I was working as an anti-spammer at Mail.Ru Group, I was rolled over, and I wrote about experiments with malloc . At that t...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Experiments with malloc and neural networks</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/web/06c/d01/e07/06cd01e07bb54ac599913f91c47151ab.jpg" width="600"><br><br><p> More than a year ago, when I was working as an anti-spammer at Mail.Ru Group, I was rolled over, and I wrote about <a href="https://habrahabr.ru/company/mailru/blog/281497/">experiments with malloc</a> .  At that time, I was pleased to help conduct seminars on AKOS at the FIVT <a href="http://mipt.ru/">MIPT</a> , and there was a topic about memory allocation.  The topic is large and very interesting, and at the same time it covers both the low level of the core and the algorithm-intensive structures itself.  In all textbooks it is written that one of the main problems of dynamic memory allocation is its unpredictability.  As they say, I would have known a pack - I would have lived in Sochi.  If the oracle had previously told the entire plan for which memory would be allocated and freed, then it would have been possible to make an optimal strategy that minimizes heap fragmentation, peak memory consumption, etc.  From here, there was a fuss with manual allocators.  In the process of thinking, I came across the lack of logging tools <code>malloc()</code> and <code>free()</code> .  I had to write them!  Just about this was an article (and I also studied macOS).  Two parts were planned, but life turned abruptly and it was not until <code>malloc()</code> .  So, it's time to restore justice and realize the promise: <em>strike with deep training in predicting work with a bunch</em> . </p><br><p>  Inside: </p><br><ul><li>  Improving <code>libtracemalloc</code> interceptor <code>malloc()</code> . </li><li>  We build LSTM on Keras - a deep recurrent network. </li><li>  We teach the model on the example of the real application ( <a href="https://github.com/vcmi/vcmi">vcmi / vcmi</a> - and you thought, and here Heroes III?). </li><li>  We are surprised by unexpectedly good results. </li><li>  We fantasize about the practical application of technology. </li><li>  <a href="https://github.com/vmarkovtsev/hack_malloc">Sources</a> </li></ul><br><p>  Interesting?  Welcome under cat. </p><br><a name="habracut"></a><br><h3 id="libtracemalloc">  libtracemalloc </h3><br><p>  In the first article, we logged only <code>malloc()</code> .  That implementation had several drawbacks: </p><br><ol><li>  Multithreading was ignored when serializing calls.  In other words, we were losing information about which thread the memory was allocated from. </li><li>  Multithreading was ignored when writing to a file.  The <code>write()</code> call was made competitively, without a mutex.  Despite the fact that POSIX requires its atomicity, <a href="https://patchwork.kernel.org/patch/3755941/">in Linux up to version 3.14 there was an unpleasant positioning bug that the Principal himself fixed</a> , and <a href="https://github.com/fsaintjacques/experiments/tree/master/append-atomicity">some still test this property in practice</a> . </li><li>  Not logged in <code>free()</code> . </li></ol><br><p>  The following code corrects (1) and (2): </p><br><pre> <code class="hljs cpp"><span class="hljs-keyword"><span class="hljs-keyword">int</span></span> fd = <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">void</span></span>* (*__malloc)(<span class="hljs-keyword"><span class="hljs-keyword">size_t</span></span>) = <span class="hljs-literal"><span class="hljs-literal">NULL</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">pthread_mutex_t</span></span> write_sync = PTHREAD_MUTEX_INITIALIZER; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">inline</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">get_time</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">long</span></span></span></span><span class="hljs-function"><span class="hljs-params">* sec, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">long</span></span></span></span><span class="hljs-function"><span class="hljs-params">* mcsec)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-comment"><span class="hljs-comment">/* ... */</span></span> } <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function">* </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">malloc</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">size_t</span></span></span></span><span class="hljs-function"><span class="hljs-params"> size)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (!__malloc) { __malloc = (<span class="hljs-keyword"><span class="hljs-keyword">void</span></span>*(*)(<span class="hljs-keyword"><span class="hljs-keyword">size_t</span></span>)) dlsym(RTLD_NEXT, <span class="hljs-string"><span class="hljs-string">"malloc"</span></span>); } <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (!fd) { fd = open(LOG, O_WRONLY | O_CREAT | O_EXCL, <span class="hljs-number"><span class="hljs-number">0666</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (fd &lt; <span class="hljs-number"><span class="hljs-number">0</span></span>) { <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> __malloc(size); } } <span class="hljs-keyword"><span class="hljs-keyword">long</span></span> sec, mcsec; get_time(&amp;sec, &amp;mcsec); <span class="hljs-keyword"><span class="hljs-keyword">void</span></span>* ptr = __malloc(size); <span class="hljs-keyword"><span class="hljs-keyword">char</span></span> record[<span class="hljs-number"><span class="hljs-number">64</span></span>]; pthread_mutex_lock(&amp;write_sync); write(fd, record, <span class="hljs-built_in"><span class="hljs-built_in">sprintf</span></span>(record, <span class="hljs-string"><span class="hljs-string">"%ld.%06ld\t%ld\t%zu\t%p\n"</span></span>, sec, mcsec, pthread_self(), size, ptr)); pthread_mutex_unlock(&amp;write_sync); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> ptr; }</code> </pre> <br><p>  Accordingly, we use <code>pthread_self()</code> and execute <code>write()</code> under the mutex.  If you look closely, you can still see <code>O_EXCL</code> in the flags of <code>open()</code> .  I added it to correct the behavior during early <code>fork()</code> , i.e.  before working with a bunch.  Two forked processes simultaneously opened a file and overwritten each other. </p><br><p>  It remains to correct (3): </p><br><pre> <code class="hljs cpp"><span class="hljs-keyword"><span class="hljs-keyword">void</span></span> (*__free)(<span class="hljs-keyword"><span class="hljs-keyword">void</span></span>*) = <span class="hljs-literal"><span class="hljs-literal">NULL</span></span>; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">free</span></span></span><span class="hljs-function"> </span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">void</span></span></span></span><span class="hljs-function"><span class="hljs-params"> *ptr)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (!__free) { __free = (<span class="hljs-keyword"><span class="hljs-keyword">void</span></span>(*)(<span class="hljs-keyword"><span class="hljs-keyword">void</span></span>*)) dlsym(RTLD_NEXT, <span class="hljs-string"><span class="hljs-string">"free"</span></span>); } <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (!fd) { __free(ptr); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span>; } <span class="hljs-keyword"><span class="hljs-keyword">long</span></span> sec, mcsec; get_time(&amp;sec, &amp;mcsec); <span class="hljs-keyword"><span class="hljs-keyword">char</span></span> record[<span class="hljs-number"><span class="hljs-number">64</span></span>]; pthread_mutex_lock(&amp;write_sync); write(fd, record, <span class="hljs-built_in"><span class="hljs-built_in">sprintf</span></span>(record, <span class="hljs-string"><span class="hljs-string">"%ld.%06ld\t%ld\t-1\t%p\n"</span></span>, sec, mcsec, pthread_self(), ptr)); pthread_mutex_unlock(&amp;write_sync); __free(ptr); }</code> </pre> <br><p>  Logging happens completely by analogy with <code>malloc()</code> . </p><br><p>  As a result, we get something like the following: </p><br><pre> <code class="hljs css">0<span class="hljs-selector-class"><span class="hljs-selector-class">.000000</span></span> 140132355127680 552 0<span class="hljs-selector-tag"><span class="hljs-selector-tag">x2874040</span></span> 0<span class="hljs-selector-class"><span class="hljs-selector-class">.000047</span></span> 140132355127680 120 0<span class="hljs-selector-tag"><span class="hljs-selector-tag">x2874270</span></span> 0<span class="hljs-selector-class"><span class="hljs-selector-class">.000052</span></span> 140132355127680 1024 0<span class="hljs-selector-tag"><span class="hljs-selector-tag">x28742f0</span></span> 0<span class="hljs-selector-class"><span class="hljs-selector-class">.000079</span></span> 140132355127680 <span class="hljs-selector-tag"><span class="hljs-selector-tag">-1</span></span> 0<span class="hljs-selector-tag"><span class="hljs-selector-tag">x2874270</span></span> 0<span class="hljs-selector-class"><span class="hljs-selector-class">.000089</span></span> 140132355127680 <span class="hljs-selector-tag"><span class="hljs-selector-tag">-1</span></span> 0<span class="hljs-selector-tag"><span class="hljs-selector-tag">x28742f0</span></span> 0<span class="hljs-selector-class"><span class="hljs-selector-class">.000092</span></span> 140132355127680 <span class="hljs-selector-tag"><span class="hljs-selector-tag">-1</span></span> 0<span class="hljs-selector-tag"><span class="hljs-selector-tag">x2874040</span></span> 0<span class="hljs-selector-class"><span class="hljs-selector-class">.000093</span></span> 140132355127680 <span class="hljs-selector-tag"><span class="hljs-selector-tag">-1</span></span> (<span class="hljs-selector-tag"><span class="hljs-selector-tag">nil</span></span>) 0<span class="hljs-selector-class"><span class="hljs-selector-class">.000101</span></span> 140132355127680 37 0<span class="hljs-selector-tag"><span class="hljs-selector-tag">x2874040</span></span> 0<span class="hljs-selector-class"><span class="hljs-selector-class">.000133</span></span> 140132355127680 32816 0<span class="hljs-selector-tag"><span class="hljs-selector-tag">x2874070</span></span> 0<span class="hljs-selector-class"><span class="hljs-selector-class">.000157</span></span> 140132355127680 <span class="hljs-selector-tag"><span class="hljs-selector-tag">-1</span></span> 0<span class="hljs-selector-tag"><span class="hljs-selector-tag">x2874070</span></span> 0<span class="hljs-selector-class"><span class="hljs-selector-class">.000162</span></span> 140132355127680 8 0<span class="hljs-selector-tag"><span class="hljs-selector-tag">x2874070</span></span></code> </pre> <br><h3 id="lstm-na-keras">  LSTM at Keras </h3><br><p>  To begin with, let's define what we specifically want to predict.  It would be desirable to predict the sequence of future ones in the preceding call history of <code>malloc()</code> and <code>free()</code> , and immediately with the size.  It would be very cool to apply attention (attention) and immediately indicate which parts of the memory will be freed, but I suggest that the inquiring reader be engaged in this - an excellent thesis will be released.  Here I will do it easier and I will predict how much memory is released. </p><br><p>  The next point is that predicting the exact size of RMSE is a rotten and disastrous idea.  I tried: the network treacherously converges to the average value on all.  Therefore, I introduce size classes in powers of two, just like that of the famous <a href="https://en.wikipedia.org/wiki/Buddy_memory_allocation">buddy allocator</a> .  In other words, the prediction problem is posed as a classification problem.  Example: </p><br><table><thead><tr><th>  the size </th><th>  the class </th></tr></thead><tbody><tr><td>  one </td><td>  one </td></tr><tr><td>  2 </td><td>  2 </td></tr><tr><td>  3 </td><td>  2 </td></tr><tr><td>  four </td><td>  3 </td></tr><tr><td>  five </td><td>  3 </td></tr><tr><td>  6 </td><td>  3 </td></tr></tbody></table><br><p>  In total we have 32 classes, having put mental (incorrect) restriction on <code>malloc(uint32_t size)</code> .  In fact, there is 64-bit <code>size_t</code> , and you can allocate more than 4 GiB. </p><br><p>  We will take the class from <code>free()</code> from the corresponding <code>malloc()</code> call, since  we know the pointer to the memory being freed.  To somehow distinguish the classes of <code>malloc()</code> from the classes of <code>free()</code> , we add to the last 32. Total only 64 classes.  This, frankly, quite a bit.  If there are any regularities in our data, then any even the most stupid network should learn something from them.  The following code parses the log received from <code>libtracemalloc</code> . </p><br><pre> <code class="python hljs">threads = defaultdict(list) ptrs = {} <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> gzip.open(args.input) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> fin: <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> line <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> fin: parts = line[:<span class="hljs-number"><span class="hljs-number">-1</span></span>].split(<span class="hljs-string"><span class="hljs-string">b"\t"</span></span>) thread = int(parts[<span class="hljs-number"><span class="hljs-number">1</span></span>]) size = int(parts[<span class="hljs-number"><span class="hljs-number">2</span></span>]) ptr = parts[<span class="hljs-number"><span class="hljs-number">3</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> size &gt; <span class="hljs-number"><span class="hljs-number">-1</span></span>: threads[thread].append(size.bit_length()) ptrs[ptr] = size <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: size = ptrs.get(ptr, <span class="hljs-number"><span class="hljs-number">0</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> size &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">del</span></span> ptrs[ptr] threads[thread].append(<span class="hljs-number"><span class="hljs-number">32</span></span> + size.bit_length())</code> </pre> <br><p>  As you can see, we save new pointers and delete old ones, as if emulating a bunch.  Now we need to turn the <code>threads</code> dictionary into digestible <code>x</code> and <code>y</code> . </p><br><pre> <code class="python hljs">train_size = sum(max(<span class="hljs-number"><span class="hljs-number">0</span></span>, len(v) - maxlen) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> v <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> threads.values()) <span class="hljs-keyword"><span class="hljs-keyword">try</span></span>: x = numpy.zeros((train_size, maxlen), dtype=numpy.int8) <span class="hljs-keyword"><span class="hljs-keyword">except</span></span> MemoryError <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> e: log.error(<span class="hljs-string"><span class="hljs-string">"failed to allocate %d bytes"</span></span>, train_size * maxlen) <span class="hljs-keyword"><span class="hljs-keyword">raise</span></span> e <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> <span class="hljs-keyword"><span class="hljs-keyword">None</span></span> y = numpy.zeros((train_size, <span class="hljs-number"><span class="hljs-number">64</span></span>), dtype=numpy.int8) offset = <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> _, allocs <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> sorted(threads.items()): <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(maxlen, len(allocs)): x[offset] = allocs[i - maxlen:i] y[offset, allocs[i].bit_length()] = <span class="hljs-number"><span class="hljs-number">1</span></span> offset += <span class="hljs-number"><span class="hljs-number">1</span></span></code> </pre> <br><p>  Here <code>maxlen</code> is the length of the context by which we will predict.  By default, I set it to 100. It remains to create the model itself.  In this case - 2 layers of LSTM and polingling above, as standard. </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> models, layers, regularizers, optimizers model = models.Sequential() embedding = numpy.zeros((<span class="hljs-number"><span class="hljs-number">64</span></span>, <span class="hljs-number"><span class="hljs-number">64</span></span>), dtype=numpy.float32) numpy.fill_diagonal(embedding, <span class="hljs-number"><span class="hljs-number">1</span></span>) model.add(layers.embeddings.Embedding( <span class="hljs-number"><span class="hljs-number">64</span></span>, <span class="hljs-number"><span class="hljs-number">64</span></span>, input_length=x[<span class="hljs-number"><span class="hljs-number">0</span></span>].shape[<span class="hljs-number"><span class="hljs-number">-1</span></span>], weights=[embedding], trainable=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>)) model.add(getattr(layers, layer_type)( neurons, dropout=dropout, recurrent_dropout=recurrent_dropout, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)) model.add(getattr(layers, layer_type)( neurons // <span class="hljs-number"><span class="hljs-number">2</span></span>, dropout=dropout, recurrent_dropout=recurrent_dropout)) model.add(layers.Dense(y[<span class="hljs-number"><span class="hljs-number">0</span></span>].shape[<span class="hljs-number"><span class="hljs-number">-1</span></span>], activation=<span class="hljs-string"><span class="hljs-string">"softmax"</span></span>)) optimizer = getattr(optimizers, optimizer)(lr=learning_rate, clipnorm=<span class="hljs-number"><span class="hljs-number">1.</span></span>) model.compile(loss=<span class="hljs-string"><span class="hljs-string">"categorical_crossentropy"</span></span>, optimizer=optimizer, metrics=[<span class="hljs-string"><span class="hljs-string">"accuracy"</span></span>, <span class="hljs-string"><span class="hljs-string">"top_k_categorical_accuracy"</span></span>])</code> </pre> <br><div style="text-align:center;"><img src="https://habrastorage.org/web/86e/40a/3ad/86e40a3ad5134e87a9674e114dfb0d35.png"></div><br><p>  To handle memory with care, I use untrained Embedding and do not do one hot encoding beforehand.  So  <code>x</code> and <code>y</code> 8-bit (64 &lt;256), and the minibatch is 32-bit.  This is important because very short-running programs manage to generate tens of millions of samples.  <code>neurons</code> default is <code>neurons</code> 128, no dropouts.  Let's start learning! </p><br><pre> <code class="python hljs">model.fit(x, y, batch_size=batch_size, epochs=epochs, validation_split=validation)</code> </pre> <br><p>  I was forced to <code>export TF_CPP_MIN_LOG_LEVEL=1</code> , otherwise Tensorflow was spamming PoolAllocators. </p><br><h3 id="rezultaty">  results </h3><br><p>  As an experimental, let's take <a href="https://github.com/vcmi/vcmi">vcmi / vcmi</a> - the GPL-implementation of the third- <a href="https://github.com/vcmi/vcmi">person</a> engine, which I've been contributing to.  A very complete and quite good implementation, but the guys urgently need autotests.  And since I was talking, I really want to screw the Python API to the engine and try to implement neural network AI.  Sometimes people object, they say that Heroes have many degrees of freedom.  I answer that no one forces AlphaGo to do right away; you can start small, with fights. </p><br><p>  Clone, collect the vcmi code, get the original resources, run the game and collect the heap call log: </p><br><pre> <code class="hljs sql"><span class="hljs-comment"><span class="hljs-comment"># ... easy ... LD_PRELOAD=/path/to/libtracemalloc.so /path/to/vcmiclient</span></span></code> </pre> <br><p>  I launched Arrogance, wandered a couple of weeks, got resources.  The speed sags heavily, but this is not valgrind.  The resulting log unloaded on <a href="https://drive.google.com/open%3Fid%3D0B-w8jGUJto0iY3JycW1BVGluS0U">Google Drive</a> - 94MiB.  Distribution on the first 32 classes: </p><br><p><img src="https://habrastorage.org/web/725/cdf/1f4/725cdf1f4fc2483d9e5c93dc054e897e.png" alt="histogram"></p><br><p>  So  our baseline is 0.26 accuracy.  Let's try to improve it.  The training of the model took 10.5 hours per era on Pascal Titan (2 epochs, 21 hours, <code>validation_split</code> = 15%).  In general, the second era does not greatly change the result and only one is enough.  Such metrics turned out: </p><br><pre> <code class="hljs css"><span class="hljs-selector-tag"><span class="hljs-selector-tag">loss</span></span>: 0<span class="hljs-selector-class"><span class="hljs-selector-class">.0512</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">val_loss</span></span>: 0<span class="hljs-selector-class"><span class="hljs-selector-class">.1160</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">acc</span></span>: 0<span class="hljs-selector-class"><span class="hljs-selector-class">.9837</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">val_acc</span></span>: 0<span class="hljs-selector-class"><span class="hljs-selector-class">.9711</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">top_k_categorical_accuracy</span></span>: 1<span class="hljs-selector-class"><span class="hljs-selector-class">.0000</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">val_top_k_categorical_accuracy</span></span>: 0<span class="hljs-selector-class"><span class="hljs-selector-class">.9978</span></span></code> </pre> <br><p>  In my opinion, it came out very cool.  We achieved 97% accuracy of validation, which means approximately 20 correct predictions with an accuracy higher than 50%.  If we replace LSTM with GRU, then it will be possible to reduce the epoch time to 8 hours with slightly better metrics. </p><br><p>  What I see vectors of development of the model: </p><br><ol><li>  Increasing the number of neurons in the forehead, perhaps, will give an improvement in metrics. </li><li>  Experiments with architecture, metaparameters.  At a minimum, you need to investigate the dependence on the length of the context and the number of layers. </li><li>  Enrich the prediction context by expanding the call stack and using debuginfo.  From the chain of functions to the full source code. </li></ol><br><p>  The size of the trained model is 1 megabyte, which is much less than the full story - 98MB in gzip.  I am sure that having properly networked the network, it will be possible to reduce it without compromising quality. </p><br><h3 id="buduschee">  Future </h3><br><p>  ‚ÄúWait,‚Äù the reader will say, ‚Äúno one in their right mind will drive the network forward with each call to malloc.‚Äù  Of course, when every cycle counts, multiplying the matrix 128 by 100 by 64 looks silly.  But I have objections: </p><br><ol><li>  You need to run the network every 20 calls or even less.  If technology is improved, this number will increase. </li><li>  Multi-core processors have long become commonplace, and they are far from being used 100%.  During periods of program downtime, on a block in some <code>read()</code> , we have a tangible time quantum and resources for inference. </li><li>  Not far off neuroaccelerators.  <a href="https://en.wikipedia.org/wiki/Tensor_processing_unit">TPU is</a> already manufactured by <a href="https://cloud.google.com/tpu/">Google</a> , <a href="http://www.research.ibm.com/articles/brain-chip.shtml">IBM</a> , <a href="http://www.androidauthority.com/closer-look-samsung-mongoose-cpu-712587/">Samsung</a> .  Why not use them to speed up existing "simple" programs, analyzing their behavior over time and dynamically adapting runtime to them. </li></ol><br><h3 id="tldr">  TL; DR </h3><br><p>  Model RNN to predict the dynamic allocation and release of memory in the game Heroes III managed to train with an accuracy of 97%, which is very unexpected and cool.  There is a prospect to implement the idea in practice to create memory allocators of the new generation. </p><br><p> <a href="http://talks.sourced.tech/machine-learning-2017/"><img align="left" src="https://habrastorage.org/web/693/43d/90e/69343d90ef92438ab75620b75b29d5b4.jpg" width="300"></a>  Source code machine learning is a new, exciting topic.  Come to <a href="http://talks.sourced.tech/machine-learning-2017/">source {d} tech talks</a> conference on June 3, there will be Chalz Sutton, the author of <a href="http://homepages.inf.ed.ac.uk/csutton/">half of all articles</a> and Georgios Giusius, the star of <a href="http://msrconf.org/">Mining Software Repositories</a> and the founder of <a href="http://ghtorrent.org/">GHTorrent</a> .  Participation is free, the number of places is limited. </p></div>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <p>Source: <a href="https://habr.com/ru/post/329518/">https://habr.com/ru/post/329518/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../329506/index.html">What to do if PK Identity runs out of values?</a></li>
<li><a href="../329510/index.html">How to achieve the reuse of React components (Translation)</a></li>
<li><a href="../329512/index.html">Results WannaCry: a selection of basic materials on the "Habrahabr" and not only</a></li>
<li><a href="../329514/index.html">Stack Overflow brought more than a million users out of Vim</a></li>
<li><a href="../329516/index.html">Comprehensive online marketing guide. Day 1. Three ways to scale a business</a></li>
<li><a href="../329520/index.html">You have the right to anonymity. Part 2. Legislation against anonymity</a></li>
<li><a href="../329522/index.html">What is the difference between Bitcoin and other cryptocurrencies?</a></li>
<li><a href="../329524/index.html">Friday discussion: Russian vs foreign IT - company. Why everyone wants to work at Google</a></li>
<li><a href="../329528/index.html">Development of a chess program</a></li>
<li><a href="../329530/index.html">What did you encounter when translating the project to Android Studio 3.0 Preview and Gradle 4.0-milestone-1</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>