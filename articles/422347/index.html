<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Migrating a real-world application from standalone MySQL to Percona XtraDB Cluster</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Unfortunately, there is quite a bit of information on the Internet on the migration of real-world applications and the production of Percona XtraDB Cl...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Migrating a real-world application from standalone MySQL to Percona XtraDB Cluster</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/getpro/habr/post_images/2b3/23e/2d3/2b323e2d35539763c7a0d17a4694d5af.png" alt="image"><br><br>  Unfortunately, there is quite a bit of information on the Internet on the migration of real-world applications and the production of Percona XtraDB Cluster (hereinafter PXC).  I will try to correct this situation with my story and tell about our experience.  There will be no step-by-step installation instructions and the article should be viewed not as a replacement for off-documentation, but as a collection of recommendations. <br><a name="habracut"></a><br><h3>  Problem </h3><br>  I work as a system administrator at <a href="https://www.ultimate-guitar.com/">ultimate-guitar.com</a> .  Since we provide a web service, we naturally have backends and databases, which is the core of the service.  Uptime service directly depends on the performance of the database. <br><br>  Percona MySQL 5.7 was used as the database.  Redundancy has been implemented using the master replication scheme master.  Slaves were used to read some data. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/getpro/habr/post_images/05a/ca3/bc6/05aca3bc6ba1c357cd98c280e8a07772.png" alt="image"><br><br>  But this scheme did not suit us with the following minuses: <br><br><ul><li>  Due to the fact that in MySQL replication, asynchronous slaves could lag behind indefinitely.  All critical data had to be read from the master. </li><li>  From the previous paragraph follows the complexity of the development.  The developer could not simply make a request to the database, but was obliged to think over whether he was ready in each specific case for the slave lag and if not, then read the data from the master. </li><li>  Manual switching in case of an accident.  Automatic switching was problematic due to the fact that the MySQL architecture does not have built-in protection against split brain.  I would have had to write the arbiter with the complex logic of the choice of the master  When writing to both masters, there could be conflicts at the same time breaking the master replication and leading to the classic split brain. </li></ul><br>  A few dry numbers, so that you understand what we have worked with: <br><br>  Database size: 300 GB <br>  QPS: ~ 10k <br>  RW ratio: 96/4% <br>  Server Wizard Configuration: <br>  CPU: 2x E5-2620 v3 <br>  RAM: 128 Gb <br>  SSD: Intel Optane 905p 960 Gb <br>  Network: 1 Gbps <br><br>  We have a classic OLTP load with a lot of reading, which needs to be done very quickly and with a small amount of writing.  The load on the database is quite small due to the fact that caching is actively used in Redis and Memcached. <br><br><h3>  Decision making </h3><br>  As you may have guessed from the title, we chose PXC, but here I will explain why we chose it. <br><br>  We had 4 options: <br><br><ol><li>  DBMS change </li><li>  MySQL Group Replication </li><li>  Screw the necessary functionality by using scripts on top of the master replication master. </li><li>  MySQL Galera cluster (or its fork, for example PXC) </li></ol><br>  The option to change the database was practically not considered, since  the application is large, in many places it is tied to the functionality or syntax of mysql and, for example, migration to PostgreSQL will take a lot of time and resources. <br><br>  The second option was MySQL Group Replication.  Its undoubted advantage is that it develops in the vanilla MySQL branch, which means that in the future it will be widely distributed and will have a large pool of active users. <br><br>  But he has a few drawbacks.  Firstly, it imposes more restrictions on the application and database schema, which means it will be more difficult to migrate.  Secondly, Group Replication solves the problem of fault tolerance and the split brain, but replication in a cluster is still asynchronous. <br><br>  The third option, we also did not like too much for too many bicycles, which we will inevitably have to implement in solving the problem in this way. <br><br>  Galera made it possible to completely solve the MySQL fault tolerance problem and partially solve the problem of the relevance of data on the slaves.  Partially, because replication asynchrony is preserved.  After a transaction is committed on the local node, the changes are spilled onto the other nodes asynchronously, but the cluster makes sure that the nodes are not far behind and if they start to lag, then it artificially slows down the work.  The cluster ensures that after a transaction commit, no one can commit conflicting changes even on a node that has not yet replicated the changes. <br><br>  After migration, the scheme of our database should look like this: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/2d8/435/190/2d8435190207a5bb711d131d852a572f.png" alt="image"><br><br><h3>  Migration </h3><br>  Why migration is the second item after choosing a solution?  It's simple - the cluster contains a number of requirements that the application and the database must follow and we need to fulfill them before the migration. <br><br><ul><li>  <b>InnoDB engine for all tables.</b>  MyISAM, Memory and other backends are not supported.  The fix is ‚Äã‚Äãquite simple - we convert all the tables in InnoDB. </li><li>  <b>Binlog in ROW format.</b>  The cluster does not require binlog for work and if you do not need classic slaves, then you can turn it off, but the binlog format should be ROW. </li><li>  <b>All tables must have a PRIMARY / FOREIGN KEY.</b>  This is required for proper concurrent writing to the same table from different nodes.  For those tables that do not contain a unique key, you can use a composite Primary key or auto increment. </li><li>  <b>Do not use 'LOCK TABLES', 'GET_LOCK () / RELEASE_LOCK ()', 'FLUSH TABLES {{table}} WITH READ LOCK' or the isolation level 'SERIALIZABLE' for transactions.</b> </li><li>  <b>Do not use 'CREATE TABLE ... AS SELECT' queries</b> , since  they combine schema and data changes.  It is easily divided into 2 queries, the first of which creates a table, and the second fills with data. </li><li>  <b>Do not use 'DISCARD TABLESPACE' and 'IMPORT TABLESPACE'</b> , because  they are not replicated </li><li>  <b>Set the 'innodb_autoinc_lock_mode' options to '2'.</b>  This option may damage data when working with STATEMENT replication, but since the cluster is allowed to use only ROW replication, there will be no problems. </li><li>  <b>As a 'log_output', only 'FILE' is supported.</b>  If you have a log entry was kept in the table, you will have to remove it. </li><li>  <b>XA transactions are not supported.</b>  If they were used, you will have to rewrite the code without them. </li></ul><br>  I should note that almost all of these restrictions can be removed if you set the variable 'pxc_strict_mode = PERMISSIVE', but if you value your data, then it is better not to.  If you have 'pxc_strict_mode = ENFORCING' set, then MySQL will not let you perform the above operations or will not let you start the node. <br><br>  After we have fulfilled all the requirements for the database and have thoroughly tested the work of our application in dev environment, we can proceed to the next stage. <br><br><h3>  Cluster Deployment and Configuration </h3><br>  We have several databases running on the database servers and other databases do not need to be migrated to the cluster.  But the MySQL cluster package replaces classic mysql.  We had several solutions to this problem: <br><br><ul><li>  <b>Use virtualization and run a cluster in the VM.</b>  We did not like this option because of the large (compared to the others) overhead and the appearance of another entity that needs to be serviced. </li><li>  <b>Build your version of the package, which will put mysql in a nonstandard place.</b>  Thus, it will be possible to have several versions of mysql on one server.  A good option if you have a lot of servers, but the constant support of your package, which must be regularly updated can take quite a lot of time. </li><li>  <b>Use Docker.</b> </li></ul><br>  We chose Docker, but we use it in a minimal way.  Local data are used for data storage.  Uses the '--net host' operating mode to reduce network delays and CPU load. <br><br>  We also had to build our version of the Docker image.  The reason is that the standard Percona image does not support restoring positions at startup.  This means that each time the instance is restarted, it is not a fast IST synchronization that only floods the necessary changes, but a slow SST that completely reloads the base. <br><br>  Another issue is the size of the cluster.  In a cluster, each node stores the entire data set.  Therefore, reading scales well with increasing cluster size.  With the record, the situation is reversed - when committing, each transaction is validated for the absence of conflicts on all nodes.  Naturally, the more nodes, the more time a commit will take. <br>  Here we also have several options: <br><br><ul><li>  <b>2 nodes + arbitrator.</b>  2 nodes + arbitrator.  A good option for tests.  At the time of deployment of the second node on the master should not be recorded. <br></li><li>  <b>3 nodes.</b>  The classic option.  Balance of speed and reliability.  Please note that in this configuration one node should pull out the entire load, since  at the time of adding the third node will be the second donor. <br></li><li>  <b>4+ nodes.</b>  With an even number of nodes, an arbiter must be added to avoid the split-brain.  An option that is well suited for a very large amount of reading.  The reliability of the cluster also grows. </li></ul><br>  We have so far stopped at the version with 3 nodes. <br><br>  The cluster configuration almost completely copies the standalone MySQL configuration and differs in only a few options: <br><br>  <b>"Wsrep_sst_method = xtrabackup-v2"</b> This option specifies how to copy the nodes.  Other options are mysqldump and rsync, but they block the node for the duration of the copy.  I see no reason to use a non-‚Äúxtrabackup-v2‚Äù copy method. <br><br>  <b>"Gcache"</b> is an analogue of cluster binlog.  It is a circular buffer (in a file) of a fixed size in which all changes are recorded.  If you turn off one of the cluster nodes, and then turn it back on, it will try to read the missing changes from Gcache (IST sync).  If there are no changes needed in it, then a full reloading of the node is required (SST synchronization).  The size of gcache is set as follows: wsrep_provider_options = 'gcache.size = 20G;'. <br><br>  <b>wsrep_slave_threads</b> Unlike classic replication in a cluster, it is possible to simultaneously apply several ‚Äúwrite sets‚Äù to one database.  This option indicates the number of workers applying the changes.  It is better not to leave the default value 1, since  during the use of a large write set by the worker, the rest will wait in the queue and node replication will begin to lag behind.  Some people advise setting this parameter to 2 * CPU THREADS, but I think it is necessary to look at the number of parallel write operations you have. <br><br>  We stopped at a value of 64. With a smaller value, the cluster sometimes did not have time to apply all write sets from the queue during load spikes (for example, when launching heavy crowns). <br><br>  <b>wsrep_max_ws_size The</b> size of a single transaction in a cluster is limited to 2 GB.  But large transactions do not fit into the concept of PXC.  It is better to complete 100 transactions of 20 MB each than one for 2 GB.  Therefore, we first limited the size of the transaction in the cluster to 100 MB, and then reduced the limit to 50 MB. <br><br>  If you have strict mode enabled, you can set the variable " <b>binlog_row_image</b> " to "minimal".  This will reduce the size of the entries in the binlog several times (10 times in the test from Percona).  This will save disk space and allow transactions that did not fit into the limit with ‚Äúbinlog_row_image = full‚Äù. <br><br>  <b>Limits for SST.</b>  For Xtrabackup, which is used to fill the nodes, you can set a limit on network usage, the number of streams and the method of compression.  This is necessary to ensure that the donor server does not start to slow down when filling the node.  To do this, the ‚Äússt‚Äù section is added to the my.cnf file: <br><br><pre><code class="hljs cs">[<span class="hljs-meta"><span class="hljs-meta">sst</span></span>] rlimit = <span class="hljs-number"><span class="hljs-number">80</span></span>m compressor = <span class="hljs-string"><span class="hljs-string">"pigz -3"</span></span> decompressor = <span class="hljs-string"><span class="hljs-string">"pigz -dc"</span></span> backup_threads = <span class="hljs-number"><span class="hljs-number">4</span></span></code> </pre> <br>  We limit the copy speed to 80 MB / sec.  For compression use pigz, this is a multi-threaded version of gzip. <br><br>  <b>GTID</b> If you use classic slaves, then I recommend to enable GTID on the cluster.  This will allow you to connect the slave to any node of the cluster without reloading the slave. <br><br>  Additionally, I want to talk about 2 cluster mechanisms, their meaning and configuration. <br><br><h4>  Flow control </h4><br>  Flow control is a way to manage the write load on a cluster.  It does not allow nodes to lag too far in replication.  Thus, "almost synchronous" replication is achieved.  The mechanism of operation is quite simple - as soon as the node has a queue for receiving it reaches the set value, it sends the message ‚ÄúFlow control pause‚Äù to the other nodes, which tells them to wait until the new transaction commits until the lagging node finishes the queue . <br><br>  From here several things follow: <br><br><ol><li>  Recording in a cluster will occur at the speed of the slowest node.  (But this can be tweaked.) </li><li>  If you have a lot of conflict when committing transactions, then you can adjust Flow Control more aggressively, which should reduce their number. </li><li>  The maximum node lag in a cluster is a constant, not in time, but in the number of transactions in the queue.  The time lag depends on the average transaction size and the number of wsrep_slave_threads. </li></ol><br>  You can view the Flow control settings as follows: <br><br> <code>mysql&gt; SHOW GLOBAL STATUS LIKE 'wsrep_flow_control_interval_%'; <br> wsrep_flow_control_interval_low | 36 <br> wsrep_flow_control_interval_high | 71 <br></code> <br>  First of all, we are interested in the ‚Äúwsrep_flow_control_interval_high‚Äù parameter.  It adjusts the queue length at which FC pause is turned on.  This parameter is calculated by the formula: gcs.fc_limit * ‚àöN (where N = the number of nodes in the cluster.). <br><br>  The second parameter is ‚Äúwsrep_flow_control_interval_low‚Äù.  It is responsible for the value of the queue length, after which the FC is turned off.  Calculated by the formula: wsrep_flow_control_interval_high * gcs.fc_factor.  By default, gcs.fc_factor = 1. <br><br>  Thus, by changing the queue length, we can manage the replication lag.  Reducing the queue length will increase the time the cluster spends in FC pause, but it will reduce the lag of nodes. <br><br>  You can set the session variable " <b>wsrep_sync_wait</b> = 7".  This will force the PXC to perform read or write requests only after all write-sets in the current queue have been applied.  Naturally this will increase latency requests.  Increased latency is directly proportional to the length of the queue. <br><br>  It is also desirable to reduce the maximum transaction size to the minimum possible, so as not to accidentally skip long transactions. <br><br><h4>  EVS or Auto Evict </h4><br>  This mechanism allows you to throw out the nodes with which intermittent communication (for example, packet loss or long delays) or which respond slowly.  Thanks to him, the problems of communication with one node will not put the entire cluster, and allow you to disable the node and continue to work in normal mode.  This mechanism can be especially useful when operating a cluster via WAN or non-controlled sections of the network.  By default, EVS is turned off. <br><br>  To enable it, you need to add the ‚Äúevs.version = 1;‚Äù and ‚Äúevs.auto_evict = 5;‚Äù options to the <b>wsrep_provider_options</b> parameter (the number of operations after which the node turns off. A value of 0 turns off EVS.) There are also several parameters that allow you to fine-tune EVS: <br><br><ul><li>  <b>evs.delayed_margin The</b> time the <b>node</b> is allotted to respond.  By default, 1 sec., But when operating in a local network, it can be reduced to 0.05-0.1 sec or less. </li><li>  <b>evs.inactive_check_period Check</b> period.  Default 0.5 sec </li></ul><br>  In fact, the time that a node can work on problems before an EVS triggers is evs.inactive_check_period * evs.auto_evict.  You can also set "evs.inactive_timeout" and the node that did not respond this time will be immediately thrown out, by default 15 seconds. <br><br>  An important caveat is that this mechanism will not return the node itself when the connection is restored.  It must be restarted by hand. <br><br>  We set up EVS at home, but we haven‚Äôt had a chance to test it in combat. <br><br><h3>  Load balancing </h3><br>  In order for clients to use the resources of each node evenly, and to perform queries only on the live nodes of the cluster, we need a load balancer.  Percona offers 2 solutions: <br><br><ul><li>  <b>ProxySQL.</b>  This is L7 proxy for MySQL. </li><li>  <b>Haproxy.</b>  But Haproxy does not know how to check the status of a cluster node and determine whether it is ready to execute queries.  To solve this problem it is proposed to use an additional <a href="https://github.com/olafz/percona-clustercheck">percona-clustercheck</a> script <a href="https://github.com/olafz/percona-clustercheck">.</a> </li></ul><br>  At first, we wanted to use ProxySQL, but after testing the performance, it turned out that by latency it loses Haproxy by about 15-20% even when using the fast_forward mode (in this mode query rewrite, routing and many other ProxySQL functions do not work, requests are proxied as-is) . <br><br>  Haproxy is faster, but Percona has a few drawbacks. <br><br>  First, it is written in bash, which does not contribute to its customization.  A more serious problem is that it does not cache the result of the MySQL check.  Thus, if we have 100 clients, each of which checks the status of the node once every 1 second, the script will make a request to MySQL every 10 ms.  If, for some reason, MySQL starts to work slowly, the verification script will start creating a huge number of processes, which will not exactly improve the situation. <br><br>  It was decided to write <a href="https://github.com/larrabee/pxc-checker">my own solution</a> in which the MySQL status check and the Haproxy response are not related to each other.  The script checks the status of the node in the background at regular intervals and caches the result.  The web server gives Haproxy the cached result. <br><br><div class="spoiler">  <b class="spoiler_title">Haproxy configuration example</b> <div class="spoiler_text"> <code>listen db <br> bind 127.0.0.1:3302 <br> mode tcp <br> balance first <br> default-server inter 200 rise 6 fall 6 <br> option httpchk HEAD / <br> server node1 192.168.0.1:3302 check port 9200 id 1 <br> server node2 192.168.0.2:3302 check port 9200 backup id 2 <br> server node3 192.168.0.3:3302 check port 9200 backup id 3 <br> <br> listen db_slave <br> bind 127.0.0.1:4302 <br> mode tcp <br> balance leastconn <br> default-server inter 200 rise 6 fall 6 <br> option httpchk HEAD / <br> server node1 192.168.0.1:3302 check port 9200 backup <br> server node2 192.168.0.2:3302 check port 9200 <br> server node3 192.168.0.3:3302 check port 9200 <br></code> <br>  This example shows a configuration with one master.  The rest of the cluster servers work as slaves. <br></div></div><br><h3>  Monitoring </h3><br>  To monitor the status of the cluster, we used Prometheus + mysqld_exporter and Grafana to visualize the data.  Since  mysqld_exporter collects a bunch of metrics to create dashboards on your own rather tedious.  You can take ready-made <a href="https://github.com/percona/grafana-dashboards">dashboards from Percona</a> and customize them for yourself. <br><br>  We also use Zabbix to collect the main cluster metrics and alerting. <br><br>  The main cluster metrics that are desirable to monitor: <br><br><ul><li>  <b>wsrep_cluster_status</b> On all nodes, the value should be ‚ÄúPrimary‚Äù.  If the value is ‚Äúnon-primary‚Äù, then this node has lost connection with the cluster quorum. </li><li>  <b>wsrep_cluster_size</b> The number of nodes in the cluster.  This also includes "lost" nodes that should be in a cluster, but for some reason not available.  When the node is turned off gently, the value of this variable decreases. </li><li>  <b>wsrep_local_state</b> Indicates whether the node is an active member of the cluster and is ready to work. </li><li>  <b>wsrep_evs_state</b> An important parameter if you have the Auto Eviction mechanism enabled (disabled by default).  This variable indicates that EVS considers this node healthy. </li><li>  <b>wsrep_evs_evict_list</b> A list of nodes that have been thrown out of EVS from the cluster.  Normally, the list should be empty. </li><li>  <b>wsrep_evs_delayed</b> List of candidates for deletion by EVS.  Must also be empty. </li></ul><br>  Key performance metrics: <br><br><ul><li>  <b>wsrep_evs_repl_latency</b> Shows (minimum / average / maximum / station deviation / packet size) delay communication within the cluster.  That is, it measures network latency.  Increasing values ‚Äã‚Äãmay indicate network congestion or cluster nodes.  This metric is recorded even when EVS is off. </li><li>  <b>wsrep_flow_control_paused_ns</b> Time (in ns) since the launch of the node, which she spent in Flow control pause.  Ideally, it should be 0. The growth of this parameter indicates a cluster performance problem or a lack of ‚Äúwsrep_slave_threads‚Äù.  It is possible to determine which node can be slowed down by the " <b>wsrep_flow_control_sent</b> " parameter. </li><li>  <b>wsrep_flow_control_paused The</b> percentage of time since the last execution of ‚ÄúFLUSH STATUS;‚Äù that the node spent in Flow control pause.  Also, like the previous variable should tend to zero. </li><li>  <b>wsrep_flow_control_status</b> Shows whether the Flow Control is currently running.  On the initiating FC pause node, the value of this variable will be ON. </li><li>  <b>wsrep_local_recv_queue_avg</b> The average length of the queue to receive.  The growth of this parameter indicates problems with node performance. </li><li>  <b>wsrep_local_send_queue_avg</b> The average length of a send queue.  The growth of this parameter indicates the problems with network performance. </li></ul><br>  There are no universal recommendations on the values ‚Äã‚Äãof these parameters.  It is clear that they should tend to zero, but on a real load, this is likely to be wrong and you will have to determine for yourself where the boundary of the normal state of the cluster lies. <br><br><h3>  Backup </h3><br>  Cluster backup is almost the same as standalone mysql.  For production use, we have several options. <br><br><ul><li>  Remove a backup from one of the ‚Äúprofitable‚Äù nodes with xtrabackup.  The easiest option, but during the backup, the cluster performance will sink. </li><li>  Use classic slaves and take backups from the replica. </li></ul><br>  The backups from standalone and from the cluster version created using xtrabackup are portable between each other.  That is, the backup taken from the cluster can be deployed to standalone mysql and vice versa.  Naturally a major version of MySQL should be the same, preferably a minor one.  Backups made using mysqldump are naturally portable too. <br><br>  The only caveat is that after deploying the backup, you need to run the mysql_upgrade script that will check and correct the structure of some system tables. <br><br><h3>  Data migration </h3><br>  Now that we‚Äôve figured out how to configure, monitor, and other things, you can start migrating on the sale. <br><br>  Migration of data in our scheme was quite simple, but we got a little messy;). <br>  Legend - master 1 and master 2 are linked by master replication.  The recording goes only to master 1. Master 3 is a clean server. <br><br>  Our migration plan (in the plan, I will omit the operations with the slaves for simplicity and will only talk about the master servers). <br><br><h4>  Attempt 1 </h4><br><ol><li>  We remove the database backup from wizard 1 using xtrabackup. </li><li>  Copy the backup to master 3 and start the cluster in single-node mode. </li><li>  Set up master replication between masters 3 and 1. </li><li>  We switch read and write to master 3. We check the operation of the application. </li><li>  On wizard 2, turn off replication and start cluster MySQL.  We are waiting for him to copy the database from master 3. During the copying, we had a cluster of one node in the status ‚ÄúDonor‚Äù and one still not working node.  During copying, we got a bunch of locks and in the end both nodes fell with an error (the creation of a new node cannot be completed due to dead locks).  This little experiment cost us four minutes of downtime. </li><li>  Switch read and write back to master 1. </li></ol><br>  The migration did not work because when testing the circuit in a dev environment, there was practically no write traffic to the database, and if the same circuit was repeated, problems got out under load. <br>  We changed the migration scheme a bit to avoid these problems and tried again, on the 2nd time successfully;). <br><br><h4>  Attempt 2 </h4><br><ol><li>  Restart master 3 so that it works again in single-node mode. </li><li>  Re-raise on the master 2 cluster MySQL.  At the moment, only the replication traffic was sent to the cluster, so there were no repetition of problems with locks and the second node was successfully added to the cluster. </li><li>  Again we switch reading and writing to master 3. We check the operation of the application. </li><li>  Turning off master replication with master 1. Turning on master 1 cluster mysql and wait until it starts.  In order not to step on the same rake, it is important that Donor does not write the application to the node (details in the section about load balancing).  After launching the third node, we will have a fully functional cluster of three nodes. </li><li>  You can remove a backup from one of the cluster nodes and create the number of classic slaves you need. </li></ol><br>  The difference between the second scheme and the first one is that we switched the traffic to the cluster only after raising the second node in the cluster. <br><br>  This procedure took about 6 hours. <br><br><h3>  Multi-master </h3><br>  After the migration, our cluster worked in the single-master mode, that is, the entire record went to one of the servers, and the rest was only read data. <br><br>  After switching production to multi-master mode, we ran into a problem - transaction conflicts occurred much more often than we expected.  It was especially bad with queries that change many records, for example, update the value of all records in a table.  Those transactions that were successfully performed on the same node in series on the cluster are executed in parallel and the longer transaction receives a deadlock error.  I will not pull, after several attempts to fix it at the application level, we abandoned the idea with a multi-master. <br><br><h3>  Other nuances </h3><br><ul><li>  A cluster can be a slave.  When using this function, I recommend adding to the config of all nodes except the one that is the slave option ‚Äúskip_slave_start = 1‚Äù.  Otherwise, each new node will start replication from the wizard, which will cause either replication errors or data corruption on the replica. </li><li>  As I said, Donor node can not normally serve customers.  It must be remembered that in a cluster of three nodes situations are possible when one node has flown out, the second is a donor and only one node remains for customer service. </li></ul><br><h3>  findings </h3><br>  After migration and some time of operation, we came to the following conclusions. <br><br><ul><li>  The Galera cluster works and is fairly stable (at least until there are abnormal node drops or there is no abnormal behavior).  In terms of resiliency, we got exactly what we wanted. </li><li>  Percona's multi-master applications are primarily marketing.  Yes, it is possible to use the cluster in this mode, but this will require a deep rework of the application for this usage model. </li><li>  There is no synchronous replication, but now we control the maximum lag of the nodes (in transactions).  Together with the limitation of the maximum transaction size of 50 MB, we can fairly accurately predict the maximum lag time of the nodes.  Developers become easier to write code. </li><li>  In monitoring, we observe short-term peaks in the growth of the replication queue.  The reason is our 1 Gbit / s network.  It is possible to operate a cluster on such a network, but there are problems when a load spikes.  Now we are planning to upgrade the network to 10 Gbit / s. </li></ul><br>  Total of the three "hotelok" we got about a half.  The most important requirement is fault tolerance. <br><br>  Our PXC configuration file for those interested in: <br><br><div class="spoiler">  <b class="spoiler_title">my.cnf</b> <div class="spoiler_text"> <code>[mysqld] <br> #Main <br> server-id = 1 <br> datadir = /var/lib/mysql <br> socket = mysql.sock <br> port = 3302 <br> pid-file = mysql.pid <br> tmpdir = /tmp <br> large_pages = 1 <br> skip_slave_start = 1 <br> read_only = 0 <br> secure-file-priv = /tmp/ <br> <br> #Engine <br> innodb_numa_interleave = 1 <br> innodb_flush_method = O_DIRECT <br> innodb_flush_log_at_trx_commit = 2 <br> innodb_file_format = Barracuda <br> join_buffer_size = 1048576 <br> tmp-table-size = 512M <br> max-heap-table-size = 1G <br> innodb_file_per_table = 1 <br> sql_mode = "NO_ENGINE_SUBSTITUTION,NO_AUTO_CREATE_USER,ERROR_FOR_DIVISION_BY_ZERO" <br> default_storage_engine = InnoDB <br> innodb_autoinc_lock_mode = 2 <br> <br> #Wsrep <br> wsrep_provider = "/usr/lib64/galera3/libgalera_smm.so" <br> wsrep_cluster_address = "gcomm://192.168.0.1:4577,192.168.0.2:4577,192.168.0.3:4577" <br> wsrep_cluster_name = "prod" <br> wsrep_node_name = node1 <br> wsrep_node_address = "192.168.0.1" <br> wsrep_sst_method = xtrabackup-v2 <br> wsrep_sst_auth = "USER:PASS" <br> pxc_strict_mode = ENFORCING <br> wsrep_slave_threads = 64 <br> wsrep_sst_receive_address = "192.168.0.1:4444" <br> wsrep_max_ws_size = 50M <br> wsrep_retry_autocommit = 2 <br> wsrep_provider_options = "gmcast.listen_addr=tcp://192.168.0.1:4577; ist.recv_addr=192.168.0.1:4578; gcache.size=30G; pc.checksum=true; evs.version=1; evs.auto_evict=5; gcs.fc_limit=80; gcs.fc_factor=0.75; gcs.max_packet_size=64500;" <br> <br> #Binlog <br> expire-logs-days = 4 <br> relay-log = mysql-relay-bin <br> log_slave_updates = 1 <br> binlog_format = ROW <br> binlog_row_image = minimal <br> log_bin = mysql-bin <br> log_bin_trust_function_creators = 1 <br> <br> #Replication <br> slave-skip-errors = OFF <br> relay_log_info_repository = TABLE <br> relay_log_recovery = ON <br> master_info_repository = TABLE <br> gtid-mode = ON <br> enforce-gtid-consistency = ON <br> <br> #Cache <br> query_cache_size = 0 <br> query_cache_type = 0 <br> thread_cache_size = 512 <br> table-open-cache = 4096 <br> innodb_buffer_pool_size = 72G <br> innodb_buffer_pool_instances = 36 <br> key_buffer_size = 16M <br> <br> #Logging <br> log-error = /var/log/stdout.log <br> log_error_verbosity = 1 <br> slow_query_log = 0 <br> long_query_time = 10 <br> log_output = FILE <br> innodb_monitor_enable = "all" <br> <br> #Timeout <br> max_allowed_packet = 512M <br> net_read_timeout = 1200 <br> net_write_timeout = 1200 <br> interactive_timeout = 28800 <br> wait_timeout = 28800 <br> max_connections = 22000 <br> max_connect_errors = 18446744073709551615 <br> slave-net-timeout = 60 <br> <br> #Static Values <br> ignore_db_dir = "lost+found" <br> <br> [sst] <br> rlimit = 80m <br> compressor = "pigz -3" <br> decompressor = "pigz -dc" <br> backup_threads = 8 <br></code> <br></div></div><br><h3>  Sources and useful links </h3><br>  ‚Üí <a href="">Our Docker image</a> <br>  ‚Üí <a href="https://www.percona.com/doc/percona-xtradb-cluster/LATEST/index.html">Percona XtraDB Cluster 5.7 Documentation</a> <br>  ‚Üí <a href="http://galeracluster.com/documentation-webpages/monitoringthecluster.html">Monitoring Cluster Status - Galera Cluster Documentation</a> <br>  ‚Üí <a href="http://galeracluster.com/documentation-webpages/galerastatusvariables.html">Galera Status Variables - Galera Cluster Documentation</a> </div><p>Source: <a href="https://habr.com/ru/post/422347/">https://habr.com/ru/post/422347/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../422335/index.html">The smallest Linux computers</a></li>
<li><a href="../422337/index.html">Yandex has launched a cloud</a></li>
<li><a href="../422339/index.html">"I think JavaScript is not suitable for the web." 10 Questions to the Programmer, 4th Edition (from Berlin)</a></li>
<li><a href="../422341/index.html">IoT - promote while others think</a></li>
<li><a href="../422345/index.html">Server in the clouds: the results of the project</a></li>
<li><a href="../422351/index.html">Remote code execution via uploading pictures on your server or local computer to ghostscript / imagick</a></li>
<li><a href="../422353/index.html">Instructions for working with TensorFlow Object Detection API</a></li>
<li><a href="../422355/index.html">Games with time: we accelerate the application at the level of perception</a></li>
<li><a href="../422357/index.html">Deep learning to determine the style and genre of paintings</a></li>
<li><a href="../422359/index.html">The results of the quest that you have passed. Or not</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>