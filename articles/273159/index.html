<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Non-local image smoothing algorithm</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Removing noise from an image is one of the fundamental operations of computer vision. Smoothing algorithms are used almost everywhere: they can be bot...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Non-local image smoothing algorithm</h1><div class="post__text post__text-html js-mediator-article">  Removing noise from an image is one of the fundamental operations of computer vision.  Smoothing algorithms are used almost everywhere: they can be both a stand-alone procedure for improving photos, and the first step for a more complex procedure, for example, for recognizing objects in an image.  Therefore, there are a great many ways of smoothing, and I would like to tell you about one of them, which differs from the others by its good applicability on textures and images with a large number of identical details. <br><br>  There are a lot of pictures under the cut, more accurate with traffic. <br><a name="habracut"></a><br><h4>  Preliminary information </h4><br>  Briefly about the task.  It is assumed that in some ideal world we can get the perfect image <img src="http://tex.s2cms.ru/svg/I" alt="I">  (matrix or vector <img src="http://tex.s2cms.ru/svg/N%20%5Ctimes%20M" alt="N \ times M">  elements), which ideally conveys information about the outside world.  Unfortunately, we do not live in such a beautiful place, and therefore, for various reasons, we have to operate with images <img src="http://tex.s2cms.ru/svg/I%20%2B%20n" alt="I + n">  where <img src="http://tex.s2cms.ru/svg/n" alt="n">  - matrix or noise vector.  There are many models of noise, but in this article we will assume that <img src="http://tex.s2cms.ru/svg/n" alt="n">  - white Gaussian noise.  According to the information we are trying to restore the image <img src="http://tex.s2cms.ru/svg/I_d" alt="I_d">  that will be as close as possible to the perfect image <img src="http://tex.s2cms.ru/svg/I" alt="I">  .  Unfortunately, this is almost always impossible, since in case of noise some data is inevitably lost.  In addition, the very formulation of the problem involves an infinite number of solutions. <br><br>  As a rule, <a href="http://habrahabr.ru/post/142818/">ordinary smoothing filters</a> set a new value for each pixel using information about its neighbors.  A cheap and angry Gaussian filter, for example, collapses an image matrix with a Gaussian matrix.  As a result, in a new image, each pixel is a weighted sum of a pixel with the same number of the original image and its neighbors.  A slightly different approach uses the median filter: it replaces each pixel with the median among all nearby pixels.  The development of ideas for these methods of smoothing is a bilateral filter.  This procedure takes a weighted sum around, relying both on the distance to the selected pixel and on the proximity of pixels in color. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h4>  Filter idea </h4><br>  However, all of the above filters use only information about nearby pixels.  The main idea of ‚Äã‚Äãa non-local smoothing filter is to use all the information in the image, and not just the pixels adjacent to the one being processed.  How does this work, because often the values ‚Äã‚Äãat remote points do not depend on each other? <br><br>  It is obvious that if we have several images of the same object with different noise levels, then we can compose them into one image without noise.  If these several objects are placed in different places of the same image, then we can still use this additional information (the small thing is to first find these objects).  And even if these objects look a bit different or partially overlapped, we still have redundant data that can be used.  The non-local smoothing filter uses this idea: it finds similar areas of the image and applies the information from them for mutual averaging.  Of course, that parts of the image are similar, does not mean that they belong to the same objects, but, as a rule, the approximation is quite good.  Look at the drawing with lines.  Obviously, windows 2 and 3 are similar to window 1, but windows 4, 5 and 6 are not.  In the photo of the Hungarian Parliament, you can also notice a large number of identical elements. <br><br><img src="https://habrastorage.org/files/7d1/011/f66/7d1011f66b094a0ea071a784481494cd.png" alt="image"><img src="https://habrastorage.org/files/cdf/324/bf5/cdf324bf562e4cd7849cd3dbd69aa080.png" alt="image"><br><img src="https://habrastorage.org/files/d34/af7/e50/d34af7e50c204d2a960e660ed4833083.jpg" alt="image"><br><br>  Suppose that if a neighborhood of a pixel in one window looks like a neighborhood of the corresponding pixel in another window, then the values ‚Äã‚Äãof these pixels can be used for mutual averaging (blue and green points in the figure).  But how to find these similar windows?  How to match their weights, with what force do they influence each other?  We formalize the concept of "similarity" of image pieces.  First, we need the function of distinguishing two pixels.  Everything is simple here: for black-and-white images, the modulus of the difference in pixel values ‚Äã‚Äãis usually used.  If there is any additional information about the image, options are possible.  For example, if it is known that a clean image consists of objects of absolutely black color on a completely white background, a good idea would be to use a metric that matches the zero distance to pixels that are not very different in color.  In the case of color images, again, options are possible.  You can use the Euclidean metric in RGB format or something more cunning in HSV format.  The ‚Äúdifferentness‚Äù of the image windows is just the sum of the differences in their pixels. <br><br>  Now it would be good to convert the resulting value to a more familiar weight format. <img src="http://tex.s2cms.ru/svg/w%20%5Cin%20%5B0%2C%201%5D" alt="w \ in [0, 1]">  .  Let's transfer the difference of windows calculated at the previous step into some decreasing (or at least non-increasing) function and normalize the result obtained by sum of the values ‚Äã‚Äãof this function on all possible windows.  Usually, the role of such a function appears familiar to all the tooth gnash <img src="http://tex.s2cms.ru/svg/e%5E%7B-%5Cfrac%7Bx%5E2%7D%7Bh%5E2%7D" alt="e ^ {- \ frac {x ^ 2} {h ^ 2}">  where <img src="http://tex.s2cms.ru/svg/x" alt="x">  - distance, and <img src="http://1450831086466697032345" alt="h">  - parameter of scatter of scales.  The more <img src="http://1450831086466697032345" alt="h">  the less effect the difference between the windows on anti-aliasing.  With <img src="http://1450831086466697032345%20%5Crightarrow%20%5Cinfty" alt="h \ rightarrow \ infty">  , all windows regardless of the difference between them equally contribute to each pixel, and the image will turn out perfectly gray, with <img src="http://1450831086466697032345%20%5Crightarrow%200" alt="h \ rightarrow 0">  , significant weight will be only at the window corresponding to itself, and smoothing will not work. <br><br>  Thus, a naive mathematical model of a non-local averaging filter looks like this: <br><br><div style="text-align:center;"><img src="http://tex.s2cms.ru/svg/I_d(j)%20%3D%20%5Csum_%7Bj%20%5Cin%20I%7Dw(i%2C%20j)I(j)" alt="I_d (j) = \ sum_ {j \ in I} w (i, j) I (j)"></div><br><img src="http://tex.s2cms.ru/svg/i" alt="i">  -th pixel of the resulting image is equal to the sum of all pixels of the original image, taken with weights <img src="http://tex.s2cms.ru/svg/w" alt="w">  where weight is <br><br><div style="text-align:center;"><img src="http://tex.s2cms.ru/svg/w(i%2C%20j)%20%3D%20%5Cfrac%7B1%7D%7BZ(i)%7De%5E%7B-%5Cfrac%7B%5C%7CI(N_i)%20-%20I(N_j)%5C%7C%5E2_2%7D%7Bh%5E2%7D%7D" alt="w (i, j) = \ frac {1} {Z (i)} e ^ {- \ frac {\ | I (N_i) - I (N_j) \ | ^ 2_2} {h ^ 2}}"></div><br>  and the normalizing divider <br><br><div style="text-align:center;"><img src="http://tex.s2cms.ru/svg/Z(i)%20%3D%20%5Csum_%7Bj%20%5Cin%20I%7De%5E%7B-%5Cfrac%7B%5C%7CI(N_i)%20-%20I(N_j)%5C%7C%5E2_2%7D%7Bh%5E2%7D%7D" alt="Z (i) = \ sum_ {j \ in I} e ^ {- \ frac {\ | I (N_i) - I (N_j) \ | ^ 2_2} {h ^ 2}}"></div><br>  Alternative metrics suggested above: <br><br><div style="text-align:center;"><img src="http://tex.s2cms.ru/svg/%0A%20%20%5Crho(x%2C%20y%2C%20t)%3D%5Cbegin%7Bcases%7D%0A%20%20%20%200%2C%20%26%20%5Ctext%7Bif%20%24%7Cx-y%7C%3Ct%24%7D.%5C%5C%0A%20%20%20%20%7Cx-y%7C-t%20%2C%20%26%20%5Ctext%7Botherwise%7D.%0A%20%20%5Cend%7Bcases%7D%0A" alt="\ rho (x, y, t) = \ begin {cases} 0, &amp; amp; \ text {if $ | x-y | &amp; lt; t $}. \\ | x-y | -t, &amp; amp; \ text {otherwise}. \ end {cases}"></div><br>  In all cases <img src="http://tex.s2cms.ru/svg/%5C%7CI(N_i)%20-%20I(N_j)%5C%7C" alt="\ | I (N_i) - I (N_j) \ |">  denotes the element by element difference between the windows, as described above. <br><br>  If you look closely, the final formula is almost the same as that of the bilateral filter, only in the exponent instead of the geometric distance between the pixels and the color difference there is a difference between the image patches and the summation is carried out over all pixels of the image. <br><br><h4>  Efficiency considerations and implementation </h4><br>  Obviously, the complexity of the proposed algorithm <img src="http://tex.s2cms.ru/svg/O(n%5E2(2r%2B1))" alt="O (n ^ 2 (2r + 1))">  where <img src="http://tex.s2cms.ru/svg/r" alt="r">  - the radius of the window, which is used to calculate the similarity of parts of the image, and <img src="http://tex.s2cms.ru/svg/n" alt="n">  - the total number of pixels, because for each pixel we compare its size neighborhood <img src="http://tex.s2cms.ru/svg/2r%2B1" alt="2r + 1">  with a neighborhood of every other pixel.  This is not too good, because the naive implementation of the algorithm is slow enough even in 300x300 images.  The following improvements are usually suggested: <br><br><ul><li>  Obviously, it is not necessary to count all the weights all the time, because the pixel weight <img src="http://tex.s2cms.ru/svg/i" alt="i">  for pixel <img src="http://tex.s2cms.ru/svg/j" alt="j">  and vice versa - are equal.  If you save the calculated weight, the execution time is halved, but it takes <img src="http://tex.s2cms.ru/svg/O(n%5E2)" alt="O (n ^ 2)">  memory for storing weights. </li><li>  For most real-world images, the weights between most of the pixels will be zero.  So why not zero them at all?  You can use heuristics based on image segmentation, which will suggest where to count the weight pixel by pixel meaningless. </li><li>  When calculating weights, an exhibitor can be replaced by a function that is cheaper to calculate.  At least piecewise interpolation of the same exponent. </li></ul><br>  A common question that arises when considering this algorithm is: why do we use only the values ‚Äã‚Äãof the central pixel in the area?  Generally speaking, nothing prevents you from summing over the entire domain in the basic formula, as in bilateral anti-aliasing, and this even slightly affects the complexity, but the result of the modified algorithm is likely to be too vague.  Do not forget that in real images even identical objects are rarely absolutely identical, and such a modification of the algorithm will average them.  To use information from adjacent image elements, you can pre-perform the usual bilateral anti-aliasing.  Although if it is known that the original objects were or should end up being exactly the same (text smoothing), then such a change would be beneficial. <br><br>  Naive implementation of the algorithm (C + OpenCV 2.4.11): <br><br><pre><code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">include</span></span></span><span class="hljs-meta"> </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">"targetver.h"</span></span></span><span class="hljs-meta"> #</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">include</span></span></span><span class="hljs-meta"> </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;stdio.h&gt; #include &lt;math.h&gt; #include &lt;opencv2/opencv.hpp&gt; #include "opencv2/imgproc/imgproc.hpp" #include "opencv2/imgproc/imgproc_c.h" #include "opencv2/highgui/highgui.hpp" #include "opencv2/core/core.hpp" #include "opencv2/features2d/features2d.hpp" #include "opencv2/calib3d/calib3d.hpp" #include "opencv2/nonfree/nonfree.hpp" #include "opencv2/contrib/contrib.hpp" #include &lt;opencv2/legacy/legacy.hpp&gt; #include &lt;stdlib.h&gt; #include &lt;stdio.h&gt; using namespace cv; /* Returns measure of diversity between two pixels. The more pixels are different the bigger output number. Usually it's a good idea to use Euclidean distance but there are variations. */ double distance_squared(unsigned char x, unsigned char y) { unsigned char zmax = max(x, y); unsigned char zmin = min(x, y); return (zmax - zmin)*(zmax - zmin); } /* Returns weight of interaction between regions: the more dissimilar are regions the less resulting influence. Usually decaying exponent is used here. If distance is Euclidean, being combined, they form a typical Gaussian function. */ double decay_function(double x, double dispersion) { return exp(-x/dispersion); } int conform_8bit(double x) { if (x &lt; 0) return 0; else if (x &gt; 255) return 255; else return static_cast&lt;int&gt;(x); } double distance_over_neighbourhood(unsigned char* data, int x00, int y00, int x01, int y01, int radius, int step) { double dispersion = 15000.0; //should be manually adjusted double accumulator = 0; for(int x = -radius; x &lt; radius + 1; ++x) { for(int y = -radius; y &lt; radius + 1; ++y) { accumulator += distance_squared(static_cast&lt;unsigned char&gt;(data[(y00 + y)*step + x00 + x]), static_cast&lt;unsigned char&gt;(data[(y01 + y)*step + x01 + x])); } } return decay_function(accumulator, dispersion); } int main(int argc, char* argv[]) { int similarity_window_radius = 3; //may vary; 2 is enough for text filtering char* imageName = "text_noised_30.png"; IplImage* image = 0; image = cvLoadImage(imageName, CV_LOAD_IMAGE_GRAYSCALE); if (image == NULL) { printf("Can not load image\n"); getchar(); exit(-1); } CvSize currentSize = cvGetSize(image); int width = currentSize.width; int height = currentSize.height; int step = image-&gt;widthStep; unsigned char *data = reinterpret_cast&lt;unsigned char *&gt;(image-&gt;imageData); vector&lt;double&gt; processed_data(width*height, 0); //External cycle for(int x = similarity_window_radius + 1; x &lt; width - similarity_window_radius - 1; ++x) { printf("x: %d/%d\n", x, width - similarity_window_radius - 1); for(int y = similarity_window_radius + 1; y &lt; height - similarity_window_radius - 1; ++y) { //Inner cycle: computing weight map vector&lt;double&gt; weight_map(width*height, 0); double* weight_data = &amp;weight_map[0]; double norm = 0; for(int xx = similarity_window_radius + 1; xx &lt; width - similarity_window_radius - 1; ++xx) for(int yy = similarity_window_radius + 1; yy &lt; height - similarity_window_radius - 1; ++yy) { double weight = distance_over_neighbourhood(data, x, y, xx, yy, similarity_window_radius, step); norm += weight; weight_map[yy*step + xx] = weight; } //After all weights are known, one can compute new value in pixel for(int xx = similarity_window_radius + 1; xx &lt; width - similarity_window_radius - 1; ++xx) for(int yy = similarity_window_radius + 1; yy &lt; height - similarity_window_radius - 1; ++yy) processed_data[y*step + x] += data[yy*step + xx]*weight_map[yy*step + xx]/norm; } } //Transferring data from buffer to original image for(int x = similarity_window_radius + 1; x &lt; width - similarity_window_radius - 1; ++x) for(int y = similarity_window_radius + 1; y &lt; height - similarity_window_radius - 1; ++y) data[y*step + x] = conform_8bit(processed_data[y*step + x]); cvSaveImage("gray_denoised.png", image); cvReleaseImage(&amp;image); return 0; }</span></span></span></span></code> </pre> <br><h4>  Examples </h4><br>  Let's look at some results: <br><br><img src="https://habrastorage.org/files/48f/81b/bf6/48f81bbf6ba34976bc044c523a8bdbf3.png" alt="image"><img src="https://habrastorage.org/files/c81/b76/910/c81b769100da4ea39714e53d41c14eb6.png" alt="image"><br><br>  Note the near perfect smoothing and the sharp edges of the lines.  The more identical square areas in the image, the better the algorithm works.  Here the program had enough examples for each type of neighborhood, because all the square areas along the lines are about the same. <br><br>  Of course, everything is not so rosy for those cases where the "similarity" of areas cannot be detected by a simple square window.  For example: <br><br><img src="https://habrastorage.org/files/9a5/f62/2a5/9a5f622a50eb47c3b586157516e6d685.png" alt="image"><img src="https://habrastorage.org/files/52d/319/f18/52d319f1820f4876b3eef06f605ea1ce.png" alt="image"><br><br>  Although the background and the inside of the circle smoothed out well, artifacts remained along the circumference.  Of course, the algorithm cannot understand that the right side of the circle is the same as the left, only rotated 180 degrees, and use this when smoothing.  Such an obvious blunder can be corrected by viewing rotated windows, but then the execution time will increase by as many times as the window turns are considered. <br><br>  So that there is no doubt that the algorithm can smooth not only straight lines, here is another example that at the same time illustrates the importance of choosing a smoothing parameter: <br><br><img src="https://habrastorage.org/files/876/133/b85/876133b8535b4d5fad88a14f152ef5be.png" alt="image"><img src="https://habrastorage.org/files/d60/246/47b/d6024647bd4a4280a784fe416bc66229.png" alt="image"><br><img src="https://habrastorage.org/files/e6e/3bf/c96/e6e3bfc9664c45a987a2e2ca586fc067.png" alt="image"><img src="https://habrastorage.org/files/70a/0fc/2e3/70a0fc2e3d674843931f5ea6876ebfab.png" alt="image"><br><br>  In the second image, we see approximately the same artifacts as in the previous case.  It's not a lack of similar windows, but a parameter that is too small. <img src="http://1450831086466697032345" alt="h">  : even similar areas gain too low weights.  In the fourth picture, on the contrary, was chosen too large <img src="http://1450831086466697032345" alt="h">  , and all areas received roughly the same weight.  The third represents the middle ground. <br><br>  Another example of the work on the text.  Even a small and very noisy image is processed well enough for subsequent use by the machine (after equalization of the histogram and focusing, of course): <br><br><img src="https://habrastorage.org/files/96e/442/cce/96e442ccef1c413689fc980c2852d2ff.png" alt="image"><br><img src="https://habrastorage.org/files/23c/aa4/477/23caa4477c2f48afbd2b20715d82b13b.png" alt="image"><br><img src="https://habrastorage.org/files/46e/1bd/a9c/46e1bda9ce6a4c0f9c660d1e17f36866.png" alt="image"><br><br>  A few more examples from the <a href="http://demo.ipol.im/demo/bcm_non_local_means_denoising/">site</a> where you can apply an already optimized non-local smoothing algorithm: <br><br><img src="https://habrastorage.org/files/456/65b/03e/45665b03e11449618c111d8c5bd57aac.png"><img src="https://habrastorage.org/files/ce6/70b/c8e/ce670bc8ea394591905765eef4351e70.png"><br><img src="https://habrastorage.org/files/1dd/3d2/20b/1dd3d220bea74a73bc9901e59b5afe76.png"><img src="https://habrastorage.org/files/d17/ce9/f32/d17ce9f324334a2fb2e7c481d16aed8c.png"><br><img src="https://habrastorage.org/files/66a/448/c01/66a448c013dd4aeda2cb360888452218.png"><img src="https://habrastorage.org/files/e5c/1d9/3bf/e5c1d93bfe8a43b0abb3a460d8a1dd6c.png"><br><br>  Order: original, noisy, restored.  Notice how well Escher‚Äôs drawings were cleaned up with many similar elements.  Only black lines became more transparent and smoothed texture. <br><br><h5>  Scaling with descriptor points </h5><br>  Unfortunately, the high computational complexity of the algorithm limits its application in practice, however, it shows good results on the tasks of smoothing images with repeating elements.  The main problem of this algorithm lies in its main idea of ‚Äã‚Äãcalculating weights.  It is necessary for each pixel to go through the surroundings of all other pixels.  Even if we assume that double viewing of all pixels is an inevitable evil, then viewing of its neighbors seems superfluous, because even for a window radius of 3, it increases the time for calculating weights by 49 times.  Let's go back a little to the original idea.  We want to find similar places in the image to use to smooth each other out.  But we don‚Äôt have to compare all possible windows in the image pixel by pixel to find similar places.  We already have a good way to identify and compare interesting image elements!  Of course, I'm talking about a variety of feature descriptors.  Usually, this means SIFT, but in our case it is better to use something <i>less</i> accurate, because the goal at this stage is to find many quite similar areas, and not several exactly the same.  In the case of the use of descriptors, the step of calculating the scales is as follows: <br><br><ul><li>  Pre-count the descriptors at each point of the image. </li><li>  We pass through the image and for each pixel </li><li>  o Pass by every other pixel </li><li>  o Compare descriptors </li><li>  o If descriptors are similar, then compare windows pixel by pixel and count the weight </li><li>  o If different, reset weight </li><li>  In order not to pass through the image a second time, the calculated weights and coordinates of the pixels are entered into a separate list.  When the list has accumulated a sufficient number of items, you can stop the search. </li><li>  If you did not manage to find the specified number of similar points (the pixel is not noticeable), simply go through the image and count the weights as usual </li></ul><br>  The advantages of this approach: <br><br><ul><li>  Smoothing is improved at specific points that are usually most interesting to us. </li><li>  If the image has many similar special points, the speed increase is noticeable. </li></ul><br>  Disadvantages: <br><br><ul><li>  Not the fact that there will be many similar points to recoup the counting of descriptors. </li><li>  The result and acceleration of the algorithm strongly depend on the choice of the descriptor. </li></ul><br><h5>  Conclusion </h5><br>  Findings: <br><br><ul><li>  The algorithm works well on periodic textures. </li><li>  The algorithm smooths homogeneous areas well. </li><li>  The larger the image, the more similar areas and the better the algorithm works.  But <i>godlessly</i> long. </li><li>  Areas for which it was not possible to find such ones are poorly smoothed out (solved by preliminary use of a bilateral filter or by examining turns of windows) </li><li>  As with many other algorithms, it is necessary to adjust the value of the smoothing parameter. </li></ul><br>  Thus, we have considered a smoothing algorithm that uses information about similar objects in the image to best approximate a clean image.  From such a ‚Äúpseudo-recognition‚Äù, the transition to a real smoothing is not far after the selection of similar objects.  Indeed, modern approaches to image restoration use neural networks for this purpose and, as a rule, they actually do better and faster.  However, neural networks require more skill in programming and fine tuning.  Even such an algorithm, which only simulates recognition, can give a comparable and sometimes better result. <br><br><h4>  Sources </h4><br>  <i>Antoni Buades, Bartomeu Coll</i> A Non-local Algorithm For Image Denoising <br>  <i>Yifei Lou, Paolo Favaro, Stefano Soatto, and Andrea Bertozzi</i> Nonlocal Similarity Image Filtering </div><p>Source: <a href="https://habr.com/ru/post/273159/">https://habr.com/ru/post/273159/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../273147/index.html">Myths about / dev / urandom</a></li>
<li><a href="../273149/index.html">String Security Emulation in PostgreSQL 9.4</a></li>
<li><a href="../273151/index.html">Transfer tabs to another window in the new assembly Vivaldi 1.0.344.34</a></li>
<li><a href="../273155/index.html">Interesting bagofich 1C when working with a managed form context</a></li>
<li><a href="../273157/index.html">Creative Commons licenses have published over 1 billion papers.</a></li>
<li><a href="../273161/index.html">Xamarin and Xamarin.Forms - cactus in chocolate. Part 2</a></li>
<li><a href="../273163/index.html">Conference for developers Top & Featured in Moscow on December 17</a></li>
<li><a href="../273165/index.html">Winter internship for developers at Redmadrobot</a></li>
<li><a href="../273167/index.html">How do postgreSQL security_barrier views work</a></li>
<li><a href="../273169/index.html">Pebble: Timeline - Inside View</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>