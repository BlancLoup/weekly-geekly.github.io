<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Working groups in OpenCL 2.0. Heterogeneous working groups</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Among the new features of OpenCL 2.0, several new useful built-in functions have appeared, the so-called workgroup functions. These built-in functions...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Working groups in OpenCL 2.0. Heterogeneous working groups</h1><div class="post__text post__text-html js-mediator-article">  Among the new features of OpenCL 2.0, several new useful built-in functions have appeared, the so-called workgroup functions.  These built-in functions provide widely used parallel primitives that operate at the workgroup level.  This article briefly describes the workgroup functions, provides performance data for an OpenCL Intel HD Graphics device, and also discusses an example of using heterogeneous workgroups. <br><a name="habracut"></a><br><h4>  Description of the functions of the working groups </h4><br>  The functions of the working groups include three classical algorithms of the working group level ( <i>value broadcast, reduce and scan</i> ), as well as two built-in functions that check the logical result of the operation performed for the entire working group.  The <i>reduce</i> and <i>scan</i> algorithms support operations <i>add, min</i> and <i>max</i> . <br>  The functionality of the built-in workgroup functions is evident from the titles. <br><ul><li>  <i>work_group_broadcast ()</i> distributes the value of the selected work item to all members of the workgroup. </li><li>  <i>work_group_reduce ()</i> calculates the values ‚Äã‚Äãof sum, min or max for all elements of the working group, and then distributes the resulting value to all elements of the working group. </li><li>  <i>work_group_scan ()</i> calculates the values ‚Äã‚Äãof sum, min or max for all previous work items (with the possible inclusion of current ones). </li><li>  <i>work_group_all ()</i> returns a logical AND for the same logical expression calculated for each work item. </li><li>  <i>work_group_any ()</i> works in the same way as <i>work_group_all ()</i> , but uses a logical OR. </li></ul><br>  An important restriction regarding the listed built-in functions: they are valid only for scalar data types (for example, the popular types int4 and float4 are not supported).  In addition, 8-bit data types, such as char or uchar, are not supported. <br>  The functions of the working groups, as their name implies, always work in parallel for the whole working group.  There is an implicit consequence from this: any call to the function of the working group acts as a barrier. <br>  The use of workgroup functions involves two main ideas.  First, the functions of the working groups are convenient.  It is much easier to use one built-in function instead of writing a sufficiently large piece of code that would be required to implement the same functionality in OpenCL 1.2.  Secondly, the functions of the working groups are more efficient from the point of view of productivity, since they use equipment optimization. <br><br>  For example, consider the following task (which may be part of an algorithm): calculating the sums of prefixes for subordinate arrays of equal size of some larger array.  So, we need to calculate the sum of the prefix for each element of each slave array and store it in the target memory area with the same markup.  The source and target data layouts are shown in the following diagram. <br><br><img src="https://habrastorage.org/files/c6f/e18/02f/c6fe1802f8754ee682782c248c7ef699.png">
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      A simple OpenCL kernel for this task may look like this: <br><ul><li>  each array (line in the illustration) will be processed by one working group; </li><li>  for each work item, the scan is performed using a simple for () loop for the preceding items, then the cumulative prefix value is added, and then the result is stored at the destination; </li><li>  if the size of the workgroup is smaller than the input array, then the source and destination indices are shifted by the size of the workgroup, the cumulative prefix is ‚Äã‚Äãupdated and this process is repeated until the end of the source line. </li></ul><br>  The corresponding code is shown below. <br><div class="spoiler">  <b class="spoiler_title">Code</b> <div class="spoiler_text"><pre><code class="cpp hljs">__<span class="hljs-function"><span class="hljs-function">kernel </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">Calc_wg_offsets_naive</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">( __global </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">const</span></span></span></span><span class="hljs-function"><span class="hljs-params"> uint* gHistArray, __global uint* gPrefixsumArray, uint bin_size )</span></span></span><span class="hljs-function"> </span></span>{ uint lid = get_local_id(<span class="hljs-number"><span class="hljs-number">0</span></span>); uint binId = get_group_id(<span class="hljs-number"><span class="hljs-number">0</span></span>); <span class="hljs-comment"><span class="hljs-comment">//calculate source/destination offset for workgroup uint group_offset = binId * bin_size; local uint maxval; //initialize cumulative prefix if( lid == 0 ) maxval = 0; barrier(CLK_LOCAL_MEM_FENCE); do { //perform a scan for every workitem uint prefix_sum=0; for(int i=0; i&lt;lid; i++) prefix_sum += gHistArray[group_offset + i]; //store result gPrefixsumArray[group_offset + lid] = prefix_sum + maxval; prefix_sum += gHistArray[group_offset + lid]; //update group offset and cumulative prefix if( lid == get_local_size(0)-1 ) maxval += prefix_sum; barrier(CLK_LOCAL_MEM_FENCE); group_offset += get_local_size(0); } while(group_offset &lt; (binId+1) * bin_size); }</span></span></code> </pre> <br></div></div><br>  Such a primitive approach is extremely inefficient in most cases (except for very small working groups).  Obviously, the inner for () loop performs too many redundant load and add operations;  This procedure can clearly be optimized.  Moreover, with an increase in the size of the working group, redundancy also increases.  More efficient use of Intel HD Graphics hardware resources requires a more efficient algorithm, such as Blelloch.  We will not examine it in detail: it is wonderfully described in the classic <a href="http.developer.nvidia.com/GPUGems3/gpugems3_ch39.html">GPU Gems</a> article. <br>  OpenCL 1.2 code with parallel scanning will look like this. <br><div class="spoiler">  <b class="spoiler_title">Code</b> <div class="spoiler_text"><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">define</span></span></span><span class="hljs-meta"> WARP_SHIFT 4 #</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">define</span></span></span><span class="hljs-meta"> GRP_SHIFT 8 #</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">define</span></span></span><span class="hljs-meta"> BANK_OFFSET(n) ((n) &gt;&gt; WARP_SHIFT + (n) &gt;&gt; GRP_SHIFT) __kernel void Calc_wg_offsets_Blelloch(__global const uint* gHistArray, __global uint* gPrefixsumArray, uint bin_size ,__local uint* temp ) { int lid = get_local_id(0); uint binId = get_group_id(0); int n = get_local_size(0) * 2; uint group_offset = binId * bin_size; uint maxval = 0; do { </span><span class="hljs-comment"><span class="hljs-meta"><span class="hljs-comment">// calculate array indices and offsets to avoid SLM bank conflicts int ai = lid; int bi = lid + (n&gt;&gt;1); int bankOffsetA = BANK_OFFSET(ai); int bankOffsetB = BANK_OFFSET(bi); // load input into local memory temp[ai + bankOffsetA] = gHistArray[group_offset + ai]; temp[bi + bankOffsetB] = gHistArray[group_offset + bi]; // parallel prefix sum up sweep phase int offset = 1; for (int d = n&gt;&gt;1; d &gt; 0; d &gt;&gt;= 1) { barrier(CLK_LOCAL_MEM_FENCE); if (lid &lt; d) { int ai = offset * (2*lid + 1)-1; int bi = offset * (2*lid + 2)-1; ai += BANK_OFFSET(ai); bi += BANK_OFFSET(bi); temp[bi] += temp[ai]; } offset &lt;&lt;= 1; } // clear the last element if (lid == 0) { temp[n - 1 + BANK_OFFSET(n - 1)] = 0; } // down sweep phase for (int d = 1; d &lt; n; d &lt;&lt;= 1) { offset &gt;&gt;= 1; barrier(CLK_LOCAL_MEM_FENCE); if (lid &lt; d) { int ai = offset * (2*lid + 1)-1; int bi = offset * (2*lid + 2)-1; ai += BANK_OFFSET(ai); bi += BANK_OFFSET(bi); uint t = temp[ai]; temp[ai] = temp[bi]; temp[bi] += t; } } barrier(CLK_LOCAL_MEM_FENCE); //output scan result to global memory gPrefixsumArray[group_offset + ai] = temp[ai + bankOffsetA] + maxval; gPrefixsumArray[group_offset + bi] = temp[bi + bankOffsetB] + maxval; //update cumulative prefix sum and shift offset for next iteration maxval += temp[n - 1 + BANK_OFFSET(n - 1)] + gHistArray[group_offset + n - 1]; group_offset += n; } while(group_offset &lt; (binId+1) * bin_size); }</span></span></span></span></code> </pre><br></div></div><br>  As a rule, such code works more efficiently and forms not so high load on hardware resources, but with some reservations. <br>  In this code, there are costs for moving data between local and global memory, as well as some restrictions.  To achieve really high efficiency, the algorithm requires a sufficiently large working group size.  With small workgroups (&lt;16), performance is unlikely to be higher than that of a simple cycle. <br>  In addition, pay attention to the complexity of the code and additional logic designed to avoid conflicts in the common local memory (for example, the macro <i>BANK_OFFSET</i> ). <br>  Using working groups allows you to bypass all the problems mentioned.  The corresponding version of the optimized OpenCL code is shown below. <br><div class="spoiler">  <b class="spoiler_title">Code</b> <div class="spoiler_text"><pre> <code class="cpp hljs">__<span class="hljs-function"><span class="hljs-function">kernel </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">Calc_wg_offsets_wgf</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">( __global </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">const</span></span></span></span><span class="hljs-function"><span class="hljs-params"> uint* gHistArray, __global uint* gPrefixsumArray, uint bin_size )</span></span></span><span class="hljs-function"> </span></span>{ uint lid = get_local_id(<span class="hljs-number"><span class="hljs-number">0</span></span>); uint binId = get_group_id(<span class="hljs-number"><span class="hljs-number">0</span></span>); uint group_offset = binId * bin_size; uint maxval = <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">do</span></span> { uint binValue = gHistArray[group_offset + lid]; uint prefix_sum = work_group_scan_exclusive_add( binValue ); gPrefixsumArray[group_offset + lid] = prefix_sum + maxval; maxval += work_group_broadcast( prefix_sum + binValue, get_local_size(<span class="hljs-number"><span class="hljs-number">0</span></span>)<span class="hljs-number"><span class="hljs-number">-1</span></span> ); group_offset += get_local_size(<span class="hljs-number"><span class="hljs-number">0</span></span>); } <span class="hljs-keyword"><span class="hljs-keyword">while</span></span>(group_offset &lt; (binId+<span class="hljs-number"><span class="hljs-number">1</span></span>) * bin_size); }</code> </pre><br></div></div><br>  The performance results of both optimized algorithms are measured for a sufficiently large amount of input data (each working group scans 65,536 elements, which, depending on the local size, corresponds to 8192 ... 2048 iterations of the outer loop). <br><br><img src="https://habrastorage.org/files/80a/e1a/fe1/80ae1afe1279478a82de604c08dd3a0e.png"><br><br>  As expected, the simple cycle runs much slower as the local size increases, and the performance of both optimized variants increases. <br>  If you set the optimal size of the working group for a given algorithm, then the kernel comparison will be like this. <br><br><img src="https://habrastorage.org/files/0ed/18e/fad/0ed18efadf854b42a323b57459a08a6a.png"><br><br>  Note that the use of <i>work_group_scan_exclusive_add ()</i> significantly improves the productivity of a workgroup of any size and at the same time simplifies the code. <br><br><h4>  Heterogeneous OpenCL 2.0 working groups </h4><br>  The OpenCL execution model includes the concept of working groups, which are groups of individual work items in the NDRange.  If an application uses OpenCL 1.x, then the size of the NDRange should be completely (without remainder) divided by the size of the working groups.  If the <i>clEnqueueNDRangeKernel</i> call includes <i>global_size</i> and <i>local_size parameters</i> that are not completely divisible, the call will return the error code <i>CL_INVALID_WORK_GROUP_SIZE</i> .  If the <i>clEnqueueNDRangeKernel</i> call specifies a NULL value for the <i>local_size</i> parameter, allowing the executable module to choose the size of the workgroup, then the executable module will need to choose a size that can be used to completely divide the global NDRange sizes. <br><br>  The need to choose such a size of working groups so that the size of the NDRange is completely divided into it may cause difficulties for developers.  Consider a simple 3x3 image blur algorithm.  In this algorithm, each output pixel is calculated as the average value for the input pixel values ‚Äã‚Äãin the neighboring area of ‚Äã‚Äã3x3.  The problem arises when processing the output pixels located on the image frame, since these pixels depend on the pixels outside the bounds of the input image. <br><br><img src="https://habrastorage.org/files/88d/2cd/645/88d2cd645b234f0485a167040fee267e.png"><br><br>  In some applications, the input values ‚Äã‚Äãof the frames do not matter, you can skip them.  In this case, the size of the NDRange is the same as the size of the output image minus the frame area.  This often turns out the size of NDRange, which is difficult to completely divide.  For example, to apply a 3x3 filter to a 1920x1080 image, a frame is required that is one pixel thick on each side.  The easiest way to do this is with the 1918x1078 kernel.  But neither 1918 nor 1078 are divided completely into the values ‚Äã‚Äãgiving working groups of optimal size. <br><br>  OpenCL 2.0 introduces a new feature that resolves the issues described in the previous section.  We are talking about the so-called heterogeneous working groups: the OpenCL 2.0 executable module can divide the NDRange into non-uniform working groups in any dimension.  If the developer specifies the size of the workgroup to which the size of the NDRange is not completely divided, the module being executed will divide the NDRange in such a way as to create as many workgroups as possible with the specified size, and the rest of the workgroups will have a different size. <br><br>  Because of this, OpenCL can use workgroups of any size for any size of NDRange when the developer passes the NULL value of the <i>local_size</i> parameter to <i>clEnqueueNDRangeKernel</i> .  In general, using the NULL value in the <i>local_size</i> parameter remains the preferred method for executing kernels, unless the logic of your application requires any particular size of workgroup. <br>  Inside the kernel code, the built-in <i>get_local_size ()</i> function returns the actual size of the workgroup from which it was called.  If the kernel needs the exact size specified for the <i>local_size</i> parameter in <i>clEnqueueNDRangeKernel</i> , the built-in <i>get_get_enqueued_local_size ()</i> function returns these values. <br><br>  To enable the use of heterogeneous workgroups, you must compile the kernel with the <i>-cl-std = CL2.0 flag</i> , including this and other OpenCL 2.0 features.  Without using this flag, the compiler will use OpenCL version 1.2, even if the device supports OpenCL 2.0.  In addition, heterogeneous workgroups can be disabled for kernels compiled for the <i>-cl-std = CL2.0</i> flag using the <i>-cl-uniform-work-group-size</i> flag.  This can be useful for obsolete kernel code before fully switching to OpenCL 2.0. <br><br>  The heterogeneous workgroup function in OpenCL 2.0 improves the ease of use of OpenCL and can improve the performance of some cores.  Developers no longer add system and kernel code to work with NDRange sizes that are not completely divided.  The code created to use this feature can effectively use SIMD and memory access alignment: these benefits are provided by the right choice of workgroup size. <br><br>  In the code of the curriculum, the 3x3 blur algorithm described above is implemented.  The most interesting part of the code is in the main.cpp file. <br><div class="spoiler">  <b class="spoiler_title">Code</b> <div class="spoiler_text"><pre> <code class="cpp hljs"><span class="hljs-comment"><span class="hljs-comment">//1.    . //2.   OpenCL C    OpenCL 1.2. // Get the box blur kernel compiled using OpenCL 1.2 (which is the // default compilation, even on an OpenCL 2.0 device). This allows // the code to show the pre-OpenCL 2.0 behavior. cl::Kernel kernel_1_2 = GetKernel(device, context); //3.   OpenCL C    OpenCL 2.0 (        OpenCL 2.0). // Get the box blur kernel compiled using OpenCL 2.0. OpenCL 2.0 // is required in order to use the non-uniform work-groups feature. kernel_2_0 = GetKernel(device, context, "-cl-std=CL2.0"); //4.   ,       . // Set the size of the global NDRange, to be used in all NDRange cases. // Since this is a box blur, we use a global size that is two elements // smaller in each dimension. This creates a range which often doesn't // divide nicely by local work sizes we might commonly pick for running // kernels. cl::NDRange global_size = cl::NDRange(input.get_width() - 2, input.get_height() - 2); //5.      ,   OpenCL 1.2,    local_size   NULL. // Blur the image with a NULL local range using the OpenCL 1.2 compiled // kernel. cout &lt;&lt; "Compiled with OpenCL 1.2 and using a NULL local size:" &lt;&lt; end1 &lt;&lt; end1; output = RunBlurKernel(context, queue, kernel_1_2, global_size, cl::NullRange, input, true); //6.      ,   OpenCL 1.2,    local_size 16x16. // Blur the image with an even local range using the OpenCL 1.2 // compiled kernel. This won't work, even if we are running on an // OpenCL 2.0 implementation. The kernel has to be explicitly compiled // with OpenCL 2.0 compilation enabled in the compiler switches. try { cout &lt;&lt; "Compiled with OpenCL 1.2 and using an even local size:" &lt;&lt; end1 &lt;&lt; end1; output = RunBlurKernel(context, queue, kernel_1_2, global_size, cl::NDRange(16, 16), input, true); cout &lt;&lt; end1; output.Write(output_files[1]); } catch (...) { cout &lt;&lt; "Trying to launch a non-uniform workgroup with a kernel " "compiled using" &lt;&lt; end1 &lt;&lt; "OpenCL 1.2 failed (as expected.)" &lt;&lt; end1 &lt;&lt; end1; } //7.      ,   OpenCL 2.0,    local_size NULL. // Blur the image with a NULL local range using the OpenCL 2.0 // compiled kernel. cout &lt;&lt; "Compiled with OpenCL 2.0 and using a NULL local size:" &lt;&lt; end1 &lt;&lt; end1; output = RunBlurKernel(context, queue, kernel_2_0, global_size, cl::NullRange, input, true); //8.      ,   OpenCL 2.0,    local_size 16x16. // Blur the image with an even local range using the OpenCL 2.0 // compiled kernel. This will only work on an OpenCL 2.0 device // and compiler. cout &lt;&lt; "Compiled with OpenCL 2.0 and using an even local size:" &lt;&lt; end1 &lt;&lt; end1; output = RunBlurKernel(context, queue, kernel_2_0, global_size, cl::NDRange(16, 16), input, true); //9.   ,   . 2‚Äî5.</span></span></code> </pre><br></div></div><br>  For each option in paragraphs.  5-8, the results of a call to <i>get_local_size ()</i> and <i>get_get_enqueued_local_size ()</i> in each of the four corners of the NDRange are displayed on the screen.  Thus, we see how the NDRange is divided into working groups.  The kernel that implements the blur algorithm is stored in BoxBlur.cl.  It contains a very simple implementation, but is not the most effective way to apply blur. <br><br>  To build and run this training program, you need a PC that meets the following requirements: <br><ul><li>  Intel¬Æ Core ‚Ñ¢ processor series, codenamed Broadwell. </li><li>  Microsoft Windows * 8 or 8.1. </li><li>  Intel¬Æ SDK for OpenCL ‚Ñ¢ applications version 2014 R2 or later. </li><li>  Microsoft Visual Studio * 2012 or later. </li></ul><br>  The training program is a console application that reads an input bitmap image and writes output raster images for each of the varieties of NDRange described in the section above.  This training program supports several command line parameters: -h, -?  (display of help text and output), -i &lt;input prefix&gt; (prefix of input bitmap image), -o &lt;output prefix&gt; (prefix of output bitmap image). <br><br>  After starting the training program for the provided picture, the result will be as follows. <br><div class="spoiler">  <b class="spoiler_title">Hidden text</b> <div class="spoiler_text"><pre> <code class="hljs vbscript">Input file: input.bmp Output files: output_0.bmp, output_1.bmp, output_2.bmp, output_3.bmp Device: Intel(R) HD Graphics <span class="hljs-number"><span class="hljs-number">5500</span></span> Vendor: Intel(R) Corporation Compiled <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> OpenCL <span class="hljs-number"><span class="hljs-number">1.2</span></span> <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> using a <span class="hljs-literal"><span class="hljs-literal">NULL</span></span> local size: Work Item get_global_id() get_local_size() get_enqueued_local_size() ------------------------------------------------------------------------- Top <span class="hljs-built_in"><span class="hljs-built_in">left</span></span> (<span class="hljs-number"><span class="hljs-number">0</span></span>,<span class="hljs-number"><span class="hljs-number">0</span></span>) (<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">239</span></span>) undefined Top <span class="hljs-built_in"><span class="hljs-built_in">right</span></span> (<span class="hljs-number"><span class="hljs-number">637</span></span>,<span class="hljs-number"><span class="hljs-number">0</span></span>) (<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">239</span></span>) undefined Bottom <span class="hljs-built_in"><span class="hljs-built_in">left</span></span> (<span class="hljs-number"><span class="hljs-number">0</span></span>,<span class="hljs-number"><span class="hljs-number">477</span></span>) (<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">239</span></span>) undefined Bottom <span class="hljs-built_in"><span class="hljs-built_in">right</span></span> (<span class="hljs-number"><span class="hljs-number">637</span></span>,<span class="hljs-number"><span class="hljs-number">477</span></span>) (<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">239</span></span>) undefined Compiled <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> OpenCL <span class="hljs-number"><span class="hljs-number">1.2</span></span> <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> using an even local size: Trying <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> launch a non-uniform workgroup <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> a kernel compiled using OpenCL <span class="hljs-number"><span class="hljs-number">1.2</span></span> failed (as expected.) Compiled <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> OpenCL <span class="hljs-number"><span class="hljs-number">2.0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> using a <span class="hljs-literal"><span class="hljs-literal">NULL</span></span> local size: Work Item get_global_id() get_local_size() get_enqueued_local_size() Top <span class="hljs-built_in"><span class="hljs-built_in">left</span></span> (<span class="hljs-number"><span class="hljs-number">0</span></span>,<span class="hljs-number"><span class="hljs-number">0</span></span>) (<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">239</span></span>) (<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">239</span></span>) Top <span class="hljs-built_in"><span class="hljs-built_in">right</span></span> (<span class="hljs-number"><span class="hljs-number">637</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>) (<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">239</span></span>) (<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">239</span></span>) Bottom <span class="hljs-built_in"><span class="hljs-built_in">left</span></span> (<span class="hljs-number"><span class="hljs-number">0</span></span>,<span class="hljs-number"><span class="hljs-number">477</span></span>) (<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">239</span></span>) (<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">239</span></span>) Bottom <span class="hljs-built_in"><span class="hljs-built_in">right</span></span> (<span class="hljs-number"><span class="hljs-number">637</span></span>,<span class="hljs-number"><span class="hljs-number">477</span></span>) (<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">239</span></span>) (<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">239</span></span>) Compiled <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> OpenCL <span class="hljs-number"><span class="hljs-number">2.0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> using an even local size: Work Item get_global_id() get_local_size() get_enqueued_local_size() Top <span class="hljs-built_in"><span class="hljs-built_in">left</span></span> (<span class="hljs-number"><span class="hljs-number">0</span></span>,<span class="hljs-number"><span class="hljs-number">0</span></span>) (<span class="hljs-number"><span class="hljs-number">16</span></span>,<span class="hljs-number"><span class="hljs-number">16</span></span>) (<span class="hljs-number"><span class="hljs-number">16</span></span>,<span class="hljs-number"><span class="hljs-number">16</span></span>) Top <span class="hljs-built_in"><span class="hljs-built_in">right</span></span> (<span class="hljs-number"><span class="hljs-number">637</span></span>,<span class="hljs-number"><span class="hljs-number">0</span></span>) (<span class="hljs-number"><span class="hljs-number">14</span></span>,<span class="hljs-number"><span class="hljs-number">16</span></span>) (<span class="hljs-number"><span class="hljs-number">16</span></span>,<span class="hljs-number"><span class="hljs-number">16</span></span>) Bottom <span class="hljs-built_in"><span class="hljs-built_in">left</span></span> (<span class="hljs-number"><span class="hljs-number">0</span></span>,<span class="hljs-number"><span class="hljs-number">477</span></span>) (<span class="hljs-number"><span class="hljs-number">16</span></span>,<span class="hljs-number"><span class="hljs-number">14</span></span>) (<span class="hljs-number"><span class="hljs-number">16</span></span>,<span class="hljs-number"><span class="hljs-number">16</span></span>) Bottom <span class="hljs-built_in"><span class="hljs-built_in">right</span></span> (<span class="hljs-number"><span class="hljs-number">637</span></span>,<span class="hljs-number"><span class="hljs-number">477</span></span>) (<span class="hljs-number"><span class="hljs-number">14</span></span>,<span class="hljs-number"><span class="hljs-number">14</span></span>) (<span class="hljs-number"><span class="hljs-number">16</span></span>,<span class="hljs-number"><span class="hljs-number">16</span></span>) Done!</code> </pre><br></div></div><br><br>  The input image has a size of 640x480, so the size of the NDRange in each case will be 638x478.  The result above shows that running the OpenCL 1.2 kernel with the <i>local_size</i> parameter <i>NULL</i> forces you to use odd sizes for each workgroup (1, 239).  Working group sizes that are not powers of two can work very slowly in some cores.  SIMD conveyors may be idle, synchronous memory access may be impaired. <br><br>  Running the OpenCL 1.2 kernel with the specified workgroup size (16x16) gives an error, since neither 648 nor 478 are completely divided by 16. <br>  Running the OpenCL 2.0 kernel with the <i>local_size</i> parameter NULL <i>value</i> allows the OpenCL module to split the NDRange into workgroups of any size.  The above is the result: it can be seen that the executable module continues to use the uniform size of the working groups in the same way as for the OpenCL 1.2 core. <br><br>  Running an OpenCL 2.0 kernel with a given workgroup size (16x16) will result in the NDRange size being divided into heterogeneous workgroups.  We see that the left upper working group has a size of 16x16, the upper right is 14x16, the lower left is 16x14, and the lower right is 14x14.  Since in most cases the size of the working group is 16x16, this core will use SIMD pipelines very efficiently and memory access will be very fast. <br><br>  <b>Full versions of articles on the IDZ website:</b> <br><ul><li>  <a href="https://software.intel.com/ru-ru/articles/using-opencl-20-work-group-functions">Using Working Group Functions in OpenCL 2.0</a> </li><li>  <a href="https://software.intel.com/ru-ru/articles/opencl-20-non-uniform-work-groups">Heterogeneous OpenCL 2.0 working groups</a> </li></ul><br>  <b>Original articles in English:</b> <br><ul><li>  <a href="https://software.intel.com/en-us/articles/using-opencl-20-work-group-functions">Using OpenCL 2.0 Work-group Functions</a> </li><li>  <a href="https://software.intel.com/en-us/articles/opencl-20-non-uniform-work-groups">OpenCL 2.0 Non-Uniform Work Groups</a> </li></ul></div><p>Source: <a href="https://habr.com/ru/post/246091/">https://habr.com/ru/post/246091/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../246075/index.html">Updates on vds.menu</a></li>
<li><a href="../246077/index.html">Ruby and Postgis Time Zone Service</a></li>
<li><a href="../246081/index.html">About slow programming</a></li>
<li><a href="../246087/index.html">.NEXT in Moscow: how hardcore .NET-conference conquered the capital</a></li>
<li><a href="../246089/index.html">Creating Bluetooth profiles in the BLE TI stack</a></li>
<li><a href="../246093/index.html">Hacker's guide to neural networks. Schemes of real values. Patterns in the "reverse" stream. Example "One neuron"</a></li>
<li><a href="../246095/index.html">Monitoring Methods in DWDM Systems (Part 1)</a></li>
<li><a href="../246097/index.html">The problem of the "7th of January"</a></li>
<li><a href="../246099/index.html">OpenStack, Docker and Web Terminal, or how we do interactive exercises for learning Linux.</a></li>
<li><a href="../246105/index.html">Data structures: 2-3 heap (2-3 heap)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>