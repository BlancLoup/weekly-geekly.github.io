<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Transactional Memory: History and Development</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Definition 
 Parallel programming is difficult. When using systems with shared memory, one cannot do without synchronization of access of parallel pro...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Transactional Memory: History and Development</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/getpro/habr/post_images/8ca/138/48a/8ca13848a6daf524e5d5e2450088e43c.gif"><h4>  Definition </h4><br>  Parallel programming is difficult.  When using systems with shared memory, one cannot do without synchronization of access of parallel processes / threads to a shared resource (memory).  To do this, use: <br><ul><li>  locks (mutex); </li><li>  non-blocking algorithms (lockless, lock-free); </li><li>  transactional memory. </li></ul><br><br>  Transactional memory is a technology for synchronizing concurrent streams.  It simplifies parallel programming by separating groups of instructions into atomic transactions.  Competitive threads work in parallel <sup>1</sup> , until they begin to modify the same memory.  For example, the operations of adding nodes to a red-black tree (animation in the header) are able to work in parallel in several streams. <br><div class="spoiler">  <b class="spoiler_title">Hidden text</b> <div class="spoiler_text"><pre><code class="hljs pgsql"><span class="hljs-comment"><span class="hljs-comment">/* Move item from one list to another */</span></span> <span class="hljs-type"><span class="hljs-type">int</span></span> <span class="hljs-keyword"><span class="hljs-keyword">move</span></span>(list *<span class="hljs-keyword"><span class="hljs-keyword">from</span></span>, list *<span class="hljs-keyword"><span class="hljs-keyword">to</span></span>) { __transaction_atomic { node *n = pop(<span class="hljs-keyword"><span class="hljs-keyword">from</span></span>); push(<span class="hljs-keyword"><span class="hljs-keyword">to</span></span>, n); } }</code> </pre> </div></div><br><a name="habracut"></a><br>  The approach to managing competitiveness using transactional memory is called optimistic: we believe that threads work independently of each other and in rare cases change the same data.  In this case, most transactions end successfully.  In contrast, locking approaches are pessimistic: we assume that threads will always conflict and always prohibit them from being in the critical section at the same time. <br><br>  If a data conflict occurs, the transaction is canceled.  Cancellation of a transaction results in the cancellation of the actions that the thread performed during the transaction.  After this, the transaction is usually restarted, or the function previously specified as an ‚Äúemergency exit‚Äù is called, most often a rollback to the use of locks. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Advantages of transactional memory: <br><ul><li>  relative ease of use (concluding whole methods in a transaction block); </li><li>  complete absence of locks and interlocks; </li><li>  increased concurrency and, consequently, performance. </li></ul><br>  Transactional memory is not a silver bullet.  There are also disadvantages: <br><ul><li>  improper use may result in poor performance and incorrect operation; </li><li>  limited use - in a transaction it is impossible to perform operations that cannot be undone; </li><li>  debugging complexity - it is impossible to put a breakpoint inside a transaction. </li></ul><br><br><h4>  The birth of technology </h4><br>  Transactions in databases have existed for several decades.  For the first time, the idea of ‚Äã‚Äãtransferring transactions from the world of databases to the world of parallel programming originated in the 1980s.  Developed and popularized technology <a href="http://cs.brown.edu/people/mph/">Maurice Herlihy</a> , <a href="http://pages.cs.wisc.edu/~rajwar/">Ravi Rajwar</a> , <a href="http://people.csail.mit.edu/shanir/">Nir Shavit</a> .  The first studies offered hardware implementations of transactional memory, which were not destined to be born for another 30 years. <br>  In the 1990s, the first software implementations of the technology appeared, hardware implementations were pulled up to the 2000s. <br><br><h4>  Software implementations (Software Transactional Memory, STM) </h4>  Among the many implementations of software transactional memory, I would like to highlight four.  Examples are available on github: <a href="https://github.com/JIghtuse/tm-experiments">JIghtuse / tm-experiments</a> . <br><br><h5>  Clojure </h5>  Clojure is the only language whose core supports transactional memory.  The main constructions of STM are: <code>ref</code> (reference to data, through which data is changed only in a transaction) and <code>dosync</code> (transaction block). <br><br>  Clojure's STM approach is called MultiVersion Concurrency Control ( <a href="http://en.wikipedia.org/wiki/Multiversion_concurrency_control">MVCC</a> ) concurrency control: it stores multiple logical versions of the data used in a transaction.  During a transaction, the stream observes a snapshot of the data at the time it starts. <br><div class="spoiler">  <b class="spoiler_title">Hidden text</b> <div class="spoiler_text"><img src="https://habrastorage.org/getpro/habr/post_images/4d5/ff6/f3e/4d5ff6f3eabbbcccb8dea52944270519.png"><br>  Link version diagram in a Clojure transaction. <br><br>  Transactions 1 and 2 begin at the same time, receiving one copy of the version of <code>ref v0</code> .  Inside the transaction, the data is processed, which changes the value of <code>ref</code> .  The first transaction ends earlier and wins the race for updating the <code>ref</code> new value.  Then the second transaction ends, and its attempt to update <code>ref</code> fails (red arrow in the diagram), since the version of <code>ref</code> was not the one that was expected.  In this case, the transaction is restarted, receiving a copy of the new version of <code>ref</code> .  Since no other transaction attempts to change the <code>ref</code> , transaction 2 completes successfully the second time. <br>  The calculations in transaction 3 do not change the value of <code>ref</code> , so the restart is not called and it completes successfully. <br></div></div><br>  Consider an example of transferring funds between bank accounts: <br><div class="spoiler">  <b class="spoiler_title">Hidden text</b> <div class="spoiler_text">  The program runs in the same thread, but is thread-safe. <br><pre> <code class="hljs pgsql">(def account1 (<span class="hljs-keyword"><span class="hljs-keyword">ref</span></span> <span class="hljs-number"><span class="hljs-number">100</span></span>)) (def account2 (<span class="hljs-keyword"><span class="hljs-keyword">ref</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>)) ;     <span class="hljs-string"><span class="hljs-string">'ref'</span></span>  (deref refname): (deref account1) <span class="hljs-number"><span class="hljs-number">100</span></span> ; @refname -  (deref refname) @account2 <span class="hljs-number"><span class="hljs-number">0</span></span> (defn transfer [amount <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> <span class="hljs-keyword"><span class="hljs-keyword">to</span></span>] (dosync (<span class="hljs-keyword"><span class="hljs-keyword">alter</span></span> <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> - amount) (<span class="hljs-keyword"><span class="hljs-keyword">alter</span></span> <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> + amount))) (transfer <span class="hljs-number"><span class="hljs-number">100</span></span> account1 account2) <span class="hljs-number"><span class="hljs-number">100</span></span></code> </pre></div></div><br>  There are options for using competition, in which the environment is allowed to "relax" to achieve additional performance.  For example, imagine that you keep a transaction log for the day.  The order of transactions in the log is not important if you know that the final balance will be correct.  If you receive two installments of $ 100 and $ 50, the sequence of their entry in the journal does not matter.  The contribution from two transactions is commutative, and clojure provides a competitive <code>commute</code> operation for just such cases. <br><div class="spoiler">  <b class="spoiler_title">Hidden text</b> <div class="spoiler_text"><pre> <code class="hljs lisp">(<span class="hljs-name"><span class="hljs-name">defn</span></span> log-deposit [account amount] (<span class="hljs-name"><span class="hljs-name">dosync</span></span> (<span class="hljs-name"><span class="hljs-name">println</span></span> <span class="hljs-string"><span class="hljs-string">"Depositing $"</span></span> amount <span class="hljs-string"><span class="hljs-string">" into account, balance now: "</span></span> (<span class="hljs-name"><span class="hljs-name">commute</span></span> account + amount)))) (<span class="hljs-name"><span class="hljs-name">def</span></span> myaccount (<span class="hljs-name"><span class="hljs-name">ref</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>)) (<span class="hljs-name"><span class="hljs-name">log-deposit</span></span> myaccount <span class="hljs-number"><span class="hljs-number">100</span></span>) (<span class="hljs-name"><span class="hljs-name">log-deposit</span></span> myaccount <span class="hljs-number"><span class="hljs-number">50</span></span>) <span class="hljs-comment"><span class="hljs-comment">; (as good as) equivalent to (log-deposit myaccount 50) (log-deposit myaccount 100)</span></span></code> </pre></div></div><br><h5>  Haskell </h5><br>  Haskell's transactional memory is contained in the STM library, which is part of the Haskell Platform.  Incorrect use of transactional types is determined at the compilation of the program. <br><br>  Haskell has a powerful type system.  The language separates functions with side effects and pure functions.  Any value of type <code>IO t</code> is called an action.  To perform an action atomically in Haskell, the action is preceded by the word atomically.  Calling atomically with action as an argument gives two guarantees: <br><ul><li>  atomicity - the effect of <code>atomically act</code> will be visible to other threads at once and completely.  No other thread is able to see the state inside the atomic action, only the final state. </li><li>  isolation ‚Äî during a call to <code>atomically act</code> , <code>act</code> is completely independent of other threads.  It removes the state of the world at startup and runs in that state. </li></ul><br>  <code>atomically</code> has the type <code>atomically :: STM a -&gt; IO a</code> .  Action type <code>STM a</code> - argument.  Like the <code>IO</code> action, the <code>STM</code> action has side effects, but their range is significantly narrower.  Basically, in the <code>STM</code> action, the transaction variable <code>TVar a</code> is written or read: <br><ul><li> <code>readTVar :: TVar a -&gt; STM a</code> </li> <li> <code>writeTVar :: TVar a -&gt; a -&gt; STM ()</code> </li> </ul><br>  Consider an example of transferring funds between bank accounts. <div class="spoiler">  <b class="spoiler_title">Hidden text</b> <div class="spoiler_text"><pre> <code class="haskell hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> System.IO <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Control.Concurrent.STM <span class="hljs-comment"><span class="hljs-comment">--          TVar   type Account = TVar Int withdraw :: Account -&gt; Int -&gt; STM () withdraw acc amount = do bal &lt;- readTVar acc writeTVar acc (bal - amount) deposit :: Account -&gt; Int -&gt; STM () deposit acc amount = withdraw acc (- amount) transfer :: Account -&gt; Account -&gt; Int -&gt; IO () --  'amount'   'from'   'to' transfer from to amount = atomically (do deposit to amount withdraw from amount) showAccount :: Account -&gt; IO Int showAccount acc = atomically (readTVar acc) main = do from &lt;- atomically (newTVar 200) to &lt;- atomically (newTVar 100) transfer from to 50 v1 &lt;- showAccount from v2 &lt;- showAccount to putStrLn $ (show v1) ++ ", " ++ (show v2) --   "150, 150"</span></span></code> </pre></div></div><br><h5>  Scala </h5><br>  The STM implementation for Scala (ScalaSTM) was developed under the impression of implementations in Haskell and Clojure.  In addition to Scala, ScalaSTM is called from Java and Clojure.  The implementation is used in the popular Akka framework for writing parallel programs. <br>  ScalaSTM provides the <code>Ref</code> cell, which is modified exclusively within the transaction.  Data structures based on immutable objects and <code>Ref</code> are used by many threads. <br><br>  Consider the implementation of a doubly linked thread-safe list using transactional memory.  Unfortunately, I did not manage to collect an example on Scala, I leave this activity to the reader. <br><div class="spoiler">  <b class="spoiler_title">Hidden text</b> <div class="spoiler_text">  Full github example: <a href="https://github.com/nbronson/scala-stm/blob/master/src/test/scala/scala/concurrent/stm/examples/ConcurrentIntList.scala">github.com/nbronson/scala-stm/blob/master/src/test/scala/scala/concurrent/stm/examples/ConcurrentIntList.scala</a> <br><br>  To implement a shared structure, pointers to the next and previous node make it thread-safe.  If there is a possibility that one thread writes a variable at the same time when another one accesses it (reads or writes), then use <code>Ref</code> .  Define the class for the list node and initialize the head of the list.  List of roundabouts: when creating pointers of the head list point to it.  These pointers are never <code>null</code> . <br><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> scala.concurrent.stm._ <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">ConcurrentIntList</span></span></span><span class="hljs-class"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Node</span></span></span><span class="hljs-class">(</span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">val elem: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">Int</span></span></span></span><span class="hljs-class"><span class="hljs-params">, prev0: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">Node</span></span></span></span><span class="hljs-class"><span class="hljs-params">, next0: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">Node</span></span></span></span></span><span class="hljs-class">) </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> isHeader = prev0 == <span class="hljs-literal"><span class="hljs-literal">null</span></span> <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> prev = <span class="hljs-type"><span class="hljs-type">Ref</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (isHeader) <span class="hljs-keyword"><span class="hljs-keyword">this</span></span> <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> prev0) <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> next = <span class="hljs-type"><span class="hljs-type">Ref</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (isHeader) <span class="hljs-keyword"><span class="hljs-keyword">this</span></span> <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> next0) } <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> header = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-type"><span class="hljs-type">Node</span></span>(<span class="hljs-number"><span class="hljs-number">-1</span></span>, <span class="hljs-literal"><span class="hljs-literal">null</span></span>, <span class="hljs-literal"><span class="hljs-literal">null</span></span>)</code> </pre> <br>  If <code>x</code> is <code>Ref</code> , then <code>x()</code> gets the value stored in <code>x</code> , and <code>x() = v</code> sets it equal to the value of <code>v</code> . <br>  <code>Ref</code> are read and written only inside the atomic block (transaction).  This is checked at compile time.  The following demonstrates the use of a transaction. <br><pre> <code class="hljs scala"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">addLast</span></span></span></span>(elem: <span class="hljs-type"><span class="hljs-type">Int</span></span>) { atomic { <span class="hljs-keyword"><span class="hljs-keyword">implicit</span></span> txn =&gt; <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> p = header.prev() <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> newNode = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-type"><span class="hljs-type">Node</span></span>(elem, p, header) p.next() = newNode header.prev() = newNode } }</code> </pre> </div></div><br>  Scala combines the ideas of many programming paradigms.  It is not surprising that in the field of transactional memory language has original technologies.  The aforementioned Akka framework combines the capabilities of actors and transactional memory, getting <a href="http://doc.akka.io/docs/akka/2.0.4/scala/agents.html">agents</a> and <a href="http://doc.akka.io/docs/akka/2.0.4/scala/transactors.html">transactors</a> that will finally blow your mind. <br><br><h5>  C / C ++ (GCC 4.7+) </h5><br>  Starting from version 4.7, GCC supports transactional memory.  The implementation is a libitm runtime library, the -fgnu-tm (-mrtm, -mhle) flag is specified for compilation.  The library was developed with an eye to the <a href="https://sites.google.com/site/tmforcplusplus/C%252B%252BTransactionalConstructs-1.1.pdf">draft of</a> transactional structures for C ++ (the inclusion of a language in the standard is proposed). <br><br>  Most implementations of hardware transactional memory use the principle of greatest effort.  Therefore, practical implementations use the combination of hardware technology and software transactional memory.  Such systems are called ‚Äúhybrid transactional memory‚Äù systems.  These include, in particular, the implementation of GCC. <br><br>  Key words are entered into the language: <br><ul><li>  <code>__transaction_atomic { ‚Ä¶ }</code> - an indication that the code block is a transaction; </li><li>  <code>__transaction_relaxed { ‚Ä¶ }</code> - an indication that an insecure code inside the block does not lead to side effects; </li><li>  <code>__transaction_cancel</code> - explicitly cancel the transaction; </li><li>  <code>attribute((transaction_safe))</code> - indication of the transaction-safe function; </li><li>  <code>attribute((transaction_pure))</code> - an indication of the function without side effects. </li></ul><br><br>  To demonstrate the use of transactional memory in C, we will fill in a histogram of data in competitive streams. <br><div class="spoiler">  <b class="spoiler_title">Hidden text</b> <div class="spoiler_text">  Full implementation on github: <a href="">github.com/JIghtuse/tm-experiments/blob/master/histogram/src/hist.c</a> <br><br>  One transaction block is used per histogram update cycle.  The runtime library (or hardware) will determine when and which transactions to restart. <br><pre> <code class="hljs rust">#ifdef _USE_TSX __transaction_atomic { #endif <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (i = <span class="hljs-number"><span class="hljs-number">0</span></span>; i &lt; d-&gt;sz; ++i) { <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">struct</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">pixel</span></span></span></span> p = d-&gt;pixels[i]; unsigned int luminance = rY * p.red + gY * p.green + bY * p.blue; #<span class="hljs-keyword"><span class="hljs-keyword">if</span></span> defined _USE_TSX ++histogram[luminance/BORDER]; #elif defined _USE_MUTEX pthread_mutex_lock(&amp;<span class="hljs-keyword"><span class="hljs-keyword">mut</span></span>); ++histogram[luminance/BORDER]; pthread_mutex_unlock(&amp;<span class="hljs-keyword"><span class="hljs-keyword">mut</span></span>); #endif } #ifdef _USE_TSX } #endif</code> </pre> </div></div><br><br><h4>  Hardware implementations (Hardware Transactional Memory, HTM) </h4>  Only recently have begun to appear hardware implementation of transactional memory. <br><br><h3>  Sun Rock (SPARC v9) 2007-2008 </h3><br><img src="https://habrastorage.org/getpro/habr/post_images/f4a/55a/900/f4a55a900faea60cce782c08973aedae.jpg"><br><br>  Rock Microprocessor from Sun Microsystems was the first microprocessor with hardware support for transactional memory.  The 64-bit SPARC v9 architecture processor had 16 cores. <br><br>  In 2007, the company announced technology support.  Two new <code>chkpt</code> and <code>commit</code> instructions and one new status register <code>cps</code> were added for the operation of the transactional memory.  The <code>chkpt &lt;fail_pc&gt;</code> used to start a transaction, and the <code>commit</code> instruction to terminate it.  When canceling a transaction, a transition to <code>&lt;fail_pc&gt;</code> , at which time it was possible to check the <code>cps</code> register to determine the reason for the cancellation.  Transactions were interrupted for reasons of data conflicts, TLB misses, interruptions, complex instructions.  However, in many cases, the use of transactional memory in the Rock processor gave advantages in synchronization. <br><br>  In 2008, Sun engineers unveiled the transactional memory interface and Adaptive Transactional Memory Test Platform simulator.  After the acquisition of Sun by Oracle Corporation, the Rock project was closed: ‚ÄúThis processor had two amazing properties: it was incredibly slow and consumed an enormous amount of energy.  It was so hot that they had to put 12 inches of cooling fans on top so that the processor would not overheat.  It would be folly to continue this project. ‚Äù <sup>2</sup> <br><br><h3>  IBM BlueGene / Q (PowerPC A2) 2011 </h3><br><img src="https://habrastorage.org/getpro/habr/post_images/38e/1d4/786/38e1d478652cb8169f1acd9eb2b4673c.jpg"><br>  The BlueGene / Q supercomputer Sequoia became the first commercial system with hardware support for transactional memory.  The technology works in a 32-megabyte cache of the second level of the PowerPC A2 processor (PowerPC BQC 16C).  The data in the cache is labeled ‚Äúversion‚Äù, and the cache is capable of storing multiple versions of the same data. <br><br>  The program informs the processor about the start of the transaction, does its work and reports that the transaction needs to be completed (commit).  If other threads have changed the same data ‚Äî by creating versions ‚Äî the cache rejects the transaction and the thread tries to conduct it again.  If no other versions of the data appear, the data is modified and the transaction is completed successfully. <br><br>  VersionPC technology in PowerPC A2 is also used for speculative execution.  Instead of waiting for a new version of the data, the stream can perform calculations with the available data, speculatively doing useful work.  If the data was the same as after the update, the thread completes (commit) the work from the cache.  Performance is higher: the thread performed the work until the final value was obtained.  Otherwise, the results of speculative work are rejected and the flow makes calculations with the correct values. <br><br>  Supporting transactional memory is in some way a logical extension of a feature that has long been present in PowerPC processors ‚Äî the load-link / store-conditional, or LL / SC.  LL / SC is a primitive operation that can be used as a building block for all thread-safe structures.  The first part of LL / SC, load-link, is used by the program to get data from memory.  Next, the stream modifies the data and writes it back to memory using the store-conditional.  The command succeeds if the data has not changed.  Otherwise, the program repeats actions with data from the beginning. <br><br>  Transactional memory - LL / SC on steroids: threads perform LL operations on many different memory areas, and the transaction completion operation atomically changes all memory areas or cancels the transaction (like SC). <br><br>  Ruud Haring, who presented IBM's work on transactional memory at <a href="http://www.hotchips.org/">Hot Chips</a> , admitted that the company faced many nontrivial problems in its implementation.  For all the complexity, the implementation has limitations: it does not provide interprocessor transaction support.  The problem is not relevant for Sequoia and at the same time allows us to estimate the gain from the use of transactional memory. <br><br><h3>  IBM zEnterprise EC12 (Z / Architecture) 2012 </h3><br>  The first commercial server supporting transactional memory instructions.  When using transactional memory, IBM found a performance increase of 45% compared to the z196 machine in the DB2 database and in virtualized server workloads. <br><br><h3>  IBM Power8 (Power) 2013 </h3><br><img src="https://habrastorage.org/getpro/habr/post_images/0bb/224/3e6/0bb2243e6668afd5fee7e212a88cf638.jpg"><br>  Power 8 memory controllers support transactional memory.  Technology support in the Linux kernel appeared since kernel version 3.9. <br>  <i>Information on the HTM in Power8 was not found so much, I hope it still appears.</i> <br><br><h3>  Intel Haswell (x86) 2013 </h3><br><img src="https://habrastorage.org/getpro/habr/post_images/c35/589/7f6/c355897f6a7dfefa3bc6d6b60258cf8d.jpg"><br>  In 2012, Intel announced the introduction of Transactional Syncrhonization Extensions (TSX) extensions to the x86 instruction set.  Extensions allow programmers to mark individual sections of code as transactions. <br>  In 2013, with the release of the Haswell processor generation, hardware support for transactional memory for the first time becomes available at the consumer level. <br><br>  Haswell manages read and write sets with cache line granularity, tracking L1 data cache addresses.  Conflicts are determined using the cache coherence protocol.  Which is logical to assume, since the tasks of determining transaction conflicts and maintaining coherence of caches are very close: if the value changes in one thread, but not in others, then something is wrong. <br><br>  TSX consists of two parts.  Hardware lock elimination (HLE) provides a simple conversion of lock-based programs into transactional programs, and the resulting programs will be backward compatible with existing processors.  Restricted Transactional Memory (RTM) is a more complete implementation of transactional memory. <br><br><h6>  Hardware Lock Elision </h6><br>  HLE slightly modifies the instructions for changing the memory location.  The technology adds prefixes ‚Äî instructions that do not produce any actions, but change the interpretation of the next instruction ‚Äî to modify the instructions for taking and releasing the lock (XACQUIRE and XRELEASE, respectively). <br><br>  Between taking and releasing a lock, the processor keeps track of the chunks that read and write streams.  In the event of a conflict ‚Äî if two streams modify one data, or one stream reads data that another writes ‚Äî the processor cancels the transaction when the lock is released.  Otherwise, execution continues normally. <br><br>  Thus, HLE allows the generally accepted lock-based code to work optimistically.  Each thread will assume that it has received a lock, while other threads can operate simultaneously.  As long as it is safe, transactions are not canceled. <br><br>  The technology is backward compatible with non-HTM processors.  Lock management operations remain, but with a special prefix.  Haswell processors will take into account the prefix and use transactional execution instead of blocking manipulations.  Any other processor will ignore the prefix and simply control the lock using traditional lock-based behavior.  The XACQUIRE and XRELEASE instructions already exist, but do not carry any meaning until they are used with specific instructions. <br><br>  HLE allows you to write programs and operating systems that will use Haswell transactions, increasing non-blocking concurrency.  The code will work correctly on current processors.  As a result, entering a new feature will be easy and safe. <br><br><div class="spoiler">  <b class="spoiler_title">HLE by a simple example</b> <div class="spoiler_text">  Operating systems implement locks in the kernel as chunks of memory, usually using the type typical for a processor.  A lock taker does something with this memory location, for example, it increases the value from 0 to 1. The reverse operation is applied to release the lock (for example, decrement from 1 to 0).  Changes are visible to each processor core and each thread in the system, so other threads immediately determine that they cannot take a lock and must wait for it to be released (acquiring the value 0). <br><br>  With the XACQUIRE / XRELEASE prefixes, an attempt to take a lock is completed successfully, and the process assumes that the lock belongs to it and works further.       .  ,     ,     1,      -  0.       ,      .     ,       . <br><br>     HLE:     0  1  ,     0. ‚Äú‚Äù  . <br></div></div><br><br><h6><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Restricted Transactional Memory </font></font></h6><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">RTM requires more participation: it moves away from backward compatibility and introduces three new instructions. </font><font style="vertical-align: inherit;">While HLE implicitly uses transactions, allowing lock-based code to work in parallel, RTM makes the start, end, and interruption of transactions explicit. </font><font style="vertical-align: inherit;">The thread starts a transaction with an XBEGIN instruction, providing a ‚Äúfallback‚Äù function that starts when the transaction is interrupted. </font><font style="vertical-align: inherit;">The transaction is completed with the XEND instruction, and the processor conducts the transaction if there are no conflicts or interrupts it, switching to the spare function. </font><font style="vertical-align: inherit;">Transactions are explicitly aborted in the program by the XABORT instruction. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Thanks to the explicit use of boundaries and ‚Äúescape route‚Äù, RTM allows you to more fully control transactions than HLE. </font><font style="vertical-align: inherit;">In the long term, RTM will simplify the implementation of transactional capabilities.</font></font><br><br><h4>  findings </h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The use of transactional memory is a viable alternative to existing synchronization methods, which simplifies parallel programming. </font></font><br> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">For inaccuracies in translation, stylistics, and typos, please write in a personal message.</font></font></i> <br><br><h4>  Notes </h4><br><ol><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">On the difference between the concepts of "competitiveness" and "parallelism", Rob Pike correctly put it in his speech " </font></font><a href="http://talks.golang.org/2012/waza.slide"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Concurrency is not Parallelism</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ": "Competitiveness - working with many things at once, parallelism - doing many things at once"</font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Yes, in addition to a pack of excellent software products (OpenSolaris, MySQL, OpenOffice), Oracle abandoned promising hardware technology </font></font></li></ol><br><h4>  Sources </h4><br><ul><li> <a href="http://en.wikipedia.org/wiki/Software_transactional_memory"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Software transactional memory - Wikipedia</font></font></a> </li><li> <a href="http://sw1nn.com/blog/2012/04/11/clojure-stm-what-why-how/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Clojure STM - What?</font></font></a>  <a href="http://sw1nn.com/blog/2012/04/11/clojure-stm-what-why-how/">Why?</a> <a href="http://sw1nn.com/blog/2012/04/11/clojure-stm-what-why-how/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">How? </font><font style="vertical-align: inherit;">- sw1nn</font></font></a> </li><li> <a href="http://www.haskell.org/haskellwiki/Software_transactional_memory"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Software transactional memory - HaskellWiki</font></font></a> </li><li> <a href="https://www.fpcomplete.com/school/advanced-haskell/beautiful-concurrency/3-software-transactional-memory">Software Transactional Memory ‚Äî School of Haskell | FP Complete</a> </li><li> <a href="http://nbronson.github.io/scala-stm/quick_start.html">ScalaSTM ‚Äî Quick Start</a> </li><li> <a href="http://www-users.cs.umn.edu/~boutcher/stm/">Software Transactional Memory in GCC</a> </li><li> <a href="https://software.intel.com/en-us/blogs/2013/06/07/resources-about-intel-transactional-synchronization-extensions">Web Resources about Intel¬Æ Transactional Synchronization Extensions</a> </li><li> <a href="http://en.wikipedia.org/wiki/Rock_(processor)">Rock (processor) ‚Äî Wikipedia</a> </li><li> <a href="http://ru.wikipedia.org/wiki/Rock_(%25D0%25BF%25D1%2580%25D0%25BE%25D1%2586%25D0%25B5%25D1%2581%25D1%2581%25D0%25BE%25D1%2580">Rock () ‚Äî </a> </li><li> <a href="http://top500.org/system/177556">Sequoia ‚Äî BlueGene/Q, Power BQC 16C 1.60 GHz, Custom | TOP500 Supercomputer Sites</a> </li><li> <a href="http://arstechnica.com/gadgets/2011/08/ibms-new-transactional-memory-make-or-break-time-for-multithreaded-revolution/">IBM's new transactional memory: make-or-break time for multithreaded revolution | Ars Technica</a> </li><li> <a href="http://eandt.theiet.org/news/2012/jun/ibm-sequoia.cfm/">IBM Sequoia named world's fastest supercomputer ‚Äî E &amp; T Magazine</a> </li><li> <a href="http://www.theregister.co.uk/2013/08/27/ibm_power8_server_chip/">You won't find this in your phone: A 4GHz 12-core Power8 for badass boxes ‚Ä¢ The Register</a> </li><li> <a href="http://en.wikipedia.org/wiki/Transactional_Synchronization_Extensions">Transactional Synchronization Extensions ‚Äî Wikipedia</a> </li><li> <a href="http://arstechnica.com/business/2012/02/transactional-memory-going-mainstream-with-intel-haswell/">Transactional memory going mainstream with Intel Haswell | Ars Technica</a> </li><li> <a href="http://www.bit-tech.net/news/hardware/2012/02/09/intel-haswell-tsx/">Intel's Haswell brings transactional memory tech | bit-tech.net</a> </li></ul></div><p>Source: <a href="https://habr.com/ru/post/221667/">https://habr.com/ru/post/221667/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../221653/index.html">The prototype goes to Open Source: Exchange of telephone operators</a></li>
<li><a href="../221655/index.html">We eliminate errors when getting an array from a user instead of a string</a></li>
<li><a href="../221657/index.html">Falcon 9-R took off one kilometer and landed back. With cows</a></li>
<li><a href="../221659/index.html">Easy python web framework: Bottle</a></li>
<li><a href="../221663/index.html">Arduino operates an industrial freight elevator</a></li>
<li><a href="../221669/index.html">Consulo + .NET plugin, two months later</a></li>
<li><a href="../221673/index.html">Chromium Transmission Integration</a></li>
<li><a href="../221675/index.html">VPN: past, present, future</a></li>
<li><a href="../221677/index.html">Sol 610: Mars Live Panorama and Curiosity</a></li>
<li><a href="../221679/index.html">Do not keep activities</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>