<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Lectures of the Technosphere. Semester 2 Modern methods and tools for building information retrieval systems</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Our educational heading is on air again. At this time, we offer to get acquainted with the next course of the Technosphere, dedicated to information r...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Lectures of the Technosphere. Semester 2 Modern methods and tools for building information retrieval systems</h1><div class="post__text post__text-html js-mediator-article"><iframe width="560" height="315" src="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://www.youtube.com/embed/LbyRkt595xk%3Ffeature%3Doembed&amp;xid=17259,15700022,15700186,15700191,15700248,15700253&amp;usg=ALkJrhgSqM7Dp0yZmj6oF0ADA4QH02Viyw" frameborder="0" allowfullscreen=""></iframe><br><br>  Our educational heading is on air again.  At this time, we offer to get acquainted with the next course of the Technosphere, dedicated to information retrieval.  The purpose of the course is to tell about the main methods used when creating search engines.  Some of them are a good example of wit, some show where and how the modern mathematical apparatus can be applied.  Course teachers: Alexey Voropayev, Vladimir Gulin, Dmitry Soloviev, Igor Andreev, Alexey Romanenko, Jan Kisel. <br><a name="habracut"></a><br><h4>  <b>Lecture 1. Introduction to information retrieval.</b>  <b>Search Engine Architecture Overview</b> </h4><br>  Definition of the task of information retrieval.  Examples of search engines.  Tasks related to information retrieval.  The history of the search engines.  The logical model of information retrieval, its tasks.  Principles of boolean search.  Matrix "term-document".  Reverse index  Dictionary and coordinate blocks.  Creating a reverse index.  Token splitting and sorting.  Dictionaries and coordinate blocks. <br><br><iframe width="560" height="315" src="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://www.youtube.com/embed/T9EMrLfFT7Q%3Ffeature%3Doembed&amp;xid=17259,15700022,15700186,15700191,15700248,15700253&amp;usg=ALkJrhiM765yeyLOl_OzOYCjdn99aorn1w" frameborder="0" allowfullscreen=""></iframe>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h4>  <b>Lecture 2. Linguistics</b> </h4><br>  What is linguistics, what are its tasks.  The history of the origin and development of linguistics as a science.  Problems solved by linguistics, its varieties.  General linguistics: phonetics, phonology, morphology, syntax, semantics, pragmatics.  Historical linguistics.  Linguistic typology.  Sociolinguistics.  Dialectology.  Lexicography.  Psycholinguistics.  Mathematical linguistics.  Statistical linguistics.  Approaches to language: rationalistic and empirical.  Morphology.  Corpus linguistics.  Concordance, Zipf's laws, amendments and the Mandelbrot formula. <br><br><iframe width="560" height="315" src="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://www.youtube.com/embed/wFvkpgqBEVA%3Ffeature%3Doembed&amp;xid=17259,15700022,15700186,15700191,15700248,15700253&amp;usg=ALkJrhiNmuMuoncYtpPLLbFmBHWAiISDNw" frameborder="0" allowfullscreen=""></iframe><br><br><h4>  <b>Lecture 3. Basics of text processing</b> </h4><br>  Criteria document encoding.  Levels of linguistic analysis.  Tokens and terms.  Language detection: graphematic, N-gram and lexical approaches.  Normalization.  Tokenization problems.  The presence and absence of gaps.  Chinese, Japanese, Arabic.  Accent and diacritics.  Equivalence classes.  Lower case  Stop words.  Lemmatization.  Stemming.  Predictor.  Types of languages.  Statistical removal of homonymy.  Splitting text into sentences.  Expansion of search query. <br><br><iframe width="560" height="315" src="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://www.youtube.com/embed/_qZ8I2wbEbU%3Ffeature%3Doembed&amp;xid=17259,15700022,15700186,15700191,15700248,15700253&amp;usg=ALkJrhhEZKOpdXEDx6Ekp-WT7YGe1ozi6w" frameborder="0" allowfullscreen=""></iframe><br><br><h4>  <b>Lecture 4. Collocation</b> </h4><br>  Probability calculation methods: parametric and non-parametric approaches, standard and binomial distributions, multinominal and normal distributions, approximation.  Bayesian approach to statistics.  Definition of collocations, their signs.  Frequency of bigrams.  Filter by parts of speech.  Deviations, deviation histograms.  Search for collocations, examples of t-test.  Search for differences in usage.  Pearson criterion.  x <sup>2</sup> criterion.  Likelihood ratio criterion.  Relative frequencies  Mutual information.  Sparseness of data.  F-measure. <br><br><iframe width="560" height="315" src="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://www.youtube.com/embed/etnudCnFVV8%3Ffeature%3Doembed&amp;xid=17259,15700022,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjSj0oj299l2hmWVYJpQTkFmqXQFA" frameborder="0" allowfullscreen=""></iframe><br><br><h4>  <b>Lecture 5. Language models.</b>  <b>N-grams.</b>  <b>Markov chains</b> </h4><br>  Objectives of language recognition.  Language models.  Search using language models.  The fundamental problem of lack of data.  Constructing N-grams.  Maximum likelihood method.  Smoothing.  Validation models.  Linear mixing models.  Markov chain.  Transition matrix  The sequence of states.  Hidden Markov models.  Three tasks HMM.  Algorithms forward and backward.  Algorithms of Viterbi, Bauma Welch.  Application of MMB Tagger.  Analysis of user behavior. <br><br><iframe width="560" height="315" src="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://www.youtube.com/embed/0gMZyXFn8_0%3Ffeature%3Doembed&amp;xid=17259,15700022,15700186,15700191,15700248,15700253&amp;usg=ALkJrhhA1_xjJdqo1TJSrrAPyI2IG4FYFw" frameborder="0" allowfullscreen=""></iframe><br><br><h4>  <b>Lecture 6. Machine translation</b> </h4><br>  Definition and tasks of machine translation.  The history of the development of machine translation.  Approaches to machine translation: rule-based, corpora-based, hybrid.  Three core methodologies.  RBMT, its comparison with SMT, their advantages and disadvantages.  Parallel housing.  Alignment by sentences.  Word-based model.  IBM Model, their limitations.  Phrase models: phrasal statistical translation, calculation of the probability of translation, language model, translation model, construction of a phrasal table.  Decoding.  Evaluation of machine translation.  BLEU (Bilingual evaluation understudy).  The evolution of machine translation. <br><br><iframe width="560" height="315" src="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://www.youtube.com/embed/1HzdL8OrERg%3Ffeature%3Doembed&amp;xid=17259,15700022,15700186,15700191,15700248,15700253&amp;usg=ALkJrhhxhWg5Qd0s9M-PSwLVo2_c2zIKNA" frameborder="0" allowfullscreen=""></iframe><br><br><h4>  <b>Lecture 7. Indexing</b> </h4><br>  The general scheme of the search base.  Assign reverse index.  Technical limitations and disk subsystem.  Composition of the inverse index and options for its construction.  Optimization of the intersection of blocks.  Compression of coordinate blocks: a comparison of bitwise and byte approaches: Fibonacci code, VarByte, gamma codes, Simple9.  Practical tips to reduce the size of the index.  Data structures used to build the dictionary.  Approaches to the storage of stop words.  The problems of indexing large volumes.  Document distribution and database balancing.  Indexer architecture. <br><br><iframe width="560" height="315" src="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://www.youtube.com/embed/GLpU3dwJD8k%3Ffeature%3Doembed&amp;xid=17259,15700022,15700186,15700191,15700248,15700253&amp;usg=ALkJrhgtYPAzJRp_EcwOeTjM3J_6F4XKeA" frameborder="0" allowfullscreen=""></iframe><br><br><h4>  <b>Lecture 8. Web search architecture.</b>  <b>Text ranking</b> </h4><br>  The logical scheme of the search engine.  Search cluster.  Indexing.  Boolean search.  Weight calculation  Jacquard coefficient.  Frequency matrix  The word bag model.  Frequency term.  Logarithmic weighting.  Document frequency  IDF.  Documents as vectors.  Text ranking optimization methods.  Terms with great IDF.  Documents with more terms from the query.  Static weights, total weight.  Echelons.  Index Clustering.  Parametric indexes and zones.  Fields (numeric zones).  Indexes for zones.  Compact entry.  Probabilistic search.  Using language models when searching.  Options for comparing models.  Likelihood request and document.  Comparison of models.  Feedback on relevance.  Binary probabilistic model.  Bayesian networks in the ranking problem. <br><br><iframe width="560" height="315" src="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://www.youtube.com/embed/4Nkb3q2VuwQ%3Ffeature%3Doembed&amp;xid=17259,15700022,15700186,15700191,15700248,15700253&amp;usg=ALkJrhheneMEs350POMBOPqvC1a18Wskwg" frameborder="0" allowfullscreen=""></iframe><br><br><h4>  <b>Lecture 9. Design of search results.</b>  <b>Snippets.</b>  <b>Evaluation of search quality</b> </h4><br>  Examples of page designs search results of various resources.  SERP components.  Organic results.  Highlighting paragraphs.  Splitting into sentences.  Snippet generation, general generation algorithm.  Enrichment snippetov.  Snippet metrics.  Assessment by assessors.  Search engine quality metrics.  Quality search.  Standard collections.  TREC.  Accuracy / completeness.  Criticism of pure relevance.  Marker Tests.  Search for peripheral sites.  Regional navigation.  Subject search.  Overall search quality.  Assessment service.  Evaluation of the relevance of the document.  Cross validation.  SOM Cards.  Auto search for errors.  Online metrics.  Evaluation of hypotheses.  Click metrics.  Correlation with assessors. <br><br><iframe width="560" height="315" src="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://www.youtube.com/embed/DnYLLeJM3pA%3Ffeature%3Doembed&amp;xid=17259,15700022,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj6bm0zFNmMS51ZRyRyvTpAwBBFIg" frameborder="0" allowfullscreen=""></iframe><br><br><h4>  <b>Lecture 10. Features of web-search.</b>  <b>Spider</b> </h4><br>  Popularity of using search.  Search engine history.  Basics of web search.  User needs.  Empirical evaluation of search results by the user.  Collection of web documents.  Search advertising, how it is ranked, what are its pros and cons.  Spider, his tasks.  Queue URLs  Search robots.  The main architecture of the spider.  Parsing: URL normalization.  Distributed spider.  The interaction of servers.  Mercator scheme.  Front queues, back queues.  Freshness base.  Deep Web (hard-to-reach sites).  Site maps.  Document storage.  Noise removal. <br><br><iframe width="560" height="315" src="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://www.youtube.com/embed/7Rbytb4rEZk%3Ffeature%3Doembed&amp;xid=17259,15700022,15700186,15700191,15700248,15700253&amp;usg=ALkJrhj1B4SzDgiA1MSvk5f8pUds21EZOg" frameborder="0" allowfullscreen=""></iframe><br><br><h4>  <b>Lecture 11. Finding duplicates in the Web.</b> </h4><br>  Comparison of documents: accurate and inaccurate duplicates, almost duplicates, print versions.  Three stages of determining similar documents.  Shingles (shingles), compression option.  Multiple model, matrix model.  Search for similar columns.  Signatures  Identification of a similar set (minhashing).  Search for similar couples.  Selection of candidates from the Minhash signatures.  Locality-sensitive hashing.  Distribution in parts and in baskets.  LSH tradeoffs.  Find duplicates on the Web. <br><br><iframe width="560" height="315" src="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://www.youtube.com/embed/sja6zKHLJYY%3Ffeature%3Doembed&amp;xid=17259,15700022,15700186,15700191,15700248,15700253&amp;usg=ALkJrhg65IrUR0aBKkRk-2jYAyy17AcJIg" frameborder="0" allowfullscreen=""></iframe><br><br><h4>  <b>Lecture 12. The use of self-organizing maps in a search engine</b> </h4><br>  The lecture is divided into two parts.  The first part: the issues of prioritization of the search engine spider, algorithms for segmentation of large sites into parts and the distribution of priorities for pumping segments.  The second part: algorithms for analyzing and visualizing large amounts of data using Kohonen self-organizing maps (SOM), using this tool in the task of analyzing the structure of the web and prioritizing the search robot, the possibility of using SOM for data analysis in various areas of the search engine development. <br><br><iframe width="560" height="315" src="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://www.youtube.com/embed/Lwpg0cg2tQs%3Ffeature%3Doembed&amp;xid=17259,15700022,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjtDbBQEUEfARBNQNKthZK5SKmBVQ" frameborder="0" allowfullscreen=""></iframe><br><br><h4>  <b>Lecture 13. Identification of spam sites based on the analysis of content pages.</b> </h4><br>  Various aspects of cleaning the search index from garbage.  Questions construction classifiers.  Basic machine learning topics: the correct construction of a training set, the generation of features, the choice of classification algorithms.  The problem of building classifiers for different classes of data. <br><br><iframe width="560" height="315" src="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://www.youtube.com/embed/be0puOxOfgQ%3Ffeature%3Doembed&amp;xid=17259,15700022,15700186,15700191,15700248,15700253&amp;usg=ALkJrhhTzMOdaNlad5lzihggi_sHaYRv_A" frameborder="0" allowfullscreen=""></iframe><br><br><h4>  <b>Lecture 14. Behavioral and Reference Ranking</b> </h4><br>  Calculation of behavioral relevance.  Indexing anchor text.  Algorithm HITS, Page Rank.  The block structure method.  Systems for processing graphs. <br><br><iframe width="560" height="315" src="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://www.youtube.com/embed/t7WUdhw5yrs%3Ffeature%3Doembed&amp;xid=17259,15700022,15700186,15700191,15700248,15700253&amp;usg=ALkJrhi_pLW0IOBAQWADCTRQts06scSAjg" frameborder="0" allowfullscreen=""></iframe><br><br><h4>  <b>Lecture 15. Ranking with machine learning</b> </h4><br>  Classic ranking.  Ranking factors.  Ranging based on machine learning.  The specificity of the task of machine learning ranking.  Formal statement of the problem.  Gradient descent.  Decision trees  "Inattentive" decision trees.  Algorithmic compositions over decision trees (bagging, boosting).  Stacking  BagBoo algorithm.  Issues of building training data.  Active learning.  Sampling uncertainty.  Committee methods of active learning.  The use of self-organizing maps to sample training data.  SOM + QBag Algorithm for Active Ranking Learning. <br><br><iframe width="560" height="315" src="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://www.youtube.com/embed/HPJr2-nXwVs%3Ffeature%3Doembed&amp;xid=17259,15700022,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjCFWxjgMTqWJAsx4GGQJZm7skHmQ" frameborder="0" allowfullscreen=""></iframe><br><br><h4>  <b>Previous issues</b> </h4><br>  Technopark: <br><ul><li>  <a href="http://habrahabr.ru/company/mailru/blog/248745/">1 semester</a>  <a href="http://habrahabr.ru/company/mailru/blog/248745/">Web technologies</a> </li><li>  <a href="http://habrahabr.ru/company/mailru/blog/251561/">1 semester</a>  <a href="http://habrahabr.ru/company/mailru/blog/251561/">Algorithms and data structures</a> </li><li>  <a href="http://habrahabr.ru/company/mailru/blog/253095/">1 semester</a>  <a href="http://habrahabr.ru/company/mailru/blog/253095/">C / C ++</a> </li><li>  <a href="http://habrahabr.ru/company/mailru/blog/254073/">Semester 2</a>  <a href="http://habrahabr.ru/company/mailru/blog/254073/">Database</a> </li><li>  <a href="http://habrahabr.ru/company/mailru/blog/254843/">Term 3</a>  <a href="http://habrahabr.ru/company/mailru/blog/254843/">Design of high-load systems</a> </li></ul><br>  Technosphere: <br><ul><li>  <a href="http://habrahabr.ru/company/mailru/blog/254897/">1 semester</a>  <a href="http://habrahabr.ru/company/mailru/blog/254897/">Algorithms for intelligent processing of large amounts of data</a> </li><li>  <a href="http://habrahabr.ru/company/mailru/blog/256039/">1 semester</a>  <a href="http://habrahabr.ru/company/mailru/blog/256039/">Methods of using DBMS in Internet applications</a> </li></ul><br>  Subscribe to the <a href="http://www.youtube.com/user/TPMGTU/">youtube channel</a> Technopark and Technosphere! </div><p>Source: <a href="https://habr.com/ru/post/257119/">https://habr.com/ru/post/257119/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../257109/index.html">Attackers use Linux / Mumblehard to compromise servers, part 1</a></li>
<li><a href="../257111/index.html">Effective work with text or how I reinvent the wheel.</a></li>
<li><a href="../257113/index.html">Writing a system of invitations (invitations) for your Meteor application</a></li>
<li><a href="../257115/index.html">Simple control of arduino via the Internet</a></li>
<li><a href="../257117/index.html">Lab penetration testing "Test lab v.7" is open</a></li>
<li><a href="../257121/index.html">Image and video analysis. Image segmentation</a></li>
<li><a href="../257123/index.html">Develop a simple game in the game maker. Episode 1</a></li>
<li><a href="../257125/index.html">How to earn points without even starting the game</a></li>
<li><a href="../257127/index.html">Microsoft showed Project Astoria: what it will look like using Android code in Windows applications</a></li>
<li><a href="../257129/index.html">Creating plug-ins for AutoCAD using the .NET API (part 4 - inserting primitive objects)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>