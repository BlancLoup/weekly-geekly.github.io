<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Clustering text documents according to semantic features (part two: model description)</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Word2Vec Models 
 As mentioned in the first part of the publication , the models are derived from classes ‚Äî the representation of the result of the te...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Clustering text documents according to semantic features (part two: model description)</h1><div class="post__text post__text-html js-mediator-article"><h3>  Word2Vec Models </h3><br>  As mentioned <a href="https://habrahabr.ru/post/324540/">in the first part of the publication</a> , the models are derived from classes ‚Äî the representation of the result of the text word2vec in the form of associative semantic classes by smoothing the distributions. <br><br>  The idea of ‚Äã‚Äãsmoothing is as follows. <br><a name="habracut"></a><br><ol><li>  We obtain a frequency dictionary of educational material, where each word is assigned its frequency of occurrence of the documents (that is, how many documents this lexeme met). </li><li>  Based on this frequency distribution for each class word, its standard deviation (or variance, in this case does not have a fundamental difference) is considered. </li><li>  For each class, we consider the average of all deviations of its components. </li><li>  From each class we remove "outliers" - words with a large standard deviation: </li></ol><br><p><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-1-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mi>S</mi><mi>D</mi><mi>w</mi><mo>&amp;#x2217;</mo><mi>k</mi><mo>&amp;lt;</mo><mi>a</mi><mi>v</mi><mi>r</mi><mo stretchy=&quot;false&quot;>(</mo><mi>S</mi><mi>D</mi><mi>c</mi><mi>l</mi><mo stretchy=&quot;false&quot;>)</mo><mo>,</mo></math>" role="presentation" style="font-size: 100%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="22.578ex" height="2.66ex" viewBox="0 -832 9721 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/324998/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhhUBlw9Kqq_1pRqPEaOsX_Tj8nQXA#MJMATHI-53" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/324998/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhhUBlw9Kqq_1pRqPEaOsX_Tj8nQXA#MJMATHI-44" x="645" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/324998/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhhUBlw9Kqq_1pRqPEaOsX_Tj8nQXA#MJMATHI-77" x="1474" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/324998/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhhUBlw9Kqq_1pRqPEaOsX_Tj8nQXA#MJMAIN-2217" x="2412" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/324998/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhhUBlw9Kqq_1pRqPEaOsX_Tj8nQXA#MJMATHI-6B" x="3135" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/324998/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhhUBlw9Kqq_1pRqPEaOsX_Tj8nQXA#MJMAIN-3C" x="3934" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/324998/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhhUBlw9Kqq_1pRqPEaOsX_Tj8nQXA#MJMATHI-61" x="4991" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/324998/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhhUBlw9Kqq_1pRqPEaOsX_Tj8nQXA#MJMATHI-76" x="5520" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/324998/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhhUBlw9Kqq_1pRqPEaOsX_Tj8nQXA#MJMATHI-72" x="6006" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/324998/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhhUBlw9Kqq_1pRqPEaOsX_Tj8nQXA#MJMAIN-28" x="6457" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/324998/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhhUBlw9Kqq_1pRqPEaOsX_Tj8nQXA#MJMATHI-53" x="6847" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/324998/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhhUBlw9Kqq_1pRqPEaOsX_Tj8nQXA#MJMATHI-44" x="7492" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/324998/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhhUBlw9Kqq_1pRqPEaOsX_Tj8nQXA#MJMATHI-63" x="8321" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/324998/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhhUBlw9Kqq_1pRqPEaOsX_Tj8nQXA#MJMATHI-6C" x="8754" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/324998/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhhUBlw9Kqq_1pRqPEaOsX_Tj8nQXA#MJMAIN-29" x="9053" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/324998/&amp;xid=25657,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhhUBlw9Kqq_1pRqPEaOsX_Tj8nQXA#MJMAIN-2C" x="9442" y="0"></use></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mi>S</mi><mi>D</mi><mi>w</mi><mo>‚àó</mo><mi>k</mi><mo>&lt;</mo><mi>a</mi><mi>v</mi><mi>r</mi><mo stretchy="false">(</mo><mi>S</mi><mi>D</mi><mi>c</mi><mi>l</mi><mo stretchy="false">)</mo><mo>,</mo></math></span></span></div><script type="math/tex;mode=display" id="MathJax-Element-1"> SDw * k <avr (SDcl), </script></p><br>  Where SDw is the standard deviation of each word, avr (SDcl) is the mean root mean square of the class, k is the smoothing coefficient. <br><br>  Obviously, the result will depend on the coefficient k.  His choice is an empirical task, it depends on the language, the size of the training sample, its homogeneity, etc. But still, we will try to identify some common things. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h3>  Building and testing models </h3><br>  For the models used material collected from the daily flow of the Internet, collected on the lists of the most frequent keywords.  The English text contained about 170 million word forms, Russian - a little less than a billion.  The range of classes was from 250 to 5000 classes in increments of 250. The remaining parameters were used by default. <br><br>  Testing was conducted on the Russian-language and English-language material. <br><br>  The test method in two words is as follows: reference test cases were taken for classification and run through clustering models with different parameters: by changing the number of classes and the smoothing coefficient, the dynamics of the result change and, consequently, the quality of the model can be demonstrated. <br><br>  English five buildings taken from an <a href="http://ana.cachopo.org/datasets-for-single-label-text-categorization">open source</a> : <br><br><ul><li>  20NG-TEST-ALL-TERMS - 20 themes (10555K) </li><li>  MINI20-TEST - 20 themes (816K) </li><li>  R52-TEST-ALL-TERMS - 52 threads (1487K) </li><li>  R8-TEST-ALL-TERMS - 8 themes (1167K) </li><li>  WEBKB-TEST-STEMMED - 4 threads (1271K) </li></ul><br>  Russian corps had to be used from private development, since it was not possible to detect open sources: <br><br><ul><li>  Ru1 - Short Message Enclosure - 13 Topics (76K) </li><li>  Ru2 - News corps - 10 topics (577K) </li></ul><br>  When testing, we used the simplest method of comparison, without using any complex metrics.  The choice in favor of such a simple classification (Dumb classifier) ‚Äã‚Äãwas made in view of the fact that the purpose of the study was not to improve the classification result, but to make a comparative analysis of the results with different input parameters.  That is, it was not the result that was interesting, but its dynamics. <br><br>  At the same time, tests were conducted on some clustering models using the logfi measure TFiDF to check how, in principle, these results on these models can differ from the results on models trained in lexical unigrams.  Such tests showed that the results on models with associative semantic classes are almost as good as models on unigrams: there was a slight deterioration in quality from 1 to 10%, depending on the test case.  That speaks about the competitiveness of the obtained clustering models, considering that they were not originally ‚Äúsharpened‚Äù under the topics. <br><br><h3>  The dependence of the quality of the model on the number of classes </h3><br>  Tests with different numbers of semantic classes were carried out with all bodies: from 250 to 5000 with a step of 250 classes. <br><br>  Figures 1 and 2 demonstrate the dependence of classification accuracy on the number of classes of models for Russian and English. <br><br><img src="https://habrastorage.org/files/828/d0f/1b8/828d0f1b85b5496c9034ec4ebf58d04c.png"><br>  <i>Fig.1.</i>  <i>Dependence of classification accuracy on the number of word2vec semantic classes for Russian-language buildings.</i>  <i>The abscissa is the number of classes, the ordinate is the accuracy values.</i> <br><br><img src="https://habrastorage.org/files/941/611/b01/941611b019364122bd68b7c83cbee485.png"><br>  <i>Fig.2.</i>  <i>The dependence of classification accuracy on the number of word2vec semantic classes for English-language buildings.</i>  <i>The abscissa axis shows the number of classes, and the ordinate axis - the classification accuracy.</i> <br><br>  From the graphs it can be seen that the fluctuations in accuracy are periodic, the period of which can vary depending on the material being tested.  To determine trends, we construct graphs of average values. <br><br><img src="https://habrastorage.org/files/8a5/b4b/5b0/8a5b4b5b051d44b7a257ade1be3e1353.png"><br>  <i>Fig.3.</i>  <i>The mean value is the dependence of the classification accuracy on the number of word2vec semantic classes for Russian-language buildings.</i>  <i>The abscissa is the number of classes, the ordinate is the accuracy values.</i>  <i>A polynomial (6th power) trend line has been added.</i> <br><br><img src="https://habrastorage.org/files/d5a/238/548/d5a238548caa4771840044fe4989ee43.png"><br>  <i>Fig.4.</i>  <i>The mean value is the dependence of classification accuracy on the number of word2vec semantic classes for English-language buildings.</i>  <i>The abscissa is the number of classes, the ordinate is the accuracy values.</i>  <i>A polynomial (6th power) trend line has been added.</i> <br><br>  From figures 3 and 4 it is already clear that the quality of the result increases on average with an increase in the number of classes in the range from 4 to 5 thousand.  That, generally speaking, is not surprising: a more subtle partition of space leads to its concretization.  But further splitting can lead to the fact that semantic classes begin to stratify into homogeneous pieces.  And this already leads to a drop in accuracy, because the classes cease to be ‚Äúhooked‚Äù: the same semantic will correspond to different semantic classes.  This is observed in the approximation to 5 thousand classes for both Russian and English. <br><br>  Curiously peaks are present in both figures in the region of 500 classes: despite the fact that there are few semantic classes (therefore, the classes are mixed), nevertheless, there is a macro-semantic association: classes as a whole are subject to one or another topic. <br><br>  From the obtained results, we can conclude that, after all, a more optimal partition can be somewhere between 4th and 5th thousand classes. <br><br>  The dependence of the quality of the model on the smoothing factor. <br><br>  Figure 5 shows the changes in the classification accuracy for the R8 body at different smoothing factors (for 1500 classes).  The frequency of changes for any number of classes within the same building is the same.  Similar graphics are observed for all enclosures. <br><br><img src="https://habrastorage.org/files/926/751/ec1/926751ec19af415da64f3654fa7d18a9.png"><br>  <i>Fig.5.</i>  <i>Changes in the classification accuracy for the body of the R8 at different values ‚Äã‚Äãof the smoothing coefficient.</i>  <i>The right shows the smoothing coefficient values.</i> <br><br>  To identify the main trends, we construct graphs of the average values ‚Äã‚Äãof the accuracy of the smoothing coefficient for all the cases for the English and Russian languages. <br><table><tbody><tr><td><img src="https://habrastorage.org/files/11f/fcc/ffc/11ffccffce40488c9f42c04467d3eddb.png"></td><td><img src="https://habrastorage.org/files/267/1b2/a84/2671b2a84c9f4c0e8f4cc44db40b2eed.png"></td></tr></tbody></table><br>  <i>Figure 6. The dependence of the change in classification accuracy (vertical) on the values ‚Äã‚Äãof smoothing coefficients (horizontally), averaged data by corpus: on the left - for English, on the right - for Russian.</i> <br><br>  From the graphs presented in Fig.  6 it follows that the smoothing coefficient is language dependent: if for English the stability occurs somewhere around the value of 0.22, then for the Russian it is about 0.12.  Apparently, this should be somehow related to the complexity of the language, its perplexia. <br><br>  It is difficult to say what explains the peak accuracy at the beginning (0.07) for the English language.  Its presence is caused by the behavior of the R8 case, and, possibly, due to the lexical content of the case itself. <br><br>  In fact, if we compare the data of the models themselves for different smoothing factors, it can be seen that at the above thresholds, some of the high-frequency words (prepositions, conjunctions, articles) are filtered.  Therefore, there is no point in introducing stop lists: this vocabulary either filters or forms a separate associative semantic class with a fairly low weight. <br><br>  The dependence of the smoothing coefficient variability on the number of classes has very little effect on the change in accuracy.  At the same time, it was not possible to identify any trends of such influence for different materials. <br><br><h3>  findings </h3><br>  Of course, this is not the only, and perhaps not the best, method of obtaining models, because it is empirical and depends on many factors.  In addition, smoothing can be done much more clever ways.  Nevertheless, this method allows you to quickly and accurately build models and get good clustering results on large amounts of information. <br><br>  Let us give an example of using clustering on Russian-language material. <br><br><h4>  Example </h4><br>  Social media message flow clustering with the search query "Sberbank".  The number of messages is 10 thousand.  This is approximately 10 MB of text or 5-6 hours of message flow on the topic of Sberbank. <br><br>  The result was 285 clusters, from which you can immediately see the main events concerning Sberbank. <br>  Here, for example, the first ten clusters (first message headers): <br><br><ol><li>  <i>Sberbank customers complained about failures in the online service</i> - this kind of 327 messages </li><li>  <i>Jews want to privatize Sberbank in the next 3 years</i> - 77 messages </li><li>  Sberbank answers, such as: <i>&lt;name&gt; hello, unfortunately, at the moment there really are interruptions in the work ...</i> - 74 messages </li><li>  <i>In 2017, Sberbank will conduct a test of quantum information transfer hi-tech</i> - 73 messages </li><li>  <i>in the year of its 175th anniversary Sberbank gives free admission to art museums</i> - 71 posts </li><li>  <i>learn about the benefits of a youth debit card visa Savings Bank and how to buy a sweatshirt for n ruble</i> - 57 messages </li><li>  <i>The Ministry of Economic Development proposed to include Sberbank in the privatization plan</i> - 58 messages </li><li>  <i>Sberbank reported failures in its systems</i> - 60 messages </li><li>  <i>Vladimir Putin took part in the conference ahead in the future the role and place of Russia</i> - 61 posts (Sberbank also took part); </li><li>  <i>Gref denied information on the privatization of Sberbank - 64 messages</i> </li></ol><br>  Most likely, the 1st and 8th clusters can be combined into macro clusters based on additional information, for example, using geo-tags, sources of messages, predicative relations between objects, etc. But this is another task, which we will describe next time . <br><br>  You can get acquainted with examples and demo implementation of the algorithm <a href="https://github.com/lionalion/clusterization">here</a> . </div><p>Source: <a href="https://habr.com/ru/post/324998/">https://habr.com/ru/post/324998/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../324988/index.html">Java implementation of a hashed binary tree</a></li>
<li><a href="../324990/index.html">Advantages of SDN: on the example of VMware vSphere integration with Huawei Cloud Fabric</a></li>
<li><a href="../324992/index.html">How to create an Internet of things from LEGO bricks based on AWS IoT platform</a></li>
<li><a href="../324994/index.html">Native Data Centers: Overview of Russian Data Centers (Part 1)</a></li>
<li><a href="../324996/index.html">Relevant connection - specific and universal attributes</a></li>
<li><a href="../325000/index.html">What you need to know to take cheaper tours: how it all works (and how to get a hotel in Sochi for 1116 rubles for 5 nights)</a></li>
<li><a href="../325006/index.html">15 VoIP Providers and 8 CRM: Compatibility Overview</a></li>
<li><a href="../325008/index.html">We try to do web-frontend on Rust (WebAssembly)</a></li>
<li><a href="../325010/index.html">Painless inoculation of object thinking</a></li>
<li><a href="../325012/index.html">Managing CST MWS with Matlab</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>