<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Kinetics of large clusters</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Summary 


1. Fatal error Martin Kleppman. 
2. Physico-chemical kinetics do math. 
3. Cluster half-life. 
4. We solve nonlinear differential equations...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Kinetics of large clusters</h1><div class="post__text post__text-html js-mediator-article"><h2>  Summary </h2><br><ol><li>  Fatal error Martin Kleppman. <br></li><li>  Physico-chemical kinetics do math. <br></li><li>  Cluster half-life. <br></li><li>  We solve nonlinear differential equations without solving them. <br></li><li>  Noda as a catalyst. <br></li><li>  Predictive power of graphs. <br></li><li>  100 million years. <br></li><li>  Synergy. <br></li></ol><br>  In the <a href="http://gridem.blogspot.com/2017/03/cap-theorem-myths.html">previous article</a> we discussed in detail the <a href="https://cloud.google.com/spanner/docs/whitepapers/SpannerAndCap.pdf">article of Brewer and his theorem of the same name</a> .  This time we are <a href="https://martin.kleppmann.com/2017/01/26/data-loss-in-large-clusters.html">going to</a> prepare the post of <a href="https://martin.kleppmann.com/2017/01/26/data-loss-in-large-clusters.html">Martin Kleppman, "The probability of data loss in large clusters"</a> . <br><br>  In this post, the author tries to model the following problem.  To ensure data integrity, data replication is usually used.  In this case, in fact, it does not matter whether erasure encoding is used or not.  In the original post, the author sets the probability of a single node falling out, and then asks: what is the probability of data falling out as the number of nodes increases? <br><br>  The answer is shown in this picture: <br><a name="habracut"></a><br><img src="https://habrastorage.org/files/b42/00c/fff/b4200cffffe34d6d9939d406f834a30f.png" alt="Data loss">
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Those.  with the growth of the number of nodes, the number of lost data grows in direct proportion. <br><br>  Why is it important?  If we consider the size of modern clusters, we will see that their number is continuously increasing over time.  This means that a reasonable question arises: is it worth worrying about the safety of your data and raising the replication factor?  After all, this directly affects the business, cost of ownership and so on.  Also using this example, it is possible to demonstrate perfectly how to produce a mathematically correct, but incorrect result. <br><br><h2>  Cluster modeling </h2><br>  To demonstrate the erroneous calculations it is useful to understand what a model and modeling are.  If the model poorly describes the actual behavior of the system, then whatever correct formulas are used, we can easily get the wrong result.  And all due to the fact that our model can not take into account some important parameters of the system, which can not be neglected.  The art is to understand what is important and what is not. <br><br>  To describe the life of the cluster, it is important to take into account the dynamics of changes and the interrelation of various processes.  This is precisely the weak link of the original article, since  there was taken a static picture without any features associated with replication. <br><br>  To describe the dynamics, I will use the methods of <a href="https://ru.wikipedia.org/wiki/%25D0%25A5%25D0%25B8%25D0%25BC%25D0%25B8%25D1%2587%25D0%25B5%25D1%2581%25D0%25BA%25D0%25B0%25D1%258F_%25D0%25BA%25D0%25B8%25D0%25BD%25D0%25B5%25D1%2582%25D0%25B8%25D0%25BA%25D0%25B0">chemical kinetics</a> , where I will use an ensemble of nodes instead of an ensemble of particles.  As far as I know, no one used this formalism to describe the behavior of clusters.  So I will improvise. <br><br>  We introduce the following notation: <br><ol><li><img src="https://habrastorage.org/getpro/habr/post_images/f03/330/077/f033300770c37ee13618d6e081a3c1d7.svg" alt="N">  : total number of nodes in the cluster <br></li><li><img src="https://habrastorage.org/getpro/habr/post_images/4fb/daf/570/4fbdaf5703c6923711d9baa20c7dc262.svg" alt="A">  : number of functioning nodes (available) <br></li><li><img src="https://habrastorage.org/getpro/habr/post_images/41d/852/f7c/41d852f7cf6decac573c92a72a29be2f.svg" alt="F">  : number of problem nodes (failed) <br></li></ol><br>  Then it is obvious that: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/2a8/742/26c/2a874226cee2a82465106f11269b323b.svg" alt="\ begin {aligned} N = A + F \\ \ end {aligned}"></div><br>  Among the problematic nodes, I will include any problems: the disk is screwed up, the processor, network, etc. broke.  The cause is not important to me, the fact of breakdown and unavailability of data is important.  In the future, of course, you can take into account the more subtle dynamics. <br><br>  Now we write the kinetic equations of the processes of breakdown and restoration of the nodes of the cluster: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/d28/789/e05/d28789e05b90aec305491aba8c477feb.svg" alt="\ begin {aligned} A &amp; amp; \ xrightarrow {k_f} F &amp; amp; (1) \\ F &amp; amp; \ xrightarrow {k_a} A &amp; amp; (2) \\ \ end {aligned}"></div><br>  These simple equations say the following.  The first equation describes the process of node failure.  It does not depend on any parameters and describes the isolated output of the node down.  Other nodes are not involved in this process.  On the left is used the original "composition" of participants in the process, and on the right - the products of the process.  Speed ‚Äã‚Äãconstants <img src="https://habrastorage.org/getpro/habr/post_images/6de/221/a4c/6de221a4cc494dee7de843c357a85e6b.svg" alt="k_f">  and <img src="https://habrastorage.org/getpro/habr/post_images/400/beb/2a7/400beb2a777273a4036d8ccfe7cf62ee.svg" alt="k_a">  set the speed characteristics of the processes for breaking and restoring the nodes, respectively. <br><br>  Find out the physical meaning of the rate constants.  To do this, we write the kinetic equations: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/54a/daa/9be/54adaa9bec4bcd2cbd6ef57d74f61188.svg" alt="\ begin {aligned} \ frac {dA} {dt} &amp; amp; = -k_f A + k_a F \\ \ frac {dF} {dt} &amp; amp; = k_f A - k_a F \\ \ end {aligned}"></div><br>  From these equations, the meaning of the constants is clear. <img src="https://habrastorage.org/getpro/habr/post_images/6de/221/a4c/6de221a4cc494dee7de843c357a85e6b.svg" alt="k_f">  and <img src="https://habrastorage.org/getpro/habr/post_images/400/beb/2a7/400beb2a777273a4036d8ccfe7cf62ee.svg" alt="k_a">  .  Assuming that there are no admins and the cluster does not heal itself (i.e. <img src="https://habrastorage.org/getpro/habr/post_images/df1/056/c19/df1056c1902d27711386e86e7b28b4e5.svg" alt="k_a = 0">  ), then we immediately get the equation: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/680/717/edd/680717eddfc4aeb3c7cec2d20f9a2177.svg" alt="\ begin {aligned} \ frac {dA} {dt} = -k_f A \\ \ end {aligned}"></div><br>  Or <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/69b/90d/733/69b90d7330e23fc7aa942ae05603784f.svg" alt="\ begin {aligned} A = N e ^ {- k_f t} \\ \ end {aligned}"></div><br>  Those.  magnitude <img src="https://habrastorage.org/getpro/habr/post_images/3c6/c33/7a2/3c6c337a2815000bf341cc9c042a25fa.svg" alt="1 / k_f">  Is the half-life of the cluster for parts, up to <img src="https://habrastorage.org/getpro/habr/post_images/83a/643/0e9/83a6430e9c1cb3e595f03835c9efaeee.svg" alt="e / 2">  .  Let be <img src="https://habrastorage.org/getpro/habr/post_images/dac/51c/caf/dac51ccaf825fbf17a4bb1ea64979eac.svg" alt="\ tau_f">  - the characteristic time of transition of a single node from the state <img src="https://habrastorage.org/getpro/habr/post_images/4fb/daf/570/4fbdaf5703c6923711d9baa20c7dc262.svg" alt="A">  in state <img src="https://habrastorage.org/getpro/habr/post_images/41d/852/f7c/41d852f7cf6decac573c92a72a29be2f.svg" alt="F">  , but <img src="https://habrastorage.org/getpro/habr/post_images/0e5/251/3c6/0e52513c6bdb78d8eea5bef18551473e.svg" alt="\ tau_a">  - the characteristic time of transition of a single node from the state <img src="https://habrastorage.org/getpro/habr/post_images/41d/852/f7c/41d852f7cf6decac573c92a72a29be2f.svg" alt="F">  in state <img src="https://habrastorage.org/getpro/habr/post_images/4fb/daf/570/4fbdaf5703c6923711d9baa20c7dc262.svg" alt="A">  .  Then <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/01f/6d4/69d/01f6d469dfc8b0fa20ab738f06bf2876.svg" alt="\ begin {aligned} \ tau_f &amp; amp; \ sim \ frac {1} {k_f} \\ \ tau_a &amp; amp; \ sim \ frac {1} {k_a} \\ \ frac {\ tau_a} {\ tau_f} &amp; amp; = \ frac {k_f} {k_a} \\ \ end {aligned}"></div><br>  Solve our kinetic equations.  I just want to make a reservation that I will cut corners wherever it is possible, in order to get the simplest possible analytical dependencies that I will use for possible predictions and tuning. <br><br>  Since  the maximum limit on the number of solutions of differential equations has been reached, then I will solve these equations <a href="http://www.chem.msu.su/rus/teaching/eremin/6.html">by the method of quasistationary states</a> : <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/ec4/18c/fec/ec418cfec1e105c8becbf2a9ebcb3da2.svg" alt="\ begin {aligned} \ frac {dA} {dt} = 0 \ Rightarrow F = A \ frac {k_f} {k_a} \\ \ end {aligned}"></div><br>  Given that <img src="https://habrastorage.org/getpro/habr/post_images/0d1/50b/c97/0d150bc97336b924ae25c1d057cb6a7d.svg" alt="F \ ll N">  (this is quite a reasonable assumption, otherwise you need to buy better hardware or more advanced admins), we get: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/4b0/d27/c06/4b0d27c06ef8b5496e162d4fb58b1e1f.svg" alt="\ begin {aligned} A &amp; amp; \ simeq N \\ F &amp; amp; = N \ frac {k_f} {k_a} \\ \ end {aligned}"></div><br>  If we assume that the recovery time <img src="https://habrastorage.org/getpro/habr/post_images/0e5/251/3c6/0e52513c6bdb78d8eea5bef18551473e.svg" alt="\ tau_a">  about 1 week and the time of death <img src="https://habrastorage.org/getpro/habr/post_images/dac/51c/caf/dac51ccaf825fbf17a4bb1ea64979eac.svg" alt="\ tau_f">  about 1 year, we find that the proportion of broken nodes <img src="https://habrastorage.org/getpro/habr/post_images/3c8/5a5/5f0/3c85a55f0bfa1cc19973e1028bc4f691.svg" alt="p_f">  : <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/6cd/83c/b40/6cd83cb409a43566aa6f5feea1707380.svg" alt="\ begin {aligned} p_f = \ frac {F} {N} = \ frac {\ tau_a} {\ tau_f} \ approx 2 \% \\ end {aligned}"></div><br><h2>  Chunky </h2><br>  Denote by <img src="https://habrastorage.org/getpro/habr/post_images/9c2/6a8/bf3/9c26a8bf36329cb001b536a2710b0f28.svg" alt="U">  - the number of underreplicated chunks that need to be replicated after the node drops out when going into the state <img src="https://habrastorage.org/getpro/habr/post_images/41d/852/f7c/41d852f7cf6decac573c92a72a29be2f.svg" alt="F">  .  Then to account for the chunks, we correct our equations: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/18a/b09/ed8/18ab09ed89e0268694545a5ce35f5389.svg" alt="\ begin {aligned} A &amp; amp; \ xrightarrow {k_f} F + U &amp; amp; (1) \\ F &amp; amp; \ xrightarrow {k_a} A &amp; amp; (2) \\ U + A &amp; amp; \ xrightarrow {k_r} H + A &amp; amp; (3) \\ \ end {aligned}"></div><br>  Where <img src="https://habrastorage.org/getpro/habr/post_images/7da/d14/4a9/7dad144a9524d019156d45b2af470fb0.svg" alt="k_r">  - the rate constant of replication of the process of the second order, and <img src="https://habrastorage.org/getpro/habr/post_images/153/d02/1ed/153d021ed18aaa01c5ada27a63c2788a.svg" alt="H">  means a healthy chunk, which will dissolve in the total mass of chunks. <br><br>  The 3rd equation needs to be clarified.  It describes the second order process, not the first: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/d4f/c21/5e4/d4fc215e4d4bf96f107d52940b71a145.svg" alt="\ begin {aligned} U &amp; amp; \ xrightarrow {k_r} H \\ \ end {aligned}"></div><br>  If we did that, we would get a Kleppman curve that is not in my plans.  In fact, all nodes are involved in the recovery process, and the more nodes, the faster the process goes.  This is due to the fact that chunks from a killed node are distributed approximately evenly throughout the cluster, therefore each participant must be replicated in <img src="https://habrastorage.org/getpro/habr/post_images/4fb/daf/570/4fbdaf5703c6923711d9baa20c7dc262.svg" alt="A">  less time.  This means that the final rate of recovery of chunks from a killed node will be proportional to the number of available nodes. <br><br>  It is also worth noting that in equation (3) on the left and on the right is <img src="https://habrastorage.org/getpro/habr/post_images/4fb/daf/570/4fbdaf5703c6923711d9baa20c7dc262.svg" alt="A">  , and while it is not consumed.  Chemists would immediately say that in this case <img src="https://habrastorage.org/getpro/habr/post_images/4fb/daf/570/4fbdaf5703c6923711d9baa20c7dc262.svg" alt="A">  acts as a catalyst.  And if you think carefully, then it really is. <br><br>  Using the method of quasistationary concentrations instantly we get the result: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/747/435/0f7/7474350f7fa0d368005b23a7294e46af.svg" alt="\ begin {aligned} \ frac {dU} {dt} = 0 = k_f A - k_r U A \\ \ end {aligned}"></div><br>  or <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/add/22f/5ef/add22f5ef935c895dea2b09623eef750.svg" alt="\ begin {aligned} U = \ frac {k_f} {k_r} \\ \ end {aligned}"></div><br>  Amazing result!  Those.  the number of chunks that need to be replicated does not depend on the number of nodes!  And this is due to the fact that increasing the number of nodes increases the resulting reaction rate (3), thereby compensating for a greater number <img src="https://habrastorage.org/getpro/habr/post_images/41d/852/f7c/41d852f7cf6decac573c92a72a29be2f.svg" alt="F">  nod.  Catalysis! <br><br>  We estimate this value. <img src="https://habrastorage.org/getpro/habr/post_images/2f6/87f/35a/2f687f35af601a1d2c1b792517901446.svg" alt="\ tau_r">  - recovery time chunks, as if we had only one node.  Let 5TB of data be replicated at the node, with the replication stream in bytes set as 50MB / s, then we get: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/311/225/3e3/3112253e30c6591160853f1e033bba33.svg" alt="\ begin {aligned} U = \ frac {\ tau_r} {\ tau_f} \ approx \ frac {1 \ times 10 ^ 5} {3.2 \ times 10 ^ 7} \ approx 3 \ times 10 ^ {- 3} \\ \ end {aligned}"></div><br>  Those. <img src="https://habrastorage.org/getpro/habr/post_images/03a/6f1/a0d/03a6f1a0d9dc2800f03c143eebb6f568.svg" alt="U \ ll 1">  and you can not be afraid for the safety of data.  Here it is worth considering that the loss of one chunk out of 3 does not lead to data loss. <br><br><h2>  Replication planning </h2><br>  In the previous calculation, we made an implicit assumption that the nodes instantly know which chunks need to be replicated, and immediately begin the process of their replication.  In reality, this is absolutely not true: the master needs to understand that the node has died, then understand what specific chunks need to be replicated and start the replication process on the nodes.  All this is not instantaneous and takes some time. <img src="https://habrastorage.org/getpro/habr/post_images/b3d/bb0/ec8/b3dbb0ec87b940715f6907b5fe076c86.svg" alt="\ tau_s">  (scheduling). <br><br>  To account for the delay, we use the <a href="http://www.chemport.ru/data/chemipedia/article_80.html">theory of a <em>transition state</em> or an <em>activated complex</em></a> , which describes the process of transition through a saddle point on a multidimensional surface of potential energy.  From our point of view, we will have some additional intermediate state <img src="https://habrastorage.org/getpro/habr/post_images/913/3a9/748/9133a9748573a885159ebf3245a53032.svg" alt="U ^ *">  which means that this chunk has been scheduled for replication, but the replication process has not yet begun.  Those.  the next nanosecond replication will begin exactly, but not picosecond earlier.  Then our system will take the final form: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/eeb/00b/587/eeb00b5874f1689a3666d5d29a5d196a.svg" alt="\ begin {aligned} A &amp; amp; \ xrightarrow {k_f} F + U &amp; amp; (1) \\ F &amp; amp; \ xrightarrow {k_a} A &amp; amp; (2) \\ U &amp; amp; \ xrightarrow {k_s} U ^ * &amp; amp; (3) \\ U ^ * + A &amp; amp; \ xrightarrow {k_r} H + A &amp; amp; (4) \\ \ end {aligned}"></div><br>  Solving it, we find that: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/bea/d11/67c/bead1167c02c706c1e7bca6ba1e643dd.svg" alt="\ begin {aligned} \ frac {dU} {dt} &amp; amp; = k_f A - k_s U \\ \ frac {dU ^ *} {dt} &amp; = k_s U - k_r U ^ * A \\ \ end {aligned }"></div><br>  Using the method of quasistationary concentrations, we find: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/ea4/ae3/4ed/ea4ae34ed01e7b6f5004ac8af7bfc503.svg" alt="\ begin {aligned} U &amp; amp; = A \ frac {k_f} {k_s} \\ U ^ * &amp; amp; = \ frac {k_f} {k_r} \\ U_ {sum} &amp; amp; = U + U ^ * = \ frac {\ tau_r} {\ tau_f} \ bigg (1 + \ frac {A} {\ widetilde {A}} \ bigg) \\ \ end {aligned}"></div><br>  Where: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/fec/509/89a/fec50989a558cd0ae3384e39c6d26854.svg" alt="\ begin {aligned} \ widetilde {A} = \ frac {\ tau_r} {\ tau_s} \\ \ end {aligned}"></div><br>  As you can see, the result is the same as the previous one, except for the multiplier. <img src="https://habrastorage.org/getpro/habr/post_images/a24/f47/2d0/a24f472d0683b6b94b9147f15a28d39d.svg" alt="(1 + A / \ widetilde {A})">  .  Consider 2 extreme cases: <br><ol><li><img src="https://habrastorage.org/getpro/habr/post_images/39c/4a7/034/39c4a70341b3f70c764d0df237b4edcd.svg" alt="A \ ll \ widetilde {A}">  .  In this case, all the arguments cited earlier are preserved: the number of chunks does not depend on the number of nodes, and therefore does not grow with the growth of the cluster. <br></li><li><img src="https://habrastorage.org/getpro/habr/post_images/13a/18e/0db/13a18e0db173f10df96714450ec5092e.svg" alt="A \ gg \ widetilde {A}">  .  In this case <img src="https://habrastorage.org/getpro/habr/post_images/1b0/285/35c/1b028535cce465f6d05f8231f8ba2314.svg" alt="U_ {sum} \ simeq A \ tau_s / \ tau_f">  and grows linearly with the number of nodes. <br></li></ol><br>  To determine the mode, we estimate what is <img src="https://habrastorage.org/getpro/habr/post_images/c8b/cf1/02e/c8bcf102e83e83dffd448f4fd480fbf5.svg" alt="\ widetilde {A}">  . <img src="https://habrastorage.org/getpro/habr/post_images/b3d/bb0/ec8/b3dbb0ec87b940715f6907b5fe076c86.svg" alt="\ tau_s">  - this is the characteristic total time of detecting an underreplicated chunk and planning its replication.  A rough estimate (using the ‚Äúfinger to the sky‚Äù method) gives a value of 100 s.  Then: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/8d3/6fb/9b3/8d36fb9b36ce4ea67c0d55d711f48ff1.svg" alt="\ begin {aligned} \ widetilde {A} = \ frac {1 \ times 10 ^ 5} {100} = 1000 \\ \ end {aligned}"></div><br>  Thus, a further increase in the cluster above this figure under these conditions will begin to increase the probability of losing chunk. <br><br>  What can be done to improve the situation?  It would seem that the asymptotics can be improved by shifting the border. <img src="https://habrastorage.org/getpro/habr/post_images/c8b/cf1/02e/c8bcf102e83e83dffd448f4fd480fbf5.svg" alt="\ widetilde {A}">  by increasing <img src="https://habrastorage.org/getpro/habr/post_images/2f6/87f/35a/2f687f35af601a1d2c1b792517901446.svg" alt="\ tau_r">  however this will only increase the value <img src="https://habrastorage.org/getpro/habr/post_images/729/79e/cc1/72979ecc140622740cfd5172d16a081f.svg" alt="U_ {sum}">  without any real improvement.  The surest way: this reduction <img src="https://habrastorage.org/getpro/habr/post_images/b3d/bb0/ec8/b3dbb0ec87b940715f6907b5fe076c86.svg" alt="\ tau_s">  i.e.  decision time for chunk replication, since <img src="https://habrastorage.org/getpro/habr/post_images/dac/51c/caf/dac51ccaf825fbf17a4bb1ea64979eac.svg" alt="\ tau_f">  depends on the characteristics of the hardware and this is hard to influence with software. <br><br><h2>  Discussion of marginal cases </h2><br>  The proposed model actually breaks the aggregate clusters into 2 camps. <br><br>  A relatively small cluster with the number of nodes &lt;1000 adjoins the first camp. In this case, the probability of obtaining an under-replicated chunk is described by a simple formula: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/734/f3d/c3f/734f3dc3ff16eea95783aac4508a97ed.svg" alt="\ begin {aligned} U = \ frac {\ tau_r} {\ tau_f} \\ \ end {aligned}"></div><br>  To improve the situation, you can use 2 approaches: <br><ol><li>  Improve iron, thereby increasing <img src="https://habrastorage.org/getpro/habr/post_images/dac/51c/caf/dac51ccaf825fbf17a4bb1ea64979eac.svg" alt="\ tau_f">  . <br></li><li>  Accelerate replication by reducing <img src="https://habrastorage.org/getpro/habr/post_images/2f6/87f/35a/2f687f35af601a1d2c1b792517901446.svg" alt="\ tau_r">  . <br></li></ol><br>  These methods are generally fairly obvious. <br><br>  In the second camp, we have already large and super-large servers with the number of nodes&gt; 1000. Here the dependence will be determined as follows: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/699/75b/c8e/69975bc8e28c4cbac1f024668856c617.svg" alt="\ begin {aligned} U = A \ frac {\ tau_s} {\ tau_f} \\ \ end {aligned}"></div><br>  Those.  will be directly proportional to the number of nodes, which means a subsequent increase in the cluster will adversely affect the likelihood of under-replicated chunks.  However, here you can significantly reduce the negative effects using the following approaches: <br><ol><li>  Continue to increase <img src="https://habrastorage.org/getpro/habr/post_images/dac/51c/caf/dac51ccaf825fbf17a4bb1ea64979eac.svg" alt="\ tau_f">  . <br></li><li>  Accelerate the detection of under-replicated chunks and subsequent replication planning, thereby reducing <img src="https://habrastorage.org/getpro/habr/post_images/b3d/bb0/ec8/b3dbb0ec87b940715f6907b5fe076c86.svg" alt="\ tau_s">  . <br></li></ol><br>  2nd reduction approach <img src="https://habrastorage.org/getpro/habr/post_images/b3d/bb0/ec8/b3dbb0ec87b940715f6907b5fe076c86.svg" alt="\ tau_s">  is no longer obvious.  It would seem, what's the difference, will take 20 seconds or 100 seconds?  However, this value significantly affects the probability of under-replicated chunks.  Also unclear is the fact that the dependence on <img src="https://habrastorage.org/getpro/habr/post_images/2f6/87f/35a/2f687f35af601a1d2c1b792517901446.svg" alt="\ tau_r">  i.e.  the replication speed itself does not matter.  It is understandable in this model: with an increase in the number of nodes, this speed only increases, therefore, the constant addition of the ‚Äúacceleration‚Äù of the replication process, aimed at detecting and scheduling replication, begins to significantly affect the chunk replication. <br><br>  Worth a little more detail on <img src="https://habrastorage.org/getpro/habr/post_images/dac/51c/caf/dac51ccaf825fbf17a4bb1ea64979eac.svg" alt="\ tau_f">  .  In addition to directly contributing to the livelihoods of chunks, <img src="https://habrastorage.org/getpro/habr/post_images/dac/51c/caf/dac51ccaf825fbf17a4bb1ea64979eac.svg" alt="\ tau_f">  It has a beneficial effect on the number of available nodes, since <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/920/eaa/6af/920eaa6afcb8e599852fcb18e90cc3ac.svg" alt="\ begin {aligned} A = N - F \ simeq N \ bigg (1 - \ frac {\ tau_a} {\ tau_f} \ bigg) \\ \ end {aligned}"></div><br>  Thereby increasing the number of available nodes.  Thus, the improvement <img src="https://habrastorage.org/getpro/habr/post_images/dac/51c/caf/dac51ccaf825fbf17a4bb1ea64979eac.svg" alt="\ tau_f">  directly affects the availability of available cluster resources, speeding up calculations and at the same time increasing the reliability of data storage.  On the other hand, improving the quality of iron directly affects the cost of ownership of the cluster.  The described model allows us to quantify the economic feasibility of such decisions. <br><br><h2>  Comparison of approaches </h2><br>  In conclusion, I would like to give a comparison of the two approaches.  About this eloquently say the following graphics. <br><br><img src="https://habrastorage.org/files/b42/00c/fff/b4200cffffe34d6d9939d406f834a30f.png" alt="Data loss"><br><br><img src="https://habrastorage.org/files/12d/b06/df9/12db06df9cc6415bb8fd15a6d6229015.png" alt="Kinetics"><br><br>  From the first graph, you can only see a linear relationship, but it will not give an answer to the question: ‚Äúand what needs to be done to improve the situation?‚Äù The second picture describes a more complex model that can immediately answer questions about what to do and how affect the behavior of the replication process.  Moreover, it gives a recipe for a quick way, literally in the mind, of evaluating the consequences of certain architectural decisions.  In other words, the predictive power of the developed model is at a qualitatively different level. <br><br><h2>  Loss of chunk </h2><br>  We now find the characteristic time of chunk loss.  To do this, write down the kinetics of the formation of such chunks, taking into account the degree of replication = 3: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/134/c72/7db/134c727db5b2530a2658d4391af16da2.svg" alt="\ begin {aligned} A &amp; amp; \ xrightarrow {k_f} F + U \\ F &amp; amp; \ xrightarrow {k_a} A \\ U &amp; amp; \ xrightarrow {k_s} U ^ * \\ U ^ * + A &amp; amp; \ xrightarrow {k_r} H + A \\ U &amp; amp; \ xrightarrow {k_f} F + U_2 \\ U ^ * &amp; amp; \ xrightarrow {k_f} F + U_2 \\ U_2 &amp; amp; \ xrightarrow {k_s} U_2 ^ * \\ U_2 ^ * + A &amp; amp; \ xrightarrow {k_r} U + A \\ U_2 &amp; amp; \ xrightarrow {k_f} F + L \\ U_2 ^ * &amp; amp; \ xrightarrow {k_f} F + L \\ \ end {aligned}"></div><br>  Here through <img src="https://habrastorage.org/getpro/habr/post_images/7e7/d44/ac7/7e7d44ac7743ea6bc9276f46c50dbe10.svg" alt="U_2">  indicated the number of under-replicated chunks that are missing two copies, <img src="https://habrastorage.org/getpro/habr/post_images/9f2/92d/d98/9f292dd9855549158323bd0f468e2107.svg" alt="U_2 ^ *">  - intermediate state, similarly <img src="https://habrastorage.org/getpro/habr/post_images/913/3a9/748/9133a9748573a885159ebf3245a53032.svg" alt="U ^ *">  corresponding to the state <img src="https://habrastorage.org/getpro/habr/post_images/7e7/d44/ac7/7e7d44ac7743ea6bc9276f46c50dbe10.svg" alt="U_2">  , but <img src="https://habrastorage.org/getpro/habr/post_images/824/ed8/7f2/824ed87f2e22c5c92ae1df8b4186c5b0.svg" alt="L">  means a lost chunk.  Then: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/57e/e75/499/57ee754994af9ab7daa502a70ea9053a.svg" alt="\ begin {aligned} \ frac {dL} {dt} &amp; amp; = k_f \ big (U_2 + U_2 ^ * \ big) \\ \ tau_l &amp; amp; = \ frac {1} {k_f \ big (U_2 + U_2 ^ * \ big)} \\ \ end {aligned}"></div><br>  Where <img src="https://habrastorage.org/getpro/habr/post_images/92f/99b/cc3/92f99bcc3d5a814de158f27b9a1390c8.svg" alt="\ tau_l">  - the characteristic time of formation of the lost chunk.  We will solve our system for 2 extreme cases for the case when <img src="https://habrastorage.org/getpro/habr/post_images/7ab/e59/094/7abe590948e71974314d956eca5fecb3.svg" alt="A = 1000">  . <br><br><img src="https://habrastorage.org/getpro/habr/post_images/39c/4a7/034/39c4a70341b3f70c764d0df237b4edcd.svg" alt="A \ ll \ widetilde {A}">  then <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/e9b/d71/0fd/e9bd710fd06bef2a8e8291791921d194.svg" alt="\ begin {aligned} \ tau_l = A \ frac {\ tau_f ^ 3} {\ tau_r ^ 2} \ approx 100 \ 000 \ 000 \ years \\ \ end {aligned}"></div><br>  For <img src="https://habrastorage.org/getpro/habr/post_images/13a/18e/0db/13a18e0db173f10df96714450ec5092e.svg" alt="A \ gg \ widetilde {A}">  we get: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/66e/770/187/66e7701874eb6db1e8760c00d34f53eb.svg" alt="\ begin {aligned} \ tau_l = \ frac {\ tau_f ^ 3} {A \ tau_s ^ 2} \ approx 100 \ 000 \ 000 \ years \\ \ end {aligned}"></div><br>  Those.  the characteristic time of formation of a lost chunk is 100 million years!  At the same time, approximately similar values ‚Äã‚Äãare obtained, since  we are in a transition zone.  Characteristic time <img src="https://habrastorage.org/getpro/habr/post_images/92f/99b/cc3/92f99bcc3d5a814de158f27b9a1390c8.svg" alt="\ tau_l">  speaks for itself and everyone can draw conclusions himself. <br><br>  It is, however, worth paying attention to one feature.  In the limiting case <img src="https://habrastorage.org/getpro/habr/post_images/39c/4a7/034/39c4a70341b3f70c764d0df237b4edcd.svg" alt="A \ ll \ widetilde {A}">  while <img src="https://habrastorage.org/getpro/habr/post_images/9c2/6a8/bf3/9c26a8bf36329cb001b536a2710b0f28.svg" alt="U">  is constant and does not depend on <img src="https://habrastorage.org/getpro/habr/post_images/4fb/daf/570/4fbdaf5703c6923711d9baa20c7dc262.svg" alt="A">  in terms of <img src="https://habrastorage.org/getpro/habr/post_images/92f/99b/cc3/92f99bcc3d5a814de158f27b9a1390c8.svg" alt="\ tau_l">  we get the inverse relationship, i.e.  With cluster growth, triple replication even improves data integrity!  With further cluster growth, the situation changes exactly to the opposite. <br><br><h2>  findings </h2><br>  The article consistently introduces an innovative way of modeling the kinetics of large cluster processes.  The considered approximate model of cluster dynamics description allows calculating probabilistic characteristics describing data loss. <br><br>  Of course, this model is only the first approximation to what is really happening on the cluster.  Here we only took into account the most significant processes for obtaining a qualitative result.  But even such a model makes it possible to judge what is happening inside the cluster, and also gives recommendations for improving the situation. <br><br>  Nevertheless, the proposed approach allows for more accurate and reliable results based on the subtle consideration of various factors and the analysis of real data on the work of the cluster.  The following is far from an exhaustive list for improving the model: <br><ol><li>  Cluster nodes can fail due to various hardware failures.  The failure of a particular node usually has a different probability.  Moreover, a failure, for example, of a processor, does not lose data, but only gives temporary unavailability of the node.  It is easy to take into account in the model, introducing various states. <img src="https://habrastorage.org/getpro/habr/post_images/8f0/74a/181/8f074a18154437d62d2fc460dac51d84.svg" alt="F_ {proc}">  , <img src="https://habrastorage.org/getpro/habr/post_images/53f/c93/154/53fc93154ad6776644b2ee8f787d70d2.svg" alt="F_ {disk}">  , <img src="https://habrastorage.org/getpro/habr/post_images/b0a/30a/4d2/b0a30a4d29f80de1e3d97971567a829b.svg" alt="F_ {mem}">  etc.  with different speeds of processes and various consequences. <br></li><li>  Not all nodes are equally useful.  Different batches may differ in character and frequency of failures.  This can be taken into account in the model by entering <img src="https://habrastorage.org/getpro/habr/post_images/386/584/1d2/3865841d2acac0779c0949fe123c197a.svg" alt="A_1">  , <img src="https://habrastorage.org/getpro/habr/post_images/a7d/8d1/dd2/a7d8d1dd2a9bc8920b8fdc3b1966550d.svg" alt="A_2">  etc.  with different speeds of the respective processes. <br></li><li>  Adding various types of nodes to the model: with partially damaged disks, banned, etc. For example, you can analyze in detail the effect of turning off an entire rack and determining the characteristic speeds of a cluster transition to a stationary mode.  In this case, numerically solving the differential equations of processes, we can visually consider the dynamics of chunks and nodes. <br></li><li>  Each disk has slightly different read / write characteristics, including latency and throughput.  Nevertheless, it is possible to more accurately estimate the rate constants of the processes, integrating over the corresponding distribution functions of the characteristics of the disks, by analogy with the rate constants in gases, integrated over the <a href="https://ru.wikipedia.org/wiki/%25D0%25A0%25D0%25B0%25D1%2581%25D0%25BF%25D1%2580%25D0%25B5%25D0%25B4%25D0%25B5%25D0%25BB%25D0%25B5%25D0%25BD%25D0%25B8%25D0%25B5_%25D0%259C%25D0%25B0%25D0%25BA%25D1%2581%25D0%25B2%25D0%25B5%25D0%25BB%25D0%25BB%25D0%25B0">Maxwell distribution of speeds</a> . <br></li></ol><br>  Thus, the kinetic approach allows, on the one hand, to obtain a simple description and analytical dependencies, on the other hand, it has a very serious potential for introducing additional subtle factors and processes based on the analysis of cluster data, adding specific points as needed.  It is possible to evaluate the impact of the contribution of each factor on the resulting equations, allowing you to simulate the improvements with a view to their expediency.  In the simplest case, such a model allows you to quickly obtain analytical dependencies, giving recipes for improving the situation.  In this case, the simulation can be bidirectional: you can iteratively improve the model by adding processes to the system of kinetic equations;  so try to analyze potential system improvements by introducing relevant processes into the model.  Those.  to carry out modeling of improvements to the direct costly implementation of them in the code. <br><br>  In addition, one can always proceed to the numerical integration of a system of rigid nonlinear differential equations, obtaining the dynamics and response of the system to specific actions or small perturbations. <br><br>  Thus, the synergy of seemingly unrelated areas of knowledge allows you to get amazing results that have undeniable predictive power. <br><br>  <em>Grigory Demchenko, developer of <a href="https://habrahabr.ru/company/yandex/blog/311104/">YT</a></em> <br><br><hr><br><div class="spoiler">  <b class="spoiler_title">Literature</b> <div class="spoiler_text">  [1] <a href="http://gridem.blogspot.com/2017/03/cap-theorem-myths.html">Cap Theorem Myths</a> <br>  [2] <a href="https://cloud.google.com/spanner/docs/whitepapers/SpannerAndCap.pdf">Spanner, TrueTime and the CAP Theorem</a> <br>  [3] <a href="https://martin.kleppmann.com/2017/01/26/data-loss-in-large-clusters.html">The number of data loss in large clusters</a> <br>  [4] <a href="https://ru.wikipedia.org/wiki/%25D0%25A5%25D0%25B8%25D0%25BC%25D0%25B8%25D1%2587%25D0%25B5%25D1%2581%25D0%25BA%25D0%25B0%25D1%258F_%25D0%25BA%25D0%25B8%25D0%25BD%25D0%25B5%25D1%2582%25D0%25B8%25D0%25BA%25D0%25B0">Chemical Kinetics</a> <br>  [5] The <a href="http://www.chemport.ru/data/chemipedia/article_80.html">activated complex theory</a> <br>  [6] <a href="http://www.chem.msu.su/rus/teaching/eremin/6.html">Approximate methods of chemical kinetics</a> <br>  [7] <a href="https://ru.wikipedia.org/wiki/%25D0%25A0%25D0%25B0%25D1%2581%25D0%25BF%25D1%2580%25D0%25B5%25D0%25B4%25D0%25B5%25D0%25BB%25D0%25B5%25D0%25BD%25D0%25B8%25D0%25B5_%25D0%259C%25D0%25B0%25D0%25BA%25D1%2581%25D0%25B2%25D0%25B5%25D0%25BB%25D0%25BB%25D0%25B0">Maxwell distribution</a> <br>  [8] <a href="https://habrahabr.ru/company/yandex/blog/311104/">YT: Why does Yandex need its own MapReduce-system and how it works?</a> <br></div></div></div><p>Source: <a href="https://habr.com/ru/post/325798/">https://habr.com/ru/post/325798/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../325786/index.html">Why we created a replacement for the old document search systems</a></li>
<li><a href="../325788/index.html">PWA, ‚ÄúOminous Valley‚Äù and stable work offline</a></li>
<li><a href="../325790/index.html">Look at yourself through Zuckerberg‚Äôs eyes and help his rivals.</a></li>
<li><a href="../325792/index.html">SystemD sucks, long live SystemD</a></li>
<li><a href="../325796/index.html">How to reduce the time to launch applications for iOS</a></li>
<li><a href="../325802/index.html">Working in the cloud on Hyper-V, part 4: creating backup copies of a virtual machine</a></li>
<li><a href="../325804/index.html">Who are you in a startup: hipster, hustler, hacker or analyst</a></li>
<li><a href="../325806/index.html">Y Combinator 2017 Startup School: ‚ÄúWhy?‚Äù (Part One)</a></li>
<li><a href="../325808/index.html">Image filtering by mathematical morphology on FPGA</a></li>
<li><a href="../325810/index.html">Convenient localization of iOS applications in Interface Builder</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>