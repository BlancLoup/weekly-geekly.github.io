<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Low-latency InfiniBand network performance on the HPC HUB virtual cluster</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Modeling of complex physical processes today is considered as an important technological opportunity by many modern companies. A widely used approach ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Low-latency InfiniBand network performance on the HPC HUB virtual cluster</h1><div class="post__text post__text-html js-mediator-article"><div style="text-align:center;"><img src="https://habrastorage.org/files/87f/444/853/87f44485380b4b25935f0dc527387f75.png" alt="areas"></div><br>  Modeling of complex physical processes today is considered as an important technological opportunity by many modern companies.  A widely used approach to create calculators capable of calculating complex models is to create cluster systems, where the computing node is a general-purpose server connected to a low latency network and managed by its own OS (usually from the GNU / Linux family). <br><br>  Introducing the virtualization layer into the system software of the computational clusters allows creating a ‚Äúvirtual cluster‚Äù within a few minutes.  Such virtual clusters within the same OpenStack infrastructure are completely independent.  The user programs inside them can be changed as needed by the user without any coordination with someone, and the logical devices on which user data resides are not available to other virtual clusters. <br><br>  Low latency network support with virtualization solutions is a separate complex problem.  For application programs, in most cases, modern KVM-based virtualization leads to minimal loss of computing power (&lt;1%).  However, specialized tests of low latency networks show no virtualization overhead of more than 20% on synchronization operations. <br><a name="habracut"></a><br><h2>  <font color="#808080">The value of low latency networks for HPC</font> </h2><br>  Modern tasks of modeling physical processes require large amounts of memory and computational power in order for the calculations to be performed in practice in realistic time.  Such large amounts of RAM and such large numbers of computational cores are difficult and expensive to combine in one system running one classic OS using modern technologies. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      A much cheaper and now widely used alternative approach is the creation of cluster systems, where the computing node is a general-purpose computer controlled by its own OS.  At the same time, the cluster computing nodes are synchronized and jointly managed by special software that provides the launch, maintenance and shutdown of the so-called "parallel applications".  The latter are independent processes in the OS of nodes synchronized with each other due to interaction in the network.  Further we will call such networks ‚Äúcomputational networks‚Äù, computational nodes ‚Äî ‚Äúcluster nodes‚Äù or simply ‚Äúnodes‚Äù, the control software ‚Äî ‚Äúcluster software‚Äù. <br><br>  Modern programming concepts use two basic methods of parallelization: by data and by processes.  To simulate natural phenomena, data paralleling is most often used, namely: <br><br><ul><li>  at the beginning of the calculation step, parts of the data are distributed to different solvers and they perform some actions on these parts </li><li>  then the calculators exchange information according to various numerical schemes (usually quite rigidly programmed) in order to have the initial data for the next step </li></ul><br>  From the point of view of programming practice, a calculator can be anything that has at least one processor, a certain amount of memory and access to a computer network for exchanges with other calculators.  In essence, a computer is a subscriber of a computer network with some (albeit relatively small) computing power.  The calculator can be either a thread within a process, or a process within an OS, or a virtual machine with one or more virtual processors, or a hardware node with some kind of reduced specialized OS, etc. <br><br>  The most widespread API standard for creating modern parallel applications is MPI, which exists in several implementations.  The Intel OpenMP API standard, which is designed to create parallel applications within a single OS on a multiprocessor node, is also widely used.  Since modern cluster nodes contain multi-core processors with a large amount of memory, a large number of options for determining the "calculator" within the framework of the parallelization paradigm of data and the implementation of this paradigm based on the approach of parallel applications are possible.  The most common are two approaches: <br><br><ol><li>  one processor core - one calculator </li><li>  one multiprocessor node - one calculator </li></ol><br>  To implement the first approach, it is sufficient to use MPI, for which it was actually created.  In the second approach, a bunch of MPI + OpenMP is often used, where MPI is used for communication between nodes, and OpenMP for parallelization within a node. <br><br>  Naturally, in a situation where parallel applications run on several nodes, the total performance depends not only on processors and memory, but also on network performance.  It is also clear that network exchanges will be slower than exchanges within multiprocessor systems.  Those.  Cluster systems are almost always slower compared to equivalent multiprocessor systems (SMP).  In order to minimize the degradation of the exchange rates in comparison with SMP machines, special low-latency computer networks are used. <br><br><h2>  <font color="#808080">Key characteristics of computer networks</font> </h2><br>  The key characteristics of specialized computer networks are the latency and width of the channel (the exchange rate for large amounts of data).  The transfer rate of large amounts of data is important for various tasks, for example, when nodes need to send each other the results obtained at the current calculation step in order to collect initial data for the next step.  Latency plays a key role in the transmission of small messages, such as the synchronization messages necessary for the nodes to be aware of the status of other nodes whose data they need.  Synchronization messages are usually very small (typical size is several tens of bytes), but they are used to prevent logical races and deadlocks (race condition, deadlock).  The high speed of synchronization messages actually distinguishes a computational cluster from its closest relative - a computational farm, where the network between nodes does not provide the properties of low latency. <br><br>  Intel Infiniband is one of the most popular low latency network standards today.  It is the equipment of this type that is often used as a computer network for modern cluster systems.  There are several generations of Infiniband networks.  The most common standard now is Infiniband FDR (2011).  Still remains the standard QDR (2008).  Equipment suppliers are now actively promoting the next standard Infiniband EDR (2014).  Infiniband ports typically consist of aggregated groups of basic bi-directional buses.  The most common ports are 4x. <br><br>  <b>Latest Generation Infiniband Network Features</b> <br><table border="1"><tbody><tr><td></td><td>  QDRx4 </td><td>  FDRx4 </td><td>  EDRx4 </td></tr><tr><td>  Full bandwidth, Gbit / s </td><td>  32 </td><td>  56 </td><td>  100 </td></tr><tr><td>  Latency port-port, ms </td><td>  1.3 </td><td>  0.7 </td><td>  0.7 </td></tr></tbody></table><br>  As you know, virtualization introduces some of its specific delays when guest systems work with devices.  Not an exception in this case, and the network of low latency.  But because low latency (latency) is their most important feature, interfacing with virtualization environments is crucial for such networks.  However, their bandwidth, as a rule, remains the same as without virtualization in a wide range of connection parameters.  An important step in the development of Infiniband, made relatively recently (2011), is the use of SR-IOV technology.  This technology allows the physical network adapter Infiniband to turn into a set of virtual devices - virtual functions VF.  Such devices look like independent Infiniband adapters and, for example, can be handed over to exclusive control of various virtual machines or some high-load services.  Naturally, IB VF adapters work on other algorithms, and their characteristics differ from the original IB adapters without SR-IOV support included. <br><br><h2>  <font color="#808080">Group operations exchanges between nodes</font> </h2><br>  As already mentioned above, the MPI library is currently the most popular HPC tool.  There are several basic options for implementing the MPI API: <br><ul><li>  <a href="https://www.mpich.org/">MPICH</a> </li><li>  <a href="http://mvapich.cse.ohio-state.edu/">MVAPICH</a> </li><li>  <a href="https://www.open-mpi.org/">Openmpi</a> </li><li>  <a href="https://software.intel.com/en-us/intel-mpi-library/documentation/">Intel MPI</a> </li></ul><br>  The MPI libraries contain the basic functions necessary to implement parallel computing.  Critical to HPC applications are interprocess messaging functions, especially group synchronization and messaging functions.  It is worth noting that most often the group refers to all processes of a parallel application.  Detailed MPI API descriptions are easy to find on the web: <br><br><ul><li>  <a href="https://computing.llnl.gov/tutorials/mpi/">https://computing.llnl.gov/tutorials/mpi/</a> </li><li>  <a href="https://parallel.ru/docs/mpi2/mpi2-report.html">https://parallel.ru/docs/mpi2/mpi2-report.html</a> . </li></ul><br>  The basics of the algorithms used to implement MPI are well described in [1], and many articles on this topic can be found <a href="https://www.open-mpi.org/papers/">here</a> .  Evaluations of the effectiveness of these algorithms are the subject of a large number of papers [2, 3, 4, 5].  Most often, the estimates are constructed using the methods of asymptotic analysis of the theory of algorithms and operate with concepts <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-1-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>t</mi><mi>s</mi></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.843ex" height="2.298ex" viewBox="0 -728.2 793.5 989.6" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/hpchub/blog/319940/&amp;xid=17259,15700023,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjptIL1lQrY5rQMmfKikB6iBRLauQ#MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/hpchub/blog/319940/&amp;xid=17259,15700023,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjptIL1lQrY5rQMmfKikB6iBRLauQ#MJMATHI-73" x="511" y="-213"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>t</mi><mi>s</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-1"> t_s </script>  connection establishment time <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-2-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>t</mi><mi>w</mi></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.249ex" height="2.298ex" viewBox="0 -728.2 968.1 989.6" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/hpchub/blog/319940/&amp;xid=17259,15700023,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjptIL1lQrY5rQMmfKikB6iBRLauQ#MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/hpchub/blog/319940/&amp;xid=17259,15700023,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjptIL1lQrY5rQMmfKikB6iBRLauQ#MJMATHI-77" x="511" y="-213"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>t</mi><mi>w</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-2"> t_w </script>  information unit transfer rate <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-3-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>m</mi></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.04ex" height="1.455ex" viewBox="0 -520.7 878.5 626.5" role="img" focusable="false" style="vertical-align: -0.246ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/hpchub/blog/319940/&amp;xid=17259,15700023,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjptIL1lQrY5rQMmfKikB6iBRLauQ#MJMATHI-6D" x="0" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>m</mi></math></span></span><script type="math/tex" id="MathJax-Element-3"> m </script>  the number of units of information transmitted, <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-4-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>p</mi></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.259ex" height="1.817ex" viewBox="-38.5 -520.7 542 782.1" role="img" focusable="false" style="vertical-align: -0.607ex; margin-left: -0.089ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/hpchub/blog/319940/&amp;xid=17259,15700023,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjptIL1lQrY5rQMmfKikB6iBRLauQ#MJMATHI-70" x="0" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>p</mi></math></span></span><script type="math/tex" id="MathJax-Element-4"> p </script>  the number of processors involved. <br><br>  Naturally, for modern multiprocessor systems connected by a network of low latency, the parameters <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-5-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>t</mi><mi>s</mi></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.843ex" height="2.298ex" viewBox="0 -728.2 793.5 989.6" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/hpchub/blog/319940/&amp;xid=17259,15700023,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjptIL1lQrY5rQMmfKikB6iBRLauQ#MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/hpchub/blog/319940/&amp;xid=17259,15700023,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjptIL1lQrY5rQMmfKikB6iBRLauQ#MJMATHI-73" x="511" y="-213"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>t</mi><mi>s</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-5"> t_s </script>  and <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-6-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>t</mi><mi>w</mi></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.249ex" height="2.298ex" viewBox="0 -728.2 968.1 989.6" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/hpchub/blog/319940/&amp;xid=17259,15700023,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjptIL1lQrY5rQMmfKikB6iBRLauQ#MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/hpchub/blog/319940/&amp;xid=17259,15700023,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjptIL1lQrY5rQMmfKikB6iBRLauQ#MJMATHI-77" x="511" y="-213"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>t</mi><mi>w</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-6"> t_w </script>  it is necessary to take different for processors that interact within the same node and are located on different nodes, on the same multi-core chip and on different ones.  However, a good initial estimated approximation for <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-7-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>t</mi><mi>s</mi></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.843ex" height="2.298ex" viewBox="0 -728.2 793.5 989.6" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/hpchub/blog/319940/&amp;xid=17259,15700023,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjptIL1lQrY5rQMmfKikB6iBRLauQ#MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/hpchub/blog/319940/&amp;xid=17259,15700023,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjptIL1lQrY5rQMmfKikB6iBRLauQ#MJMATHI-73" x="511" y="-213"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>t</mi><mi>s</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-7"> t_s </script>  and <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-8-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>t</mi><mi>w</mi></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.249ex" height="2.298ex" viewBox="0 -728.2 968.1 989.6" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/hpchub/blog/319940/&amp;xid=17259,15700023,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjptIL1lQrY5rQMmfKikB6iBRLauQ#MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/hpchub/blog/319940/&amp;xid=17259,15700023,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjptIL1lQrY5rQMmfKikB6iBRLauQ#MJMATHI-77" x="511" y="-213"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>t</mi><mi>w</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-8"> t_w </script>  in the case of tasks using several nodes of a computing cluster, are the values ‚Äã‚Äãof latency and throughput of the computer network. <br><br>  As it is easy to understand, group synchronization operations are the most demanding of the ‚Äúlow latency‚Äù property of the network and the scalability of this property.  For our tests, we, like other authors [6], used the following 3 operations: <br><br>  <b>broadcast</b> <br>  The simplest of group operations is broadcast (broadcast).  One process sends the same message to all the others (M denotes a buffer with data. Taken from [1]). <br><img src="https://habrastorage.org/files/26b/282/ea1/26b282ea1e66437d90a519586670138c.png" alt="broadcast"><br><br>  In computing programs, broadcast is often used to distribute some conditions, parameters at the beginning of an account and between iterations.  Broadcast is often an element of the implementation of other, more complex collective operations.  For example, broadcast is used in some implementations of the barrier function.  There are several variants of algorithms for broadcast implementation.  The optimal running time for a broadcast on a non-blocking switch full-duplex channels without hardware acceleration is: <br><p><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-9-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mi>t</mi><mo>=</mo><mo stretchy=&quot;false&quot;>(</mo><msub><mi>t</mi><mi>s</mi></msub><mo>+</mo><msub><mi>t</mi><mi>w</mi></msub><mi>m</mi><mo stretchy=&quot;false&quot;>)</mo><mi>l</mi><mi>o</mi><msub><mi>g</mi><mn>2</mn></msub><mi>p</mi></math>" role="presentation" style="font-size: 100%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="19.873ex" height="2.66ex" viewBox="0 -832 8556.5 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/hpchub/blog/319940/&amp;xid=17259,15700023,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjptIL1lQrY5rQMmfKikB6iBRLauQ#MJMATHI-74" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/hpchub/blog/319940/&amp;xid=17259,15700023,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjptIL1lQrY5rQMmfKikB6iBRLauQ#MJMAIN-3D" x="639" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/hpchub/blog/319940/&amp;xid=17259,15700023,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjptIL1lQrY5rQMmfKikB6iBRLauQ#MJMAIN-28" x="1695" y="0"></use><g transform="translate(2085,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/hpchub/blog/319940/&amp;xid=17259,15700023,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjptIL1lQrY5rQMmfKikB6iBRLauQ#MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/hpchub/blog/319940/&amp;xid=17259,15700023,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjptIL1lQrY5rQMmfKikB6iBRLauQ#MJMATHI-73" x="511" y="-213"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/hpchub/blog/319940/&amp;xid=17259,15700023,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjptIL1lQrY5rQMmfKikB6iBRLauQ#MJMAIN-2B" x="3100" y="0"></use><g transform="translate(4101,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/hpchub/blog/319940/&amp;xid=17259,15700023,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjptIL1lQrY5rQMmfKikB6iBRLauQ#MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/hpchub/blog/319940/&amp;xid=17259,15700023,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjptIL1lQrY5rQMmfKikB6iBRLauQ#MJMATHI-77" x="511" y="-213"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/hpchub/blog/319940/&amp;xid=17259,15700023,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjptIL1lQrY5rQMmfKikB6iBRLauQ#MJMATHI-6D" x="5069" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/hpchub/blog/319940/&amp;xid=17259,15700023,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjptIL1lQrY5rQMmfKikB6iBRLauQ#MJMAIN-29" x="5948" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/hpchub/blog/319940/&amp;xid=17259,15700023,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjptIL1lQrY5rQMmfKikB6iBRLauQ#MJMATHI-6C" x="6337" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/hpchub/blog/319940/&amp;xid=17259,15700023,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjptIL1lQrY5rQMmfKikB6iBRLauQ#MJMATHI-6F" x="6636" y="0"></use><g transform="translate(7121,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/hpchub/blog/319940/&amp;xid=17259,15700023,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjptIL1lQrY5rQMmfKikB6iBRLauQ#MJMATHI-67" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/hpchub/blog/319940/&amp;xid=17259,15700023,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjptIL1lQrY5rQMmfKikB6iBRLauQ#MJMAIN-32" x="675" y="-213"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/hpchub/blog/319940/&amp;xid=17259,15700023,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjptIL1lQrY5rQMmfKikB6iBRLauQ#MJMATHI-70" x="8053" y="0"></use></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mi>t</mi><mo>=</mo><mo stretchy="false">(</mo><msub><mi>t</mi><mi>s</mi></msub><mo>+</mo><msub><mi>t</mi><mi>w</mi></msub><mi>m</mi><mo stretchy="false">)</mo><mi>l</mi><mi>o</mi><msub><mi>g</mi><mn>2</mn></msub><mi>p</mi></math></span></span></div><script type="math/tex;mode=display" id="MathJax-Element-9"> t = (t_s + t_w m) log_2p </script></p><br>  <b>all-reduce</b> <br>  The all-reduce operation performs the associative operation specified in the parameters on the data in the memory of the group of calculators, and then reports the result to all the calculators of the group.  (Sign <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-10-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mtext>&amp;#xA0;</mtext><mi>o</mi><mi>p</mi><mi>l</mi><mi>u</mi><mi>s</mi></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="5.991ex" height="2.419ex" viewBox="0 -780.1 2579.5 1041.5" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/hpchub/blog/319940/&amp;xid=17259,15700023,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjptIL1lQrY5rQMmfKikB6iBRLauQ#MJMATHI-6F" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/hpchub/blog/319940/&amp;xid=17259,15700023,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjptIL1lQrY5rQMmfKikB6iBRLauQ#MJMATHI-70" x="735" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/hpchub/blog/319940/&amp;xid=17259,15700023,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjptIL1lQrY5rQMmfKikB6iBRLauQ#MJMATHI-6C" x="1239" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/hpchub/blog/319940/&amp;xid=17259,15700023,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjptIL1lQrY5rQMmfKikB6iBRLauQ#MJMATHI-75" x="1537" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/hpchub/blog/319940/&amp;xid=17259,15700023,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjptIL1lQrY5rQMmfKikB6iBRLauQ#MJMATHI-73" x="2110" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtext>&nbsp;</mtext><mi>o</mi><mi>p</mi><mi>l</mi><mi>u</mi><mi>s</mi></math></span></span><script type="math/tex" id="MathJax-Element-10"> \ oplus </script>  means the specified associative operation.  Taken from [1]). <br><img src="https://habrastorage.org/files/7d7/061/ded/7d7061ded94b4d54a7d5d792a6864ed8.png" alt="all-reduce"><br><br>  From the point of view of the structure of network exchanges, all-reduce is similar to the all-to-all broadcast function.  This operation is used to sum or multiply, search for a maximum or a minimum among the operands located on different calculators.  Sometimes this function is used as a barrier.  The optimal time for an all-reduce operation on a non-blocking switch with full duplex channels without hardware acceleration is: <br><p><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-11-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mi>t</mi><mo>=</mo><mo stretchy=&quot;false&quot;>(</mo><msub><mi>t</mi><mi>s</mi></msub><mo>+</mo><msub><mi>t</mi><mi>w</mi></msub><mi>m</mi><mo stretchy=&quot;false&quot;>)</mo><mi>l</mi><mi>o</mi><msub><mi>g</mi><mn>2</mn></msub><mi>p</mi></math>" role="presentation" style="font-size: 100%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="19.873ex" height="2.66ex" viewBox="0 -832 8556.5 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/hpchub/blog/319940/&amp;xid=17259,15700023,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjptIL1lQrY5rQMmfKikB6iBRLauQ#MJMATHI-74" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/hpchub/blog/319940/&amp;xid=17259,15700023,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjptIL1lQrY5rQMmfKikB6iBRLauQ#MJMAIN-3D" x="639" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/hpchub/blog/319940/&amp;xid=17259,15700023,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjptIL1lQrY5rQMmfKikB6iBRLauQ#MJMAIN-28" x="1695" y="0"></use><g transform="translate(2085,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/hpchub/blog/319940/&amp;xid=17259,15700023,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjptIL1lQrY5rQMmfKikB6iBRLauQ#MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/hpchub/blog/319940/&amp;xid=17259,15700023,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjptIL1lQrY5rQMmfKikB6iBRLauQ#MJMATHI-73" x="511" y="-213"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/hpchub/blog/319940/&amp;xid=17259,15700023,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjptIL1lQrY5rQMmfKikB6iBRLauQ#MJMAIN-2B" x="3100" y="0"></use><g transform="translate(4101,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/hpchub/blog/319940/&amp;xid=17259,15700023,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjptIL1lQrY5rQMmfKikB6iBRLauQ#MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/hpchub/blog/319940/&amp;xid=17259,15700023,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjptIL1lQrY5rQMmfKikB6iBRLauQ#MJMATHI-77" x="511" y="-213"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/hpchub/blog/319940/&amp;xid=17259,15700023,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjptIL1lQrY5rQMmfKikB6iBRLauQ#MJMATHI-6D" x="5069" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/hpchub/blog/319940/&amp;xid=17259,15700023,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjptIL1lQrY5rQMmfKikB6iBRLauQ#MJMAIN-29" x="5948" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/hpchub/blog/319940/&amp;xid=17259,15700023,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjptIL1lQrY5rQMmfKikB6iBRLauQ#MJMATHI-6C" x="6337" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/hpchub/blog/319940/&amp;xid=17259,15700023,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjptIL1lQrY5rQMmfKikB6iBRLauQ#MJMATHI-6F" x="6636" y="0"></use><g transform="translate(7121,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/hpchub/blog/319940/&amp;xid=17259,15700023,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjptIL1lQrY5rQMmfKikB6iBRLauQ#MJMATHI-67" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/hpchub/blog/319940/&amp;xid=17259,15700023,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjptIL1lQrY5rQMmfKikB6iBRLauQ#MJMAIN-32" x="675" y="-213"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/hpchub/blog/319940/&amp;xid=17259,15700023,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjptIL1lQrY5rQMmfKikB6iBRLauQ#MJMATHI-70" x="8053" y="0"></use></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mi>t</mi><mo>=</mo><mo stretchy="false">(</mo><msub><mi>t</mi><mi>s</mi></msub><mo>+</mo><msub><mi>t</mi><mi>w</mi></msub><mi>m</mi><mo stretchy="false">)</mo><mi>l</mi><mi>o</mi><msub><mi>g</mi><mn>2</mn></msub><mi>p</mi></math></span></span></div><script type="math/tex;mode=display" id="MathJax-Element-11"> t = (t_s + t_w m) log_2p </script></p><br>  <b>all-to-all</b> <br>  The all-to-all operation is sometimes referred to as ‚Äúpersonalized all-to-all‚Äù or ‚Äútotal exchange‚Äù.  During this operation, each calculator forwards the message to each other calculator.  All messages can be unique (Taken from [1]). <br><img src="https://habrastorage.org/files/0c0/236/826/0c0236826e6e4df78c9775679ce7dd3d.png" alt="all-to-all"><br><br>  This operation is intensively used by various algorithms, such as Fourier transform, matrix transforms, sorting, parallel operations on databases.  This is one of the most "difficult" collective operations.  For this collective operation, the optimal algorithm depends on the ratios of the values ‚Äã‚Äãof key variables. <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-12-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>t</mi><mi>s</mi></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.843ex" height="2.298ex" viewBox="0 -728.2 793.5 989.6" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/hpchub/blog/319940/&amp;xid=17259,15700023,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjptIL1lQrY5rQMmfKikB6iBRLauQ#MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/hpchub/blog/319940/&amp;xid=17259,15700023,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjptIL1lQrY5rQMmfKikB6iBRLauQ#MJMATHI-73" x="511" y="-213"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>t</mi><mi>s</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-12"> t_s </script>  , <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-13-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>t</mi><mi>w</mi></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.249ex" height="2.298ex" viewBox="0 -728.2 968.1 989.6" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/hpchub/blog/319940/&amp;xid=17259,15700023,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjptIL1lQrY5rQMmfKikB6iBRLauQ#MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/hpchub/blog/319940/&amp;xid=17259,15700023,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjptIL1lQrY5rQMmfKikB6iBRLauQ#MJMATHI-77" x="511" y="-213"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>t</mi><mi>w</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-13"> t_w </script>  , <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-14-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>p</mi></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.259ex" height="1.817ex" viewBox="-38.5 -520.7 542 782.1" role="img" focusable="false" style="vertical-align: -0.607ex; margin-left: -0.089ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/hpchub/blog/319940/&amp;xid=17259,15700023,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjptIL1lQrY5rQMmfKikB6iBRLauQ#MJMATHI-70" x="0" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>p</mi></math></span></span><script type="math/tex" id="MathJax-Element-14"> p </script>  and size of transmitted messages <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-15-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>m</mi></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.04ex" height="1.455ex" viewBox="0 -520.7 878.5 626.5" role="img" focusable="false" style="vertical-align: -0.246ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/hpchub/blog/319940/&amp;xid=17259,15700023,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjptIL1lQrY5rQMmfKikB6iBRLauQ#MJMATHI-6D" x="0" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>m</mi></math></span></span><script type="math/tex" id="MathJax-Element-15"> m </script>  .  When using the hypercube algorithm, which is not optimal in terms of volume of shipments and is used for small messages, the time estimate is: <br><p><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-16-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mi>t</mi><mo>=</mo><mo stretchy=&quot;false&quot;>(</mo><msub><mi>t</mi><mi>s</mi></msub><mo>+</mo><msub><mi>t</mi><mi>w</mi></msub><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>p</mi><mi>m</mi><mtext>&amp;#xA0;</mtext><mi>o</mi><mi>v</mi><mi>e</mi><mi>r</mi><mn>2</mn></mrow><mo stretchy=&quot;false&quot;>)</mo><mi>l</mi><mi>o</mi><msub><mi>g</mi><mn>2</mn></msub><mi>p</mi></math>" role="presentation" style="font-size: 100%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="27.173ex" height="2.66ex" viewBox="0 -832 11699.5 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/hpchub/blog/319940/&amp;xid=17259,15700023,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjptIL1lQrY5rQMmfKikB6iBRLauQ#MJMATHI-74" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/hpchub/blog/319940/&amp;xid=17259,15700023,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjptIL1lQrY5rQMmfKikB6iBRLauQ#MJMAIN-3D" x="639" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/hpchub/blog/319940/&amp;xid=17259,15700023,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjptIL1lQrY5rQMmfKikB6iBRLauQ#MJMAIN-28" x="1695" y="0"></use><g transform="translate(2085,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/hpchub/blog/319940/&amp;xid=17259,15700023,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjptIL1lQrY5rQMmfKikB6iBRLauQ#MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/hpchub/blog/319940/&amp;xid=17259,15700023,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjptIL1lQrY5rQMmfKikB6iBRLauQ#MJMATHI-73" x="511" y="-213"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/hpchub/blog/319940/&amp;xid=17259,15700023,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjptIL1lQrY5rQMmfKikB6iBRLauQ#MJMAIN-2B" x="3100" y="0"></use><g transform="translate(4101,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/hpchub/blog/319940/&amp;xid=17259,15700023,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjptIL1lQrY5rQMmfKikB6iBRLauQ#MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/hpchub/blog/319940/&amp;xid=17259,15700023,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjptIL1lQrY5rQMmfKikB6iBRLauQ#MJMATHI-77" x="511" y="-213"></use></g><g transform="translate(5069,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/hpchub/blog/319940/&amp;xid=17259,15700023,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjptIL1lQrY5rQMmfKikB6iBRLauQ#MJMATHI-70" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/hpchub/blog/319940/&amp;xid=17259,15700023,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjptIL1lQrY5rQMmfKikB6iBRLauQ#MJMATHI-6D" x="503" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/hpchub/blog/319940/&amp;xid=17259,15700023,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjptIL1lQrY5rQMmfKikB6iBRLauQ#MJMATHI-6F" x="1632" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/hpchub/blog/319940/&amp;xid=17259,15700023,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjptIL1lQrY5rQMmfKikB6iBRLauQ#MJMATHI-76" x="2117" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/hpchub/blog/319940/&amp;xid=17259,15700023,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjptIL1lQrY5rQMmfKikB6iBRLauQ#MJMATHI-65" x="2603" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/hpchub/blog/319940/&amp;xid=17259,15700023,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjptIL1lQrY5rQMmfKikB6iBRLauQ#MJMATHI-72" x="3069" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/hpchub/blog/319940/&amp;xid=17259,15700023,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjptIL1lQrY5rQMmfKikB6iBRLauQ#MJMAIN-32" x="3521" y="0"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/hpchub/blog/319940/&amp;xid=17259,15700023,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjptIL1lQrY5rQMmfKikB6iBRLauQ#MJMAIN-29" x="9091" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/hpchub/blog/319940/&amp;xid=17259,15700023,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjptIL1lQrY5rQMmfKikB6iBRLauQ#MJMATHI-6C" x="9480" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/hpchub/blog/319940/&amp;xid=17259,15700023,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjptIL1lQrY5rQMmfKikB6iBRLauQ#MJMATHI-6F" x="9779" y="0"></use><g transform="translate(10264,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/hpchub/blog/319940/&amp;xid=17259,15700023,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjptIL1lQrY5rQMmfKikB6iBRLauQ#MJMATHI-67" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/hpchub/blog/319940/&amp;xid=17259,15700023,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjptIL1lQrY5rQMmfKikB6iBRLauQ#MJMAIN-32" x="675" y="-213"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/hpchub/blog/319940/&amp;xid=17259,15700023,15700186,15700190,15700248,15700253&amp;usg=ALkJrhjptIL1lQrY5rQMmfKikB6iBRLauQ#MJMATHI-70" x="11196" y="0"></use></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mi>t</mi><mo>=</mo><mo stretchy="false">(</mo><msub><mi>t</mi><mi>s</mi></msub><mo>+</mo><msub><mi>t</mi><mi>w</mi></msub><mrow class="MJX-TeXAtom-ORD"><mi>p</mi><mi>m</mi><mtext>&nbsp;</mtext><mi>o</mi><mi>v</mi><mi>e</mi><mi>r</mi><mn>2</mn></mrow><mo stretchy="false">)</mo><mi>l</mi><mi>o</mi><msub><mi>g</mi><mn>2</mn></msub><mi>p</mi></math></span></span></div><script type="math/tex;mode=display" id="MathJax-Element-16"> t = (t_s + t_w {pm \ over 2}) log_2p </script></p><br>  Other approaches to testing HPC media are also used.  For example, with the help of integral tests that simulate the calculations of common problems.  One of the most popular sets of integrated tests is the <a href="http://www.nas.nasa.gov/publications/npb.html">NAS parallel benchmarks</a> .  This test was also used to test virtual HPC environments [7]. <br><br><h2>  <font color="#808080">Testing method</font> </h2><br>  For the performance tests outlined in this paper, we used servers with Intel Xeon processors with 64 GB RAM and IB ConnectX-3 adapters.  OpenMPI was installed on virtual and physical nodes, the node-node connection was tested using the perftest and OSU benchmarks utilities. <br><br><div class="spoiler">  <b class="spoiler_title">In details</b> <div class="spoiler_text">  Intel H2000JF family of servers (S2600JF motherboard) with Intel Xeon E5-2680v2 2.8 GHz processors (10 cores, HyperThreading off), 64 GB RAM of DDR3 standard, IB with ConnectX-3 family of connectX-3 (ConnectX3-rel-2_36_5000 firmware) connected via the Mellanox SwitchX switch (36 ports SX6036 FDR). <br><br>  OS CentOS Linux release 7.2.1511 (CentOS 7.2), kernel 3.10.0-327.18.2.el7.x86_64, qemu / KVM customized based on 2.3.0 (version 1.5.3 is used in CentOS 7 distribution), Mellanox OFED 3.3 driver -1.0.4, qemu-kvm supported NUMA mode. <br><br>  Guest OS CentOS Linux release 7.1.1503 (CentOS 7.1), kernel 3.10.0-229.el7.x86_64, Mellanox ConnectX-3 drivers.  Each virtual machine was the only one on its physical server and occupied all the processors and 48 GB of RAM on it, overcommit on the processor cores was turned off. <br><br>  IB adapters were switched to SR-IOV support mode, and 2 VF per adapter was created.  One of the VFs was exported to KVM.  Accordingly, only one Infiniband adapter was visible in the guest OS, and two in the host OS: mlx4_0 and mlx4_1 (VF). <br><br>  OpenMPI version 1.10.3rc4 (included in the Mellanox OFED 3.3-1.0.4 packages) was installed on virtual and physical nodes.  The node-to-node connection was tested using perftest 0.19.g437c173.33100. <br><br>  Group tests were performed using OSU benchmarks version 5.3.1, compiled using gcc 4.8.5 and the above OpenMPI.  Each OSU benchmarks result is an averaging of 100 or 1000 measurements, depending on a number of conditions. <br>  On physical nodes, the tuned daemon has a latency-performance profile installed.  On virtual nodes it was turned off. <br></div></div><br>  Tests were run on two nodes (40 cores).  The measurements were carried out in series of 10-20 measurements.  As a result, the arithmetic average of the three lowest values ‚Äã‚Äãwas taken. <br><br><h2>  <font color="#808080">results</font> </h2><br>  The network parameters listed in the table are ideal, and in a real situation they are unattainable.  For example, the latency between two nodes with Infiniband FDR adapters (datagram mode), measured using <i>ib_send_lat</i> , is 0.83 ¬µs for small messages, and the useful throughput (excluding service information) between two nodes, measured using <i>ib_send_bw</i> , is 6116.40 MB / with (~ 51.3 Gbit / s).  Penalty latency and bandwidth in real systems due to the following factors: <br><ol><li>  additional switch latency </li><li>  delays due to OS nodes </li><li>  loss of bandwidth to ensure the transfer of service information protocols </li></ol><br>  The launch was carried out on the server with the command: <br><br><pre><code class="bash hljs">ib_send_bw -F -a -d mlx4_0</code> </pre> <br>  on the client: <br><br><pre> <code class="bash hljs">ib_send_bw -F -a -d mlx4_0 &lt;server-name&gt;</code> </pre> <br>  So <i>ib_send_lat</i> between a pair of guest OSs located on different physical servers shows a latency of 1.10 ¬µs (an increase in delay of 0.27 ¬µs, a ratio of latencies of native and virtualized IB is 0.75), and <i>ib_send_bw</i> shows a bandwidth of 6053.6 MB / s (~ 50.8 Gbit / s , 0.99 of the useful channel width without virtualization).  These results are in good agreement with the results of tests of other authors, for example [6]. <br><br>  It is worth noting that in the host OS, the test did not work with the SR-IOV VF, but with the adapter itself.  The results are presented in three graphs: <br><br><ol><li>  all message sizes </li><li>  messages only up to 256 bytes inclusive </li><li>  relationship of test execution times for native Infiniband and for VF </li></ol><br>  The <b>broadcast</b> test was launched both in the host and in the guest OS as: <br><br><pre> <code class="bash hljs">/usr/mpi/gcc/openmpi-1.10.3rc4/bin/mpirun --hostfile mh -N 20 -<span class="hljs-built_in"><span class="hljs-built_in">bind</span></span>-to core -mca pml ob1 -mca btl_openib_if_include mlx4_0:1 /usr/<span class="hljs-built_in"><span class="hljs-built_in">local</span></span>/libexec/osu-micro-benchmarks/mpi/collective/osu_bcast</code> </pre> <br>  The worst time ratio is 0.55, for most tests the ratio is not worse than 0.8. <br><div style="text-align:center;"><img src="https://habrastorage.org/files/eb8/d2d/b98/eb8d2db983544783a1747a60c2ac1b06.png"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/files/68f/971/63a/68f97163a6704661969df6d553cff4ac.png"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/files/9ff/861/c00/9ff861c00dd14dd582b58aa56d2c1d74.png"></div><br>  The <b>all-reduce</b> test started in both the host and the guest OS as: <br><br><pre> <code class="bash hljs">/usr/mpi/gcc/openmpi-1.10.3rc4/bin/mpirun --hostfile mh -N 20 -<span class="hljs-built_in"><span class="hljs-built_in">bind</span></span>-to core -mca pml ob1 -mca btl_openib_if_include mlx4_0:1 /usr/<span class="hljs-built_in"><span class="hljs-built_in">local</span></span>/libexec/osu-micro-benchmarks/mpi/collective/osu_allreduce</code> </pre> <br>  The worst time ratio is 0.7, for most tests the ratio is not worse than 0.8. <br><div style="text-align:center;"><img src="https://habrastorage.org/files/49b/f83/eda/49bf83eda27c4c3a92e963bf962e3fa8.png"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/files/c71/00f/767/c7100f76738b41fb97fea6003b172566.png"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/files/b4f/f6a/80b/b4ff6a80b2cb481fb97853c5c01cdb9d.png"></div><br>  The <b>all-to-all</b> test started in both the host and the guest OS as: <br><br><pre> <code class="bash hljs">/usr/mpi/gcc/openmpi-1.10.3rc4/bin/mpirun --hostfile mh -N 20 -<span class="hljs-built_in"><span class="hljs-built_in">bind</span></span>-to core -mca pml ob1 -mca btl_openib_if_include mlx4_0:1 /usr/<span class="hljs-built_in"><span class="hljs-built_in">local</span></span>/libexec/osu-micro-benchmarks/mpi/collective/osu_alltoall</code> </pre> <br>  The worst time ratio is 0.87, for most tests the ratio is not worse than 0.88. <br><div style="text-align:center;"><img src="https://habrastorage.org/files/fa6/8fa/cc3/fa68facc345746ecbf339f7ffbcf3107.png"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/files/311/532/900/311532900ef145d19ae7b948dc4ece95.png"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/files/085/08d/256/08508d2567a74b2c81f284b0094c2984.png"></div><br><h2>  <font color="#808080">Discussion</font> </h2><br>  The gear form of the graphs presented in the tests, on the one hand, is due to the result of a not very large sample of tests, but, on the other hand, it is just the desired effect of the method of selection of the smallest measured values ‚Äã‚Äãused for profiling programs.  The rationale for this method is the reasoning that a code fragment cannot execute faster than its maximum speed, and all processes that can occur in the system simultaneously with the execution of the test code either do not affect its speed or slow it down.  The presence of seemingly contradictory results, when the virtualized test is executed a little faster (2-5% of acceleration), than the non-virtualized one should be attributed to the features of the drivers and firmware of IB adapters, which, firstly, have their own optimization schemes, and secondly, still a little work differently in both cases (data buffer sizes, interrupt handling features, etc.). <br><br>  The features of modern virtualization technologies introduce additional sources of delay compared to the situation where there is no virtualization layer.  Significant for HPC are three types of such delays: <br><br><ul><li>  Slowing the speed of the network of low latency.  In our particular case, slowing down Infiniband in the SR-IOV virtual function mode.  This delay is the central theme of this work and is discussed above. <br><br></li><li>  Programs and services that are external to the virtualization shell will occasionally require CPU time, and will reset the caches of counting applications.  In a rather complicated way, it will introduce a variety of desynchronization and delays in counting applications running under the virtualization shell.  Such systematic interference can be extremely unpleasant for any kind of "extreme" programs, or for improperly optimized ones.  Of course, it is worth understanding that without a virtualization layer, counting programs will work faster.  However, in most practically important cases, the performance penalty due to the presence of the control code outside the virtualization shell on modern multi-core nodes does not exceed a few percent, and most often it is &lt;1%.  In addition, there are a number of approaches that allow you to select and fix the processor cores, which will deal with loads outside the virtualization shell, excluding them from the virtualized environment.  As a result, the impact on the processor cores and their caches inside the virtualization shells can be minimized. <br><br></li><li>  When working with a virtual APIC, there are numerous exits to the hypervisor, which is quite expensive in terms of delay (tens of microseconds).  This problem has become relevant recently due to the growth of requests for multi-core virtual machines, and attention has been paid to it at various conferences and in specialized publications, for example [8,9].  Such delays occur when interrupts are delivered, including from SR-IOV devices (in our case, Infiniband) on a guest, and when the processor core wakes up from a sleeping state (IPI), for example, when a message is received </li></ul><br>  In the opinion of the authors, the most radical methods of reducing virtualization penalties for handling interrupts are either using Intel processors with vAPIC support, or using container virtualization (for example, LXC) for counting nodes.  The materiality of the delay arising in the handling of interrupts in KVM is also indirectly indicated in [7], where the authors establish a link between the increase in the number of interruptions and a significant decrease in the performance of the virtualized version of the test. <br><br>  It is difficult to estimate these delays, except the first one, using simple formulas, similar to those given in [1], for several reasons: <br><br><ul><li>  The first and main one is that these delays appear asynchronously with a counting-task algorithm that works in a virtualized environment. </li><li>  The second reason is that these delays depend on the ‚Äúhistory‚Äù of the computational node as a whole, including both the counting task algorithm and the virtualization software ‚Äî the states of the caches, memory, controllers </li></ul><br>  It is also important to understand that when a large number of packets are sent over a low latency network, in particular, when large messages are fragmented, the interrupt generation rate will grow according to a complex law, which can lead to nontrivial dependencies of the message transfer rate on their length and again stack of virtualization software. <br><br>  The creators of traditional cluster computing systems make great efforts to eliminate interference for computing tasks: <br><br><ul><li>  shutting down all unnecessary OS services </li><li>  minimization of all network exchanges </li><li>  minimization of any other interrupt sources for nodes </li></ul><br>  In the case of a combination of virtualization and cloud software, we are only at the beginning of this optimization path for high performance computing. <br><br><h2>  <font color="#808080">findings</font> </h2><br>  Comparative tests of a set of three commonly used MPI operations (broadcast, all-reduce, personalized all-to-all) showed that the virtualization environment based on qemu / KVM and using SR-IOV technology shows an increased test time by an average of 20% ( in the worst case, by 80% with broadcast packets of sizes 16 and 32Kb).  This drop in performance, although noticeable, is not critical for most parallel applications related to continuum mechanics, molecular dynamics, signal processing, etc.  Ease of use of a virtualized environment, the ability to quickly expand the computational field and its settings multiply compensates for the costs of a possible increase in the computing time. <br><br>  For tasks that require rapid random access of one node to the memory of another, such a delay can be critical.  Most likely, it will not allow efficient use of virtualized clusters for solving such problems. <br><br>  In practice, the degradation of computational program performance is often much less than the indicated values ‚Äã‚Äã(max 20%).  This is because most of the time well-written and widely used programs still consider and process data inside the calculator, rather than perform synchronization or data transfer operations.  After all, the authors of parallel code always strive to select such algorithms and implementation techniques that minimize the need for synchronization and transfers between calculators. <br><br><h2>  <font color="#808080">Literature</font> </h2><br><div class="spoiler">  <b class="spoiler_title">In details</b> <div class="spoiler_text"><ol><li>  A. Grama, A. Gupta, G. Karypis, V. Kumar.  Introduction to Parallel Computing, Second Edition.  Addison-Wesley, 2003 </li><li>  R. Thakur, W. Gropp.  Improving the Mpi Collective Communication on Switched Networks, 2003 </li><li>  R. Thakur, R. Rabenseifner, W. Gropp.  Optimization of Collective Communication Operations in MPICH.  Int'l Journal of High Performance Computing Applications, - 2005 - Vol 19 (1) - pp.  49-66. </li><li>  J. Pje≈°ivac-Grboviƒá, T. Angskun, G. Bosilca, GE Fagg, E. Gabriel, JJ Dongarra.  Performance analysis of MPI collective operations.  Cluster Computing - 2007 - Vol.  10 - p.127. </li><li>  BS Parsons.  Accelerating MPI communication and imbalance awareness.  Ph.  D. Thesis on Computer Science, Purdue University, USA, 2015 </li><li>  J. Jose, M. Li, X. Lu, KC Kandalla, MD Arnold, DK Panda.  SR-IOV Support for Virtualization on InfiniBand Clusters: Early Experience.  International Symposium on Cluster, May 2011 </li><li>  A. Kudryavtsev, V. Koshelev, A. Avetisyan.  Modern HPC cluster virtualization using KVM and Palacios.  High Performance Computing (HiPC) Conference, 2012 </li><li>  D. Matlack.  KVM Message Passing Performance.  KVM forum, 2015 </li><li>  R. van Riel.  KVM vs.  Message Passing Throughput, Reducing Context Switching Overhead.  Red Hat KVM Forum 2013 </li></ol><br></div></div><br>  The material was prepared by Andrey Nikolaev, Denis Lunev, Anna Subbotina, Wilhelm Bitner. </div><p>Source: <a href="https://habr.com/ru/post/319940/">https://habr.com/ru/post/319940/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../319928/index.html">Plan without B: planning in the company from ‚ÄúI‚Äù to ‚Äúwe‚Äù</a></li>
<li><a href="../319932/index.html">Site security by its headers, or what to do if you want to crawl into the insides of each site</a></li>
<li><a href="../319934/index.html">Application Monitoring with Pinba</a></li>
<li><a href="../319936/index.html">JS optimization killers are no longer so scary</a></li>
<li><a href="../319938/index.html">How to find your first job as a programmer? From summary to trial period</a></li>
<li><a href="../319942/index.html">Windows users have the opportunity to work with openSUSE (and Arch Linux)</a></li>
<li><a href="../319944/index.html">How to build a product localization process from scratch</a></li>
<li><a href="../319948/index.html">Gartner rolled out a new magic quadrant for monitoring systems</a></li>
<li><a href="../319950/index.html">Using rebar3 to manage Erlang projects</a></li>
<li><a href="../319954/index.html">Announcement of 2017 DotNext Piter: Jon Skeet in Petersburg</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>