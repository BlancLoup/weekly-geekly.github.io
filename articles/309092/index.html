<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Visualization of the photo portfolio. Part 1: Unusual deep learning</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Briefly about the problem: there is a photo-portfolio with a lot of photos, we want to know the list of popular and not popular topics. 

 For example...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Visualization of the photo portfolio. Part 1: Unusual deep learning</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/files/de5/d15/016/de5d1501647c4798bc4430a342be9a48.png" alt="image"><br><br>  Briefly about the problem: there is a photo-portfolio with a lot of photos, we want to know the list of popular and not popular topics. <br><a name="habracut"></a><br>  For example, consider the <a href="http://www.istockphoto.com/ru/portfolio/urbancow%3Ffacets%3D%257B%2522pageNumber%2522:1,%2522perPage%2522:100,%2522abstractType%2522:%255B%2522photos%2522,%2522illustrations%2522%255D,%2522order%2522:%2522bestMatch%2522,%2522portfolioID%2522:%255B300612%255D,%2522f%2522:true%257D">author's</a> portfolio with iStock (consider only photos with age &lt;= 2 years; about 5000 photos). <br><br><div class="spoiler">  <b class="spoiler_title">This is for those who want to pull information from iStock</b> <div class="spoiler_text">  The links to the photos look like this: <a href="http://www.istockphoto.com/ru/ru/%25D1%2584%25D0%25BE%25D1%2582%25D0%25BE/%25D1%2581%25D0%25BC%25D0%25BE%25D1%2582%25D1%2580%25D0%25B5%25D1%2582%25D1%258C-%25D1%2581%25D0%25B5%25D0%25B2%25D0%25B5%25D1%2580%25D0%25BD%25D0%25BE%25D0%25B5-%25D1%2581%25D0%25B8%25D1%258F%25D0%25BD%25D0%25B8%25D0%25B5-gm516188033-48762778%3Fst%3D5721cc0">www.istockphoto.com/ru/ru/en/photo/monitor-signal-give-gm516188033-48762778?st=5721cc0</a> , where the line after gm and before the hyphen is id photo (516188033). <br>  Information about the photo (number of downloads, download date, keywords, author's name, ...) can be found at: <a href="https://rest.istockphoto.com/api/v1/assets/516188033">rest.istockphoto.com/api/v1/assets/516188033</a> 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <div class="spoiler">  <b class="spoiler_title">Sample script for downloading json pages with rest.api</b> <div class="spoiler_text"><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> requests <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> bs4 <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> BeautifulSoup <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> wget <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> json <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> sys <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> time author_name = <span class="hljs-string"><span class="hljs-string">"urbancow"</span></span> author_id = <span class="hljs-number"><span class="hljs-number">300612</span></span> page_count = <span class="hljs-number"><span class="hljs-number">93</span></span> path_to_save = <span class="hljs-string"><span class="hljs-string">"/home/forcesh/Downloads/Projects/iStock/urbancow/"</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> page <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">1</span></span>, page_count): search_url = <span class="hljs-string"><span class="hljs-string">'http://www.istockphoto.com/ru/portfolio/'</span></span>+author_name data = {<span class="hljs-string"><span class="hljs-string">"facets"</span></span>: {<span class="hljs-string"><span class="hljs-string">"pageNumber"</span></span>: page, <span class="hljs-string"><span class="hljs-string">"perPage"</span></span>: <span class="hljs-number"><span class="hljs-number">100</span></span>, <span class="hljs-string"><span class="hljs-string">"abstractType"</span></span>: [<span class="hljs-string"><span class="hljs-string">"photos"</span></span>, <span class="hljs-string"><span class="hljs-string">"illustrations"</span></span>], <span class="hljs-string"><span class="hljs-string">"order"</span></span>: <span class="hljs-string"><span class="hljs-string">"bestMatch"</span></span>, <span class="hljs-string"><span class="hljs-string">"portfolioID"</span></span>: [author_id], <span class="hljs-string"><span class="hljs-string">"additionalAudio"</span></span>: <span class="hljs-string"><span class="hljs-string">"false"</span></span>}} r = requests.post(search_url, json.dumps(data)) soup = BeautifulSoup(r.text, <span class="hljs-string"><span class="hljs-string">"lxml"</span></span>) scope = soup.select(<span class="hljs-string"><span class="hljs-string">"div.results-container"</span></span>) search_list = scope[<span class="hljs-number"><span class="hljs-number">0</span></span>].select(<span class="hljs-string"><span class="hljs-string">"section.search-list"</span></span>) figure_list = search_list[<span class="hljs-number"><span class="hljs-number">0</span></span>].select(<span class="hljs-string"><span class="hljs-string">"figure"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> figure <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> figure_list: href = figure.select(<span class="hljs-string"><span class="hljs-string">"a"</span></span>)[<span class="hljs-number"><span class="hljs-number">0</span></span>].get(<span class="hljs-string"><span class="hljs-string">"href"</span></span>) gm_id = href.rsplit(<span class="hljs-string"><span class="hljs-string">"gm"</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>)[<span class="hljs-number"><span class="hljs-number">1</span></span>].split(<span class="hljs-string"><span class="hljs-string">'-'</span></span>)[<span class="hljs-number"><span class="hljs-number">0</span></span>] rest_url = <span class="hljs-string"><span class="hljs-string">"https://rest.istockphoto.com/api/v1/assets/"</span></span>+gm_id wget.download(rest_url, out = path_to_save + gm_id) <span class="hljs-comment"><span class="hljs-comment">#iStock is sensitive to frequent requests time.sleep(0.5)</span></span></code> </pre> <br></div></div><br><div class="spoiler">  <b class="spoiler_title">Sample script for downloading images and forming a csv file</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> json <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> requests <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> wget <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> time author_name = <span class="hljs-string"><span class="hljs-string">'urbancow'</span></span> portfolio_path = <span class="hljs-string"><span class="hljs-string">'/home/forcesh/Downloads/Projects/iStock/'</span></span> path_to_gm_ids_list = portfolio_path + author_name + <span class="hljs-string"><span class="hljs-string">'/gm_ids_list.txt'</span></span> gm_ids = open(path_to_gm_ids_list,<span class="hljs-string"><span class="hljs-string">'r'</span></span>) rest_info_file = open(portfolio_path + author_name + <span class="hljs-string"><span class="hljs-string">'/rest_info.csv'</span></span>,<span class="hljs-string"><span class="hljs-string">'a'</span></span>) rest_info_file.write(<span class="hljs-string"><span class="hljs-string">'gm_id,downloads,keywords\n'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> gm_id <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> gm_ids: gm_id = gm_id.replace(<span class="hljs-string"><span class="hljs-string">'\n'</span></span>,<span class="hljs-string"><span class="hljs-string">''</span></span>) rest_page = open(portfolio_path + author_name + <span class="hljs-string"><span class="hljs-string">'/'</span></span> + gm_id,<span class="hljs-string"><span class="hljs-string">'r'</span></span>).read() parsed_string = json.loads(rest_page) downloads_count = parsed_string[<span class="hljs-string"><span class="hljs-string">'downloadsCount'</span></span>] info = gm_id + <span class="hljs-string"><span class="hljs-string">','</span></span> info += str(downloads_count) info += <span class="hljs-string"><span class="hljs-string">','</span></span>.join( parsed_string[<span class="hljs-string"><span class="hljs-string">'keywords'</span></span>]) rest_info_file.write(info) thumbnails_preview_url = parsed_string[<span class="hljs-string"><span class="hljs-string">'thumbnails'</span></span>][<span class="hljs-string"><span class="hljs-string">'previewUrl'</span></span>] wget.download(thumbnails_preview_url, out = portfolio_path + author_name+<span class="hljs-string"><span class="hljs-string">'/images/'</span></span>+gm_id+<span class="hljs-string"><span class="hljs-string">'.jpg'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> thumbnails_preview_url time.sleep(<span class="hljs-number"><span class="hljs-number">0.5</span></span>)</code> </pre><br></div></div><br></div></div><br>  The signs by which the data will be split will be obtained using the inceptionV3 model.  But we will not use the names of the objects that the neuron finds, but the output signals from the penultimate layer (2048 signs). <br><br><div class="spoiler">  <b class="spoiler_title">An example of a script that pulls a signal from the last but one layer on Keras</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># coding: utf-8 from keras_inception_v3.inception_v3 import InceptionV3, preprocess_input from keras.preprocessing import image import numpy as np from keras_inception_v3.imagenet_utils import decode_predictions import json import os import keras from multiprocessing import Pool from multiprocessing.dummy import Pool as ThreadPool import time import h5py import keras.backend as K import tensorflow as tf import nltk from nltk.stem import WordNetLemmatizer def preprocess_image(image_path): img = image.load_img(image_path, target_size=(299, 299)) x = image.img_to_array(img) x = np.expand_dims(x, axis=0) x = preprocess_input(x) return x def preprocess_image_batch(images): batch = np.zeros((len(images), 299, 299, 3), dtype=np.float32) for i, image_path in enumerate(images): batch[i] = preprocess_image(image_path) return batch def get_descriptor(i): offset = i%num_file_items file_id = i/num_file_items f = open("descriptors/descriptors_inception_v3_pool3_%d.bin"%file_id, "rb") f.seek(8*2048*offset, os.SEEK_SET) desc = np.fromfile(f, dtype=np.double, count=2048) f.close() return desc model = InceptionV3(include_top=False, weights=None) weights_file = h5py.File('/home/snapper/.keras/models/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5') weight_value_tuples = [] for layer in model.layers: layer_name = layer.name if layer_name in weights_file and len(weights_file[layer_name]) != 0: g = weights_file[layer_name] weight_names = [n.decode('utf8') for n in g.attrs['weight_names']] weight_values = [g[weight_name] for weight_name in weight_names] symbolic_weights = layer.weights weight_value_tuples += zip(symbolic_weights, weight_values) K.batch_set_value(weight_value_tuples) batch = preprocess_image_batch(['/home/snapper/120549251.jpg']) p = model.predict(batch) images = ['/home/snapper/120549251.jpg' for i in range(100)] images = np.array(images) num_file_items = 1024*4 descriptors = np.zeros([num_file_items, 2048], dtype=np.double) step = 64 m = len(images) for i in range(0, m, step): data_end_index = min(i % num_file_items + step, i % num_file_items+min(i+step, m)-i) data_indexes = np.arange(i % num_file_items, data_end_index) batch_indexes = np.arange(i, min(i+step, m)) batch = images[batch_indexes] X = preprocess_image_batch(batch) p = model.predict(X) descriptors[data_indexes] = p if i%num_file_items+step &gt;= num_file_items or i+step&gt;= m: print 'saving to', 'descriptors_inception_v3_pool3_%d.bin'%(i/num_file_items) descriptors[:data_end_index].tofile('descriptors/descriptors_inception_v3_pool3_%d.bin'%(i/num_file_items)) np.allclose(get_descriptor(0), p[0])</span></span></code> </pre><br></div></div><br>  <a href="https://github.com/fchollet/deep-learning-models/blob/master/inception_v3.py">Link to trained InceptionV3</a> <br><br>  Next, we will use t-distributed Stochastic Neighbor Embedding (t-sne) - a tool for visualizing high-dimensional data.  Developers of sklearn in the documentation recommend previously using other methods to reduce the dimension (PCA for dense data or TruncatedSVD for discharged data).  Compress the dimension, for example, to 50 and then use t-sne. <br><br>  In our case, the data is flat, so choose TruncatedSVD and compress the dimension to 50. Then compress the data to two-dimensional space.  And everything, you can draw pictures. <br><br>  In order to highlight popular and non-popular topics on the constructed image, we will use gaussian_kde from sklearn (a function for estimating density).  Calculate .. (mean) and .. (sd) downloads and select 4 groups of photos: <br><br><ul><li>  photos that have the number of downloads = 0 </li><li>  photos whose download count is&gt; 0 and &lt;= mean + sd </li><li>  photos with the number of downloads&gt; mean + sd and &lt;= mean + 2 * sd </li><li>  photos that have the number of downloads&gt; mean + 2 * sd </li></ul><br>  Next, we will build 4 pictures for each group of photos.  The gradient from blue to green and from green to red is the visualization of the density of points (photo) in this area.  The closer the color is to red, the more points in a given area belong to the group in question. <br><br><div class="spoiler">  <b class="spoiler_title">Portfolio Visualization Script</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># coding: utf-8 import numpy as np import pandas as pd import sys import matplotlib as mpl mpl.use('Agg') import matplotlib.pyplot as plt import json import os import cv2 from sklearn import manifold, decomposition from matplotlib.offsetbox import OffsetImage, AnnotationBbox from scipy.stats import gaussian_kde import gc num_file_items = 1024*4 def get_descriptor( directory, i ): offset = i%num_file_items file_id = i/num_file_items f = open( directory + "descriptors_inception_v3_pool3_%d.bin"%file_id, "rb" ) f.seek(8*2048*offset, os.SEEK_SET) desc = np.fromfile(f, dtype=np.double, count=2048) f.close() return desc def imscatter(x, y, image, ax=None, label=False): label=label==True im = OffsetImage(image) x, y = np.atleast_1d(x, y) artists = [] for x0, y0 in zip(x, y): ab = AnnotationBbox(im, (x0, y0), xycoords='data', frameon=label) artists.append(ax.add_artist(ab)) ax.update_datalim(np.column_stack([x, y])) ax.autoscale() return artists name = 'urbancow' portfolio_dir = '/home/traineeship/portfolio/' images_directory = portfolio_dir + name + '/images/' descriptors_directory = portfolio_dir + name + '/descriptors/' #order number of gm_id with open( descriptors_directory + 'descriptors_map.json' ) as data_file: descriptors_map = json.load( data_file ) #gm_id,downloads,keywords rest_info = pd.read_csv( portfolio_dir + name + '/rest_info.csv' ) gm_ids = rest_info['gm_id'] downloads = dict( zip( list( map( str, rest_info['gm_id'] ) ), rest_info['downloads'] ) ) X = np.matrix( [ get_descriptor( descriptors_directory, descriptors_map[str(gm_id)]) for gm_id in gm_ids ] ) #descriptors y = np.array( [ downloads[str(gm_id)] for gm_id in gm_ids ] ) #downloads count sd_downloads = y.std() mean_downloads = y.mean() X_list = list() y_list = list() gm_ids_list = list() part_size = 10000 if (len(X) &gt; part_size): batches_count = len(X) / part_size + 1 index = 0 for i in range(batches_count - 1): if (i &lt; batches_count - 2): X_list.append(X[index:index+part_size]) y_list.append(y[index:index+part_size]) gm_ids_list.append(gm_ids[index:index+part_size]) elif (i == batches_count - 2): if (len(X[index+part_size:]) &lt; 1000): X_list.append(X[index:]) y_list.append(y[index:]) gm_ids_list.append(gm_ids[index:]) batches_count -= 1 else: X_list.append(X[index:index+part_size]) y_list.append(y[index:index+part_size]) gm_ids_list.append(gm_ids[index:index+part_size]) index += part_size X_list.append(X[index:]) y_list.append(y[index:]) gm_ids_list.append(gm_ids[index:]) index += part_size else: X_list.append(X) y_list.append(y) gm_ids_list.append(gm_ids) print len(X_list), len(X) del X del y del gm_ids del rest_info del descriptors_map del downloads gc.collect() for ii in range(len(X_list)): X = X_list[ii] y = y_list[ii] gm_ids = gm_ids_list[ii] #TruncatedSVD due to sparse data X = decomposition.TruncatedSVD(n_components=50).fit_transform(X) X = manifold.TSNE().fit_transform(X) fig, ax = plt.subplots() scale_factor=15 fig.set_size_inches(16*scale_factor, 9*scale_factor, forward=True) for i, gm_id in enumerate( gm_ids ): image_path = images_directory + str(gm_id) + '.jpg' try: image=cv2.imread(image_path) b,g,r = cv2.split(image) # get b,g,r image = cv2.merge([r,g,b]) # switch it to rgb image=cv2.resize(image, (80, 80)) except Exception as ex: size = 80, 80, 3 image = np.zeros(size, dtype=np.uint8) pass x1=X[i, 0] x2=X[i, 1] imscatter(x1, x2, image, ax) ax.plot(x1, x2) for idx in range(4): if (idx == 0): x1=X[y == 0][:,0] x2=X[y == 0][:,1] elif (idx == 1): x1=X[(y &gt; 0) &amp; (y &lt;= mean_downloads + sd_downloads)][:,0] x2=X[(y &gt; 0) &amp; (y &lt;= mean_downloads + sd_downloads)][:,1] elif (idx == 2): x1=X[(y &gt; mean_downloads + sd_downloads) &amp; (y &lt;= mean_downloads + 2 * sd_downloads)][:,0] x2=X[(y &gt; mean_downloads + sd_downloads) &amp; (y &lt;= mean_downloads + 2 * sd_downloads)][:,1] elif (idx == 3): x1=X[y &gt; mean_downloads + 2 * sd_downloads][:,0] x2=X[y &gt; mean_downloads + 2 * sd_downloads][:,1] xy = np.vstack([x1,x2]) kde = gaussian_kde(xy)#simple density estimation z = kde(xy) xmin, xmax = ax.get_xlim() ymin, ymax = ax.get_ylim() xedges = np.linspace(xmin, xmax, 700) yedges = np.linspace(ymin, ymax, 700) xx, yy = np.meshgrid(xedges, yedges) gridpoints = np.array([xx.ravel(), yy.ravel()]) zz = np.reshape(kde(gridpoints), xx.shape) im = ax.imshow(zz, cmap='jet', interpolation='nearest', origin='lower', extent=[xmin, xmax, ymin, ymax]) ax.grid() suffix_name = str(idx) + '_tsne_part'+str(ii)+'.png' fig.savefig('vism/'+name+'/descriptors/'+name+'_'+ suffix_name, dpi=100, bbox_inches='tight') fig.clf() ax.cla()</span></span></code> </pre><br></div></div><br>  The following pictures were built (the size of the pictures is about 50 MB, the resolution is about 10k x 10k; GPicView opens them quite well): <br><br><ul><li>  <a href="https://drive.google.com/open%3Fid%3D0B1upW33U2iNWY3JiSVhPc01PRkk">download count is 0</a> </li><li>  <a href="https://drive.google.com/open%3Fid%3D0B1upW33U2iNWQk1JLWFaZWMzRkU">number of downloads&gt; 0 and &lt;= mean + sd</a> </li><li>  <a href="https://drive.google.com/open%3Fid%3D0B1upW33U2iNWM25JbTZnSFZMRFE">download count&gt; mean + sd and &lt;= mean + 2 * sd</a> </li><li>  <a href="https://drive.google.com/open%3Fid%3D0B1upW33U2iNWTlFFU0lvenlIUTQ">download count&gt; mean + 2 * sd</a> </li></ul><br>  It turned out that the author has the following popular topics: <br><br><ul><li>  photo of the streets above </li><li>  places with a large gathering of people (subway, ...); </li><li>  attractions </li><li>  students </li><li>  inside supermarkets with children </li></ul><br>  and not popular: <br><br><ul><li>  landscape;  nature </li></ul><br>  PS Especially for those who do not want to collect data and calculate signs, but want to see how the data is visualized, spread the <a href="https://drive.google.com/open%3Fid%3D0B1upW33U2iNWVzNicGdwcnVIdWs">portfolio of</a> another author and the calculated signs. </div><p>Source: <a href="https://habr.com/ru/post/309092/">https://habr.com/ru/post/309092/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../309076/index.html">Unreachable web: how we made such a mess</a></li>
<li><a href="../309078/index.html">Tips for working with Steam GreenLight or how not to get bogged down in a swamp</a></li>
<li><a href="../309080/index.html">On the process of creating a server - from idea to detail</a></li>
<li><a href="../309086/index.html">NVMe over Fabric, Fiber Channel and others</a></li>
<li><a href="../309088/index.html">DisQwerty: you do not need more than one button to type</a></li>
<li><a href="../309094/index.html">Samsung has created a ‚Äúdigital eye‚Äù based on the IBM Truenorth chip</a></li>
<li><a href="../309096/index.html">Dagaz: In the wilds of notations</a></li>
<li><a href="../309098/index.html">[St. Petersburg, Announcement] CodeFreeze meeting with PHP developer Dmitry Stogov about the internal structure of the PHP virtual machine</a></li>
<li><a href="../309100/index.html">How technology companies affect the media business</a></li>
<li><a href="../309102/index.html">GitLab Container Registry</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>