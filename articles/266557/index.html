<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Sorting integers when memory is low</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="The author of the original in English - dzeban habrauzer 

 Introduction 
 Last time we discussed how to artificially limit the memory available to a ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Sorting integers when memory is low</h1><div class="post__text post__text-html js-mediator-article">  <i>The author of the original in English - dzeban <a href="http://habrahabr.ru/users/dzeban/" class="user_link">habrauzer</a></i> <br><br><h4>  Introduction </h4><br>  <a href="http://habrahabr.ru/post/266083/">Last time we discussed</a> how to artificially limit the memory available to a program.  As a bonus, I got myself a <a href="">libmemrestrict</a> , a library with wrappers for functions like malloc to track memory usage, and <a href="">ptrace-restrict</a> , a <a href="">ptrace-</a> based tool that hooks brk, sbrk and mmap calls for the same purpose. <br><br>  So why should we try to organize a memory limit ‚Äî is it often the case?  When was the OOM last hit your app?  Do you always think about memory consumption while programming?  Memory is cheap, and if you don‚Äôt have enough memory, add another couple of gigabytes. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      And, nevertheless, it is impossible to add memory indefinitely - and not because you do not have its infinite source.  When processing Big Data, it is simply impossible to fit the entire input into the array - it is necessary to distribute the data between the RAM, the media and the network.  Algorithms and techniques are required for such data processing. <br><br>  And so I started doing similar tasks, starting with a simple one - how to sort a million integers (4 MiB data) with 2 MiB memory?  This task can be generalized in case you do not have enough memory to hold all the data. <br><br><h4>  Given </h4><br>  You must write a program to sort a set of integers stored in a file.  To create it, I wrote the simplest tools <a href="">randints</a> and <a href="">rangeints.</a> <br><br>  The program should output a sorted array to stdout as text. <br><br>  It should measure the time of work and bring it to stderr.  You can not just run the program through the time utility, because it counts the time to read the file and the time to output it. <br><br>  It should work, having memory at least two times less than the file size.  To do this, we will use libmemrestrict or ptrace-restrict. <br><br>  For some methods, these tools are not useful.  For example, for mmap they will not work - you have to physically limit the use of memory. <br><br>  They will be checked to solve the original problem (sorting 4 MiB into 2 MiB).  Also I will run them on a virtual machine with 128 MiB of memory for sorting 500 Mb (125 million four-byte integers). <br><a name="habracut"></a><br><h4>  Naive approach </h4><br>  Let's try to sort the numbers directly and calculate the memory usage (and time).  <a href="">Just count the file</a> into an array of integers, and call qsort. <br><br>  Let's try a file with 4 MB of data.  Without limitations, everything works: <br><br><pre><code class="bash hljs">$ ./naive 4M.bin &gt; /dev/null 4000000 bytes sorted <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> 0.323146 seconds</code> </pre> <br><br>  but it is not interesting.  Restrict memory 2 MiB: <br><br><pre> <code class="bash hljs">$ LD_PRELOAD=./libmemrestrict.so ./naive ints &gt; ints.sorted Segmentation fault</code> </pre><br><br>  Let us raise the limit to 4 MiB - and fail again.  (libmemrestrict reads settings from environment). <br><br><pre> <code class="bash hljs">$ MR_THRESHOLD=5000000 LD_PRELOAD=./libmemrestrict.so ./naive ints &gt; ints.sorted Segmentation fault</code> </pre><br><br>  Obviously, qsort requires more memory.  Let's see how much he wants, using the <a href="http://alex.dzyoba.com/linux/profiling-valgrind.html">massif from valgrind</a> : <br><br><pre> <code class="bash hljs">$ valgrind --tool=massif ./naive ints $ ms_print massif.out.10676</code> </pre><br><br>  Here is a beautiful schedule: <br><br><pre> <code class="bash hljs"> MB 8.819^ :::::::::::::::::::::::::::<span class="hljs-comment"><span class="hljs-comment"># | : # | : # | : # | : # | : # | : # | : # | : # | :::::::@ #:::::::::::::::::::::::: | : @ # | : @ # | : @ # | : @ # | : @ # | @@@@@@: @ # | @ : @ # | @ : @ # | :::@ : @ # | ::: @ : @ # 0 +-----------------------------------------------------------------------&gt;Gi 0 1.721</span></span></code> </pre><br><br>  There are several data placements that double the memory requests to 4 MiB - this is my array, and then four more MiB for qsort.  Statistics: <br><br><pre> <code class="bash hljs">-------------------------------------------------------------------------------- n time(i) total(B) useful-heap(B) extra-heap(B) stacks(B) -------------------------------------------------------------------------------- 21 173,222,581 5,247,504 4,000,568 1,246,936 0 22 173,223,802 5,246,920 4,000,000 1,246,920 0 23 173,226,655 5,247,504 4,000,568 1,246,936 0 24 173,229,202 5,246,920 4,000,000 1,246,920 0 25 173,229,311 9,246,928 8,000,000 1,246,928 0 26 869,058,772 9,246,928 8,000,000 1,246,928 0 86.52% (8,000,000B) (heap allocation <span class="hljs-built_in"><span class="hljs-built_in">functions</span></span>) malloc/new/new[], --alloc-fns, etc. -&gt;43.26% (4,000,000B) 0x400A26: readfile (<span class="hljs-keyword"><span class="hljs-keyword">in</span></span> /home/avd/dev/cs/sorting/external/naive) | -&gt;43.26% (4,000,000B) 0x400ACD: main (<span class="hljs-keyword"><span class="hljs-keyword">in</span></span> /home/avd/dev/cs/sorting/external/naive) | -&gt;43.26% (4,000,000B) 0x35D40383F7: qsort_r (<span class="hljs-keyword"><span class="hljs-keyword">in</span></span> /usr/lib64/libc-2.18.so) | -&gt;43.26% (4,000,000B) 0x400B3D: main (<span class="hljs-keyword"><span class="hljs-keyword">in</span></span> /home/avd/dev/cs/sorting/external/naive) | -&gt;00.00% (0B) <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> 1+ places, all below ms_print<span class="hljs-string"><span class="hljs-string">'s threshold (01.00%)</span></span></code> </pre><br><br>  4 million bytes I use, and another 4 million by qsort_r.  And another 1.2 MB in addition to the heap uses massif. <br><br>  Apparently, in this case, qsort behaves like O (n) with respect to volume complexity.  Which is strange, since qsort works ‚Äúon site‚Äù and uses various optimization techniques that guarantee volume complexity in O (log n).  <a href="https://sourceware.org/git/%3Fp%3Dglibc.git%3Ba%3Dblob%3Bf%3Dstdlib/qsort.c%3Bh%3D04c25b984f74a8f738233cc6da8a738b6437833c%3Bhb%3Db8079dd0d360648e4e8de48656c5c38972621072">Additional reading on glibc qsort implementation</a> . <br><br>  Well, can he sort out 500 MB in 128 MiB RAM? <br><br><pre> <code class="bash hljs">$ ./naive 500M.bin &gt; /dev/null Segmentation fault</code> </pre><br><br>  Of course not.  Speed: <br><br><pre> <code class="bash hljs">$ ./naive 4M.bin &gt; /dev/null 4000000 bytes sorted <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> 0.322712 seconds</code> </pre><br><br>  This means that naive sorting works well without restrictions, does not work with restrictions at all, and qsort requires O (n) memory.  This is strange.  For example, if you limit the memory to 5.3 MB, it will work and will not require memory of O (n).  I still understand this. <br><br><h4>  File and mmap </h4><br>  mmap is a hacker method of sorting a large amount of data in conditions of limited memory  He shifts the burden of data distribution between memory and swap on OS shoulders. <br><br>  It works like this: <br><ul><li>  Through mmap we send the entire file to memory. </li><li>  We get from him a pointer to the data </li><li>  Call the data sorting algorithm by this pointer. </li></ul><br><br>  And that's it!  Now you do not get memory overflow, even sorting a file by size larger than the available memory.  To understand how the mechanism works, you need to understand a little about memory management in the OS. <br><br>  Each program is represented by a process that has its own personal, virtual address space isolated from others.  Its length is limited by the width of the CPU bus, that is, for a 32-bit CPU, it is equal to 2 <sup>32</sup> , that is 4 GiB. <br><br>  All memory allocation, which is involved in the process, occurs in virtual memory.  This virtual memory is mapped to the physical kernel subsystem for working with memory - MMU.  And it usually happens in the "lazy" mode - that is, when the process asks for memory, the kernel immediately gives it to it, but it does not physically place it instantly - that is, the virtual memory page does not immediately appear on the physical.  When such a page is accessed (for example, for writing), the MMU throws an ‚Äúpage fault‚Äù exception, which the kernel handles, rendering the virtual page on physical.  Now it is displayed, and the entry to this page <a href="http://en.wikipedia.org/wiki/Memory_management_unit">will be broadcast by the MMU</a> as an entry to a specific address in physical memory. <br><br>  On the other hand, if you remember that the virtual address space is limited only by the size of the CPU bus, you can get into a situation in which the program will want to take up more memory than is available.  For example, in a 32-bit system with 256 MiB RAM, a process can accommodate and use 1 GiB of memory.  In this case, the memory pages will fall into the swap - instead of RAM, they will go to the drive, such as a hard disk.  When accessing such a page, the kernel reads it from the drive and sends it to memory (replacing another page in memory). <br><br>  The kernel copes well with the distribution of data between the memory and the drive, so it is natural to try to use this property in our task.  When we call mmap for our file, the kernel will reserve a range of virtual addresses that will not be placed immediately.  When we try to access them, the kernel loads it from the input file into memory.  When we run out of physical memory, the kernel will remove the pages in the swap.  This way we will balance the data between the disk file, the memory and the swap. <br><br>  The only limitation is the virtual address space (4 GiB for a 32bit system and 256 TiB for a 64bit), and swap - but drives are inexpensive today. <br><br>  Due to the fact that mmap loads the entire file into virtual memory, we will not be able to use libmemrestrict or ptrace-restrict, since they limit the virtual memory itself.  Trying to limit the sorting of data to 100M in virtual memory with a volume of 10M, we get an error from mmap: <br><br><pre> <code class="bash hljs">$ qemu-x86_64 -R 10M ./mmaped 100M.bin mmap stack: Cannot allocate memory</code> </pre><br><br>  No wonder - the file is loaded into virtual memory, and the kernel distributes it between the physical memory and the swap.  So we need at least 100M of virtual memory, plus some more space for qemu. <br><br>  Therefore, for this method, I use a virtual machine with 128 MiB of memory.  <a href="">Here is my sorting program</a> using mmap.  And it works! <br><br><pre> <code class="bash hljs">$ free -m total used free shared buffers cached Mem: 119 42 76 0 4 16 -/+ buffers/cache: 21 97 Swap: 382 0 382 $ ll -h 500M.bin -rw-r--r-- 1 root root 477M Feb 3 05:39 500M.bin $ ./mmaped 500M.bin &gt; /dev/null 500000000 bytes sorted <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> 32.250000 seconds</code> </pre><br><br>  Information from top: <br><br><pre> <code class="bash hljs">PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 3167 root 20 0 480m 90m 90m R 84.6 76.4 1:18.65 mmaped</code> </pre><br><br>  We use 500 MB of virtual memory, and the actual available memory is 90 MiB.  Note that MiB is 2 <sup>20</sup> , and MB is 10 <sup>6</sup> = 1 million.  And 500 MB = 500 000 000 bytes, and 500 000 000 &gt;&gt; 20 = 476 MiB. <br><br>  Looking at the details from vmstat while sorting 500 MB, we will see how the kernel balances between swap, disk cache, buffers and free memory: <br><br><pre> <code class="bash hljs">procs -----------memory---------- ---swap-- -----io---- -system-- ----cpu---- rb swpd free buff cache si so bi bo <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> cs us sy id wa 0 0 0 77776 2120 15104 1 27 710 971 24 34 3 1 95 1 1 1 0 2060 488 90068 1 27 785 1057 25 37 3 1 95 1 1 0 928 3400 60 89744 1 27 799 1092 25 38 3 1 94 1 0 2 1908 1928 212 92040 1 27 852 1174 26 40 4 1 94 1 0 2 3436 2360 280 93056 1 27 911 1282 28 42 4 1 94 2 0 0 5272 3688 196 94688 1 27 1066 1471 31 48 4 1 93 2 0 0 5272 3720 204 94700 1 27 1064 1469 31 48 4 1 93 2</code> </pre><br><br>  At first we had ~ 70 MiB of free memory, an empty swap and a little bit of memory was allocated for I / O buffers and cache.  Then after mmap, all this memory went to the cache.  When the free memory ran out, the core began to use a swap, which increases with the increase in I / O load.  And we come to the fact that almost all the memory is allocated for the disk cache - which is normal, since the pages with disk cache, in the case when we need memory for the application, go first. <br><br>  So, sorting through mmap is a cool hack that requires basic concepts of working with memory, and gives a simple solution for processing large amounts of data with a small amount of memory. <br><br><h4>  Outer merge sort </h4><br>  Suppose mmap cannot be used - you want to sort the file into 5 GiB on a 32-bit system. <br><br>  There is a well-known popular method called "merge external sorting".  If you do not have enough memory, you need to use an external drive - for example, a hard disk.  We'll just have to work with the data bit by bit, because they all do not fit into the memory. <br><br>  External merge sorting works like this: <br><ul><li>  break the data into pieces by the amount of available memory </li><li>  each piece is sorted in memory and written to external media </li><li>  you now have pieces the size of filesize / buffersize </li><li>  read pieces of buffersize / # chunks pieces to combine them in a buffer and output the result to a file </li></ul><br><br>  I did a <a href="">simple, non-optimized implementation</a> : <br><br><pre> <code class="bash hljs">$ LD_PRELOAD=./libmemrestrict.so ./external-merge 4M.bin 1048576 &gt; /dev/null 4194304 bytes sorted <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> 0.383171 seconds</code> </pre><br><br>  Sorted with 2 MiB of memory and using a buffer of 1 MiB. <br><br>  Now we will sort 500 MB.  First, turn off the swap, because we manage the exchange of data pieces manually. <br><br><pre> <code class="bash hljs">$ swapoff /dev/vda5</code> </pre><br><br>  Flush the caches: <br><br><pre> <code class="bash hljs">$ <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> 3 &gt; /proc/sys/vm/drop_caches</code> </pre><br><br>  Check available memory: <br><br><pre> <code class="bash hljs">$ free -m total used free shared buffers cached Mem: 119 28 90 0 0 6 -/+ buffers/cache: 21 97 Swap: 0 0 0</code> </pre><br><br>  We will use a buffer of 50 MB - 10 times smaller than the file size. <br><br><pre> <code class="bash hljs">$ ./external-merge 500M.bin 50000000 &gt; /dev/null 500000000 bytes sorted <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> 120.115180 seconds</code> </pre><br><br>  Two minutes!  Why did it happen?  Of course, due to I / O operations.  Three things slow down the process.  In the data separation phase, we sequentially read the file using a small buffer.  In the merge phase, we open and close files with pieces of information.  And there is also a conclusion - in the merge phase, we output 50 MB of data to stdout, which, despite the redirection to / dev / null, gives a load.  If this is disabled, we get a performance boost of 25%. <br><br><pre> <code class="bash hljs">$ ./external-merge-no-output 500M.bin 50000000 &gt; /dev/null 500000000 bytes sorted <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> 87.140000 seconds</code> </pre><br><br>  Memory usage is fine with me.  If you run the program through massif, you can see that the peak of consumption is the size of the buffer and a small pile. <br><br><pre> <code class="bash hljs">-------------------------------------------------------------------------------- Command: ./external-merge 500M.bin 50000000 Massif arguments: (none) ms_print arguments: massif.out.17423 -------------------------------------------------------------------------------- MB 47.75^ ::::: |<span class="hljs-comment"><span class="hljs-comment">#::::::@:::::::::::@:::::::::@:::@::::@::::@::::::::@::::@::::@:::@ |# : : @ : : : : @ : : @ @ @ @ : @ @ @ @ |# : : @ : : : : @ : : @ @ @ @ : @ @ @ @ |# : : @ : : : : @ : : @ @ @ @ : @ @ @ @ |# : : @ : : : : @ : : @ @ @ @ : @ @ @ @ |# : : @ : : : : @ : : @ @ @ @ : @ @ @ @ |# : : @ : : : : @ : : @ @ @ @ : @ @ @ @ |# : : @ : : : : @ : : @ @ @ @ : @ @ @ @ |# : : @ : : : : @ : : @ @ @ @ : @ @ @ @ |# : : @ : : : : @ : : @ @ @ @ : @ @ @ @ |# : : @ : : : : @ : : @ @ @ @ : @ @ @ @ |# : : @ : : : : @ : : @ @ @ @ : @ @ @ @ |# : : @ : : : : @ : : @ @ @ @ : @ @ @ @ |# : : @ : : : : @ : : @ @ @ @ : @ @ @ @ |# : : @ : : : : @ : : @ @ @ @ : @ @ @ @ |# : : @ : : : : @ : : @ @ @ @ : @ @ @ @ |# : : @ : : : : @ : : @ @ @ @ : @ @ @ @ |# : : @ : : : : @ : : @ @ @ @ : @ @ @ @ |# : : @ : : : : @ : : @ @ @ @ : @ @ @ @ 0 +-----------------------------------------------------------------------&gt;Gi 0 332.5 Number of snapshots: 98 Detailed snapshots: [4 (peak), 10, 20, 29, 32, 35, 38, 45, 48, 54, 64, 74, 84, 94] -------------------------------------------------------------------------------- n time(i) total(B) useful-heap(B) extra-heap(B) stacks(B) -------------------------------------------------------------------------------- 0 0 0 0 0 0 1 119,690 584 568 16 0 2 123,141 50,004,496 50,000,568 3,928 0 3 4,814,014 50,005,080 50,001,136 3,944 0 4 4,817,234 50,005,080 50,001,136 3,944 0 99.99% (50,001,136B) (heap allocation functions) malloc/new/new[], --alloc-fns, etc. -&gt;99.99% (50,000,000B) 0x400FA2: external_merge_sort (in /root/external-merge) | -&gt;99.99% (50,000,000B) 0x40128E: main (in /root/external-merge) | -&gt;00.00% (1,136B) in 1+ places, all below ms_print's threshold (01.00%)</span></span></code> </pre><br><br>  You can limit the memory and 50 MB, plus another 500 KB for temporary lines containing the paths to the files: <br><br><pre> <code class="bash hljs">$ LD_PRELOAD=./libmemrestrict.so MR_THRESHOLD=51000000 ./external-merge 500M.bin 50000000 &gt; /dev/null 500000000 bytes sorted <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> 87.900000 seconds</code> </pre><br><br>  In general, with memory - ok, with speed - not ok.  mmap allowed you to do this operation in 32 seconds.  Let's improve our way. <br><br>  Perform program profiling with gprof.  Create a binary <br><br><pre> <code class="bash hljs">$ gcc -pg -g -Wall -Wextra external-merge.c -o external-merge-gprof</code> </pre><br><br>  And we will call the program repeatedly to accumulate statistics with the help of my convenient script from the article on gprof.  Here is the result: <br><br><pre> <code class="bash hljs">% cumulative self self total time seconds seconds calls Ts/call Ts/call name 81.98 432.87 432.87 compar 18.17 528.82 95.95 print_arr 0.00 528.82 0.00 1100 0.00 0.00 form_filename 0.00 528.82 0.00 100 0.00 0.00 merge 0.00 528.82 0.00 100 0.00 0.00 save_buf 0.00 528.82 0.00 10 0.00 0.00 external_merge_sort 0.00 528.82 0.00 10 0.00 0.00 split</code> </pre><br><br>  Most of the time was spent on sorting and output.  But do not forget that gprof does not show the time spent on system calls and I / O. <br><br>  What can be improved? <br><ul><li>  add multithreading and I / O tricks to external sorting </li><li>  take a different sorting algorithm </li></ul><br><br>  Universal external merge sorting is a simple idea for sorting big data with a small amount of memory, but without any improvements it works slowly. <br><br><h4>  Customize sorting </h4><br>  You can, of course, use multithreading to separate and merge - but this is a bad idea.  Using it during the separation phase does not make sense, because the data is contained in a single buffer.  You can try to influence how the kernel reads the data.  There are two functions for this: <br><ul><li>  readahead (Linux only). </li><li>  posix_fadvise with POSIX_FADV_SEQUENTIAL. </li></ul><br><br>  They tell the memory management subsystem how we will read the data.  In our case, the reading is sequential, so it would be nice to see the contents of the file in the page cache. <br><br>  During the merge phase, we can not do the permanent opening and closing of files, but create dedicated streams for each of the files.  Each stream will keep its file open, and we will fill the buffer for it.  When it is filled, it is sorted and displayed.  And readahead will work for each thread. <br><br>  Here is an improved multi-threaded version of merge external sorting.  Well, as I said, multithreading is not a good idea.  There is no difference in the single core process. <br><br><pre> <code class="bash hljs">$ ./mt-ext-merge 500M.bin 50000000 &gt; /dev/null 500000000 bytes sorted <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> 117.380000 seconds</code> </pre><br><br>  This is with data output.  And without output: <br><br><pre> <code class="bash hljs">$ ./mt-ext-merge-no-output 500M.bin 50000000 &gt; /dev/null 500000000 bytes sorted <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> 91.040000 seconds</code> </pre><br><br>  Well, let's try on a quad-core machine (Intel Core i7-3612QM CPU @ 2.10GHz): <br><br><pre> <code class="bash hljs">$ ./naive 500M.bin &gt; /dev/null 500000000 bytes sorted <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> 23.040499 seconds $ ./mmaped 500M.bin &gt; /dev/null 500000000 bytes sorted <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> 23.542076 seconds $ ./external-merge 500M.bin 50000000 &gt; /dev/null 500000000 bytes sorted <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> 39.228695 seconds $ ./mt-external-merge 500M.bin 50000000 &gt; /dev/null 500000000 bytes sorted <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> 41.062793 seconds $ ./external-merge-no-output 500M.bin 50000000 &gt; /dev/null 500000000 bytes sorted <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> 28.893745 seconds $ ./mt-external-merge-no-output 500M.bin 50000000 &gt; /dev/null 500000000 bytes sorted <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> 28.368976 seconds       : $ ./external-merge-no-output 500M.bin 5000000 &gt; /dev/null 500000000 bytes sorted <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> 27.107728 seconds $ ./mt-external-merge-no-output 500M.bin 5000000 &gt; /dev/null 500000000 bytes sorted <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> 28.558468 seconds</code> </pre><br><br>  There is no difference between external-merge and mt-external-merge.  Why is that?  Yes, because multithreading does not solve the problems of input and output limitations.  It is well suited for those cases where: <br><ul><li>  execution of threads independently </li><li>  input and output resources can work in parallel ‚Äî for example, like RAID </li></ul><br><br>  Our threads are interdependent - the main thread has to wait for the buffer to be sorted, and only then begin the next reading from the file.  And reading for separation is faster than buffer sorting, so most of the time, threads wait until the main thread finishes. <br><br>  We need other ways to improve the algorithm. <br><br><h4>  Special sorting algorithms </h4><br>  Let's try to use something other than QuickSort.  Since we know that we are sorting integers, we need to use it.  There are specific algorithms that are used for specific data types, and they can be divided into two groups: <br><ul><li>  do not use comparisons </li><li>  do not require loading the entire array into memory </li></ul><br><br>  They work better than O (n log (n)) - the lower limit for comparing algorithms like QuickSort.  But not all of them are suitable in case of memory limitations.  Therefore, I stopped on the use of sorting by counting <br><br><h4>  Sort by count </h4><br>  If we have a lot of data with a small spread, you can use sorting by counting.  The idea is simple - we will not store data in memory, but an array of counters.  We consistently read the data and increase the corresponding counters.  The complexity of the algorithm is linear in time, and in terms of volume - proportional to the range of data. <br><br>  A simple implementation works with an array from 0 to N. Integers correspond to array indices.  <a href="">Here is my version</a> , which works well without any tuning.  The second argument is the size of the buffer in the elements.  Buffering greatly speeds up work, because the program reads from a file not 4 bytes each. <br><br><pre> <code class="bash hljs">$ ./counting-array 500M-range.bin 1000000 &gt; /dev/null Range is 1000000 500000000 bytes sorted <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> 3.240000 seconds</code> </pre><br><br>  Ugums  Polgiga data sorted for 3 and a half seconds on 128 MiB of memory and one CPU.  Compare to qsort or mmap: <br><br><pre> <code class="bash hljs">$ ./mmaped 500M-range.bin &gt; /dev/null 500000000 bytes sorted <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> 76.150000 seconds</code> </pre><br><br>  23 times faster! <br><br>  But do not forget about the restrictions - only integers (or their equivalent), and their small consecutive interval.  I tried to make a <a href="">variant with inconsistent intervals</a> through hashes and binary search - but its speed is very bad. <br><br>  And if we assume the uniqueness of our numbers, then the counters can only be in two states - is it or not, so they can be single-bit.  Then our array will shrink.  Yes, and we do not need an array - we can store numbers as bits, that is, instead of an array, we will have a vector.  We read the file and set the Nth bit, if the number N was found there. After that, we simply go through the vector and output to the file those numbers for which the bits are cocked. <br><br>  Such decisions require a careful approach, since you can still go beyond the limits.  For example, to sort all the numbers from the interval of integers (2 <sup>32</sup> ), you need 1 bit for each number, and this is 4294967296 bits = 536870912 bytes = 512 MiB.  And we have only 128 MiB, which is not enough for you.  But in some cases, the gain will be enormous - this is the story on this topic from <a href="http://www.cs.bell-labs.com/cm/cs/pearls/cto.html">‚ÄúProgramming Pearls‚Äù by Jon Bentley</a> . <br><br>  Knowing your data is very helpful. <br><br><h4>  Total </h4><br>  During the 5 months spent on the article, I did a lot of things - a dozen programs, some good ideas, many bad ones.  And much more can be done and corrected. <br><br>  The simple problem of sorting data with a lack of memory revealed a whole set of oddities, which we usually do not think about: <br><ul><li>  common algorithms are not suitable for all problems </li><li>  debugging and profiling - very useful and visual things </li><li>  I / O is a problem area, if you do not shift all the work to the core </li><li>  multithreading is not a panacea for speed </li><li>  know your data and your surroundings </li></ul><br><br>  Sorting plate: <br><table><tbody><tr><td>  Test </td><td>  Naive QuickSort </td><td>  mmap and quicksort </td><td>  Outer merge sort </td><td>  Multi-thread merge external sorting </td><td>  Sort by count </td></tr><tr><td>  4 MiB in 2 MiB </td><td>  Segfault </td><td>  N / A </td><td>  0.38s </td><td>  0.41s </td><td>  0.01 </td></tr><tr><td>  500 MB in 128 MiB </td><td>  Segfault </td><td>  32.25s </td><td>  87.14s </td><td>  91.04 </td><td>  3.24 </td></tr></tbody></table><br><br>  Get to know your data and develop a simple algorithm to work with them! <br><br><h4>  Links </h4><br><ul><li>  <a href="http://neopythonic.blogspot.ru/2008/10/sorting-million-32-bit-integers-in-2mb.html">Sorting a million 32-bit numbers in 2 MB of memory in Python</a> </li><li>  <a href="http://www.umbrant.com/blog/2011/external_sorting.html">External sorting of large data sets</a> </li><li>  <a href="http://www.reddit.com/r/programming/comments/grrrr/efficiently_sorting_datasets_bigger_than_memory_c/">Efficient data sorting, exceeding the memory capacity</a> </li><li>  <a href="http://www.cs.bell-labs.com/cm/cs/pearls/cto.html">We open an oyster (1st article from "Programming Pearls")</a> </li><li>  <a href="http://www.drdobbs.com/parallel/multithreaded-file-io/220300055">Multithreaded file input and output</a> </li><li>  <a href="http://www.drdobbs.com/architecture-and-design/algorithm-improvement-through-performanc/220300654">Improving algorithms by measuring performance, part 2</a> </li><li>  <a href="http://stackoverflow.com/questions/3969813/which-parallel-sorting-algorithm-has-the-best-average-case-performance">Parallel sorting algorithms</a> </li></ul></div><p>Source: <a href="https://habr.com/ru/post/266557/">https://habr.com/ru/post/266557/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../266545/index.html">Installation programs - how much do they influence the product or company image?</a></li>
<li><a href="../266547/index.html">JetBrains IDE is now only available for rent.</a></li>
<li><a href="../266549/index.html">Healthcare IT: or how to throw out $ 34 million</a></li>
<li><a href="../266551/index.html">Recognize cannot be left a picture, or something about difficult cases of optical character recognition</a></li>
<li><a href="../266553/index.html">Determine that the user has Wikipedia blocked.</a></li>
<li><a href="../266559/index.html">Smart and Stupid React Components</a></li>
<li><a href="../266561/index.html">We develop a monitoring system for 55,000 RTP video streams</a></li>
<li><a href="../266563/index.html">Profit about the printer</a></li>
<li><a href="../266565/index.html">GPS service ViaLatM - scripting language (part 2)</a></li>
<li><a href="../266567/index.html">Expand the Ghost blog in InfoboxCloud</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>