<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Parallel queries in PostgreSQL</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="There are a lot of cores in modern CPUs. For years, applications sent queries to databases in parallel. If this is a reporting query to a set of rows ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Parallel queries in PostgreSQL</h1><div class="post__text post__text-html js-mediator-article"><p><img src="https://habrastorage.org/webt/kx/ht/dl/kxhtdlsry_f8p1jv2ve_1ziks7e.jpeg"></p><br><p>  There are a lot of cores in modern CPUs.  For years, applications sent queries to databases in parallel.  If this is a reporting query to a set of rows in a table, it is executed faster when it involves several CPUs, and in PostgreSQL, this is possible starting from version 9.6. </p><br><p>  It took 3 years to implement the function of parallel queries - I had to rewrite the code at different stages of query execution.  In PostgreSQL 9.6, an infrastructure has appeared to further improve the code.  In later versions, other types of queries are executed in parallel. </p><a name="habracut"></a><br><h3 id="ogranicheniya">  Restrictions </h3><br><ul><li>  Do not enable parallel execution if all cores are already occupied, otherwise other requests will slow down. </li><li>  Most importantly, parallel processing with high WORK_MEM values ‚Äã‚Äãinvolves a lot of memory ‚Äî each hash connection or sorting takes up memory in the work_mem volume. </li><li>  Low latency OLTP requests cannot be accelerated by parallel execution.  And if the request returns a single line, parallel processing only slows it down. </li><li>  Developers love to use the TPC-H benchmark.  Maybe you have similar queries for perfect parallel execution. </li><li>  Only SELECT queries without a predicate lock are executed in parallel. </li><li>  Sometimes correct indexing is better than sequential scanning of a table in parallel mode. </li><li>  Pause queries and cursors are not supported. </li><li>  Window functions and aggregate functions of ordered sets are not parallel. </li><li>  You do not win anything in I / O workloads. </li><li>  There are no parallel sorting algorithms.  But queries with sorts can run in parallel in some aspects. </li><li>  Replace CTE (WITH ...) with nested SELECT to enable parallel processing. </li><li>  Third-party data wrappers do not support parallel processing yet (they could!) </li><li>  FULL OUTER JOIN is not supported. </li><li>  max_rows disables parallel processing. </li><li>  If there is a function in the request that is not marked as PARALLEL SAFE, it will be single-threaded. </li><li>  The transaction isolation level SERIALIZABLE disables parallel processing. </li></ul><br><h3 id="testovaya-sreda">  Test environment </h3><br><p>  PostgreSQL developers have tried to cut the response time of the benchmark TPC-H.  Download the benchmark and <a href="https://github.com/tvondra/pg_tpch">adapt it to PostgreSQL</a> .  This is an unofficial use of the TPC-H benchmark ‚Äî not for comparing databases or equipment. </p><br><ol><li>  Download TPC-H_Tools_v2.17.3.zip (or newer version) <a href="http://www.tpc.org/tpc_documents_current_versions/current_specifications.asp">from TPC offsite</a> . </li><li>  Rename makefile.suite to Makefile and change as described here: <a href="https://github.com/tvondra/pg_tpch">https://github.com/tvondra/pg_tpch</a> .  Compile the code with the make command. </li><li> Generate data: <code>./dbgen -s 10</code> creates a 23 GB database.  That's enough to see the performance difference between parallel and non-parallel queries. </li><li>  Convert <code>tbl</code> files to <code>csv  for</code> and <code>sed</code> . </li><li>  Clone the pg_tpch repository and copy the <code>csv</code> to <code>pg_tpch/dss/data</code> . </li><li>  Create queries with the <code>qgen</code> command. </li><li>  Download data to the database with the command <code>./tpch.sh</code> . </li></ol><br><h3 id="parallelnoe-posledovatelnoe-skanirovanie">  Parallel sequential scan </h3><br><p>  It may be faster not because of parallel reading, but because the data is scattered across many CPU cores.  In modern operating systems, PostgreSQL data files are well cached.  With read ahead, you can get more block from storage than the PG daemon requests.  Therefore, query performance is not limited to disk I / O.  It consumes CPU cycles to: </p><br><ul><li>  read lines one by one from the pages of the table; </li><li>  compare string values ‚Äã‚Äãand <code>WHERE</code> conditions. </li></ul><br><p>  Perform a simple <code>select</code> query: </p><br><pre> <code class="plaintext hljs">tpch=# explain analyze select l_quantity as sum_qty from lineitem where l_shipdate &lt;= date '1998-12-01' - interval '105' day; QUERY PLAN -------------------------------------------------------------------------------------------------------------------------- Seq Scan on lineitem (cost=0.00..1964772.00 rows=58856235 width=5) (actual time=0.014..16951.669 rows=58839715 loops=1) Filter: (l_shipdate &lt;= '1998-08-18 00:00:00'::timestamp without time zone) Rows Removed by Filter: 1146337 Planning Time: 0.203 ms Execution Time: 19035.100 ms</code> </pre> <br><p>  A serial scan yields too many rows without aggregation, so the query is executed by a single CPU core. </p><br><p>  If you add <code>SUM()</code> , you can see that two workflows can help speed up the request: </p><br><pre> <code class="plaintext hljs">explain analyze select sum(l_quantity) as sum_qty from lineitem where l_shipdate &lt;= date '1998-12-01' - interval '105' day; QUERY PLAN ---------------------------------------------------------------------------------------------------------------------------------------------------- Finalize Aggregate (cost=1589702.14..1589702.15 rows=1 width=32) (actual time=8553.365..8553.365 rows=1 loops=1) -&gt; Gather (cost=1589701.91..1589702.12 rows=2 width=32) (actual time=8553.241..8555.067 rows=3 loops=1) Workers Planned: 2 Workers Launched: 2 -&gt; Partial Aggregate (cost=1588701.91..1588701.92 rows=1 width=32) (actual time=8547.546..8547.546 rows=1 loops=3) -&gt; Parallel Seq Scan on lineitem (cost=0.00..1527393.33 rows=24523431 width=5) (actual time=0.038..5998.417 rows=19613238 loops=3) Filter: (l_shipdate &lt;= '1998-08-18 00:00:00'::timestamp without time zone) Rows Removed by Filter: 382112 Planning Time: 0.241 ms Execution Time: 8555.131 ms</code> </pre> <br><h3 id="parallelnaya-agregaciya">  Parallel aggregation </h3><br><p>  The "Parallel Seq Scan" node produces rows for partial aggregation.  The "Partial Aggregate" node truncates these strings with <code>SUM()</code> .  At the end, the SUM counter from each workflow is collected by the "Gather" node. </p><br><p>  The final result is calculated by the node "Finalize Aggregate".  If you have your own aggregation functions, do not forget to mark them as "parallel safe". </p><br><h3 id="kolichestvo-rabochih-processov">  Number of workflows </h3><br><p>  The number of working processes can be increased without restarting the server: </p><br><pre> <code class="plaintext hljs">alter system set max_parallel_workers_per_gather=4; select * from pg_reload_conf();</code> </pre> <br><p>  Now we see 4 workers in the explain output: </p><br><pre> <code class="plaintext hljs">tpch=# explain analyze select sum(l_quantity) as sum_qty from lineitem where l_shipdate &lt;= date '1998-12-01' - interval '105' day; QUERY PLAN ---------------------------------------------------------------------------------------------------------------------------------------------------- Finalize Aggregate (cost=1440213.58..1440213.59 rows=1 width=32) (actual time=5152.072..5152.072 rows=1 loops=1) -&gt; Gather (cost=1440213.15..1440213.56 rows=4 width=32) (actual time=5151.807..5153.900 rows=5 loops=1) Workers Planned: 4 Workers Launched: 4 -&gt; Partial Aggregate (cost=1439213.15..1439213.16 rows=1 width=32) (actual time=5147.238..5147.239 rows=1 loops=5) -&gt; Parallel Seq Scan on lineitem (cost=0.00..1402428.00 rows=14714059 width=5) (actual time=0.037..3601.882 rows=11767943 loops=5) Filter: (l_shipdate &lt;= '1998-08-18 00:00:00'::timestamp without time zone) Rows Removed by Filter: 229267 Planning Time: 0.218 ms Execution Time: 5153.967 ms</code> </pre> <br><p>  What's going on here?  The workflow was 2 times more, and the request was only 1.6599 times faster.  The calculations are interesting.  We had 2 workflows and 1 leader.  After the change was 4 + 1. </p><br><p>  Our maximum acceleration from parallel processing: 5/3 = 1.66 (6) times. </p><br><h2 id="kak-eto-rabotaet">  How it works? </h2><br><h3 id="processy">  Processes </h3><br><p>  Query execution always begins with a leading process.  The leader makes everything non-parallel and part of parallel processing.  Other processes that perform the same requests are called workflows.  Parallel processing uses a <a href="https://www.postgresql.org/docs/11/bgworker.html">dynamic background workflow</a> infrastructure (from version 9.4).  Since other parts of PostgreSQL use processes rather than threads, a query with 3 workflows could be 4 times faster than traditional processing. </p><br><h3 id="vzaimodeystvie">  Interaction </h3><br><p>  Workflows communicate with the leader through a message queue (based on shared memory).  Each process has 2 queues: for errors and for tuples. </p><br><h3 id="skolko-nuzhno-rabochih-processov">  How many workflows are needed? </h3><br><p>  The minimum limit specifies the <a href="https://www.postgresql.org/docs/11/runtime-config-resource.html"><code>max_parallel_workers_per_gather</code></a> parameter.  Then the <a href="https://www.postgresql.org/docs/11/runtime-config-resource.html"><code>max_parallel_workers size</code></a> takes workflows from the pool bounded by the <a href="https://www.postgresql.org/docs/11/runtime-config-resource.html"><code>max_parallel_workers size</code></a> parameter.  The last limit is <a href="https://www.postgresql.org/docs/11/runtime-config-resource.html"><code>max_worker_processes</code></a> , that is, the total number of background processes. </p><br><p>  If you cannot allocate the workflow, the processing will be single-process </p><br><p>  A query planner can shorten workflows depending on the size of the table or index.  For this there are parameters <a href="https://www.postgresql.org/docs/current/runtime-config-query.html"><code>min_parallel_table_scan_size</code></a> and <a href="https://www.postgresql.org/docs/current/runtime-config-query.html"><code>min_parallel_index_scan_size</code></a> . </p><br><pre> <code class="plaintext hljs">set min_parallel_table_scan_size='8MB' 8MB table =&gt; 1 worker 24MB table =&gt; 2 workers 72MB table =&gt; 3 workers x =&gt; log(x / min_parallel_table_scan_size) / log(3) + 1 worker</code> </pre> <br><p>  Every time a table is 3 times larger than <code>min_parallel_(index|table)_scan_size</code> , Postgres adds a workflow.  The number of work processes is not cost based.  Circular dependency makes complex implementations difficult.  Instead, the scheduler uses simple rules. </p><br><p>  In practice, these rules are not always suitable for production, so you can change the number of worker processes for a particular table: ALTER TABLE ... SET ( <code>parallel_workers = N</code> ). </p><br><h3 id="pochemu-parallelnaya-obrabotka-ne-ispolzuetsya">  Why is parallel processing not used? </h3><br><p>  In addition to a long list of restrictions, there are also cost checks: </p><br><p>  <a href="https://www.postgresql.org/docs/current/runtime-config-query.html"><code>parallel_setup_cost</code></a> - to avoid parallel processing of short requests.  This parameter estimates the time for preparing the memory, starting the process and initial data exchange. </p><br><p>  <a href="https://www.postgresql.org/docs/current/runtime-config-query.html"><code>parallel_tuple_cost</code></a> : the leader‚Äôs communication with the workers may drag in proportion to the number of tuples from workflows.  This parameter considers the cost of data exchange. </p><br><h3 id="soedineniya-vlozhennyh-ciklov--nested-loop-join">  Nested loop connections - Nested Loop Join </h3><br><pre> <code class="plaintext hljs">PostgreSQL 9.6+      ‚Äî   . explain (costs off) select c_custkey, count(o_orderkey) from customer left outer join orders on c_custkey = o_custkey and o_comment not like '%special%deposits%' group by c_custkey; QUERY PLAN -------------------------------------------------------------------------------------- Finalize GroupAggregate Group Key: customer.c_custkey -&gt; Gather Merge Workers Planned: 4 -&gt; Partial GroupAggregate Group Key: customer.c_custkey -&gt; Nested Loop Left Join -&gt; Parallel Index Only Scan using customer_pkey on customer -&gt; Index Scan using idx_orders_custkey on orders Index Cond: (customer.c_custkey = o_custkey) Filter: ((o_comment)::text !~~ '%special%deposits%'::text)</code> </pre> <br><p>  The collection takes place at the last stage, so that Nested Loop Left Join is a parallel operation.  Parallel Index Only Scan appeared only in version 10. It works in the same way as parallel sequential scanning.  Condition <code>c_custkey = o_custkey</code> reads one order for each client line.  So it is not parallel. </p><br><h3 id="hesh-soedinenie--hash-join">  Hash join - Hash Join </h3><br><p>  Each workflow creates its own hash table before PostgreSQL 11. And if there are more than four of these processes, the performance will not increase.  In the new version, the hash table is common.  Each workflow can use WORK_MEM to create a hash table. </p><br><pre> <code class="plaintext hljs">select l_shipmode, sum(case when o_orderpriority = '1-URGENT' or o_orderpriority = '2-HIGH' then 1 else 0 end) as high_line_count, sum(case when o_orderpriority &lt;&gt; '1-URGENT' and o_orderpriority &lt;&gt; '2-HIGH' then 1 else 0 end) as low_line_count from orders, lineitem where o_orderkey = l_orderkey and l_shipmode in ('MAIL', 'AIR') and l_commitdate &lt; l_receiptdate and l_shipdate &lt; l_commitdate and l_receiptdate &gt;= date '1996-01-01' and l_receiptdate &lt; date '1996-01-01' + interval '1' year group by l_shipmode order by l_shipmode LIMIT 1; QUERY PLAN ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- Limit (cost=1964755.66..1964961.44 rows=1 width=27) (actual time=7579.592..7922.997 rows=1 loops=1) -&gt; Finalize GroupAggregate (cost=1964755.66..1966196.11 rows=7 width=27) (actual time=7579.590..7579.591 rows=1 loops=1) Group Key: lineitem.l_shipmode -&gt; Gather Merge (cost=1964755.66..1966195.83 rows=28 width=27) (actual time=7559.593..7922.319 rows=6 loops=1) Workers Planned: 4 Workers Launched: 4 -&gt; Partial GroupAggregate (cost=1963755.61..1965192.44 rows=7 width=27) (actual time=7548.103..7564.592 rows=2 loops=5) Group Key: lineitem.l_shipmode -&gt; Sort (cost=1963755.61..1963935.20 rows=71838 width=27) (actual time=7530.280..7539.688 rows=62519 loops=5) Sort Key: lineitem.l_shipmode Sort Method: external merge Disk: 2304kB Worker 0: Sort Method: external merge Disk: 2064kB Worker 1: Sort Method: external merge Disk: 2384kB Worker 2: Sort Method: external merge Disk: 2264kB Worker 3: Sort Method: external merge Disk: 2336kB -&gt; Parallel Hash Join (cost=382571.01..1957960.99 rows=71838 width=27) (actual time=7036.917..7499.692 rows=62519 loops=5) Hash Cond: (lineitem.l_orderkey = orders.o_orderkey) -&gt; Parallel Seq Scan on lineitem (cost=0.00..1552386.40 rows=71838 width=19) (actual time=0.583..4901.063 rows=62519 loops=5) Filter: ((l_shipmode = ANY ('{MAIL,AIR}'::bpchar[])) AND (l_commitdate &lt; l_receiptdate) AND (l_shipdate &lt; l_commitdate) AND (l_receiptdate &gt;= '1996-01-01'::date) AND (l_receiptdate &lt; '1997-01-01 00:00:00'::timestamp without time zone)) Rows Removed by Filter: 11934691 -&gt; Parallel Hash (cost=313722.45..313722.45 rows=3750045 width=20) (actual time=2011.518..2011.518 rows=3000000 loops=5) Buckets: 65536 Batches: 256 Memory Usage: 3840kB -&gt; Parallel Seq Scan on orders (cost=0.00..313722.45 rows=3750045 width=20) (actual time=0.029..995.948 rows=3000000 loops=5) Planning Time: 0.977 ms Execution Time: 7923.770 ms</code> </pre> <br><p>  Request 12 of TPC-H clearly shows a parallel hash connection.  Each workflow is involved in creating a shared hash table. </p><br><h3 id="soedinenie-sliyaniem--merge-join">  Merge Join </h3><br><p>  A merge join is non-parallel in nature.  Do not worry if this is the last stage of the request - it can still be executed in parallel. </p><br><pre> <code class="plaintext hljs">-- Query 2 from TPC-H explain (costs off) select s_acctbal, s_name, n_name, p_partkey, p_mfgr, s_address, s_phone, s_comment from part, supplier, partsupp, nation, region where p_partkey = ps_partkey and s_suppkey = ps_suppkey and p_size = 36 and p_type like '%BRASS' and s_nationkey = n_nationkey and n_regionkey = r_regionkey and r_name = 'AMERICA' and ps_supplycost = ( select min(ps_supplycost) from partsupp, supplier, nation, region where p_partkey = ps_partkey and s_suppkey = ps_suppkey and s_nationkey = n_nationkey and n_regionkey = r_regionkey and r_name = 'AMERICA' ) order by s_acctbal desc, n_name, s_name, p_partkey LIMIT 100; QUERY PLAN ---------------------------------------------------------------------------------------------------------- Limit -&gt; Sort Sort Key: supplier.s_acctbal DESC, nation.n_name, supplier.s_name, part.p_partkey -&gt; Merge Join Merge Cond: (part.p_partkey = partsupp.ps_partkey) Join Filter: (partsupp.ps_supplycost = (SubPlan 1)) -&gt; Gather Merge Workers Planned: 4 -&gt; Parallel Index Scan using &lt;strong&gt;part_pkey&lt;/strong&gt; on part Filter: (((p_type)::text ~~ '%BRASS'::text) AND (p_size = 36)) -&gt; Materialize -&gt; Sort Sort Key: partsupp.ps_partkey -&gt; Nested Loop -&gt; Nested Loop Join Filter: (nation.n_regionkey = region.r_regionkey) -&gt; Seq Scan on region Filter: (r_name = 'AMERICA'::bpchar) -&gt; Hash Join Hash Cond: (supplier.s_nationkey = nation.n_nationkey) -&gt; Seq Scan on supplier -&gt; Hash -&gt; Seq Scan on nation -&gt; Index Scan using idx_partsupp_suppkey on partsupp Index Cond: (ps_suppkey = supplier.s_suppkey) SubPlan 1 -&gt; Aggregate -&gt; Nested Loop Join Filter: (nation_1.n_regionkey = region_1.r_regionkey) -&gt; Seq Scan on region region_1 Filter: (r_name = 'AMERICA'::bpchar) -&gt; Nested Loop -&gt; Nested Loop -&gt; Index Scan using idx_partsupp_partkey on partsupp partsupp_1 Index Cond: (part.p_partkey = ps_partkey) -&gt; Index Scan using supplier_pkey on supplier supplier_1 Index Cond: (s_suppkey = partsupp_1.ps_suppkey) -&gt; Index Scan using nation_pkey on nation nation_1 Index Cond: (n_nationkey = supplier_1.s_nationkey)</code> </pre> <br><p>  The "Merge Join" node is located above the "Gather Merge".  So the merge does not use parallel processing.  But the "Parallel Index Scan" node still helps with the <code>part_pkey</code> segment. </p><br><h3 id="soedinenie-po-sekciyam">  Section Connection </h3><br><p>  In PostgreSQL 11 <a href="http://ashutoshpg.blogspot.com/2017/12/partition-wise-joins-divide-and-conquer.html">, sectional connection is</a> disabled by default: it has very expensive scheduling.  Tables with similar partitioning can be joined section by section.  So Postgres will use smaller hash tables.  Each section connection may be parallel. </p><br><pre> <code class="plaintext hljs">tpch=# set enable_partitionwise_join=t; tpch=# explain (costs off) select * from prt1 t1, prt2 t2 where t1.a = t2.b and t1.b = 0 and t2.b between 0 and 10000; QUERY PLAN --------------------------------------------------- Append -&gt; Hash Join Hash Cond: (t2.b = t1.a) -&gt; Seq Scan on prt2_p1 t2 Filter: ((b &gt;= 0) AND (b &lt;= 10000)) -&gt; Hash -&gt; Seq Scan on prt1_p1 t1 Filter: (b = 0) -&gt; Hash Join Hash Cond: (t2_1.b = t1_1.a) -&gt; Seq Scan on prt2_p2 t2_1 Filter: ((b &gt;= 0) AND (b &lt;= 10000)) -&gt; Hash -&gt; Seq Scan on prt1_p2 t1_1 Filter: (b = 0) tpch=# set parallel_setup_cost = 1; tpch=# set parallel_tuple_cost = 0.01; tpch=# explain (costs off) select * from prt1 t1, prt2 t2 where t1.a = t2.b and t1.b = 0 and t2.b between 0 and 10000; QUERY PLAN ----------------------------------------------------------- Gather Workers Planned: 4 -&gt; Parallel Append -&gt; Parallel Hash Join Hash Cond: (t2_1.b = t1_1.a) -&gt; Parallel Seq Scan on prt2_p2 t2_1 Filter: ((b &gt;= 0) AND (b &lt;= 10000)) -&gt; Parallel Hash -&gt; Parallel Seq Scan on prt1_p2 t1_1 Filter: (b = 0) -&gt; Parallel Hash Join Hash Cond: (t2.b = t1.a) -&gt; Parallel Seq Scan on prt2_p1 t2 Filter: ((b &gt;= 0) AND (b &lt;= 10000)) -&gt; Parallel Hash -&gt; Parallel Seq Scan on prt1_p1 t1 Filter: (b = 0)</code> </pre> <br><p>  The main thing is that the connection in sections is parallel only if these sections are large enough. </p><br><h3 id="parallelnoe-dopolnenie--parallel-append">  Parallel addition - Parallel Append </h3><br><p>  <a href="https://www.postgresql.org/docs/11/parallel-plans.html">Parallel Append</a> can be used instead of different blocks in different workflows.  This is usually the case with UNION ALL queries.  The disadvantage is less concurrency, because each workflow processes only 1 request. </p><br><p>  2 workflows are running here, although 4 is included. </p><br><pre> <code class="plaintext hljs">tpch=# explain (costs off) select sum(l_quantity) as sum_qty from lineitem where l_shipdate &lt;= date '1998-12-01' - interval '105' day union all select sum(l_quantity) as sum_qty from lineitem where l_shipdate &lt;= date '2000-12-01' - interval '105' day; QUERY PLAN ------------------------------------------------------------------------------------------------ Gather Workers Planned: 2 -&gt; Parallel Append -&gt; Aggregate -&gt; Seq Scan on lineitem Filter: (l_shipdate &lt;= '2000-08-18 00:00:00'::timestamp without time zone) -&gt; Aggregate -&gt; Seq Scan on lineitem lineitem_1 Filter: (l_shipdate &lt;= '1998-08-18 00:00:00'::timestamp without time zone)</code> </pre> <br><h3 id="samye-vazhnye-peremennye">  The most important variables </h3><br><ul><li>  WORK_MEM limits the amount of memory for each process, not only for requests: work_mem connection <em>processes</em> = a lot of memory. </li><li>  <a href="https://www.postgresql.org/docs/11/runtime-config-resource.html"><code>max_parallel_workers_per_gather</code></a> ‚Äî how many worker processes the executing program will use for parallel processing from the plan. </li><li>  <a href="https://www.postgresql.org/docs/11/runtime-config-resource.html"><code>max_worker_processes</code></a> - adjusts the total number of worker processes to the number of CPU cores on the server. </li><li>  <a href="https://www.postgresql.org/docs/11/runtime-config-resource.html"><code>max_parallel_workers</code></a> - the same, but for parallel workflows. </li></ul><br><h3 id="itogi">  Results </h3><br><p>  Starting from version 9.6, parallel processing can significantly improve the performance of complex queries that scan multiple rows or indexes.  PostgreSQL 10 has parallel processing enabled by default.  Do not forget to disable it on servers with a large OLTP workload.  Sequential scans or index scans consume a lot of resources.  If you do not run a report on the entire data set, queries can be made more efficient simply by adding the missing indexes or using the correct partitioning. </p><br><h3 id="ssylki">  Links </h3><br><ul><li>  <a href="https://www.postgresql.org/docs/11/how-parallel-query-works.html">https://www.postgresql.org/docs/11/how-parallel-query-works.html</a> </li><li>  <a href="https://www.postgresql.org/docs/11/parallel-plans.html">https://www.postgresql.org/docs/11/parallel-plans.html</a> </li><li>  <a href="http://ashutoshpg.blogspot.com/2017/12/partition-wise-joins-divide-and-conquer.html">http://ashutoshpg.blogspot.com/2017/12/partition-wise-joins-divide-and-conquer.html</a> </li><li>  <a href="http://rhaas.blogspot.com/2016/04/postgresql-96-with-parallel-query-vs.html">http://rhaas.blogspot.com/2016/04/postgresql-96-with-parallel-query-vs.html</a> </li><li>  <a href="http://amitkapila16.blogspot.com/2015/11/parallel-sequential-scans-in-play.html">http://amitkapila16.blogspot.com/2015/11/parallel-sequential-scans-in-play.html</a> </li><li>  <a href="https://write-skew.blogspot.com/2018/01/parallel-hash-for-postgresql.html">https://write-skew.blogspot.com/2018/01/parallel-hash-for-postgresql.html</a> </li><li>  <a href="http://rhaas.blogspot.com/2017/03/parallel-query-v2.html">http://rhaas.blogspot.com/2017/03/parallel-query-v2.html</a> </li><li>  <a href="https://blog.2ndquadrant.com/parallel-monster-benchmark/">https://blog.2ndquadrant.com/parallel-monster-benchmark/</a> </li><li>  <a href="https://blog.2ndquadrant.com/parallel-aggregate/">https://blog.2ndquadrant.com/parallel-aggregate/</a> </li><li>  <a href="https://www.depesz.com/2018/02/12/waiting-for-postgresql-11-support-parallel-btree-index-builds/">https://www.depesz.com/2018/02/12/waiting-for-postgresql-11-support-parallel-btree-index-builds/</a> </li><li>  <a href="https://youtu.be/jWIOZzezbb8">Concurrency in PostgreSQL 11</a> </li></ul></div>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <p>Source: <a href="https://habr.com/ru/post/446706/">https://habr.com/ru/post/446706/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../446690/index.html">Electrolux has released a smart air cleaner for the most polluted cities</a></li>
<li><a href="../446694/index.html">JBOD modular storage and degrees of freedom</a></li>
<li><a href="../446696/index.html">Myths about 152-FZ, which can be costly for the operator of personal data</a></li>
<li><a href="../446702/index.html">And one more strange headphones - for sleeping</a></li>
<li><a href="../446704/index.html">The path of the programmer from working at the factory with a salary of 800 UAH to ‚Ç¨‚Ç¨‚Ç¨‚Ç¨ in top companies in Ukraine</a></li>
<li><a href="../446708/index.html">Comparison of space communication systems</a></li>
<li><a href="../446710/index.html">Four real histories of working with microservice architecture - report from the Backend United mitap 3: Kholodets</a></li>
<li><a href="../446712/index.html">HTTPS is not always as secure as it seems. Vulnerabilities found in 5.5% of HTTPS sites</a></li>
<li><a href="../446714/index.html">Curious perversions from the IT world - 4</a></li>
<li><a href="../446716/index.html">Consciousness and Doomsday Argument</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>