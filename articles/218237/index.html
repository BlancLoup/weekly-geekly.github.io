<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Creating a hosting site based on Proxmox + HP ProLiant</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Good time of day. 

 So, turned to me with the task of moving to your own server from three VPS about 100 sites, including news with a MySQL database ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Creating a hosting site based on Proxmox + HP ProLiant</h1><div class="post__text post__text-html js-mediator-article">  Good time of day. <br><br>  So, turned to me with the task of moving to your own server from three VPS about 100 sites, including news with a MySQL database of about 20 GB in size, and the total weight of small (mostly) files hosted about 500 GB. <br>  The server itself was installed without my participation in the provider‚Äôs rack, two IP addresses were given - access to the server‚Äôs admin panel and hosting IP address. <br>  Pictures to attract attention: <br><img src="https://habrastorage.org/getpro/habr/post_images/b4f/46c/27c/b4f46c27c5cf5e5eedfc1768344ea74e.png" alt="image"><img src="https://habrastorage.org/getpro/habr/post_images/94f/535/33e/94f53533e6650b7e97ff72040679fd0f.jpg" alt="image"><br><a name="habracut"></a><br>  Server configuration: <br><br><blockquote>  Proc 1: 2267 MHz <br>  Execution technology: 6/6 cores;  12 maximum threads <br>  Memory technology: 64-bit capable <br>  Processor 1 Internal L1 Cache: 192 KB <br>  Processor 1 Internal L2 Cache: 1536 KB <br>  Processor 1 Internal L3 Cache: 12288 KB <br>  Proc 2: 2267 MHz <br>  Execution technology: 6/6 cores;  12 maximum threads <br>  Memory technology: 64-bit capable <br>  Processor 2 Internal L1 Cache: 192 KB <br>  Processor 2 Internal L2 Cache: 1536 KB <br>  Processor 2 Internal L3 Cache: 12288 KB 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      HDD: <br>  1 PLEXTOR PX-256M <br>  2 WDC WD1000DHTZ <br><br>  Ram <br>  PROC 1 DIMM 4B: 16384 MB 1333 MHz <br>  PROC 1 DIMM 6C: 16384 MB 1333 MHz <br>  PROC 2 DIMM 4B: 16384 MB 1333 MHz <br>  PROC 2 DIMM 6C: 16384 MB 1333 MHz <br></blockquote><br><br>  At the desired on the server: <br>  1. Windows 2012 Server for some purposes related to 1C. <br>  2. Primary hosting (high load). <br>  3. Test machine <br><br><blockquote>  During the setup process, he convinced the owners to purchase another IP address for the test machine. </blockquote><br>  Two licenses of ISP Panel for main hosting and test hosting have been purchased. <br><br>  Actually with the choice of * nix OS there were no options, insisted on CentOS 6. <br><br>  The admin panel of the server was pleasantly struck - everything is convenient, understandable. <br>  So, virtualization (based on the tasks) decided to do on ProxMox, for which I swung the <a href="http://www.proxmox.com/ru/downloads">disk image</a> . <br>  In the admin, I hooked the image from my machine, like an image of a CD in the virtual media section.  I was surprised that the image was not uploaded to the server, but was pulled straight from my machine as it was loaded.  The entire installation process took about 1.5 hours.  I have a channel of 60 MB, but there are still people <s>working</s> watching online and downloading media files. <br>  What should be noted: proxmox is installed on ssd, the disk partitioning is at the mercy of the installation, everything is ‚Äúdefault‚Äù.  That is, WD has remained pristine-clean. <br>  As a result, on the IP address of the hosting we have the Proxmox admin area at: <a href="https://ip/">IP</a> : 8006 /. <br>  It has to be said that it was limited in time, so I didn‚Äôt pick around with the ‚ÄúCT‚Äù machines, tried to pour the CentOS template on and off, and only showed a black screen.  I must say that before that I raised the templates for the CT machines on my local server.  IMHO their advantage - access to all server resources. <br><br>  Fill in the car image of CentOS.  There was some inconvenience from ProxMox - you can swing the image not by reference, but only on your hard drive.  So I had to pour it to myself first, then pour it onto the server. <br><br>  With WD (/ dev / sdb), which should be the main repository, I entered the following way in the Proxmox console under the article <a href="http://habrahabr.ru/post/67283/">from here</a> : <br><br><pre><code class="bash hljs">0. aptitude update &amp;&amp; aptitude upgrade 1. pvcreate /dev/sdb 2. vgcreate ws /dev/sdb 3. lvcreate -n data -L980G ws ( 980    ,       10 ) 4. mkfs.ext4 -L data /dev/ws/data        ,   ,    0   1   aptitude install screen.   4   : screen -dmS createfs mkfs.ext4 -L data /dev/ws/data 5. <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">"/dev/ws/data /var/lib/ws ext4 defaults 0 1"</span></span> &gt;&gt; /etc/fstab 6. mount -a</code> </pre> <br><br>  Thus, I received additional storage for virtual disks of machines. <br>  But it was decided to place the swap files on ssd.  About this below. <br><br>  About setting permissions.  Since the user will not root, then we start it and give access rights to the storage and machines.  To do this, I went to the data center, the group tab, created the group ‚Äúusers‚Äù.  Entered the user into the group ‚Äúusers‚Äù, in the users tab. <br>  It should be noted that if we go rooting, then in the authorization form of Proxmox, you need to select OS authorization - ‚Äúpam‚Äù, I already started the user with authorization directly from the proxmox user base, so when entering, you must select the authorization type ‚Äúpve‚Äù. <br>  Just another ‚ÄúSJ‚Äù in the direction of the creators of Proxmox - would fasten the generation of passwords in the admin panel, it is inconvenient to have more than one user. <br>  Go to the Data Center, the Permissions tab and add the ‚Äúusers‚Äù group admin rights (well, the owners) to access the ws storage and create virtual machines.  For now enough. <br><br>  At first I decided to create a test hosting machine.  Create a VM "tests" (machine 100) with the following characteristics: <br>  4 GB RAM;  default processor kvm64, CD - drive CentOS image, HDD - disk image from vmvare (vmdk), write back caching, 120 Gb on storage ws, network Intel on bridge vmbr0.  I‚Äôll tell you about the network functions just below when we will be hosting for work sites. <br>  We set centos, we catch repositories, we are updated, we put mc.  atop, set up resolv.conf and so on.  This stopped the virtual machine thought. <br>  Since I spent an hour installing the OS image, I decided to optimize this process for the following n-machines.  Therefore, the console went / var / lib / ws / images / 100, and copied the vmdk disk image in the folder / home <br>  Set the ip address of the eth0 interface of the virtual machine (for now from the proxmox console). <br><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> /etc/sysconfig/network-scripts cat ifcfg-eth0 DEVICE=eth0 HWADDR= ( mak ,     proxmox) TYPE=Ethernet ONBOOT=yes NM_CONTROLLED=yes BOOTPROTO=none IPADDR=&lt;,   &gt; NETMASK= &lt;,   &gt; GATEWAY= &lt;,   &gt; DNS1=8.8.8.8 DNS2=8.8.4.4 service network restart</code> </pre><br><br>  Next, from the ISPmanager site, <a href="http://ru.ispdoc.com/index.php/%25D0%25A3%25D1%2581%25D1%2582%25D0%25B0%25D0%25BD%25D0%25BE%25D0%25B2%25D0%25BA%25D0%25B0_ISPmanager_(ISPmanager)">the installation section</a> expands the necessary services.  Some time has passed, the car took off, earned.  I did not touch anything in konfy, I left everything by default. <br><br>  As for the proxmox options for a virtual machine, it is necessary to make a reservation: <br>  1. Run at boot - put "Yes" or "No" by hand.  By default, "No", be careful. <br>  2. CPU units is a completely obscure thing, which nevertheless affects the performance of virtualoks.  Went the following way: <br><br><pre> <code class="bash hljs">vzcpucheck   proxmox. vzcpucheck Current CPU utilization: 4000 OpenVZ VM is getting 1000 divided by 906755 and multiplied by 100 = 0.1% of the CPU time So <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> I want to give 5 percent of guaranteed time to my VPS, I would enter CPU Units = 45337</code> </pre><br><br>  I must say for each created machine did just that - CPU Units = 45000. <br><br>  What to do with a highly loaded hosting thought matured for a long time: <br>  Create virtualok on the principle of one server - one service.  In addition, since we have proxmox external IP hosting, then we will ipfirewall to make connections to the machines we need.  We also create an ‚Äúinternal‚Äù grid, for example, 192.168.12.0/24. <br>  In Proxmox for this, I decided to raise the dummy interface: <br><br><pre> <code class="bash hljs">modprobe dummy</code> </pre><br>  Next in the admin area of ‚Äã‚ÄãProxmox, Data Center - Network create vmbr1 (bridge) based on the dummy interface. <br>  We set the ip address of proxmox 192.168.12.1.  The preparation is done. <br>  Go. <br>  1 machine: mysql (vm101).  It was found out experimentally that a database of such a volume of data (20GB) well exists on 27 GB of RAM.  The processor 4 sockets on 3 kernels.  But hard cling like the car number 1.  When Proxmox creates a machine, I copy the hdd image of the first CentOS from / home (if you remember, the network and hostname are not configured there, but everything is updated and ready to start).  Network card on bridge vmbr1 <br>  Configure the network interface.  Since we have eth0 left on the test machine, we need to create the ifcfg-eth1 file in / etc / sysconfig / network-scripts with the following content: <br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> /etc/sysconfig/network-scripts cat ifcfg-eth1 DEVICE=eth1 HWADDR= ( mak ,     proxmox) TYPE=Ethernet ONBOOT=yes NM_CONTROLLED=yes BOOTPROTO=none IPADDR=192.168.12.10 NETMASK= 255.255.255.0 GATEWAY= 192.168.12.1 DNS1=8.8.8.8 DNS2=8.8.4.4 service network restart</code> </pre><br><br>  We <a href="http://www.percona.com/doc/percona-server/5.5/installation/yum_repo.html">put the necessary Percona repository</a> and Percona itself. <br><div class="spoiler">  <b class="spoiler_title">The mysql configuration file was cited below (it partially moved from the old server, was partially optimized):</b> <div class="spoiler_text"><pre> <code class="bash hljs">cat my.cnf [mysqld] user=mysql skip-external-locking low-priority-updates port= 3306 wait_timeout = 120 <span class="hljs-comment"><span class="hljs-comment">#     #innodb_force_recovery = 5 datadir=/var/lib/mysql socket=/var/lib/mysql/mysql.sock symbolic-links=0 key_buffer = 256M key_buffer_size = 256M max_allowed_packet = 4M thread_stack = 2048K thread_cache_size = 8086 thread_concurrency = 8 query_cache_limit = 1G query_cache_size = 1G #myisam-recover = BACKUP max_connections = 1400 table_definition_cache = 8000 join_buffer_size =4M tmp_table_size = 768M max_heap_table_size = 768M max_tmp_tables = 500 character-set-server = utf8 expire_logs_days=2 innodb_data_home_dir=/var/lib/mysql innodb_data_file_path=ibdata1:10M:autoextend innodb_log_group_home_dir = /var/lib/mysql innodb_file_per_table=1 # You can set .._buffer_pool_size up to 50 - 80 % # of RAM but beware of setting memory usage too high innodb_open_files=1200 innodb_buffer_pool_size = 22G innodb_buffer_pool_instances = 22 innodb_additional_mem_pool_size = 512M # Set .._log_file_size to 25 % of buffer pool size innodb_log_file_size = 64M innodb_log_buffer_size = 4M innodb_lock_wait_timeout = 50 innodb_flush_log_at_trx_commit = 2 innodb_flush_method=O_DIRECT innodb_doublewrite=0 innodb_support_xa=0 innodb_checksums=0 innodb_io_capacity = 120 max-connect-errors = 10000 back_log = 500 binlog_cache_size = 1M sync_binlog = 0 key_cache_division_limit=70 [mysqld_safe] log-error=/var/log/mysqld.log pid-file=/var/run/mysqld/mysqld.pid [myisamchk] key_buffer_size = 128M sort_buffer_size = 128M read_buffer = 64M write_buffer = 64M key_cache_division_limit=70</span></span></code> </pre><br>  As for all kinds of meanings, this is the topic of a separate article, which may appear later.  Therefore, I bring the fruit of my raids on MySQL as is, without comment. <br></div></div><br><br>  As for installing nginx as a proxy for apache, <a href="https://www.google.ru/search%3Fq%3Dnginx%2Bproxy%2Bapache%26oq%3Dnginx%2Bprox%26aqs%3Dchrome.4.69i57j0l5.8473j0j7%26sourceid%3Dchrome%26espv%3D210%26es_sm%3D122%26ie%3DUTF-8">there are a lot of articles on this topic</a> .  Plus, in the same virtual machine I get Exim + dovecot with a base in MySQL. <br>  Nginx virtual machine (vm102).  The disk image is also copied after creating the virtual machine.  CPU 3 sockets, 3 cores;  4 GB RAM.  Network card on the bridge vmbr1. <br><div class="spoiler">  <b class="spoiler_title">I will give nginx config.</b> <div class="spoiler_text"><pre> <code class="bash hljs">cat nginx.conf user nginx; worker_processes 6; <span class="hljs-comment"><span class="hljs-comment">#  ,    ,   . #worker_processes auto; #worker_cpu_affinity 010000 100000 001000 000100 000010 000001; error_log /var/log/nginx/error.log; pid /var/run/nginx.pid; events { worker_connections 2048; } http { include /etc/nginx/mime.types; default_type text/html; access_log /var/log/nginx/access.log; sendfile on; keepalive_timeout 20; tcp_nodelay on; gzip on; gzip_comp_level 2; gzip_proxied any; gzip_types text/plain text/css application/x-javascript text/xml application/xml application/xml+rss text/javascript; client_max_body_size 64m; include /etc/nginx/conf.d/*; } cd /etc/nginx/conf.d cat default server { listen *:80; ## listen for ipv4; this line is default and implied access_log /var/log/nginx/access.log; location /nginx_status { stub_status on; access_log off; allow 127.0.0.1; deny all; } server_name nginx.xxx.ru; location / { proxy_pass http://192.168.12.20:80/; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $remote_addr; proxy_connect_timeout 60; proxy_send_timeout 60; proxy_read_timeout 90; } }</span></span></code> </pre><br>  192.168.12.20 - apache address with ISPManager <br>  192.168.12.30 - the address of nginx (and exim), that is, a machine that looks into the network, which will turn traffic on the ports http / https / mail <br></div></div><br><br>  Create apache (vm103).  CPU 4 sockets with 2 cores, 16 GB RAM, 1st HDD 120 Gb for the finished image, second HDD 500Gb for sites, Network interface card on the bridge vmbr1.  Pouring an image of an already installed CentOS, configure it: <br><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> /etc/sysconfig/network-scripts cat ifcfg-eth1 DEVICE=eth1 HWADDR= ( mak ,     proxmox) TYPE=Ethernet ONBOOT=yes NM_CONTROLLED=yes BOOTPROTO=none IPADDR=192.168.12.20 NETMASK= 255.255.255.0 GATEWAY= 192.168.12.1 DNS1=8.8.8.8 DNS2=8.8.4.4 service network restart</code> </pre><br><br>  How do we install ISPManager on a hosting located inside a local network?  Nothing smarter came to mind except how to set the other IP address available to us for ProxMox - from the machine tests, the tests to the car, disable autorun, and temporarily transfer the network interface to the vmbr0 bridge.  After the reboot Proxmox, inside the apache machine (vm103): <br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> /etc/sysconfig/network-scripts cat ifcfg-eth1 DEVICE=eth1 HWADDR= ( mak ,     proxmox) TYPE=Ethernet ONBOOT=yes NM_CONTROLLED=yes BOOTPROTO=none IPADDR=&lt;,   &gt; NETMASK= &lt;,   &gt; GATEWAY= &lt;,   &gt; DNS1=8.8.8.8 DNS2=8.8.4.4 service network restart</code> </pre><br><br>  We cling HDD 500 GB on / var / www: <br><br><pre> <code class="bash hljs">fdisk /dev/sdb &lt;&lt;    &gt;&gt; mkfs.ext4 -L data /dev/sdb1 <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">"/dev/sdb1 /var/www ext4 defaults 0 1"</span></span> &gt;&gt; /etc/fstab 6. mount -a</code> </pre><br><br>  Next, from the ISPmanager site, <a href="http://ru.ispdoc.com/index.php/%25D0%25A3%25D1%2581%25D1%2582%25D0%25B0%25D0%25BD%25D0%25BE%25D0%25B2%25D0%25BA%25D0%25B0_ISPmanager_(ISPmanager)">the installation section</a> expands the necessary services. <br>  Turning off Posfix, courier (we have the same mailer is not here), other unnecessary services to taste.  Turn off mysql, tell ISPmanager that the mysql server is on a different machine.  This is done from ISPManager in the MySQL section. <br>  We return the settings as it was (apache vmbr1, 192.168.12.20; tests autostart at boot; proxmox ip is the address of the hosting). <br>  In proxmox (192.168.12.1; &lt;Real IP&gt;) I add a port 1500 forwarding (admin panel ISPManager) to apc.c (192.168.12.20), forcing ssh to virtualkam, port forwarding for nginx to rc.local: <br><pre> <code class="bash hljs">cat /etc/rc.local /sbin/iptables -F /sbin/iptables -X /sbin/iptables -t nat -A PREROUTING -p tcp -d &lt; IP&gt; --dport 22003 -j DNAT --to-destination 192.168.12.10:22003 /sbin/iptables -t nat -A PREROUTING -p tcp -d &lt; IP&gt; --dport 22002 -j DNAT --to-destination 192.168.12.20:22002 /sbin/iptables -t nat -A PREROUTING -p tcp -d &lt; IP&gt; --dport 22004 -j DNAT --to-destination 192.168.12.30:22004 /sbin/iptables -t nat -A PREROUTING -p tcp -d &lt; IP&gt; --dport 1500 -j DNAT --to-destination 192.168.12.20:1500 <span class="hljs-comment"><span class="hljs-comment">#nginx /sbin/iptables -t nat -A PREROUTING -p tcp -d &lt; IP&gt; --dport 80 -j DNAT --to-destination 192.168.12.30:80 /sbin/iptables -t nat -A PREROUTING -p tcp -d &lt; IP&gt; --dport 445 -j DNAT --to-destination 192.168.12.30:445 /sbin/iptables -t nat -A PREROUTING -p tcp -d &lt; IP&gt; --dport 443 -j DNAT --to-destination 192.168.12.30:443 /sbin/iptables -t nat -A PREROUTING -p tcp -d &lt; IP&gt; --dport 25 -j DNAT --to-destination 192.168.12.30:25 /sbin/iptables -t nat -A PREROUTING -p tcp -d &lt; IP&gt; --dport 110 -j DNAT --to-destination 192.168.12.30:110</span></span></code> </pre><br><br>  As for the launch of IPSManager, which requires an ip on the local machine to which the license is attached, I also decided through the dummy interface.  I give him the necessary ip address, then I do ifconfig dummy down.  Previously, I did not do this, but the sites are set up so that they take pictures for display at the address of <a href="http://xn--h1ai1d/">the</a> site <a href="http://xn--h1ai1d/">name</a> / images / ... / ... / ... jpg. <br>  Therefore, if the interface is not extinguished, then it is <br><pre> <code class="bash hljs">nslookup &lt; &gt;  &lt;ip &gt; -    IP ? -  httpd. -    ,     -  .     ,  .     .</code> </pre><br><br>  He promised to tell you about the swap partition on the SSD disk.  It's all quite simple, create a disk image in the default repository, where Proxmox was actually put.  Set the required image size.  Then we connect the sections as follows: <br><br><pre> <code class="bash hljs">mkswap /dev/sd&lt; &gt; cat /proc/swaps swapoff -v /dev/sda&lt;  &gt; (   swap swapon /dev/sd&lt; &gt;</code> </pre><br><br>  Finally, I‚Äôll give fstab machines with apache (there‚Äôs the most virtual disks). <br><br><pre> <code class="bash hljs"> cat /etc/fstab <span class="hljs-comment"><span class="hljs-comment"># # /etc/fstab # Created by anaconda on Tue Mar 11 15:57:46 2014 # # Accessible filesystems, by reference, are maintained under '/dev/disk' # See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info # /dev/mapper/VolGroup-lv_root / ext4 defaults 1 1 UUID=43977fc1-b315-4c84-8d4e-147f4063a60e /boot ext4 defaults 1 2 /dev/mapper/VolGroup-lv_home /home ext4 defaults 1 2 /dev/sdc swap swap defaults 0 0 tmpfs /dev/shm tmpfs defaults 0 0 devpts /dev/pts devpts gid=5,mode=620 0 0 sysfs /sys sysfs defaults 0 0 proc /proc proc defaults 0 0 /dev/sdb1 /var/www ext4 defaults 1 2 noatime,nodiratime,noacl,data=writeback,commit=15</span></span></code> </pre><br><br>  Notice the last line of the fstab file.  Significantly accelerated the work of the file system by installing after 1 2. Before that, I dug all kinds of forums for a long time and made such a line from what I‚Äôve dug up.  Hodgepodge, so to speak. <br><br>  In principle, one way or another, everything works and has been flying for 2 weeks, that is, the test period has passed. <br>  As for the backup (BACKUP), I suggested to go in a very simple way - take the WD Live Book gig that way for 3, enable ftp on it and pour snapshots of virtual machines there that ProxMox successfully creates. <br>  As for passive FTP forwarding, I have not done it yet.  The point is that it is necessary to forward ports 20, 21 on apache and a certain number of ports for a passive connection, but I do not get this forwarding.  Well, ftp from outside does not cling to my server in any way.  It does not burn yet, so I decide as inspiration comes.  I would appreciate a hint.  There is a proftpd server.  The idea was as follows - it is hard to set up a port pool for passive FTP mode in the config, and forward it inside from ProxMox.  Not yet got to know how it is done. <br><br>  Thanks for attention! <br>  PS Here they write that I can not edit this article, I read 30 minutes, everything seems to be clean.  I apologize for the voluntary and involuntary vulgarisms in the text, errors or typos. </div><p>Source: <a href="https://habr.com/ru/post/218237/">https://habr.com/ru/post/218237/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../218225/index.html">Micro ORM one class</a></li>
<li><a href="../218227/index.html">Autoconfiguration (Auto Setup) of Polycom Phones Using Asterisk</a></li>
<li><a href="../218229/index.html">Compile life</a></li>
<li><a href="../218231/index.html">SaltStack: managing an arbitrary number of configuration files</a></li>
<li><a href="../218233/index.html">LPC1102 and warm lamp indicator</a></li>
<li><a href="../218241/index.html">Happy webmasters!</a></li>
<li><a href="../218243/index.html">Big data and their storage</a></li>
<li><a href="../218245/index.html">How do we do trello</a></li>
<li><a href="../218247/index.html">How is coworking useful?</a></li>
<li><a href="../218249/index.html">SaltStack: using jinja templates and pillar storage for flexible configuration settings</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>