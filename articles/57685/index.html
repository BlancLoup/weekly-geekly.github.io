<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Simulation of view. Part six. Eye tracking modeling</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="1 Excursion in the eye - 2 Perception - 3 Geometry of view - 4 Eye tracking - 5 How to catch the eye - 6 Simulation of eye tracking 

 The sixth part,...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Simulation of view. Part six. Eye tracking modeling</h1><div class="post__text post__text-html js-mediator-article">  <sup><a href="http://geektimes.ru/post/57679/">1 Excursion in the eye</a> - <a href="http://geektimes.ru/post/57681/">2 Perception</a> - <a href="http://geektimes.ru/post/57682/">3 Geometry of view</a> - <a href="http://geektimes.ru/post/57683/">4 Eye tracking</a> - <a href="http://geektimes.ru/post/57684/">5 How to catch the eye</a> - <b>6 Simulation of eye tracking</b></sup> <br><br>  The sixth part, the final.  The story is directly about the principles of eye tracking modeling, as well as it can be applied to real life.  In this part, at last, the numbers and principles illuminated in the <a href="http://ymik.habrahabr.ru/blog/57682/">third</a> , <a href="http://ymik.habrahabr.ru/blog/57683/">fourth</a> and <a href="http://ymik.habrahabr.ru/blog/57684/">fifth</a> posts will be useful. <br><a name="habracut"></a><br><h2>  Which eye tracking models are of interest? </h2><br>  As described in the fourth part, there is a direct link between the time spent viewing the region of the image and the degree of attention given to the same region by human consciousness.  At a minimum, if a person is not aware of what he was looking at, then he will remember something for sure! <br><br>  Therefore, one of the types of modeling is the creation of a thermal map of the viewing time or information about what potential for a long study any region of the image has. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Another interesting type of model is the dynamics of saccades: a diagram showing at what point a person‚Äôs gaze darts, if he now looks at the current one.  Analyzing this type of diagrams, it is possible to understand which parts of the image appear to be the most important when viewed.  Combining the diagram of the dynamics with the heat map, it is possible to understand which side details can distract a person‚Äôs gaze from what he considers most important. <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/505/346/8cb/5053468cb4fec6eff8efdda0a1dd3205.jpg"><br><br><h2>  Limits of applicability of modeling </h2><br><br>  <b>Only psychologically neutral images respond well to saccade modeling</b> : emotionally colored pictures displace attention centers considerably.  For example, when viewing a crying child, the gaze of a person will inevitably pay more attention to the study of facial expressions than to side contours. <br><br>  The same factor means that a person‚Äôs view is exclusively individual: if a particular person is not indifferent to pigeons, then when viewing a photo with pigeons he will undoubtedly move the view differently than a person indifferent to birds. <br><br>  <b>The presence in the picture (even if it is psychologically neutral) of small, but recognizable contours (faces of people, text characters, etc.) pose to the task of preliminary recognition of the patterns of these contours.</b>  In the program that prompted the writing of this manual, there is no recognition at all, but there is only an assessment of the complexity of the perception of the contour.  But the conclusion that the <b>quality of pattern recognition significantly improves the compliance of the model with the data obtained on real eye tracking, and the absence can lead to fatal inconsistencies</b> necessary to do. <br><br>  <b>Simulation works well for picture viewing situations without any goal, without a job received.</b>  In the case of viewing images with a specific goal, the role of pattern recognition, which affects the power of perception of contours, increases. <br><br><h2>  Where can this be applicable? </h2><br><br>  When familiarizing with the limits of applicability of models, a logical question arises: "And where is this, with such restrictions, applicable in real life?" <br><br>  And it is <b>applicable in a wide class of tasks, primarily related to text analysis</b> .  As you know, the perception of the text is strongly influenced by its formatting, the amount of empty spaces between paragraphs, words and symbols, font style, etc. <br><br>  The text initially, prior to processing, is seen as a psychologically neutral picture, ideally suited for analysis by the methods of saccade modeling.  The same heat map shows which words, paragraphs, and other text units are most prone to memorization, since more attention is paid to them because of the formatting of the text.  And on the other hand, it is possible to understand which blocks of text due to the same formatting fall out of focus due to falling into the area of ‚Äã‚Äãindistinguishability. <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/bbd/b66/16a/bbdb6616aff3ca0d36aaec0824b40db2.jpg"><br><br>  In addition to analyzing the perception of texts, models can work well for finding the optimal regions of perception (to show something - an ad unit) or non-perception (to hide something - a contact phone);) <br><br>  Well, you do not need to completely exclude the class of tasks of quick image analysis for the purpose of usability testing.  Access to the ‚Äúadult‚Äù eye tracking system and the top ten people from a focus group is often an impossible luxury. <br><br><h2>  How does it work </h2><br><br>  Simulation of saccade vectors at the simplest level (that is, the way it works for me) is to solve two problems: <br><br><ol><li>  The calculation of a certain "power of perception" for the specified area. </li><li>  Finding and highlighting gaze traps based on information about the "weight" of the center of attention. </li></ol><br>  The classical solution of the first problem is performed using the following sequence of actions: <br><br><ol><li>  Selection of the required area, in accordance with the angle of optical perception of the eye; </li><li>  Normalization of the selected area in accordance with the parameters of human visual acuity (therefore, the Gauss blur is not entirely applicable here); </li><li>  Selection of contours using frequency analysis and perceptual thresholds (for us at this stage the contours themselves are not so much important as their approximate shapes, Gabor filters are not a bad fit); </li><li>  Detection of discontinuities of the continuity of contours and normalization of points of discontinuity by the Glass algorithm (for finding the vectors of subjective contours and complementing the objective contours by them); </li><li>  Calculation of the zone weight based on the number of changes in direction, the scatter of the directions of the contour vectors and the number of break points. </li></ol><br><br>  In fact, since the weight of the zone is just an estimate of the complexity of the contours in it are located, and the complexity of the contours is a certain composition of the scatter of the directions of vectors and break points.  And for the second task, we do not need exact numbers, but their relative weight.  Therefore, instead of a function of the complexity of the circuit, you can take its derivative.  And the derivative, in its case, is proportional to the composition of the coordinates of the edges of the segments in radial coordinates.  Accordingly, the task of determining the complexity of a contour can be reduced to finding the number of intersections of contours with a large number of radial chords. <br><br>  Experience shows that with small radius sizes (in the case of 96dpi, the radius of the zone of acute vision will be about 18 pixels, and the region under study, taking into account peripheral vision, is 57), 9 radial chords with a step of 20 degrees are sufficient for calculating the weight.  Reducing the angular pitch improves the accuracy of determining the order of weight, but not significantly by comparison with the results obtained using the classical model for calculating weight. <br><br>  The same experience shows that for different dpi and, accordingly, different radii of view zones, it makes sense to use the same 18-ray model with preliminary normalization of the region in the form of bringing it to a circle with a radius of 30 pixels. <br><br>  Because of what <i>the</i> greater accuracy of calculations in any case does not lead to the best result?  And due to the fact that the operation of contour extraction itself has a certain error and the calculation error of the 18-ray model is relatively small relative to the error of the method itself. <br><br>  The second task - the task of identifying traps for a look can be solved in the following way: <br><br><ol><li>  Scanning of the whole area of ‚Äã‚Äãthe picture with selection of zones with maximum weights </li><li>  Construction of the graph from the found points with the establishment of the weight of relations between them </li><li>  The solution of the standard problem on the graph </li></ol><br>  When solving the second problem, each pair or triad of points that make up the eye catcher is assigned a certain weight, which is the relative strength of the composition of points relative to neighboring traps.  The meaning of this weight is in the duration of fixation of the gaze in the trap found.  Another approach is the elastic graph method with establishing the weight of connections between points. <br><br>  I will not touch upon the generation of diagrams from the information found;) <br><br>  <sup><a href="http://geektimes.ru/post/57679/">1 Excursion in the eye</a> - <a href="http://geektimes.ru/post/57681/">2 Perception</a> - <a href="http://geektimes.ru/post/57682/">3 Geometry of view</a> - <a href="http://geektimes.ru/post/57683/">4 Eye tracking</a> - <a href="http://geektimes.ru/post/57684/">5 How to catch the eye</a> - <b>6 Simulation of eye tracking</b></sup> </div><p>Source: <a href="https://habr.com/ru/post/57685/">https://habr.com/ru/post/57685/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../57680/index.html">Freedom of information</a></li>
<li><a href="../57681/index.html">Simulation of view. Part two. Perception</a></li>
<li><a href="../57682/index.html">Simulation of view. Part Three View geometry</a></li>
<li><a href="../57683/index.html">Simulation of view. Part Four. Eye tracking</a></li>
<li><a href="../57684/index.html">Simulation of view. Part Five How to catch a look</a></li>
<li><a href="../57686/index.html">Vision modeling</a></li>
<li><a href="../57687/index.html">A boring exploit for one wide hole</a></li>
<li><a href="../57688/index.html">Perfect smartphone. Thoughts in the course of life</a></li>
<li><a href="../57693/index.html">Czech! The process of obtaining a residence permit</a></li>
<li><a href="../57696/index.html">Free lecture on HTML-layout in Minsk. April 23, Thursday</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>