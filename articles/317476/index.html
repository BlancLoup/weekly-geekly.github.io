<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Debugging Your OS: A Lesson in Memory Allocation</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="It all started, like many other investigations, from a bug report . 

 The name of the report was quite simple: "With an HTTP connection, iter_content...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Debugging Your OS: A Lesson in Memory Allocation</h1><div class="post__text post__text-html js-mediator-article"><div style="text-align:center;"><img src="https://habrastorage.org/files/81f/627/120/81f627120ada4d2d8830722074599a71.jpg"></div><br>  It all started, like many other investigations, from a <a href="https://github.com/kennethreitz/requests/issues/3729">bug report</a> . <br><br>  The name of the report was quite simple: "With an HTTP connection, iter_content works slowly with large chunks."  This name immediately turned on the siren in my head for two reasons.  Firstly, it is rather difficult to determine what is meant by ‚Äúslow‚Äù?  How slow?  How big is the ‚Äúbig size‚Äù?  Secondly, if the described would be shown really seriously, we would already know about it.  The <code>iter_content</code> method has <code>iter_content</code> used for a long time, and if it slowed down significantly in the common user mode, such information would not pass by us. <br><a name="habracut"></a><br>  I quickly looked at the report.  The author provided few details, but wrote this: "This leads to a 100% processor load and reduces network bandwidth below 1 Mb / s."  I jumped at this phrase, because this can not be.  Simple downloads with minimal processing are never that slow! <br><br>  However, all bug reports before refutation deserve investigation.  After talking with the author of the report, it was possible to restore the bug manifestation script: if you use Requests with PyOpenSSL and run the following code, the processor will be fully loaded and the network bandwidth will drop to the minimum: 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> requests https = requests.get(<span class="hljs-string"><span class="hljs-string">"https://az792536.vo.msecnd.net/vms/VMBuild_20161102/VirtualBox/MSEdge/MSEdge.Win10_preview.VirtualBox.zip"</span></span>, stream=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> content <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> https.iter_content(<span class="hljs-number"><span class="hljs-number">100</span></span> * <span class="hljs-number"><span class="hljs-number">2</span></span> ** <span class="hljs-number"><span class="hljs-number">20</span></span>): <span class="hljs-comment"><span class="hljs-comment"># 100MB pass</span></span></code> </pre> <br>  This is just a <b>wonderful,</b> playable script, because it clearly points to the Requests stack.  User-supplied code is not executed here: it is part of the Requests library or one of its dependencies;  There is no possibility that this user has written a stupid low-performance code.  Real fiction.  Even more fantastic is the use of a public URL.  I could <b>execute the script</b> !  And, having done this, I ran into a bug.  With every execution. <br><br>  Here was another lovely detail: <br><br><blockquote>  At 10 MB, there is no increase in the load on the processor and no effect on throughput.  At 1 GB, the processor is loaded at 100%, as at 100 MB, but the bandwidth falls below 100 KB / s, in contrast to 1 MB / s at 100 MB. </blockquote><br>  This is a very interesting point: it hints that the <b>literal value of the</b> chunk size affects the workload.  Considering that this happens only when using PyOpenSSL, and also that most of the time the stack serves the above code, the problem becomes clear: <br><br><pre> <code class="bash hljs">File <span class="hljs-string"><span class="hljs-string">"/home/user/.local/lib/python2.7/site-packages/OpenSSL/SSL.py"</span></span>, line 1299, <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> recv buf = _ffi.new(<span class="hljs-string"><span class="hljs-string">"char[]"</span></span>, bufsiz)</code> </pre> <br>  The investigation showed that the standard behavior of CFFI relative to <code>FFI.new</code> is to return <b>zero</b> memory.  This meant a linear increase in redundancy, depending on the size of the allocated memory: larger volumes had to be reset longer.  Consequently, bad behavior is associated with the release of large volumes.  We took advantage of CFFI's ability to disable resetting these buffers, and the problem went away <sup>1</sup> .  So she solved, right? <br><br>  Wrong. <br><br><h1>  Real bug </h1><br>  Joking aside: it really allowed to solve the problem.  But a few days later I was asked a very profound question: <a href="https://bitbucket.org/cffi/cffi/issues/295/cffinew-is-way-slower-than-it-should-be-it">why was the memory actively reset at all</a> ?  To understand the essence of the question, let's digress and talk about memory allocation in POSIX systems. <br><br><h3>  <i>malloc and calloc and vmalloc, oh well!</i> </h3><br>  Many programmers know the standard way to request memory from the operating system.  This mechanism involves the <code>malloc</code> function from the standard C library (you can read the documentation about it for your OS by typing <code>man 3 malloc</code> in the manual).  This function takes one argument ‚Äî the number of bytes of memory to allocate.  The standard C library allocates memory using one of several different techniques, but somehow it returns a pointer to a section of memory that <b>is at least as large</b> as the amount you requested. <br><br>  By default, <code>malloc</code> returns <b>uninitialized memory</b> .  That is, the standard C library allocates a certain amount and immediately transfers it to your program, without changing the data that is <b>already there</b> .  That is, when using <code>malloc</code> your program will return a buffer to which it has already written data.  This is a common cause of bugs in non-memory-safe (memory-unsafe) languages, for example C. In general, reading from uninitialized memory is very risky. <br><br>  However, <code>malloc</code> has a friend documented on the same manual page: <code>calloc</code> .  Its main difference is that it takes <b>two</b> arguments ‚Äî a counter and a size.  Using <code>malloc</code> , you ask for the standard C library: "Please allocate at least <code>n</code> bytes to me."  And when you call <code>calloc</code> you ask for it: ‚ÄúPlease allocate enough memory for <code>n</code> objects of size <code>m</code> bytes.‚Äù  Obviously, the <b>primary idea of</b> calling <code>calloc</code> was to safely allocate heaps for arrays of objects <sup>2</sup> . <br><br>  But <code>calloc</code> has a side effect associated with its original purpose for placing arrays in memory.  He is very modestly mentioned in the manual. <br><br><blockquote>  The allocated memory is filled with zero bytes. </blockquote><br>  This goes hand in hand with the <code>calloc</code> purpose.  For example, if you place an array of values ‚Äã‚Äãin memory, it will often be very useful for it to <b>initially</b> have a default state.  In some modern memory-safe languages, this has already become the standard behavior when creating arrays and structures.  Say, when you initialize a structure in Go, then all its members are defaulted to their so-called "zero" values, equivalent to "those values ‚Äã‚Äãthat would be if everything were reset to zero."  This can be considered a promise that all Go structures are located in memory using <code>calloc</code> <sup>3</sup> . <br><br>  This behavior means that <code>malloc</code> returns uninitialized memory, and <code>calloc</code> returns initialized memory.  And if so, and even in the light of the aforementioned strict promises, the operating system can optimize the allocated memory.  Indeed, many modern operating systems do this. <br><br><h1>  Use calloc </h1><br>  Of course, the simplest way to implement <code>calloc</code> is to write something like: <br><br><pre> <code class="cpp hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> *</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">calloc</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">size_t</span></span></span></span><span class="hljs-function"><span class="hljs-params"> count, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">size_t</span></span></span></span><span class="hljs-function"><span class="hljs-params"> size)</span></span></span><span class="hljs-function"> </span></span>{ assert(!multiplication_would_overflow(count, size)); <span class="hljs-keyword"><span class="hljs-keyword">size_t</span></span> allocation_size = count * size; <span class="hljs-keyword"><span class="hljs-keyword">void</span></span> *allocation = <span class="hljs-built_in"><span class="hljs-built_in">malloc</span></span>(allocation_size); <span class="hljs-built_in"><span class="hljs-built_in">memset</span></span>(allocation, <span class="hljs-number"><span class="hljs-number">0</span></span>, allocation_size); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> allocation; }</code> </pre> <br>  The cost of this function varies approximately linearly with respect to the size of the allocated memory: the more bytes, the more expensive they are all zeroed.  Today, most operating systems in fact contain standard C libraries that contain <b>optimized</b> paths for <code>memset</code> (usually, specialized processor vector instructions are used that allow a single instruction to reset a large number of bytes at once).  However, the cost of this procedure varies linearly. <br><br>  To allocate large amounts in the OS uses another trick related to virtual memory. <br><br><h1>  Virtual memory </h1><br>  Here we will not analyze the entire structure and operation of virtual memory, but I highly recommend reading about it (the topic is extremely interesting!).  In short: virtual memory is a lie of the OS kernel to processes about available memory.  Each executed process has its own idea of ‚Äã‚Äãmemory belonging to it and only to it.  This representation is indirectly ‚Äúmapped‚Äù (mapped) to physical memory. <br><br>  As a result, the OS can scroll through all sorts of tricky tricks.  Most often, it gives out for memory special files that are displayed in it (memory-mapped file).  They are used to upload the contents of memory to disk, as well as to display memory in them.  In the latter case, the program asks the OS: ‚ÄúPlease allocate n bytes of memory to me and save them to a file on disk, so that when I write to memory, all the records would be executed into this file, and when I read from memory, the data would be read from it. ‚Äù <br><br>  At the kernel level, it works like this: when a process tries to read from such memory, the processor notifies that the memory does not exist, pauses the process and throws a "page fault" (page fault).  The kernel <b>stores</b> actual data into memory so that the application can read them.  Then the process is removed from the pause and magically finds the data in the appropriate place.  From the point of view of the process, everything happened instantly, without a pause. <br><br>  This mechanism can be used to perform other subtle tricks.  One of them is the "free" allocation of very large amounts of memory.  Or, more precisely, to make their cost proportional to the degree of <b>use of</b> this memory, and not to <b>the size allocated.</b> <br><br>  Historically, many programs that need decent chunks of memory at runtime create a <b>large</b> buffer at startup, which can then be distributed within the program during its life cycle.  This was done because programs were written for environments that did not use virtual memory;  the programs had to immediately occupy some amounts of memory, so that later they would not have enough of it.  But after the introduction of virtual memory, this behavior has become unnecessary: ‚Äã‚Äãeach program can allocate as much memory for itself as is necessary, without tearing out a piece from the mouth of others <sup>4</sup> . <br><br>  To avoid the very high costs of running applications, operating systems began to lie to applications.  In most operating systems, if you try to allocate more than 128 KB in a single call, the standard C library will directly ask the OS for completely new virtual memory pages that will cover the requested volumes.  But the main thing: this <b>selection is almost worthless</b> .  After all, in fact, the OS does nothing: it only reconfigures the virtual memory scheme.  So using <code>malloc</code> costs are scanty. <br><br>  The memory was not ‚Äúassigned‚Äù to the process, and as soon as the application tries to actually use it, a memory page error occurs.  The OS intervenes here, finds the page you need and places it where the process goes, just like in the case of a memory error and a mapped file.  The only difference is that virtual memory is provided with physical memory, not file. <br><br>  As a result, if you call <code>malloc(1024 * 1024 * 1024)</code> to allocate 1 GB of memory, it will happen almost instantly, because in fact the memory is not allocated to the process.  But programs can instantly ‚Äúallocate‚Äù for themselves many gigabytes, although in reality this would not have happened very quickly. <br><br>  But even more surprising is that the same optimization is available for <code>calloc</code> .  The OS can display a completely new page on the so-called ‚Äúzero page‚Äù: this is a read-only memory page, and only zeros are read from it.  Initially, this mapping is copy-on-write: when your process tries to write data to this new memory ‚Äî the kernel intervenes, copies all zeros to a new page, and then allows you to write. <br><br>  Thanks to this trick from the OS, <code>calloc</code> can do the same thing as <code>malloc</code> when allocating large volumes, requesting new virtual memory pages.  This will be free until the memory is used.  This optimization means that the cost of <code>calloc(1024 * 1024 * 1024, 1)</code> will be equal to the call to <code>malloc</code> for the same amount of memory, despite the fact that <code>calloc</code> also promises to fill the memory with zeros.  Clever! <br><br><h1>  Back to our bug </h1><br>  So: if CFFI used <code>calloc</code> , then why was the memory reset? <br><br>  For a start: <code>calloc</code> was not always used.  But I suspected that in this case I could reproduce the deceleration directly using <code>calloc</code> , so I threw the program again: <br><br><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">include</span></span></span><span class="hljs-meta"> </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;stdlib.h&gt; #define ALLOCATION_SIZE (100 * 1024 * 1024) int main (int argc, char *argv[]) { for (int i = 0; i &lt; 10000; i++) { void *temp = calloc(ALLOCATION_SIZE, 1); free(temp); } return 0; }</span></span></span></span></code> </pre> <br>  A very simple C program that allocates and releases 100 MB by calling <code>calloc</code> ten thousand times.  Then exits.  Next - two options <sup>5</sup> : <br><br><ol><li>  <code>calloc</code> can use the above virtual memory trick.  In this case, the program should work quickly: the allocated memory is not actually used, is not paginated, and the pages do not become ‚Äúdirty‚Äù (dirty).  The OS is lying to us about the selection, and we do not catch her hand, so everything works fine. </li><li>  <code>calloc</code> can draw <code>malloc</code> and manually reset memory using <code>memset</code> .  This should be done very, very slowly: in total, we need to reset a <b>terabyte of</b> memory (ten thousand cycles of 100 MB each), which is very difficult. </li></ol><br>  This greatly exceeds the standard OS threshold for using the first option, so one can expect exactly this behavior.  Indeed, Linux does just that: if you compile the code with GCC and run it, it will execute extremely quickly, generate several page errors and almost do not lead to memory load.  But if you run the same program on MacOS, it will run <b>extremely</b> long: it took me almost <b>eight minutes</b> . <br><br>  Moreover, if you increase <code>ALLOCATION_SIZE</code> (for example, <code>1000 * 1024 * 1024</code> ), then on MacOS this program will work almost instantly!  <b>What the hell?</b> <br><br>  What is going on here? <br><br><h1>  In-depth analysis </h1><br>  On MacOS, there is a <code>sample</code> utility (see <code>man 1 sample</code> ), which can tell a lot about the process being executed, registering its state.  For our code, <code>sample</code> gives the following: <br><br><pre> <code class="bash hljs">Sampling process 57844 <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> 10 seconds with 1 millisecond of run time between samples Sampling completed, processing symbols... Sample analysis of process 57844 written to file /tmp/a.out_2016-12-05_153352_8Lp9.sample.txt Analysis of sampling a.out (pid 57844) every 1 millisecond Process: a.out [57844] Path: /Users/cory/tmp/a.out Load Address: 0x10a279000 Identifier: a.out Version: 0 Code Type: X86-64 Parent Process: zsh [1021] Date/Time: 2016-12-05 15:33:52.123 +0000 Launch Time: 2016-12-05 15:33:42.352 +0000 OS Version: Mac OS X 10.12.2 (16C53a) Report Version: 7 Analysis Tool: /usr/bin/sample ---- Call graph: 3668 Thread_7796221 DispatchQueue_1: com.apple.main-thread (serial) 3668 start (<span class="hljs-keyword"><span class="hljs-keyword">in</span></span> libdyld.dylib) + 1 [0x7fffca829255] 3444 main (<span class="hljs-keyword"><span class="hljs-keyword">in</span></span> a.out) + 61 [0x10a279f5d] + 3444 calloc (<span class="hljs-keyword"><span class="hljs-keyword">in</span></span> libsystem_malloc.dylib) + 30 [0x7fffca9addd7] + 3444 malloc_zone_calloc (<span class="hljs-keyword"><span class="hljs-keyword">in</span></span> libsystem_malloc.dylib) + 87 [0x7fffca9ad496] + 3444 szone_malloc_should_clear (<span class="hljs-keyword"><span class="hljs-keyword">in</span></span> libsystem_malloc.dylib) + 365 [0x7fffca9ab4a7] + 3227 large_malloc (<span class="hljs-keyword"><span class="hljs-keyword">in</span></span> libsystem_malloc.dylib) + 989 [0x7fffca9afe47] + ! 3227 _platform_bzero<span class="hljs-variable"><span class="hljs-variable">$VARIANT</span></span><span class="hljs-variable"><span class="hljs-variable">$Haswel</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">in</span></span> libsystem_platform.dylib) + 41 [0x7fffcaa3abc9] + 217 large_malloc (<span class="hljs-keyword"><span class="hljs-keyword">in</span></span> libsystem_malloc.dylib) + 961 [0x7fffca9afe2b] + 217 madvise (<span class="hljs-keyword"><span class="hljs-keyword">in</span></span> libsystem_kernel.dylib) + 10 [0x7fffca958f32] 221 main (<span class="hljs-keyword"><span class="hljs-keyword">in</span></span> a.out) + 74 [0x10a279f6a] + 217 free_large (<span class="hljs-keyword"><span class="hljs-keyword">in</span></span> libsystem_malloc.dylib) + 538 [0x7fffca9b0481] + ! 217 madvise (<span class="hljs-keyword"><span class="hljs-keyword">in</span></span> libsystem_kernel.dylib) + 10 [0x7fffca958f32] + 4 free_large (<span class="hljs-keyword"><span class="hljs-keyword">in</span></span> libsystem_malloc.dylib) + 119 [0x7fffca9b02de] + 4 madvise (<span class="hljs-keyword"><span class="hljs-keyword">in</span></span> libsystem_kernel.dylib) + 10 [0x7fffca958f32] 3 main (<span class="hljs-keyword"><span class="hljs-keyword">in</span></span> a.out) + 61 [0x10a279f5d] Total number <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> stack (recursive counted multiple, when &gt;=5): Sort by top of stack, same collapsed (when &gt;= 5): _platform_bzero<span class="hljs-variable"><span class="hljs-variable">$VARIANT</span></span><span class="hljs-variable"><span class="hljs-variable">$Haswell</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">in</span></span> libsystem_platform.dylib) 3227 madvise (<span class="hljs-keyword"><span class="hljs-keyword">in</span></span> libsystem_kernel.dylib) 438</code> </pre> <br>  Here we clearly see that a lot of time is spent on the <code>_platform_bzero$VARIANT$Haswell</code> method.  It is used to clear buffers.  That is, MacOS resets them.  Why? <br><br>  Some time after the release, Apple makes open most of the core code of its OS.  And you can see that this program spends a lot of time in <code>libsystem_malloc</code> .  I went to <a href="https://opensource.apple.com/">opensource.apple.com</a> , downloaded the <a href="https://opensource.apple.com/source/libmalloc/libmalloc-116/">libmalloc-116</a> archive with the source code I needed and began to investigate. <br><br>  Looks like all the magic happens in <a href="https://opensource.apple.com/source/libmalloc/libmalloc-116/src/magazine_large.c.auto.html">large_malloc</a> .  This branch is needed for memory allocation larger than 127 KB, it uses a virtual memory trick.  So why does everything slowly work for us? <br><br>  It seems that the fact is that Apple has become too smart.  In <code>large_malloc</code> behind the constant <code>#define</code> a bunch of code is hidden, <code>CONFIG_LARGE_CACHE</code> .  Basically, all this code comes down to the ‚Äúfree-list‚Äù pages of large amounts of memory allocated for the program.  If MacOS allocates a contiguous buffer of 127 KB to <code>LARGE_CACHE_SIZE_ENTRY_LIMIT</code> (approximately 125 MB), then <code>libsystem_malloc</code> will try to <code>libsystem_malloc</code> these pages if they can be used by another memory allocation process.  Because of this, he does not have to ask the Darwin kernel page, which saves context switching and a system call: in principle, non-trivial savings. <br><br>  However, this is the case for <code>calloc</code> when you need to reset the bytes.  And if MacOS finds a page that can be reused and that was called from <code>calloc</code> , then the <b>memory will be reset</b> .  All.  And so every time. <br><br>  This has its own reason: the zeroed pages are a limited resource, especially in the conditions of modest iron (I look at the Apple Watch).  So if the page can be reused, it can be a good savings. <br><br>  <b>However, the</b> page cache completely deprives us of the advantages of using <code>calloc</code> to provide zero memory pages.  It would not be so bad if it were done only for dirty pages.  If the application writes to a nullable page, then it will probably not be reset.  But MacOS does this <b>unconditionally</b> .  This means that even if you call <code>alloc</code> , <code>free</code> and <code>calloc</code> without touching the memory at all, then the second call to <code>calloc</code> will take the pages allocated during the first call and never supported by physical memory.  Therefore, the OS <b>has to</b> load (page-in) all this memory in order to reset it, although it <b>has already been reset</b> .  This is what we want to avoid using a virtual memory-based distribution engine when it comes to allocating large amounts: never used memory <b>becomes</b> used by the ‚Äúlist of free‚Äù pages. <br><br>  As a result, on MacOS, the cost of <code>calloc</code> linearly increases depending on the size of the allocated memory up to 125 MB, despite the fact that other operating systems demonstrate the behavior of O (1) starting from 127 KB.  After 125 MB, MacOS stops caching pages, so the speed magically takes off. <br><br>  I did not expect to find such a bug from a program in Python, and I had a number of questions.  For example, how many processor cycles are lost to reset the memory, which is already reset?  How many context switches does it take to force applications to load (page-in) memory that they did not use (and are not going to) so that the OS could senselessly reset it? <br><br>  It seems to me that all this confirms the loyalty of the old saying: there are leaks in all abstractions ( <a href="http://www.joelonsoftware.com/articles/LeakyAbstractions.html">all abstractions are leaky</a> ).  You can not forget about this just because you are programming in Python.  Your program runs on a machine that uses memory and all sorts of tricks to manage it. ,  ,       .     ,     . <br><br>      <a href="http://rdar//29508271/">Radar 29508271</a> .     ,   . <br><br><h1>  findings </h1><br><ol><li>    ,    ? , CFFI    :     ,  ,         ,      .        <code>char</code>    OpenSSL,      ,    OpenSSL <b> </b> .  ,  OpenSSL         .      , OpenSSL  ,    .          .       )   ,    OpenSSL,    ,  )        .      ( ) :  OpenSSL   ,        ,       .            . </li><li>    ¬´¬ª.   C-,     ,    : <code>type *array = malloc(number_of_elements * size_of_element)</code> .   ,      <b></b> :    <code>number_of_elements  size_of_element</code>      ,    <b>  </b> . <code>calloc</code>     ,      .      ,    . </li><li>  ,  ¬´ ¬ª ‚Äî   ¬´¬ª.    runtime Go     . </li><li> ,  <b></b>        <b></b> ,     . </li><li>   ,      :       ! </li></ol></div><p>Source: <a href="https://habr.com/ru/post/317476/">https://habr.com/ru/post/317476/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../317466/index.html">Rollback in Cisco IOS XR</a></li>
<li><a href="../317468/index.html">Yandex.Metrica or specialized monitoring system - what and when to choose?</a></li>
<li><a href="../317470/index.html">My story of emigration, the dream of the administrator</a></li>
<li><a href="../317472/index.html">New Year! Distributing 10 Trips to New Orleans on VeeamON 2017</a></li>
<li><a href="../317474/index.html">10 best books to run a successful startup under the version of MakeRight</a></li>
<li><a href="../317478/index.html">December 16 - the official launch of the Imagine Cup competition in Russia! Come to find out more.</a></li>
<li><a href="../317480/index.html">The book "Ruby. Object Oriented Design</a></li>
<li><a href="../317482/index.html">Cambium brings new life to your overloaded networks on Ubiquiti: a new program for operators</a></li>
<li><a href="../317484/index.html">How to teach a web application to speak 100 languages: localization features</a></li>
<li><a href="../317488/index.html">We start Gulp with votcher on a usual hosting through adminpanel</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>