<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Free Cluster (Proxmox + Nexenta)</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Probably many of us, solving the problem of organizing a small IT infrastructure, faced the problem of choosing a hypervisor. What functionality shoul...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Free Cluster (Proxmox + Nexenta)</h1><div class="post__text post__text-html js-mediator-article">  Probably many of us, solving the problem of organizing a small IT infrastructure, faced the problem of choosing a hypervisor.  What functionality should software have and how much is it worth paying for?  Will this or some other part of the solution be compatible with what is already there? <br>  And as if, all this drive on the stand to make sure the correctness of the choice? <br>  Taking into account the rate of one, all known currency, I want something simple, no frills and, if possible, free.  Especially when it comes to a small or medium company (startup), limited in the budget. <br><br><h3>  <font color="#595959">What do we need?</font> </h3><br><img src="https://habrastorage.org/files/f3f/044/18d/f3f04418d7304d5b810d7d9387bbbb42.jpg" alt="image"><br><br><ul><li>  Hardware compatible hypervisor </li><li>  Cluster with access to admin panel via web interface </li><li>  High Availability for Virtual Machines in a Cluster </li><li>  Backup and restore function out of the box </li><li>  Accessibility for understanding and work of the average administrator (yesterday's student-student). </li></ul><br>  From Open-Source solutions, Proxmox is the easiest to install and configure.  In order not to insult oVirt lovers, etc. (this is not a promotional article), I‚Äôll say that the initial requirement for ease of installation and administration, in my opinion, is still more pronounced for Proxmox.  Also, I repeat, we do not have a data center, but only a cluster of 2-3 nodes for a small company. <br>  As a hypervisor, it uses <a href="https://ru.wikipedia.org/wiki/Kernel-based_Virtual_Machine">KVM</a> and <a href="https://ru.wikipedia.org/wiki/LXC">LXC</a> , respectively, keeps KVM OS (Linux, * BSD, Windows and others) with minimal loss of performance and Linux without loss. <br><a name="habracut"></a><br><h3>  <font color="#595959">So, let's go:</font> </h3><br>  Installing the hypervisor is the simplest, download it <a href="https://www.proxmox.com/en/downloads">from here</a> : <br>  It is installed literally in a few clicks and entering the admin password. <br>  After that, we are given a console window with the address for the web interface of the form <blockquote>  <a href="http://172.16.2.150/">172.16.2.150</a> : 8006 </blockquote>  (hereinafter addressing the test network). <br>  Next, install the second and third nodes, with the same result. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h3>  <font color="#595959">Run the cluster:</font> </h3><br>  1. Set up hosts on pve1.local: <br><pre><code class="bash hljs">root@pve1:~<span class="hljs-comment"><span class="hljs-comment"># nano /etc/hosts 127.0.0.1 localhost.localdomain localhost 172.16.2.170 pve1.local pve1 pvelocalhost 172.16.2.171 pve2.local pve2</span></span></code> </pre> <br>  2. Set up hosts on pve2.local: <br><pre> <code class="bash hljs">root@pve2:~<span class="hljs-comment"><span class="hljs-comment"># nano /etc/hosts 127.0.0.1 localhost.localdomain localhost 172.16.2.171 pve2.local pve2 pvelocalhost 172.16.2.170 pve1.local pve1</span></span></code> </pre><br>  3. By analogy, configure hosts on pve3.local <br>  4. On the server pve1.local we execute: <br><pre> <code class="bash hljs">root@pve1:~<span class="hljs-comment"><span class="hljs-comment"># pvecm create cluster</span></span></code> </pre><br>  5. On the server pve2.local we execute: <br><pre> <code class="bash hljs">root@pve2:~<span class="hljs-comment"><span class="hljs-comment"># pvecm add pve1</span></span></code> </pre><br>  6. In the same way, we configure and add the third pve3.local host to the cluster. <br><br><h3>  <font color="#595959">Update all nodes:</font> </h3><br>  We align the repository: <br><pre> <code class="bash hljs">root@pve1:~<span class="hljs-comment"><span class="hljs-comment"># nano /etc/apt/sources.list deb http://ftp.debian.org.ru/debian jessie main contrib # PVE pve-no-subscription repository provided by proxmox.com, NOT recommended for production use deb http://download.proxmox.com/debian jessie pve-no-subscription # security updates deb http://security.debian.org/ jessie/updates main contrib</span></span></code> </pre><br><br>  Commenting on the unnecessary repository: <br><pre> <code class="bash hljs">root@pve1:~<span class="hljs-comment"><span class="hljs-comment"># nano /etc/apt/sources.list.d/pve-enterprise.list # deb https://enterprise.proxmox.com/debian jessie pve-enterprise</span></span></code> </pre><br>  And updated (at each node, respectively): <br><pre> <code class="bash hljs">root@pve1:~<span class="hljs-comment"><span class="hljs-comment"># apt-get update &amp;&amp; apt-get dist-upgrade</span></span></code> </pre><br>  That's it, the cluster is ready for battle! <br><br><img src="https://habrastorage.org/files/2e1/167/946/2e11679469ba4236bf4d3d25b36609a6.jpg" alt="image"><br><br>  Here, we already have a backup function (called redundancy) out of the box, which almost immediately impresses! <br><br><h3>  <font color="#595959">Storage:</font> </h3><br>  Further, the question arises of the choice of shared storage. <br>  Choose iSCSI (as the most budget option) Storage: <br>  In principle, when setting up, you can limit yourself to one interface, but in a cluster you cannot have one point of failure, therefore it is better to use the <a href="https://pve.proxmox.com/wiki/ISCSI_Multipath">multipath</a> from Proxmox, or the combination of interfaces from the storage itself. <br><br>  Here, you can take some kind of commercial storage, disk shelf, etc. <br>  Actually, the first test was conducted just along with the solution from <a href="http://www.infortrend.com/ru/Home">Infortrend</a> . <br><br>  But then again, what to do if the budget is simply utterly limited (or is it simply not there) ?! <br>  The easiest way is to fill the disks with the iron that is, and make it a storage facility that allows you to achieve your goals. <br>  As a result, we need opportunities (taking into account the fact that the company may expand dramatically): <br><br><ul><li>  Unified storage: NAS / SAN </li><li>  iSCSI target functionality </li><li>  CIFS, NFS, HTTP, FTP Protocols </li><li>  RAID 0,1,5,6,10 support </li><li>  Bare metal or virtualization installation </li><li>  8TB + Journaled filesystems </li><li>  Filesystem Access Control Lists </li><li>  Point In Time Copy (snapshots) support </li><li>  Dynamic volume manager </li><li>  Powerful web-based management </li><li>  Block level remote replication </li><li>  High Availability clustering </li><li>  Key features must be present in the Open-Cource / Community version. </li></ul><br>  After some agonies of choice, <a href="https://www.openfiler.com/">OpenFiler</a> and <a href="https://nexenta.com/products/downloads/download-community-edition/">NexentaStor remained</a> . <br>  <a href="https://www.starwindsoftware.com/starwind-virtual-san-free">Of</a> course, I would like to use <a href="https://www.starwindsoftware.com/starwind-virtual-san-free">Starwind</a> or <a href="http://www.freenas.org/for-business/">FreeNAS</a> ( <a href="http://www.nas4free.org/">NAS4Free</a> ), but if one needs Windows and shamanism with ISCSI for work, then the other has a good file clustering function. <br>  OpenFiler unfortunately has a scant GUI and its latest version is from 2011.  So it remains NexentaStor. <br>  She, of course, has a paid active-active scheme in the Nexenta cluster, if you need it later.  Also, if there are 2 nodes (controller) in the storage, then the second one‚Äôs support is also for money!  Actually, all plugins are available only in the Enterprise version. <br>  However, what is available in the Community version covers most of the initial needs.  This includes 18TB of storage space, ZFS with snapshots, and the ability to replicate out of the box! <br><br><h3>  <font color="#595959">Installing NexentaStor Community Edition:</font> </h3><br>  First of all, it is necessary to study the <a href="https://nexenta.com/sites/default/files/docs/NexentaStor_4_HCL_20150414_22.pdf">Compatibility List</a> . <br>  Download distribution <a href="https://nexenta.com/products/downloads/download-community-edition/">from here</a> (registration is required to get the key for installation). <br>  The installation procedure is as simple as possible. In its process, we configure an IP address with a port to configure in the GUI. <br>  Next, successively clicking on the requests of the wizard, we set the password and array in the GUI (in Nexenta, it is called the Volume). <br>  Next, go to the <b>SCSI Target</b> section and sequentially create: <br><ol><li>  <b>Target Portal Groups</b> </li><li>  <b>Targets</b> </li><li>  <b>Remote Initiators</b> - for each node: </li></ol><br><img src="https://habrastorage.org/files/be6/3e7/4b2/be63e74b280845e39e13d47acbba46b9.jpg" alt="image"><br><br>  Further, in accordance with the <a href="https://pve.proxmox.com/wiki/Storage:_ZFS_over_iSCSI">manual</a> : <br><pre> <code class="bash hljs">root@pve1:~<span class="hljs-comment"><span class="hljs-comment"># mkdir /etc/pve/priv/zfs root@pve1:~# ssh-keygen -f /etc/pve/priv/zfs/172.16.2.150_id_rsa root@pve1:~# ssh-copy-id -i /etc/pve/priv/zfs/192.16.2.150_id_rsa.pub root@172.16.2.150</span></span></code> </pre><br>  Copy the key to each node: <br><pre> <code class="bash hljs">root@pve1:~<span class="hljs-comment"><span class="hljs-comment"># ssh -i /etc/pve/priv/zfs/172.16.2.150_id_rsa root@172.16.2.150</span></span></code> </pre><br>  You can hook up the iSCSI storage in Proxmox in two ways: <br>  Through the ISCSI menu in adding storage (you will have to create an additional LVM) - see the <a href="https://pve.proxmox.com/wiki/Storage_Model">manual</a> . <br>  Through the menu ZFS over iSCSI - see the <a href="https://pve.proxmox.com/wiki/Storage:_ZFS_over_iSCSI">manual</a> . <br>  We will go the second way, as it gives us the opportunity to create and store snapshots.  Nexenta can also do this. <br>  The configuration process in the GUI looks like this: <br><br><img src="https://habrastorage.org/files/e57/113/120/e57113120ff94803815c849da159c10e.jpg" alt="image"><br><br>  The result is: <br><br><img src="https://habrastorage.org/files/0d2/084/bf2/0d2084bf2b154a26a5fc9a455ce7c6de.jpg" alt="image"><br><br>  When setting up, do not confuse the pool name (in nexenta it is similar to Datastore): <br><br><pre> <code class="bash hljs">root@nexenta:~<span class="hljs-comment"><span class="hljs-comment"># zpool status pool: volume1 state: ONLINE scan: none requested config: NAME STATE READ WRITE CKSUM volume1 ONLINE 0 0 0 c0t1d0 ONLINE 0 0 0 errors: No known data errors</span></span></code> </pre><br>  Now we can choose how and what to back up. <br>  We can make an automatic backup of VM to remote storage directly from Proxmox: <br>  Those.  go to the ‚ÄúStorage‚Äù tab and add an NFS array.  This can be either an ordinary NAS storage, or an xNIX server with a folder accessible via NFS (which is more convenient for someone).  Then, we specify contents (backup). <br><br>  Alternatively, you can replicate with Nexenta: <br>  Implemented in the GUI tabs <b>Data Management -&gt; Auto Services -&gt; Auto-Tier Services -&gt; Create</b> . <br>  Here we mean a remote repository (or just a Linux machine) running the rsync service.  Therefore, before this we need to create a connection between the hosts. <br>  The <b>Settings</b> tabs <b>-&gt; Network -&gt; SSH-bind</b> help raise the connection. <br><br><h3>  <font color="#595959">HA Setup:</font> </h3><br>  Fully customizable via GUI. <br><ol><li>  Select the <b>datacenter</b> , click the <b>HA</b> tab on top. </li><li>  Click <b>Groups</b> below and create a group of hosts to which VMs can migrate. </li><li>  Next, click <b>Resources</b> and add the VM we want there. </li></ol><br>  You can also view the status in the console: <br><pre> <code class="bash hljs">root@pve1:~<span class="hljs-comment"><span class="hljs-comment"># ha-manager status quorum OK master pve1 (active, Sun Mar 20 14:55:59 2016) lrm pve1 (active, Sun Mar 20 14:56:02 2016) lrm pve2 (active, Sun Mar 20 14:56:06 2016) service vm:100 (pve1, started)</span></span></code> </pre><br>  Now we‚Äôll check the performance of the cluster. <br>  Install the VM, with Windows, with the disk in the shared storage, and try the migration manually: <br><br><iframe width="420" height="315" src="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://www.youtube.com/embed/1h0WYdSxsqQ%3Ffeature%3Doembed&amp;xid=17259,15700002,15700023,15700186,15700191,15700248,15700253&amp;usg=ALkJrhgvuymmVY4YDGwNTLJ0eei18MOEIQ" frameborder="0" allowfullscreen=""></iframe><br><br>  Works! <br>  Ok, now we check its fault tolerance, turn off the server through IPMI.  We are waiting for the move.  The machine automatically migrates in a minute and a half. <br>  What is the problem?  Here it is necessary to understand that the fencing mechanism in version 4.x has changed.  Those.  Whatchdog fencing, which does not have active hardware support, is currently working.  Will be fixed in version 4.2. <br><br><h3>  <font color="#595959">Conclusion</font> </h3><br>  So, what we got in the end? <br>  And we got a Production-ready cluster that supports most of the OS, with a simple management interface, multiple data backup (this is also Proxmox and Nexentastor with snapshots and replication). <br>  Plus, we always have the ability to scale and add features, both from the side of Proxmox and from the side of Nexenta (in this case, you will have to buy a license). <br>  And all this is completely free! <br>  In my opinion, setting all this does not require any special time or detailed study of various manuals. <br>  Of course, the rake is not without some, it‚Äôs a comparison with ESXi + VMWare vCenter in favor of the latter.  However, you can always ask a question on the support forum! <br>  As a result, almost 100% of the functionality, most often used by the administrator of a small project (company), we immediately got out of the box.  Therefore, I recommend everyone to think, and is it worth spending on unnecessary features, so long as they are licensed? <br><br>  PS In the above experiment, the equipment was used: <br><br>  4 x <a href="http://www.stss.ru/products/servers/R-series/RX237.4-016LH.html%3Fconfig%3D">STSS Flagman RX237.4-016LH</a> Servers consisting of: <br><ul><li>  X9DRi-LN4F + </li><li>  2 x Xeon E5-2609 </li><li>  8 x 4GB DDR-III ECC </li><li>  ASR-6805 + FBWC </li></ul><br>  Three of the four servers were used as nodes, one was packed with 2TB disks and used as a storage. <br><br>  In the first experiment, a finished storage <a href="http://www.stss.ru/products/infortrend_storage/Infortrend_EonNAS_3016R/Infortrend_EonNAS_3016R_NS3016R00000D-0032.html%3Fconfig%3D">Infortrend EonNAS 3016R was</a> used as a NAS <a href="http://www.stss.ru/products/infortrend_storage/Infortrend_EonNAS_3016R/Infortrend_EonNAS_3016R_NS3016R00000D-0032.html%3Fconfig%3D">.</a> <br><br>  The equipment was chosen not to test performance, but to evaluate the concept of the solution as a whole. <br>  It is possible that there are more optimal options for implementation.  However, performance testing in different configurations was not included in the scope of this article. <br><br>  Thank you for your attention, waiting for your comments! </div><p>Source: <a href="https://habr.com/ru/post/279589/">https://habr.com/ru/post/279589/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../279573/index.html">DroidShoter - screenshots of the application at different screen resolutions, using one device and Adb</a></li>
<li><a href="../279577/index.html">Why did Citrix not become the ‚Äúnew Red Hat‚Äù in the virtualization market? Part 1</a></li>
<li><a href="../279579/index.html">XData Studio Assist - autocompletion in XData blocks of InterSystems Cach√© classes</a></li>
<li><a href="../279585/index.html">Full-text fuzzy search using the Wagner-Fisher algorithm</a></li>
<li><a href="../279587/index.html">Game Industry Digest: February</a></li>
<li><a href="../279591/index.html">Our experience of using photogrammetry in the development of a computer game (Part 1)</a></li>
<li><a href="../279595/index.html">L10n lines in applications (javascript)</a></li>
<li><a href="../279597/index.html">The best technological videos of Channel 9 of this week, March 18</a></li>
<li><a href="../279601/index.html">Setting up LaTeX templates for Jupyter notebook</a></li>
<li><a href="../279603/index.html">ICQ Contest. The results of the competition for the redesign of the mobile application</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>