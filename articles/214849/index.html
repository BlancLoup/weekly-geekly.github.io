<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Why does the robot have ears? (survey: do you need OpenTod)</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="The second of the laws of robotics, formulated by the notorious American science fiction writer Isaac Asimov, says that the robot must obey the orders...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Why does the robot have ears? (survey: do you need OpenTod)</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/getpro/habr/post_images/7a7/ccd/31c/7a7ccd31cf6ab8f1787cecf25fae3fc5.jpg"><br>  The second of the laws of robotics, formulated by the notorious American science fiction writer Isaac Asimov, says that the robot must obey the orders given by man.  What ways you can give orders to the robot?  According to most science fiction films, the most comfortable way of communicating with a robot is natural human speech.  That is why we provided the robot Tod, as a real servant of man, the long-awaited opportunity to understand voice control commands and speech synthesis in Russian.  Now it is enough, for example, to give the order ‚ÄúRobot, go to the kitchen‚Äù in order for the robot to fulfill the necessary task.  Under the cut, we will tell you more about the software used to recognize and synthesize speech on the robot, and in the videos we will show examples of using voice commands. <br>  The vector of development of our project depends on the opinion of the community.  Are you interested in using Tod robot as an open source platform for developers?  Please vote in our poll. <br><a name="habracut"></a><br><br><h4>  Speech Recognition in Pocketsphinx </h4><br>  Most owners of modern smartphones have already tried some kind of voice search system and appreciated some of its advantages over the traditional method of sensory input.  And some automation lovers have taught their PCs how to understand voice control commands, since there are enough manuals on this topic on Habr√© and the network. <br>  If your robot uses Linux, then teaching him to understand speech will not be much more difficult than doing the same on a home PC.  You can use to recognize the speech of any of the engines, distributed with open source.  Unlike speech recognition cloud services, this allows the robot to stay connected even in the absence of the Internet. <br>  Our robot uses the open source CMU Sphinx voice engine developed by American Carnegie Mellon University and actively supported by the Massachusetts Institute of Technology and Sun Microsystems.  One of the advantages of this engine is the ability to adapt the sound model for a particular person.  And what is important for us, the engine is easily integrated into ROS - a robotic framework for our Tod. <br>  CMU Sphinx consists of 3 main components: <br><ul><li>  acoustic model that converts sound into phonemes </li><li>  dictionary that converts phonemes into words </li><li>  language model - builds a sentence from the words obtained </li></ul><br>  Acoustic model is a set of sound recordings, divided into speech segments.  For a small dictionary, you can create an acoustic base yourself, but it is better to use the acoustic base of the VoxForge.org project, which contains more than ten hours of dictation in Russian. <br>  The next stage of adaptation of the acoustic model is optional, but it will make the recognition better for your voice.  The phrases you dictate are added to the main acoustic model, which allows you to take into account the peculiarities of your pronunciation in recognition. <br>  The dictionary in CMU Sphinx is just a text file with phrases and corresponding phonemes.  Our dictionary consists of various commands to control the robot: <br><div class="spoiler">  <b class="spoiler_title">Vocabulary</b> <div class="spoiler_text">  without bb je s <br>  without (2) bb iz <br>  without (3) bb is <br>  without (4) bb je z <br>  without (5) bb je s <br>  forward f pp i rr jo t <br>  time v rr je mm i <br>  where g dd je <br>  two dv aa <br>  two-three dv aa t rr ii <br>  day dd je nn <br>  tomorrow z aa ftr ay <br>  hall z aa l <br>  hello zdr aa stvuj <br>  you know zn aa i sh <br>  name is zav uu t <br>  how k aa k <br>  what k aa k ay i <br>  which (2) kak aa i <br>  what kak oo j <br>  the end of kanc aa <br>  who kt oo <br>  kitchen k uu h nn uj <br>  love you ju bb i sh <br>  me mm i nn ja <br>  cute mm ii ‚Äã‚Äãlyj <br>  i m nn je <br>  you can m oo zh y sh <br>  my m oo j <br>  find naj tt ii <br>  weeks nn i dd je ll i <br>  look back ag ll ja t kk i <br>  one a dd ii n <br>  papa aa pp i <br>  beer pp ii v ay <br>  you p ay zh yv aa i sh <br>  let's play p ay igr aa im <br>  bye pak aa <br>  weather pag oo d ay <br>  item p rr id mm je t <br>  bring p rr i vv i zz ii <br>  hi p rr i vv je t <br>  tell r ay ska zh yy <br>  today ss iv oo d nn i <br>  now ss ij ch ja s <br>  now (2) ss i ch ja s <br>  now (3) sch ja s <br>  how many sk oo ll k ay <br>  you tt i bb ja <br>  you (2) tt ja <br>  you (3) tt i <br>  point t oo ch k ay <br>  three t rr ii <br>  three-four t rr ii ch it yy rr i <br>  you t yy <br>  you know u mm je i sh <br>  four ch it yy rr i <br>  anything sh t oo nn ib uu tt <br>  anything (2) ch t oo nn ib uu tt <br>  anything (3) ch t oo nn ibu tt <br></div></div><br>  The dictionary is converted into a language model understandable for the CMU Sphinx engine.  So, in the end, it looks like a speech recognition process. <br><br><iframe width="560" height="315" src="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://www.youtube.com/embed/BkOiylkbPXI%3Ffeature%3Doembed&amp;xid=17259,1500008,15700022,15700186,15700190,15700253&amp;usg=ALkJrhjRlcJz_e6XuhuV5ZRCrboh8G2xtg" frameborder="0" allowfullscreen=""></iframe>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      In ROS, any program node, subscribing to the topic / recognizer / output, can now receive text-based sentences built with the CMU Sphinx language model.  We wrote a small voice control node that receives recognized phrases and converts them into patrol commands or synthesizes robot response phrases.  Below you will find a video on this topic. <br><br><h4>  Speech synthesis in the Festival </h4><br>  For full communication with the robot, there is not enough reverse voice response.  Our bot, Tod, was helped to speak on the Festival-accessible Linux speech synthesis package.  Festival is also a joint development of several large universities, which provides high-quality speech synthesis and supports the Russian language.  On the basis of a bunch of Sphinx / Festival, you can implement full-fledged dialogues.  And here is a video demonstrating the use of voice commands of our robot. <br><br><iframe width="560" height="315" src="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://www.youtube.com/embed/JJTdRu-mdbE%3Ffeature%3Doembed&amp;xid=17259,1500008,15700022,15700186,15700190,15700253&amp;usg=ALkJrhhOORZ_ua5oa_eZoC5HrokH1hNOAQ" frameborder="0" allowfullscreen=""></iframe><br><br><h4>  And what else can you hear? </h4><br>  Speaking about the task associated with the sound, it is impossible not to mention the HARK.  HARK is a Japanese sound software that greatly expands the ability to process sound.  Here are some of them: <br><ul><li>  sound source localization </li><li> highlighting of several useful sound sources (for example, phrases of several people speaking at the same time) </li><li>  noise filtering to extract "clean" speech from the audio stream </li><li>  creating a three-dimensional audio effect for the telepresence task </li></ul><br><br><img src="https://habrastorage.org/getpro/habr/post_images/1de/fb8/1d7/1defb81d70bb7826c043488037c804d9.png"><br><br>  It does not make much sense to use HARK with only one microphone, since most sound processing tasks are solved on the basis of the so-called array of microphones.  And here Kinect fits in perfectly, with an array of 4 microphones attached to the front. <br>  We, of course, did not miss the opportunity to use HARK in our project.  In the process of patrolling the territory, the robot must respond to surrounding events, including the man‚Äôs addressing to it.  The sound source localization module provided by HARK can help the robot to find the interlocutor, even if it is not present in the direct line of sight.  Such a task is reduced to localizing the sound source and rotating the head so that it faces the other person.  How it looks, look in our video. <br><br><iframe width="560" height="315" src="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://www.youtube.com/embed/WfMZ1LAvc28%3Ffeature%3Doembed&amp;xid=17259,1500008,15700022,15700186,15700190,15700253&amp;usg=ALkJrhhJ2EPDTbpVdeLOr3q51Ihgszzt3Q" frameborder="0" allowfullscreen=""></iframe><br><br>  Regular readers of our blog, for sure, have noticed that since the last publication, the robot Tod has not only become smarter, but also has grown up, has acquired a manipulator and a second Kinect.  In the <a href="http://habrahabr.ru/company/tod/blog/216681/">next post</a> we will talk about how to control the manipulator and use it to capture objects.  See you again in our blog. </div><p>Source: <a href="https://habr.com/ru/post/214849/">https://habr.com/ru/post/214849/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../214833/index.html">What do gamedevs have in common with astronautics or work with PHP iterators?</a></li>
<li><a href="../214837/index.html">OrientDB - a simple example of working with graphs for beginners.</a></li>
<li><a href="../214839/index.html">Using GPIO from Python on Raspberry Pi</a></li>
<li><a href="../214841/index.html">5 ways to compare two byte arrays. Comparative Testing</a></li>
<li><a href="../214847/index.html">MMORPG without unnecessary details</a></li>
<li><a href="../214851/index.html">How to lose capital</a></li>
<li><a href="../214853/index.html">Startup Negotiations with the investor "amateur"</a></li>
<li><a href="../214855/index.html">Updated Opera for Android</a></li>
<li><a href="../214857/index.html">Conference DUMP-2014: Section "Testing"</a></li>
<li><a href="../214861/index.html">Objective-C Runtime in examples</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>