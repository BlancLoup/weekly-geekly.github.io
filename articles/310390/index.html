<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Removing Service Routing Mess With Docker</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="‚ÄúNot difficulties‚Äú break ‚Äùyou, but how you transfer them‚Äù - Lou Holtz 

 Co-authored by Emmet O'Grady (founder of NimbleCI and Docker Ninja) 


 In Fr...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Removing Service Routing Mess With Docker</h1><div class="post__text post__text-html js-mediator-article"><p><img src="https://habrastorage.org/files/c35/ba1/ad8/c35ba1ad8b264ccd8de5847930795492.png" alt="Removing Service Routing Mess With Docker"></p><br><blockquote>  ‚ÄúNot difficulties‚Äú break ‚Äùyou, but how you transfer them‚Äù - Lou Holtz </blockquote><p>  <strong>Co-authored by Emmet O'Grady (founder of NimbleCI and Docker Ninja)</strong> </p><br><p>  In Franz Kafka‚Äôs book ‚ÄúThe Transformation‚Äù (‚ÄúMetamorphoses‚Äù), a person wakes up one morning and discovers that he has turned into a giant insect-like creature.  Like DevOps engineers, we have the same surreal moments in life.  We find exotic errors ‚Äúunder the rug‚Äù (hidden in the most inaccessible places) or are attacked by worms or other dangerous entities.  If you have been doing this for a long time, you will sooner or later have a terrible story, or even two (share them with us!).  At such a moment we cannot sit and wait for the crisis to come, we must act quickly.  Hurrying to fix it as soon as possible, we must deploy a new entity and release a new version of our service, eliminating the problem. <a name="habracut"></a><br>  How about another surreal moment: your app gains popularity in the media, the crowded Slack channel (chat) or your internal bulletin board.  Users will come quickly and lightning-fast to your website, your service will be overwhelmed by them, the number of users will reach the limit and even go beyond it.  In a furious race, trying to fix error 502, you must find servers, start new entities, and reconfigure your network and your load balancers.  You frantically trying to put all the pieces together.  You feel as if you have to fight with a spoon against a knife.  Dreamily you think: ‚ÄúIt should be automated‚Äù, maybe then I will have more time to relax and read the classics. </p><br><p>  Do not experience more of these feelings!  Docker 1.12 will help you.  This release comes with a set of new features that provide the following conditions: </p><br><ul><li>  Rapid deployment and rollback of service </li><li>  Automatic load balancing </li><li>  Enable scaling of services and infrastructure in which they operate </li><li>  Restore service or failed nodes automatically </li></ul><br><p>  And when you learn what Docker offers, it will be easy to use. </p><br><h2>  Routing grid </h2><br><p>  Docker 1.12 provides a complete set of new definitions.  One of them is a new feature called ‚ÄúRouting Grid‚Äù.  Computer network geometry and its routing algorithm are not new; the genius of the Docker engineering team was to use this approach to simplify the delivery of software changes and the discovery service in the Micro Service Architecture.  ‚ÄúGrid‚Äù is just a new way of routing and balancing traffic in Docker 1.12 containers.  The new routing strategy allows the service to reach the same port on all nodes in Swarm, even if the node does not have a service deployed on it.  The routing grid also transparently distributes requests across all available services in Swarm, identifying failed nodes. </p><br><p><img src="https://habrastorage.org/files/069/f9e/45e/069f9e45ee2e4bf0b530fa643c7c998a.jpeg" alt="Does your network look the same today?"></p><br><p>  The new approach makes it very easy to set up load balancing services: imagine three Swarm nodes with seven different services running in Swarm.  From the outside, we can send a request to any node and it will be transferred (routed) to a random service automatically, or we can always send a request to a single node and Docker will internally distribute the balance between the services.  Thus, we obtain load balancing of services with our own internal forces. </p><br><p>  The routing grid allows us to process containers in a truly transparent way, in the sense that we are not worried about how many containers our application serves, the cluster processes the entire network and performs load balancing.  If before that we had to connect a reverse proxy server before the services, which was supposed to act as a load balancer, now we can relax and let the Docker do load balancing for us.  Since Docker does all the dirty work for us, the difference between when we have one container and 100 containers is now trivially small;  it's just a reason to have more computer (computational) resources to be able to scale and then run just one command to increase scaling.  We no longer need to think about architectural analysis before scaling, since all this is done by Docker.  When it starts scaling, we can relax, knowing that Docker will execute it transparently, for one container as well as 100. </p><br><p>  You may be wondering why we use the terminology ‚Äúservices‚Äù instead of ‚Äúcontainers‚Äù.  This is something new in Docker 1.12, let's see. </p><br><h2>  Services and Tasks </h2><br><p>  Docker 1.12 introduces a new abstraction - ‚Äúservices‚Äù.  Services determine the desired state of the containers in the cluster.  Internally, the kernel uses this new concept to ensure that the containers are running, handle errors, and route traffic to the containers. </p><br><p>  Let's dive a little deeper and discuss new task concepts.  Services consist of tasks representing a single container entity that should be running.  Swarm schedules these tasks between nodes.  Services for the most part define running container entities (tasks) that must be running all the time, just as they should work (configurations and flags for each container), as well as how to update them (for example, floating updates).  All of this together represents the desired state of the service, and the Docker kernel constantly monitors the current state of the cluster and makes changes to make sure that they match the state you want. </p><br><p>  Here is a small preview of the redis service, which will be discussed later in this article.  To run it, we need to execute a command like this: </p><br><pre><code class="bash hljs">$ docker service create --name redisdb --replicas=3 redis:alpine</code> </pre> <br><h2>  Routing grid in action </h2><br><p>  Enough theory, let's see it all in action.  We'll start with a small nodejs service that will help show the inner workings of the routing grid.  You will find the code on github <a href="https://github.com/lherrera/webapp">here</a> .  Let's take a look at the most important webapp.js file: </p><br><pre> <code class="javascript hljs"><span class="hljs-comment"><span class="hljs-comment">//  -,    ,  , IP    var http = require('http'); var os = require(‚Äúos‚Äù); var redis = require('redis'); var server = http.createServer(function (request, response) { //      ‚ÄúOK‚Äù response.writeHead(200, {‚ÄúContent-Type‚Äù: ‚Äútext/plain‚Äù}); //     log ,        var version = ‚Äú2.0‚Äù; var log = {}; log.header = 'webapp'; log.name = os.hostname(); log.version = version; //        IPv4 var interfaces = os.networkInterfaces(); var addresses = []; for (var k in interfaces) { for (var k2 in interfaces[k]) { var address = interfaces[k][k2]; if (address.family === 'IPv4' &amp;&amp; !address.internal) { addresses.push(address.address); } } } log.nics = addresses; //    redis- (redisdb)   var client = redis.createClient('6379', 'redisdb'); client.on('connect', function(err,reply) { if (err) return next(err); console.log('Connected to Redis server'); client.incr('counter', function(err, reply) { if(err) return next(err); console.log('This page has been viewed ' + reply + ' times!'); console.log(JSON.stringify(log)); response.end(‚Äú Hello, I'm version ‚Äú+ log.version +‚Äù.My hostname is ‚Äú+ log.name +‚Äù, this page has been viewed ‚Äú+ reply +‚Äù\n and my ip addresses are ‚Äú + log.nics + ‚Äú\n‚Äù ); }); // client.incr }); // client.on }); // http.createHttpServer //   http-   8000 server.listen(8000);</span></span></code> </pre> <br><p>  The service only returns the host name, the IP address of the container that launched it, and the counter with the number of visits. </p><br><p>  That's all our application.  Before diving into it, we must be sure that we have switched to Docker 1.12 </p><br><pre> <code class="bash hljs">$ docker version Client: Version: 1.12.0 API version: 1.24 Go version: go1.6.3 Git commit: 8eab29e Built: Thu Jul 28 21:04:48 2016 OS/Arch: darwin/amd64 Experimental: <span class="hljs-literal"><span class="hljs-literal">true</span></span> Server: Version: 1.12.0 API version: 1.24 Go version: go1.6.3 Git commit: 8eab29e Built: Thu Jul 28 21:04:48 2016 OS/Arch: linux/amd64 Experimental: <span class="hljs-literal"><span class="hljs-literal">true</span></span></code> </pre> <br><p>  We will start by creating a cluster of 3 nodes using a Docker machine: </p><br><pre> <code class="bash hljs">$ docker-machine create --driver virtualbox swarm-1 Running pre-create checks‚Ä¶ Creating machine‚Ä¶ ‚Ä¶ Setting Docker configuration on the remote daemon‚Ä¶ Checking connection to Docker‚Ä¶ Docker is up and running! ‚Ä¶ $ docker-machine create --driver virtualbox swarm-2 ‚Ä¶ Docker is up and running! $ docker-machine create --driver virtualbox swarm-3 ‚Ä¶ Docker is up and running! $ docker-machine ls NAME ACTIVE DRIVER STATE URL SWARM DOCKER ERRORS swarm-1 ‚Äî virtualbox Running tcp://192.168.99.106:2376 v1.12.0 swarm-2 ‚Äî virtualbox Running tcp://192.168.99.107:2376 v1.12.0 swarm-3 ‚Äî virtualbox Running tcp://192.168.99.108:2376 v1.12.0</code> </pre> <br><p>  For clarity, we have reduced the output of some commands.  Then, we set up our swarm.  Docker 1.12 makes it very easy to do this: </p><br><pre> <code class="bash hljs">$ <span class="hljs-built_in"><span class="hljs-built_in">eval</span></span> $(docker-machine env swarm-1) $ docker swarm init --advertise-addr $(docker-machine ip swarm-1) Swarm initialized: current node (bihyblm2kawbzd3keonc3bz0l) is now a manager. To add a worker to this swarm, run the following <span class="hljs-built_in"><span class="hljs-built_in">command</span></span>: docker swarm join \ --token SWMTKN-1‚Äì1n7gtfmvvrlwo91pv4r59vsdf73bwuwodj3saq0162vcsny89l-5zige8u81ug5adk3o4bsx32fi \ 192.168.99.106:2377 ‚Ä¶</code> </pre> <br><p>  Now, we will copy and paste the command, which was at the output of the previous command for the ‚Äúworker‚Äù node, in the other two nodes </p><br><pre> <code class="bash hljs">$ <span class="hljs-built_in"><span class="hljs-built_in">eval</span></span> $(docker-machine env swarm-2) $ docker swarm join \ --token SWMTKN-1‚Äì1n7gtfmvvrlwo91pv4r59vsdf73bwuwodj3saq0162vcsny89l-5zige8u81ug5adk3o4bsx32fi \ 192.168.99.106:2377 This node joined a swarm as a worker. $ <span class="hljs-built_in"><span class="hljs-built_in">eval</span></span> $(docker-machine env swarm-3) $ docker swarm join \ --token SWMTKN-1‚Äì1n7gtfmvvrlwo91pv4r59vsdf73bwuwodj3saq0162vcsny89l-5zige8u81ug5adk3o4bsx32fi \ 192.168.99.106:2377 ‚Ä¶ This node joined a swarm as a worker.</code> </pre> <br><p>  Note: when you initialize a new swarm, the command will output two new commands that you can use to attach other nodes to the swarm.  Don't worry about losing these commands;  You can get them again at any time by running the ‚Äúdocker swarm join-token worker | manager‚Äù. </p><br><p>  Before continuing, let's make sure that our swarm cluster is functioning.  We specify our Docker client for the manager node and check its status: </p><br><pre> <code class="bash hljs">$ <span class="hljs-built_in"><span class="hljs-built_in">eval</span></span> $(docker-machine env swarm-1) $ docker node ls ID HOSTNAME STATUS AVAILABILITY MANAGER STATUS 5jqsuf8hsemi7bfbwzfdxfcg5 swarm-2 Ready Active 93f0ghkpsh5ru7newtqm82330 swarm-3 Ready Active b2womami9n2t8tti1acvz6v5j * swarm-1 Ready Active Leader $ docker info ‚Ä¶ Swarm: active NodeID: b2womami9n2t8tti1acvz6v5j Is Manager: <span class="hljs-literal"><span class="hljs-literal">true</span></span> ClusterID: bimg9n2ti2tnsprkdjqg07tdm Managers: 1 Nodes: 3 Orchestration: Task History Retention Limit: 5 Raft: Snapshot interval: 10000 Heartbeat tick: 1 Election tick: 3 Dispatcher: Heartbeat period: 5 seconds CA configuration: Expiry duration: 3 months Node Address: 192.168.99.106</code> </pre> <br><p>  Let's start creating a new network, which we will use for our examples: </p><br><pre> <code class="bash hljs">$ docker network create --driver overlay webnet a9j4al25hzhk2m7rdfv5bqt54</code> </pre> <br><p>  Thus, we are now ready to launch a new service for Swarm.  We'll start by running the redis database and the ‚Äúlherrera / webapp‚Äù container, which saves the visit pages to redis and displays other interesting details, such as the host name and container IP address. </p><br><p>  When we deploy our web application, it becomes possible for it to connect to the redis database using the Redis ‚Äúredisdb‚Äù service.  We do not need to use IP addresses, because Swarm has an internal DNS that automatically assigns a DNS record to each service.  Everything is very simple! </p><br><p>  We can only deploy services from the control nodes.  As long as your Docker client still points to the control node, we can just type ‚Äúdocker service create‚Äù on the command line: </p><br><pre> <code class="bash hljs">$ docker service create --name webapp --replicas=3 --network webnet --publish 80:8000 lherrera/webapp:1.0 avq41soybmtw2jamdus0m3pg $ docker service create --name redisdb --network webnet --replicas 1 redis:alpine bmotumdr8bcewcfj6zqkws97x $ docker service ls ID NAME REPLICAS IMAGE COMMAND avq41soybmtw webapp 3/3 lherrera/webapp:1.0 bmotumdr8bce redisdb 1/1 redis:alpine</code> </pre> <br><p>  In the service creation team, we need to specify at least an image (in our case, lherrera / webapp).  By convention, we also specify the name of the webapp.  We must also specify the command in order to launch inside the containers only after (connecting) the image.  In the previous command, we also specify that we want three replicas of the container running at any current time.  Using the ‚Äú- replicas‚Äù flag means that we do not have to worry about which node it goes to, if we want one service per node, we can use the ‚Äú- mode = global‚Äù command instead. </p><br><p>  You can see that we are using the ‚Äúwebnet‚Äù network that we created earlier.  To be able to create our service from outside Swarm, we need to specify the port on which the Swarm listens for web requests.  In our example, we ‚Äúset‚Äù port 8000 inside the service to port 80 on all nodes.  Thanks to the routing grid, it will reserve port 80 on all routing nodes and the Docker Engine will balance traffic between port 8000 in all container replicas. </p><br><p>  Swarm will use the description of this service as the desired state for your application and will begin to deploy the application on the nodes to achieve and maintain this desired state.  We could specify additional service parameters to complete our description, such as reload rules, memory and CPU resource limits, node containers, etc.  For a complete list of all available flags, you can use the ‚Äúdocker service create‚Äù command (see here). </p><br><p>  At this stage, we can be sure that our web application is correctly connected to the webnet network. </p><br><pre> <code class="bash hljs">$ docker network ls NETWORK ID NAME DRIVER SCOPE df19a5c87d90 bridge bridge <span class="hljs-built_in"><span class="hljs-built_in">local</span></span> 7c5762c8c6ff docker_gwbridge bridge <span class="hljs-built_in"><span class="hljs-built_in">local</span></span> eb0bd5a4920b host host <span class="hljs-built_in"><span class="hljs-built_in">local</span></span> bqqh4te5f5tf ingress overlay swarm 3e06a1616b7b none null <span class="hljs-built_in"><span class="hljs-built_in">local</span></span> a9j4al25hzhk webnet overlay swarm $ docker service inspect webapp ‚Ä¶ ‚ÄúVirtualIPs‚Äù: [ { ‚ÄúNetworkID‚Äù: ‚Äú7i9t9uhtr7x0hybsvnsheh92u‚Äù, ‚ÄúAddr‚Äù: ‚Äú10.255.0.6/16‚Äù }, { ‚ÄúNetworkID‚Äù: ‚Äúa9j4al25hzhk2m7rdfv5bqt54‚Äù, ‚ÄúAddr‚Äù: ‚Äú10.0.0.4/24‚Äù } ] }, ‚Ä¶</code> </pre> <br><p>  Now let's go back to our example and make sure that our service is up and running: </p><br><pre> <code class="bash hljs">$ docker service ps webapp ID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR bb8n4iagxcjv4rn2oc3dj6cvy webapp.1 lherrera/webapp:1.0 swarm-1 Running Preparing about a minute ago chndeorlvglj45alr4vhy50vg webapp.2 lherrera/webapp:1.0 swarm-3 Running Preparing about a minute ago 4txay0gj6p18iuiknacdoa91x webapp.3 lherrera/webapp:1.0 swarm-2 Running Preparing about a minute ago</code> </pre> <br><p>  One question that you need to be aware of: although the Docker-service creates a team that quickly returns with id, the actual scaling of the service can take some time, especially if the images must reside on the nodes.  In this case, just run the ‚Äúdocker service ps webapp‚Äù command several times until all the replicas are provided to the service. </p><br><p>  When the services are running (it may take a few minutes, get some coffee for this time), we can check that our services receive in response to requests. <br>  Initially, we need to get the IP of the first node: </p><br><pre> <code class="bash hljs">$ NODE1=$(docker-machine ip swarm-1)</code> </pre> <br><p>  Then we will set port 80 for that IP address, because we published a service on port 80 in Swarm.  We use curl in the example below, but you can also set the IP in your browser to get the same result. </p><br><p><img src="https://habrastorage.org/files/c8b/37f/485/c8b37f48598440cf9a4f788eddf9706d.png"></p><br><p>  Now, we are ready to test our new service: </p><br><pre> <code class="bash hljs">$ curl <span class="hljs-variable"><span class="hljs-variable">$NODE1</span></span> Hello, I<span class="hljs-string"><span class="hljs-string">'m version 1.0.My hostname is 5a557d3ed474, this page has been viewed 1 and my ip addresses are 10.255.0.9,10.255.0.6,172.18.0.3,10.0.0.7,10.0.0.4 $ curl $NODE1 Hello, I'</span></span>m version 1.0.My hostname is 4e128c8af4ae, this page has been viewed 2 and my ip addresses are 10.255.0.7,10.255.0.6,172.18.0.3,10.0.0.5,10.0.0.4 $ curl <span class="hljs-variable"><span class="hljs-variable">$NODE1</span></span> Hello, I<span class="hljs-string"><span class="hljs-string">'m version 1.0.My hostname is eaa73f01996c, this page has been viewed 3 and my ip addresses are 10.255.0.8,10.255.0.6,172.18.0.4,10.0.0.6,10.0.0.4</span></span></code> </pre> <br><p>  We can see that the first request was sent to container ‚Äú5a557d3ed474‚Äù.  If you hit ‚Äúrefresh‚Äù a few times or call ‚Äúcurl‚Äù again from the command line, you will see a request that was sent to all three replicas of the containers we created. </p><br><p>  To demonstrate other aspects of the routing grid, try ‚Äúassign‚Äù port 80 to the IP of the other two Docker nodes.  You will see the same thing as before, it follows from this that it does not matter which node you requested;  above the request, internal load balancing between the three containers will always be performed. </p><br><h2>  Floating Updates (Rolling Updates) </h2><br><p>  As part of the service description, you can set a strategy for updating your service.  For example, you can use the <code>‚Äî update-delay</code> flag to configure the delay between updates for a service task (container) or task set.  Or you can use the <code>‚Äî update-parallelism</code> flag to change the default behavior: updating one container at a time.  You can set all these flags in the process of creating a service or later using the ‚Äúdocker service update‚Äù command, as we will see in the following example.  The update command requires almost identical parameters with the ‚Äúdocker service create‚Äù command, but some flags have different names with the update command.  Everything you can install in the create command you can change in the update command, so you have complete freedom to change any part of the service description at any time. </p><br><p><img src="https://habrastorage.org/files/31c/5be/0c2/31c5be0c232d41a2ab925fb831b285ad.png" alt="Apply rolling updates manually: run downhill, realizing that you are out of control"></p><br><p>  Let's update our webapp service to see how the ‚Äúrolling update‚Äù mechanism works.  The development team worked hard to improve the webapp and we released a new tag called ‚Äú2.0‚Äù.  Now we will update our new service with this new image: </p><br><pre> <code class="bash hljs">$ docker service update --update-parallelism 1 --update-delay 5s --image lherrera/webapp:2.0 webapp</code> </pre> <br><p>  Note that we also indicated that we want the update to happen one at a time and set the interval to 5 seconds between each update.  This approach means that we will not have any downtime! </p><br><p>  While updates are taking place, watch them in real time, launching ‚Äúdocker service ps webapp‚Äù every few seconds.  You will see old images that are turned off one by one and replaced by new ones: </p><br><pre> <code class="bash hljs">$ docker service ps webapp ID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR 7bdpfbbjok78zt32xd9e2mqlt webapp.1 lherrera/webapp:2.0 swarm-3 Running Running 43 seconds ago bb8n4iagxcjv4rn2oc3dj6cvy \_ webapp.1 lherrera/webapp:1.0 swarm-1 Shutdown Shutdown 44 seconds ago af2rlu0laqhrj3uz8brym0f8r webapp.2 lherrera/webapp:2.0 swarm-2 Running Running 30 seconds ago chndeorlvglj45alr4vhy50vg \_ webapp.2 lherrera/webapp:1.0 swarm-3 Shutdown Shutdown 30 seconds ago 0xjt6gib1hql10iqj6866q4pe webapp.3 lherrera/webapp:2.0 swarm-1 Running Running 57 seconds ago 4txay0gj6p18iuiknacdoa91x \_ webapp.3 lherrera/webapp:1.0 swarm-2 Shutdown Shutdown 57 seconds ago</code> </pre> <br><p>  This is just something incredible! </p><br><p>  If our application also prints a version of the image, another way to see updates in real time is to press the service (end point) repeatedly during the update.  When the service is updated, you will slowly see more and more requests returning ‚Äúversion 2.0‚Äù until the update is complete and all services return version 2.0. </p><br><pre> <code class="bash hljs">$ curl <span class="hljs-variable"><span class="hljs-variable">$NODE1</span></span> Hello, I<span class="hljs-string"><span class="hljs-string">'m version 1.0.My hostname is 5a557d3ed474, this page has been viewed 4 and my ip addresses are 10.255.0.9,10.255.0.6,172.18.0.3,10.0.0.7,10.0.0.4 $ curl $NODE1 Hello, I'</span></span>m version 2.0.My hostname is e0899324d9df, this page has been viewed 5 and my ip addresses are 10.255.0.10,10.255.0.6,172.18.0.4,10.0.0.8,10.0.0.4 $ curl <span class="hljs-variable"><span class="hljs-variable">$NODE1</span></span> ...</code> </pre> <br><p>  Please note that Redis considers continuations ineffective (the Redis service graph is unchanged), since we did not change the Redis service, only the webapp image. </p><br><h2>  Growth problem solution </h2><br><p>  A swarm of honey bees is a familiar sight at the beginning of summer.  Honey bees instinctively use survival in a colony by joining together in a swarm when they become many.  And we do the same in our container clusters. </p><br><p><img src="https://habrastorage.org/files/1f2/d0e/13a/1f2d0e13a1a8445e9bfbc6e9d5e0e638.png" alt="Let's unite in a swarm ..."></p><br><p>  Let's say that our node has reached the power limit and we need to add an additional node to our cluster.  It's that simple, you can do it with just 4 teams!  For clarity, we are going to use a few more to make sure that what is happening is well understood. </p><br><pre> <code class="bash hljs">$ docker-machine create -d virtualbox swarm-4 ‚Ä¶ Docker is up and running! Join the node the swarm as a worker as before: $ <span class="hljs-built_in"><span class="hljs-built_in">eval</span></span> $(docker-machine env swarm-4) $ docker swarm join \ --token SWMTKN-1‚Äì1n7gtfmvvrlwo91pv4r59vsdf73bwuwodj3saq0162vcsny89l-5zige8u81ug5adk3o4bsx32fi \ 192.168.99.106:2377 This node joined a swarm as a worker.</code> </pre> <br><p>  Verify that both the new host and the webapp service are running: </p><br><pre> <code class="bash hljs">$ <span class="hljs-built_in"><span class="hljs-built_in">eval</span></span> $(docker-machine env swarm-1) $ docker node ls ID HOSTNAME STATUS AVAILABILITY MANAGER STATUS 93f0ghkpsh5ru7newtqm82330 swarm-3 Ready Active e9rxhj0w1ga3gz89g927qvntd swarm-4 Ready Active 5jqsuf8hsemi7bfbwzfdxfcg5 swarm-2 Ready Active b2womami9n2t8tti1acvz6v5j * swarm-1 Ready Active Leader $ docker service ps webapp ID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR 7bdpfbbjok78zt32xd9e2mqlt webapp.1 lherrera/webapp:2.0 swarm-3 Running Running 5 minutes ago bb8n4iagxcjv4rn2oc3dj6cvy \_ webapp.1 lherrera/webapp:1.0 swarm-1 Shutdown Shutdown 5 minutes ago af2rlu0laqhrj3uz8brym0f8r webapp.2 lherrera/webapp:2.0 swarm-2 Running Running 5 minutes ago chndeorlvglj45alr4vhy50vg \_ webapp.2 lherrera/webapp:1.0 swarm-3 Shutdown Shutdown 5 minutes ago 0xjt6gib1hql10iqj6866q4pe webapp.3 lherrera/webapp:2.0 swarm-1 Running Running 6 minutes ago 4txay0gj6p18iuiknacdoa91x \_ webapp.3 lherrera/webapp:1.0 swarm-2 Shutdown Shutdown 6 minutes ago luis@aurelio [13:14:27] [~/webapp] [2.0]</code> </pre> <br><p>  Now let's activate our webapp service for four replicas: </p><br><pre> <code class="bash hljs">$ docker service update --replicas=4 webapp</code> </pre> <br><p>  We have to wait a few minutes for the image to load on the new nodes: </p><br><pre> <code class="bash hljs">$ docker service ps webapp ID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR 7bdpfbbjok78zt32xd9e2mqlt webapp.1 lherrera/webapp:2.0 swarm-3 Running Running 10 minutes ago bb8n4iagxcjv4rn2oc3dj6cvy \_ webapp.1 lherrera/webapp:1.0 swarm-1 Shutdown Shutdown 10 minutes ago af2rlu0laqhrj3uz8brym0f8r webapp.2 lherrera/webapp:2.0 swarm-2 Running Running 10 minutes ago chndeorlvglj45alr4vhy50vg \_ webapp.2 lherrera/webapp:1.0 swarm-3 Shutdown Shutdown 10 minutes ago 0xjt6gib1hql10iqj6866q4pe webapp.3 lherrera/webapp:2.0 swarm-1 Running Running 10 minutes ago 4txay0gj6p18iuiknacdoa91x \_ webapp.3 lherrera/webapp:1.0 swarm-2 Shutdown Shutdown 10 minutes ago 81xbk0j61tqg76wcdi35k1bxv webapp.4 lherrera/webapp:2.0 swarm-4 Running Running 20 seconds ago</code> </pre> <br><p>  Just, yes?  Bees in a swarm are always in a good mood! </p><br><p>  For global services (as opposed to replication, as we saw in the example), Swarm launches a new task automatically for a service on a new available node. </p><br><h2>  Routing stability </h2><br><p>  If something is not going well enough, the cluster will manage the state of these services (for example, running replicas) and, in the event of a failure, restore the service to the desired state.  In this scenario, new containers and IP addresses appear and disappear.  Fortunately, the new built-in service discovery mechanism will help us adapt our services to these situations and container failures and even now a complete node failure will go unnoticed. </p><br><p><img src="https://habrastorage.org/files/e1b/131/91c/e1b13191c21d4c49b7bb337d8dc05a81.png" alt="Network Routing in a Traditional Failover Environment (HA Environment)"></p><br><p>  To see this in action, we will continue to look at our example and simulate the node of our small failed cluster. </p><br><p>  Let's make sure our webapp is still running on our cluster: </p><br><pre> <code class="bash hljs">$ docker service ps webapp ID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR 7bdpfbbjok78zt32xd9e2mqlt webapp.1 lherrera/webapp:2.0 swarm-3 Running Running 10 minutes ago bb8n4iagxcjv4rn2oc3dj6cvy \_ webapp.1 lherrera/webapp:1.0 swarm-1 Shutdown Shutdown 10 minutes ago af2rlu0laqhrj3uz8brym0f8r webapp.2 lherrera/webapp:2.0 swarm-2 Running Running 10 minutes ago chndeorlvglj45alr4vhy50vg \_ webapp.2 lherrera/webapp:1.0 swarm-3 Shutdown Shutdown 10 minutes ago 0xjt6gib1hql10iqj6866q4pe webapp.3 lherrera/webapp:2.0 swarm-1 Running Running 10 minutes ago 4txay0gj6p18iuiknacdoa91x \_ webapp.3 lherrera/webapp:1.0 swarm-2 Shutdown Shutdown 10 minutes ago 81xbk0j61tqg76wcdi35k1bxv webapp.4 lherrera/webapp:2.0 swarm-4 Running Running 20 seconds ago</code> </pre> <br><p>  Nodes: </p><br><pre> <code class="bash hljs">$ docker node ls ID HOSTNAME STATUS AVAILABILITY MANAGER STATUS 21z5m0vik76msi90icrf8prvf swarm-3 Ready Active 7zyckxuwsruehcfosgymwiucm swarm-4 Ready Active 9aso727d8c4vc59cxu0e8g778 swarm-2 Ready Active bihyblm2kawbzd3keonc3bz0l * swarm-1 Ready Active Leader</code> </pre> <br><p>  This is where the fun begins - who doesn't like to shut down working nodes to see what happens? </p><br><pre> <code class="bash hljs">$ docker-machine stop swarm-2</code> </pre> <br><p>  Let's see how our services responded: </p><br><pre> <code class="bash hljs">$ docker service ps webapp ID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR 7bdpfbbjok78zt32xd9e2mqlt webapp.1 lherrera/webapp:2.0 swarm-3 Running Running 11 minutes ago bb8n4iagxcjv4rn2oc3dj6cvy \_ webapp.1 lherrera/webapp:1.0 swarm-1 Shutdown Shutdown 11 minutes ago af2rlu0laqhrj3uz8brym0f8r webapp.2 lherrera/webapp:2.0 swarm-4 Running Running 11 minutes ago chndeorlvglj45alr4vhy50vg \_ webapp.2 lherrera/webapp:1.0 swarm-3 Shutdown Shutdown 11 minutes ago 0xjt6gib1hql10iqj6866q4pe webapp.3 lherrera/webapp:2.0 swarm-1 Running Running 11 minutes ago 4txay0gj6p18iuiknacdoa91x \_ webapp.3 lherrera/webapp:1.0 swarm-4 Shutdown Shutdown 11 minutes ago 15pxa5ccp9fqfbhdh76q78aza webapp.4 lherrera/webapp:2.0 swarm-3 Running Running 4 seconds ago 81xbk0j61tqg76wcdi35k1bxv \_ webapp.4 lherrera/webapp:2.0 swarm-2 Shutdown Running about a minute ago</code> </pre> <br><p>  Great!  Docker deployed a new container on the swarm-3 node, after we ‚Äúkilled‚Äù the swarm-2 node.  As you can see, we still have three running replicas (two in the ‚Äúswarm-3‚Äù node) ... </p><br><pre> <code class="bash hljs">$ curl <span class="hljs-variable"><span class="hljs-variable">$NODE1</span></span> Hello, I<span class="hljs-string"><span class="hljs-string">'m version 2.0.My hostname is 0d49c828b675, this page has been viewed 7 and my ip addresses are 10.0.0.7,10.0.0.4,172.18.0.4,10.255.0.10,10.255.0.6 $ curl $NODE1 Hello, I'</span></span>m version 2.0.My hostname is d60e1881ac86, this page has been viewed 8 and my ip addresses are 10.0.0.7,10.0.0.4,172.18.0.4,10.255.0.10,10.255.0.6</code> </pre> <br><p>  And the traffic is automatically redirected to the newly created container! </p><br><h2>  Swarm growth and development </h2><br><p>  Software changes fast.  Failures happen, and they inevitably occur when you least expect it.  A new abstraction ‚Äúservices‚Äù was introduced in Docker 1.12, simplifying updates and preventing downtime and service failures.  In addition, this new approach makes planning and maintaining long-running services, such as a web server, much easier.  You can now deploy a replicable, distributed, load-balanced service to Swarm on the Docker Engine with a few commands.  A cluster can manage the state of your services and even bring the service to the desired state if the node or container has failed. </p><br><p>  Solomon Hykes well described how we hope to make the life of developers simpler: ‚ÄúWith the development of instrumentation, networks and security in our orchestration (orchestration) tools, Docker connects developers to build more complex applications that can be developed on a scale from a desktop computer to the cloud, regardless of basic infrastructure. ‚Äù </p><br><p>  With the release of Docker 1.12, we think it will surely deliver its promise.  Docker makes things simpler, I hope this is the moment when these surreal moments that we mentioned at the beginning will disappear.  Do you have any other surrealistic moments in DevOps?  Share this with us! </p><br><h2>  More information and links to Docker 1.12 </h2><br><ul><li>  <a href="https://www.youtube.com/watch%3Fv%3DdooPhkXT9yI%25E2%2580%258A">https://www.youtube.com/watch?v=dooPhkXT9yI</a> is an excellent in-depth look at the specifics of how Swarm nodes work and exchange information among themselves. </li><li>  <a href="https://www.youtube.com/watch%3Fv%3D_F6PSP-qhdA">https://www.youtube.com/watch?v=_F6PSP-qhdA</a> is an in-depth review part 2, focused on how orchestrated services are orchestrated and how failures are handled. </li></ul></div>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <p>Source: <a href="https://habr.com/ru/post/310390/">https://habr.com/ru/post/310390/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../310378/index.html">Monetization OpenStack. From private cloud to ready-made business in 72 hours</a></li>
<li><a href="../310380/index.html">The complete guide to web consoles 2016: cPanel, Plesk, ISPmanager and others</a></li>
<li><a href="../310382/index.html">Creating a project in Adobe Captivate in stages using the example of an on-board computer model for a live-action role-playing game.</a></li>
<li><a href="../310384/index.html">The Macro: Corporate Commerce Guide for Y Combinator Residents</a></li>
<li><a href="../310386/index.html">Improve the work of the largest media about online business with the help of a customized referral system</a></li>
<li><a href="../310392/index.html">CTRL + G - hot key, completely changed the principle of my work</a></li>
<li><a href="../310396/index.html">Collaboration with documents: SharePoint 2016, Office Online and all-all-all. Part 1. What is it?</a></li>
<li><a href="../310398/index.html">Countdown: a book about Stuxnet, malware researchers and vulnerable critical infrastructure</a></li>
<li><a href="../310402/index.html">Ontodia + Cach√© - an ontology visualizer for navigating InterSystems Cach√© stored entities</a></li>
<li><a href="../310404/index.html">How I Made a Game of Indians of Central America</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>