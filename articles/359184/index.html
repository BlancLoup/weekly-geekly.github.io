<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>AI, practical course. Comparison of deep learning software</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="At a certain stage of your AI project, you will have to decide which machine learning environment you will use. For some tasks, traditional machine le...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>AI, practical course. Comparison of deep learning software</h1><div class="post__text post__text-html js-mediator-article">  At a certain stage of your AI project, you will have to decide which machine learning environment you will use.  For some tasks, traditional machine learning algorithms will suffice.  However, if you are working with a large amount of text, images, video or voice data, it is recommended to use deep learning. <br>  So which deep learning environment to choose?  This article is devoted to a comparative analysis of existing deep learning environments. <br><br><img src="https://habrastorage.org/webt/lz/5e/8r/lz5e8rzjv31crits-8tndm6fzly.png"><br><a name="habracut"></a><br><h2>  <font color="#0071c5">general information</font> </h2><br>  Deep learning environments simplify the development and training of deep learning models by providing the simplest high-level elements for complex and unreliable mathematical transformations, such as gradient descent, backward propagation, and inference. <br><br>  Choosing the right environment is not easy, because this area is still poorly developed, and at the moment there is no absolutely winning option.  Also, the choice of environment may depend on your goals, resources and team. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      We will focus on environments that have versions optimized by Intel and that can work efficiently on new CPUs (for example, Intel Xeon Phi processors) optimized for matrix multiplication. <br><br><h3>  <font color="#0071c5">Criteria for evaluation</font> </h3><br>  We evaluated media in two stages. <br><br><ol><li>  At first, we quickly evaluated them for their compliance with the basic criterion of community activity. </li><li>  After that, we performed a deeper and thorough analysis of each environment. </li></ol><br><h3>  <font color="#0071c5">Preliminary estimate</font> </h3><br>  Every Wednesday we evaluated based on community activity and participants' ratings. <br>  <a href="https://github.com/">Github</a> <br><br><ul><li>  Stars of the repository (tracking interesting projects) </li><li>  Forks of the repository (free experimentation with changes) </li><li>  The number of commits for the last month (indicates whether the project is active) </li></ul><br>  <a href="https://stackoverflow.com/">Stack overflow</a> <br><br><ul><li>  Number of asked and answered programming questions </li><li>  Informal popularity rating for citing (web search engines, articles, blogs, etc.) </li></ul><br><h3>  <font color="#0071c5">Detailed analysis</font> </h3><br><br><ul><li>  Each medium was carefully analyzed based on the following criteria: </li><li>  Availability of pre-trained models. </li><li>  Licensing model. </li><li>  Connect to a research university or academy. </li><li>  Availability of information on large-scale deployments by respected companies. </li><li>  Reference standards: </li><li>  The presence of a dedicated cloud environment optimized for the library; </li><li>  Availability of debugging tools (for example, visualization and model checkpoints). </li><li>  Training; </li><li>  Engineering productivity; </li><li>  Compatibility (supported languages ‚Äã‚Äãfor writing applications); </li><li>  Open source; </li><li>  Supported operating systems and platforms; </li><li>  Language implementation environment. </li><li>  Supported families of algorithms and deep learning models </li></ul><br><h2>  <font color="#0071c5">Deep learning environments</font> </h2><br>  According to the results of our analysis of popular media, we have compiled the following table for evaluating each medium by popularity and activity. <br><br>  <b>The overall popularity and activity of different environments</b> <br><table><tbody><tr><th>  Deep learning environment </th><th>  Number of stars GitHub </th><th>  Number of forks GitHub </th><th>  Number of GitHub commits in the last month </th><th>  Number of questions Stack Overflow </th></tr><tr><td>  Tensorflow </td><td>  60 030 </td><td>  28,808 </td><td>  1127 </td><td>  12 118 </td></tr><tr><td>  Caffe </td><td>  18 354 </td><td>  11,277 </td><td>  12 </td><td>  4355 </td></tr><tr><td>  Keras </td><td>  16 344 </td><td>  5788 </td><td>  71 </td><td>  2754 </td></tr><tr><td>  Microsoft Cognitive Toolkit </td><td>  11,250 </td><td>  2823 </td><td>  337 </td><td>  545 </td></tr><tr><td>  MXNet </td><td>  9951 </td><td>  3730 </td><td>  230 </td><td>  289 </td></tr><tr><td>  Torch </td><td>  6963 </td><td>  2062 </td><td>  7 </td><td>  722 </td></tr><tr><td>  Deeplearning4J </td><td>  6800 </td><td>  3168 </td><td>  172 </td><td>  316 </td></tr><tr><td>  Theano </td><td>  6417 </td><td>  2154 </td><td>  100 </td><td>  2207 </td></tr><tr><td>  Wednesday neon </td><td>  3043 </td><td>  665 </td><td>  38 </td><td>  0 </td></tr></tbody></table><br><img src="https://habrastorage.org/webt/ht/4v/s4/ht4vs4da7qzek1tgcdqml388vgo.png"><br><br>  According to these data, the most popular environments are TensorFlow, Caffe, Keras, Microsoft Cognitive Toolkit (formerly known as CNTK), MXNet, Torch, Deeplearning4j (DL4J) and Theano.  The popularity of the neon environment is also growing.  We will cover these environments in the next section. <br><br><h2>  <font color="#0071c5">Learn more about the most popular environments.</font> </h2><br>  In-depth learning environments vary in their level of functionality.  Some of them, such as Theano and TensorFlow, allow you to define neural networks of arbitrary level of complexity using the most basic structural elements.  Environments of this type can even be called languages.  Other environments, such as Keras, are engines or shells designed to increase developer productivity, but are limited in functionality due to a higher level of abstraction. <br><br>  When choosing a deep learning environment, you must first choose a low-level environment.  A high-level shell may be a good addition, but it is not required.  As ecosystems mature, more and more low-level environments will be complemented by higher-level satellites. <br><br><h3>  <font color="#0071c5">Caffe</font> </h3><br>  <a href="http://caffe.berkeleyvision.org/">Caffe</a> is a deep learning environment that is designed with expression, speed, and modularity in mind.  It was created by Berkeley AI Research (BAIR) with the participation of community members.  Yangqing Jia created a project during his doctoral thesis at the University of California at Berkeley.  The Caffe Library is licensed under article 2 on the distribution of Berkeley University software. <br><br>  Important features: <br><br><ul><li>  expressive architecture fosters application and innovation; </li><li>  extensible code stimulates active development; </li><li>  Speed ‚Äã‚Äã- Caffe offers one of the fastest deployment options for convolutional neural networks (CNN). </li><li>  Used for research projects, prototypes of start-ups and even large-scale production applications in the field of vision, speech and multimedia. </li></ul><br><h3>  <font color="#0071c5">Microsoft Cognitive Toolkit</font> </h3><br>  <a href="https://www.microsoft.com/en-us/cognitive-toolkit/">Microsoft Cognitive Toolkit</a> (formerly called CNTK) is a unified set of tools for deep learning that presents neural networks as a series of computational actions through a directed graph.  In the graph, leaves represent input values ‚Äã‚Äãor network parameters, and other nodes represent matrix operations in response to input values.  The toolkit makes it easy to implement and combine popular types of models, for example, pre-emptive deep neural networks, convolutional neural networks, recurrent neural networks (RNN) and networks with long short-term memory (LSTM).  It implements learning on the principle of stochastic gradient descent (SGD, backward error propagation) with automatic differentiation and parallelization across several GPUs and servers.  The library has been licensed for open source software since April 2015. <br><br>  Important features. <br><br><ul><li>  Speed ‚Äã‚Äãand Scalability: Teaches and analyzes deep learning algorithms faster than other available toolkits, effectively scaling in different environments. </li><li>  Quality at the level of commercial products. </li><li>  Compatibility: has the most expressive and easy-to-use architecture with well-known languages ‚Äã‚Äãand networks, such as C ++ and Python *. </li></ul><br><h3>  <font color="#0071c5">Keras</font> </h3><br>  <a href="https://keras.io/">Keras</a> is a high-level neural network API written in Python.  This library can be used in addition to TensorFlow or Theano.  The Keras library is mainly intended to speed up experiments.  An important condition for successful research is the possibility of transition from the idea to the result with the minimum possible delay. <br><br>  Important features. <br><br><ul><li>  User-friendly: minimizes the number of user actions required in standard situations, and also provides clear and practical instructions in the event of a user error. </li><li>  Modular design: A model is considered as a sequence or graph of autonomous, fully configurable modules that can be connected together with a minimum number of restrictions. </li><li>  Simple extension: new modules are easily added as new classes and functions, and existing modules provide enough examples. </li></ul><br><h3>  <font color="#0071c5">DeepLearning4j</font> </h3><br>  <a href="https://deeplearning4j.org/">Deeplearning4j</a> (DL4J) is the first distributed open source deep learning library for commercial use written for Java * and Scala *.  The DL4J library is integrated with Hadoop * and Apache Spark * and is intended for use in corporate environments on distributed graphics processors (GPUs) and CPUs.  DL4J is a state-of-the-art, ready-to-use library that is more standard-oriented than customizable and provides rapid prototyping for non-professional researchers.  DL4J can be customized when scaled.  The library is available under the Apache 2.0 license, and all derived products from DL4J belong to their creators.  DL4J allows you to import neural network models from most of the core environments through Keras, including TensorFlow, Caffe, Torch and Theano, closing the gap between the Python ecosystem and the Java Virtual Machine (JVM) using a common set of tools designed for analysts, data engineers and developers. .  As the DL4J application programming interface in Python, Keras is used. <br><br>  Important features. <br><br><ul><li>  Beneficially uses the latest libraries for distributed computing. </li><li>  Open libraries served by the developer community and the Skymind team. </li><li>  Written in Java and compatible with any JVM language, such as Scala, Clojure and Kotlin. </li></ul><br><h3>  <font color="#0071c5">MXNet</font> </h3><br>  <a href="https://mxnet.incubator.apache.org/">MXNet</a> is a simple, versatile and ultra- <a href="https://mxnet.incubator.apache.org/">scalable</a> environment for deep learning.  The environment supports modern models of deep learning, including convolutional neural networks and LSTM.  The library originates in the scientific community and is the product of collaborative and individual work of researchers from several leading universities.  The library, actively supported by Amazon, was developed with a special focus on machine vision, processing and understanding of speech and language, generating models, convolutional and recurrent neural networks.  MXNet allows you to define, train and deploy networks in a wide variety of conditions: from powerful cloud infrastructures to mobile and connected devices.  The library provides a universal environment with support for many common languages, making it possible to use both imperative and symbolic software constructs.  The MXNet library also takes up little space.  Because of this, it can be scaled efficiently on multiple graphics processors and machines, which is well suited for learning on large data sets in a cloud environment. <br><br>  Important features. <br><br><ul><li>  Convenience programming: the ability to mix imperative and symbolic languages. </li><li>  Compatibility: supports a wide range of programming languages ‚Äã‚Äãin the interface part of the library, including C ++, JavaScript *, Python, r *, MATLAB *, Julia *, Scala and Go * </li><li>  Portability between platforms: the ability to deploy models in a variety of conditions, providing access for the widest range of users. </li><li>  Scalability: created on the basis of a scheduler with a dynamic dependency, which analyzes data dependencies in a sequential code and automatically immediately parallelizes both declarative and imperative operations. </li></ul><br><h3>  <font color="#0071c5">Wednesday neon</font> </h3><br>  With an open source Python-based language and a set of libraries for developing deep learning models, <a href="https://www.nervanasys.com/technology/neon/">neon</a> is a fast, powerful, and easy-to-use tool. <br><br>  Important features. <br><br><ul><li>  The desire to ensure the best quality of work on any device with assembly-level optimization, support for multiple GPUs, optimized data loading and using Winograd algorithm for convolutions of calculations. </li><li>  As with Python, syntax includes object-oriented implementations of all deep learning components, including layers, learning rules, activations, optimizers, initialization blocks, and cost functions. </li><li>  The Nviz utility creates bar charts and other visualization elements, helping you to track and better understand the progress of the deep learning process. </li><li>  Available for free download under the Apache 2.0 open source license. </li></ul><br><h3>  <font color="#0071c5">Tensorflow</font> </h3><br>  <a href="https://www.tensorflow.org/">TensorFlow</a> is an open source software library for numerical calculations using data flow graphs.  The nodes in the graph represent mathematical operations, and the branches of the graph represent multidimensional data arrays (tensors) that they exchange.  Thanks to the universal computing architecture, you can deploy on one or more CPUs or graphics processors on a desktop computer, server, or mobile device with a single API.  TensorFlow was originally developed by researchers and engineers who worked for the Google Brain team at Google‚Äôs Machine Intelligence unit for machine learning and neural networks, but because of its general nature, the system can also be used in other areas. <br><br><h3>  <font color="#0071c5">Theano</font> </h3><br>  <a href="http://deeplearning.net/software/theano/">Theano</a> is a Python library designed to define, optimize, and evaluate mathematical expressions, especially expressions with multidimensional arrays (numpy.ndarray).  Theano allows you to achieve speeds of working with large amounts of data that can compete only with specially made programs in the SI language.  Theano also surpasses the SI on the CPU many times due to the use of the latest versions of graphics processors.  Theano combines aspects of the computer algebra system (SKA) with aspects of an optimizing compiler.  With Theano, you can also create custom SI code for many mathematical operations.  This combination of SKA with optimizing compilation is especially well suited for problems in which complex mathematical expressions are evaluated many times, therefore the speed of evaluation is important for them.  In situations where many different expressions are evaluated only once, Theano helps reduce unproductive compilations and analyzes, while still providing symbolic functions, such as automatic differentiation. <br><br>  Important features. <br><br><ul><li>  Runtime optimization: using g ++ or nvcc to compile parts of an expression graph in a CPU instruction or GPU that runs much faster than instructions in pure Python </li><li>  Symbolic differentiation: automatic creation of symbolic graphs for calculating gradients </li><li>  Enhancing stability: recognizing [some] numerically unstable expressions and calculating them using more robust algorithms. </li></ul><br><h3>  <font color="#0071c5">Torch</font> </h3><br>  <a href="http://torch.ch/">Torch</a> is a scientific computing environment with broad support for machine learning algorithms, with an emphasis on graphics processors (GPUs).  It is notable for its ease of use and speed due to the simple and fast scripting language, LuaJIT and the basic C / CUDA program. <br><br>  Important features. <br><br><ul><li>  It is based on the LuaJIT language with a high degree of optimization and provides access to low-level resources, for example, to work with ordinary C pointers. </li><li>  It seeks to ensure maximum versatility and speed in creating scientific algorithms, while at the same time simplifying the process. </li><li>  It has a large ecosystem of packages, including in the field of machine learning, machine vision, signal processing, parallel processing, images, video, audio, and networks that are being developed by the community, as well as being developed on the basis of the Lua community. </li><li>  Easy-to-use libraries of popular neural networks and optimization tools, characterized by maximum versatility when implementing complex topologies of neural networks. </li><li>  The whole environment (including Lua) is autonomous and can be transferred to any platform without changes. </li></ul><br><h2>  <font color="#0071c5">Detailed analysis</font> </h2><br>  Most environments have common features: speed, portability, community and ecosystem, ease of development, compatibility, and scalability. <br><br>  The inputs for the search process in the environment for our project to create an automatic video editing application must meet the following requirements. <br><br><ul><li>  A good Python shell or library, because most data analysts, including those who work with these training materials, are familiar with Python. </li><li>  A version optimized by Intel for the high-concurrency Intel Xeon Phi product family. </li><li>  A wide range of deep learning algorithms that are well suited for quickly creating prototypes and, in particular, images (emotion recognition) and data sequences (audio and music). </li><li>  Pre-trained models that can be used to create high-quality models, even when a relatively small set of image data (for emotion recognition) and musical compositions (for making music) is available for teaching a model. </li><li>  The ability to withstand high loads in production conditions on large projects, although in our project large loads are not planned. </li></ul><br><h3>  <font color="#0071c5">Developer productivity: Language</font> </h3><br>  Developer productivity is of great importance, especially at the stage of prototyping, so you need to choose an environment that matches the skills and knowledge of your team members.  For this reason, we will exclude all environments based on alternative languages. <br><br><ul><li>  The best options are Caffe, (py) Torch, Theano, TensorFlow, MXNet, Microsoft Cognitive Toolkit, neon, and Keras. </li><li>  Valid: DL4J (great for Java / Scala; most of the big data libraries most commonly used in enterprises are written in Java / Scala, for example, Spark, Hadoop, and Kafka). </li></ul><br><h3>  <font color="#0071c5">New or existing deep learning algorithms and network architecture</font> </h3><br>  Most projects, including our training project, use only some existing neural network algorithm, such as AlexNet or LSTM.  In our case, any deep learning environment should be suitable.  However, if you are working on a research project (for example, developing a new algorithm, testing a new hypothesis or optimizing a library), high-level systems, such as Keras, will not work for you.  Low-level environments are likely to require you to write a new algorithm in C ++. <br><br>  Our list of (deep learning environments) remains the same. <br><br><ul><li>  Optimal options: Caffe, (py) Torch, Theano, TensorFlow, MXNet, Microsoft Cognitive Toolkit, neon, Keras </li><li>  Valid: Not defined. </li></ul><br><h3>  <font color="#0071c5">Supported Neural Network Architectures</font> </h3><br>  Our training project involves the solution of two traditional problems of deep learning: <br><br><ul><li>  image classification (usually performed using convolutional neural networks, such as AlexNet, VGG or Resnet); </li><li>  creating musical accompaniment (a typical sequence modeling task that recurrent neural networks do well, such as LSTM); </li></ul><br>  All environments support convolutional neural networks (used mainly for image processing) and recurrent neural networks (used for sequence modeling). <br><br>  Our list remains the same: <br><br><ul><li>  Optimal options: Caffe, (py) Torch, Theano, TensorFlow, MXNet, Microsoft Cognitive Toolkit, neon, Keras </li><li>  Valid: Not defined. </li></ul><br><h3>  <font color="#0071c5">Availability of pre-trained models</font> </h3><br>  Since we do not have a large data set (for example, 6000 annotated images) to train the model of our project, we must use previously trained models. <br><br>  All selected environments support model parks.  In addition, there are converters that allow the use of models that have been trained using another library.  The Caffe library was the first to enter the model park and has the widest selection of models.  There are tools for converting Caffe park models to virtually any other model: <br><br><ul><li>  <a href="https://github.com/dmlc/mxnet/tree/master/tools/caffe_converter">MXNet</a> </li><li>  <a href="https://github.com/szagoruyko/loadcaffe">Torch</a> </li><li>  <a href="https://github.com/ethereon/caffe-tensorflow">Tensorflow</a> </li><li>  <a href="https://github.com/NervanaSystems/caffe2neon">neon</a> </li><li>  Microsoft Cognitive Toolkit (thanks to the efforts of Microsoft, you can convert almost any model into a CNTK fleet model) </li><li>  Theano (there is no actively supported tool, but Keras supports separate image processing models) </li></ul><br>  All of these environments also have their own model parks. <br><br>  Our list remains the same: <br><br><ul><li>  Optimal options: Caffe, (py) Torch, Theano, TensorFlow, MXNet, Microsoft Cognitive Toolkit, neon, Keras </li><li>  Valid: Not defined. </li></ul><br><h3>  <font color="#0071c5">Developer productivity: Easy model definition</font> </h3><br>  The model can be defined in two ways: using the configuration file (for example, using Caffe) or using scripts (in other environments).  Configuration files are convenient from the point of view of model portability, but they are difficult to use when creating a complex neural network architecture (for example, try manually copying layers in ResNet-101).  On the other hand, using scripts you can create complex neural networks with minimal code repetition, but the possibility of transferring such code to another environment will be questionable.  Usually it is preferable to use scripts, because transitions from one environment to another within one project rarely happen. <br><br>  Now our list will change as follows: <br><br><ul><li>  Optimal options: (py) Torch, Theano, TensorFlow, MXNet, Microsoft Cognitive Network, neon, Keras </li><li>  Allowed: Caffe </li></ul><br><h3>  <font color="#0071c5">Support for optimized CPUs and multiple CPUs for learning deep learning models</font> </h3><br>  The Intel Math Kernel Library (Intel MKL) for vector and matrix multiplication has been refined for deep learning and now includes the integrated multi-core architecture of Intel Many Integrated Core Architecture.  This is a processor architecture with extensive parallelization, which significantly speeds up the process of deep learning on the CPU.  All current competing environments have already integrated Intel MKL and offer versions optimized by Intel. <br><br>  It is also important to know whether distributed learning is supported by multiple CPUs.  Based on these criteria, our modified list will be as follows: <br><br><ul><li>  Optimal options: <ul><li>  <a href="https://www.tensorflow.org/deploy/distributed">Tensorflow</a> </li><li>  <a href="https://mxnet.incubator.apache.org/how_to/multi_devices.html">MXNet</a> </li><li>  <a href="https://docs.microsoft.com/en-us/cognitive-toolkit/Multiple-GPUs-and-machines">Microsoft Cognitive Toolkit</a> (in our opinion, MPI is a bit more complicated than other libraries) </li></ul></li><li>  Permissible: <ul><li>  (py) Torch (in the next major version, you will be able to work with several CPUs, if you focus on the answer of the company's representative at the <a href="https://discuss.pytorch.org/t/does-pytorch-support-parallelism-across-multiple-cpus/1631">official forum</a> . </li><li>  <a href="http://deeplearning.net/software/theano/tutorial/multi_cores.html">Theano</a> (multicore parallelization on one machine via OpenMP) </li><li>  neon (not yet available) </li></ul></li></ul><br><h3>  <font color="#0071c5">Developer Performance: Deploying the Model</font> </h3><br>  TensorFlow supports a special tool called TensorFlow Serving.  It takes a trained TensorFlow model as input and converts it into a web service that allows it to evaluate incoming requests.  If you are going to use a trained model on a mobile device, TensorFlow Mobile provides immediate compression of the model. <br><br>  <a href="https://tensorflow.github.io/serving/">Read more about TensorFlow Serving</a> <br>  <a href="https://www.tensorflow.org/mobile/">TensorFlow Mobile</a> <br><br>  MXNet provides a merge deployment, in which the model, along with all the necessary bindings, is placed in a standalone file.  Such a file can then be transferred to another machine, and accessed through other programming languages.  For example, it can be used on a mobile device.  <a href="https://mxnet.incubator.apache.org/how_to/smart_device.html">More details</a> . <br><br>  The Microsoft Cognitive Toolkit (formerly CNTK) provides model deployment through the Azure * machine learning cloud environment.  Mobile devices are not supported yet.  Their support is expected in the next version.  <a href="https://docs.microsoft.com/en-us/cognitive-toolkit/Evaluate-a-model-in-an-Azure-WebApi">More details</a> . <br><br>  Although we are not going to deploy an out-of-the-box application on a mobile device, in some situations this possibility can be very useful.  For example, imagine a video editing application that can be used to create videos from just taken snapshots (this feature is already available in Google Photos). <br><br>  Now we have two competitors left: TensorFlow and MXNet.  In the end, the team working on this project decided to use the TensorFlow library in conjunction with Keras, because it has a more active community, the team members have experience working with these tools, and also because TensorFlow has more successful projects.  See the <a href="https://www.tensorflow.org/">list of users TensorFlow</a> . <br><br><h2>  <font color="#0071c5">Conclusion</font> </h2><br>  In this article, we presented several popular environments for deep learning and compared them according to several criteria.  The ease of prototyping, deployment, and debugging of the model, along with community size and scalability across multiple machines, are among the most important criteria that should be guided in choosing a deep learning environment.  All modern environments now support convolutional and recurrent neural networks, have parks of pre-trained models and offer versions optimized for modern Intel Xeon Phi processors.  As our analysis showed, for the purposes of our project, Keras based on the TensorFlow version optimized by Intel would be an excellent choice.  Another successful option would be the Intel optimized MXNet library. <br><br>  Although according to the results of this comparative analysis, the TensorFlow library won, we did not take into account comparison standards, which are of key importance.  We plan to write a separate article in which we compare the output and training time of the TensorFlow and MXNet libraries for a wide range of deep learning models in order to determine the final winner. </div><p>Source: <a href="https://habr.com/ru/post/359184/">https://habr.com/ru/post/359184/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../359174/index.html">How to copy data sources in IDE on IntelliJ platform</a></li>
<li><a href="../359176/index.html">Why it is impossible so easy to take and implement "green" technology in the data center</a></li>
<li><a href="../359178/index.html">Manager's Guide: 10 Simple Ways to Overwhelm a Project</a></li>
<li><a href="../359180/index.html">Hysteria around GDPR, part 2. Useful tips</a></li>
<li><a href="../359182/index.html">The book "Programming for children. Learning to create games on Scratch ¬ª</a></li>
<li><a href="../359186/index.html">MTS will spend on the implementation of the law of Spring 60 billion rubles</a></li>
<li><a href="../359188/index.html">Intelligent Decision Support Systems - Brief Overview</a></li>
<li><a href="../359190/index.html">As our customer did not want to let go of the provider</a></li>
<li><a href="../359192/index.html">Classic JavaScript algorithms and data structures</a></li>
<li><a href="../359194/index.html">Java and Project Reactor. Episode 2</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>