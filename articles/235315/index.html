<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Testing flash storage. File System Impact</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="During testing the performance of leading flash systems, we, at some point, asked the following questions: What is the effect of the file system on th...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Testing flash storage. File System Impact</h1><div class="post__text post__text-html js-mediator-article">  During testing the performance of leading flash systems, we, at some point, asked the following questions: What is the effect of the file system on the performance of a real storage system?  How important is it and what does it depend on? <br><br>  It is known that the <u>file system</u> is an infrastructure software layer that is implemented at the kernel kernel level (kernel space) or, more rarely, at the user level (user space).  Being an intermediate layer between the application / system software and disk space, the file system must introduce its parasitic load, affecting the performance of the system.  Therefore, when calculating the actual storage performance, one should take into account the dependence of fixed parameters on the implementation of the file system and software using this file system. <br><a name="habracut"></a><br><br><h3>  <b>Testing program.</b> </h3><br>  In order to study the overheads created by different file systems (EXT4, VXFS, CFS) on storage performance, a stand was created, described in detail in the article <a href="http://habrahabr.ru/company/inline_tech/blog/227887/">Testing flash storage.</a>  <a href="http://habrahabr.ru/company/inline_tech/blog/227887/">IBM RamSan FlashSystem 820.</a> <br>  The tests were performed by creating a synthetic load on the block device (fio), which is a <code>stripe, 8 column, stripe unit size=1MiB</code> logical volume <code>stripe, 8 column, stripe unit size=1MiB</code> , created using Veritas Volume Manager from 8 LUNs presented from the system under test.  In relation to the file system, tests equivalent to those described in the article Testing flash storage were performed.  IBM RamSan FlashSystem 820. <br>  Then, graphs were constructed showing the effect of the file system on the performance of the storage system (performance difference in% of the block device obtained during testing) and conclusions were drawn about the extent of the influence of the file system on the performance of the storage system. <br><table><tbody><tr><td><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/9d6/fad/b99/9d6fadb99bea3b965d671be75ea0fb18.jpg"></div></td></tr><tr><td>  Figure 1. Block diagram of test stand ‚Ññ1.  (clickable) <br></td></tr></tbody></table><br><h5>  <b>Performance tests of a disk array for different types of load, executed at the ext4 file system level.</b> </h5><br>  Type of ext4 file system. <br>  4K file system block. <br>  The file system is mounted with noatime, nobarrier mount options. <br>  On the created file system, 16 files of the same size are formed for the entire volume of the file system.  The names of all generated files are given as the value of the filename parameter of the fio program (when running the tests, the generated load will be evenly distributed among all the created files). 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h5>  <b>Performance tests of a disk array with different types of load, executed at the vxfs file system level.</b> </h5><br>  The type of vxfs file system. <br>  8k file system block. <br>  The file system is mounted with mount options <code>cio,nodatainlog,noatime,convosync=unbuffered</code> <br>  Additional file system settings implemented through the vxtunefs command are as follows: <br><ul><li>  initial_extent_size = 2048; </li><li>  read_ahead = 0. </li></ul><br>  The resulting graphs are superimposed on the results of previous tests and it is concluded that the extent of the influence of the file system on storage performance. <br><br><h5>  <b>Performance tests of a disk array with different types of load generated by two servers on the Symantec CFS cluster file system.</b> </h5><br>  At this stage, another test server is added to the stand. <br><table><tbody><tr><td><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/7aa/afe/c08/7aaafec087d98eee999cd2a75a121a5f.jpg" height="251" width="640"></div></td></tr><tr><td>  Figure 2. Block diagram of test stand ‚Ññ2 </td></tr></tbody></table>  The software installed on the added server is equivalent to that installed on the first server, the same optimization settings are made.  All 8 LUNs with storage systems are presented to both servers.  On them, Symantec Volume Manager creates a cluster volume of <code>striped, 8 columns, unit size=1024KB</code> .  This volume creates a CFS file system, which is mounted with the options <code>cio,nodatainlog,noatime,nomtime,convosync=unbuffered</code> to both servers.  On the file system, 16 files are created, to which both servers have access.  On the servers, tests similar to the previous ones are simultaneously launched.  At first, on all set from the created 16 files.  Then, from each server to its own, not intersecting with another, a subset of 8 files.  Based on the results, graphs of the difference of the obtained indicators are constructed and conclusions are drawn about the degree of influence of the Symantec CFS cluster file system on performance. <br><br><h3>  <b>Test results</b> </h3><br><div class="spoiler">  <b class="spoiler_title">Performance graphs when testing ext4 and vxfs file systems in relation to a block device.</b> <div class="spoiler_text">  (All pictures are clickable) <br><table border="1" cellpadding="2" cellspacing="2"><tbody><tr><td></td><td>  Synchronous way in / in </td><td>  Asynchronous way in / in with a queue depth of 32 </td><td>  Asynchronous way in / in with a queue depth of 64 </td></tr><tr><td>  Random reading </td><td> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/bd1/7b4/9e4/bd17b49e401a229ec32232a5e87bd1c4.jpg" height="320" width="225"></a> <br></td><td> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/44a/116/b4a/44a116b4a02d5967a3c42d3b25dda7f6.jpg" height="320" width="225"></a> <br></td><td> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/d11/a87/f76/d11a87f76331379715637fba54eaa956.jpg" height="320" width="225"></a> <br></td></tr><tr><td>  When recording </td><td> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/2e3/cc3/4fd/2e3cc34fd27cdaeef4131acdd377c0c8.jpg" height="320" width="225"></a> <br></td><td> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/d49/af5/aa4/d49af5aa49a59b03515e50541b358347.jpg" height="320" width="225"></a> <br></td><td> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/442/4f9/cf9/4424f9cf9a5b47dff0f43570e770ceba.jpg" height="320" width="225"></a> <br></td></tr><tr><td>  With mixed load (70% read, 30% write) </td><td> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/add/0ef/89d/add0ef89dd96e69793dc6efb81324d2d.jpg" height="320" width="225"></a> <br></td><td> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/aa4/e63/95a/aa4e6395ac1e97c9e4f1714c7cd30c5e.jpg" height="320" width="225"></a> <br></td><td> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/2ac/9d3/785/2ac9d3785c43c0900d5bae498839e3a5.jpg" height="320" width="225"></a> <br></td></tr></tbody></table><br></div></div><br><h3>  Conclusions comparison of EXT4 and VXFS </h3><br><ol><li>  The file system has a significant impact on storage performance, right down to its 50% drop. </li><li>  As the load on the storage system increases, the performance of the file system on performance decreases in most cases (the disk array becomes saturated and the overhead of file systems becomes not noticeable against the background of a significant increase in latency at the level of the disk array). </li><li>  The vxfs file system demonstrates performance gains on asynchronous write operations and reading under low load on the disk array.  Probably due to the use of the <code>convosync=unbuffered</code> mount option, which implies direct data transfer between the buffer in the user address space and the disk (without copying the data to the kernel buffer of the operating system).  The indicated effect is not observed on the ext4 file system.  The performance of the ext4 file system is worse compared to a block device in all measurements. </li><li>  When the storage system is in saturation mode, the vxfs file system shows comparable performance with the ext4 file system.  As a rule, the storage configuration is chosen in such a way that it is not in saturation mode in normal operation mode, so the resulting lower performance of vxfs compared to ext4 is not a significant indicator of the quality of the file system. </li><li>  Significant fluctuations in the relative performance of file systems during synchronous I / O are probably due to the lack of optimization of file system drivers for low-latency SSD drives and the presence of additional I / O operations to change file system metadata.  It is possible that additional file system settings will reduce these fluctuations. </li></ol><br><h5>  <b>Performance tests of a disk array with different types of load generated by two servers on the Symantec CFS cluster file system.</b> </h5><br><div class="spoiler">  <b class="spoiler_title">Graphs of relative performance obtained with various tests</b> <div class="spoiler_text">  (All pictures are clickable) <br><table border="1" cellpadding="2" cellspacing="2"><tbody><tr><td><br></td><td>  Record </td><td>  Reading </td><td>  Mixed in / in </td></tr><tr><td>  Performance (iops) obtained when testing a cluster file system by loading from two servers onto one set of files with respect to performance when loading on a different set of files.  For 0 adopted proizv.  with a load on a different set of files. </td><td> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/286/2b9/f21/2862b9f217c47e918d38ed53d7592e8c.jpg" height="320" width="226"></a> </td><td> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/95d/372/6e6/95d3726e6b3be4db223badc4b445ae20.jpg" height="320" width="226"></a> <br></td><td> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/f69/f6d/8db/f69f6d8db1c96fba0442eb851ad19a60.jpg" height="320" width="226"></a> <br><br></td></tr><tr><td>  Performance (iops) obtained when testing a cluster file system by loading from two servers onto one set of files with respect to the performance obtained for vxfs with one server.  For 0 adopted proiv.  vxfs. </td><td> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/32c/7fc/053/32c7fc053a3f7c6d38590911e842fa88.jpg" height="320" width="226"></a> <br><br></td><td> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/c53/a38/9ea/c53a389eaa1943be5602add054d30d70.jpg" height="320" width="226"></a> <br><br></td><td> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/d50/b92/fc6/d50b92fc6459e5d5c94d88f2b0cba606.jpg" height="320" width="226"></a> <br><br></td></tr></tbody></table><br></div></div><br><h3>  Conclusions comparison CFS and VXFS </h3><br><ol><li>  Performance with the load from both servers on the same 16 files at the same time does not differ from the performance obtained when each server loads on its 8 files.  (small jumps (increase in performance by 20% when reading in 4-8K blocks with a load on one set of files, most likely, is due to background processes on the storage itself, as tests were performed in a row.) Monitoring the loading of Ethernet connections between servers used for interconnect, showed the absence of significant load, which is the advantage of CFS when running multiple servers with one set of files </li><li>  Approximately the same write performance, in both cases.  With the exception of small blocks (4-8K) where the results of CFS are 2-3 times higher than those of VXFS.  On mixed w / v CFS is 10-20% better than VXFS. </li><li>  The cluster file system CFS does not adversely affect performance.  In some cases, even greater performance is obtained.  This may be due to better parallelization of the load from two servers than from one. </li></ol></div><p>Source: <a href="https://habr.com/ru/post/235315/">https://habr.com/ru/post/235315/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../235305/index.html">Radio-controlled paper airplane PowerUP 3.0: reviews of the first pilots</a></li>
<li><a href="../235307/index.html">Selection of UX reports at 404fest</a></li>
<li><a href="../235309/index.html">How to launch Landing Page in 4 minutes?</a></li>
<li><a href="../235311/index.html">0day vulnerability in iOS apps: Gmail, Google+ and FB Messenger</a></li>
<li><a href="../235313/index.html">Older browsers - old version of google</a></li>
<li><a href="../235319/index.html">Sale of electronic books for 99 rubles</a></li>
<li><a href="../235323/index.html">How to make a dance platform for the Dance Dance Revolution</a></li>
<li><a href="../235325/index.html">Leap Motion released gesture recognition system for Oculus Rift</a></li>
<li><a href="../235329/index.html">Project 1C-Tools, Automate the routine on your favorite platform</a></li>
<li><a href="../235331/index.html">Why does Skype make us all update software?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>