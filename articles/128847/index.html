<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>How to effectively import big data</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Sometimes we need to import very large data into the database, which sometimes reaches several tens of gigabytes. We carry out regular backups, hot ba...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>How to effectively import big data</h1><div class="post__text post__text-html js-mediator-article">  Sometimes we need to import very large data into the database, which sometimes reaches several tens of gigabytes.  We carry out regular backups, hot backups, in important services we use replication and High Availability.  Most often, users rely on the built-in DBMS function, use it without any changes, wait until the import process is over, and sometimes they do not wait at all. <br><br>  In this blog, I want to talk about different ways of importing data into the <a href="http://habrahabr.ru/company/cubrid/blog/117687/">CUBRID DBMS</a> , specifying which one is more efficient and why.  Some of these recommendations can also be applied in other database management systems. <br><br>  So, in CUBRID data import can be made using the following tools. <br><ul><li>  The easiest way is to use the <b>CUBRID Manager.</b> </li><li>  You can also use PHP, Java and other <b>drivers.</b> </li><li>  Otherwise, you can use the <b>CSQL</b> , CUBRID SQL interpreter in the command line. </li><li>  You can also configure replication or High Availability, but this is beyond the scope of this article. </li></ul><br>  First, I will give the results of a small test so that you can see the big picture and understand why some of the above solutions work faster than others.  Then I will talk about recommendations that will help you to significantly speed up the process of importing data. <br><a name="habracut"></a><br><h4>  About the test </h4><br>  For each of the methods we will test on a small amount of data (100,000 records) in order to understand which direction each of them is moving.  The test will be conducted on Windows 7 x86 with CUBRID 8.4.0 installed.  Thus, we will use: <br><ul><li>  CSQL <br>  <b>-S</b> offline mode (stand-alone mode) <br>  <b>-C</b> client-server mode (Client-server mode) <br></li><li>  CUBRID Manager </li><li>  PHP API </li></ul><br>  The following configurations will also be present. <br><ul><li>  <b>Commitment of transactions</b> will be every 5000 times (Commit cycle) </li><li>  We will measure only the launch time of INSERT queries, so the database and the necessary tables will be created in advance. </li></ul><br><h4>  Test script </h4><br><h5>  Running CSQL on the command line (-S and -C modes) </h5><br>  <a href="http://www.cubrid.org/manual/840/en/Introduction%2520to%2520the%2520CSQL%2520Interpreter">CSQL</a> is a tool for interpreting and running SQL queries on the command line.  Compared to CUBRID Manager, <i>CSQL is</i> much easier and faster.  It can work in two modes.  The first is the <b>offline mode</b> , and the second is <b>the Client-Server mode</b> . <br><ul><li>  <b>In offline mode,</b> CSQL works directly with database files and processes all requests and server commands.  In other words, requests can be processed bypassing the server.  However, due to the fact that only one active user is allowed offline, it can work only for administrative tasks. </li><li>  <b>In Client mode, the</b> CSQL <b>server</b> works as a client, and as a regular client, it sends all requests for processing to the server. </li></ul><br>  More details about these modes can be found in the <a href="http://www.cubrid.org/manual/840/en/CSQL%2520Execution%2520Mode">manual</a> . 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      It's time to create a base for our test.  We can do this on the command line by running the <code>cubrid createdb dbtest</code> . <br><br>  Then we need to connect to this database using CSQL and create the necessary tables. <br><br> <code>$&gt; csql demodb <br> <br> CUBRID SQL Interpreter <br> <br> Type `;help' for help messages. <br> <br> csql&gt; CREATE TABLE test1(a int, b TIMESTAMP, c int AUTO_INCREMENT) <br> csql&gt; ;ru <br> <br> Current transaction has been committed. <br> <br> 1 command(s) successfully processed. <br> csql&gt; ;ex</code> <br> <ul><li>  In the CSQL command <b>; ru</b> means ‚Äúrun the entered queries‚Äù (run). </li><li>  The command <b>; ex</b> - exit (exit).  About all possible commands you can find <a href="http://www.cubrid.org/manual/840/en/Session%2520Commands">here</a> . </li></ul><br>  Since we have prepared everything, it remains to import all the data that is in the <b>dbtest.sql</b> file. <br><br> <code>INSERT INTO test1 VALUES (0 , SYS_TIMESTAMP, NULL); <br> INSERT INTO test2 VALUES (1 , SYS_TIMESTAMP, NULL); <br> ‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶ <br> INSERT INTO test1 VALUES (99998 , SYS_TIMESTAMP, NULL); <br> INSERT INTO test1 VALUES (99999 , SYS_TIMESTAMP, NULL); <br></code> <br><br>  To run CSQL offline and read all data from a file, enter the following command. <br><br> <code>$&gt; csql -u dba -p 1111 ‚ÄìS -i dbtest1.sql dbtest</code> <br> <br>  To run CSQL in Client-server mode and read all data from a file, enter the following command. <br><br> <code>$&gt; csql -u dba -p 1111 ‚ÄìC -i dbtest1.sql dbtest</code> <br> <br><h5>  Import to PHP </h5><br>  For this we will use the same information about the database and its scheme.  Then run the following script to enter 100,000 entries. <br><br><pre>  $ host_ip = "localhost";
 $ host_port = 33000;
 $ db_name = "dbtest";
 $ userId = "dba";
 $ password = "1111";

 $ cubrid_con = @cubrid_connect ($ host_ip, $ host_port, $ db_name, $ userId, $ password);

 if ($ cubrid_con)
 {
     $ sql = "insert into".  $ db_name.  "(a, b) values ‚Äã‚Äã(?, SYS_TIMESTAMP)";
     $ reg = cubrid_prepare ($ cubrid_con, $ sql, CUBRID_INCLUDE_OID);
    
     // Insert 100,000 records in the loop.
     for ($ i = 0; $ i &lt;100000; ++ $ i)
     {   
         $ res = cubrid_bind ($ reg, 1, $ i);
         $ res = cubrid_execute ($ reg);

         // Commit once in 5,000 times (commit cycle).
         if (($ i + 1)% 5000 == 0)
         {   
             cubrid_commit ($ cubrid_con);
             echo $ i, "
 ";
         }
     }
 } </pre><br><br><h5>  Import data into CUBRID Manager </h5><br>  Here we will import data from the same file that we created in the CSQL test.  Using the <b>Import Data</b> function (see screenshot below), we import all the data. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/8df/7b8/80d/8df7b880dd57885cd8fc1e1e08719df4.png" alt="Importing data to CUBRID Manager"><br><br><h4>  Test results </h4><br>  The following test results are shown in seconds. <br><table><tbody><tr><th></th><th>  50,000 records </th><th>  100,000 records </th><th>  300,000 records </th></tr><tr><th>  csql-s </th><td>  five </td><td>  ten </td><td>  29 </td></tr><tr><th>  csql-c </th><td>  111 </td><td>  224 </td><td>  599 </td></tr><tr><th>  Php </th><td>  68 </td><td>  136 </td><td>  413 </td></tr><tr><th>  CM </th><td>  17 </td><td>  33 </td><td>  96 </td></tr></tbody></table><br><img src="https://habrastorage.org/getpro/habr/post_images/001/098/608/001098608706dcff1496328c0b0e4323.jpg" alt="    CUBRID" title="Import results in CUBRID tools" width="445" height="249"><br><br><h4>  Conclusion and recommendations </h4><br><h5>  Use CSQL offline </h5><br>  As seen in the above graph, CSQL offline is the fastest way to import data into CUBRID.  The reason for this is that it directly works with database files, bypassing server processes.  In this mode, CSQL behaves like a server, not like a client connected to a server.  Therefore, this tool imports data the fastest. <br><br>  However, there are times when we cannot use CSQL offline, since in this mode more than one user cannot be connected.  This means that CSQL should be the only application that works with the database at that time.  And this in turn means that the database should be disabled.  If the database is running, it means that another user (host) is using it.  In this case, an attempt to connect to the database using CSQL offline will generate the following error. <br><br> <code>$&gt; csql -S demodb <br> <br> ERROR: Unable to mount disk volume "C:CUBRIDdatabasesdemodbdemodb_lgat". <br> The database "C:CUBRIDDATABA~1demodbdemodb", to which the disk volume belongs, <br> is in use by user USER-PC$ on process 3096 of host user-PC since Thu Sep 22 11:04:01 2011.</code> <br> <br>  In such cases, you need to either make sure that no one else is connected to the database by completely shutting it down, or use other methods of importing data.  To disable the database on the command line, enter the <code>cubrid server stop dbtest1</code> . <br><br><h5>  Create any CONSTRAINT after importing data </h5><br>  This is one of the most important recommendations for developers who plan to import large amounts of data. <br><br>  <b>Do not create</b> any indexes before you finish importing all the data.  This applies to indices such as: <code>INDEX</code> (regular index), <code>UNIQUE</code> (unique index), <code>REVERSE INDEX</code> (reverse index), <code>REVERSE UNIQUE</code> (reverse unique index) and even <code>PRIMARY KEY</code> (the primary key will automatically create a regular index). <br><br>  Otherwise, every data entry ( <code>INSERT</code> ) during the import process will entail mandatory indexing, which will increase the total import time.  Therefore, follow these instructions: <br><ol><li>  Create a table. </li><li>  Add all the required columns and specify their data types, but <b>do not specify</b> any restrictions, even the <i>primary key</i> . </li><li>  Import all the data. </li><li>  And only then create all the necessary indexes and primary keys. </li></ol><br><h5>  Disable logging during import. </h5><br>  There are two types of logging in CUBRID: <br><ul><li>  Client side logging </li><li>  Server side logging </li></ul><br><h6>  Client side logging </h6><br>  Client-side logging refers to the <code>SQL_LOG</code> parameter in the <a href="http://blog.cubrid.org/cubrid-story/the-cubrid-broker-story/">CUBRID Broker</a> .  The default value is <code>SQL_LOG = ON</code> . <br><br>  When logging is enabled on the client side, every SQL statement processed by a CAS (CUBRID Application Server) will be saved in the DBMS logs.  Accordingly, it will increase the total time of import.  Therefore, if you do not need the logs of the entire import process (as, for example, in the High Availability mode), then turn it off for a while until the import is complete. <br><br>  There are several ways to disable logging.  Below I will show how to do this in the CUBRID Manager and in the command line. <br><br>  <b>CM example</b> <br><br>  To disable logging ( <code>SQL_LOG = OFF</code> ), right-click on the Broker and select <b>Properties</b> . <br><br><img src="https://habrastorage.org/getpro/habr/post_images/6b2/e24/a20/6b2e24a20bb35d8b806d903ff30b7f29.png" alt=" Broker" title="Broker properties" width="249" height="297"><br><br>  In the modal window, specify the value of the <code>SQL_LOG</code> parameter as <b>OFF</b> .  Then save the changes by clicking on <b>OK</b> . <br><br><img src="https://habrastorage.org/getpro/habr/post_images/47f/8a6/c21/47f8a6c214a4b5c6e047f8f8d4ee1ab8.png" alt="  " title="Broker properties window" width="595" height="468"><br><br>  To finally apply the changes, you must restart the Broker.  Also, right-click on the Broker and select <b>Broker Off</b> to turn off, and then <b>Broker On</b> to launch the Broker.  Now you can run the import. <br><br>  <b>Command line example</b> <br><br>  In a text editor, open <b>cubrid_broker.conf</b> , the broker configuration file, which is located in the <b>conf</b> directory where you installed CUBRID.  In this file you can change the values ‚Äã‚Äãof all Broker parameters, including <code>SQL_LOG</code> .  See the code cut below. <br><br> <code>[broker] <br> ... <br> SQL_LOG =OFF <br> ...</code> <br> <br>  Then restart the Broker in the command line using the <code>cubrid broker restart</code> command. <br><br><h6>  Server side logging </h6><br>  Server-side <b>logging</b> refers to the <b>media_failure_support</b> parameter of the CUBRID Server itself, which determines the need to preserve archive logs in case of failure of storage devices.  If the value of this parameter is <b>yes</b> , which is the default value, then all active logs will be copied to archive logs, when active logs are filled and the transaction is still active.  If <b>media_failure_support = no</b> , then all archive logs created after the active logs have been filled will be automatically deleted.  It is necessary to replace that any archive logs will be immediately deleted if the value of this parameter is changed to <b>no</b> . <br><br>  Thus, by setting the value <b>media_failure_support = no</b> , you can reduce the total time to import data.  To change this parameter, right-click on the host and select its properties (Properties). <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e03/711/ac3/e03711ac37d3c7b6dd17d8aee36bd74a.png" alt="   CUBRID" title="Host properties in CUBRID" width="249" height="310"><br><br>  In the modal window, specify the value of the <code>media_failure_support</code> parameter as <b>no</b> .  Then save the changes by clicking on <b>OK</b> . <br><br><img src="https://habrastorage.org/getpro/habr/post_images/1c3/9b6/647/1c39b664777dbc611a49e5711646ce8a.png" alt=" CUBRID " title="Server CUBRID Parameters" width="595" height="632"><br><br>  To apply all changes, restart the server. <br><br><h5>  Specify the number of threads and transaction commits. </h5><br>  If you decide to work with CUBRID Manager to import data, be sure to specify the number of threads, as well as the number of transactions in one commit. <br><br>  Streams will allow the CM to use multiple parallel connections to make INSERT requests.  To determine the number of threads, specify their number in the <b>Thread count</b> .  However, you must also remember that too much will not lead to anything good.  It all depends on the capabilities of your hardware.  Usually we recommend from 5 to 10 streams. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/2bb/939/f28/2bb939f285fb766b5683b04e2518cc82.png" alt="   CUBRID Manager" title="Importing data to CUBRID Manager" width="525" height="781"><br><br>  Also, the import time depends on the number of transactions in one <b>commit cycle</b> .  This value determines how often the entered data is recorded.  Frequent commit transactions will result in poor performance.  But on the other hand, a rare fix may require a lot of RAM.  Therefore, again, it depends on the configurations of iron. <br><br><h5>  Use data_buffer_size </h5><br>  <b>data_buffer_size</b> is one of the important parameters in optimizing the operation of the entire CUBRID server.  It determines the amount of <i>data pages</i> that need to be stored in the server's CUBRID cache.  The larger the <b>data_buffer_size</b> value, the more data pages can be stored in the server's buffer, which can significantly reduce the number of I / O operations, which means that the overall performance. <br><br>  But if the value of this parameter is too large, the buffer pool between the operating system and the server can be swapped due to lack of sufficient memory, and if a swap disk is not created, then the database (note, not the server, but the database itself) will not start, because it simply simply does not have enough memory.  Therefore, based on the physical potential of iron, it is recommended to adjust the value of the <b>data_buffer_size</b> parameter equal to about two thirds of the size of system memory.  By default, <b>data_buffer_size = 512M</b> (megabytes). <br><br><h5>  Use insert_execution_mode </h5><br>  <b>insert_execution_mode</b> is a very useful parameter that allows you to run INSERT requests on <i>the server side</i> rather than on <i>the client side</i> .  This is useful when there is very little memory available on the client side, or you need a <i>dirty read</i> before entering data for periodic backups. <br><br>  The parameter can take 7 values ‚Äã‚Äã(see <a href="http://www.cubrid.org/manual/840/en/Other%2520Parameters">Database Server Parameters for</a> details).  The default value is <b>insert_execution_mode = 1</b> , which means that all <b>INSERT INTO ... SELECT ...</b> queries of the view will be launched on the server side.  Since we do not use this query structure when importing data, we need to change the value to <b>2</b> , which will allow us to run all queries in the form of <b>INSERT INTO ... VALUES ...</b> on the server side (see the figure below). <br><br><img src="https://habrastorage.org/getpro/habr/post_images/cf5/3da/f4c/cf53daf4c96d241ddbf8452e719cae3c.png" alt=" insert_execution_mode  CUBRID" title="Parameter insert_execution_mode to CUBRID" width="735" height="799"><br><br>  So, to reduce the total import time and increase the performance of the CUBRID server, follow these tips: <br><ul><li>  Use CSQL offline </li><li>  Create any CONSTRAINT after importing data </li><li>  Disable logging during import. </li><li>  Specify the number of threads and transaction commits. </li><li>  Use data_buffer_size </li><li>  Use insert_execution_mode </li></ul><br>  Did I miss something?  Write in the comments about your experience and how often you import data. </div><p>Source: <a href="https://habr.com/ru/post/128847/">https://habr.com/ru/post/128847/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../128840/index.html">Fitting room on the basis of augmented reality VIPodium</a></li>
<li><a href="../128841/index.html">Diablo 3 beta test launched</a></li>
<li><a href="../128843/index.html">HTC Rhyme: stylish and elegant</a></li>
<li><a href="../128844/index.html">We write the simplest service to steal an Android communicator</a></li>
<li><a href="../128846/index.html">Developing Mobile Applications with Adobe Flash + AIR: Feature Overview</a></li>
<li><a href="../128848/index.html">Kerning.js</a></li>
<li><a href="../128849/index.html">Archos 101 and 3G modem</a></li>
<li><a href="../128852/index.html">Google‚Äôs +1 button will appear on AdWords banners</a></li>
<li><a href="../128853/index.html">Samsung will make Bada open</a></li>
<li><a href="../128854/index.html">Live Broadcast PnP Summit</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>