<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Why does percentile calculation not work as expected?</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Often clients ask us about the p99-metric (99th percentile). 

 This is definitely a reasonable request and we plan to add similar functionality to Vi...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Why does percentile calculation not work as expected?</h1><div class="post__text post__text-html js-mediator-article">  Often clients ask us about the p99-metric (99th percentile). <br><br>  This is definitely a reasonable request and we plan to add similar functionality to VividCortex (I‚Äôll talk about this later).  But at the same time, when customers ask about it, they imply something completely definite - something that can be a problem.  They ask not the 99th percentile for some metric, they ask for the <em>metric for the 99th percentile</em> .  This is common for systems such as <a href="https://www.vividcortex.com/blog/2015/11/05/nobody-loves-graphite-anymore/">Graphite</a> , but this does not give the result that is expected from such systems.  This post will tell you that you may have misconceptions about percentiles, the exact extent of your misconceptions, and what you can do right in this case. <br><br>  (This is a translation of the <a href="https://www.vividcortex.com/blog/why-percentiles-dont-work-the-way-you-think">article</a> <a href="https://www.vividcortex.com/blog/author/baron-schwartz">Baron Schwartz</a> wrote.) <br><a name="habracut"></a><br><h1>  We refuse average </h1><br>  In the past few years, many people have immediately started talking about the fact that there are a number of problems in monitoring by means of averages.  It is good that this topic has become actively discussed now, because for a long time the average values ‚Äã‚Äãof the parameters in the monitoring were generated and accepted without any careful analysis. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Average values ‚Äã‚Äãare a problem and hardly help when it comes to monitoring.  If you are just watching the averages, you are likely to miss the data that has the greatest impact on your system: when looking for any problems, events that are especially important to you will, by definition, be emissions.  There are two problems with average values ‚Äã‚Äãin case of outliers: <br><br><ul><li>  Averages hide emissions and you don‚Äôt see them. </li><li>  Emissions shift the mean values, so that in the system in which there are outliers, the mean values ‚Äã‚Äãno longer reflect the normal state of the system. </li></ul><br><br>  So when you average any metric in the system with errors, you combine all the worst: you see the not quite normal state of the system, but at the same time you do not see anything unusual. <br><br>  By the way, the work of most software systems is simply teeming with extreme emissions. <br><br>  Viewing the emissions in the <a href="https://en.wikipedia.org/wiki/Long_tail">long tail by the frequency of occurrence is</a> very important because it shows you exactly how badly you make inquiries in some rare cases.  You will not see this if you work only with the average. <br><br>  As Werner Vogels from Amazon said at the opening re: Invent: the only thing that averages can tell you is that half of your customers you serve are even worse.  (Although this statement is absolutely correct in spirit, it does not quite reflect reality: it would be more correct to say about the median (it‚Äôs the 50th percentile) - it is this metric that provides the indicated property) <br><br>  The company Optimizely published an entry in <a href="https://blog.optimizely.com/2013/12/11/why-cdn-balancing/">this post a</a> couple of years ago.  She perfectly explains why averages can lead to unexpected consequences: <br><blockquote>  ‚ÄúAlthough the mean values ‚Äã‚Äãare very easy to understand, they can also lead to the strongest misconceptions.  Why?  Because monitoring the average response time is like measuring the average temperature of a hospital.  While what really cares for you is the temperature of each patient and, in particular, which patient needs your help first. ‚Äù <br></blockquote><br><br>  Brendan Gregg also <a href="http://www.brendangregg.com/FrequencyTrails/mean.html">explained</a> this <a href="http://www.brendangregg.com/FrequencyTrails/mean.html">well</a> : <br><blockquote>  ‚ÄúAs a statistical characteristic, average values ‚Äã‚Äã(including arithmetic average) have many advantages in practical use.  However, the ability to describe the distribution of values ‚Äã‚Äãis not one of them. ‚Äù <br></blockquote><br><br><h1>  Forward to percentiles </h1><br>  Percentiles (quantiles - in a broader sense) are often extolled as a means to overcome this fundamental lack of averages.  The meaning of the 99th percentile is to collect the entire set of data (in other words, the entire collection of system measurements) and sort them, then discard the 1% largest and take the greatest value from the remaining ones.  The resulting value has two important properties: <br><br><ol><li>  This is the largest value of the values ‚Äã‚Äãobtained in 99% of cases.  If this value, for example, is a measurement of the load time of a web page, then it reflects the worst case of service, which is obtained at least with 99% of visits to your service. </li><li>  This value is resistant to really strong emissions that occur for a variety of reasons, including measurement errors. </li></ol><br><br>  Of course, you do not have to choose exactly 99%.  The 90th, 95th, and 99.9th (or even more nines) percentiles are common variants. <br><br>  And now you suppose: the average is bad, and percentiles are great - let's calculate the percentages by metrics and store them in our storage for storing time series ( <a href="https://en.wikipedia.org/wiki/Time_series_database">TSDB</a> )?  But everything is not so simple. <br><br><h1>  How exactly TSDB stores and processes metrics </h1><br>  There is a big problem with percentiles in the time series of data.  The problem is that most TSDBs almost always store <em>aggregated</em> metrics on time intervals, rather than the <em>entire sample of</em> measured events.  Subsequently, TSDB <em>averaged</em> these metrics over time in a number of cases.  The most important: <br><br><ul><li>  They average the metrics if the discreteness of time in your query differs from the discreteness of time that was used to aggregate the data while saving.  If you want to display a graph of the metrics per day, for example, 600px wide, then each pixel will reflect 144 seconds of data.  This averaging is implicit and users are unaware of it.  But in reality, these services should have issued a warning! </li><li>  TSDBs average the data when they are stored for long-term storage at a lower resolution, which is what happens in most TSDBs. </li></ul><br><br>  And here comes the problem.  You are again dealing with averaging in some form.  Percentile averaging does not work, because to calculate the percentile at a new scale, you must have a full sample of events.  All calculations are in fact incorrect.  Percentile averaging has no meaning.  (The consequences of this can be arbitrary. I will come back to this later.) <br><br><img src="https://habrastorage.org/files/ab7/9e7/5e5/ab79e75e58fb493bbdbb1b4fb8d473ca.png"><br><br>  Unfortunately, some common open-source monitoring products incite the use of percentile metrics, which in fact will then be resampled when saved.  For example, StatsD, allows you to calculate the desired percentile and then generates a metric with a name like foo.upper_99 and periodically drops them to save to Graphite.  Everything is fine if the discreteness of time does not change when viewed, but we know that this happens all the same. <br><br>  A misunderstanding of how all these calculations occur is extremely common.  Reading the comment thread for this <a href="https://github.com/etsy/statsd/issues/157">StatsD GitHub ticket is an example of</a> this.  Some comrades there are talking about things that have nothing to do with reality. <br><br><img src="https://habrastorage.org/files/49e/39f/045/49e39f045b7648148cfd72ee3e4c08af.png"><br><blockquote>  ‚ÄúSusie, how many are 12 + 7?‚Äù <br>  - Billion! <br>  - Thank! <br>  ‚Äú... uh, but that can't seem to be true?‚Äù <br>  - the same thing she said about 3 + 4 <br></blockquote><br><br>  Perhaps the shortest way to identify a problem would be to say this: <em>Percentiles are calculated from a collection of dimensions and must be recalculated completely every time this collection changes.</em>  <em>TSDB periodically averages data over different time intervals, but at the same time does not store the original sample of measurements.</em> <br><br><h1>  Other ways to calculate percentiles </h1><br>  But, if the calculation of percentiles really requires a complete selection of the original events (for example, each time each web page is loaded), then in this case we have a big problem.  The problem of "Big Data" - it will be more accurate to say so.  That is why the truthful calculation of percentiles is extremely expensive. <br><br>  There are several ways to calculate * approximate "percentiles that are almost as good as storing a complete sample of measurements and then sorting and calculating it. You can find a lot of research in various areas including: <br><ul><li>  histograms that divide the entire collection of events by ranges (or baskets) and then calculate how many events fall into each of the ranges (baskets) </li><li>  approximate data stream structures and algorithms (sketching, "sketchs") </li><li>  repositories that select from a collection of events to provide approximate answers </li><li>  solutions with time, quantity, or both at once </li></ul><br><br>  The essence of most of these solutions is to approximate the <em>distribution of the</em> collection in one way or another.  From distribution information, you can calculate approximate percentiles, as well as some other interesting metrics.  Again, from the Optimizely blog, you can give an interesting example of the distribution of response times, as well as the average and 99th percentile: <br><br><img src="https://habrastorage.org/files/82b/16e/6e3/82b16e6e333743fba0e3b88ac1866987.png" title="Source: Catchpoint.com, data between Oct. 15, 2013 and Nov. 25, 2013 for the Optimizely page with a size of 30KB."><br><br>  There are many ways to calculate and store approximate distributions, but histograms are especially popular because of their relative simplicity.  Some monitoring solutions support histograms.  <a href="https://www.circonus.com/">Circonus</a> for example, one of these.  Theo Schlossnagle, CEO of Circonus, often writes about the advantages of histograms. <br><br>  Ultimately, having the distribution of the original collection of events is useful not only for calculating percentiles, but also allows you to identify some things that percentiles cannot say.  In the end, the percentile is just a number that is only trying to reflect a large amount of information about the data.  I will not go as far as Theo did when he <a href="https://twitter.com/postwait/status/410822849965084672">tweeted</a> that <em>‚Äúthe 99th is no better than the average,‚Äù</em> because here I agree with the fans of percentiles that they are much more informative than the average values ‚Äã‚Äãin the presentation Some important characteristics of the original sample.  Nevertheless, the percentiles are not so good to tell you about the data, as more detailed histograms.  The illustration from Optimizely above contains an order of magnitude more information than any single number can do. <br><br><h1>  Even better percentiles in TSDB </h1><br>  The best way to calculate percentiles in TSDB is to collect metrics by range.  I made a similar assumption, since the multitude of TSDBs are in fact only key-value collections ordered by timestamp without the ability to store histograms. <br><br>  Range metrics provide the same capabilities as a histogram sequence over time.  All you need to do is select the limits that will divide the values ‚Äã‚Äãby range, and then calculate all the metrics separately for each of the ranges.  The metric will be the same as for the histogram: namely, the number of events whose values ‚Äã‚Äãfall into this range. <br><br>  But in general, the choice of ranges for separation is not an easy task.  Usually a good choice would be ranges with logarithmically progressive sizes or ranges that provide storage of coarse values ‚Äã‚Äãto speed up the calculations (at the cost of avoiding the smooth growth of counters).  But ranges with the same size are unlikely to be a good choice.  More information on this topic is <a href="http://www.brendangregg.com/FrequencyTrails/modes.html">in a note from Brendan Gregg</a> . <br><br>  There is a fundamental contradiction between the amount of stored data and their degree of accuracy.  However, even a coarse distribution of the ranges provides a better presentation of the data than the average.  For example, <a href="https://www.unionstationapp.com/">Phusion Passenger Union Station</a> displays timeout metrics for 11 ranges.  (It doesn‚Äôt seem to me at all that the above illustration is vivid; the value along the y axis is somewhat embarrassing, in fact, this is a 3D graph projected in a 2D nonlinear way. It doesn‚Äôt give him more information than the average value.) <br><br><img src="https://habrastorage.org/files/980/d62/18e/980d6218e89646699ccd51664ec4c103.png"><br><br>  How can this be implemented using popular open-source products?  You must define the ranges and create columns in the form of piles as in the figure above. <br><br>  But to calculate the percentile from this data will now be much more difficult.  You will have to go through all the ranges in the reverse order, from large to smaller, summarizing the number of events along the way.  As soon as you get the sum of the number of events greater than 1% of the total, then this range will store the value of 99% of the percentile.  There are a lot of nuances - lax equality;  exactly how to handle borderline cases, what value to choose for the percentile (range from above or below? or maybe in the middle? or can be weighted from all?). <br><br>  In general, such calculations can be very confusing.  For example, you can assume that you need 100 ranges to calculate the 99th percentile, but in fact, everything could be different.  If you have only two ranges and 1% of all values ‚Äã‚Äãfall into the upper one, then you can get a 99% percentile and so on.  (If this seems strange to you, then think about quantiles in general; I think that understanding the essence of quantiles is very valuable.) <br><br>  So it's not all simple.  This is possible in theory, but in practice it strongly depends on whether the repository supports the necessary types of queries to obtain approximate percentile values ‚Äã‚Äãfor range metrics.  If you know the repositories in which this is possible - write in the comments (on the author‚Äôs website - <em>approx. Lane</em> ) <br><br>  The good thing is that in systems like Graphite (that is, those that expect that all metrics can be freely averaged and resampled), all range metrics are absolutely resistant to these types of transformations.  You will get the correct values ‚Äã‚Äãbecause all calculations are commutative with respect to time. <br><br><h1>  Beyond Percentiles: Heat Maps </h1><br>  A percentile is just a number, as well as an average.  The average displays the center of mass of the sample, the percentile shows the mark of the upper level of the specified fraction of the sample.  Think of percentiles as traces of the waves on the beach.  But, although the percentile displays the upper levels, and not only the central trend as an average, it is still not as informative and detailed as compared to the distribution, which in turn describes the entire sample as a whole. <br><br>  Meet, there are heat maps - which are actually 3D graphs in which the histograms are rotated and aligned together over time, and the values ‚Äã‚Äãare displayed in color.  Again, Circonus provides an excellent example of <a href="https://www.circonus.com/understanding-data-with-histograms/">heat map visualization</a> . <br><br><img src="https://habrastorage.org/files/8c6/d4b/e07/8c6d4be07f97429abba864b5b27a869b.png"><br><br>  On the other hand, as I know, Graphite does not yet provide the ability to create heat maps for range metrics.  If I'm wrong and this can be done with the help of some kind of trick - let me know. <br><br>  Heat maps are also great for displaying the shape and density of delays in particular.  Another example of a delayed heatmap is a summary of streaming delivery from <a href="https://www.fastly.com/">Fastly</a> . <br><br><img src="https://habrastorage.org/files/73d/148/4b7/73d1484b748b416d94d1e5a969ab254f.png"><br><br>  Even some ancient tools that already seem to you primitive can create heat maps.  For example, Smokeping, uses shading to display ranges of values.  Bright green indicates average: <br><br><img src="https://habrastorage.org/files/ee6/140/b66/ee6140b66c384f85947c8344594de8c3.png"><br><br><h1>  But is it really bad to store metrics on percentiles? </h1><br>  Well, after all the mentioned difficulties and nuances that need to be taken into account, perhaps the good old StatsD-metric upper_99 to show percentiles does not seem so bad to you.  In the end, it is very simple, convenient and ready to use.  Is this metric so bad? <br><br>  It all depends on the circumstances.  For a variety of usage scenarios, they are great.  I mean, in any case, you still limit yourself to the fact that the percentiles do not always describe the data well.  But if it doesn't matter to you, then the biggest problem for you is oversampling of these metrics, which will mean that you will then watch for incorrect data. <br><br>  But <a href="http://www.xaprb.com/blog/2010/10/02/all-measurements-are-wrong/">measuring is generally the wrong thing</a> - in any case, and besides, a lot of essentially wrong things are nonetheless still somehow useful.  For example, I could tell that a good half of the metrics that people look at are actually already deliberately distorted.  For example, load average for systems is indicative.  This parameter is undoubtedly useful, but as soon as you know <a href="http://perfcap.blogspot.com/2007/04/load-average-differences-between.html">exactly how this ‚Äúsausage‚Äù is made</a> , you may be shocked at first.  (On Habr√© there is <a href="http://habrahabr.ru/post/260335/">an excellent article</a> about the calculation of LA - <em>approx. Per.</em> ) Similarly, many systems in the same way compactly display various metrics of their performance.  Many of the Cassandra metrics are the result of the Metrics library (Coda Hale) and are in fact a floating average (an <a href="https://www.vividcortex.com/blog/2014/11/25/how-exponentially-weighted-moving-averages-work/">exponentially weighted floating average</a> ) to which many people have a permanent <a href="https://vimeo.com/131502992">aversion</a> . <br><br>  But back to the metrics on percentiles.  If you save the p99 metric, then reduce and view the average version over a long period of time - although it may not be ‚Äúcorrect‚Äù and it may even be that the graph will be quite different from the real value of the 99th percentile, but that it will wrong, does not necessarily mean that this schedule can not be used for the desired purposes, namely to understand the worst cases in the interaction of users with your application. <br><br>  So it all depends on the case.  If you understand how percented work and the fact that averaging percentiles is wrong, and it suits you, then storage of percentiles can be acceptable and even useful.  But here you bring a moral dilemma: with this approach, you can greatly embarrass unsuspecting people (maybe even your colleagues).  Look at the comments to the ticket on StatsD again: the lack of understanding of the essence of the process is directly felt. <br><br>  Let me not draw the best analogy: I sometimes use from my fridge such things that I would never have suggested to others.  Just ask my wife about it.  (Author's wife - <em>comment.</em> ).  If you give people a bottle labeled "alcohol" and it contains methanol, then these people will go blind.  But some will ask: ‚Äúwhat kind of alcohol is contained in this bottle?‚Äù You better stick to the same measure of responsibility in relation to such questions. <br><br><h1>  What exactly does VividCortex do? </h1><br>  At the moment, our TSDB does not support histograms and we do not support the calculation and preservation of percentiles (although you can simply send us any of <a href="https://www.vividcortex.com/blog/2015/08/20/send-custom-metrics-vividcortex/">your metrics</a> if necessary). <br><br>  For the future, we plan to support the storage of high-resolution band metrics, that is, metrics with a large number of ranges.  We will be able to implement something similar, since most of the ranges are likely to be empty and our TSDB will be able to efficiently process sparse data (it is also likely that after averaging over time they will not be so sparse anymore - <em>approx. Per.</em> ).  This will enable us to display histograms once a second (all our data is stored with a resolution of 1 second).  The band metrics will be redeclared to 1-minute resolution after the period specified in the settings, which is set to 3 days by default.  In this case, the band metrics will be resampled to a 1-minute resolution without any mathematical problems. <br><br>  And as a result, from these range metrics we will get the opportunity to get any desired percentile, show the estimated error, show the heat map and show the distribution curve. <br><br>  This will not be fast in implementation and will require a lot of effort from engineers, but the work has begun and the system has already been designed to take all this into account.  I cannot promise exactly when it will be implemented, but I consider it necessary to tell about our long-term plans. <br><br><h1>  findings </h1><br>  The post turned out to be somewhat longer than I first conceived, but I touched on many topics. <br><br><ul><li>  If you plan to calculate percentiles for some interval and then save the result in the form of time series - as some existing storages do - you may not get exactly what you are counting on. </li><li>  Exact calculation of percentiles requires large computational costs. </li><li>  Approximate values ‚Äã‚Äãfor percentiles can be calculated from histograms, range metrics, and other useful computing techniques. </li><li>  Such data will also allow to issue distributions and heatmaps, which will be even more informative than simple percentiles. </li><li>  If all this is not available right now or you cannot afford it, roll it, use metrics on pertsentiles, but remember the consequences. </li></ul><br><br>  Hope it was all helpful to you. <br><br><h1>  PS </h1><br><ul><li>  Someone mentioned on Twitter about the effect: ‚ÄúOops, pntnko, I find myself doing something somehow wrong.  But I switched to counting the percentage of requests that are executed in a time smaller / larger than the specified value and save this metric instead of the old one. ‚ÄùBut this also does not work.  The approach with the calculation of the average shares (and the percentage is the share) still does not work.  Instead, save the metric of the <em>number of</em> requests that are not executed in the desired time.  Here it will work. </li><li>  I could not immediately find an excellent post from Theo on this topic.  Here it is: <a href="http://www.circonus.com/problem-math/">http://www.circonus.com/problem-math/</a> </li></ul></div><p>Source: <a href="https://habr.com/ru/post/274303/">https://habr.com/ru/post/274303/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../274291/index.html">HPE service: harsh weekdays and funny stories</a></li>
<li><a href="../274293/index.html">Adobe has released an emergency patch to fix critical vulnerabilities Flash Player</a></li>
<li><a href="../274295/index.html">Prototype messaging service Geotalk</a></li>
<li><a href="../274299/index.html">Rayon: data parallelism in Rust</a></li>
<li><a href="../274301/index.html">Opening a new data center Hydro66</a></li>
<li><a href="../274305/index.html">Custom Cortina in Unity 5.3</a></li>
<li><a href="../274307/index.html">Video of the best reports of the JPoint 2015 Java Conference - Part 1</a></li>
<li><a href="../274309/index.html">New Year's gift from the Russian hoster low-cost</a></li>
<li><a href="../274311/index.html">Materials from Azov Developers Meetup 2015</a></li>
<li><a href="../274313/index.html">Compare incomparable: json in PostgreSQL vs Mysql vs Mongodb</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>