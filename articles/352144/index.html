<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>How to speed up PostgreSQL 10</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="(The article used examples and explanations from the book Nouveaulit√©s de PostgreSQL 10. (c) Dalibo, translated from French by Igor Levshin, editor Eg...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>How to speed up PostgreSQL 10</h1><div class="post__text post__text-html js-mediator-article"><p>  <em>(The article used examples and explanations from the book Nouveaulit√©s de PostgreSQL 10. (c) Dalibo, translated from French by Igor Levshin, editor Egor Rogov ( <a href="">original</a> ). Examples are checked, sometimes modified for better visibility)</em> </p><br><p>  Of course, we are already waiting, we will not wait for the appearance of the 11th version of PostgreSQL.  But it is already clear that some rather radical performance improvements have already appeared in version 10. It definitely makes sense to deal with them first. </p><br><p>  Performance "dozens" has improved in several directions.  This article will focus on acceleration due to: </p><br><ul><li>  parallelization of scanning tables and indexes, </li><li>  more efficient aggregation </li><li>  fast transition tables </li><li>  query acceleration due to multicolumn statistics. </li></ul><br><p>  We will start with concurrency. </p><a name="habracut"></a><br><h3 id="parallelizm-v-postgresql-10">  Concurrency in PostgreSQL 10 </h3><br><p> In version 9.6, parallelization of sequential table reading, joining, and aggregation already worked.  This was about reading requests, but not writing requests.  Neither <code>INSERT</code> / <code>UPDATE</code> / <code>DELETE</code> , nor writing CTE queries (Common Table Expressions, common table expressions), nor serving operations ( <code>CREATE INDEX</code> , <code>VACUUM</code> , <code>ANALYZE</code> ) supported parallelization. </p><br><p>  Version 10 allows you to parallelize: </p><br><ul><li>  index scan ( <code>Index Scan</code> and <code>Index Only Scan</code> ) </li><li>  merge join </li><li>  collecting results with sorting order preserved ( <code>Gather Merge</code> ) </li><li>  execution of prepared requests </li><li>  execution of uncorrelated subqueries </li></ul><br><p>  With a merge join, the left and right tables are ordered and then compared in parallel. </p><br><p>  The <code>Gather</code> plan node, which appeared in version 9.6, collects the results of all <em>background processes</em> in random order.  <code>Gather Merge</code> applies if each background process returns sorted results.  The node maintains order. </p><br><p>  To learn more about concurrency, see the <a href="https://dali.bo/parallel-query-v2">Parallel Query v2</a> article by <em>Robert Haas</em> . </p><br><h3 id="parametry">  Options </h3><br><p>  Accordingly, the parameters appeared in postgresql.config: <br>  <code>min_parallel_table_scan_size</code> defines the minimum amount of table data, above which the possibility of parallelizing the scan can be considered. </p><br><p>  <code>min_parallel_index_scan_size</code> defines the minimum amount of index data, above which the possibility of parallelizing the scan can be considered. </p><br><p>  <code>max_parallel_workers</code> determines the maximum number of background processes that a DBMS can allocate for processing parallel requests.  By default, this parameter is 8. </p><br><p>  When you increase or decrease this parameter, do not forget to consider the <code>max_parallel_workers_per_gather</code> parameter </p><br><p>  <code>max_parallel_workers_per_gather</code> determines the maximum number of parallel processes that can be allocated to a single Gather plan node.  By default, the parameter is 2. A value of 0 disables request parallelism. </p><br><h3 id="podgotovka">  Training </h3><br><p>  Create a table <code>t1</code> in PostgreSQL 10: </p><br><pre> <code class="sql hljs">habr_10=<span class="hljs-comment"><span class="hljs-comment"># CREATE TABLE t1 AS SELECT row_number() OVER() AS id, generate_series%100 AS c_100, generate_series%500 AS c_500 FROM generate_series(1,20000000); SELECT 20000000 habr_10=# ALTER TABLE t1 ADD CONSTRAINT pk_t1 PRIMARY KEY (id); ALTER TABLE habr_10=# CREATE INDEX idx_t1 ON t1 (c_100); CREATE INDEX</span></span></code> </pre> <br><p>  Change the parameter <code>max_parallel_workers_per_gather</code> : </p><br><pre> <code class="sql hljs">postgres=<span class="hljs-comment"><span class="hljs-comment"># ALTER SYSTEM SET max_parallel_workers_per_gather TO 3; ALTER SYSTEM postgres=# SELECT pg_reload_conf(); pg_reload_conf ---------------- t (1 row)</span></span></code> </pre> <br><p>  Repeat the same with PostgreSQL 9.6. </p><br><h2 id="parallel-bitmap-heap-scan">  Parallel Bitmap Heap Scan </h2><br><p>  In PostgreSQL 9.6, when reading parallelization, it was possible to only sequentially scan tables ( <code>parallel sequential scan</code> ), but not index access.  The scheduler had to choose between parallelization and using the index. </p><br><p>  Due to the <code>parallel bitmap heap scan</code> available in PostgreSQL 10, scanning processes create in-memory data structures that indicate which data pages should be read.  Background processes can then read their portions of pages in parallel. </p><br><pre> <code class="sql hljs">habr_9_6=<span class="hljs-comment"><span class="hljs-comment"># EXPLAIN ANALYSE VERBOSE SELECT count(*), c_100 FROM t1 WHERE c_100 &lt;10 GROUP BY c_100; QUERY PLAN ---------------------------------------------------------------------------------------------------------------------------- HashAggregate (cost=180449.79..180450.79 rows=100 width=12) (actual time=12663.666..12663.667 rows=10 loops=1) Output: count(*), c_100 Group Key: t1.c_100 -&gt; Bitmap Heap Scan on public.t1 (cost=37387.68..170463.19 rows=1997321 width=4) (actual time=231.350..12097.624 rows=2000000 loops=1) Output: id, c_100, c_500 Recheck Cond: (t1.c_100 &lt; 10) Rows Removed by Index Recheck: 13162468 Heap Blocks: exact=29054 lossy=79055 -&gt; Bitmap Index Scan on idx_t1 (cost=0.00..36888.35 rows=1997321 width=0) (actual time=226.889..226.889 rows=2000000 loops=1) Index Cond: (t1.c_100 &lt; 10) Planning time: 0.093 ms Execution time: 12663.698 ms (12 rows)</span></span></code> </pre> <br><pre> <code class="sql hljs">habr_10=<span class="hljs-comment"><span class="hljs-comment"># EXPLAIN ANALYSE VERBOSE SELECT count(*), c_100 FROM t1 WHERE c_100 &lt;10 GROUP BY c_100; QUERY PLAN ------------------------------------------------------------------------------------------------------- Finalize GroupAggregate (cost=158320.22..158323.47 rows=100 width=12) (actual time=9450.053..9450.060 rows=10 loops=1) Output: count(*), c_100 Group Key: t1.c_100 -&gt; Sort (cost=158320.22..158320.97 rows=300 width=12) (actual time=9450.050..9450.052 rows=40 loops=1) Output: c_100, (PARTIAL count(*)) Sort Key: t1.c_100 Sort Method: quicksort Memory: 26kB -&gt; Gather (cost=158276.87..158307.87 rows=300 width=12) (actual time=9449.733..9450.036 rows=40 loops=1) Output: c_100, (PARTIAL count(*)) Workers Planned: 3 Workers Launched: 3 -&gt; Partial HashAggregate (cost=157276.87..157277.87 rows=100 width=12) (actual time=9380.225..9380.227 rows=10 loops=4) Output: c_100, PARTIAL count(*) Group Key: t1.c_100 Worker 0: actual time=9357.189..9357.191 rows=10 loops=1 Worker 1: actual time=9357.320..9357.322 rows=10 loops=1 Worker 2: actual time=9356.856..9356.858 rows=10 loops=1 -&gt; Parallel Bitmap Heap Scan on public.t1 (cost=37775.94..154022.03 rows=650968 width=4) (actual time=181.108..9084.536 rows=500000 loops=4) Output: c_100 Recheck Cond: (t1.c_100 &lt; 10) Rows Removed by Index Recheck: 2743963 Heap Blocks: exact=10792 lossy=16877 Worker 0: actual time=155.190..9113.397 rows=494347 loops=1 Worker 1: actual time=154.130..9053.253 rows=499488 loops=1 Worker 2: actual time=154.988..9021.038 rows=494091 loops=1 -&gt; Bitmap Index Scan on idx_t1 (cost=0.00..37271.44 rows=2018000 width=0) (actual time=239.332..239.332 rows=2000000 loops=1) Index Cond: (t1.c_100 &lt; 10) Planning time: 0.129 ms Execution time: 9455.530 ms (29 rows)</span></span></code> </pre><br><h3 id="parallel-index-only-scan-i-parallel-index-scan">  Parallel Index-Only Scan and Parallel Index Scan </h3><br><p>  <strong>Parallel Index-Only Scan</strong> </p><br><p>  Index scans can now be done in parallel.  Consider the execution plan returned by the following request, paying attention to the presence of the <code>Gather</code> node: </p><br><pre> <code class="sql hljs">habr_9_6=<span class="hljs-comment"><span class="hljs-comment"># EXPLAIN ANALYSE SELECT count(*) FROM t1 WHERE id &gt; 10 AND id &lt; 5000000; QUERY PLAN ---------------------------------------------------------------------------------------------------------------------- Aggregate (cost=193908.66..193908.67 rows=1 width=8) (actual time=1726.007..1726.008 rows=1 loops=1) -&gt; Index Only Scan using pk_t1 on t1 (cost=0.44..181438.64 rows=4988010 width=0) (actual time=0.017..1323.316 rows=4999989 loops=1) Index Cond: ((id &gt; 10) AND (id &lt; 5000000)) Heap Fetches: 4999989 Planning time: 0.904 ms Execution time: 1726.031 ms (6 rows)</span></span></code> </pre> <br><pre> <code class="sql hljs">habr_10=<span class="hljs-comment"><span class="hljs-comment"># EXPLAIN ANALYSE SELECT count(*) FROM t1 WHERE id &gt; 10 AND id &lt; 5000000; QUERY PLAN ------------------------------------------------------------------------------------------ Finalize Aggregate (cost=153294.45..153294.46 rows=1 width=8) (actual time=1618.757..161 8.757 rows=1 loops=1) -&gt; Gather (cost=153294.13..153294.44 rows=3 width=8) (actual time=1618.596..1618.751 rows=4 loops=1) Workers Planned: 3 Workers Launched: 3 -&gt; Partial Aggregate (cost=152294.13..152294.14 rows=1 width=8) (actual time=16 10.488..1610.488 rows=1 loops=4) -&gt; Parallel Index Only Scan using pk_t1 on t1 (cost=0.44..148255.01 rows= 1615648 width=0) (actual time=1.779..1274.247 rows=1249997 loops=4) Index Cond: ((id &gt; 10) AND (id &lt; 5000000)) Heap Fetches: 1258298 Planning time: 0.931 ms Execution time: 1619.854 ms (10 rows)</span></span></code> </pre> <br><p>  <strong>Parallel Index Scan</strong> <br>  Now consider the execution plan returned by such a query: </p><br><pre> <code class="sql hljs">habr_9_6=<span class="hljs-comment"><span class="hljs-comment"># EXPLAIN ANALYSE SELECT count(c_100) FROM t1 WHERE id &lt; 5000000; QUERY PLAN ---------------------------------------------------------------------------------------------------------- Aggregate (cost=181438.82..181438.83 rows=1 width=8) (actual time=1655.367..1655.368 rows=1 loops=1) -&gt; Index Scan using pk_t1 on t1 (cost=0.44..168968.77 rows=4988019 width=4) (actual time=0.760..1137.062 rows=4999999 loops=1) Index Cond: (id &lt; 5000000) Planning time: 0.055 ms Execution time: 1655.391 ms (5 rows)</span></span></code> </pre> <br><pre> <code class="sql hljs">habr_10=<span class="hljs-comment"><span class="hljs-comment"># EXPLAIN ANALYSE SELECT count(c_100) FROM t1 WHERE id &lt; 5000000; QUERY PLAN ---------------------------------------------------------------------------------------------------------- Finalize Aggregate (cost=140773.27..140773.28 rows=1 width=8) (actual time=1675.122..1675.122 rows=1 loops=1) -&gt; Gather (cost=140772.95..140773.26 rows=3 width=8) (actual time=1675.111..1675.119 rows=4 loops=1) Workers Planned: 3 Workers Launched: 3 -&gt; Partial Aggregate (cost=139772.95..139772.96 rows=1 width=8) (actual time=1662.439..1662.439 rows=1 loops=4) -&gt; Parallel Index Scan using pk_t1 on t1 (cost=0.44..135733.82 rows=1615651 width=4) (actual time=1.020..1335.593 rows=1250000 loops=4) Index Cond: (id &lt; 5000000) Planning time: 0.060 ms Execution time: 1676.201 ms (9 rows)</span></span></code> </pre> <br><h3 id="nablyudenie-za-fonovymi-processami">  Monitoring Background Processes </h3><br><p>  This chapter does not relate directly to PostgreSQL acceleration, but is relevant here, since new parallelization features have been supplemented with new tools for monitoring parallel processes. </p><br><p>  In version 10, as in version 9.6, you can, while executing a request in one session, read the text of requests processed by background processes of other sessions, using the <code>pg_stat_activity</code> : </p><br><pre> <code class="sql hljs">habr_9_6=<span class="hljs-comment"><span class="hljs-comment"># -[ RECORD 1 ]----+------------------------------------------------------------------------ pid | 12789 application_name | psql backend_start | 2018-03-30 12:51:10.997649+03 query | SELECT pid,application_name,backend_start, query FROM pg_stat_activity; -[ RECORD 2 ]----+------------------------------------------------------------------------ pid | 12801 application_name | psql backend_start | 2018-03-30 12:52:57.486572+03 query | EXPLAIN (ANALYZE,BUFFERS,VERBOSE) SELECT COUNT(id) FROM t1; -[ RECORD 3 ]----+------------------------------------------------------------------------ pid | 12823 application_name | psql backend_start | 2018-03-30 12:54:32.775267+03 query | -[ RECORD 4 ]----+------------------------------------------------------------------------ pid | 12822 application_name | psql backend_start | 2018-03-30 12:54:32.778756+03 query | -[ RECORD 5 ]----+------------------------------------------------------------------------ pid | 12821 application_name | psql backend_start | 2018-03-30 12:54:32.782583+03 query</span></span></code> </pre> <br><p>  In 10-ke, you can see the types of processes ( <code>backend_type</code> ), among which may be background processes.  In addition, the <code>state</code> field will help <code>WHERE state='active'</code> to leave only active processes: </p><br><pre> <code class="sql hljs">habr_10=<span class="hljs-comment"><span class="hljs-comment"># SELECT pid,application_name,backend_start,backend_type,query FROM pg_stat_activity WHERE state='active'; -[ RECORD 1 ]----+----------------------------------------------------------------------------------------------------------- pid | 2225 application_name | psql backend_start | 2018-03-29 17:08:23.43802+03 backend_type | background worker query | EXPLAIN (ANALYZE, BUFFERS, VERBOSE) SELECT count(id) FROM t1; -[ RECORD 2 ]----+----------------------------------------------------------------------------------------------------------- pid | 462 application_name | psql backend_start | 2018-03-29 14:08:19.939538+03 backend_type | client backend query | SELECT pid,application_name,backend_start, backend_type, query FROM pg_stat_activity WHERE state='active'; -[ RECORD 3 ]----+----------------------------------------------------------------------------------------------------------- pid | 2224 application_name | psql backend_start | 2018-03-29 17:08:23.44016+03 backend_type | background worker query | EXPLAIN (ANALYZE, BUFFERS, VERBOSE) SELECT count(id) FROM t1; -[ RECORD 4 ]----+----------------------------------------------------------------------------------------------------------- pid | 2223 application_name | psql backend_start | 2018-03-29 17:08:23.442845+03 backend_type | background worker query | EXPLAIN (ANALYZE, BUFFERS, VERBOSE) SELECT count(id) FROM t1; -[ RECORD 5 ]----+----------------------------------------------------------------------------------------------------------- pid | 2090 application_name | psql backend_start | 2018-03-29 17:03:03.776892+03 backend_type | client backend query | EXPLAIN (ANALYZE, BUFFERS, VERBOSE) SELECT count(id) FROM t1;</span></span></code> </pre> <br><p>  Without <code>WHERE state='active'</code> , service processes such as <code>walwriter</code> and <code>checkpointer</code> will also be visible, which during the query were inactive: </p><br><pre> <code class="sql hljs">-[ RECORD 1 ]<span class="hljs-comment"><span class="hljs-comment">----+--------------------------------------------------------------------------------------------- pid | 2825 application_name | backend_start | 2017-10-25 17:22:29.188114+03 backend_type | background worker state | query | -[ RECORD 2 ]----+--------------------------------------------------------------------------------------------- pid | 2823 application_name | backend_start | 2017-10-25 17:22:29.187815+03 backend_type | autovacuum launcher state | query | -[ RECORD 3 ]----+--------------------------------------------------------------------------------------------- pid | 2855 application_name | psql backend_start | 2018-03-29 18:18:09.743613+03 backend_type | client backend state | active query | SELECT pid,application_name,backend_start, backend_type, state, query FROM pg_stat_activity; -[ RECORD 4 ]----+--------------------------------------------------------------------------------------------- pid | 2821 application_name | backend_start | 2017-10-25 17:22:29.18081+03 backend_type | background writer state | query | -[ RECORD 5 ]----+--------------------------------------------------------------------------------------------- pid | 2820 application_name | backend_start | 2017-10-25 17:22:29.181031+03 backend_type | checkpointer state | query | -[ RECORD 6 ]----+--------------------------------------------------------------------------------------------- pid | 2822 application_name | backend_start | 2017-10-25 17:22:29.180576+03 backend_type | walwriter state | query |------</span></span></code> </pre> <br><h3 id="vyigrysh-pri-agregirovanii">  Benefit from aggregation </h3><br><p>  To save space, we will not provide the code for creating a database of Orders, which includes several tables.  Here is an example of a query that uses the <code>GROUP BY</code> with different grouping sets: </p><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">EXPLAIN</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">ANALYZE</span></span>, BUFFERS, COSTS <span class="hljs-keyword"><span class="hljs-keyword">off</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> <span class="hljs-keyword"><span class="hljs-keyword">GROUPING</span></span>(client_type, country_code)::<span class="hljs-built_in"><span class="hljs-built_in">bit</span></span>(<span class="hljs-number"><span class="hljs-number">2</span></span>), <span class="hljs-keyword"><span class="hljs-keyword">GROUPING</span></span>(client_type)::<span class="hljs-built_in"><span class="hljs-built_in">boolean</span></span> g_type_cli, <span class="hljs-keyword"><span class="hljs-keyword">GROUPING</span></span>(country_code)::<span class="hljs-built_in"><span class="hljs-built_in">boolean</span></span> g_code_pays, cl.client_type, co.country_code, <span class="hljs-keyword"><span class="hljs-keyword">SUM</span></span>(l.price*l.quantity) <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> topay <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> orders c <span class="hljs-keyword"><span class="hljs-keyword">JOIN</span></span> order_lines l <span class="hljs-keyword"><span class="hljs-keyword">ON</span></span> (c.order_number = l.order_number) <span class="hljs-keyword"><span class="hljs-keyword">JOIN</span></span> clients cl <span class="hljs-keyword"><span class="hljs-keyword">ON</span></span> (c.client.id = cl.client_id) <span class="hljs-keyword"><span class="hljs-keyword">JOIN</span></span> contacts co <span class="hljs-keyword"><span class="hljs-keyword">ON</span></span> (cl.contact_id = co.contact_id) <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> c.order_date <span class="hljs-keyword"><span class="hljs-keyword">BETWEEN</span></span> <span class="hljs-string"><span class="hljs-string">'2014-01-01'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">AND</span></span> <span class="hljs-string"><span class="hljs-string">'2014-12-31'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">GROUP</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> <span class="hljs-keyword"><span class="hljs-keyword">CUBE</span></span> (cl.client_type, co.country_code);</code> </pre> <br><p>  The request will be processed differently in 9.6 and 10. In PostgreSQL 9.6, the <code>GroupAggregate</code> plan node is involved: </p><br><pre> <code class="sql hljs"> QUERY PLAN <span class="hljs-comment"><span class="hljs-comment">-------------------------------------------------------------------------------- GroupAggregate (actual time=2720.032..4971.515 rows=40 loops=1) Group Key: cl.type_client, co.code_pays Group Key: cl.type_client Group Key: () Sort Key: co.code_pays Group Key: co.code_pays Buffers: shared hit=8551 read=47879, temp read=32236 written=32218 -&gt; Sort (actual time=2718.534..3167.936 rows=1226456 loops=1) Sort Key: cl.type_client, co.code_pays Sort Method: external merge Disk: 34664kB Buffers: shared hit=8551 read=47879, temp read=25050 written=25032 -&gt; Hash Join (actual time=525.656..1862.380 rows=1226456 loops=1) Hash Cond: (l.numero_commande = c.numero_commande) Buffers: shared hit=8551 read=47879, temp read=17777 written=17759 -&gt; Seq Scan on lignes_commandes l (actual time=0.091..438.819 rows=3141967 loops=1) Buffers: shared hit=2241 read=39961 -&gt; Hash (actual time=523.476..523.476 rows=390331 loops=1) Buckets: 131072 Batches: 8 Memory Usage: 3162kB Buffers: shared hit=6310 read=7918, temp read=1611 written=2979 -&gt; Hash Join (actual time=152.778..457.347 rows=390331 loops=1) Hash Cond: (c.client_id = cl.client_id) Buffers: shared hit=6310 read=7918, temp read=1611 written=1607 -&gt; Seq Scan on commandes c (actual time=10.810..132.984 rows=390331 loops=1) Filter: ((date_commande &gt;= '2014-01-01'::date) AND (date_commande &lt;= '2014-12-31'::date)) Rows Removed by Filter: 609669 Buffers: shared hit=2241 read=7918 -&gt; Hash (actual time=139.381..139.381 rows=100000 loops=1) Buckets: 131072 Batches: 2 Memory Usage: 3522kB Buffers: shared hit=4069, temp read=515 written=750 -&gt; Hash Join (actual time=61.976..119.724 rows=100000 loops=1) Hash Cond: (co.contact_id = cl.contact_id) Buffers: shared hit=4069, temp read=515 written=513 -&gt; Seq Scan on contacts co (actual time=0.051..18.025 rows=110005 loops=1) Buffers: shared hit=3043 -&gt; Hash (actual time=57.926..57.926 rows=100000 loops=1) Buckets: 65536 Batches: 2 Memory Usage: 3242kB Buffers: shared hit=1026, temp written=269 -&gt; Seq Scan on clients cl (actual time=0.060..21.896 rows=100000 loops=1) Buffers: shared hit=1026 Planning time: 1.739 ms Execution time: 4985.385 ms (41 rows)</span></span></code> </pre> <br><p>  In PostgreSQL 10, as you can see, the <code>MixedAggregate</code> plan node appears, that is, the ability to perform <code>GROUPING SETS</code> (grouping sets) with hashing and sorting.  Using <code>MixedAggregate</code> speeds query execution by half: </p><br><pre> <code class="sql hljs"> QUERY PLAN <span class="hljs-comment"><span class="hljs-comment">-------------------------------------------------------------------------------- MixedAggregate (actual time=2640.531..2640.561 rows=40 loops=1) Hash Key: cl.type_client, co.code_pays Hash Key: cl.type_client Hash Key: co.code_pays Group Key: () Buffers: shared hit=8418 read=48015, temp read=17777 written=17759 -&gt; Hash Join (actual time=494.339..1813.743 rows=1226456 loops=1) Hash Cond: (l.numero_commande = c.numero_commande) Buffers: shared hit=8418 read=48015, temp read=17777 written=17759 -&gt; Seq Scan on lignes_commandes l (actual time=0.019..417.992 rows=3141967 loops=1) Buffers: shared hit=2137 read=40065 -&gt; Hash (actual time=493.558..493.558 rows=390331 loops=1) Buckets: 131072 Batches: 8 Memory Usage: 3162kB Buffers: shared hit=6278 read=7950, temp read=1611 written=2979 -&gt; Hash Join (actual time=159.207..429.528 rows=390331 loops=1) Hash Cond: (c.client_id = cl.client_id) Buffers: shared hit=6278 read=7950, temp read=1611 written=1607 -&gt; Seq Scan on commandes c (actual time=2.562..103.812 rows=390331 loops=1) Filter: ((date_commande &gt;= '2014-01-01'::date) AND (date_commande &lt;= '2014-12-31'::date)) Rows Removed by Filter: 609669 Buffers: shared hit=2209 read=7950 -&gt; Hash (actual time=155.728..155.728 rows=100000 loops=1) Buckets: 131072 Batches: 2 Memory Usage: 3522kB Buffers: shared hit=4069, temp read=515 written=750 -&gt; Hash Join (actual time=73.906..135.779 rows=100000 loops=1) Hash Cond: (co.contact_id = cl.contact_id) Buffers: shared hit=4069, temp read=515 written=513 -&gt; Seq Scan on contacts co (actual time=0.011..18.347 rows=110005 loops=1) Buffers: shared hit=3043 -&gt; Hash (actual time=70.006..70.006 rows=100000 loops=1) Buckets: 65536 Batches: 2 Memory Usage: 3242kB Buffers: shared hit=1026, temp written=269 -&gt; Seq Scan on clients cl (actual time=0.014..26.689 rows=100000 loops=1) Buffers: shared hit=1026 Planning time: 1.910 ms Execution time: 2642.349 ms (36 rows)</span></span></code> </pre> <br><h3 id="perehodnye-tablicy">  Transition tables </h3><br><p>  If the trigger works at the operator level, <code>OLD</code> and <code>NEW</code> cannot be used, since they are applicable only to one line.  For this case, the SQL standard provides transition tables. </p><br><p>  Version 10 solves this problem based on the SQL standard. </p><br><p>  Here is an example of use: </p><br><p>  We will create a main table, which will have a trigger, and an archive table to store the records deleted from main. </p><br><pre> <code class="sql hljs">habr_10=<span class="hljs-comment"><span class="hljs-comment"># CREATE TABLE main (c1 integer, c2 text); CREATE TABLE habr_10=# CREATE TABLE archive (id integer GENERATED ALWAYS AS IDENTITY, dlog timestamp DEFAULT now(), main_c1 integer, main_c2 text); CREATE TABLE</span></span></code> </pre> <br><p>  Now you need to create the code for the stored procedure: </p><br><pre> <code class="sql hljs">habr_10=<span class="hljs-comment"><span class="hljs-comment"># CREATE OR REPLACE FUNCTION log_delete() RETURNS trigger LANGUAGE plpgsql AS $$ BEGIN INSERT INTO archive (main_c1, main_c2) SELECT c1, c2 FROM oldtable; RETURN null; END $$; CREATE FUNCTION</span></span></code> </pre> <br><p>  And add a trigger to the main table: </p><br><pre> <code class="sql hljs">habr_10=<span class="hljs-comment"><span class="hljs-comment"># CREATE TRIGGER tr1 AFTER DELETE ON main REFERENCING OLD TABLE AS oldtable FOR EACH STATEMENT EXECUTE PROCEDURE log_delete(); CREATE TRIGGER</span></span></code> </pre> <br><p>  Now insert a million lines and delete them.  You can find out the time for deleting rows and the trigger time using <code>EXPLAIN ANALYZE</code> : </p><br><pre> <code class="sql hljs">habr_10=<span class="hljs-comment"><span class="hljs-comment"># INSERT INTO main SELECT i, 'a_string'||i FROM generate_series(1, 1000000) i; INSERT 0 1000000 habr_10=# EXPLAIN (ANALYZE) DELETE FROM main; QUERY PLAN ------------------------------------------------------------------------------------------ Delete on main (cost=0.00..17642.13 rows=1127313 width=6) (actual time=1578.771..1578.77 1 rows=0 loops=1) -&gt; Seq Scan on main (cost=0.00..17642.13 rows=1127313 width=6) (actual time=0.018..10 6.833 rows=1000000 loops=1) Planning time: 0.026 ms Trigger tr1: time=2494.337 calls=1 Execution time: 4075.228 ms (5 rows)</span></span></code> </pre> <br><p>  We see that deleting lines takes about 1.5 seconds, while the trigger works 2.5 seconds. </p><br><p>  For comparison, this is how it was done before (with the configuration of the trigger at the row level): </p><br><pre> <code class="sql hljs">habr_9_6=<span class="hljs-comment"><span class="hljs-comment"># CREATE TABLE main (c1 integer, c2 text); CREATE TABLE habr_9_6=# CREATE TABLE archive (id integer, dlog timestamp DEFAULT now(), main_c1 integer, main_c2 text); CREATE TABLE habr_9_6=# CREATE OR REPLACE FUNCTION log_delete() RETURNS trigger LANGUAGE plpgsql AS $$ BEGIN INSERT INTO archive (main_c1, main_c2) VALUES (old.c1, old.c2); RETURN null; END $$; CREATE FUNCTION postgres=# CREATE TRIGGER tr1 AFTER DELETE ON main FOR EACH ROW EXECUTE PROCEDURE log_delete(); CREATE TRIGGER habr_9_6=# INSERT INTO main SELECT i, 'a_string'||i FROM generate_series(1, 1000000) i; INSERT 0 1000000 habr_9_6=# EXPLAIN ANALYZE DELETE FROM main; QUERY PLAN ---------------------------------------------------------------------------------------------------------------------- Delete on main (cost=0.00..16369.00 rows=1000000 width=6) (actual time=2009.263..2009.263 rows=0 loops=1) -&gt; Seq Scan on main (cost=0.00..16369.00 rows=1000000 width=6) (actual time=0.028..108.559 rows=1000000 loops=1) Planning time: 0.131 ms Trigger tr1: time=8572.522 calls=1000000 Execution time: 10649.182 ms (5 rows)</span></span></code> </pre> <br><p>  We see that in the operation at the row level the trigger deletes a million rows in 10.7 seconds, of which 8.6 falls on the trigger operation.  When the trigger operates at the operator level, 4 seconds are obtained, of which 1.5 is spent on the trigger.  That is, the transition tables can increase productivity. </p><br><p>  Great interest in transition tables is associated with this. </p><br><p>  To learn more about this topic, follow: </p><br><ul><li>  <a href="https://dali.bo/waiting-for-postgresql-10-implement-syntax-for-transition-tables-in-after-triggers">Implement syntax for transition tables in AFTER triggers</a> </li><li>  <a href="https://dali.bo/cool-stuff-in-postgresql-10-transition">Cool Stuff in PostgreSQL 10: Transition Table Triggers</a> </li></ul><br><h3 id="mnogokolonochnaya-statistika">  Multicolumn statistics </h3><br><p>  Now you can create statistics for several columns of one table.  This makes it possible to improve the estimates in drawing up the execution plan in the case when the columns correlate strongly. </p><br><p>  For example : </p><br><pre> <code class="sql hljs">habr_10=<span class="hljs-comment"><span class="hljs-comment"># CREATE TABLE multi (a INT, b INT); CREATE TABLE habr_10=# INSERT INTO multi SELECT i % 100, i % 100 FROM generate_series(1, 10000) s(i); INSERT 0 10000 habr_10=# ANALYZE multi; ANALYZE</span></span></code> </pre> <br><p>  The distribution of data is very simple: there are only 100 different values ‚Äã‚Äãdistributed evenly over the table. </p><br><p>  For column <code>a</code> : </p><br><pre> <code class="sql hljs">habr_10=<span class="hljs-comment"><span class="hljs-comment"># EXPLAIN (ANALYZE, TIMING OFF) SELECT * FROM multi WHERE a = 1; QUERY PLAN ----------------------------------------------------------------------------------- Seq Scan on multi (cost=0.00..170.00 rows=100 width=8) (actual rows=100 loops=1) Filter: (a = 1) Rows Removed by Filter: 9900 Planning time: 0.063 ms Execution time: 0.496 ms (5 rows)</span></span></code> </pre> <br><p>  The optimizer checks the condition and concludes that the selectivity of this condition is 1% (rows = 100 out of 10,000 inserted records). </p><br><p>  Similarly, we obtain an estimate for column <code>b</code> . </p><br><p>  Now apply the same condition to each column using <code>AND</code> : </p><br><pre> <code class="sql hljs">habr_10=<span class="hljs-comment"><span class="hljs-comment"># EXPLAIN (ANALYZE, TIMING OFF) SELECT * FROM multi WHERE a = 1 AND b = 1; QUERY PLAN --------------------------------------------------------------------------------- Seq Scan on multi (cost=0.00..195.00 rows=1 width=8) (actual rows=100 loops=1) Filter: ((a = 1) AND (b = 1)) Rows Removed by Filter: 9900 Planning time: 0.116 ms Execution time: 2.154 ms (5 rows)</span></span></code> </pre> <br><p>  The optimizer estimates the selectivity for each condition separately, getting the same estimate at 1%, as we saw above.  The final estimate of selectivity gives 0.01% of unique values, that is, it underestimates very significantly (a large difference between <code>cost</code> and <code>actual</code> ). </p><br><p>  To improve the score, we can now create multicolumn statistics: </p><br><pre> <code class="sql hljs">habr_10=<span class="hljs-comment"><span class="hljs-comment"># CREATE STATISTICS s1 (dependencies) ON a, b FROM multi; CREATE STATISTICS habr_10=# ANALYZE multi; ANALYZE</span></span></code> </pre> <br><p>  Now let's check: </p><br><pre> <code class="sql hljs">habr_10=<span class="hljs-comment"><span class="hljs-comment"># EXPLAIN (ANALYZE, TIMING OFF) SELECT * FROM multi WHERE a = 1 AND b = 1; QUERY PLAN ----------------------------------------------------------------------------------- Seq Scan on multi (cost=0.00..195.00 rows=100 width=8) (actual rows=100 loops=1) Filter: ((a = 1) AND (b = 1)) Rows Removed by Filter: 9900 Planning time: 0.086 ms Execution time: 0.525 ms (5 rows)</span></span></code> </pre> <br><p>  Now the score is adequate. </p><br><p>  For more information, you can refer to the <a href="https://dali.bo/waiting-for-postgresql-10-implement-multivariate-n-distinct-coefficients">Implement multivariate n-distinct coefficients</a> page. </p><br><p>  <em>To be continued</em> </p></div>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <p>Source: <a href="https://habr.com/ru/post/352144/">https://habr.com/ru/post/352144/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../352130/index.html">What tools for teamwork make ordinary employees of the Dream Team?</a></li>
<li><a href="../352132/index.html">SOA: send a request to the server? What could be easier?</a></li>
<li><a href="../352134/index.html">Once again about JetBrains Open Day in Moscow</a></li>
<li><a href="../352136/index.html">As I was looking for the perfect tool for designing conversational interfaces, or Finding the Holy Grail</a></li>
<li><a href="../352138/index.html">Artificial Intelligence and Neural Networks for .NET Developers</a></li>
<li><a href="../352146/index.html">IPv6 in every home: Your own IPv6 broker server (6in4)</a></li>
<li><a href="../352148/index.html">Hello, Rails</a></li>
<li><a href="../352150/index.html">Keys in React. Cook properly</a></li>
<li><a href="../352152/index.html">Paul Graham: how to share shares in a startup</a></li>
<li><a href="../352156/index.html">Alan Kay (and Habr's collective intelligence): what books form the labor engineer's thinking</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>