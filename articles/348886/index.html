<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>See the world through the eyes of animals: new horizons of eytreking</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="When we talk about technologies for recognizing emotions, we mean by default a person, that is, the entire array of data - verbal and non-verbal - tha...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>See the world through the eyes of animals: new horizons of eytreking</h1><div class="post__text post__text-html js-mediator-article">  When we talk about technologies for recognizing emotions, we mean by default a person, that is, the entire array of data - verbal and non-verbal - that is generated and used by them for a comprehensive assessment of his condition.  However, the further, the more attention is paid to animals: in recent years, studies of the ‚Äúemotional‚Äù world of horses or dogs, for example, have been regularly conducted.  In our article, we will discuss one of the reversals of this topic: the way in which the tracking technology is used to study the characteristics of some of the fauna living side by side with us.  So how to look around with the eyes of a dog, a peacock or even a mouse? <br><img src="https://habrastorage.org/webt/v4/6x/qp/v46xqpljsr5acdxhbr4_s6gl9ks.jpeg" alt="image"><br><a name="habracut"></a><br><h2>  Dogs </h2><br>  Probably, every dog ‚Äã‚Äãlover wants to know how human friends perceive us and their relatives.  Therefore, this direction of registration of animal eye movements leads in the diversity of experimental non-invasive techniques. <br><br>  For dogs, as for other social animals, the look is an important social signal.  The predominant function of a dog‚Äôs gaze in the eyes is a signal of dominance or ritualized aggression (Schenkel, 1967).  However, such oculomotor behavior demonstrated by the dog towards the owners is interpreted as the initialization of communication (Kis, Hern√°di, Mikl√≥si, Kanizs√°r, &amp; Top√°l, 2017).  Also, analysis of the oculomotor activity of dogs is a promising direction for the study of not only communication, but also face recognition and emotional facial expressions of people. <br><br>  In the course of research using the methods of eytreking on dogs, it was shown that the latter are able not only to recognize people by their faces, but also to distinguish individual human emotions: joy, sadness, anger.  When viewing images of people's faces, dogs prefer the eye area, regardless of the facial expression of the stimulus (Kis et al., 2017). <br>  Tornqvist et al. (T√∂rnqvist et al., 2015) conducted a curious comparative study of image viewing by dogs and humans.  Photographs depicting social interaction or avoiding social interaction between two people or two dogs were chosen as stimulus material.  So, both people and dogs demonstrated a longer time viewing objects in images with social interaction.  Note that people more time looked at the pictures with the social interaction of dogs than people, while the dogs - on the contrary. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      As for the study of human eye movements, there are two main types of experimental setups for dogs: stationary and wearable Aytrekeri. <br><br>  Stationary installations are a monitor-mounted tracker or projector on which stimuli are presented.  In such installations, a dog or pre-trained to stay for a long time (for example, Tornqvist et al. (2015) used this version of the experiment), and it is also used in Clever Dog Lab - the course of experiments using video-celography techniques in this laboratory can read <a href="https://drsophiayin.com/blog/entry/how-the-treattrain-is-used-in-research-on-canine-cognition-canine-cognition/">here</a> ), or the owner fixes it in the right position, as was done in the study of Kis et al.  (Kis et al., 2017).  With regard to the preliminary training of dogs in the experimental setup, there is an opinion that training in itself creates an additional cognitive task for the dog, which distorts the distribution of visual attention (Kis et al., 2017).  In addition, it is logical to assume that retention in the installation by the owner can also introduce some kind of distortion in the results obtained, and they are fundamentally important when studying the psycho-physiological state of animals. <br><br>  Therefore, the most promising method for studying the eye movements of dogs in more natural conditions are eytreker points systems.  So, at the University of Lincoln (UK), Williams and colleagues (Williams, Mills, &amp; Guo, 2011) developed on the basis of the eytreker <a href="http://polhemus.com/eye-tracking/visiontrak/">VisionTrak</a> (60 Hz) - tracker glasses for dogs, working with an accuracy of 2.25-2.71 ¬∞.  The whole structure is fixed on the muzzle: between the ears is a scene camera, in front of the left eye - a <a href="http://ru.science.wikia.com/wiki/%25D0%2594%25D0%25B8%25D1%2585%25D1%2580%25D0%25BE%25D0%25B8%25D1%2587%25D0%25B5%25D1%2581%25D0%25BA%25D0%25BE%25D0%25B5_%25D0%25B7%25D0%25B5%25D1%2580%25D0%25BA%25D0%25B0%25D0%25BB%25D0%25BE">dichroic mirror</a> , above the left eye - a camera for recording eye movements and infrared illumination.  During calibration, a calibration structure is attached to the muzzle center (in the nose area), which consists of two crossed axes, the ends of which correspond to the frame boundaries of the scene camera.  At the end of each calibration axis, there is an area where something tasty is fixed during the calibration ‚Äî the dog‚Äôs task is to look at the desired piece of food, with successful calibration it receives it as a reward.  Thus, this tracker does not require special training of the dog's behavior during the experiment, but involves only a brief training for calibration. <br><br>  Another project to create a tracker points for dogs - DogCam (Rossi, Parada, &amp; Allen, 2010). <br>  A lot of amazing facts about the study of the behavior of dogs can be found on the page <a href="https://www.facebook.com/CleverDogLab/">CleverDogLab</a> . <br><br><h2>  Birds </h2><br>  Birds have extremely sharp eyesight, and among them there are no species that would lack vision as such, therefore studying their visual perception is of particular interest.  The peculiarity of focusing on the object in birds is that they have practically no <a href="http://meduniver.com/Medical/Neurology/vestibulookuliarnii_refleks.html">vestibulo</a> - <a href="http://meduniver.com/Medical/Neurology/vestibulookuliarnii_refleks.html">ocular reflex</a> , that is, the head can move faster than the eyes.  For example, in pigeons, eye movements cause only 10‚Äì20% of gaze movement (Yorzinski, Patricelli, Platt, &amp; Land, 2015). <br><br>  Today, there are eye tracking systems for recording eye movements of only large birds.  Such an eytreker consists of a helmet on which a camera for recording eye movements (30 Hz) with infrared illumination and a scene camera is mounted, and a backpack with a battery and a transmitter.  Similar trackers produce only monocular registration (the second eye of the bird is closed), since the design with two cameras for recording eyes would be too heavy. <br><br>  For example, during the use of the described system in the study of the visual attention of female peacocks, significant results were obtained: when females see a peacock male from close range, their visual attention is directed to the lower half of the tail, and when the male peacock dismisses the tail, being far from the female - her attention is focused on the upper half of the tail (Yorzinski, Patricelli, Babcock, Pearson, &amp; Platt, 2013). <br><br>  At present, there is no adequate equipment to study the eye movements of birds of a small size (such as starlings), so the problems of visual attention of small birds are reduced to tracking head movements.  Thus, the Butler and Fernandez-Juricic study (Butler &amp; Fernandez-Juricic, 2018) showed that starlings (ordinary or European starling) use <a href="https://studopedia.su/15_6749_tsentralnoe-zrenie.html">foveal vision</a> when viewing a predator (the authors suggest that at this time the bird receives detailed information that can be required to successfully avoid the enemy). <br><br><h2>  Mice </h2><br>  H. Payne and JL Raymond (Payne &amp; Raymond, 2017) developed a method for registering eye movements on a freely moving mouse with a very high resolution of 0.1 ¬∞.  To do this, they applied the method of magnetic light tracking.  Mice are implanted with a cylindrical magnet (0.75 x 1 mm in size, weighing 6.8 mg) in a biocompatible polymer shell on the temporal side of the conjunctiva, the incision in which is healed with a tissue adhesive.  The magnet is perpendicular to the axis of the horizontal <a href="https://ru.wikipedia.org/wiki/%25D0%25A1%25D0%25B0%25D0%25BA%25D0%25BA%25D0%25B0%25D0%25B4%25D0%25B0">saccades</a> .  A small angular magnetic sensor (4.8 x 5.8 mm in size, weighing 76 mg) is attached above the implanted magnet on the skull.  The authors also conducted pilot experiments with smaller disk implantable magnets (1.5 x 0.5 mm), but they gave a too weak signal. <br><br>  Calibration of this system is a synchronous recording of a magnetic tracker signal and video using the <a href="https://github.com/hpay/eyetrack">dual-angle video-oculography method</a> on a mouse whose head is fixed.  The essence of the dual-angle video-oculografy lies in the video recording of eye movements by two fixed cameras with infrared illumination at an angle of 40 ¬∞ from each other and at an equal distance from the center of the pupil (5 cm).  The position of the eye is calculated for each frame by comparing the images from both cameras, the position of the eye is tied to the signal from the magnetic tracker.  Calibration is carried out only once and in the future the magnetic tracker can be used on a freely moving mouse in complete darkness.  The original article is available online; you can read it <a href="https://elifesciences.org/articles/29222">here</a> . <br><br><h2>  Primates </h2><br>  In our article, of course, you can not ignore the closest relatives of a person from the animal kingdom - primates.  A great deal of successful primitive research on primates has been done than on other animals, since monkeys are a classic model object for studying the neurophysiology of the visual system.  The most common method for registering eye movements in primates is using electromagnetic raytracking (we used this method of recording eye movements on a person in our previous <a href="https://habrahabr.ru/company/neurodatalab/blog/344782/">article</a> ), however, in the case of monkeys, the movable element is attached not to the lens, but implanted.  Often, this method is used in combination with invasive neurophysiological techniques that allow detailed analysis of the features of the brain and visual attention. <br>  About the study of the movements of the eyes of monkeys in Russia can be read <a href="http://www.atomic-energy.ru/SMI/2017/12/22/81988">here</a> . <br><br><h2>  Literature </h2><br><div class="spoiler">  <b class="spoiler_title">Bibliography</b> <div class="spoiler_text"> Butler, SR, &amp; Fernandez-Juricic, E. (2018).  European starlings predators but not on conspecifics.  PLoS ONE, 1‚Äì12.  <a href="https://doi.org/10.1371/journal.pone.0188857">doi.org/10.1371/journal.pone.0188857</a> <br>  C. Pallus, A., &amp; G. Freedman, E. (2016).  Target position during the gaze pursuit.  Experimental Brain Research, 234 (8), 2107‚Äì2121.  <a href="https://doi.org/10.1007/s00221-016-4612-x">doi.org/10.1007/s00221-016-4612-x</a> <br>  Kis, A., Hern√°di, A., Mikl√≥si, B., Kanizs√°r, O., &amp; Top√°l, J. (2017).  Human Emotional Faces Is Modified by Oxytocin.  An Eye-Tracking Study.  Frontiers in Behavioral Neuroscience, 11 (October), 1‚Äì11.  <a href="https://doi.org/10.3389/fnbeh.2017.00210">doi.org/10.3389/fnbeh.2017.00210</a> <br>  Payne, HL, &amp; Raymond, JL (2017).  Magnetic eye tracking in mice.  eLife, 6, 1‚Äì24.  <a href="https://doi.org/10.7554/eLife.29222">doi.org/10.7554/eLife.29222</a> <br>  Rossi, A., Parada, FJ, &amp; Allen, C. (2010).  DogCam: A Way to Measure Visual Attention in Dogs.  7th International Conference on Methods and Techniques in Behavioral Research. <br>  Schenkel, R. (1967).  Submission: Its features and functions.  Integrative and Comparative Biology, 7 (2), 319‚Äì329.  <a href="">doi.org/10.1093/icb/7.2.319</a> <br>  T√∂rnqvist, H., Somppi, S., Koskela, A., Krause, CM, Vainio, O., &amp; Kujala, MV (2015).  Comparison of dogs and humans in visual scanning of social interaction.  Royal Society Open Science, 2 (9), 150341. <a href="https://doi.org/10.1098/rsos.150341">doi.org/10.1098/rsos.150341</a> <br>  Williams, FJ, Mills, DS, &amp; Guo, K. (2011).  Development of a head-mounted eye-tracking system for dogs.  Journal of Neuroscience Methods, 194 (2), 259-265.  <a href="">doi.org/10.1016/j.jneumeth.2010.10.022</a> <br>  Yorzinski, JL, Patricelli, GL, Babcock, JS, Pearson, JM, &amp; Platt, ML (2013).  Through their eyes: selective attention in peahens during courtship.  Journal of Experimental Biology, 216 (16), 3035-3046.  <a href="https://doi.org/10.1242/jeb.087338">doi.org/10.1242/jeb.087338</a> <br>  Yorzinski, JL, Patricelli, GL, Platt, ML, &amp; Land, MF (2015).  Eye and head movements shape gaze shifts in Indian peafowl.  Journal of Experimental Biology, 218 (23), 3771‚Äì3776.  <a href="https://doi.org/10.1242/jeb.129544">doi.org/10.1242/jeb.129544</a> </div></div><br>  <b>Material author:</b> <br>  Maria Konstantinova, Researcher at <a href="http://www.neurodatalab.com/">Neurodata Lab</a> , biologist, physiologist, specialist in visual sensory system, oculography and ocular motorics. </div><p>Source: <a href="https://habr.com/ru/post/348886/">https://habr.com/ru/post/348886/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../348876/index.html">Payment system in 50 lines of code, really?</a></li>
<li><a href="../348878/index.html">New online software for developers</a></li>
<li><a href="../348880/index.html">Use for simple tests inheritance, polymorphism and patterns? Why not‚Ä¶</a></li>
<li><a href="../348882/index.html">Market as a stereotype regarding segment, need, supply</a></li>
<li><a href="../348884/index.html">KODOS: stay alive</a></li>
<li><a href="../348890/index.html">Regular expressions: no magic</a></li>
<li><a href="../348892/index.html">Information Security Recommendations for Small and Medium Business (SMB)</a></li>
<li><a href="../348894/index.html">Guide to background work in Android. Part 1</a></li>
<li><a href="../348896/index.html">Cradle: Rave. Two hackathons + conference, with emphasis on Big Data & ML, Blockchain, Quantum Computing, DevOps and Mobile</a></li>
<li><a href="../348898/index.html">Slack is the opposite of organizational memory.</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>