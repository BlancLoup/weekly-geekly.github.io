<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Deep Learning with Spark and Hadoop: Meet Deeplearning4j</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hello, dear readers! 

 We are fully convinced of the mega-popularity of deep learning (Python) in our target audience. Now we offer to talk about the...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Deep Learning with Spark and Hadoop: Meet Deeplearning4j</h1><div class="post__text post__text-html js-mediator-article">  Hello, dear readers! <br><br>  We are fully convinced of the mega-popularity of deep learning (Python) in our target audience.  Now we offer to talk about the major league of deep learning - that is, about solving these problems in the Java language with the help of the <a href="https://ru.wikipedia.org/wiki/Deeplearning4j">Deeplearning4j</a> library.  We have translated for you the June article from the Cloudera company blog, where the most interesting details are about the specifics of this library and about the deep learning in Hadoop and Spark. <br><br>  Enjoy reading. <br><a name="habracut"></a><br>  At the end of 2016, Ben Lorica from O'Reilly Media <a href="https://www.oreilly.com/ideas/2017-will-be-the-year-the-data-science-and-big-data-community-engage-with-ai-technologies">announced</a> that ‚Äúin 2017, the data science and big data community will be seriously engaged in AI technologies.‚Äù Until 2017, mostly deep GPU education was practiced at universities and research institutes , but at the present time, <i>distributed, deep learning is</i> spreading <i>on the CPU</i> in different companies and subject areas.  While GPUs provide maximum performance in numerical calculations, modern CPUs also pull up to them in terms of efficiency, both due to improved equipment and for the reason that they can now be used "en masse".  Such free tools have appeared, the most interesting of which is the deeplearning4j library - they provide fast deep learning in large-scale systems (the Hadoop stack) and should generally have a significant impact on deep learning in the coming years. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      In this article, we take a closer look at working with free tools - Apache Spark, Apache Hadoop, Deeplearning4j (DL4J) - running on low-cost (and widely available) hardware.  We will try to solve the problem of pattern recognition as efficiently as possible with a limited set of training data.  The DL4J API library is written in Java and is particularly interesting to Java and Scala developers who already know how to use the Java virtual machine.  In addition, the ability to parallelize model training in Spark (this requires only a few lines of code) simplifies the efficient use of existing cluster resources.  Thus, the learning process can be accelerated without sacrificing accuracy. <br><br>  <b>Deeplearning4j: a tool for deep learning on JVM</b> <br><br>  <a href="https://github.com/deeplearning4j/deeplearning4j">Deeplearning4j</a> is one of the many free kits for large-scale learning of deep neural networks on the CPU and GPU.  Deeplearning4j is designed for the JVM and is specifically focused on deep learning for large enterprises.  The deeplearning4j library was created in 2014, supported by <a href="https://skymind.ai/">Skymind</a> startup and has built-in integration with Apache Spark.  Although deeplearning4j is designed to work with JVM, it uses the high-performance native library of linear algebra Nd4j, which allows you to perform highly optimized calculations on a CPU or GPU. <br><br>  <b>Classification of objects from the set of images Caltech-256</b> <br><br>  This article explains how to use Apache Spark, Apache Hadoop and deeplearning4j to solve the problem of image classification.  In particular, it describes step by step how to build a convolutional neural network capable of classifying images from the <a href="http://www.vision.caltech.edu/Image_Datasets/Caltech256/">Caltech-256 set</a> .  In fact, there are 257 categories of objects in this set, each of which contains from 80 to 800 images;  Thus, in total in this set we have 30,607 images. <br><br>  It should be noted that the maximum classification accuracy of this data set currently ranges from 72 to 75%.  This result can be beaten with DL4J and Spark. <br><br>  <b>Effective deep learning on small data</b> <br><br>  Modern convolutional networks can have several hundreds of millions of parameters.  One of the most powerful of these networks is called the <a href="http://image-net.org/challenges/LSVRC/2017/">Large Scale Visual Recognition Challenge</a> (also known as ‚ÄúImageNet‚Äù), you need to train 140 million parameters in it!  Such networks not only consume a lot of computing and disk resources (even if there is a cluster of GPUs, it can take weeks to train), but they also require a lot of data.  With only 30,000 images, it is impractical to train such a complex model on Caltech-256, since there are too few examples in this set to adequately train so many parameters.  It is better to use a method called ‚Äú <a href="http://cs231n.github.io/transfer-learning/">learning transfer</a> ‚Äù, in which a pre-trained model is taken, adapted for other use cases.  Transfer of training also allows you to significantly reduce the computational load and get rid of numerous specialized computing resources, for example, the GPU. <br><br>  Such models can be reoriented, since convolutional neural networks trained on sets of images usually isolate the <a href="">most common features</a> , and it is this kind of training based on features that can be useful when processing other sets of images.  For example, a network trained on ImageNet will most likely recognize shapes, facial features, patterns, text, etc., which will undoubtedly come in handy when processing a Caltech-256 dataset. <br><br>  <b>Download pre-trained model</b> <br><br>  The following example uses the <a href="">VGG16</a> model, which ranked second in the 2014 ImageNet competition.  Fortunately, now this model is shared, all 140 million scales have already been optimized for forecasting on the ImageNet set.  Since we are going to work with a different set of images, it will be necessary to modify small elements of the model in order to sharpen it for such a prediction.  This model has about 140 million parameters, occupies about 500 MB of disk space. <br><br>  To begin with, we will get such a version of the VGG16 model, which is understandable by DL4J, and with which this library can work.  It turns out that this feature is built right into the DL4J API and is implemented in just a few lines on Scala. <br><br><pre><code class="java hljs">val modelImportHelper = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> TrainedModelHelper(TrainedModels.VGG16) val vgg16 = modelImportHelper.loadModel() val savePath = <span class="hljs-string"><span class="hljs-string">"./dl4j-models/vgg16.zip"</span></span> val locationToSave = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> File(savePath) <span class="hljs-comment"><span class="hljs-comment">//      DL4J,       ModelSerializer.writeModel(vgg16, locationToSave, saveUpdater = true)</span></span></code> </pre> <br>  Now our model is in a format that is convenient to use in DL4J.  We investigate the built-in model summary. <br><br><pre> <code class="java hljs">val modelFile = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> File(<span class="hljs-string"><span class="hljs-string">"./dl4j-models/vgg16.zip"</span></span>) val vgg16 = ModelSerializer.restoreComputationGraph(modelFile) println(vgg16.summary())</code> </pre> <br><pre> <code class="hljs cs">VertexName (VertexType) nIn,<span class="hljs-function"><span class="hljs-function">nOut TotalParams ParamsShape Vertex Inputs </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">input_2</span></span></span><span class="hljs-function"> (</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">InputVertex</span></span></span><span class="hljs-function">) -,- - - - </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">block1_conv1</span></span></span><span class="hljs-function"> (</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">ConvolutionLayer</span></span></span><span class="hljs-function">) 3,64 1792 b:</span></span>{<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">64</span></span>}, W:{<span class="hljs-number"><span class="hljs-number">64</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>} [input_2] block1_conv2 (ConvolutionLayer) <span class="hljs-number"><span class="hljs-number">64</span></span>,<span class="hljs-number"><span class="hljs-number">64</span></span> <span class="hljs-number"><span class="hljs-number">36928</span></span> b:{<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">64</span></span>}, W:{<span class="hljs-number"><span class="hljs-number">64</span></span>,<span class="hljs-number"><span class="hljs-number">64</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>} [block1_conv1] block1_pool (SubsamplingLayer) -,- <span class="hljs-number"><span class="hljs-number">0</span></span> - [block1_conv2] block2_conv1 (ConvolutionLayer) <span class="hljs-number"><span class="hljs-number">64</span></span>,<span class="hljs-number"><span class="hljs-number">128</span></span> <span class="hljs-number"><span class="hljs-number">73856</span></span> b:{<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">128</span></span>}, W:{<span class="hljs-number"><span class="hljs-number">128</span></span>,<span class="hljs-number"><span class="hljs-number">64</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>} [block1_pool] block2_conv2 (ConvolutionLayer) <span class="hljs-number"><span class="hljs-number">128</span></span>,<span class="hljs-number"><span class="hljs-number">128</span></span> <span class="hljs-number"><span class="hljs-number">147584</span></span> b:{<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">128</span></span>}, W:{<span class="hljs-number"><span class="hljs-number">128</span></span>,<span class="hljs-number"><span class="hljs-number">128</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>} [block2_conv1] block2_pool (SubsamplingLayer) -,- <span class="hljs-number"><span class="hljs-number">0</span></span> - [block2_conv2] block3_conv1 (ConvolutionLayer) <span class="hljs-number"><span class="hljs-number">128</span></span>,<span class="hljs-number"><span class="hljs-number">256</span></span> <span class="hljs-number"><span class="hljs-number">295168</span></span> b:{<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">256</span></span>}, W:{<span class="hljs-number"><span class="hljs-number">256</span></span>,<span class="hljs-number"><span class="hljs-number">128</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>} [block2_pool] block3_conv2 (ConvolutionLayer) <span class="hljs-number"><span class="hljs-number">256</span></span>,<span class="hljs-number"><span class="hljs-number">256</span></span> <span class="hljs-number"><span class="hljs-number">590080</span></span> b:{<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">256</span></span>}, W:{<span class="hljs-number"><span class="hljs-number">256</span></span>,<span class="hljs-number"><span class="hljs-number">256</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>} [block3_conv1] block3_conv3 (ConvolutionLayer) <span class="hljs-number"><span class="hljs-number">256</span></span>,<span class="hljs-number"><span class="hljs-number">256</span></span> <span class="hljs-number"><span class="hljs-number">590080</span></span> b:{<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">256</span></span>}, W:{<span class="hljs-number"><span class="hljs-number">256</span></span>,<span class="hljs-number"><span class="hljs-number">256</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>} [block3_conv2] block3_pool (SubsamplingLayer) -,- <span class="hljs-number"><span class="hljs-number">0</span></span> - [block3_conv3] block4_conv1 (ConvolutionLayer) <span class="hljs-number"><span class="hljs-number">256</span></span>,<span class="hljs-number"><span class="hljs-number">512</span></span> <span class="hljs-number"><span class="hljs-number">1180160</span></span> b:{<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">512</span></span>}, W:{<span class="hljs-number"><span class="hljs-number">512</span></span>,<span class="hljs-number"><span class="hljs-number">256</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>} [block3_pool] block4_conv2 (ConvolutionLayer) <span class="hljs-number"><span class="hljs-number">512</span></span>,<span class="hljs-number"><span class="hljs-number">512</span></span> <span class="hljs-number"><span class="hljs-number">2359808</span></span> b:{<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">512</span></span>}, W:{<span class="hljs-number"><span class="hljs-number">512</span></span>,<span class="hljs-number"><span class="hljs-number">512</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>} [block4_conv1] block4_conv3 (ConvolutionLayer) <span class="hljs-number"><span class="hljs-number">512</span></span>,<span class="hljs-number"><span class="hljs-number">512</span></span> <span class="hljs-number"><span class="hljs-number">2359808</span></span> b:{<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">512</span></span>}, W:{<span class="hljs-number"><span class="hljs-number">512</span></span>,<span class="hljs-number"><span class="hljs-number">512</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>} [block4_conv2] block4_pool (SubsamplingLayer) -,- <span class="hljs-number"><span class="hljs-number">0</span></span> - [block4_conv3] block5_conv1 (ConvolutionLayer) <span class="hljs-number"><span class="hljs-number">512</span></span>,<span class="hljs-number"><span class="hljs-number">512</span></span> <span class="hljs-number"><span class="hljs-number">2359808</span></span> b:{<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">512</span></span>}, W:{<span class="hljs-number"><span class="hljs-number">512</span></span>,<span class="hljs-number"><span class="hljs-number">512</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>} [block4_pool] block5_conv2 (ConvolutionLayer) <span class="hljs-number"><span class="hljs-number">512</span></span>,<span class="hljs-number"><span class="hljs-number">512</span></span> <span class="hljs-number"><span class="hljs-number">2359808</span></span> b:{<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">512</span></span>}, W:{<span class="hljs-number"><span class="hljs-number">512</span></span>,<span class="hljs-number"><span class="hljs-number">512</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>} [block5_conv1] block5_conv3 (ConvolutionLayer) <span class="hljs-number"><span class="hljs-number">512</span></span>,<span class="hljs-number"><span class="hljs-number">512</span></span> <span class="hljs-number"><span class="hljs-number">2359808</span></span> b:{<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">512</span></span>}, W:{<span class="hljs-number"><span class="hljs-number">512</span></span>,<span class="hljs-number"><span class="hljs-number">512</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>} [block5_conv2] block5_pool (SubsamplingLayer) -,- <span class="hljs-number"><span class="hljs-number">0</span></span> - [block5_conv3] flatten (PreprocessorVertex) -,- - - [block5_pool] fc1 (DenseLayer) <span class="hljs-number"><span class="hljs-number">25088</span></span>,<span class="hljs-number"><span class="hljs-number">4096</span></span> <span class="hljs-number"><span class="hljs-number">102764544</span></span> b:{<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">4096</span></span>}, W:{<span class="hljs-number"><span class="hljs-number">25088</span></span>,<span class="hljs-number"><span class="hljs-number">4096</span></span>} [flatten] fc2 (DenseLayer) <span class="hljs-number"><span class="hljs-number">4096</span></span>,<span class="hljs-number"><span class="hljs-number">4096</span></span> <span class="hljs-number"><span class="hljs-number">16781312</span></span> b:{<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">4096</span></span>}, W:{<span class="hljs-number"><span class="hljs-number">4096</span></span>,<span class="hljs-number"><span class="hljs-number">4096</span></span>} [fc1] predictions (DenseLayer) <span class="hljs-number"><span class="hljs-number">4096</span></span>,<span class="hljs-number"><span class="hljs-number">1000</span></span> <span class="hljs-number"><span class="hljs-number">4097000</span></span> b:{<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">1000</span></span>}, W:{<span class="hljs-number"><span class="hljs-number">4096</span></span>,<span class="hljs-number"><span class="hljs-number">1000</span></span>} [fc2] Total Parameters: <span class="hljs-number"><span class="hljs-number">138357544</span></span> Trainable Parameters: <span class="hljs-number"><span class="hljs-number">138357544</span></span> Frozen Parameters: <span class="hljs-number"><span class="hljs-number">0</span></span></code> </pre><br>  Here is a beautiful and concise general description of the model;  however, it is very useful to show it in the form of a picture. <br><br><img src="https://habrastorage.org/webt/4y/te/50/4yte50oibhalri1qpvcyaff0ksk.png"><br><br>  In VGG16, there are 13 convolutional layers interspersed with layers in which the maximum value is selected (max-pooling);  This is done to compress the image.  Weight values ‚Äã‚Äãin the convolutional layer are, in essence, filters that learn to isolate visual features from the image, and layers with the choice of the maximum value ‚Äúcompress‚Äù the image ‚Äî and therefore the filters in the next convolutional layers will ‚Äúsee‚Äù the image more fully.  Therefore, the result of the work of convolutional layers is the <a href="https://arxiv.org/pdf/1311.2901.pdf">most common visual signs of the</a> input image, for example, ‚Äúis there a face in the picture?‚Äù Or ‚Äúa sunset in the picture?‚Äù.  The result of the work of convolutional layers is supplied to a series of three fully connected (dense) layers capable of learning the nonlinear interconnections between these visual characteristics and output information. <br><br>  This is one of the main properties of convolutional networks, which ensures the transfer of learning.  The point is that you can skip the new information about the images through the already trained VGG16 network and isolate the signs from each image.  Such an operation is called ‚Äúcharacterization‚Äù (featurizing): after extracting the signs, it remains to work only with the last parts of the VGG16 network, and this task is much more advanced both from a computational point of view and in terms of complexity. <br><br>  <b>Characterization of images with VGG16</b> <br><br>  The data set can be downloaded from the <a href="http://www.vision.caltech.edu/Image_Datasets/Caltech256/">Caltech-256</a> site, where it is divided into fragments for training / checking / testing and stored in HDFS ( <a href="https://github.com/sethah/dl4j-demo">detailed instructions</a> ).  When this is done, we take the entire set of images and pass it through all the convolutional layers, as well as through the first dense layer, and save the output in HDFS. <br><br>  For some reason, it is desirable to do this and, to understand the importance of this approach, we note one general rule regarding convolution networks: most of the computer time and computational power is spent in convolutional layers, and most of the parameters (weights) in the VGG16 network are localized in dense layers.  Due to the transfer of training, you can use pre-trained convolutional layers to extract features of the input images, so you have to retrain only a small part of the original model - dense layers.  The rest remains static or "frozen."  You can save a lot of time and computing power by transferring the raw images only once through the frozen part of the network, and then not returning to this part at all. <br><br>  First we extract the part of the network that will be used at the characterization stage.  The deeplearning4j library has a built-in API for transferring training, which can be used for this purpose.  To separate the model after the first fully connected layer ‚Äúfc1‚Äù, we first obtain a list of layers before and after separation. <br><br><pre> <code class="java hljs">val modelFile = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> File(<span class="hljs-string"><span class="hljs-string">"./dl4j-models/vgg16.zip"</span></span>) val vgg16 = ModelSerializer.restoreComputationGraph(modelFile) val (frozenLayers: Array[Layer], unfrozenLayers: Array[Layer]) = { vgg16.getLayers.splitAt(vgg16.getLayers.map(_.conf().getLayer.getLayerName).indexOf(<span class="hljs-string"><span class="hljs-string">"fc2"</span></span>) + <span class="hljs-number"><span class="hljs-number">1</span></span>) }</code> </pre> <br>  Now we take the org.deeplearning4j.nn.transferlearning package to extract only layers up to "fc2" inclusive. <br><br><img src="https://habrastorage.org/webt/nf/yc/s9/nfycs9sdocauf2i7jyrab4og5pi.png"><br><br><pre> <code class="java hljs">val builder = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> TransferLearning.GraphBuilder(model) .setFeatureExtractor(frozenLayers.last.conf().getLayer.getLayerName) <span class="hljs-comment"><span class="hljs-comment">//    ,     ,     unfrozenLayers.foreach { layer =&gt; builder.removeVertexAndConnections(layer.conf().getLayer.getLayerName) } builder.setOutputs(frozenLayers.last.conf().getLayer.getLayerName) val frozenGraph = builder.build()</span></span></code> </pre> <br>  Next, you need to go to actually read image files, which are stored in HDFS in JPEG format, each separately.  Images are arranged in subdirectories, and each subdirectory contains a set of pictures belonging to a particular class.  Let's start uploading images saved in HDFS using sc.binaryFiles and use image processing tools from the DataVec library (native ETL library for DL4J) and using them to convert images into INDArray arrays, which are native tensor representations consumed by DL4J (full code <a href="https://github.com/sethah/dl4j-demo/blob/master/dl4j-cnn/src/main/scala/com/cloudera/datascience/dl4j/cnn/examples/caltech256/SaveFeaturizedData.scala">here</a> ).  Finally, we use a frozen graph to issue predictions for input images: in essence, we pass them through expensive layers that will be discarded. <br><br><pre> <code class="java hljs">val finalOutput = Utils.getPredictions(data, frozenGraph, sc) val df = finalOutput.map { ds =&gt; (Nd4j.toByteArray(ds.getFeatureMatrix), Nd4j.toByteArray(ds.getLabels)) }.toDF() df.write.parquet(<span class="hljs-string"><span class="hljs-string">"hdfs:///user/leon/featurizedPredictions/train"</span></span>)</code> </pre> <br>  Now the new data set is saved in HDFS, and with its help you can start building models with the transfer of training.  Such data with signs allows you to radically reduce the duration of training and reduce the complexity of calculations.  In the above example, the new data consists of 30,607 vectors of 4096 length. <br><br>  <b>Replacing the VGG16 prediction layer</b> <br><br>  The VGG16 model was trained on the ImageNet dataset, which is a set of classified objects, divided into 1000 different categories.  The last layer in a typical neural network to classify images, the so-called "output layer", on the basis of the input generates probabilities for each object contained in the data set.  Therefore, such input can be considered as a generalized picture of the visual features of an image containing useful information about what an object is and what it contains.  It is intuitively clear that the same ‚Äúgeneralized‚Äù input entering the last layer should also be useful for generating a different set of probabilities, optimized for recognizing objects in the Caltech-256 data set. <br><br>  After characterizing the data using the principle described above, we define a new model that occupies the 4096-dimensional inference in the fc2 layer and generates 257 probabilities for the Caltech256 data set. <br><br><pre> <code class="java hljs">val conf = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> NeuralNetConfiguration.Builder() .seed(<span class="hljs-number"><span class="hljs-number">42</span></span>) .optimizationAlgo(OptimizationAlgorithm.STOCHASTIC_GRADIENT_DESCENT) .iterations(<span class="hljs-number"><span class="hljs-number">1</span></span>) .activation(Activation.SOFTMAX) .weightInit(WeightInit.XAVIER) .learningRate(<span class="hljs-number"><span class="hljs-number">0.01</span></span>) .updater(Updater.NESTEROVS) .momentum(<span class="hljs-number"><span class="hljs-number">0.8</span></span>) .graphBuilder() .addInputs(<span class="hljs-string"><span class="hljs-string">"in"</span></span>) .addLayer(<span class="hljs-string"><span class="hljs-string">"layer0"</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> OutputLayer.Builder(LossFunction.NEGATIVELOGLIKELIHOOD) .activation(Activation.SOFTMAX) .nIn(<span class="hljs-number"><span class="hljs-number">4096</span></span>) .nOut(<span class="hljs-number"><span class="hljs-number">257</span></span>) .build(), <span class="hljs-string"><span class="hljs-string">"in"</span></span>) .setOutputs(<span class="hljs-string"><span class="hljs-string">"layer0"</span></span>) .backprop(<span class="hljs-keyword"><span class="hljs-keyword">true</span></span>) .build() val model = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> ComputationGraph(conf)</code> </pre> <br>  Here's what it looks like. <br><br><img src="https://habrastorage.org/webt/_r/2l/9m/_r2l9m-exut5dpy6y0ounan1ije.png"><br><br>  So, now this model can be trained with the help of heavy calculations DL4J and scaled with Spark.  For training in Spark, we use the <code>ParameterAveragingTrainingMaster</code> interface in DL4J ‚Äî a concise API for distributed training of models in Spark.  The name for this interface was chosen well, since distributed learning in it is achieved using the SGD algorithm on each of the working cores in the Spark cluster and averaging the various models studied on each core using RDD-aggregation operations. <br><br><pre> <code class="java hljs">val tm = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> ParameterAveragingTrainingMaster.Builder(<span class="hljs-number"><span class="hljs-number">1</span></span>) .averagingFrequency(<span class="hljs-number"><span class="hljs-number">5</span></span>) .workerPrefetchNumBatches(<span class="hljs-number"><span class="hljs-number">2</span></span>) .batchSizePerWorker(<span class="hljs-number"><span class="hljs-number">32</span></span>) .rddTrainingApproach(RDDTrainingApproach.Export) .build() val model = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> SparkComputationGraph(sc, graph, tm)</code> </pre> <br>  Now we teach <code>SparkComputationGraph</code> for a given number of epochs and monitor the learning statistics to see how progress is progressing. <br><br><pre> <code class="java hljs">model.setListeners(<span class="hljs-keyword"><span class="hljs-keyword">new</span></span> ScoreIterationListener(<span class="hljs-number"><span class="hljs-number">1</span></span>)) (<span class="hljs-number"><span class="hljs-number">1</span></span> to param.numEpochs).foreach { i =&gt; logger4j.info(s<span class="hljs-string"><span class="hljs-string">"epoch $i starting"</span></span>) model.fit(trainRDD) <span class="hljs-comment"><span class="hljs-comment">//     ¬´¬ª        5  if (i % 5 == 0) { logger4j.info(s"Train score: ${model.calculateScore(trainRDD, true)}") logger4j.info(s"Train stats:\n${Utils.evaluate(model.getNetwork, trainRDD, 16)}") if (validRDD.isDefined) { logger4j.info(s"Validation stats:\n${Utils.evaluate(model.getNetwork, validRDD.get, 16)}") logger4j.info(s"Validation score: ${model.calculateScore(validRDD.get, true)}") } } }</span></span></code> </pre> <br>  Finally, we start the training task with the help of spark submit and through the <a href="https://github.com/sethah/dl4j-demo/blob/master/dl4j-ui/src/main/scala/com/cloudera/datascience/dl4j/ui/RunUIServer.scala">graphic web interface DL4J we</a> monitor progress and diagnose problems.  Below we see the ‚Äúscore‚Äù of the model ‚Äî this indicator in this case means the negative log likelihood of the mini-block, the smaller the better.  On the graph, it is depicted in relation to the "raw" values ‚Äã‚Äã(numbers) and a smoothed trend line.  Keep in mind that when training with Spark, the ‚Äúaccount‚Äù of each mini-block actually corresponds to only one core in a Spark cluster, and we may have thousands of such cores.  Ideally, the score on one core should match the count on the other, but if the data is not randomly randomized, then these indicators in the cluster can differ dramatically from core to core. <br><br><img src="https://habrastorage.org/webt/r9/fo/oc/r9foochgambaknqq_0tiwql5_1s.png"><br><br>  Apparently, this time, the model learns much faster, even with a lower coefficient of learning speed, since the signs used this time have a much higher predictive value than the ImageNet probabilities. <br><br><pre> <code class="hljs pgsql"><span class="hljs-number"><span class="hljs-number">17</span></span>/<span class="hljs-number"><span class="hljs-number">05</span></span>/<span class="hljs-number"><span class="hljs-number">12</span></span> <span class="hljs-number"><span class="hljs-number">16</span></span>:<span class="hljs-number"><span class="hljs-number">06</span></span>:<span class="hljs-number"><span class="hljs-number">12</span></span> <span class="hljs-keyword"><span class="hljs-keyword">INFO</span></span> caltech256.TrainFeaturized$: Train score: <span class="hljs-number"><span class="hljs-number">0.6663876733861492</span></span> <span class="hljs-number"><span class="hljs-number">17</span></span>/<span class="hljs-number"><span class="hljs-number">05</span></span>/<span class="hljs-number"><span class="hljs-number">12</span></span> <span class="hljs-number"><span class="hljs-number">16</span></span>:<span class="hljs-number"><span class="hljs-number">06</span></span>:<span class="hljs-number"><span class="hljs-number">39</span></span> <span class="hljs-keyword"><span class="hljs-keyword">INFO</span></span> caltech256.TrainFeaturized$: Train stats: Accuracy: <span class="hljs-number"><span class="hljs-number">0.8877570632327504</span></span> <span class="hljs-type"><span class="hljs-type">Precision</span></span>: <span class="hljs-number"><span class="hljs-number">0.8937314411403346</span></span> Recall: <span class="hljs-number"><span class="hljs-number">0.876864905154427</span></span> <span class="hljs-number"><span class="hljs-number">17</span></span>/<span class="hljs-number"><span class="hljs-number">05</span></span>/<span class="hljs-number"><span class="hljs-number">12</span></span> <span class="hljs-number"><span class="hljs-number">16</span></span>:<span class="hljs-number"><span class="hljs-number">07</span></span>:<span class="hljs-number"><span class="hljs-number">17</span></span> <span class="hljs-keyword"><span class="hljs-keyword">INFO</span></span> caltech256.TrainFeaturized$: Validation stats: Accuracy: <span class="hljs-number"><span class="hljs-number">0.7625918867410836</span></span> <span class="hljs-type"><span class="hljs-type">Precision</span></span>: <span class="hljs-number"><span class="hljs-number">0.7703367671469078</span></span> Recall: <span class="hljs-number"><span class="hljs-number">0.7383574179140013</span></span> <span class="hljs-number"><span class="hljs-number">17</span></span>/<span class="hljs-number"><span class="hljs-number">05</span></span>/<span class="hljs-number"><span class="hljs-number">12</span></span> <span class="hljs-number"><span class="hljs-number">16</span></span>:<span class="hljs-number"><span class="hljs-number">07</span></span>:<span class="hljs-number"><span class="hljs-number">26</span></span> <span class="hljs-keyword"><span class="hljs-keyword">INFO</span></span> caltech256.TrainFeaturized$: Validation score: <span class="hljs-number"><span class="hljs-number">1.08481537405921</span></span></code> </pre> <br>  It seems that in this case the model has been retrained, since the learning accuracy is 88.8%, and the verification accuracy is only 76.3%.  To make sure that the model does not retrain on the test set, we will evaluate it on a blind test set. <br><br> <code>Accuracy: 0.7530218882718066 <br> Precision: 0.7613121478786196 <br> Recall: 0.7286152891276695</code> <br> <br>  Although the accuracy has slightly decreased, it still surpasses the cutting-edge results for this data set, and in fact we used a simple architecture for deep learning, built on the basis of a ready-made Hadoop architecture and cheap CPUs!  Yes, not a titanic achievement, however, this result still helps to test what can be achieved with the help of deep learning in Java. <br><br>  <b>findings</b> <br><br>  Although the deeplearning4j library is just one of many tools for deep learning, it is equipped with native integration with Apache Spark and written in Java, therefore it fits particularly well with the Hadoop ecosystem.  Since access to information in enterprises is universally provided through Hadoop, and its processing takes place in Spark, the library deeplearning4j allows you to speed up the deployment and reduce costs, and you can immediately extract such information obtained by deep learning.  The library uses ND4J for complex computations - another well-optimized library that interacts well with low-cost CPUs, but also supports GPU operations when it comes to dramatically increasing performance.  Deeplearning4j is a full-featured library for deep learning, it has a complete set of tools to handle data from consumption to deployment.  With this library, you can solve all sorts of tasks: image and video recognition, audio processing, natural language processing, creation of recommender systems, etc. </div><p>Source: <a href="https://habr.com/ru/post/344824/">https://habr.com/ru/post/344824/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../344812/index.html">What was said about JavaScript in 1995</a></li>
<li><a href="../344814/index.html">Bezier and Picasso curves</a></li>
<li><a href="../344816/index.html">Challenges with ZeroNights 2017: Become the king of captcha</a></li>
<li><a href="../344818/index.html">Load testing on the Gatling framework</a></li>
<li><a href="../344822/index.html">Dirty tricks and RAM</a></li>
<li><a href="../344826/index.html">Microkernel vs. monolith and the "triumph" of MINIX</a></li>
<li><a href="../344830/index.html">Quantum computing: annealing with switches and other fun</a></li>
<li><a href="../344832/index.html">Stay lazy with angular / cli</a></li>
<li><a href="../344834/index.html">In France, bitcoins are not money</a></li>
<li><a href="../344836/index.html">Lack of RAM in Linux on a working PC: optimization and actions when it hangs</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>