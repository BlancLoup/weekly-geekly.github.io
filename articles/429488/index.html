<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>96-core supercomputer on NanoPi Fire3 single board</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Creating a high-performance cluster with 12 NanoPi-Fire3 nodes for less than ¬£ 100 (¬£ 550, including twelve Fire3) 

 My last cluster on the Raspberry...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>96-core supercomputer on NanoPi Fire3 single board</h1><div class="post__text post__text-html js-mediator-article">  <b>Creating a high-performance cluster with 12 NanoPi-Fire3 nodes for less than ¬£ 100 (¬£ 550, including twelve Fire3)</b> <br><br>  My last cluster on the Raspberry Pi 3 last year interested the public a lot, so I‚Äôll try to do similar projects on other great single-board computers that are on the market.  FriendlyARM from China very generously sent me 12 of its last <a href="http://www.friendlyarm.com/index.php%3Froute%3Dproduct/product%26product_id%3D206">64-bit ARM NanoPi-Fire3 boards</a> , each of which has <b>eight</b> nuclear ARM A53 SoC operating at 1.4 GHz with Gigabit Ethernet. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/f03/00c/337/f0300c3373e6d530f653bb180c64ac0f.jpg" width="500"></div><br><a name="habracut"></a><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/027/40f/8ae/02740f8ae0c376fdd34d19c64cedd991.jpg" width="500"></div>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      The cluster size is 146.4 (w) √ó 151 (h) √ó 216 mm (d), and weight is 1.67 kg. <br><br><h1>  Software to run in a cluster? </h1><br>  or ... <b>What is it for ??</b> <br><br>  Clusters are often used for resource-intensive tasks (medical research, weather modeling, AI / deep learning, mining cryptocurrency) and / or high availability services (redundant nodes are involved in case of hardware failures).  This cluster is, of course, slow from the point of view of modern supercomputers, but a small portable system is ideal for learning or developing distributed software, which can then be transferred to much more powerful systems. <br><br>  I plan to write several articles to evaluate this cluster for mining and deep learning. <br><br>  <a href="https://docs.docker.com/engine/swarm/">Docker Swarm</a> or <a href="https://kubernetes.io/">Kubernetes</a> seem like excellent options for managing a cluster, although I haven't tried them yet. <br><br><h1>  NanoPi-Fire3 versus Raspberry Pi 3 </h1><br>  The NanoPi-Fire3 board is much more advanced compared to the Raspberry Pi 3, both in terms of performance and in terms of functions, in a smaller form factor, while at about the same price: <br><br><table><tbody><tr><th></th><th>  NanoPi-Fire3 </th><th>  Raspberry Pi 3 model B </th></tr><tr><td>  <abbr title="System-on-a-chip">SoC</abbr> </td><td>  8-core ARM A53 <br>  S5P6818 @ 1.4 GHz </td><td>  4-core ARM A53 <br>  BCM2837 @ 1.2 GHz </td></tr><tr><td>  Memory </td><td>  1 GB DDR3 </td><td>  1 GB DDR2 </td></tr><tr><td>  GPU </td><td>  Mali-400 MP4 <br>  500 MHz? </td><td>  Broadcom VideoCore IV <br>  400 MHz? </td></tr><tr><td>  Network </td><td>  1000 Mbps </td><td>  100 Mbps </td></tr><tr><td>  WiFi </td><td>  not </td><td>  802.11bgn </td></tr><tr><td>  Bluetooth </td><td>  not </td><td>  4.1 + BLE </td></tr><tr><td>  Storage </td><td>  MicroSD card </td><td>  MicroSD card </td></tr><tr><td>  USB </td><td>  1 connector <br>  1 microUSB </td><td>  4 connectors </td></tr><tr><td>  Video </td><td>  Micro HDMI 1.4a, RGB-LCD </td><td>  HDMI, DSI </td></tr><tr><td>  Camera interface </td><td>  DVP </td><td>  CSI </td></tr><tr><td>  Audio </td><td>  not </td><td>  3.5 mm </td></tr><tr><td>  The size </td><td>  75 √ó 40 mm </td><td>  85 √ó 56 mm </td></tr><tr><td>  Nutrition </td><td>  1.2 ‚Üí 3.6 W <br>  2A max. MicroUSB </td><td>  1.2 ‚Üí 2.1 W <br>  2.5A max. MicroUSB </td></tr><tr><td>  Release </td><td>  Q4 2017 </td><td>  Q1 2016 </td></tr><tr><td>  Price (UK) </td><td>  ¬£ 34.30 <sup>1</sup> </td><td>  ¬£ 33.59 </td></tr><tr><td colspan="3">  <sup>1</sup> $ 35 for Fire3 + $ 5 shipping + 20% VAT + 0% import duty = ¬£ 34.30 </td></tr></tbody></table><img src="https://habrastorage.org/getpro/habr/post_images/d65/928/fa7/d65928fa7fffe412e0c5dbf15bdb1ebd.jpg"><br><img src="https://habrastorage.org/getpro/habr/post_images/7b4/61b/954/7b461b9544c2fe47cd117d1bb3ed1b1f.jpg"><h1>  Benchmarks </h1><br><h3>  CPU </h3><br>  Most modern computers have multi-core processors capable of performing two or more tasks at the same time.  These can be different applications (for example, a web server that processes three web pages and a database), or one task divided into several streams for maximum speed (for example, a ray tracer, file compression, etc.).  This test from the <code>hpcc</code> package uses all the CPU cores, effectively testing the overall performance of the processor in floating point operations. <br><br><img src="https://habrastorage.org/webt/va/bl/i4/vabli4jp7wxz7hoiar0od_k8tly.png"><br>  <i><font color="gray">Linpack TPP v1.4.1 (linear equation solver).</font></i>  <i><font color="gray">Number of MFLOPS (millions of floating point operations per second)</font></i> <br><br>  On the Fire3 board, there are twice as many cores, a higher clock frequency and faster memory: as a result, the result is <b>6.6 times</b> higher than on Pi 3. <br><br>  60,000 MFLOPS - not too much by current performance standards, but as early as 2000 this cluster of 12 Fire3 would have entered the <b>top 250 fastest supercomputers</b> in the world (!).  A cluster of five Fire3 runs 8.2 times faster than a Pi 3 cluster of the same size, which is explained by additional CPU cores, faster memory and a much faster network for exchanging data between nodes. <br><br>  The 16-core supercomputer Cray C90, released in 1992, produced 10,780 MFLOPS, but cost $ 30.5 million, weighed 10.9 tons and needed 495 kW of power! <br><br>  Setting up a cluster for maximum results is a whole art: optimizing the compiler, setting up math libraries, etc.  But we took the estimates from the standard <code>hpcc</code> package in Ubuntu 16.04.4 using the default configuration. <br><br><div class="spoiler">  <b class="spoiler_title">Shell commands for benchmark</b> <div class="spoiler_text"><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># Setup on each node apt install hpcc swapoff -a adduser mpiuser # Controller node setup su - mpiuser cp /usr/share/doc/hpcc/examples/_hpccinf.txt hpccinf.txt # Edit default hpccinf.txt so that NB=80, N=18560, P=8 and Q=12 (P x Q = 96 cores) sed -i "8s/.*/80\tNBs/; 6s/.*/18560\tNs/; 11s/.*/8\tPs/; 12s/.*/12\tQs/" hpccinf.txt # Generate &amp; copy SSH keys across cluster, so controller can run benchmark on all nodes # (use the hostnames or IP addresses for your nodes) ssh-keygen -t rsa nodes=('controller' 'b1' 'b2' 'b3' 'b4' 'b5' 't1' 't2' 't3' 't4' 't5' 't6') for i in ${nodes[@]} do ssh-copy-id "fire3-$i" echo "fire3-$i slots=8" &gt;&gt; mycluster done mpirun -hostfile mycluster --mca plm_rsh_no_tree_spawn 1 hpcc grep -F -e HPL_Tflops -e PTRANS_GBs -e MPIRandomAccess_GUPs -e MPIFFT_Gflops -e StarSTREAM_Triad -e StarDGEMM_Gflops -e CommWorldProcs -e RandomlyOrderedRingBandwidth_GBytes -e RandomlyOrderedRingLatency_usec hpccoutf.txt</span></span></code> </pre> </div></div><br><h3>  Graphics </h3><br>  Both in Fire3 and Pi 3, quad-core GPUs are used for parallel processing of large amounts of data in computer graphics.  Recently, they are also used for specialized computing, such as mining cryptocurrency. <br><br><img src="https://habrastorage.org/webt/zi/8l/ys/zi8lys-ro-ktaaga3gwiieonlei.png"><br>  <i><font color="gray">glmark2-es2 2014.03 (OpenGL ES 2.0).</font></i>  <i><font color="gray">Score the more the better</font></i> <br><br>  The Fire3 board in this test was <b>7.5 times</b> faster than Pi 3. The results of the clusters are simply scaled by the number of nodes. <br><br>  As in the case of the CPU, there are many options for customizing graphics by compiling with different drivers, etc.  In this test, we simply launched the standard glmark2-es2 binary on Ubuntu 16.04.4, using the default configuration.  It is started with the following command: <br><br><pre> <code class="bash hljs">sudo apt install glmark2-es2 glmark2-es2 --off-screen</code> </pre> <br>  The outdated OpenGL render for Pi 3 is rather weak, but if you switch to the experimental Mesa <code>rpi-config</code> render via <code>rpi-config</code> , you will get a performance like Fire3. <br><br>  Most ARM monoplatniks have relatively old GPUs that show very modest performance compared to the latest flagship smartphones, not to mention desktop PCs with expensive high-end graphics cards and huge power supplies.  The Mali-400 MP4 GPU in Fire3 dates back to 2008, and Broadcom VideoCore-IV in Pi 3 is 2010.  There are several more recent single-board <a href="https://www.pine64.org/%3Fpage_id%3D61454">devices</a> , such as <a href="https://www.pine64.org/%3Fpage_id%3D61454">RockPro64</a> from PINE64, with more powerful and new graphics processors (Mali-T860 MP4), while the latest generation Mali-G72 MP18 is installed on the Samsung Galaxy S9. <br><br><h3>  Network </h3><br>  In these tests, the actual data transfer rate in <a href="http://blog.quindorian.org/2014/05/a-guide-to-iperf-network-metering.html/">iPerf between two cards</a> connected to an Ethernet switch 100 / 1000Mpbs is checked. <br><img src="https://habrastorage.org/webt/dt/zr/mc/dtzrmcrbvtakj_hcqtvsmzvmonw.png"><br>  <i><font color="gray">iPerf v2.0.5 (TCP, 1000Mbps Ethernet, between boards), Mbps</font></i> <br><br>  With the default settings, the 1000 Mbps interface on Fire3 shows a huge speed difference of <b>8.5 times</b> compared to the 100 Mbps interface on Pi 3. <br><br><div class="spoiler">  <b class="spoiler_title">Shell commands for benchmark</b> <div class="spoiler_text"><pre> <code class="bash hljs">sudo apt install iperf <span class="hljs-comment"><span class="hljs-comment"># On node1 iperf -s -V # On node2 iperf -c node1 -i 1 -t 20 -V</span></span></code> </pre> </div></div><br>  If you want to increase network performance on the Raspberry Pi (older than the Pi 3 model B +), you can <a href="http://www.jeffgeerling.com/blogs/jeff-geerling/getting-gigabit-networking">install a gigabit USB-Ethernet adapter</a> instead of the standard integrated interface.  It will increase speed by <b>2.8 times</b> , but due to limitations USB2 will still be much slower than the current 1000 Mbps interface.  This network interface is integrated in the newest model Pi 3 B +. <br><br><h3>  Cluster performance per watt </h3><br>  To evaluate performance per watt, I took the Linpack test results higher in MFLOPS and divided it into power consumption.  This indicator is usually used for <a href="https://en.wikipedia.org/wiki/Performance_per_watt">ranking computer systems</a> . <br><br><img src="https://habrastorage.org/webt/fo/m9/q8/fom9q829loarqz0y7g4ayzsesu4.png"><br>  <i><font color="gray">MFLOPS per watt</font></i> <br><br>  The five-node Fire3 cluster is <b>5.8 times</b> more energy efficient than the Pi 3 cluster of the same size, although it consumes more power at 100% load. <br><br>  Watts were measured at 100% load <i>for the entire cluster</i> , including network switches, fans, and power supplies.  WiFi, Bluetooth, HDMI, etc. left in the default settings. <br><br>  The Cray C90 supercomputer mentioned above delivered only 0.02 MFLOPS per watt in 1992. <br><br><h1>  3D case design </h1><br>  I changed the original design of the Raspberry Pi cluster in the free version of <a href="http://www.sketchup.com/">SketchUp</a> , sketching out rough 3D NanoPi-Fire3 templates, network switches, connectors, etc.  I decided not to include ventilation slots / grilles in the model.  The case is exactly the same size as the clusters of five nodes: the task was to accommodate 12 cards, twice as many fans and Ethernet switches, as well as all the cables! <br><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/522/877/c09/522877c095c3993a4f9af83025e4d71a.png"></a> <br><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/a96/b14/5a8/a96b145a83d8ff99a42cbedcf1837c0a.png"></a> <br><br>  <b><a href="">Download the SKP file for SketchUp 2013</a></b> <br><br><h1>  Laser cutting </h1><br>  I use the free <a href="https://inkscape.org/en/">Inkscape</a> program: it prepares 2D models for loading into a laser cutter.  Different colors correspond to different levels of laser power / speed.  First, contours are cut along green lines with openings for ports, bolts and ventilation.  Pink indicates additional cuts to make it easier to remove fragile parts.  Then orange text and lines are etched, and at the very end of the panel are cut out along blue contours. <br><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/d72/5b9/b00/d725b9b00e3c221b184b398737b6c826.png"></a> <br><br>  You can download files for cutting on one sheet of 600 √ó 400 √ó 3 mm, although I myself took either transparent or black sheets for different panels: <br><br><ul><li>  <b><a href="">SVG format sheet</a></b> </li><li>  <b><a href="">DXF sheet</a></b> </li></ul><br>  An optional little detail is a diffuser for a (very bright!) LED panel that can be cut from matte acrylic or simply buy the official Pimoroni diffuser for three pounds. <br><br>  See my <a href="https://climbers.net/sbc/diy-raspberry-pi-3-cluster/">first article for</a> more information on laser cutting and screwless hull assembly systems. <br><br><h1>  Changes in design compared to the Pi 3 cluster </h1><br>  Although the case remained exactly the same size but I made a lot of changes and improvements: <br><br><ul><li>  The design of the <b>horizontal mounting rail</b> has been preserved, but the holes in the Fire3 are M3, for which it is easier to find parts than for M2.5 in Pi.  And the holes are closer to each other, because the overall size of the board is slightly smaller than the Pi.  Is it a little tiring to screw plastic nuts on horizontal rails, and I would like to print some plastic clips on a 3D printer to hold the boards along each rail, or to make thick elastic washers? </li><li>  <b>External power supply instead of internal USB hub</b> : I replaced the internal USB power supply with a fanless AC power supply outside the case.  This frees up space inside (for more Fire3 boards and two fans) and should help with heat dissipation.  Each Fire3 can pull a maximum of 2A, but in reality the cluster will pull much less, without taking into account additional peripherals that hang on USB and GPIO. </li><li>  <b>Two microUSB chains instead of 12 separate cables</b> : there were no suitable ones for sale, so I made my own cables in a ‚Äúchain‚Äù (daisy-chain) using shorter and thicker wires (rating 11A) and soldering 12 microUSB connectors: as a result, the cables occupied very little space inside the case ... <a href="https://habr.com/ru/post/429488/">more</a> </li><li>  <b>Two fans instead of one</b> : I was sure that the more powerful Fire3 boards would need much more active cooling, so I made room on the case for two ultra-quiet 92 mm fans: the rear fan sucks in cold air into the case, and the front fan blows hot air out. </li><li>  <b>Fan Gelid Solutions Silent 9 instead of Nanoxia Deep Silence</b> : I am very pleased with the performance of the fan Nanoxia (and their excellent technical support), but I wanted to try a cheaper option.  Gelid rubber gaskets are thicker than those of Nanoxia, so I increased the diameter of the mounting holes in the case by 0.5 mm. </li><li>  <b>5V direct power supply for fans instead of 5V from GPIO</b> : in previous clusters, the fans were powered from one of the boards with GPIO output.  But taking into account the installation of two 12V fans, I connected a step-up converter with a straight line from the main power supply of the case. </li><li>  <b>Several vents instead of a large number</b> : instead of cutting dozens of vents all over the body (which takes time), I cut out the holes only on the front and rear panels opposite the fans.  Maybe it optimizes the air flow through the case? </li><li>  <b>USB connectors on the case</b> : these two combined USB connectors worked fine in my original cluster, but I never liked them because of the long cables that don't normally bend.  So now I took two separate USB ports with short cables and connectors at an angle, which leaves more space inside the case. </li><li>  <b>No shelf for attaching a USB hub</b> : transferring the power supply to the outside simplified the design of the case, which can now be cut from a single sheet of acrylic 600 √ó 400 mm.  Removing the shelf reduces the rigidity of the case, but if you screw the horizontal mounting rail to the side panels, then the rigidity is normal. </li><li>  <b>Flat LAN cables instead of round ones</b> : I liked the multicolored network cables from the RPi3 project, but it's very difficult to put them inside the case.  Flat cables bend much more easily, which is even more important with such a dense package of boards.  At first I tried the 25 cm cables, but they were too long, but the 15 cm cables left more space inside the case. </li><li>  <b>Blue network cables instead of dull gray</b> : blue <i>really</i> colors the gray design ... plus the FriendlyARM logo blue with green. </li><li>  <b>A gigabit switch instead of a 10-gigabit</b> switch: Fire3 has 1000 Mbps network ports (ten times faster than Pi), so it‚Äôs obvious that the switch should be at least 1000 Mbps.  The ten-gigabit switch will completely eliminate the bottleneck in this location: so ten or more Fire3s will be able to communicate at full speed with the external network.  However, these switches are still expensive (from ¬£ 200) and too cumbersome.  The NETGEAR GS110MX switch looks promising. </li><li>  <b>Board holders 4 mm instead of 6 mm</b> : lowering the switch board, we got a little more space for cable laying and air exchange. </li><li>  <b>Micro HDMI instead of HDMI</b> : on the Fire3 boards, Micro HDMI connectors, so I used the shortest Micro HDMI ‚Üí HDMI cable I could find (50 cm).  Another option was a shorter cable with a separate HDMI ‚Üí Micro HDMI adapter, but it is cumbersome and can block one of the LAN ports. </li><li>  <b>Black plexiglass panels instead of transparent ones</b> : to ‚Äúhide‚Äù two fans, but leave all the electronics in sight from the side and from above.  The black front panel also attracts the gaze to the Unicorn LED panel. </li><li>  <b>LED panel Unicorn pHAT instead of simple LEDs on the boards</b> : there are so many nodes in the cluster that it makes sense to put on the front panel of the case a visual monitoring of the status that shows CPU speed, temperature, disk and network activity for each node ... <a href="https://habr.com/ru/post/429488/">more</a> </li></ul><br>  You can read more about some <a href="https://climbers.net/sbc/diy-raspberry-pi-3-cluster/">design solutions</a> in the original Pi cluster. <br><br><a name="3"></a><h1>  Server Status Indicators with MQTT </h1><br>  I chose the excellent <a href="https://shop.pimoroni.com/products/unicorn-phat">Unicorn pHAT 32x RGB LEDs</a> panel from Pimoroni to create a colorful ‚Äústate display‚Äù of the cluster.  It shows the processor load, temperature, disk and network activity for each node.  These inexpensive boards usually connect directly to the Raspberry Pi pins, but you have to tinker a bit to connect them to another board.  Jeremy Garff‚Äôs rpi_ws281x library uses a very smart low-level PWM / DMA code specific to Raspberry Pi, so I changed the library to use a single SPI pin to control the LEDs, which should work on almost any hardware. <br><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/8da/9c5/221/8da9c52219b3fe23e6c9a17a7d9996dd.jpg"></a> <br><br>  Unicorn pHAT is connected to the board with just three wires: + 5V, GND and SPI0 MOSI (pin 19).  In the next article I will describe in detail how this all works.  The LEDs are very bright, so they look much better behind the diffuser, which is attached to the outside of the case with two to four M2.5 screws.  You can cut your own diffuser from matte acrylic or buy a Pimoroni model with screws for ¬£ 3. <br><br>  The cluster status on the controller node is controlled by the lightweight broker (server) Mosquitto MQTT (Message Queue Telemetry Transport).  Every node every second tells the broker the current processor speed, temperature, network activity, etc. <br><br><h1>  Power, temperature and cooling </h1><br>  Without a load, the entire system of twelve Fire3s, two network switches and two 7V fans consumes only 24 watts, and at full load 55 watts. <br><br>  <b>Do you need radiators?</b>  With double the number of cores, Fire3 SoC generates much more heat than Pi3, so the presence of a radiator is very important.  Fortunately, FriendlyARM supplies a large heatsink with thermal grease that fits securely onto the Fire3 board.  It is much more than radiators for other monoplatniks that I have seen on the market, and perfectly lowers the temperature of the stone, but the fans will still not interfere. <br><br>  The power adapter produces a maximum of 75 watts (1.1 A on Fire3), so external USB devices (for example, hard drives) will most likely need a separate power supply.  Measure the temperature: <br><br><pre> <code class="bash hljs">cat /sys/devices/virtual/thermal/thermal_zone0/temp</code> </pre> <br>  We see that the processor without load heats up to 39 ¬∞ C with cooling from both 12V fans. <br><br>  On a load of 100% with fans, the temperature reaches a stable 58 ¬∞ C: <br><br><pre> <code class="bash hljs">sysbench --<span class="hljs-built_in"><span class="hljs-built_in">test</span></span>=cpu --cpu-max-prime=20000000 --num-threads=8 run &amp;</code> </pre> <br>  Without fans, the temperature will quickly reach 80 ¬∞ C with an automatic lowering of the clock frequency to avoid further overheating.  Processors can work for a long time at this temperature without any problems, but you do not get maximum performance. <br><br>  Exactly the same design of the case should be suitable for the NanoPi Fire2s and Fire2As models, which are not as hot as the Fire3, so that one fan will suffice.  For cooling one Fire3, a much smaller fan will fit, perhaps 40-60 mm. <br><br>  Unusual for single-board devices, Fire3 is able to go to sleep with ultra-low energy consumption (about 5 ŒºA), which makes it thought to put to sleep and remove individual nodes from sleep as needed.  Unfortunately, there is no Wake-on-LAN Ethernet support, only the inflexible <a href="http://wiki.friendlyarm.com/wiki/index.php/NanoPi_Fire3">"wake after X minutes"</a> setting.  However, <u>there is a</u> <code>PWR</code> header on the boards.  Perhaps, it can be connected for remote wake-up from the pin GPIO on the controller? <br><br><h3>  Silent cooling </h3><br>  To cool the cluster, I installed two 92 mm fans in the case.  I searched for the <a href="https://www.quietpc.com/casefans">quietest</a> coolers, rated by <a href="https://www.quietpc.com/casefans">Quietpc.com</a> , and the choice fell on Gelid Silent 9 for ¬£ 5.40. <br><br>  To hear even the slightest fan noise at 5V, you need to bring the ear to it at a distance of 5-7 cm, and the rubber gaskets from the kit perfectly isolate the case from any vibrations.  However, at 12V, the fans are quite audible (20dBA) in a quiet room.  Therefore, I was looking for a voltage that would provide sufficient cooling, but retained silence.  Using an upconverter, I changed the speed of the fans by trying voltage options between 5V and 12V. <br><br><table><tbody><tr><th>  Fans </th><th>  Radiators? </th><th>  Without load </th><th>  100% load </th><th>  Performance </th></tr><tr><td>  Rear 12V, 1500 rpm </td><td>  Yes </td><td>  42 ¬∞ C </td><td>  66 ¬∞ C </td><td>  Ok </td></tr><tr><td>  Rear 9V ,?  rpm </td><td>  Yes </td><td>  44 ¬∞ C </td><td>  71 ¬∞ C </td><td>  Ok </td></tr><tr><td>  Rear 7V ,?  rpm </td><td>  Yes </td><td>  46 ¬∞ C </td><td>  75 ¬∞ C </td><td>  frequency reduction </td></tr><tr><td>  Both 12V, 1500 rpm </td><td>  Yes </td><td>  39 ¬∞ C </td><td>  58 ¬∞ C </td><td>  Ok </td></tr><tr><td>  Both are 7V ,?  rpm </td><td>  Yes </td><td>  40 ¬∞ C </td><td>  65 ¬∞ C </td><td>  Ok </td></tr><tr><td>  Both 5V ,?  rpm </td><td>  Yes </td><td>  46 ¬∞ C </td><td>  77 ¬∞ C </td><td>  frequency reduction </td></tr></tbody></table>  <i>(here are the average temperatures for different nodes, that is, at an average of 71 ¬∞ C, in reality, two boards are close to an emergency frequency reduction).</i> <br><br>  I was surprised that the second fan does not particularly affect the result, and in the end it remains to choose between one fan at 9V or two at 7V, while the second option is a little cooler and quieter.  I assume that the second fan is more important on a larger case and / or a more complex air flow path inside the case? <br><br><a name="1"></a><h3>  Power cables: saga in five parts </h3><br>  The hardest thing was finding a good solution for powering 12 nodes, two Ethernet switches and two fans.  I tried to avoid a lot of soldering and self-manufacturing of cables ... <br><br><ol><li>  Fire3s are powered via microUSB, like Pi, but I didn‚Äôt find a 12-port USB hub at 15A.  I considered a 6-port hub with six two-way microUSB splitters or even two separate 6-port USB hubs.  But the first option did not provide enough power for 12 nodes, and the second took too much space inside the case. </li><li>  With an external ‚Äúbrick‚Äù as an AC source, I tried some standard 8x and 6x splitters.  The cables are designed for CCTV cameras with microUSB ‚Üí DC corner connectors, but they take up a lot of space (bad for the air flow) and are not rated for current, which leads to a voltage drop on each Fire3 board. </li><li>  And if you use steel chassis rails as a conductor for 5V + GND ?!  This is not <i>as</i> insane as it seems: each rail has a low resistance of only 0.5 ohms and must be electrically isolated from the boards.  But I could not figure out how to make a reliable connection from each board to the rail in order to easily disconnect them in case of replacement of the node, etc. </li><li>  <i>New Hope?</i>  Is there any way to power the boards other than soldering 12 homemade microUSB cables?  Fire3 boards have unused points of 5V + GND, such as the UART header.  It would be easier and cheaper to solder a two-pin header to each node and provide power using ready-made two-pin DuPont connectors instead of microUSB.  However, this bold plan had to be abandoned when I realized that after assembling the cluster between the boards there was not enough space to connect or disconnect the two-pin connectors ... and ideally I would not want to solder each board. </li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In the end, I made a homemade chain of power cables (daisy-chain), taking a 0.5 mm thick twin cable (11A, 6 knots in length) and soldering to it the microUSB corner connectors. </font><font style="vertical-align: inherit;">It came out very neatly, and the cable took up very little space inside the case, ensuring excellent air flow. </font><font style="vertical-align: inherit;">Two power chains come out of the case through separate ones through separate sockets in order to limit the maximum current through one DC connector. </font><font style="vertical-align: inherit;">It also means that you can </font></font><u><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">only</font></font></u><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> include the </font><font style="vertical-align: inherit;">upper or lower half of the cluster if you want.</font></font></li></ol><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Both Ethernet switches are also powered by 5V, and round DC connectors are soldered. </font></font><br><br><h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Fire3 cluster build </font></font></h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The build process is similar to the </font></font><a href="https://climbers.net/sbc/40-core-arm-cluster-nanopc-t3/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">40-core ARM cluster on the NanoPC-T3</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , with only more nodes, an additional network switch and a fan. </font><font style="vertical-align: inherit;">Fire3 boards are placed at a distance of 20 mm along the rails with an M3 thread, each fastened with eight nuts. </font><font style="vertical-align: inherit;">For beauty, I pasted the 5V-to-12V up-converter board to the back of the case and added pins to easily turn the fans on and off. </font><font style="vertical-align: inherit;">Some cables are laid and secured using small cable ties. </font><font style="vertical-align: inherit;">The Pimoroni LED display is connected to the controller board through three GPIO pins ... </font><a href="https://habr.com/ru/post/429488/"><font style="vertical-align: inherit;">more</font></a><font style="vertical-align: inherit;"> .</font></font><br><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/06f/8f9/bcf/06f8f9bcf8636cf6e38531cc421ef348.jpg"></a> <br><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/0ca/424/1b7/0ca4241b7cbcc10f3f75dae9cf5f900f.jpg"></a> <br><br><font style="vertical-align: inherit;"></font><br><br><font style="vertical-align: inherit;"></font><a href="https://habr.com/ru/post/429488/"><font style="vertical-align: inherit;"></font></a><font style="vertical-align: inherit;"></font><br><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/f17/544/f25/f17544f25ee11ea956e2cd2c05b9fd90.jpg"></a> <br><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/68f/56f/495/68f56f4953dd1383322bb192935cb996.jpg"></a> <br><br><h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> List of materials </font></font></h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Most parts are from different sellers on AliExpress or eBay, which greatly increases postage. </font><font style="vertical-align: inherit;">If there is sufficient demand for clusters, it is cheaper to purchase parts in bulk.</font></font><br><br><table><tbody><tr><td>  Edimax ES-5800G V3 Gigabit Ethernet (2 .) </td><td> ¬£19,96 </td></tr><tr><td>   15  Cat6 LAN (12 .) </td><td> ¬£6,79 </td></tr><tr><td>   M3 12  (8  10 ) </td><td> ¬£1,45 </td></tr><tr><td>   M3 4  (8  50 .) </td><td> ¬£0,99 </td></tr><tr><td> 5,5/2,1  DC  (2  5 .) </td><td> ¬£1,49 </td></tr><tr><td> 1    + </td><td>  n / a </td></tr><tr><td> 1  2- 0,5    (11A) DC </td><td> ¬£0,99 </td></tr><tr><td>   microUSB   (12  20 .) </td><td> ¬£1,63 </td></tr><tr><td> 5,5/2,1mm  DC     (2  10 .) </td><td> ¬£0,65 </td></tr><tr><td>   10A (4  12) </td><td> ¬£1,29 </td></tr><tr><td>  100  (5  @ 20 )  , 5,5/2,1  +  UK </td><td> ¬£13,51 </td></tr><tr><td>  RJ45   ¬´-¬ª (2 .) </td><td> ¬£1,74 </td></tr><tr><td>   M3 8  (4  5) </td><td> ¬£1,25 </td></tr><tr><td>     M3 150      (8 .) </td><td> ¬£9,20 </td></tr><tr><td>    M3 (120  150) </td><td> ¬£1,73 </td></tr><tr><td> Micro HDMI ¬´¬ª  HDMI ¬´¬ª   50  </td><td> ¬£2,19 </td></tr><tr><td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> USB "mother" to the corner "male" panel mount 25 cm (2 pcs.) </font></font></td><td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ¬£ 2.38 </font></font></td></tr><tr><td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 3 mm transparent plexiglas 600 √ó 400 mm </font></font></td><td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ¬£ 5.32 </font></font></td></tr><tr><td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 5V-to-12V boost converter </font></font></td><td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ¬£ 2.04 </font></font></td></tr><tr><td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Charge for laser cutter </font></font></td><td>  n / a </td></tr><tr><td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 92 mm fan Gelid Silent 9 (2 pcs.) </font></font></td><td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ¬£ 11.65 </font></font></td></tr><tr><td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Polyurethane rubber feet (4 of 10) </font></font></td><td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ¬£ 1.75 </font></font></td></tr><tr><td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Unicorn pHAT 32x RGB LED panel </font></font></td><td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ¬£ 10.00 </font></font></td></tr><tr><td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Black screws M2.5 10 mm (2‚àí4 out of 20) </font></font></td><td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ¬£ 1.02 </font></font></td></tr><tr><td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Small cable ties (10 pcs.) </font></font></td><td>  n / a </td></tr><tr><th><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Total materials </font></font></th><td> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">¬£ 97.73</font></font></b> </td></tr><tr><td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">NanoPi-Fire3 for $ 35 (12 pcs.) </font></font><sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">1</font></font></sup> </td><td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ¬£ 383.38 </font></font></td></tr><tr><td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> SanDisk Industrial class 10 8 GB microSDHC card (12 pcs.) </font></font></td><td><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ¬£ 62.16 </font></font></td></tr><tr><th>  Total </th><td> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">¬£ 543.27</font></font></b> </td></tr></tbody></table> <sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">1</font></font></sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> NanoPi-Fire3 can be imported duty free into the UK, and shipping 12 boards from China costs only $ 29, but with a British VAT of 20%, you get ¬£ 383.38.</font></font><br><br><h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Clusters from other single board computers </font></font></h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> By now I also built: </font></font><br><br><ul><li> <a href="https://climbers.net/sbc/diy-raspberry-pi-3-cluster-2017/">    Raspberry Pi 3</a> </li><li> <a href="https://climbers.net/sbc/40-core-arm-cluster-nanopc-t3/">40- ARM-  NanoPC-T3</a> </li><li> <a href="https://climbers.net/sbc/orange-pi-plus-2e-cluster/">   Orange Pi Plus 2e</a> </li><li> <a href="https://climbers.net/sbc/bargain-pine-a64-cluster/">    PINE A64+</a> </li><li> <a href="https://climbers.net/sbc/clusterhat-review-raspberry-pi-zero/">ClusterHAT   Raspberry Pi Zero</a> </li></ul></div><p>Source: <a href="https://habr.com/ru/post/429488/">https://habr.com/ru/post/429488/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../429474/index.html">The digest of interesting materials for the mobile developer # 274 (November 5 - 11)</a></li>
<li><a href="../429478/index.html">Game Design: A New Approach to Difficulty Levels</a></li>
<li><a href="../429482/index.html">Problems of access to personal data on behalf of all participants in the process</a></li>
<li><a href="../429484/index.html">Again about the interviews, but in overseas countries</a></li>
<li><a href="../429486/index.html">JunOS: Preventing MP-BGP Session Dumping</a></li>
<li><a href="../429490/index.html">Time management without strict schedules, experience in developing a mobile application</a></li>
<li><a href="../429494/index.html">Dagaz: Details</a></li>
<li><a href="../429496/index.html">Self-made laser installation "Lightsaber": as it were. Part 2</a></li>
<li><a href="../429498/index.html">4 causes of procrastination (text)</a></li>
<li><a href="../429500/index.html">"It's time to do business" finally flew</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>