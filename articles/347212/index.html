<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Configuring squid or how not to buy a paid solution</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hello! 

 Often in organizations we use various kinds of proxies, proxies as a component of a software gateway or an independent classical version of ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Configuring squid or how not to buy a paid solution</h1><div class="post__text post__text-html js-mediator-article"><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/e33/bc4/094/e33bc4094bb45332c7eac9eb61d738d9.png" alt="image"></div><br>  Hello! <br><br>  Often in organizations we use various kinds of proxies, proxies as a component of a software gateway or an independent classical version of squid + log analyzer, etc. <br><br>  We tried to implement a solution from Ideco and IKS, eventually settled on squid.  Under the cat history of the path and technical information on setting up the good old squid. <br><a name="habracut"></a><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/ebe/854/cd3/ebe854cd397e4a7c5b182ced385972c4.png" alt="image"></div><br>  Perhaps I'll start with the fact that of course it's strange on habr in 2018 to see an article about configuring squid, but nevertheless, even at the present time, paid products can yield on some items of open source software that somehow forms the basis of a paid product with a beautiful interface . 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      It all started with the fact that the management made it clear that we can afford to buy Internet billing. <br><br>  The requirements are as follows: integration into Windows AD, full management of users from AD, speed shaper, filtering by content type, by site list, the ability to give access to the entire network to local company resources. <br><br>  The company‚Äôs network has over 550 computers.  Most of them need access to internal resources. <br><br>  Everything unfolded in a virtual environment, Hyper-v core virtualization server - Wrong choice, I will explain the reasons at the end of the article. <br><br>  A little about the choice of contestants, UserGate remember him from the time when I started working in IT, the windows application is an old memory - by default it does not fit. <br><br>  Internet Control Server (IKS) - it came to tests.  It was possible to load correctly from 10 only 2 times, noting its excellent instability went further.  By the way, I can not fail to note the humor of the developers, who in the course will understand!  The product is developing, maybe there are already no problems, but the problem has been solved. <br><br>  Ideco - I liked it, an excellent solution, but not only Internet billing is included in the functionality, it is a full gateway with all the buns, for us too much.  Nevertheless, he passed the full test, there were 2 insurmountable obstacles: <br><br>  <b>1.</b> It is impossible to give access to certain resources of the entire network or all users of the domain - by default, not counting such users for the user you want to license. <br><br>  <b>1.1</b> - A considerable price follows from point 1, since  we have a lot of computers in our company that need to connect to internal web services and do not need access to the Internet, we did not plan to buy licenses for the use of internal resources, we also did not plan to plant zoo servers distributing Internet. <br><br>  <b>2. The</b> IP address of the computer is rigidly tied to the username that first authenticated on the proxy, so when you change the employee you need to be in the admin.  panels remove the binding in manual mode, which of course does not meet the requirement to manage everything through AD. <br><br>  By the way, the ideco gateway is available in the free version for up to 40 users and without being tied to AD.  IDECO SELECTA also appeared, or I did not notice its release or it was released after all the tests. <br><br>  After all the stages passed, it was decided to do everything on squid on our own, but with adjustments to our technical requirements, what came out of it read further. <br><br>  Let's start with the fact that there are no correct and complete manuals on the network, there are some parts, but all instructions were frustrated by new releases of squid. <br><br>  We use the ubuntu server, therefore the following information is relevant for this OS and with other OSs can be seriously different. <br><br>  Everything on the command line needs to be done from under sudo, I will not write further before each sudo command. <br><br>  Setting up the OS ubuntu server 16.04: <br><br><pre><code class="bash hljs">apt-get update apt-get upgrade apt-get install mc g++ libecap3-dev libdb-dev libldap2-dev libpam0g-dev libldb-dev libsasl2-dev libkrb5-dev gcc libssl-dev krb5-user libpam-krb5 libkrb5-3 libsasl2-modules-gssapi-mit linux-virtual-lts-xenial linux-tools-virtual-lts-xenial linux-cloud-tools-virtual-lts-xenial linux-image-virtual linux-tools-virtual linux-cloud-tools-virtual squid3</code> </pre> <br>  Since  we use Hyper-v virtualization then we installed the necessary packages. <br><br>  We download the squid from the site, in this post we analyze the version 3.5.26, for other versions it will probably be irrelevant.  UPD in the docker configured 3.5.28 normal flight. <br><br><pre> <code class="bash hljs">wget http://www.squid-cache.org/Versions/v3/3.5/squid-3.5.26.tar.gz</code> </pre><br>  We unpack in home or any other directory. <br><br><pre> <code class="bash hljs">tar xzf squid-3.5.26.tar.gz <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> /home/squid-3.5.26/</code> </pre> <br><pre> <code class="bash hljs">chmod +x configure</code> </pre> <br>  Specify which packages we need, you can delete unnecessary or add something.  Someone seems that there is a lot of excess.  The list is taken from the installed version of the squid and additional packages are added. <br><br><pre> <code class="bash hljs">./configure <span class="hljs-string"><span class="hljs-string">'--enable-ssl'</span></span> <span class="hljs-string"><span class="hljs-string">'--with-openssl=/usr/lib/ssl/'</span></span> <span class="hljs-string"><span class="hljs-string">'--disable-ipv6'</span></span> <span class="hljs-string"><span class="hljs-string">'--enable-ssl-crtd'</span></span> <span class="hljs-string"><span class="hljs-string">'--build=x86_64-linux-gnu'</span></span> <span class="hljs-string"><span class="hljs-string">'--prefix=/usr'</span></span> <span class="hljs-string"><span class="hljs-string">'--includedir=${prefix}/include'</span></span> <span class="hljs-string"><span class="hljs-string">'--mandir=${prefix}/share/man'</span></span> <span class="hljs-string"><span class="hljs-string">'--infodir=${prefix}/share/info'</span></span> <span class="hljs-string"><span class="hljs-string">'--sysconfdir=/etc'</span></span> <span class="hljs-string"><span class="hljs-string">'--localstatedir=/var'</span></span> <span class="hljs-string"><span class="hljs-string">'--libexecdir=${prefix}/lib/squid3'</span></span> <span class="hljs-string"><span class="hljs-string">'--srcdir=.'</span></span> <span class="hljs-string"><span class="hljs-string">'--disable-maintainer-mode'</span></span> <span class="hljs-string"><span class="hljs-string">'--disable-dependency-tracking'</span></span> <span class="hljs-string"><span class="hljs-string">'--disable-silent-rules'</span></span> <span class="hljs-string"><span class="hljs-string">'BUILDCXXFLAGS=-g -O2 -fPIE -fstack-protector-strong -Wformat -Werror=format-security -Wl,-Bsymbolic-functions -fPIE -pie -Wl,-z,relro -Wl,-z,now'</span></span> <span class="hljs-string"><span class="hljs-string">'--datadir=/usr/share/squid'</span></span> <span class="hljs-string"><span class="hljs-string">'--sysconfdir=/etc/squid'</span></span> <span class="hljs-string"><span class="hljs-string">'--libexecdir=/usr/lib/squid'</span></span> <span class="hljs-string"><span class="hljs-string">'--mandir=/usr/share/man'</span></span> <span class="hljs-string"><span class="hljs-string">'--enable-inline'</span></span> <span class="hljs-string"><span class="hljs-string">'--disable-arch-native'</span></span> <span class="hljs-string"><span class="hljs-string">'--enable-async-io=8'</span></span> <span class="hljs-string"><span class="hljs-string">'--enable-storeio=ufs,aufs,diskd,rock'</span></span> <span class="hljs-string"><span class="hljs-string">'--enable-removal-policies=lru,heap'</span></span> <span class="hljs-string"><span class="hljs-string">'--enable-delay-pools'</span></span> <span class="hljs-string"><span class="hljs-string">'--enable-cache-digests'</span></span> <span class="hljs-string"><span class="hljs-string">'--enable-icap-client'</span></span> <span class="hljs-string"><span class="hljs-string">'--enable-follow-x-forwarded-for'</span></span> <span class="hljs-string"><span class="hljs-string">'--enable-auth-basic=DB,fake,getpwnam,LDAP,NCSA,NIS,PAM,POP3,RADIUS,SASL,SMB'</span></span> <span class="hljs-string"><span class="hljs-string">'--enable-auth-digest=file,LDAP'</span></span> <span class="hljs-string"><span class="hljs-string">'--enable-auth-negotiate=kerberos,wrapper'</span></span> <span class="hljs-string"><span class="hljs-string">'--enable-auth-ntlm=fake,smb_lm'</span></span> <span class="hljs-string"><span class="hljs-string">'--enable-external-acl-helpers=file_userip,kerberos_ldap_group,LDAP_group,session,SQL_session,unix_group,wbinfo_group'</span></span> <span class="hljs-string"><span class="hljs-string">'--enable-url-rewrite-helpers=fake'</span></span> <span class="hljs-string"><span class="hljs-string">'--enable-eui'</span></span> <span class="hljs-string"><span class="hljs-string">'--enable-esi'</span></span> <span class="hljs-string"><span class="hljs-string">'--enable-icmp'</span></span> <span class="hljs-string"><span class="hljs-string">'--enable-zph-qos'</span></span> <span class="hljs-string"><span class="hljs-string">'--enable-ecap'</span></span> <span class="hljs-string"><span class="hljs-string">'--disable-translation'</span></span> <span class="hljs-string"><span class="hljs-string">'--with-swapdir=/var/spool/squid'</span></span> <span class="hljs-string"><span class="hljs-string">'--with-logdir=/var/log/squid'</span></span> <span class="hljs-string"><span class="hljs-string">'--with-pidfile=/var/run/squid.pid'</span></span> <span class="hljs-string"><span class="hljs-string">'--with-filedescriptors=65536'</span></span> <span class="hljs-string"><span class="hljs-string">'--with-large-files'</span></span> <span class="hljs-string"><span class="hljs-string">'--with-default-user=proxy'</span></span> <span class="hljs-string"><span class="hljs-string">'--enable-build-info=Ubuntu linux'</span></span> <span class="hljs-string"><span class="hljs-string">'--enable-linux-netfilter'</span></span> <span class="hljs-string"><span class="hljs-string">'build_alias=x86_64-linux-gnu'</span></span> <span class="hljs-string"><span class="hljs-string">'CFLAGS=-g -O2 -fPIE -fstack-protector-strong -Wformat -Werror=format-security -Wall'</span></span> <span class="hljs-string"><span class="hljs-string">'LDFLAGS=-Wl,-Bsymbolic-functions -fPIE -pie -Wl,-z,relro -Wl,-z,now'</span></span> <span class="hljs-string"><span class="hljs-string">'CPPFLAGS=-Wdate-time -D_FORTIFY_SOURCE=2'</span></span> <span class="hljs-string"><span class="hljs-string">'CXXFLAGS=-g -O2 -fPIE -fstack-protector-strong -Wformat -Werror=format-security'</span></span> make make install</code> </pre><br>  --with-openssl = / usr / lib / ssl / - specify the path to openssl, the default path is specified in the ubuntu server. <br>  --disable-ipv6 - turn off ipv6 - read below for reasons. <br>  --enable-ssl-crtd is for bundling the generation of ssl certificates for bump. <br><br>  Perhaps there will be dependencies, you need to install them. <br><br>  By default everything is installed in / etc / squid / <br><br>  Create a folder inside / etc / squid for ssl certificates: <br><br><pre> <code class="bash hljs">mkdir /etc/squid/ssl/private</code> </pre> <br>  Create a certificate: <br>  Go to the directory <br><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> mkdir /etc/squid/ssl/private</code> </pre> <br>  Create a key <br><br><pre> <code class="bash hljs">openssl genrsa -aes256 -out private.pem 2048</code> </pre> <br>  Create a certificate <br><br><pre> <code class="bash hljs">openssl req -x509 -sha256 -nodes -days 3650 -newkey rsa:2048 -keyout private.pem -out public.pem</code> </pre> <br>  Convert certificate to browser-friendly format <br><br><pre> <code class="bash hljs">openssl x509 -outform der -<span class="hljs-keyword"><span class="hljs-keyword">in</span></span> public.pem -out squid3domainlocal.der</code> </pre> <br>  Create a certificate database: <br><br><pre> <code class="bash hljs">/usr/lib/squid/ssl_crtd -c -s /etc/squid/ssl/ssl_db/</code> </pre> <br>  Assign access: <br><br><pre> <code class="bash hljs">chown root:proxy -R /etc/squid/ssl chmod 640 -R /etc/squid/ssl/private chmod 660 -R /etc/squid/ssl/ssl_db</code> </pre><br>  I draw your attention to the fact that the name of the proxy server and the name specified when creating the certificate should be the same.  Format squid3.domain.local. <br><br>  Received squid3domainlocal.der through group policies or manually add them to trusted certificate authorities.  The proxy server in the browser does not specify ip but the full name of the computer, for example, squid3.domain.local. <br><br>  Create a regular user in the domain, let it be squid3. <br><br>  To pass authentication through kerberos, we need the squid3 user keytab for the principal HTTP/squid3.DOMAIN.LOCAL@DOMAIN.LOCAL, with standard login to the domain through net ads, keytab /etc/krb5.keytab is created, but the principal does not indicate http but host .  What makes it impossible to authenticate users through a web browser.  If you put the keytab in /etc/krb5.keytab and then enter the machine itself into the domain, then the keytab will simply be supplemented with new principals. But I draw your attention to the fact that you do not need to install the samba package and enter the machine into the domain, just a generated keytab for user <br><br>  Next, go to the domain controller and execute a simple command: <br><br><pre> <code class="dos hljs">ktpass -princ HTTP/squid3.DOMAIN.LOCAL@DOMAIN.LOCAL mapuser squid3@DOMAIN.LOCAL -crypto AES128-SHA1 -pass XXXXXXXXXXXXXX -ptype KRB5_NT_PRINCIPAL -out c:\krb5.keytab</code> </pre> <br>  We transfer the resulting file to the proxy server and then put it in a convenient location, I choose /etc/krb5.keytab. <br><br>  If you want to make authorization also for the web site, statistics or the company's internal portal, then you need to create a group and include proxy and www-data users there. <br><br>  Create a group: <br><br><pre> <code class="hljs nginx"><span class="hljs-attribute"><span class="hljs-attribute">groupadd</span></span> allowreadkeytab</code> </pre> <br>  Add the required users to the group: <br><br><pre> <code class="bash hljs">adduser proxy allowreadkeytab adduser www-data allowreadkeytab</code> </pre> <br>  Assign owners to krb5.keytab <br><br><pre> <code class="bash hljs">chown root:allowreadkeytab /etc/krb5.keytab</code> </pre> <br>  If there is no need for additional services to give access, then we do not create a group, we simply set the owners and rights: <br><br><pre> <code class="bash hljs">chown root:proxy /etc/krb5.keytab</code> </pre> <br>  Assign access: <br><br><pre> <code class="bash hljs">chmod 640 /etc/krb5.keytab</code> </pre> <br>  We get: <br><br><pre> <code class="bash hljs">-rw-r----- 1 root allowreadkeytab /etc/krb5.keytab</code> </pre> <br>  Or <br><br><pre> <code class="bash hljs">-rw-r----- 1 root proxy /etc/krb5.keytab</code> </pre> <br>  Read and write for root, read only for allowreadkeytab and no access for others. <br><br>  Configuring krb5.conf <br><br><pre> <code class="bash hljs">mcedit /etc/krb5.conf</code> </pre> <br><div class="spoiler">  <b class="spoiler_title">krb5.conf</b> <div class="spoiler_text"><pre> <code class="bash hljs"> [libdefaults] krb4_config = /etc/krb.conf krb4_realms = /etc/krb.realms kdc_timesync = 1 ccache_type = 4 forwardable = <span class="hljs-literal"><span class="hljs-literal">true</span></span> proxiable = <span class="hljs-literal"><span class="hljs-literal">true</span></span> default_tgs_enctypes = aes256-cts-hmac-sha1-96 rc4-hmac des-cbc-crc des-cbc-md5 default_tkt_enctypes = aes256-cts-hmac-sha1-96 rc4-hmac des-cbc-crc des-cbc-md5 permitted_enctypes = aes256-cts-hmac-sha1-96 rc4-hmac des-cbc-crc des-cbc-md5 default_keytab_name = FILE:/etc/krb5.keytab v4_instance_resolve = <span class="hljs-literal"><span class="hljs-literal">false</span></span> v4_name_convert = { host = { rcmd = host ftp = ftp } plain = { something = something-else } } fcc-mit-ticketflags = <span class="hljs-literal"><span class="hljs-literal">true</span></span> [realms] DOMAIN.LOCAL = { kdc = DC1.DOMAIN.LOCAL kdc = DC2.DOMAIN.LOCAL admin_server = DC1.DOMAIN.LOCAL admin_server = DC2.DOMAIN.LOCAL default_domain = DOMAIN.LOCAL } [domain_realm] .domain.local = domain.LOCAL domain.local = domain.LOCAL [login] krb4_convert = <span class="hljs-literal"><span class="hljs-literal">true</span></span> krb4_get_tickets = <span class="hljs-literal"><span class="hljs-literal">false</span></span></code> </pre><br></div></div><br>  We save. <br><br>  I draw your attention to the fact that below squid.conf will not contain all acl and all the rules, they will only be configured according to example 1, full configuration of acl and site access lists, etc.  will be too voluminous.  The following configuration can be considered as requiring modification for your needs. <br><br>  Go to the squid configuration: <br><br><pre> <code class="bash hljs">mcedit /etc/squid/squid.conf acl SSL_ports port 443 acl Safe_ports port 80 acl Safe_ports port 21 acl purge method PURGE acl CONNECT method CONNECT http_access allow purge localhost http_access deny purge http_access deny CONNECT !SSL_ports</code> </pre> <br>  Here an important point, there are sites that raise the connection directly to the "computer", and user authentication is not performed.  As a result, the connection is blocked.  To circumvent this problem, access is given to a specific ip to a specific site. <br><br>  <b>!!!</b>  <b>Important note !!!</b>  The rule must be located above the rules with the authentication of basic, ntlm, kerberos, etc. <br><br><pre> <code class="bash hljs">acl authip src <span class="hljs-string"><span class="hljs-string">"/etc/squid/pools/ip.txt"</span></span> acl domainautip dstdomain <span class="hljs-string"><span class="hljs-string">"/etc/squid/exceptions/domain.txt"</span></span> http_access allow authip domainautip http_reply_access allow authip domainautip</code> </pre> <br>  We define acl: <br><br>  ‚Üí <a href="http://www.squid-cache.org/Doc/config/acl/">Documentation</a> <br><br>  Acl to determine the type of content: <br><br>  acl application_mime rep_mime_type application / octet-stream <br>  acl video_mime rep_mime_type "/etc/squid/ban/mime_type_video.txt" <br><br><div class="spoiler">  <b class="spoiler_title">mime_type_video.txt</b> <div class="spoiler_text">  video / mpeg <br>  video / mp4 <br>  video / ogg <br>  video / quicktime <br>  video / webm <br>  video / x-ms-wmv <br>  video / x-flv <br>  video / 3gpp <br>  video / 3gpp2 <br>  video / avi <br>  video / msvideo <br>  video / x-msvideo <br>  video / x-dv <br>  video / dl <br>  video / x-dl <br>  video / vnd.rn-realvideo <br></div></div><br>  You can also filter some content by url, for this we create acl: <br><br>  acl blockextention urlpath_regex -i "/etc/squid/ban/blockextention.txt" <br><br><div class="spoiler">  <b class="spoiler_title">blockextention.txt</b> <div class="spoiler_text">  \ .snapshot $ <br>  \ .windows $ <br>  \ .mac $ <br>  \ .zfs $ <br>  \ .action $ <br>  \ .apk $ <br>  \ .app $ <br>  \ .bat $ <br>  \ .bin $ <br>  \ .cmd $ <br>  \ .com $ <br>  \ .command $ <br>  \ .cpl $ <br>  \ .csh $ <br>  \ .exe $ <br>  \ .gadget $ <br>  \ .inf1 $ <br>  \ .ins $ <br>  \ .inx $ <br>  \ .ipa $ <br>  \ .isu $ <br>  \ .job $ <br>  \ .ksh $ <br>  \ .msc $ <br>  \ .msi $ <br>  \ .msp $ <br>  \ .mst $ <br>  \ .osx $ <br>  \ .out $ <br>  \ .paf $ <br>  \ .reg $ <br>  \ .rgs $ <br>  \ .run $ <br>  \ .sct $ <br>  \ .sh $ <br>  \ .shb $ <br>  \ .shs $ <br>  \ .u3p $ <br>  \ .vb $ <br>  \ .vbe $ <br>  \ .vbs $ <br>  \ .vbscript $ <br>  \ .workflow $ <br>  \ .ws $ <br>  \ .wsf $ <br>  \ .bin $ <br>  \ .inf $ <br>  \ .com $ <br>  \ .cpp $ <br>  \ .msu $ <br>  \ .pif $ <br>  \ .7z $ <br>  \ .ace $ <br>  \ .arj $ <br>  \ .cab $ <br>  \ .cbr $ <br>  \ .deb $ <br>  \ .gz $ <br>  \ .gzip $ <br>  \ .jar $ <br>  \ .one $ <br>  \ .pak $ <br>  \ .ppt $ <br>  \ .rpm $ <br>  \ .sib $ <br>  \ .sis $ <br>  \ .sisx $ <br>  \ .sit $ <br>  \ .sitx $ <br>  \ .spl $ <br>  \ .tar $ <br>  \ .tar-gz $ <br>  \ .tgz $ <br>  \ .xar $ <br>  \ .zipx $ <br>  \ .asf $ <br>  \ .asm $ <br>  \ .c $ <br>  \ .cfm $ <br>  \ .cgi $ <br>  \ .class $ <br>  \ .cpp $ <br>  \ .cs $ <br>  \ .dot $ <br>  \ .dtd $ <br>  \ .fla $ <br>  \ .ged $ <br>  \ .gv $ <br>  \ .h $ <br>  \ .icl $ <br>  \ .java $ <br>  \ .jse $ <br>  \ .kml $ <br>  \ .lua $ <br>  \ .m $ <br>  \ .mb $ <br>  \ .mdf $ <br>  \ .mod $ <br>  \ .obj $ <br>  \ .pkg $ <br>  \ .pl $ <br>  \ .po $ <br>  \ .pot $ <br>  \ .ps1 $ <br>  \ .pub $ <br>  \ .py $ <br>  \ .rss $ <br>  \ .sln $ <br>  \ .so $ <br>  \ .sql $ <br>  \ .ts $ <br>  \ .vc4 $ <br>  \ .vcproj $ <br>  \ .vc4 $ <br>  \ .vcproj $ <br>  \ .vcxproj $ <br>  \ .wsc $ <br>  \ .xcodeproj $ <br>  \ .xsd $ <br>  \ .torrent $ <br></div></div><br>  There is also a curious acl allowerrorsert, since  we do not allow access to crooked certificate sites by default, I use the allowerrorsert to determine the list of allowed sites with ‚Äúcurved‚Äù ssl.  This is not much lower. <br><br><pre> <code class="bash hljs">acl banksites dstdomain <span class="hljs-string"><span class="hljs-string">"/etc/squid/allow/bank.txt"</span></span> acl allofficesites dstdomain <span class="hljs-string"><span class="hljs-string">"/etc/squid/allow/alloffice.txt"</span></span> acl manual dstdomain <span class="hljs-string"><span class="hljs-string">"/etc/squid/ban/manual.txt"</span></span> acl allowerrorsert dstdomain <span class="hljs-string"><span class="hljs-string">"/etc/squid/exceptions/allowerrorsert.txt"</span></span></code> </pre><br>  It is also possible to control access to sites based on ssl rules, but in my opinion it is more efficient to manage via http_access.  Here is an example acl for use in ssl rules: <br><br><pre> <code class="bash hljs">acl sslproxy ssl::server_name <span class="hljs-string"><span class="hljs-string">"/etc/squid/ban/proxy.txt"</span></span></code> </pre> <br>  Below we will return to this type of acl and their application. <br><br>  Allows you to see in advanced mode requests POST and mime. <br><br><pre> <code class="bash hljs">strip_query_terms off log_mime_hdrs on</code> </pre> <br>  Authentication and authorization of a user in the group active direcory via kerberos: <br><br><pre> <code class="bash hljs">auth_param negotiate program /usr/lib/squid/negotiate_kerberos_auth -s HTTP/squid3.domain.local@DOMAIN.LOCAL auth_param negotiate children 20 startup=10 idle=10 auth_param negotiate keep_alive on</code> </pre><br>  Here it is necessary to stop and disassemble in more detail, children - the maximum number of processes available to start, startup the number of processes that are always running, idle the maximum queue to the assistant if a specified number is exceeded, the assistant process will start. <br><br>  A small digression on the work of authorization: <br><br>  There is a feature here, the fact is that some sites try to connect a wagon of various resources and pictures from other sites, collect a bunch of statistics and so on, each request passes authorization, this can cause a large queue in the authorization assistant process, you can simply increase the children, increase the idle ... but it is only at first glance, there can be several tens of thousands of requests from 1 user, which carries a long queue.  When a large queue appears, the load on the CPU goes off scale.  In the conditions of a large number of PCs and a small proportion of users with full Internet access, installed on a PC, chrome created a surprising number of connections directly - 500 thousand requests to clients1.google.com per day.  As a result, there were peaks in the queues. <br><br>  Details of the solution are at the end of the article, where some technical aspects of solving the problems encountered during the debugging process will be described. <br><br>  Search for a user in a group: <br><br><pre> <code class="bash hljs">external_acl_type domainusers ttl=300 negative_ttl=60 ipv4 %LOGIN /usr/lib/squid3/ext_kerberos_ldap_group_acl -a -T d09fd0bed0bbd18cd0b7d0bed0b2d0b0d182d0b5d0bbd0b820d0b4d0bed0bcd0b5d0bdd0b0 -D DOMAIN.LOCAL external_acl_type allow-all ttl=300 negative_ttl=60 ipv4 %LOGIN /usr/lib/squid3/ext_kerberos_ldap_group_acl -a -g internet-allow-all -D DOMAIN.LOCAL</code> </pre> <br>  The two lines above perform 1 function, load the helper to search for a user in a group, you can do it yourself on the command line / usr / lib / squid3 / ext_kerberos_ldap_group_acl -a -g internet-allow-all -D DOMAIN.LOCAL click enter and type in the user name, if the user is found in the specified group, the answer will be OK if not, then ERR.  I draw attention to the fact that the specified group internet-allow-all was created in AD. <br><br>  If you noticed, the two lines are different, in one incomprehensible set of letters and numbers in the second everything is clear ... The first line contains the Domain Users group, not wanting to deal with Cyrillic in the squid config and helper's work, I decided to do so the only group in AD that is associated with this service is a name written in Cyrillic.  The syntax is also changed, from g which means group to T. <br><br>  He promised to tell why he disabled ipv6, it was a long story, the user did not log in because I did not specify external_acl_type in the line ....... <b>ipv4</b> .  we do not use ipv6 and very few people use it in local networks it was decided to disable it altogether in order to avoid such problems.  On surfing the Internet this is also not reflected in any way. <br><br>  Speed ‚Äã‚Äãlimit groups: <br><br><pre> <code class="bash hljs">external_acl_type <span class="hljs-built_in"><span class="hljs-built_in">disable</span></span>-speed ttl=300 negative_ttl=60 ipv4 %LOGIN /usr/lib/squid3/ext_kerberos_ldap_group_acl -a -g internet-deny-speed -D DOMAIN.LOCAL external_acl_type allow-speed ttl=300 negative_ttl=60 ipv4 %LOGIN /usr/lib/squid3/ext_kerberos_ldap_group_acl -a -g internet-allow-speed -D DOMAIN.LOCAL</code> </pre> <br>  internet-allow-speed - A group created in AD. <br><br>  Since we get groups and users from an external helper, we need to define acl in the squid syntax for http_access, etc. <br><br><pre> <code class="bash hljs">acl domainusers external domainusers acl allow-all external allow-all acl allow-speed external allow-speed acl <span class="hljs-built_in"><span class="hljs-built_in">disable</span></span>-speed external <span class="hljs-built_in"><span class="hljs-built_in">disable</span></span>-speed</code> </pre><br>  Next are allow and block rules.  The rules work as usual in a chain, everything above is more important. <br><br><pre> <code class="bash hljs">http_access allow localhost http_access deny manual http_reply_access deny application_mime http_access allow allow-all http_reply_access allow allow-all http_access allow domainusers banksites http_access deny domainusers</code> </pre> <br>  Here begins the bump, in the http_port line we specify the port and specify the ssl-bump function, then we turn on certificate generation, then the cache size, then we specify the certificate itself to the word that is added as a trusted certification authority on domain computers, then the key. <br><br>  The scheme of work is the following, the client enters <a href="https://google.com/">google.com</a> , the client establishes ssl connection with the proxy, and the proxy in turn with the site, the proxy raises ssl with the site and separately ssl with the client acting as an intermediary. <br><br>  This scheme with full bump of the connection, you can not disassemble completely, but only for 1 of the parties, I have not found this application, so we do not use it.  In addition, to see all traffic openly as http, only this scheme is suitable. <br><br><pre> <code class="bash hljs">http_port 3128 ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=16MB cert=/etc/squid/ssl/private/public.pem key=/etc/squid/ssl/private/private.pem</code> </pre> <br>  Settings assistant that generates ssl certificates for sites: <br><br><pre> <code class="bash hljs">sslcrtd_program /usr/lib/squid/ssl_crtd -s /etc/squid/ssl/ssl_db -M 16MB sslcrtd_children 20 startup=10 idle=10 visible_hostname = squid3.domain.local</code> </pre> <br>  We create acl with bump steps, there are only 3 steps, sslbump1 looks at open information in the certificate, the one that is accessible to everyone. <br><br>  sslbump2 creates a connection to the site sslbump3 creates a connection to the client. <br><br><pre> <code class="bash hljs">acl step1 at_step SslBump1 acl step2 at_step SslBump2 acl step3 at_step SslBump3</code> </pre><br>  We specify acl which will be brought in exceptions during the work with sslbump <br><br><pre> <code class="bash hljs">acl sslbanksites ssl::server_name <span class="hljs-string"><span class="hljs-string">"/etc/squid/exceptions/bank.txt"</span></span> acl allowsplice ssl::server_name <span class="hljs-string"><span class="hljs-string">"/etc/squid/exceptions/allowsplice.txt"</span></span></code> </pre> <br>  In bank.txt and allowsplice.txt are domain names. <br><br>  This rule allows to accept certificates with an error, i.e.  expired, self-signed, issued to another host, etc.  We created acl for this rule above. <br><br><pre> <code class="bash hljs">sslproxy_cert_error allow allowerrorsert</code> </pre> <br>  splice - skip all subsequent actions i.  do not do bump skip as is. <br>  peek - peek at available infu without full bump <br>  terminate - close the connection, do not use, we filter via http_access <br>  bump - gets into the connection, makes https visible as http <br><br><pre> <code class="bash hljs">ssl_bump splice allowsplice ssl_bump splice sslbanksites ssl_bump peek step1 all ssl_bump bump step2 all ssl_bump bump step3 all</code> </pre> <br>  We close access to all. <br><br><pre> <code class="bash hljs">http_access deny all icp_access deny all htcp_access deny all</code> </pre><br>  Other settings <br><br><pre> <code class="bash hljs">cache deny all error_directory /etc/squid/errors/ forwarded_for off</code> </pre><br>  We cut the speed, indicate how many delay pools we use: <br><br><pre> <code class="bash hljs">delay_pools 3</code> </pre> <br>  VIP users, favorite sites without speed limits <br><br><pre> <code class="bash hljs">delay_class 1 1 delay_access 1 allow allow-speed delay_access 1 allow banksites delay_parameters 1 -1/-1 delay_access 1 deny all</code> </pre><br>  After hours - the Internet is turned off (up to 100KB / sec.) <br><br><pre> <code class="bash hljs">delay_class 2 2 delay_access 2 allow !workhours delay_parameters 2 -1/-1 10000/10000 delay_access 2 deny all</code> </pre><br>  Download restriction - up to 10MB download the entire channel without restrictions, above only 100 KB / C <br><br><pre> <code class="bash hljs">delay_class 3 2 delay_access 3 allow <span class="hljs-built_in"><span class="hljs-built_in">disable</span></span>-speed delay_parameters 3 -1/-1 32000/10485760 delay_access 3 deny all</code> </pre><br>  In the syntax of the log, the letter a is changed to a large A, here:% 6tr%&gt; A.  This makes it possible to see in the logs the name of the computer instead of its IP address, which of course is more convenient. <br><br><pre> <code class="bash hljs">logformat squid %ts.%03tu %6tr %&gt;A %Ss/%03&gt;Hs %&lt;st %rm %ru %[un %Sh/%&lt;a %mt</code> </pre> <br>  Not a lot about the problems and features that have arisen. <br><br>  The proxy server is displayed in a separate dmz, the firewall restricts access to and from the dmz.  Since  Since a squid constantly polls dns and kerberos by udp predominantly, it immediately exceeded the allowed number of connections with 1 ip, to the AD server which is in another dmz, the connections were dropped.  The problem was not obvious, the authorization helper fell, the client received an authentication window. <br><br>  The error looks like this: <br><br>  support_krb5.cc (64): pid = 36139: 2017/10/24 08: 53: 51 |  kerberos_ldap_group: ERROR: Error while initializing credentials from keytab: Cannot contact any KDC for realm 'DOMAIN.LOCAL' <br><br>  Solved the problem by raising bind on the proxy server, the number of requests has decreased significantly.  In general, it was possible to disable restrictions on the firewall, which was actually done, but bind is still a good idea that allows you to significantly reduce the number of connections. <br><br>  There was 1 more error: <br><br>  support_sasl.cc (276): pid = 8872: 2017/10/24 06: 26: 31 |  kerberos_ldap_group: ERROR: ldap_sasl_interactive_bind_s error: Local error <br>  support_ldap.cc (957): pid = 8872: 2017/10/24 06: 26: 31 |  kerberos_ldap_group: ERROR: Error while binding to server with SASL / GSSAPI: Local error <br><br>  In bind you need to copy the reverse zone. <br><br>  <b>UPD</b> - The Most Interesting <br><br>  There was a problem with a high load on cpu and io, the percents were mostly negotiate_kerberos io were loading ext_kerberos_ldap_group_acl, it‚Äôs clear that negotiate_kerberos ran ext_kerberos_ldap_group_acl, the load was not constant, twice a day for 30 minutes. <br><br>  Changing the ratio of the number of children and idle did not give the desired result.  In the process of debugging, there was a clear picture; in any configuration during the peak period, the maximum number of authentication processes was launched.  Access.log was analyzed, as a result of the analysis it was highlighted that at the time of peak load there were a lot of ssl connections, this suggested that the problem lies not in authorization but in ssl_bump, ssl_bump was turned off for the experiment, as a result there was a complete lack of load throughout the day.  In general, during the day, the work of the squid and his assistants did not cause any complaints, but at certain moments a huge number of connections came up, dry numbers: from 1 computer per unit of time (5-15 min) 10,000 requests came for an ssl connection that falls under the bump rule.  Another day is the same from another computer on. * Whatsapp.net. <br><br>  Ultimately, ssl_bump is enabled, it works without any complaints.  If there are a lot of requests to a host that is not available by timeout, then there are peaks.  The decrease in the queue was mainly affected by the exclusion of clients1.google.com and clients2.google.com from the proxy. <br><br>  It‚Äôs up to you to decide to give access to clients1.google.com and clients2.google.com, disable the update task or exclude these hosts from the proxy. <br><br>  Regarding hyper-v, in general, everything works stably, the uptime usually exceeds two months, but the day comes when absolutely out of the blue with no errors in the logs and any load virtual machines hang or reboot, but subsequent loading does not result loading working condition.  It is necessary to do a reset and the subsequent download is done normally, I apologize for the tautology.  With all the equal on the specified server, two virtual servers of ubuntu server 16.04 are spinning and both have an ode and the same problem with a difference between them of several days, then again uptime for at least 2 months.  To solve this problem, we transfer a squid to a docker, I will draw up the following article about setting up a squid in a docker, in general, it is not much different than a whole heap of dependencies. <br><br>  Bind setting: <br><br><pre> <code class="bash hljs"> nano /etc/<span class="hljs-built_in"><span class="hljs-built_in">bind</span></span>/named.conf.options</code> </pre> <br>  We edit and paste: <br><br><pre> <code class="bash hljs">zone <span class="hljs-string"><span class="hljs-string">"domain.local"</span></span> { <span class="hljs-built_in"><span class="hljs-built_in">type</span></span> slave; masters { 192.168.XX.XX; 192.168.XX.XX;}; file <span class="hljs-string"><span class="hljs-string">"bak.domain.local"</span></span>; forwarders {}; zone <span class="hljs-string"><span class="hljs-string">"XX.168.192.in-addr.arpa"</span></span> { <span class="hljs-built_in"><span class="hljs-built_in">type</span></span> slave; masters { 192.168.XX.XX; 192.168.XX.XX;}; file <span class="hljs-string"><span class="hljs-string">"XX.168.192.in-addr.arpa.zone"</span></span>; };</code> </pre><br>  Log Analyzer: <br><br>  <b>Squidanalyzer</b> <br><br>  ‚Üí <a href="http://squidanalyzer.darold.net/">Site</a> <br>  ‚Üí Instructions: <a href="http://squidanalyzer.darold.net/install.html">one</a> and <a href="http://squidanalyzer.darold.net/config.html">two</a> <br><br>  For it to work, you need to install apache2: <br><br><pre> <code class="bash hljs">apt-get install apache2</code> </pre> <br>  Talking about how to insist I will not, on the links is quite understandable and accessible.  I will pay attention only to one, until the first report is generated - nothing appears on the web address, there will be an error. <br><br>  As soon as the first report is generated, you will receive a cherished report page. <br>  It should be noted that the page with reports can be styled for your company, change logos, signatures, background, etc.  The part should be changed in the main config: <br><br>  /etc/squidanalyzer/squidanalyzer.conf <br><br>  And in the script that is the template for / usr / bin / squid-analyzer: <br><br>  /usr/local/share/perl/5.22.1/SquidAnalyzer.pm <br><br>  The article was written intermittently, periodically supplemented and corrected, I hope it will be useful. <br><br>  Below is the listing of the cleaned config, it should be used as a sample, not subject to copy-paste, this will not give a working copy, you need to create files that are listed in acl, fill them, etc. <br><br>  In the process of debugging, awk was very helpful, a command that displays and groups the columns: <br><br><pre> <code class="bash hljs"> cat /var/<span class="hljs-built_in"><span class="hljs-built_in">log</span></span>/squid/access.log | awk <span class="hljs-string"><span class="hljs-string">'{print $}'</span></span> | cut -d: -f1 | sort | uniq -c | sort -n</code> </pre> <br>  You can add grep. <br><br>  To convert the date and time format in the squid log, you can use the following perl script: <br><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#! /usr/bin/perl -p s/^\d+\.\d+/localtime $&amp;/e</span></span></code> </pre> <br>  Save to file, say time.  Next, copy or save the desired piece of the access.log log and execute: <br><br>  perl time filename.log&gt; time-filename.log <br>  Etc. <br><br><div class="spoiler">  <b class="spoiler_title">squid.conf</b> <div class="spoiler_text"><pre> <code class="bash hljs">acl SSL_ports port 443 acl SSL_ports port 80 acl Safe_ports port 88 acl Safe_ports port 443 acl purge method PURGE acl CONNECT method CONNECT acl blockip src <span class="hljs-string"><span class="hljs-string">"/etc/squid/ban/blockip.txt"</span></span> http_access deny blockip http_reply_access deny blockip acl allnet src 192.168.XX.0/18 acl allnet src 192.168.0.0/24 acl javaapletclient src <span class="hljs-string"><span class="hljs-string">"/etc/squid/pools/javaaplet.txt"</span></span> acl javaapletdomain dstdomain <span class="hljs-string"><span class="hljs-string">"/etc/squid/exceptions/javaaplet.txt"</span></span> acl microsoftcrt url_regex -i <span class="hljs-string"><span class="hljs-string">"/etc/squid/exceptions/microsoftCRT.txt"</span></span> http_access allow javaapletclient javaapletdomain http_access allow allnet microsoftCRT http_reply_access allow allnet microsoftCRT http_access deny allnet manual http_access allow purge localhost http_access deny purge http_access deny CONNECT !SSL_ports acl application_mime rep_mime_type <span class="hljs-string"><span class="hljs-string">"/etc/squid/ban/mime_type_application.txt"</span></span> acl audio_mime rep_mime_type <span class="hljs-string"><span class="hljs-string">"/etc/squid/ban/mime_type_audio.txt"</span></span> acl video_mime rep_mime_type <span class="hljs-string"><span class="hljs-string">"/etc/squid/ban/mime_type_video.txt"</span></span> acl blockextention urlpath_regex -i <span class="hljs-string"><span class="hljs-string">"/etc/squid/ban/blockextention.txt"</span></span> acl blockextention2 urlpath_regex -i <span class="hljs-string"><span class="hljs-string">"/etc/squid/ban/blockextention2.txt"</span></span> acl allowextention urlpath_regex -i <span class="hljs-string"><span class="hljs-string">"/etc/squid/exceptions/allowextention.txt"</span></span> acl others src 192.168.XX.0/20 192.168.XX.0/18 192.168.XX.0/24 acl localnet dst 192.168.0.0/24 acl workhours time 7:00-18:59 strip_query_terms off log_mime_hdrs on acl manual_reg url_regex -i <span class="hljs-string"><span class="hljs-string">"/etc/squid/ban/manual_url.txt"</span></span> acl banner_reg url_regex -i <span class="hljs-string"><span class="hljs-string">"/etc/squid/ban/adv/urls"</span></span> acl dating_reg url_regex -i <span class="hljs-string"><span class="hljs-string">"/etc/squid/ban/dating/urls"</span></span> acl redirector_reg url_regex -i <span class="hljs-string"><span class="hljs-string">"/etc/squid/ban/redirector/urls"</span></span> acl porno_reg url_regex -i <span class="hljs-string"><span class="hljs-string">"/etc/squid/ban/porn/urls"</span></span> acl shopping_reg url_regex -i <span class="hljs-string"><span class="hljs-string">"/etc/squid/ban/shopping/urls"</span></span> acl socialnet_reg url_regex -i <span class="hljs-string"><span class="hljs-string">"/etc/squid/ban/socialnet/urls"</span></span> acl spyware_reg url_regex -i <span class="hljs-string"><span class="hljs-string">"/etc/squid/ban/spyware/urls"</span></span> acl allowerrorsert dstdomain <span class="hljs-string"><span class="hljs-string">"/etc/squid/exceptions/allowerrorsert.txt"</span></span> auth_param negotiate program /usr/lib/squid/negotiate_kerberos_auth -s HTTP/squid3.DOMAIN.local@DOMAIN.LOCAL auth_param negotiate children 50 startup=15 idle=15 auth_param negotiate keep_alive on external_acl_type domainusers ttl=300 negative_ttl=60 ipv4 %LOGIN /usr/lib/squid3/ext_kerberos_ldap_group_acl -a -T d09fd0bed0bbd18cd0b7d0bed0b2d0b0d182d0b5d0bbd0b820d0b4d0bed0bcd0b5d0bdd0b0 -D DOMAIN.LOCAL external_acl_type allow-all ttl=300 negative_ttl=60 ipv4 %LOGIN /usr/lib/squid3/ext_kerberos_ldap_group_acl -a -g internet-allow-all -D DOMAIN.LOCAL external_acl_type allow-speed ttl=300 negative_ttl=60 ipv4 %LOGIN /usr/lib/squid3/ext_kerberos_ldap_group_acl -a -g internet-allow-speed -D DOMAIN.LOCAL external_acl_type standart ttl=300 negative_ttl=60 ipv4 %LOGIN /usr/lib/squid3/ext_kerberos_ldap_group_acl -a -g internet-standart -D DOMAIN.LOCAL external_acl_type bankusers ttl=300 negative_ttl=60 ipv4 %LOGIN /usr/lib/squid3/ext_kerberos_ldap_group_acl -a -g internet-bank -D DOMAIN.LOCAL external_acl_type <span class="hljs-built_in"><span class="hljs-built_in">disable</span></span>-speed ttl=300 negative_ttl=60 ipv4 %LOGIN /usr/lib/squid3/ext_kerberos_ldap_group_acl -a -g internet-deny-speed -D DOMAIN.LOCAL external_acl_type allowformat ttl=300 negative_ttl=60 ipv4 %LOGIN /usr/lib/squid3/ext_kerberos_ldap_group_acl -a -g internet-allowFormat -D DOMAIN.LOCAL external_acl_type denyformat ttl=300 negative_ttl=60 ipv4 %LOGIN /usr/lib/squid3/ext_kerberos_ldap_group_acl -a -g internet-denyFormat -D DOMAIN.LOCAL acl domainusers external domainusers acl allow-all external allow-all acl allow-speed external allow-speed acl standart external standart acl bankusers external bankusers acl <span class="hljs-built_in"><span class="hljs-built_in">disable</span></span>-speed external <span class="hljs-built_in"><span class="hljs-built_in">disable</span></span>-speed acl allowformat external allowformat acl denyformat external denyformat http_access deny blockextention denyformat http_access deny blockextention2 allowformat http_access deny localnet others http_access deny spyware http_access deny spyware_reg http_access deny porno http_access deny porno_reg http_access deny ra http_access deny proxy http_access deny other http_access deny banner http_access deny banner_reg http_access deny dating http_access deny dating_reg http_access deny redirector http_access deny redirector_reg http_access deny standart audiovideo http_access deny standart shopping http_access deny standart shopping_reg http_access deny standart socialnet http_reply_access deny denyformat application_mime http_reply_access allow allowformat application_mime http_access deny manual http_reply_access allow all http_access allow localhost http_access allow allow-all http_access allow standart http_access allow bankusers banksites http_access allow domainusers allofficesites http_access deny domainusers !allofficesites http_port 3128 ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=100MB cert=/etc/squid/ssl/private/public.pem key=/etc/squid/ssl/private/private.pem sslcrtd_program /usr/lib/squid/ssl_crtd -s /etc/squid/ssl/ssl_db -M 100MB visible_hostname = squid3.DOMAIN.local sslcrtd_children 70 startup=5 idle=10 acl step1 at_step SslBump1 acl step2 at_step SslBump2 acl step3 at_step SslBump3 acl sslbanksites ssl::server_name <span class="hljs-string"><span class="hljs-string">"/etc/squid/exceptions/bank.txt"</span></span> acl allowsplice ssl::server_name <span class="hljs-string"><span class="hljs-string">"/etc/squid/exceptions/allowsplice.txt"</span></span> sslproxy_cert_error allow allowerrorsert ssl_bump splice allowsplice ssl_bump splice sslbanksites ssl_bump peek step1 all ssl_bump bump step2 all ssl_bump bump step3 all http_access deny all icp_access deny all htcp_access deny all cache deny all cache_mgr support@DOMAIN.COM negative_ttl 10 seconds hosts_file /etc/hosts error_directory /etc/squid/errors/ forwarded_for off delay_pools 3 delay_class 1 1 delay_access 1 allow allow-speed delay_access 1 allow allofficesites delay_access 1 allow allowspeeddomain delay_parameters 1 -1/-1 delay_access 1 deny all delay_class 2 2 delay_access 2 allow !allow-speed delay_access 2 allow !allowspeeddomain delay_access 2 allow !workhours delay_parameters 2 -1/-1 625000/625000 delay_access 2 deny all delay_class 3 2 delay_access 3 allow <span class="hljs-built_in"><span class="hljs-built_in">disable</span></span>-speed delay_parameters 3 -1/-1 320000/10485760 delay_access 3 deny all deny_info ERR_ACCESS_DENIED_BANNERS banner banner_reg deny_info ERR_ACCESS_DENIED_DATING dating dating_reg deny_info ERR_ACCESS_DENIED_REDIRECTOR redirector redirector_reg deny_info ERR_ACCESS_DENIED_PORNO porno porno_reg deny_info ERR_ACCESS_DENIED_SOCIALNET socialnet socialnet_reg deny_info ERR_ACCESS_DENIED_SPYWARE spyware spyware_reg deny_info ERR_ACCESS_DENIED_MANUAL manual manual_reg deny_info ERR_ACCESS_DENIED_AUDIOVIDEO audiovideo deny_info ERR_ACCESS_DENIED_BLOKEXTENTION blockextention deny_info ERR_ACCESS_DENIED_BLOKEXTENTION2 blockextention2 logformat squid %ts.%03tu %6tr %&gt;A %Ss/%03&gt;Hs %&lt;st %rm %ru %[un %Sh/%&lt;a %mt</code> </pre><br></div></div></div><p>Source: <a href="https://habr.com/ru/post/347212/">https://habr.com/ru/post/347212/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../347202/index.html">In the US with a bodyshop: go or not go?</a></li>
<li><a href="../347204/index.html">IT solutions architecture. Part 1. Enterprise architecture</a></li>
<li><a href="../347206/index.html">As simple as possible about sorting combinations in real business problems</a></li>
<li><a href="../347208/index.html">Kodein is an interesting alternative to Dagger 2 for dependency injection in Kotlin</a></li>
<li><a href="../347210/index.html">Behaviors - Erlang behaviors</a></li>
<li><a href="../347216/index.html">The principle of the stream cipher with examples in C #. From One-time pad to stream cipher based on hashf and CTR</a></li>
<li><a href="../347218/index.html">Projection Modeling Technique</a></li>
<li><a href="../347220/index.html">Microchip implantation: myths and reality</a></li>
<li><a href="../347222/index.html">Postgres logging experience</a></li>
<li><a href="../347224/index.html">PBX in the container. Asterisk 14 + Nginx + Freepbx 14 + srtp on Centos 7 in Proxmox VE 4 lxc container</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>