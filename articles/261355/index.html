<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>NetBackup 7.6 Implementation Experience</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="In this article we will try to briefly tell you about the experience of implementing the Symantec NetBackup backup system. 

 In order to increase the...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>NetBackup 7.6 Implementation Experience</h1><div class="post__text post__text-html js-mediator-article">  In this article we will try to briefly tell you about the experience of implementing <b>the Symantec NetBackup backup system.</b> <br><br>  In order to increase the security of internal corporate systems against information loss and reduce the production costs of recovery in case of failures, the customer decided to implement a backup system based on NetBackup 7.6.  We leave the description of the process of choosing a specific solution by a customer outside the scope of this article. <a name="habracut"></a><br><br>  As a result, the main parameters of the solution were identified: <br><ul><li>  list of information systems to be backed up; </li><li>  backup windows; </li><li>  available server resources; </li><li>  resources of storage systems and data networks </li></ul><br>  and formulated the project objectives, the achievement of which was considered necessary. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      In preparation for the project, a survey was conducted of the existing infrastructure, which allowed us to get an idea of ‚Äã‚Äãall the systems to be backed up, determine the requirements for the volumes of backup storage and data transmission capacity, as well as create the necessary schemes. <br><br>  Since the introduction of the system was carried out mainly in a remote mode, the presence of diagrams and descriptions made at the survey stage, simplified the solution of a large number of issues that arose during the work. <br><br><h5>  <b>Customer infrastructure description</b> </h5><br>  The customer's infrastructure, on the one hand, is relatively simple, as there is a clear separation of functions between servers, and, on the other hand, its heterogeneity and richness in various systems required the development of a large number of different backup policies.  The task was to perform the backup of all systems using only one master server and one media server. <br><br>  The list of systems to be backed up includes about 40 servers (both physical and virtual) with a total storage capacity of about 60 TB. <br><br>  Most of the servers, virtualization, disk systems and tape libraries are located on the first site of the customer.  Separate hardware servers - on the second (within one city).  The sites are interconnected by a GbE network.  Inside the first site, there are two storage network factories to which storage resources and various servers are connected. <br>  Of course, in order to ensure the safety of data in various serious incidents (fires, flooding, etc.), working data and backup copies should be better placed at different sites, but in this case the customer‚Äôs available resources did not allow such a scheme to be implemented, and this task was put in the project. <br><br><img src="https://habrastorage.org/files/bb3/7aa/cf8/bb37aacf838646608fa89dae722a23ce.jpg"><br><br><h5>  <b>Solution Architecture Description</b> </h5><br>  The solution includes: <br><ul><li>  1 NetBackup master server (it also has the NBAC access control module and the OpsCenter monitoring tool); </li><li>  1 NetBackup media server; </li><li>  Several LUNs from disk arrays designed for storing backup copies; </li><li>  2 tape libraries (3 tape drives in total). </li></ul><br>  Both tape libraries, disk arrays and a media server are connected to two isolated SAN factories built on Brocade switches with a bandwidth of up to 8 Gb / s.  Virtualization hosts with VMware ESXi hypervisors are also connected to the SAN.  This allowed us to further use the backup mode of virtual machines over the SAN and significantly relieve the GbE network. <br><br>  Correct SAN tuning is one of the key factors affecting the stability of the solution as a whole.  Errors in the SAN zone configuration or in the physical transport of the network (on ports, links to servers and repositories, in inter-switch communications, etc.), overload during peak traffic, lack of reception and transmission credits and other not always obvious problems can lead to first glance, to incomprehensible or unreasonable unavailability of resources, their sudden disappearance with the slightest changes, etc.  In addition to configuring the storage network itself, at this stage, setting up the publication of resources on storage systems: both on disk arrays and libraries. <br><br>  Sometimes it happens that the customer‚Äôs specialists do not particularly follow the work of the SAN, since for them this part of the work is not everyday.  As they say, once set up and forgotten, while working - do not touch.  And when preparing the network for launching the backup system, a lot of changes are made in its configuration and storage system settings.  Therefore, a detailed study of the SAN configuration before network changes is a very important step. <br><br>  On disk arrays, LUNs were allocated for storing backup copies: LUNs of 6 TB size for deduplicated data and LUN sizes of just less than 2 TB for storing data that are easier to compress than deduplicate, for example, these types of data include logs of database transactions.  Both disk volumes are connected to a media server on which they were marked up as GPT basic volumes by means of Windows Server OS. <br><br>  For backup purposes, it makes sense immediately to mark up disk resources in GPT, since the MBR limit of 2 TB is quite easily reached during operation and there is a need to increase the storage volume above this value.  At the same time, the PDDO component in NetBackup, which will be described later, has a limitation: on a media server, it can use only one logical drive to store deduplicated data.  Therefore, in order not to create multiple LUNs of 2 TB each in the future and not to combine them into a Spanned Volume with dynamic volume management tools, it is much easier to immediately mark the desired LUN in GPT. <br><br>  Here, of course, you need to consider whether the necessary backup volume will be available within one LUN from one array.  If the disk space is ‚Äúsliced‚Äù into various pieces from several arrays, the management of the disk space on the media server can be complicated.  Especially, considering that when using virtual machine backup over SAN, the media server should have access to all VMFS volumes as well. <br><br><h5>  <b>Features of the implementation of the solution</b> </h5><br>  Due to the limited bandwidth of the network interfaces of the media server and the high density of backup tasks performed at night, the system was originally designed to use the following techniques, which significantly speed up the backup process: <br><ul><li>  SAN backup </li><li>  deduplication on the client; </li><li>  client compression; </li><li>  Acceleration of backup copies (Accelerator). </li></ul><br>  <i>SAN backup is</i> used as part of a solution to create copies of virtual machines hosted on VMware vSphere.  In short, the meaning of this technique is that when creating a backup, the data from the virtualization host is transmitted to the media server not over the Ethernet network, but over the SAN, which, if you use the GbE network, unloads it very much (for 10GbE networks this is obviously is no longer so relevant).  At the same time, the media server directly via the SCSI protocol (wrapped in FC traffic) interacts with disk storage, on which LUNs are located with virtual machines.  In this case, appropriate zones must be created in the SAN from the media server to disk arrays containing LUNs with virtual machines, and these LUNs should be presented to the media server by means of disk arrays. <br><br>  <i>Deduplication in NetBackup is</i> implemented by either Media Server Deduplication Pool (MSDP), PureDisk Deduplication Option (PDDO), or Open Storage Technology (OST).  All three options require special licensing and are not included in the basic package of NetBackup.  The first two options allow you to create special types of storage on a media server (Media Server Deduplication Pool and PureDisk Deduplication Pool, respectively).  The third option allows you to connect external OST-compatible third-party disk storage. <br><br><img src="https://habrastorage.org/files/94f/ce0/ff5/94fce0ff58894aa9b17d427e25ca23db.jpg"><br><br>  Deduplication in NetBackup can be done both on the media server and on the client.  For obvious reasons, network traffic will be significantly reduced if deduplication is used on the client.  The flip side of the coin here is the increase in the load on the client's CPU, which may be unacceptable for highly loaded systems.  Theoretically, deduplication efficiency can reach 100% (if the data did not change at all in the interval between the individual backup tasks).  In reality, the effectiveness of deduplication varies in the whole range of values ‚Äã‚Äãfrom 0 to 100% and depends on the number of changes made to the data.  The illustration below in the Deduplication Rate column shows the high performance of SAP DB deduplication when performing backups to the PDDO pool. <br><br><img src="https://habrastorage.org/files/c41/7ef/37b/c417ef37b388440eb03b158b98726a5c.jpg"><br><br>  When using deduplication on the client, there is a regular decrease in the time required to back up data (if the client CPU is doing the job normally).  For example, the first full backup in a volume of 1 TB may take 5 hours conditionally, and the second with the same amount of data can be performed in 1 hour or less if the changes in the copied files were small.  This should be considered when planning backup windows. <br><br>  Compressing the client also reduces network traffic and loads the client's CPU.  At the same time, compression (like encryption) greatly changes the contents of the files transferred to the media server, which leads to a sharp drop in the effectiveness of deduplication.  Therefore, when using deduplication, the compression and encryption options in the backup policy should be disabled. <br><br>  To preserve the effectiveness of deduplication and compression, NetBackup, by default, independently compresses (but does not encrypt) the deduplicated data on the media server, i.e., first the data is deduplicated and then compressed.  This is regulated via the pd.conf configuration file, whose parameters are described in detail in the ‚ÄúSymantec NetBackup Deduplication Guide‚Äù in the ‚ÄúMSDP pd.conf file parameters‚Äù section. <br><br>  If the data changes frequently and often (for example, logs of transaction logs of the database), their compression may be more effective than deduplication.  In this case, the compressed data should be written to the storages of the types BasicDisk or AdvancedDisk that do not support deduplication. <br><br>  <i>NetBackup Accelerator</i> is a technology that allows, as the name implies, to speed up the creation of backup copies.  This is done by detecting data blocks on the client, backup copies of which have already been created, and the data has not changed since the previous backup was created, and it is still available in NetBackup repositories. <br><br>  Unlike the well-known ‚ÄúArchive‚Äù file attribute in Windows (or backup based on the date the file was changed), this method allows transferring unchanged files as a whole, but only modified blocks in these files, which saves the bandwidth between the client and the media server and significantly reduces the time to create a backup.  At the same time, a new backup copy from old (unchanged) and new (changed) data blocks is synthesized on the fly. <br><br>  NetBackup Accelerator is compatible only with the following types of backup policies: <br><ul><li>  Standard (file resources on any servers); </li><li>  MS-Windows (the same file resources on MS Windows systems); </li><li>  VMware (VMware virtual machines). </li></ul><br>  The use of Accelerator is only possible with MSDP, PureDisk and OST disk storages.  Working with BasicDisk and AdvancedDisk is not supported.  Accelerator requires a Data Protection Optimization Option for NetBackup. <br><br>  In the case of the Standard policy, Accelerator doesn‚Äôt depend on the OS; on the client side it maintains a log of changes in files.  When using the MS-Windows policy, you must use the NTFS or ReFS file system log, which is enabled by the <b>Use Change Journal</b> option.  For these two policies, the logic behind Accelerator is: <br><ul><li>  if resources have not yet been backed up from this client, NetBackup makes a regular full copy and creates a change log; </li><li>  during the next backup, NetBackup determines which blocks in the files have changed, and sends to the media server a data stream containing modified blocks and links to immutable blocks from the previous backup; </li><li>  the media server reconstructs the full backup based on the information received from the client. </li></ul><br>  The work of Accelerator in the framework of the VMware policy is generally the same, but for logging, the VMware Changed Block Tracking (CBT) option is used, which may require separate configuration on the virtualization system.  In addition, for individual events (cold restart of the virtual machine, power failure of the host, etc.), the change log in VMware can be reset, which will create a full backup without taking into account changes in the files and will naturally affect the backup time during the next backup. .  In addition, when creating a full backup of a virtual machine and enabled Accelerator, the granular recovery of MS Exchange, MS SQL and MS Sharepoint data from a VMDK VM file is supported. <br><br>  In addition to Accelerator, NetBackup has another option that allows you to back up only changed data blocks.  It is called ‚ÄúBlock Incremental Backup‚Äù (Block-level Incremental Backup, BLIB) and is designed to work with Oracle databases.  BLIB is a technology that allows you to transfer from Oracle to the media server only those blocks of Oracle database files that are marked as modified.  In NetBackup, it can only be used when hosting databases on VxFS file systems created using the Symantec Storage Foundation. <br><br>  In this project, despite the availability of Oracle databases as part of SAP solutions, the BLIB method was not used due to the absence of a Storage Foundation product at the customer.  All other methods to speed up the creation of backups were successfully applied and allowed to fit into very small backup windows set by the customer. <br><br><h5>  <b>Backup Techniques</b> </h5><br>  The list of resource classes to be regularly backed up included the following: <br><ul><li>  file resources on Windows and Linux servers; </li><li>  directory services Actve Directory; </li><li>  VMware virtual machines; </li><li>  physical machines; </li><li>  SAP / Oracle database; </li><li>  MS SQL database; </li><li>  SharePoint portal. </li></ul><br>  For each resource class, one or more backup policies are created, based on which NetBackup generates backup tasks and a schedule for their launch. <br><br>  NetBackup backup tasks are the intersection of four types of parameters that can be described in the following words: <br><ul><li>  how to copy (policy attributes, Attributes); </li><li>  when to copy (task schedules, Schedules); </li><li>  from where to copy (backup clients, Clients); </li><li>  what to copy (list of copied resources, selections). </li></ul><br>  The parameters defining the backup destination (storage, volume group) may be defined in the policy attributes, but in practice this method is rarely used, since the backup destination depends on the schedule. <br><br>  At the same time, if the attributes of a policy are set in a single set for one policy, then the lists of schedules, customers, and resources can include multiple values. <br><br>  Depending on the class of policy set on the Attributes tab, other parameters may change their meaning. <br><br><img src="https://habrastorage.org/files/3f5/e6c/c66/3f5e6cc66dfb45d6aa2ae0d3445335d4.jpg"><br><br>  For example, if the Standard policy on the Selections tab lists the list of reserved resources by absolute paths in the client's file system, then for SAP or Oracle backup tasks this list contains the list of scripts that are run by the NetBackup client, and the backup process is already being managed from them.  This approach allows you to achieve maximum flexibility in the organization of the backup process, which is especially important for working with large databases. <br><br>  Depending on the type of backup policy, various additional options are also selected that both optimize the backup process (like Accelerator) and can provide special features in the process of restoring data from a backup.  For example, Granular Recovery allows you to restore individual emails from MS Exchange backup or individual files from the Share Point DB. <br><br>  On the Attributes tab, you can also specify a location for storing backups (Policy Storage), although the practice shows that it‚Äôs not always convenient to specify a storage location at the policy level.  More features are provided by the definition of storage locations at the Storage Lifecycle Policy (SLP) level.  These are special objects that combine information about the place of storage, the period of storage, the order of duplication of backups, as well as the distribution of media (files on disk or tapes) among pools. <br><br><img src="https://habrastorage.org/files/50a/b9a/d95/50ab9ad95d8f4b9caa3fef8874174402.jpg"><br><br>  Using SLP allows you to flexibly set the rules for storing backups within the same NetBackup policy, since SLP can be specified for each task schedule separately. <br><br>  Task schedules are specified on a separate tab of Schedules and allow you to define within one policy the order in which tasks are launched according to the overall backup policy of the organization.  Usually, separate schedules are set for annual, monthly, weekly, daily tasks, as well as for tasks that are performed many times during one day (for example, backup tasks for database transaction logs). <br><br><img src="https://habrastorage.org/files/e83/e81/a32/e83e81a3268b48b69d992979a701afbf.jpg"><br><br>  A special feature of the backup of database tasks is that for each type of backup, you need to create a couple of tasks: <br><ul><li>  normal (Full, Differential, etc.), which is, in fact, the trigger that initiates the launch of the backup script; </li><li>  an application's backup task, which accepts data from backup tools located on the client that were started by the script.  In the case of database backup, it is in this problem that the SLP is indicated. </li></ul><br><br><img src="https://habrastorage.org/files/e56/e6c/f4d/e56e6cf4d5644b77a1441f7cef4ac953.jpg"><br><br>  The Clients tab lists the list of clients that are backed up as part of this policy.  There can be quite a lot of customers, but the same rules will apply to all of them. <br><br><img src="https://habrastorage.org/files/29f/0d7/774/29f0d77744fc42868475d44a8389bee8.jpg"><br><br>  The same applies to the list of copied resources.  Net Backup on each of the listed clients will try to find all the resources listed on the Backup Selections tab, and if any particular resource from the list is found, Net Backup will back it up in accordance with the policy. <br><br><img src="https://habrastorage.org/files/bbe/8f0/837/bbe8f08379db4bbfac3580411badbdf2.jpg"><br><br><h5>  <b>Data recovery from backup</b> </h5><br>  In most cases, you need to use the Backup, Archive and Restore program included in the NetBackup installation to recover data.  It allows you to specify a list of resources to be recovered based on the required date, a list of resources, a destination (here you can override the data destination by specifying a different path or another server), as well as recovery rules in exceptional situations (for example, specify whether files are overwritten, if they are already at the restore point). <br><br>  For Windows, you can specify files, directories, the state of the system as a whole, registry keys, etc. in the recovery tree. <br><br><img src="https://habrastorage.org/files/f95/db4/860/f95db4860f714afa877d59b0d1114d4c.jpg"><br><br>  The combination of options for restoring data from backups in NetBackup is very much, more than backup methods.  The framework of this article does not allow to disclose them in detail.  All of them are documented in as much detail as possible in the official instructions of Symantec, and referring to these instructions in the process of working with Net Backup is always useful, since it is quite difficult to cover one person‚Äôs full potential.  But we can confidently say that if the design and configuration of the backup system were performed correctly, then data recovery in case of real problems related to their damage or loss is a technical matter. <br><br>  Author: Andrey Khlebnikov, Softline </div><p>Source: <a href="https://habr.com/ru/post/261355/">https://habr.com/ru/post/261355/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../261345/index.html">Effective logo design, part 2: using natural templates</a></li>
<li><a href="../261347/index.html">A library that facilitates the development of forms on sites</a></li>
<li><a href="../261349/index.html">Compile-time reflection D</a></li>
<li><a href="../261351/index.html">Maximum overload - adventures in JavaScript in the C ++ world</a></li>
<li><a href="../261353/index.html">Cordova 5.1.1 and plugin updates</a></li>
<li><a href="../261359/index.html">Where are my files, ROBOCOPY?</a></li>
<li><a href="../261361/index.html">Stuck heads fore WiFi equipment manufacturers. (I apologize wildly, but Ruckus did everyone again)</a></li>
<li><a href="../261363/index.html">HP Education Day - a bit of everything HP has</a></li>
<li><a href="../261365/index.html">Wall Street Technology Arms Race: An Inside Look</a></li>
<li><a href="../261367/index.html">Microsoft and the Internet of Things? An introductory article on how we see this concept.</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>