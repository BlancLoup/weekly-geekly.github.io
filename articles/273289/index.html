<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Intel RealSense SDK and Oculus Rift DK2</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="This article describes the technical details and problems that developers may encounter when creating software solutions that use the Intel RealSense ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Intel RealSense SDK and Oculus Rift DK2</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/files/cb9/825/767/cb982576711d47bb804ae36f0da246c1.png"><br>  This article describes the technical details and problems that developers may encounter when creating software solutions that use the <a href="https://software.intel.com/en-us/intel-realsense-sdk">Intel RealSense SDK</a> for Windows * and Oculus Rift * glasses (headset).  We begin with an overview of the Oculus Rift Development Kit 2 (DK2), then move on to some of the problems encountered when developing applications that work with several infrared cameras.  This article also describes the integration of the Intel RealSense SDK and the Oculus Rift in the Unity * 5 project. <br><a name="habracut"></a><br><h2>  <font color="#0071c5">System requirements</font> </h2><br>  The information presented in this article concerns the use of the Intel RealSense F200 (front view) camera.  To perform all the described actions, you will need an <a href="https://support.oculus.com/hc/en-us/articles/201835987-Oculus-Rift-Development-Kit-2-FAQ">Oculus Rift DK2</a> kit, an <a href="https://software.intel.com/en-us/RealSense/Devkit/">Intel RealSense</a> camera <a href="https://software.intel.com/en-us/RealSense/Devkit/">(F200)</a> and a development system that meets the following requirements. <br><ul><li>  Intel Core 4th generation or later (to support the Intel RealSense SDK) </li><li>  150 MB of free hard disk space </li><li>  4 GB of RAM </li><li>  One USB3 port for the F200 camera and two USB 2.0 ports for the Oculus Rift DK2 </li><li>  Windows * 8.1 </li><li>  A dedicated NVIDIA GTX * 600 Series or AMD Radeon * HD 7000 Series (or higher) graphics card with DVI * -D or HDMI * output. </li></ul><br>  The following software components are required to support the Oculus Rift * DK2 and Intel RealSense Camera (F200). <br><ul><li>  Intel RealSense SDK (version 6.0.21.6598 or later) </li><li>  Intel RealSense Depth Camera Manager F200 (version 1.4.27.41944 or later) </li><li>  Oculus SDK for Windows * (version 0.7.0.0-beta or later) </li><li>  Oculus runtime for Windows * (version 0.7.0.0-beta or later) </li><li>  Oculus Utilities for Unity 5 (version 0.1.2.0-beta or later) </li></ul><br>  To get familiar with Unity, you can use the free personal version (5.2.2 or later) available <a href="https://unity3d.com/get-unity/download%3Fref%3Dpersonal">here</a> . <br><br><h2>  <font color="#0071c5">Oculus Rift * DK2 Kit</font> </h2><br>  Oculus Rift DK2 is a set of equipment and software components that allows developers to create games and virtual reality interfaces.  In addition to the glasses (headset), the kit also includes a low-latency position tracking camera to monitor the movement of the user's head. <br><br>  This is, in fact, an ordinary webcam, on the lens of which an infrared filter is installed.  Glasses (headset) are equipped with several hidden infrared LEDs installed in such a way that the tracking camera uses them to determine the position of the user's head in three-dimensional space.  Interestingly, these hidden infrared sources are detected by the Intel RealSense camera when viewing the camera's infrared stream in the Raw Streams example in the SDK. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/files/a96/df0/362/a96df0362fd149108a7af26f18a43e7e.png"><br>  <i>Oculus Rift * IR LEDs are visible on the Intel RealSense camera</i> <br><br>  Glasses (headset) Oculus Rift include a gyroscope, accelerometer and magnetometer. <br>  In combination with the combined sensor data, this equipment determines the orientation of the user's head and provides the corresponding rotation coordinates around the longitudinal, transverse and vertical axes.  The tracking camera provides additional information on the position of the user's head (i.e., spatial coordinates along the X, Y and Z axes). <br><br>  To better understand what the DK2 tracking camera adds to the picture of virtual reality, run the demo scene from the Oculus setup program. <br><br><img src="https://habrastorage.org/files/835/769/7e8/8357697e83d94f42b7e19b5151bcd282.png"><br>  <i>Oculus setup program</i> <br><br>  When viewing the demo scene with a tracking camera connected to the USB port, you will see that the objects on the virtual table will be closer or farther away when the head approaches or moves away from the camera. <br><br><img src="https://habrastorage.org/files/605/323/981/6053239815cf4ab58d113ec10990bfc9.png"><br>  <i>Oculus Rift demo scene</i> <br><br>  If you then start this demo scene by disconnecting the tracking camera's USB connector, you will see that the orientation data provided by the Oculus Rift glasses (headset) sensor will still set the rotation angles around the longitudinal, transverse and vertical axes, but the depth sensation disappears when moving the head along the z axis. <br><br><h2>  <font color="#0071c5">Interference with simultaneous use with front view camera</font> </h2><br>  Developers who use the Intel RealSense SDK and are interested in building virtual reality applications that use the Intel RealSense F200 front-view camera should be aware of the potential for interference from the mutual influence of the 3D depth camera and the Oculus Rift tracking camera.  The figure below shows the Lenovo ThinkPad * Yoga 15 ultrabook transformer with an integrated Intel RealSense F200 camera and an Oculus Rift tracking camera mounted side by side on the edge of the screen. <br><br><img src="https://habrastorage.org/files/13a/7e1/302/13a7e1302a9d4ca8a03577eba5dfb6e7.jpg"><br>  <i>Front View Cameras</i> <br><br>  The Intel RealSense F200 Camera uses light encoding technology to project infrared radiation onto a user and capture the invisible reflected image with an IR camera.  The Oculus Rift headset uses a set of IR LEDs for partial head tracking, the luminescence of which is recorded by its own passive IR camera;  This camera is equipped with an optical filter that transmits only the infrared region of the spectrum.  The effect of the IR LEDs of the Oculus Rift headset on an Intel RealSense camera can be seen as changing noise in the depth stream. <br><br><img src="https://habrastorage.org/files/9ab/300/080/9ab3000805ce4a2da0fc35ef7627aafe.png"><br>  <i>IR noise depth data</i> <br><br>  Shifting the DK2 tracking camera to a certain angle relative to the Intel RealSense camera may slightly reduce the effects of IR interference, but the fact that the Oculus headset can be a source of IR radiation means that it will definitely affect the Intel RealSense front-view camera. when the DK2 tracking camera is used. <br><br>  To better understand the effects of such interference, we launched the SDK Hands Viewer sample application by connecting the DK2 tracking camera to the USB port and running the Oculus Rift demo application.  As shown in the figure below, there is a significant drop in personnel speed.  This can be attributed to various factors (for example, the NVIDIA GeForce * 840M video adapter, less powerful than the minimum requirements, was used for this test).  But it‚Äôs still interesting to see that hand tracking and gesture recognition with the Intel RealSense camera work quite well. <br><br><img src="https://habrastorage.org/files/de6/685/f43/de6685f434ba4833a4d85a9abb36fa7f.png"><br>  <i>Gesture Recognition with Oculus Rift Infrared LEDs</i> <br><br><h2>  <font color="#0071c5">Using Unity 5</font> </h2><br>  Earlier, we mentioned possible interference between the Intel RealSense camera and the DK2 camera, but what happens if you combine these technologies in a real project? <br>  In the following sections, we briefly analyze the creation of a simple Unity 5 project with support for an Intel RealSense camera, and then turn on virtual reality. <br><br><h4>  Create a new Unity project </h4><br>  Launch a new Unity project by double-clicking the Unity icon on your desktop.  Select <b>New</b> , then select the name and location of the project. <br>  If the Unity editor is already open, create a new project by selecting <b>File</b> , <b>New Project</b> in the menu, then specify the name and location of the project. <br><br><h4>  Import the RSSDK Unity Toolkit Toolkit </h4><br>  Import the RSSDK Unity Toolkit by selecting <b>Assets</b> , <b>Import Package</b> , <b>Custom Package ...</b> from the menu. <br>  On the <b>Import Package</b> screen, go to the SDK folder in which the Unity Toolkit is located.  This location may vary depending on where the SDK was installed.  In this example, the toolbox is located in the folder <i>C: \ Program Files (x86) \ Intel \ RSSDK \ framework \ Unity</i> . <br>  Select UnityToolkit, then click <b>Open</b> . <br>  (Note. This folder contains two Unity files: <b>UnityToolkit</b> and <b>UnityCSharp</b> . When importing <b>UnityCSharp</b> , only the necessary managed and unmanaged DLLs needed to support the Intel RealSense SDK in the Unity application will be added. If you import the UnityToolkit, the necessary DLLs will be imported into a project along with many other resources to streamline the development of a project with support for the Intel RealSense SDK.) <br><br>  The <b>Importing Package</b> screen <b>appears</b> , in which all plug-ins, actions and presets are selected.  Leave the checkboxes selected and click the Import button. <br><br>  On the <b>Project</b> screen <b>,</b> note that a number of assets have been added to the project, which are located in the following folders. <br><ul><li>  <b>Plug-ins</b>  Contains the <b>libpxccpp2c.dll</b> file and the unmanaged C ++ P / Invoke DLL. </li><li>  <b>Plugins.Managed</b> .  Contains the <b>libpxcclr.unity.dll</b> file and the managed C # interface library. </li><li>  <b>RSUnityToolkit</b> .  Contains folders <b>Actions, Internals, Prefabs</b> and <b>Samples</b> . </li></ul><br><h4>  Add game object </h4><br>  The project will initially contain a main camera and a directional light source.  On the <b>Hierarchy</b> screen, click <b>Create</b> , then select <b>3D Object</b> and <b>Cube</b> .  At the same time, a game object-cube will be added to the game scene. <br><br>  In the <b>Project</b> folder in <b>Assets,</b> expand the <b>RSUnityToolkit</b> folder and select Actions. <br><br>  The Actions folder contains scripts that can be applied to game objects.  Click the <b>TrackingAction</b> script, then drag it onto the <b>Cube</b> game object on the <b>Hierarchy</b> screen. <br><br>  Select <b>Cube</b> on the <b>Hierarchy</b> screen, and you will see that the <b>Tracking Action (Script)</b> appears on the <b>Inspector</b> screen. <br><br><h4>  Hand tracking setup </h4><br>  The default for the tracking action is <b>HandTracking</b> , and for the dimensions of the virtual world area (Virtual World Box Dimensions) is set to 100 along the X, Y, and Z axes. If you are playing a game at this point, you will see that the 3D camera depth LED will turn on, indicating that the camera is activated. <br><br>  If you raise your hand in front of the camera, you (most likely) will see that the game object-cube will fly away from the screen.  The reason is that the <b>Virtual World Box Dimensions</b> parameter is set too large.  Change the <b>Virtual World Box Dimensions</b> settings to 10 for the X, Y, and Z axes. <br><br>  Notice that in the scene view, the virtual world field, outlined in red, is now close to the game object. <br><br>  Run the game again.  Now the game object-cube should track the movement of your hand in a closer virtual space. <br><br>  You may have noticed that the cube moves intermittently.  You can make the movement smoother by setting the <b>Smoothing Factor</b> parameter to 10. <br><br><img src="https://habrastorage.org/files/f7f/964/882/f7f964882a764110a61af24ef1e3ee7b.png"><br>  <i>Unity * Editor - tracking action parameters</i> <br><br><h4>  Turning on virtual reality in a Unity project </h4><br>  As stated on <a href="https://developer.oculus.com/documentation/game-engines/latest/concepts/unity-intro/">the Oculus Rift DK2 website</a> , Unity 5.1+ developers can replace the stereoscopic virtual reality camera with built-in means of tracking the orientation and position of the main camera.  To do this, check the <b>Virtual Reality Supported</b> checkbox in the <b>Player Settings</b> section.  Follow these steps to enable virtual reality in your project. <br><br>  Select <b>Edit - Project Settings</b> from the menu, then click <b>Player</b> . <br>  In the <b>Inspector</b> window, select the checkbox <b>Virtual Reality Supported</b> . <br><br>  Click the <b>Play</b> button and put on your Oculus Rift glasses.  You will immediately see that the transformation of the main camera is now replaced by tracking the orientation of the Oculus Rift glasses.  The cube still tracks the movement of your hand using the <b>TrackingAction</b> script in the Intel RealSense SDK Toolkit for Unity, but the Unity camera now tracks the movement of glasses. <br><br><img src="https://habrastorage.org/files/565/82c/cd7/56582ccd78ce4bc39ce0b0c5f4c7b244.png"><br>  <i>Unity with virtual reality enabled</i> <br><br><h4>  Import the Oculus Utilities package for Unity </h4><br>  The Utilities package is an optional addition, it includes workpieces, scenes and scenes for developing virtual reality applications.  The following shows how to import this package into your project. <br><br>  Choose <b>Assets, Import Package, Custom Package ...</b> from the menu. <br><br>  On the <b>Import Package</b> screen, navigate to the folder where the OculusUtilities Unity package file is located.  Select <b>OculusUtilities</b> , then click <b>Open</b> . <br><br>  The <b>Importing Package</b> screen <b>appears</b> , where all Oculus components will be selected.  Leave all checkboxes selected and click the <b>Import</b> button. <br><br>  Note.  In this example, we will add the <b>OVRCameraRig</b> from the OculusUtilities package to the scene.  Therefore, there is no need to check the <b>Virtual Reality Supported</b> box in the Inspector window when using the OculusUtilities package. <br><br>  Drag the <b>OVRCameraRig</b> to the stage. <br><br>  Turn off the main camera on stage to make sure that only <b>OVRCameraRig is used</b> . <br><br>  Click the Play button and put on your Oculus Rift glasses.  You will see that <b>OVRCameraRig</b> now tracks the movement of points, and the transformation of the cube is still controlled by the movement of the hand. <br>  Note.  For complete details on using the Oculus Utilities package, see the <a href="http://static.oculus.com/documentation/pdfs/game-engines/latest/unity.pdf">documentation</a> . <br><br><h4>  Add Virtual Reality to the Intel RealSense SDK Toolkit Sample Project for Unity * </h4><br>  With built-in virtual reality support in Unity 5.1+, you can very easily enable virtual reality support in the sample Intel RealSense SDK Toolkit for Unity, for example, in Sample 1 - Translation.  Try the following. <br><br>  In the <b>Project</b> folder <b>,</b> expand <b>RSUnityToolkit</b> - <b>Samples</b> - <b>Scenes</b> and double-click <b>Sample 1 - Translation</b> (remember to save your previous work first if you need it). <br><br>  Select <b>Edit</b> - <b>Project Settings</b> from the menu, then click <b>Player</b> . <br>  Make sure that the <b>Virtual Reality Supported</b> check box is <b>selected</b> in the <b>Inspector</b> window. <br>  Click <b>Play</b> and try! <br><br><h2>  <font color="#0071c5">Conclusion</font> </h2><br>  In this article, we looked at the potential interference problems that may occur when using an Intel RealSense front-view camera in a project using the Oculus Rift tracking camera.  We also talked about simple scenarios in which the Intel RealSense camera hand tracking was used in virtual reality.  Try it yourself and see what interesting results you can achieve! </div><p>Source: <a href="https://habr.com/ru/post/273289/">https://habr.com/ru/post/273289/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../273273/index.html">Data Storage: Something about 3D Disks</a></li>
<li><a href="../273275/index.html">C-like structures in javascript</a></li>
<li><a href="../273279/index.html">Apache Spark in combat projects - survival experience</a></li>
<li><a href="../273281/index.html">Creating a business process in BPEL using the Serena Business Manager platform</a></li>
<li><a href="../273283/index.html">Open source application architecture: How nginx works</a></li>
<li><a href="../273291/index.html">Look in both or a little about infographics.</a></li>
<li><a href="../273293/index.html">Castanedovskiy warrior risk management</a></li>
<li><a href="../273295/index.html">How to create software for a microtomograph for 5233 man-hours</a></li>
<li><a href="../273299/index.html">Unity's demo project The Blacksmith</a></li>
<li><a href="../273301/index.html">War, peace and ABBYY Compreno: the continuation of our affair with Tolstoy</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>