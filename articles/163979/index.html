<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Benchmark HTML parsers</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Rewrote in the island a piece of one service from Python to Erlang. The service itself is engaged in downloading a large number of similar HTML pages ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Benchmark HTML parsers</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/storage2/f5a/a24/203/f5aa242039c973359c9ceae64804feb9.png" align="right">  Rewrote <a href="http://ostrovok.ru/">in the island a</a> piece of one service from Python to Erlang.  The service itself is engaged in downloading a large number of similar HTML pages via HTTP and extracting some information from them.  The main CPU load of the service falls on the HTML parsing in the DOM tree. <br><br>  At first I wanted to compare the performance of the Erlang parser mochiweb_html with that used in Python lxml.etree.HTML ().  I spent the simplest benchmark, made the necessary conclusions, and then I thought that it would be nice to add a couple of parsers and platforms to the benchmark, make a more beautiful look, publish the code and write an article. <br>  At the moment, I managed to write benchmarks on <strong>Erlang</strong> , <strong>Python</strong> , <strong>PyPy</strong> , <strong>NodeJS</strong> and <strong>C</strong> in the following combinations: <br><ul><li>  Erlang - mochiweb_html </li><li>  CPython - lxml.etree.HTML </li><li>  CPython - BeautifulSoup 3 </li><li>  CPython - BeautifulSoup 4 </li><li>  CPython - html5lib </li><li>  PyPy - BeautifulSoup 3 </li><li>  PyPy - BeautifulSoup 4 </li><li>  PyPy - html5lib </li><li>  Node.JS - cheerio </li><li>  Node.JS - htmlparser </li><li>  Node.JS - jsdom </li><li>  C - libxml2 (more for reference) </li></ul><br>  The test compares the processing speed of N iterations of the parser and peak memory consumption. <br><br>  Intrigue: Who is faster - Python or PyPy?  How does the Erlang immunity affect parsing speed and memory consumption?  How fast is the V8 NodeJS?  And how does all this look at the code on pure C. <br><a name="habracut"></a><br><h3>  Terms </h3><br>  Most likely you are familiar with them, but why not repeat? 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      <i>Quiet HTML parser</i> is an HTML parser that can handle invalid HTML code (unclosed tags, characters <code>&gt;</code> <code>&lt;</code> inside <code>&lt;script&gt;</code> tags, non-escaped ampersand characters <code>&amp;</code> , attribute values ‚Äã‚Äãwithout quotes, etc.).  It is clear that not any broken HTML can be recovered, but you can bring it to the form to which the browser leads it.  It is noteworthy that most of the HTML, which is found on the Internet, is to some extent invalid! <br>  <i>DOM tree</i> - Document Object Model strictly speaking, the DOM is the API that is provided to javascript in the browser for manipulating HTML documents.  We will simplify the task a bit and assume that this is a data structure that is a tree-like display of the structure of an HTML document.  At the root of the tree is the <code>&lt;html&gt;</code> element, its child elements are <code>&lt;head&gt;</code> and <code>&lt;body&gt;</code> and so on.  For example, in a python document <br><pre> <code class="hljs xml"><span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">html</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">lang</span></span></span><span class="hljs-tag">=</span><span class="hljs-string"><span class="hljs-tag"><span class="hljs-string">"ru-RU"</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">head</span></span></span><span class="hljs-tag">&gt;</span></span><span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">head</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">body</span></span></span><span class="hljs-tag">&gt;</span></span>Hello, World!<span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">body</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">html</span></span></span><span class="hljs-tag">&gt;</span></span></code> </pre> <br>  Can be in the simplest form as <br><pre> <code class="hljs lisp">(<span class="hljs-string"><span class="hljs-string">"html"</span></span>, {<span class="hljs-string"><span class="hljs-string">"lang"</span></span>: <span class="hljs-string"><span class="hljs-string">"ru-RU"</span></span>}, [ (<span class="hljs-string"><span class="hljs-string">"head"</span></span>, {}, []), (<span class="hljs-string"><span class="hljs-string">"body"</span></span>, {}, [<span class="hljs-string"><span class="hljs-string">"Hello, World!"</span></span>]) ])</code> </pre> <br>  HTML is usually converted into a DOM tree for transformation or for data extraction.  To extract data from the tree is very convenient to use XPath or CSS selectors. <br><br><h3>  Contestants </h3><br><ul><li>  <strong>Erlang</strong> <br><ul><li>  <a href="">Mochiweb html parser</a> .  The only weak HTML parser for Erlang.  Written on Erlang. </li></ul><br></li><li>  <strong>CPython</strong> <br><ul><li>  <a href="http://lxml.de/">lxml.etree.HTML</a> binding libxml2.  Cython </li><li>  <a href="http://www.crummy.com/software/BeautifulSoup/bs3/documentation.html">BeautifulSoup 3</a> Written in python HTML DOM parser (3rd version). </li><li>  <a href="http://www.crummy.com/software/BeautifulSoup/bs4/doc/">BeautifulSoup 4</a> HTML DOM parser with pluggable backends. </li><li>  <a href="http://code.google.com/p/html5lib/">html5lib</a> Written on python DOM parser, focused on HTML5. </li></ul><br></li><li>  <strong>PyPy</strong> (the same parsers as CPython, except lxml) <br><ul><li>  BeautifulSoup 3 </li><li>  BeautifulSoup 4 </li><li>  html5lib </li></ul><br></li><li>  <strong>Node.JS</strong> <br><ul><li>  <a href="https://npmjs.org/package/cheerio">cheerio</a> JS HTML written DOM parser with jQuery API support </li><li>  <a href="https://npmjs.org/package/htmlparser">htmlparser</a> HTML DOM parser on pure JS </li><li>  <a href="https://npmjs.org/package/jsdom">jsdom</a> JS HTML written DOM parser with a heaped API similar to the browser API </li></ul><br></li><li>  <strong>C</strong> <br><ul><li>  <a href="http://xmlsoft.org/html/libxml-HTMLparser.html">libxml2</a> Written in C lax HTML SAX / DOM parser. </li></ul><br></li></ul><br><br><h3>  Goals </h3><br>  In general, HTML parsing (as well as JSON) is interesting because the document should be viewed character by character.  There are no instructions in it like ‚Äúthe next 10Kb is a solid text, we copy it as is‚Äù.  If we encounter a <code>&lt;p&gt;</code> tag in the text, then we need to sequentially look through all the subsequent characters for the presence of a <code>&lt;/</code> .  The fact that HTML can be invalid makes it "double check everything 2 times."  Because, for example, if we met the <code>&lt;option&gt;</code> , it is far from a fact that we will meet the closing <code>&lt;/option&gt;</code> .  The second problem that usually arises with such formats is the escape of special characters.  For example, if the entire document is <code>&lt;html&gt;...100  ... &amp;amp; ... 100  ...&lt;/html&gt;</code>  <code>&lt;html&gt;...100  ... &amp;amp; ... 100  ...&lt;/html&gt;</code> , the parser will have to create in memory a complete copy of the contents of the tag with a single change - "&amp; amp;", converted into "&amp;" (although some parsers simply break such text into 3 individual piece). <br><br>  The need to build a rather large structure in memory ‚Äî a tree of small objects imposes rather strict requirements on memory management, the garbage collector, on the overhead to create many small objects. <br><br>  Our benchmark want: <br><ul><li>  Compare the performance and memory consumption of various non-strict HTML DOM parsers. </li><li>  To study the stability of the parser.  Will the processing time per page and the amount of memory consumed increase with an increase in the number of iterations? </li><li>  How the speed of parsing and memory consumption depends on the size of the HTML document. </li><li>  Well, evaluate the effectiveness of the platform: the speed of working with strings, the effectiveness of memory management </li></ul><br>  We will not check the quality of the work of the parser in terms of completeness of the restoration of broken documents.  Comparison of the convenience of the API and the availability of tools for working with a tree will also be left behind the scenes. <br><br><h3>  Test conditions and methods </h3><br>  The program once reads the document from the disk into memory and then N parses it sequentially in a loop. <br>  The parser on each iteration should build in memory the full DOM tree. <br>  After N iterations, the program prints the cycle time and ends. <br><br>  Each parser is launched on a set of several HTML documents at N = 10, 50, 100, 400, 600 and 1000 iterations. <br>  We measure User CPU, System CPU, Real runtime and (approximate?) Peak memory usage with <code>/usr/bin/time</code> . <br>  HTML documents: <br><ul><li>  <em>page_google.html</em> (116Kb) - Google output, 50 results per page.  A lot of HTML and JS embedded in the page, a little text, all HTML in one line. </li><li>  <em>page_habrahabr-70330.html</em> (1,6Mb) - article on habre with 900 comments.  A very large page, many tags, spaces and tabs. </li><li>  <em>page_habrahabr-index.html</em> (95Kb) - the main page of habrahabr.  Typical blog page. </li><li>  <em>page_wikipedia.html</em> (99Kb) - an article on wikipedia.  I wanted a page with a lot of text and few tags, but I chose not the most successful one.  As a result, a lot of tags and inline CSS. </li></ul><br>  In fact, I realized that most of the documents are the same size only at the end, but did not redo it, because  the measurement process itself takes quite some time.  And it would be interesting to track various dependencies on the page size as well.  UPD: the second part of the article is being prepared; we will parse the sites from Alexa TOP1000 in it. <br><br>  Tests run sequentially on Ubuntu 3.5.0-19-generic x86_64, processor Intel Core i7-3930K CPU @ 3.20GHz √ó 12. (Haha 12 cores, if the tests run in series? Ehh ...) <br><br><h3>  Code </h3><br>  All <a title="html parser benchmark code" href="https://github.com/seriyps/html-parsers-benchmark">code is available on github</a> .  You can try to run it yourself, detailed instructions are in the readme file.  Not even - I strongly recommend not to believe me, but to check how the tests on your environment behave! <br>  <em>Tip: if you want to test only part of the platforms (for example, you do not want to install Erlang or PyPy for yourself), then this is easily set by the PLATFORMS environment variable.</em> <br>  I will be glad to pull-requests with the implementation of parsers in other languages ‚Äã‚Äã(PHP? Java? <s>.NET?</s> Ruby?), I will try to add to the results (native implementations are interesting first of all - binding to libxml usually do not differ in speed).  It would be interesting to try running tests on some other interesting HTML files (large nesting of tags, different file sizes). <br><br><h3>  results </h3><br>  Here are the raw measurement results as a CSV file <a href="">results-1000.csv</a> <a href="">results-600.csv</a> <a href="">results-400.csv</a> <a href="">results-100.csv</a> <a href="">results-50.csv</a> <a href="">results-10.csv</a> .  Let's try to analyze them, for this we use the script in the R language (located in the repository with the benchmark in the stats / folder). <br><br><h4>  Speed </h4><br>  To study the dependence of the speed of the parser on the number of iterations, we construct histograms of the dependence of [time to process one page] on [the number of iterations].  We consider the time for processing one page as the runtime of the parser divided by the number of iterations.  Ideally, the speed of the parser should not depend on the number of iterations, and better - should increase (due to <abbr title="Just in time compiler">JIT</abbr> for example). <br>  All graphics are clickable!  Do not break your eyes! <br><br>  <strong>Dependence of the processing time of the document on the number of iterations of the parser (hereinafter, there is a separate chart for each HTML page).</strong> <br> <a href=""><img alt="html_parser_bench_pre-001" src="https://habrastorage.org/getpro/habr/post_images/046/740/406/04674040639f36faabe89c27ae327bd4.png" width="500" height="350"></a> <a href=""><img alt="html_parser_bench_pre-002" src="https://habrastorage.org/getpro/habr/post_images/9e1/c9f/8d1/9e1c9f8d1a04d078f7f95c12d676753b.png" width="500" height="350"></a> <a href=""><img alt="html_parser_bench_pre-003" src="https://habrastorage.org/getpro/habr/post_images/04e/1cf/590/04e1cf590998be19d2ae99d6633e48d1.png" width="500" height="350"></a> <a href=""><img alt="html_parser_bench_pre-004" src="https://habrastorage.org/getpro/habr/post_images/7d1/a54/d0a/7d1a54d0a796bb060ebd203146615cd3.png" width="500" height="350"></a> <br>  Bars of the same height - good, different - bad.  It can be seen that for most parsers there is no dependency (all columns of the same height).  The only exceptions are <em>BeautifulSoup 4</em> and <em>html5lib</em> under PyPy;  for some reason, with increasing number of iterations, their performance decreases.  That is, if your parser on PyPy should work for a long time, the performance will gradually decrease.  Suddenly‚Ä¶ <br><br>  Now the most interesting graph is the average processing speed of one page by each parser.  Construct a box-plot chart. <br>  <strong>The average time to process a document.</strong> <br> <a href=""><img alt="html_parser_bench_pre-005" src="https://habrastorage.org/getpro/habr/post_images/c48/960/165/c4896016545b40979444ad965c1d5152.png" width="500" height="350"></a> <a href=""><img alt="html_parser_bench_pre-006" src="https://habrastorage.org/getpro/habr/post_images/a3f/f04/d88/a3ff04d88d51b0a0412df52314110b92.png" width="500" height="350"></a> <a href=""><img alt="html_parser_bench_pre-007" src="https://habrastorage.org/getpro/habr/post_images/35b/ddb/b5a/35bddbb5a2cb0f0033a0439893ae25d9.png" width="500" height="350"></a> <a href=""><img alt="html_parser_bench_pre-008" src="https://habrastorage.org/getpro/habr/post_images/6ea/6d4/e8a/6ea6d4e8a11a5c539a4944527829bdb9.png" width="500" height="350"></a> <br>  The higher is the box - the slower the parser works.  The larger the box by area, the greater the spread of values ‚Äã‚Äã(i.e., the higher the performance dependence on the number of iterations).  It can be seen that the parser on C is in the lead, followed by <em>lxml.etree</em> , closely to the parsers on NodeJS and Erlang, then the <em>bsoup3</em> parser on PyPy, the parsers on CPython and then by a large margin the same parsers running on PyPy.  Such a surprise!  PyPy merges everything. <br>  Another oddity - bsoup 3 to the Python parser didn‚Äôt like the Wikipedia page :-). <br><br>  Sample tabular data: <br><pre>  &gt; subset (res, (file == "page_google.html") &amp; (loops == 1000)) [c ("platform", "parser", "parser.s", "real.s", "user.s ")]
     platform parser parser.s real.s user.s
 6 c-libxml2 libxml2_html_parser.c 2.934295 2.93 2.92
 30 erlang mochiweb_html.erl 13.346997 13.51 13.34
 14 nodejs cheerio_parser.js 5.303000 5.37 5.36
 38 nodejs htmlparser_parser.js 6.686000 6.72 6.71
 22 nodejs jsdom_parser.js 98.288000 98.42 98.31
 33 pypy bsoup3_parser.py 40.779929 40.81 40.62
 57 pypy bsoup4_parser.py 434.215878 434.39 433.91
 41 pypy html5lib_parser.py 361.008080 361.25 360.46
 65 python bsoup3_parser.py 78.566026 78.61 78.58
 49 python bsoup4_parser.py 33.364880 33.45 33.43
 60 python html5lib_parser.py 200.672682 200.71 200.70
 67 python by lxml_parser.py 3.060202 3.08 3.08 </pre><br><br><h4>  Memory </h4><br>  Now look at the memory usage.  First, let's see how memory consumption depends on the number of iterations.  Build the histograms again.  Ideally, all the columns of the same parser should be the same height.  If consumption grows with an increase in the number of iterations, this indicates memory leaks or problems with the garbage collector. <br>  <strong>Memory consumption depending on the number of iterations of the parser.</strong> <br> <a href=""><img alt="html_parser_bench_pre-009" src="https://habrastorage.org/getpro/habr/post_images/a53/2c7/265/a532c7265c5faa249d9f58a1fb124003.png" width="500" height="350"></a> <a href=""><img alt="html_parser_bench_pre-010" src="https://habrastorage.org/getpro/habr/post_images/1a4/2e4/6bf/1a42e46bfa4e0f5f55d9964babbd0244.png" width="500" height="350"></a> <br>  It is interesting.  <em>Bsoup4</em> and <em>html5lib</em> under PyPy occupied 5 GB of memory after 1000 iterations of 1 MB file.  (He brought here only 2 graphics, because the rest is the same picture).  It can be seen that with an increase in the number of iterations, the memory consumed grows almost linearly.  It turns out that PyPy is simply not compatible with <em>Bsoup4</em> and <em>html5lib</em> parsers.  I don‚Äôt know what is the reason for it and who is to blame, but it‚Äôs clear that using PyPy without thorough checking of compatibility with all used libraries is a very risky task. <br>  It turns out that the combination of PyPy with these parsers is eliminated.  Let's try to remove them from the charts: <br>  <strong>Memory consumption depending on the number of iterations of the parser (without Bsoup4 and html5lib on PyPy).</strong> <br> <a href=""><img alt="html_parser_bench_dropped_pre-009" src="https://habrastorage.org/getpro/habr/post_images/541/4d9/e61/5414d9e614fbcff7741b50517267a9ee.png" width="500" height="350"></a> <a href=""><img alt="html_parser_bench_dropped_pre-010" src="https://habrastorage.org/getpro/habr/post_images/918/7ef/75f/9187ef75f81768622c01278edd9c00a0.png" width="500" height="350"></a> <a href=""><img alt="html_parser_bench_dropped_pre-011" src="https://habrastorage.org/getpro/habr/post_images/0dc/f25/dad/0dcf25dad482414122da2cae5b0c0681.png" width="500" height="350"></a> <a href=""><img alt="html_parser_bench_dropped_pre-012" src="https://habrastorage.org/getpro/habr/post_images/c9c/f1c/01d/c9cf1c01d199c5bafdc2d6566235ae3e.png" width="500" height="350"></a> <br>  We see that for the parser on C all columns are almost identical in height.  Same for <em>lxml.etree</em> .  For most parsers, memory consumption at 10 iterations is slightly less.  Perhaps just <code>time</code> does not have time to measure it.  The jsdom NodeJS parser behaves quite strangely - its memory consumption for some pages jumps in a very random way, but in general you can see an increase in memory consumption over time.  Perhaps some problems with garbage collection. <br><br>  Compare the average memory consumption for the remaining parsers.  Construct a box plot. <br>  <strong>Average memory consumption.</strong> <br> <a href=""><img alt="html_parser_bench_dropped_pre-013" src="https://habrastorage.org/getpro/habr/post_images/dc7/8f9/819/dc78f9819c58760b0f0e6cd9a75c895a.png" width="500" height="350"></a> <a href=""><img alt="html_parser_bench_dropped_pre-014" src="https://habrastorage.org/getpro/habr/post_images/8d9/df2/7ca/8d9df27ca7b00e832830507848f950a7.png" width="500" height="350"></a> <a href=""><img alt="html_parser_bench_dropped_pre-015" src="https://habrastorage.org/getpro/habr/post_images/0e1/56b/42e/0e156b42e0210c72c5b598c265c8bbe8.png" width="500" height="350"></a> <a href=""><img alt="html_parser_bench_dropped_pre-016" src="https://habrastorage.org/getpro/habr/post_images/4f3/696/8ee/4f36968ee454b8060a4f747871cb2719.png" width="500" height="350"></a> <br>  We see that the arrangement is about the same as in comparison of speed, but Erlang memory consumption was lower than that of NodeJS.  <em>lxml.etree</em> requires approximately 2 times more memory than C <em>libxml2</em> , but less than any other parser.  Jsdom's NodeJS parser <em>drops</em> out of the overall picture, consuming ~ 2 times more memory than other NodeJS parsers - apparently it has a significant overhead associated with creating additional attributes for DOM elements of the tree. <br>  Sample tabular data: <br><pre> &gt; subset (res, (file == "page_google.html") &amp; (loops == 1000)) [c ("platform", "parser", "maximum.RSS")]
     platform parser maximum.RSS
 6 c-libxml2 libxml2_html_parser.c 2240
 30 erlang mochiweb_html.erl 21832
 14 nodejs cheerio_parser.js 49972
 38 nodejs htmlparser_parser.js 48740
 22 nodejs jsdom_parser.js 119256
 33 pypy bsoup3_parser.py 61756
 57 pypy bsoup4_parser.py 1701676
 41 pypy html5lib_parser.py 1741944
 65 python bsoup3_parser.py 42192
 49 python bsoup4_parser.py 54116
 60 python html5lib_parser.py 45496
 67 python by lxml_parser.py 9364
</pre><br><br><h4>  Overhead on the launch of the program </h4><br>  This is not so much a test of HTML parser as an attempt to find out which platform should be used for writing console utilities.  Just a small addition (since we already have the data).  The platform overhead is the time that the program spends not on working directly, but on preparing for it (initialization of libraries, reading an HTML file, etc.).  To calculate it, subtract from the time that the utility <code>time</code> - ‚Äútime.s‚Äù produced, the time that was measured around the parser's cycle - ‚Äúparser.s‚Äù. <br><br> <a href=""><img alt="html_parser_bench_overhead_pre-001" src="https://habrastorage.org/getpro/habr/post_images/447/7ef/681/4477ef68197fe9b45d9ef5581166433b.png" width="500" height="350"></a> <br><br>  It is seen that the overhead projector is in most cases insignificant.  It is noteworthy that Erlang is comparable to Python.  It can be assumed that it depends on the massiveness of the libraries that the program imports. <br><br><h3>  findings </h3><br>  As you can see, the C implementation is ahead of the rest of the planet (but the code in it turned out to be bigger). <br><br>  Binding libxml2 to python (lxml.etree.HTML) works at almost the same speed, but consumes 2 times more memory (most likely the overhead of the interpreter itself).  So the preferred Python parser is lxml. <br><br>  The parser on bare Erlang shows surprisingly high results, despite the erlang attributed ‚Äúcopying data for every sneeze‚Äù ¬©.  The speed is comparable with simple parsers on NodeJS and higher than that of Python parsers.  Memory consumption is lower only for C and lxml.  Stability is excellent.  Such a parser can be released in production (which I did). <br><br>  Simple parsers on NodeJS work very quickly - 2 times slower than sishna libxml.  V8 works extremely efficiently.  But the memory is consumed at the level of Python, and the memory is not spent very stably (memory consumption can increase with an increase in the number of iterations from 10 to 100, but then stabilizes).  The jsdom parser for simple parsing is clearly not suitable, since  he has too much overhead.  So for HTML parsing in NodeJS the best choice is cheerio. <br><br>  Parsers in pure Python are merged in both speed and memory consumption, and the results jump a lot on different pages.  But at the same time, they behave stably at different numbers of iterations (does GC work evenly?) <br><br>  But most of all surprised PyPy.  Either there are some problems with GC, or the task is not suitable for it, or the parsers are unsuccessful, or I‚Äôve got somewhere, but the performance of the PyPy parsers decreases with increasing number of iterations, and the memory consumption grows linearly.  Bsoup3 parser more or less copes, but its performance is on par with CPython.  Those.  for parsing on PyPy, only Bsoup3 is suitable, but it doesn‚Äôt give significant advantages over CPython. <br><br><h3>  Links </h3><br>  <a title="html parser benchmark code" href="https://github.com/seriyps/html-parsers-benchmark">Benchmark Code</a> <a href="http://seriyps.ru/blog/2012/12/23/benchmark-html-parserov/">My Blog</a> <br>  <a href="http://ru.wikipedia.org/wiki/Document_Object_Model">Document Object Model</a> <br><br>  Send your implementations!  It is very easy! <br><br>  <b>UPD:</b> <br>  <a href="">Results for added parsers (graphics, CSV)</a> : <br>  golang (3 pcs, one faster C (!!!)) <br>  haskell (very good) <br>  java (openjdk, oracle-jre) (automatically parallel, taking up ~ 150% CPU, user CPU&gt; real CPU) <br>  perl <br>  php + tidy <br>  ruby (binding to libxml) <br>  dart (very slow) <br>  mono (2 pcs) (automatically parallel, occupying ~ 150% CPU, user CPU&gt; real CPU) <br><br>  A full article + study of the dependence of speed and memory consumption on page size on Alexa TOP1000 will be later (hopefully). </div><p>Source: <a href="https://habr.com/ru/post/163979/">https://habr.com/ru/post/163979/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../163967/index.html">Creating Guest Access to the Internet with Web Authentication</a></li>
<li><a href="../163969/index.html">High-Load cluster organization with several nodes</a></li>
<li><a href="../163971/index.html">Review of the smartphone Meizu MX2</a></li>
<li><a href="../163973/index.html">Ahead of their time</a></li>
<li><a href="../163975/index.html">Solving a recursive logic puzzle in Oracle SQL</a></li>
<li><a href="../163981/index.html">Zen Reports and% XML.Writer to generate Excel reports in Cach√©</a></li>
<li><a href="../163983/index.html">Why not make a weekly review of the Habrahabr sandbox?</a></li>
<li><a href="../163985/index.html">Autopsy Apple Macintosh LC 580</a></li>
<li><a href="../163989/index.html">Top 5 Things I Learned from IBM Software for System z for Dummies</a></li>
<li><a href="../163991/index.html">Computer in a molded car drive</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>