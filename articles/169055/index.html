<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Optical flux calculation using the Lucas-Canada method. Theory</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="In computer vision and image processing systems, it is often necessary to determine the movement of objects in three-dimensional space using an optica...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Optical flux calculation using the Lucas-Canada method. Theory</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/storage2/c56/792/341/c56792341d136c7bd085dfffa70d5779.png"><img src="https://habrastorage.org/storage2/0d3/713/afb/0d3713afb72f7c4a7087da0465e2c8a9.png"><img src="https://habrastorage.org/storage2/22d/a17/293/22da17293663c2056496223d23a577b2.png"><br>  In computer vision and image processing systems, it is often necessary to determine the movement of objects in three-dimensional space using an optical sensor, that is, a video camera.  Having a sequence of frames at the entrance, it is necessary to recreate the three-dimensional space captured on them and the changes that occur with it over time.  It sounds difficult, but in practice it is often enough to find the displacements of two-dimensional projections of objects in the plane of the frame. <br><br>  If we want to know how much an object has shifted relative to its position on the previous frame during the time elapsed between the fixation of frames, then most likely we will first recall the optical flow.  To find the optical flow, you can safely use the finished tested and optimized implementation of one of the algorithms, for example, from the OpenCV library.  At the same time, however, it is very harmless to understand the theory, so I invite all those interested to look inside one of the most popular and well-studied methods.  In this article, there is no code and practical advice, but there are formulas and a number of mathematical conclusions. <br><a name="habracut"></a><br>  There are several approaches to determining offsets between two adjacent frames.  For example, for each small fragment (say, 8 by 8 pixels) of one frame, it is possible to find the most similar fragment in the next frame.  In this case, the difference between the coordinates of the original and the found fragments will give us an offset.  The main difficulty here is how to quickly find the desired fragment, without going through the entire frame pixel by pixel.  Various implementations of this approach somehow solve the problem of computational complexity.  Some are so successful that they apply, for example, in common video compression standards.  The price for speed is of course quality.  We will consider a different approach, which allows us to obtain offsets not for fragments, but for each individual pixel, and is applied when speed is not so critical.  The term ‚Äúoptical flow‚Äù is often associated with it in the literature. <br><br>  This approach is often called differential, because it is based on the calculation of partial derivatives in the horizontal and vertical directions of the image.  As we shall see, the derivatives alone are not enough to determine the displacements.  That is why, on the basis of one simple idea, a great variety of methods appeared, each of which uses some of its mathematical dance with a tambourine to achieve the goal.  Focus on the Lucas-Kanade method, proposed in '81 by Bruce Lucas and Takeo Canada. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h5>  Lucas-Canada method </h5><br>  The basis of all further reasoning is one very important and not very fair assumption: <b>Suppose that the pixel values ‚Äã‚Äãare transferred from one frame to the next without any changes</b> .  Thus, we assume that the pixels belonging to the same object may move in some direction, but their value will remain unchanged.  Of course, this assumption has little to do with reality, because global conditions of illumination and illumination of the moving object itself may vary from frame to frame.  A lot of problems associated with this assumption, but, oddly enough, despite everything, it works quite well in practice. <br><br>  In mathematical language, this assumption can be written as: <img src="https://habrastorage.org/storage2/4fd/e7a/3d9/4fde7a3d92ae567e10873bb556099c47.png">  .  Where I is the function of the brightness of pixels from the position on the frame and the time.  In other words, x and y are the coordinates of a pixel in the frame plane, <img src="https://habrastorage.org/storage2/53f/5e6/85e/53f5e685efef6a8aa47f60314070bb2a.png">  and <img src="https://habrastorage.org/storage2/ed7/d38/ced/ed7d38ced9167cb2f11ea553371c7c45.png">  Is the offset, and t is the frame number in the sequence.  We will agree that a single interval of time passes between two adjacent frames. <br><br><h6>  One-dimensional case </h6><br><img src="https://habrastorage.org/storage2/201/6cc/59d/2016cc59d47b0dd7889a0933db6a6f1c.png" align="right">  To begin, consider the one-dimensional case.  Imagine two one-dimensional frames 1 pixel high and 20 pixels wide (right figure).  In the second frame, the image is slightly shifted to the right.  This is the offset we want to find.  To do this, we represent the same frames as functions (figure on the left). <img src="https://habrastorage.org/storage2/2a4/52b/0a7/2a452b0a78e1525551e1b95ea29bdafb.png" align="left">  At the input, the position of the pixel, at the output - its intensity.  In such a view, the desired displacement (d) can be seen even more clearly.  In accordance with our assumption <img src="https://habrastorage.org/storage2/44d/2f8/6f2/44d2f86f2674a5d747627ec759ed922a.png">  it's just biased <img src="https://habrastorage.org/storage2/7cd/19f/d85/7cd19fd851b01049b0186c792144eac1.png">  that is, we can say that <img src="https://habrastorage.org/storage2/8cf/0c5/b31/8cf0c5b31eb1bbb6107a620eaf9e4f04.png">  . <br><br>  note that <img src="https://habrastorage.org/storage2/7cd/19f/d85/7cd19fd851b01049b0186c792144eac1.png">  and <img src="https://habrastorage.org/storage2/44d/2f8/6f2/44d2f86f2674a5d747627ec759ed922a.png">  if you wish, you can write in the general form: <img src="https://habrastorage.org/storage2/210/c96/3ff/210c963ffbc1cc7a484ee8b3ca25a906.png">  ; <img src="https://habrastorage.org/storage2/ed6/df4/043/ed6df40430e284889eae6dc4278f3eb0.png">  where y and t are fixed and equal to zero. <br><br>  For each coordinate, we know the values <img src="https://habrastorage.org/storage2/7cd/19f/d85/7cd19fd851b01049b0186c792144eac1.png">  and <img src="https://habrastorage.org/storage2/44d/2f8/6f2/44d2f86f2674a5d747627ec759ed922a.png">  at this point, moreover, we can calculate their derivatives.  We associate the known values ‚Äã‚Äãwith the offset d.  To do this, we write the decomposition in the <a href="http://ru.wikipedia.org/wiki/%25D0%25A0%25D1%258F%25D0%25B4_%25D0%25A2%25D0%25B5%25D0%25B9%25D0%25BB%25D0%25BE%25D1%2580%25D0%25B0">Taylor series</a> for <img src="https://habrastorage.org/storage2/9c4/409/a76/9c4409a762edbb58268309ab409ae711.png">  : <br><br><img src="https://habrastorage.org/storage2/644/ad4/36c/644ad436c7a20e2f2ee4fd2e5993d532.png"><br><br>  We make the second important assumption: <b>Suppose that</b> <b><img src="https://habrastorage.org/storage2/9c4/409/a76/9c4409a762edbb58268309ab409ae711.png"></b>  <b>fairly well approximated by the first derivative</b> .  Having made this assumption, we drop everything after the first derivative: <br><br><img src="https://habrastorage.org/storage2/537/d79/e12/537d79e127a86291c4fe166fa6d4fcb1.png"><br><br>  How correct is this?  In general, not very, here we lose exactly, unless our function / image is strictly linear, as in our artificial example.  But this greatly simplifies the method, and to achieve the required accuracy, you can make a consistent approximation, which we will consider later. <br><br>  We are almost there.  The offset d is our desired quantity, so something needs to be done with <img src="https://habrastorage.org/storage2/9c4/409/a76/9c4409a762edbb58268309ab409ae711.png">  .  As we agreed earlier, <img src="https://habrastorage.org/storage2/8cf/0c5/b31/8cf0c5b31eb1bbb6107a620eaf9e4f04.png">  so just rewrite: <br><br><img src="https://habrastorage.org/storage2/30c/3ce/c04/30c3cec0414e02df6fba4dcddc19b6a5.png"><br><br>  I.e: <br><br><img src="https://habrastorage.org/storage2/ce0/c5b/6fc/ce0c5b6fc559bbb714c3ca28b29273a3.png"><br><br><h6>  Two-dimensional case </h6><br>  We now turn from one-dimensional to two-dimensional case.  We write the decomposition in the Taylor series for <img src="https://habrastorage.org/storage2/00d/8a9/2c0/00d8a92c03891cbae0dba5936c9cafa3.png">  and immediately discard all higher derivatives.  Instead of the first derivative, a gradient appears: <br><br><img src="https://habrastorage.org/storage2/5e6/4ca/eaa/5e64caeaab60ae40a5bcb6838f819702.png"><br><br>  Where <img src="https://habrastorage.org/storage2/cb1/29c/3fb/cb129c3fb7ff81cbaa1863b14e84b3c3.png">  - displacement vector. <br>  In accordance with the assumption made <img src="https://habrastorage.org/storage2/4fd/e7a/3d9/4fde7a3d92ae567e10873bb556099c47.png">  .  Note that this expression is equivalent to <img src="https://habrastorage.org/storage2/bb4/670/2e9/bb46702e9beba60a4afe121b67b6fc74.png">  .  That's what we need.  Rewrite: <br><br><img src="https://habrastorage.org/storage2/0f9/2f0/331/0f92f033163524f56361bceff9e0728e.png"><br><br><img src="https://habrastorage.org/storage2/e53/26f/cd8/e5326fcd8c99e7dcdf46deaba9cc00c5.png"><br><br>  Since there is a unit time interval between two frames, it can be said that <img src="https://habrastorage.org/storage2/8e6/cfd/49b/8e6cfd49b217e4ff2952e6ac6c4de4de.png">  is nothing but a time derivative. <br>  Rewrite: <br><br><img src="https://habrastorage.org/storage2/91d/1b0/30d/91d1b030d1bbad7b0a5f779608886ce3.png"><br><br>  Rewrite again, revealing a gradient: <br><br><img src="https://habrastorage.org/storage2/d51/107/204/d5110720490a77507ecfc88fc9c389a2.png"><br><br>  We have obtained an equation that tells us that the sum of the partial derivatives should be zero.  The only problem is that we have one equation, and two unknowns in it: <img src="https://habrastorage.org/storage2/53f/5e6/85e/53f5e685efef6a8aa47f60314070bb2a.png">  and <img src="https://habrastorage.org/storage2/ed7/d38/ced/ed7d38ced9167cb2f11ea553371c7c45.png">  .  At this moment, the flight of fantasy and diversity of approaches begins. <br><br>  Make the third assumption: <b>Suppose that the neighboring pixels are shifted by the same distance</b> .  Take a fragment of the image, say 5 by 5 pixels, and agree that for each of the 25 pixels <img src="https://habrastorage.org/storage2/53f/5e6/85e/53f5e685efef6a8aa47f60314070bb2a.png">  and <img src="https://habrastorage.org/storage2/ed7/d38/ced/ed7d38ced9167cb2f11ea553371c7c45.png">  are equal.  Then instead of one equation we get 25 equations at once!  It is obvious that in the general case the system has no solution, therefore we will look for such <img src="https://habrastorage.org/storage2/53f/5e6/85e/53f5e685efef6a8aa47f60314070bb2a.png">  and <img src="https://habrastorage.org/storage2/ed7/d38/ced/ed7d38ced9167cb2f11ea553371c7c45.png">  that minimize the error: <br><br><img src="https://habrastorage.org/storage2/0f4/37e/0d7/0f437e0d78de4c4d4c6d2823f455886c.png"><br><br>  Here g is the function that determines the weights for the pixels.  The most common option is a two-dimensional Gaussian, which gives the greatest weight to the central pixel and less and less as the distance from the center. <br><br>  To find the minimum <img src="https://habrastorage.org/storage2/d39/66a/b2e/d3966ab2e35c25163ba49f02786439d7.png">  let's use the least squares method, find its partial derivatives with respect to <img src="https://habrastorage.org/storage2/53f/5e6/85e/53f5e685efef6a8aa47f60314070bb2a.png">  and <img src="https://habrastorage.org/storage2/ed7/d38/ced/ed7d38ced9167cb2f11ea553371c7c45.png">  : <br><br><img src="https://habrastorage.org/storage2/09f/33c/7bc/09f33c7bcd20f66a0d22d20576c6fc7f.png"><br><br><img src="https://habrastorage.org/storage2/52e/3c0/238/52e3c023850d104b16da99d7489081b1.png"><br><br>  Rewrite in a more compact form and equate to zero: <br><br><img src="https://habrastorage.org/storage2/f6a/05e/dbd/f6a05edbdbe59f995fb532b09b736f0d.png"><br><br><img src="https://habrastorage.org/storage2/f82/fcb/fa1/f82fcbfa1cc383ca7641d2aaedb6d2dc.png"><br><br>  Rewrite these two equations in matrix form: <br><br><img src="https://habrastorage.org/storage2/4bf/580/2e7/4bf5802e7f57cfc47d85aafe97e213ad.png"><br><br>  Where <br><br><img src="https://habrastorage.org/storage2/ad6/e7d/ad5/ad6e7dad507b089f83e3e33f0a60d639.png"><br><br><img src="https://habrastorage.org/storage2/a18/74e/56d/a1874e56d4ce4cc79677b0149341982c.png"><br><br><img src="https://habrastorage.org/storage2/2b7/4d8/014/2b74d8014696ab5a958deffda18432bc.png"><br><br>  If the matrix M is reversible (has rank 2), we can calculate <img src="https://habrastorage.org/storage2/53f/5e6/85e/53f5e685efef6a8aa47f60314070bb2a.png">  and <img src="https://habrastorage.org/storage2/ed7/d38/ced/ed7d38ced9167cb2f11ea553371c7c45.png">  that minimize the error E: <br><br><img src="https://habrastorage.org/storage2/979/a80/7d3/979a807d3ca1877868aed548f4eff71d.png"><br><br>  That's all.  We know the approximate pixel offset between two adjacent frames. <br><br>  Since neighboring pixels also take part in finding the offset of each pixel, when implementing this method, it is advisable to preliminarily calculate the frame derivatives horizontally and vertically. <br><br><h5>  Method disadvantages </h5><br>  The method described above is based on three significant assumptions, which, on the one hand, give us a fundamental opportunity to determine the optical flux, but, on the other hand, introduce an error.  The good news for perfectionists is that we only need one assumption to simplify the method, and we can deal with its consequences. <img src="https://habrastorage.org/storage2/5c5/c02/7a9/5c5c027a9e6415739d8f9a5a171fa4ec.png" align="left">  We assumed that the first derivative would be enough for us to approximate the bias.  In the general case, this is certainly not the case (left figure).  To achieve the required accuracy, the offset for each pair of frames (let's call them <img src="https://habrastorage.org/storage2/cf2/8ce/47c/cf28ce47c93eb038a32271b41f5dd8c4.png">  and <img src="https://habrastorage.org/storage2/271/bde/100/271bde1006a0bc5440e7e0a1caf4ea6d.png">  ) can be calculated iteratively.  In the literature, this is called warping.  In practice, this means that by calculating the offsets at the first iteration, we move each pixel of the frame <img src="https://habrastorage.org/storage2/271/bde/100/271bde1006a0bc5440e7e0a1caf4ea6d.png">  in the opposite direction so that this offset is compensated.  At the next iteration instead of the original frame <img src="https://habrastorage.org/storage2/271/bde/100/271bde1006a0bc5440e7e0a1caf4ea6d.png">  we will use its distorted version <img src="https://habrastorage.org/storage2/4a9/8e2/f6d/4a98e2f6d6bf3fe367aee632fb9ddd13.png">  .  And so on, until at the next iteration all the resulting offsets will not be less than the specified threshold value.  We get the total offset for each specific pixel as the sum of its offsets at all iterations. <br><br>  By its nature, this method is local, that is, when determining the offset of a particular pixel, only the area around this pixel is taken into account - a local neighborhood.  As a consequence, it is impossible to determine the displacements within sufficiently large (larger than the size of the local neighborhood) of uniformly colored frame areas.  Fortunately, on real frames such areas are not often found, but this feature still introduces an additional deviation from the true offset. <br><br>  Another problem is that some textures in the image give a degenerate matrix M, for which the inverse matrix cannot be found.  Accordingly, for such textures we will not be able to determine the offset.  That is, the movement seems to be there, but it is not clear which way.  In general, not only the method considered suffers from this problem.  Even the human eye perceives such a movement is not uniquely ( <a href="">Barber pole</a> ). <br><br><h5>  Conclusion </h5><br>  We have analyzed the theoretical foundations of one of the differential methods for finding the optical flow.  There are many other interesting methods, some of which, as of today, give more reliable results.  However, the method of Lucas-Canada, with its good performance remains simple enough to understand, and therefore well suited for familiarizing with the mathematical foundations. <br><br>  Although the problem of finding the optical flux has been studied for several decades, methods are still being improved.  The work continues in view of the fact that, upon close examination, the problem turns out to be very difficult, and the quality and definition of displacements in video and image processing determines the stability and efficiency of many other algorithms. <br><br>  On this pathetic note, let me round out and go to the sources and useful links. <br><br><h5>  Sources and references </h5><br>  1. Optical Flow Estimation.  David J. Fleet, Yair Weiss.  - Detailed article, which contains a detailed description of not only the method of Lucas-Canada, but also other differential methods. <br>  2. Image and Video Compression for Multimedia Engineering: Fundamentals, Algorithms, and Standards.  Yun Q. Shi, Huifang Sun - Tutorial on compressing video and images, but also contains a good overview of the background. <br>  3. <a href="http://www.ipol.im/">Image Processing On Line</a> - A large number of actual image processing algorithms.  Best of all, the algorithms are equipped with an online <a href="http://demo.ipol.im/demo/smf_tvl1_optical_flow_estimation/">demo</a> . </div><p>Source: <a href="https://habr.com/ru/post/169055/">https://habr.com/ru/post/169055/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../169039/index.html">What do Win32 / Redyms and TDL4 have in common?</a></li>
<li><a href="../169043/index.html">Leap Motion. Unpacking and small overview</a></li>
<li><a href="../169047/index.html">How to quickly create a survey on your site using Google forms?</a></li>
<li><a href="../169049/index.html">Manage Network Folders with PowerShell</a></li>
<li><a href="../169051/index.html">Responsive design using camera</a></li>
<li><a href="../169059/index.html">Judgments, conclusions, syllogisms ... or the achievements of ancient logic in one post</a></li>
<li><a href="../169061/index.html">Bill Gates Answers Reddit User Questions</a></li>
<li><a href="../169063/index.html">Wireless charging available on Google Play</a></li>
<li><a href="../169067/index.html">IBM Watson graduated from medical school and went to work</a></li>
<li><a href="../169069/index.html">Display the electricity meter on the Internet</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>