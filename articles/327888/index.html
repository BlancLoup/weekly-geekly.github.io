<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Ros. Navigation stack</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="This article will look at the approaches and libraries provided by ROS for solving problems of autonomous and not very navigation. 


 There will also...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Ros. Navigation stack</h1><div class="post__text post__text-html js-mediator-article"><p><img src="https://habrastorage.org/files/6ca/ec6/fc5/6caec6fc5d694b07b3050704076ec131.png" alt="title"></p><br><p>  This article will look at the approaches and libraries provided by ROS for solving problems of autonomous and not very navigation. </p><br><p>  There will also be considered several packages specific for anthropomorphic robots.  Any robot (surely even a machine with a mid-powerful on-board PC running Linux and a couple of webcams) will surely find something for themselves here. </p><a name="habracut"></a><br><p>  If the hardware is too weak for such calculations, you can use the distribution of ROS, which allows the nodes on different machines to interact with each other.  A similar option is described <a href="http://wiki.ros.org/rtabmap_ros/Tutorials/SetupOnYourRobot">here</a> . </p><br><h2 id="tezarus">  Tesarus </h2><br><h3 id="karta-prepyatstviy-occupancy-map-grid">  Obstacle map (Occupancy Map, Grid) </h3><br><p><img src="https://habrastorage.org/files/3e3/e5f/3c4/3e3e5f3c4a34492fa7b43d5a76847598.png" alt="occupancy_grid"></p><br><p>  A two-dimensional discrete map, in which each cell can be in one of three states: </p><br><ul><li><img src="https://habrastorage.org/files/fb7/287/7d1/fb72877d10574068b0ce91b0acb772ce.png" alt="occupied_cell"></li><li><img src="https://habrastorage.org/files/fb8/be1/e1a/fb8be1e1a03b4903a6cd71cc7b0af4c7.png" alt="free_cell"></li><li><img src="https://habrastorage.org/files/def/294/381/def29438175d4fcc956ba5b1d5c9c2d1.png" alt="unknown_cell"></li></ul><br><h3 id="oblako-tochek-pointcloud">  Point Cloud (PointCloud) </h3><br><p><img src="https://habrastorage.org/files/8f7/5cc/27a/8f75cc27ae1a41f4a48619047511023a.png" alt="point_cloud"></p><br><p>  In ROS, point clouds exist mainly in the form of <a href="http://docs.ros.org/api/sensor_msgs/html/msg/PointCloud2.html">sensor_msgs / PointCloud2</a> . </p><br><h3 id="plotnoe-oblako-tochek">  Dense point cloud </h3><br><p><img src="https://habrastorage.org/files/bfc/dff/157/bfcdff1578b44411ba62685178606e95.png" alt="octree"></p><br><p>  Analogue to Occupancy Grid, but in 3D. </p><br><p>  In this article, the default will be the implementation from the <a href="https://octomap.github.io/">Octomap</a> library. <br>  A good analysis of the library in <a href="http://www2.informatik.uni-freiburg.de/~hornunga/pub/hornung13roscon.pdf">this presentation</a> . </p><br><h3 id="koncepciya-nod--topikov--podpischikov">  Concept nodes / topics / subscribers </h3><br><p>  In short, you can run your program in the context of ROS, where it will be a node (Node). <br>  There are also Topics.  These are sort of named boxes into which nodes can add and retrieve messages of various types (for example, objects of types geometry_msgs :: Pose, sensor_msgs :: PointCloud2, nav_msgs :: Path, and many others). </p><br><p>  Any of the nodes can publish to any topics, as well as read messages from any topics. <br>  Nodes work asynchronously from each other. </p><br><p>  If not quite briefly, then </p><br><ul><li>  <a href="http://wiki.ros.org/ROS/Tutorials">tutorials</a> </li><li>  <a href="http://wiki.ros.org/roscpp/Overview">roscpp</a> </li></ul><br><h2 id="ros">  Ros </h2><br><p>  <a href="http://www.ros.org/core-components/"><strong>Robot operating system</strong></a> is a very convenient platform for the implementation of robotic projects. <br><img src="https://habrastorage.org/files/00b/bb1/519/00bbb151957e4736b9276bc645bb9d8c.png" alt="ros_pipeline"></p><br><ul><li>  Successful package concept (you can use the library functionality, simply by running the appropriate node) </li><li>  Provides many needed packages for robotics <br>  In particular, the stacks are well developed: <br><ul><li>  Navigation </li><li>  Localization </li><li>  Mapping (SLAM algorithms) </li></ul></li><li>  Provides visualizers, a convenient concept for messages and subscribers, and much more. </li></ul><br><p>  <a href="http://www.ros.org/core-components/">Details</a> </p><br><h2 id="slam-s-angl-odnovremennaya-lokalizaciya-i-kartografiya">  SLAM (with English. Simultaneous localization and cartography) </h2><br><p><img src="https://habrastorage.org/files/36e/d60/eaa/36ed60eaa59248d0a061ab25dc8f4065.png" alt="slam"></p><br><p>  For autonomous navigation, and indeed anything that requires complete information about the environment, you need a map of the environment itself. </p><br><p>  For these tasks, a map in the form of a cloud of points is well suited, from which you can later obtain other map options (dense point cloud, OccupancyGrid). </p><br><p>  Vision-based SLAM algorithms allow you to build an environment map and approximately estimate your location in it. </p><br><h3 id="na-vhode">  <strong>At the entrance</strong> </h3><br><p><img src="https://habrastorage.org/files/fc1/402/32d/fc140232d7ec4f96ac53dc50c418daab.png" alt="datasources"></p><br><h4 id="dannye-s-datchikov-pomogayuschih-ocenit-mestopolozhenie">  Data from sensors to help assess the location. </h4><br><p>  For example: </p><br><ul><li>  Ins </li><li>  Motor data </li><li>  etc. </li></ul><br><h4 id="dannye-s-vision-datchikov">  Data from Vision Sensors </h4><br><h5 id="rgb-d-camera">  RGB-D Camera </h5><br><p><img src="https://habrastorage.org/files/bec/a45/ca7/beca45ca738e4fc2acf0790350982cd0.png" alt="rgbd"></p><br><ul><li>  Representatives: Kinect, Real Sence, Asus Xtion </li><li>  Provides RGB snapshot and depth map </li><li>  Well supported by small libraries. </li><li>  Gives acceptable accuracy (depending on the distance. From 1 mm to 5 cm) </li><li>  Range 4 meters </li><li>  Blind zone 0.5 meter </li><li>  <a href="http://docs.ros.org/api/sensor_msgs/html/msg/PointCloud2.html">sensor_msgs / PointCloud2</a> </li></ul><br><h5 id="stereo-camera">  Stereo camera </h5><br><p><img src="https://habrastorage.org/files/00b/ce5/5cb/00bce55cb2bc43e7ab7f47ac07ad2298.png" alt="stereo"></p><br><ul><li>  High range </li><li>  Virtually no blind spot </li><li>  Accuracy is lower than RGB-D cameras </li><li>  A couple of webcams are not a good stereo camera ( <em>but what the hell is not joking</em> ) </li></ul><br><h5 id="lidar">  Lidar </h5><br><p><img src="https://habrastorage.org/files/f55/7ed/af1/f557edaf15ed40a3a1cb44206c6e243a.png" alt="lidar"></p><br><ul><li>  Very high range </li><li>  No less high cost </li><li>  <a href="http://docs.ros.org/api/sensor_msgs/html/msg/LaserScan.html">sensor_msgs / LaserScan</a> </li></ul><br><h3 id="na-vyhode">  <strong>At the exit</strong> </h3><br><ul><li>  Environment Map </li><li>  Location approximation </li></ul><br><h3 id="slam-pakety-v-ros">  SLAM packages in ROS </h3><br><p>  <strong>Note</strong> : in ROS you can receive point clouds from stereo cameras or RGB-D cameras.  In turn, point clouds can be converted to LaserScan, which is the running format of ROS messages for lidars and is received by some of the packages described below. </p><br><p>  This means that having a stereo camera on hand, you will most likely be able to use SLAM algorithms that receive data from Lidars or RGB-D cameras.  Similarly for RGB-D cameras, you can use them as Lidars. </p><br><h4 id="rtabmap_roswikirosorgrtabmap_ros">  <a href="http://wiki.ros.org/rtabmap_ros">rtabmap_ros</a> </h4><br><p>  ROS package providing wrapper over rtabmap <a href="https://introlab.github.io/rtabmap/">library</a> .  Probably the most popular, easy to use and versatile package. </p><br><ul><li>  Quality documentation </li><li>  Supports many sensors as data sources (RGB-D range of cameras, stereo cameras, lidars) </li><li>  Moderately demanding of resources, even when creating large maps (enough laptop with an Intel Core i3 + 4 GB RAM) </li><li>  It has many interesting settings that affect the speed of work / quality </li><li>  Provides many advanced features. <br>  For example: <br><ul><li>  builds an obstacle map by projecting groups of points, starting at a certain height </li><li>  has integration with move_base (see below) </li><li>  has a segmentation node of a point cloud into 2 other clouds (obstacles and earth) </li></ul></li><li>  Integration with the Octomap library (special structures for creating, storing and processing dense point clouds) </li></ul><br><h4 id="hector_slamhttpwikirosorghector_slam">  <a href="http://wiki.ros.org/hector_slam">hector_slam</a> </h4><br><p>  SLAM algorithm that builds a 2D obstacle map. <br>  By default, it uses data from lidar, but <br>  with the same success, it can input data from a stereo camera, an RGB-D camera to the input (see the note at the beginning of the chapter). </p><br><p>  Close relatives: <a href="http://wiki.ros.org/gmapping">slam_gmapping</a> . <br>  Surely these are the most lightweight implementations of SLAM algorithms. </p><br><h4 id="elasticfusionhttpsgithubcommp3guyelasticfusion">  <a href="https://github.com/mp3guy/ElasticFusion">Elasticfusion</a> </h4><br><ul><li>  build meshes </li><li>  high resource requirements (GPU) </li><li>  Does not have a package in ROS </li></ul><br><p>  This library is well reviewed in <a href="https://habrahabr.ru/company/singularis/blog/279035/">this article</a> . </p><br><h2 id="podhody-k-resheniyu-zadachi-avtonomnoy-i-ne-ochen-navigacii">  Approaches to solving the problem of autonomous (and not so) navigation </h2><br><p> In this section, we will analyze the main approaches to solving the above problem, which ROS provides.  The <a href="http://wiki.ros.org/navigation">official tutorial</a> presents only a small part of them.  For a number of robots there are ready-made solutions (sections 6.2 - 6.6 by the link above).  I also advise you to watch <a href="http://robots.ros.org/all/">this link</a> .  Perhaps it makes sense to rewrite their code a bit, if your robot looks like one of the list presented there. </p><br><p>  There are also a number of packages not mentioned in the sources above.  Especially solutions for copters. </p><br><h3 id="planirovanie-po-karte-prepyatstviy-occupancymap">  Obstacle Map Planning (OccupancyMap) </h3><br><p><img src="https://habrastorage.org/files/ad1/957/168/ad1957168ccd4212ba3288ffd13553ef.jpg" alt="occupancy_map"></p><br><p>  This approach allows us to solve the problem of navigation on the plane, which is quite simple in an algorithmic sense. </p><br><p>  The obstacle map (see in the article's thesis) can be obtained from a point cloud in several ways: </p><br><ul><li>  Based on a slice at a certain height from a point cloud </li><li>  How is the projection of all points on the plane z = 0 starting from any given height z =? .. <br>  This option is provided by rtabmap. <br>  It has many parameters, like this: <br><ul><li>  allowable tilt angle "plane" </li><li>  the number of points near that should be considered an obstacle </li><li>  much more </li></ul></li><li>  Some implementations of SLAM algorithms initially build only an obstacle map (see above). </li></ul><br><h4 id="ros-koncepciya-move_basehttpwikirosorgmove_base">  ROS concept <a href="http://wiki.ros.org/move_base">move_base</a> </h4><br><p><img src="https://habrastorage.org/files/112/16c/2c0/11216c2c032e44bcbab0022ea96667b3.png" alt="move_base"></p><br><p>  Good for wheeled robots.  This is the ROS concept, which consists of 2 gliders. </p><br><h5 id="global-plannerhttpwikirosorgglobal_planner">  <a href="http://wiki.ros.org/global_planner">Global planner</a> </h5><br><p>  Looks for a global route on the Obstacle Map as a line. </p><br><p><img src="https://habrastorage.org/files/be2/58d/072/be258d072fab4da795e2b09b7fdede97.png" alt="global_planner"></p><br><h5 id="local-plannerhttpwikirosorgbase_local_planner">  <a href="http://wiki.ros.org/base_local_planner">Local planner</a> </h5><br><p>  The calculation of speeds and angles falls on a local glider, so as to avoid collisions. </p><br><p><img src="https://habrastorage.org/files/858/5a6/787/8585a67876b9471f8d6e45a27ce433aa.png" alt="local_planner"></p><br><p>  Next, the speed and angles are fed to the node that controls the robot.  Well suited for wheeled platforms. </p><br><h4 id="footstep_planners">  footstep_planners </h4><br><p><img src="https://habrastorage.org/files/2c6/84b/13e/2c684b13e3014995bd0d7c9282af89a9.png" alt="vigir"><br>  This approach is designed mainly for anthropomorphic robots.  One of the scenarios for using an obstacle map in the context of navigation and movement of an anthropomorphic robot is to build a safe trajectory of steps for the robot, which it can subsequently follow. <br>  Then the trajectory in the form of a set of feet goes on execution of the robot. </p><br><p>  The use of this option is possible if the robot controller can "perform" tasks of the form "to occur at a point with given coordinates." </p><br><p>  In my opinion, when planning, the equilibrium conditions of the robot should be taken into account, although planning is carried out from a set of "safe steps".  Or, when implementing a step, the controller of the robot must evaluate the ability to realize it without falling. </p><br><p>  <strong><a href="http://wiki.ros.org/footstep_planner">footstep_planner</a> &amp; <a href="http://wiki.ros.org/humanoid_navigation">humanoid_navigation</a></strong> <br><img src="https://habrastorage.org/files/98c/1ca/b50/98c1cab50fb346a58f8a6e7a7b92fa79.png" alt="footstep_planner"></p><br><p>  <a href="http://wiki.ros.org/footstep_planner">footstep_planner</a> is part of the solution for <a href="http://wiki.ros.org/humanoid_navigation%3Fdistro%3Dindigo">humanoid_navigation</a> for navigating an anthropomorphic robot in a known environment. </p><br><p>  <strong>footstep_planner</strong> provides the ability to plan a route in the form of a set of foot positions leading from the starting position to the final position. <br>  Planning is done on a 2D obstacle map. </p><br><p>  It should be noted that this package provides many necessary settings, which allows it to be used on almost any anthropomorphic robots. <br>  Starting with the physical parameters of the feet and their positions relative to each other at a step, <br>  ending with the choice of search algorithm used when planning. </p><br><h3 id="navigaciya-v-plotnyh-i-ne-ochen-oblakah-tochek">  Navigation in dense (and not so) point clouds </h3><br><h3 id="vigir_footstep_plannerhttpwikirosorgvigir_footstep_planning">  <a href="http://wiki.ros.org/vigir_footstep_planning">Vigir_footstep_planner</a> </h3><br><p><img src="https://habrastorage.org/files/82f/e38/7c6/82fe387c6a02470dada27b176611f44e.png" alt="vigir_planner"></p><br><p>  This is the ideological successor footstep_planner'a in 3D space.  With it, you can lay a route directly in dense clouds of points.  Included - a plugin for Rviz, allowing you to edit the resulting route. </p><br><p>  Details in the <a href="https://www.sim.informatik.tu-darmstadt.de/publ/download/2016_stumpf_footstep_planning_frame_work_Humanoids.pdf">publication</a> </p><br><h3 id="3d-navigationhttpwikirosorg3d_navigation">  <a href="http://wiki.ros.org/3d_navigation">3D navigation</a> </h3><br><p><img src="https://habrastorage.org/files/b24/153/baf/b24153baf73a456ebb85b455e521a1d6.jpg" alt="3d_nav"></p><br><p>  The extension of the move_base described above is 3D with collision checking.  A model robot and a dense 3D environment map are used. </p><br><p>  <a href="http://hrl.informatik.uni-freiburg.de/papers/hornung12icra_3Dnav.pdf">Interesting publication on this package</a> </p><br><h3 id="move-ithttpmoveitrosorg">  <a href="http://moveit.ros.org/">Move it</a> </h3><br><p><img src="https://habrastorage.org/files/106/601/588/1066015884334264acfc2c24749c68cb.png" alt="move_it"></p><br><p>  Package planning of complex movements for robots of any design.  The robot is represented as a model, taking into account all moving parts and restrictions on their movement.  Further, it is possible to calculate the trajectory of all the limbs of the robot during its transition from one state to another.  It is possible to take into account collisions with the environment in the form of dense clouds of points (by Octomap). </p><br><p>  In the documentation for MoveIt, you can find a number of models that can be exported and played with them.  Among <a href="http://docs.ros.org/kinetic/api/moveit_tutorials/html/">tutorialov</a> <a href="http://docs.ros.org/kinetic/api/moveit_tutorials/html/doc/pr2_tutorials/planning/src/doc/move_group_interface_tutorial.html">this one</a> is good, showing the work with the library from C ++ code. </p><br><h2 id="interesnye-ssylki">  Interesting links </h2><br><h3 id="kachestvennyy-razbor-slam-algoritmov-angl">  Qualitative analysis of SLAM algorithms (English) </h3><br><ul><li>  <a href="http://www.probabilistic-robotics.org/">Book Probabilistic Robotics</a> </li><li>  <a href="https://www.youtube.com/channel/UCQoNsqW4v8uvrpWxnIabStg">Course on SLAM algorithms and navigation</a> <br>  Throughout the course mate thoroughly versed.  base SLAM algorithms. <br>  As practical tasks - implementation from 0 on Python with visualization. </li></ul><br><h3 id="upomyanutye-v-state">  Mentioned in the article </h3><br><ul><li>  <a href="http://www2.informatik.uni-freiburg.de/~hornunga/pub/hornung13roscon.pdf">3D mapping with Octomap</a> </li><li>  <a href="http://docs.ros.org/indigo/api/moveit_tutorials/html/">MoveIt tutorials</a> </li><li>  <a href="http://robots.ros.org/all/">Ros robots</a> </li><li>  <a href="http://wiki.ros.org/navigation">ROS navigation wiki</a> </li></ul></div>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <p>Source: <a href="https://habr.com/ru/post/327888/">https://habr.com/ru/post/327888/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../327868/index.html">Authentication in OpenSSH Putty by JaCarta PKI</a></li>
<li><a href="../327872/index.html">Benefits of the Hierarchical Work Structure (WBS) for IT project managers</a></li>
<li><a href="../327874/index.html">Support for Visual Studio 2017 and Roslyn 2.0 in PVS-Studio: sometimes using ready-made solutions is not so easy</a></li>
<li><a href="../327882/index.html">Pitfalls during project team meetings</a></li>
<li><a href="../327886/index.html">SeaMonkey Project officially requests support</a></li>
<li><a href="../327890/index.html">Ruby on Rails agreement. Part 1</a></li>
<li><a href="../327892/index.html">Email is personal data?</a></li>
<li><a href="../327894/index.html">Implementing a NetFlow sensor on an FPGA + CPU - flexibly and quickly</a></li>
<li><a href="../327896/index.html">Bash scripts, part 9: regular expressions</a></li>
<li><a href="../327898/index.html">Six programming paradigms that change your view of code</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>