<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Counterfeiters vs. Bankers: Bleed adversarial networks in Theano</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="You never would have thought, but this is a walk through the space of a neural network-counterfeiter. Made by the coolest people Anders Boesen Lindbo ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Counterfeiters vs. Bankers: Bleed adversarial networks in Theano</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/getpro/habr/post_images/e46/9e1/f0f/e469e1f0fe41ef13ea2c2c19519692e7.gif" alt="image"><br>  <i>You never would have thought, but this is a walk through the space of a neural network-counterfeiter.</i>  <i>Made by the coolest people <a href="http://torch.ch/blog/2015/11/13/gan.html">Anders Boesen Lindbo Larsen and S√∏ren Kaae S√∏nderby</a></i> <br><br>  Suppose we have a task - to understand the world around us. <br>  Let's imagine for simplicity that the world is money. <br><br>  A metaphor, perhaps with some moral ambiguity, but on the whole the example is not worse than the others - money (banknotes) definitely has some complicated structure, here they have a number, a letter, and there are cunning watermarks.  Suppose we need to understand how they are made, and find out the rule by which they are printed.  What is the plan? 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      The promising step is to go to the central bank office and ask them to issue a specification, but first, they will not give it to you, and second, if you withstand the metaphor, the universe does not have a central bank (although there are religious differences on this score). <br><br>  Well, if so, let's try to fake them. <br><a name="habracut"></a><br><h1>  Disriminative vs generative </h1><br>  In general, on the subject of understanding the world there is one fairly well-known approach, which is that to <b>understand is to recognize</b> .  That is, when you and I are engaged in some kind of activity in the outside world, we learn to distinguish some objects from others and use them afterwards accordingly.  This is a chair, it is sitting on it, and this is an apple, and it is eaten.  By consistently observing the required number of chairs and apples, we learn to distinguish them from each other according to the teacher‚Äôs instructions, and in this way we discover some heterogeneity and structure in the world. <br>  This is a rather large number of models that we call <b>discriminative</b> .  If you are a bit machine-oriented, then you can get into the discriminative model by pointing your finger at random anywhere - multi-layer perceptrons, decisive trees and forests, SVM, you name it.  Their task is to assign the correct label to the observed data, and all of them answer the question ‚Äúwhat does what I see look like?‚Äù <br><br>  Another approach, slightly completely different, is that to <b>understand is to repeat</b> .  That is, if you watched the world for some time, and then you were able to reconstruct a part of it (lay down a paper airplane, for example), then you understood something about how it works.  Models that do this usually do not need teacher instructions, and we call them <b>generators</b> - these are all kinds of hidden Markov, naive (and not naive) Bayesian ones, and the modern world of deep neural networks has recently added restricted Boltzmann machines and auto-encoders. <br><br>  The fundamental difference in these two things is this: in order to recreate a thing, you should know more or less everything about it, but in order to learn how to distinguish one thing from another, it is completely unnecessary.  It is best illustrated with this picture: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c39/4e4/78e/c394e478eb0fe2dcbb8cee62b52bf8e9.png" alt="image"><br><br>  On the left, what the generating model sees (the blue distribution has a complex bimodal structure, and the red one is more narrowed), and on the right, what the discriminative sees (only the border on which the dividing line between the two distributions passes, and she has no idea about the other structure ).  A discriminative model sees the world worse - it may well conclude that apples differ from chairs only in that they are red, and this is enough for its purposes. <br><br>  Both models have their advantages and disadvantages, but for the time being, let's agree for our purpose that the generating model is simply steeper.  We like the idea of ‚Äã‚Äãunderstanding things completely, not pairwise, comparatively. <br><br><h1>  How do we generate </h1><br>  Well, well, how do we set up this generating model?  For some limited cases, we can use just the theory of probability and the Bayes theorem ‚Äî say, we are trying to model coin tosses, and assume that they correspond to the binomial distribution, then <img src="https://habrastorage.org/files/a54/d65/6c3/a54d656c346e430bb17aed521c06ad9e.png">  and so on.  For really interesting objects like pictures or music, this does not work very well - the curse of dimension makes itself felt, there are too many signs (and they depend on each other, so you have to build a joint distribution ...). <br><br>  A more abstract (and interesting) alternative is to assume that the thing we are modeling can be represented as a small number of hidden variables or "factors."  For our hypothetical case of money, this assumption seems to be quite intuitively correct - the drawing on the bill can be decomposed into components in the form of a nominal, serial number, a beautiful picture, an inscription.  Then we can say that our source data can be compressed to the size of these factors and restored back without losing the semantic content.  On this principle, all kinds of <a href="https://en.wikipedia.org/wiki/Autoencoder">avtoenkodery</a> trying to compress the data and then build their most accurate reconstruction - a very interesting thing, about which we, however, will not speak. <br><br>  Another method <a href="http://arxiv.org/pdf/1406.2661v1.pdf">suggested by</a> Ian Goodfellow from Google, and it is this: <br><br>  1) We create two models, one - generating (let's call it a counterfeiter), and the second - discriminative (let it be a banker) <br>  2) The counterfeiter is trying to build a fake for real money at the exit, and the banker is trying to distinguish the fake from the original (both models start with random conditions and at first give out noise and trash as results). <br>  3) The counterfeiter‚Äôs goal is to make a product that a banker could not distinguish from a real one.  The goal of the banker is to distinguish counterfeit from the originals as effectively as possible.  Both models start the game against each other, <s>where only one will remain</s> . <br><br>  Both models will be neural networks - hence the name adversarial networks.  The article states that the game eventually converges to the victory of a counterfeiter and, accordingly, the defeat of the banker.  Good news for the underworld of generative models. <br><br><h1>  Little formalism </h1><br>  Let's call our counterfeiter <img src="https://habrastorage.org/files/4a3/010/709/4a301070972247dea58ba5bd48a04bfa.png">  (or generator), and banker - <img src="https://habrastorage.org/files/d47/66e/80e/d4766e80e72f429aa183611169033fff.png">  (or discriminator).  We have some amount of original money. <img src="https://habrastorage.org/files/9c0/880/073/9c088007312945c3bcd94438aec511e8.png">  for a banker, and let him have a number from zero to one at the exit, so that it expresses the banker's confidence that the money given to him for consideration is real.  Also, since the counterfeiter has a neural network, it needs some input data, let's call it <img src="https://habrastorage.org/files/318/135/e8d/318135e8d2f2454590bbad0833e01fd1.png">  .  In fact, this is just a random noise that the model will try to turn into money. <br><br>  Then, obviously, the counterfeiter‚Äôs goal is to maximize <img src="https://habrastorage.org/files/756/6b9/cd5/7566b9cd566c4f34849aafea254e06c7.png">  , that is, to make so that the banker was sure that the fakes are real. <br><br>  The banker's goal is more complicated - he needs to simultaneously positively recognize the originals, and negatively - fakes.  We write this as maximization <img src="https://habrastorage.org/files/8e3/40e/49d/8e340e49d9474ba58fa9e08c4801c2ad.png">  .  Multiplication can be turned into addition if we take the logarithm, so we get: <br><br>  For a banker: maximize <img src="https://habrastorage.org/files/0af/1e2/b49/0af1e2b4996f47fe9e6993556b09dc16.png"><br>  For counterfeiter: maximize <img src="https://habrastorage.org/files/bf4/b3f/b1f/bf4b3fb1fcc74384a5d28982f4478d3d.png"><br><br>  This is a little less than all the math that we need here. <br><br><h1>  One dimensional example </h1><br>  (almost entirely taken from this wonderful <a href="http://evjang.com/articles/genadv1">post</a> , but there - on TensorFlow) <br><br>  Let's try to solve a simple one-dimensional example: let our models deal with ordinary numbers that have condensed around a point. <img src="https://habrastorage.org/files/4fe/ed0/08c/4feed008ce784f5ab82e697b3945a675.png">  on a small scale <img src="https://habrastorage.org/files/80f/7a4/ae6/80f7a4ae66124cc0827fd7aa2d4a7333.png">  .  The probability of each met number found somewhere on the number line can be represented by a normal distribution.  Here it is: <br><br><img src="https://habrastorage.org/files/416/576/886/416576886e6f4662a8e5f4ce2db5e139.png"><br><br>  Accordingly, the numbers that correspond to this distribution (live in a neighborhood of -2) will be considered ‚Äúcorrect‚Äù and ‚Äúoriginal‚Äù, while the others will not. <br><br>  Take Theano and Lasagne, and define our models - simple neural networks with two layers of ten neurons each.  At the same time, because of the mechanism of the Theano operation (it builds a symbolic graph of calculations and allows you to specify one specific variable as the discriminator input, we need two originals and fakes) to make two copies of the discriminator: one will pass through the ‚Äúcorrect‚Äù numbers, and the second is generator fakes. <br><br><div class="spoiler">  <b class="spoiler_title">Code</b> <div class="spoiler_text"><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> theano <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> theano.tensor <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> T <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> lasagne.nonlinearities <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> rectify, sigmoid, linear, tanh G_input = T.matrix(<span class="hljs-string"><span class="hljs-string">'Gx'</span></span>) G_l1 = lasagne.layers.InputLayer((<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>), G_input) G_l2 = lasagne.layers.DenseLayer(G_l1, <span class="hljs-number"><span class="hljs-number">10</span></span>, nonlinearity=rectify) G_l3 = lasagne.layers.DenseLayer(G_l2, <span class="hljs-number"><span class="hljs-number">10</span></span>, nonlinearity=rectify) G_l4 = lasagne.layers.DenseLayer(G_l3, <span class="hljs-number"><span class="hljs-number">1</span></span>, nonlinearity=linear) G = G_l4 G_out = lasagne.layers.get_output(G) <span class="hljs-comment"><span class="hljs-comment"># discriminators D1_input = T.matrix('D1x') D1_l1 = lasagne.layers.InputLayer((None, 1), D1_input) D1_l2 = lasagne.layers.DenseLayer(D1_l1, 10, nonlinearity=tanh) D1_l3 = lasagne.layers.DenseLayer(D1_l2, 10, nonlinearity=tanh) D1_l4 = lasagne.layers.DenseLayer(D1_l3, 1, nonlinearity=sigmoid) D1 = D1_l4 D2_l1 = lasagne.layers.InputLayer((None, 1), G_out) D2_l2 = lasagne.layers.DenseLayer(D2_l1, 10, nonlinearity=tanh, W=D1_l2.W, b=D1_l2.b) D2_l3 = lasagne.layers.DenseLayer(D2_l2, 10, nonlinearity=tanh, W=D1_l3.W, b=D1_l3.b) D2_l4 = lasagne.layers.DenseLayer(D2_l3, 1, nonlinearity=sigmoid, W=D1_l4.W, b=D1_l4.b) D2 = D2_l4 D1_out = lasagne.layers.get_output(D1) D2_out = lasagne.layers.get_output(D2)</span></span></code> </pre> <br></div></div><br><br>  Let's draw a picture of how the discriminator behaves - that is, for each number that is on the line (we limit ourselves to the range from -5 to 5), we note the discriminator's confidence that this number is correct.  We will get the green curve on the graph below - as you can see, since the discriminator is not trained in us, it gives out a full house-house heresy.  And at the same time we ask the generator to spit out a certain number of numbers and draw their distribution using a red histogram: <br><br><img src="https://habrastorage.org/files/b9f/48f/d8c/b9f48fd8c47e459ea4d2907a3d21343e.png"><br><br>  And a little more Theano-code to make the price function and start learning: <br><br><div class="spoiler">  <b class="spoiler_title">Another code</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># objectives G_obj = (T.log(D2_out)).mean() D_obj = (T.log(D1_out) + T.log(1 - D2_out)).mean() # parameters update and training G_params = lasagne.layers.get_all_params(G, trainable=True) G_lr = theano.shared(np.array(0.01, dtype=theano.config.floatX)) G_updates = lasagne.updates.nesterov_momentum(1 - G_obj, G_params, learning_rate=G_lr, momentum=0.6) G_train = theano.function([G_input], G_obj, updates=G_updates) D_params = lasagne.layers.get_all_params(D1, trainable=True) D_lr = theano.shared(np.array(0.1, dtype=theano.config.floatX)) D_updates = lasagne.updates.nesterov_momentum(1 - D_obj, D_params, learning_rate=D_lr, momentum=0.6) D_train = theano.function([G_input, D1_input], D_obj, updates=D_updates) # training loop epochs = 400 k = 20 M = 200 # mini-batch size for i in range(epochs): for j in range(k): x = np.float32(np.random.normal(mu, sigma, M)) # sampled orginal batch z = sample_noise(M) D_train(z.reshape(M, 1), x.reshape(M, 1)) z = sample_noise(M) G_train(z.reshape(M, 1)) if i % 10 == 0: # lr decay G_lr *= 0.999 D_lr *= 0.999</span></span></code> </pre><br></div></div><br><br>  We use here the learning rate decay and not a very big momentum.  In addition, the discriminator trains several steps one generator step (20 in this case) - a somewhat muddy point about which there is in the article, but it is not very clear why.  My guess is that this allows the generator to not react to random throwing of the discriminator (i.e., the counterfeiter first waits until the banker approves the strategy of behavior for himself, and then tries to deceive it). <br><br>  The learning process looks like this: <br><br><img src="https://habrastorage.org/files/201/251/765/2012517655cf44679cfac7a04180afc6.gif"><br><br>  What happens in this gif?  The green line tries to push the red histogram into the blue contour.  When the discriminator's limit in a certain place falls below 0.5, this means that for the corresponding places the numerical direct discriminator suspects more fakes than the originals, and will rather produce negative conclusions (thus, it almost pushes outliers of red numbers). to the right of the distribution center after the first few seconds gifs) <br><br>  Where the histogram coincides with the contour, the discriminator curve stays at 0.5 ‚Äî this means that the discriminator can no longer distinguish counterfeits from the originals and does the best that it can in such a situation ‚Äî it just randomly spits guesses with the same probability. <br><br>  Outside the area of ‚Äã‚Äãinterest to us, the discriminator behaves not very adequately - for example, it positively classifies all numbers greater than -1 with a probability of ~ 1, but this is not terrible, because in this game we support the counterfeiter and it is his success that interests us. <br><br>  This couple is curious to watch, playing with different parameters.  For example, if you put momentum too large, both participants in the game will begin to respond too sharply to the learning signals and correct their behavior so much that they make it even worse.  Something like this: <br><br><img src="https://habrastorage.org/files/eeb/8b1/5db/eeb8b15dbb51459ca9b2cc32d8a2661b.gif"><br><br>  The entire code can be viewed <a href="https://gist.github.com/rocknrollnerd/06bfed6b9d1bce612fd6">here</a> . <br><br><h1>  An example is more interesting </h1><br>  Well, it was not so bad, but we are capable of more, as the title picture hints.  Let's try the newfound skills of the counterfeiter on the good old handwritten numbers. <br><br>  Here, the generator will have to use a little trick, which is described in the article codenamed <a href="http://arxiv.org/pdf/1511.06434.pdf">DCGAN</a> (they are also used by Lars and Soren in the title post).  It consists in the fact that we do such a kind of convolutional network, vice versa (a sweep network?), Where we replace subsampling layers that reduce the image N times with upsampling layers that increase it, and do convolutional layers in full mode - when the filter jumps out of the picture and at the output gives more result than the original picture.  If this is dull and unclear for you, <a href="http://cs231n.github.io/convolutional-networks/">this</a> page will clarify everything in five minutes, but for now you can remember a simple rule - in the case of the usual convolution <img src="https://habrastorage.org/files/60b/ac8/4be/60bac84be290480a8f55ce2a1fca5fd2.png">  by filter <img src="https://habrastorage.org/files/aec/9eb/da3/aec9ebda303b4c46b7c0d3ba3629d4fa.png">  the result will have a side <img src="https://habrastorage.org/files/5cb/bc2/97c/5cbbc297c61142b0899e5e1eebe9e77b.png">  , and full convolution - <img src="https://habrastorage.org/files/2e9/cd4/0fa/2e9cd40fa91b4eb5b50689af03f74a51.png">  .  This will allow us to start with a small square of noise and "expand" it into a full-fledged image. <br><br><div class="spoiler">  <b class="spoiler_title">Some technical incomprehensibilities</b> <div class="spoiler_text">  Generally speaking, the article says that they recommend removing subsampling / upsampling layers altogether.  You can try to do this, although in my opinion, it turns out to be slightly cumbersome ... Another incomprehensibility is related to the fact that the convolutions they use are strided, i.e.  are made with a step larger than 1. For the usual convolution, generally speaking, the result should be just the same as with subsampling + normal convolution (if I do not confuse anything), and accordingly, I decided that upsampling + full convolution would give a similar result for our scanning network.  In this case, there is also a terrible confusion with the terms - the same thing in Google is called ‚Äúfull convolution‚Äù, ‚Äúfractionaly-strided convolution‚Äù and even ‚Äúdeconvolution‚Äù.  The authors of DCGAN say that deconvolution is the wrong name, but in their <a href="https://github.com/Newmu/dcgan_code/blob/master/lib/ops.py">code</a> exactly this is used ... well, at some point I waved my hand and decided that it was working - okay. <br></div></div><br><br>  The generator code for the MNIST numbers looks something like a spoiler.  The discriminator is some simplest convolutional network.  To be honest, I one-to-one tore it from the Las Casmeme's readme, and I won't even bring it here. <br><br><div class="spoiler">  <b class="spoiler_title">More code</b> <div class="spoiler_text"><pre> <code class="python hljs">G_input = T.tensor4(<span class="hljs-string"><span class="hljs-string">'Gx'</span></span>) G = lasagne.layers.InputLayer((<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, NOISE_HEIGHT, NOISE_WIDTH), G_input) G = batch_norm(lasagne.layers.DenseLayer(G, NOISE_HEIGHT * NOISE_WIDTH * <span class="hljs-number"><span class="hljs-number">256</span></span>, nonlinearity=rectify)) G = lasagne.layers.ReshapeLayer(G, ([<span class="hljs-number"><span class="hljs-number">0</span></span>], <span class="hljs-number"><span class="hljs-number">256</span></span>, NOISE_HEIGHT, NOISE_WIDTH)) G = lasagne.layers.Upscale2DLayer(G, <span class="hljs-number"><span class="hljs-number">2</span></span>) <span class="hljs-comment"><span class="hljs-comment"># 4 * 2 = 8 G = batch_norm(lasagne.layers.Conv2DLayer(G, 128, (3, 3), nonlinearity=rectify, pad='full')) # 8 + 3 - 1 = 10 G = lasagne.layers.Upscale2DLayer(G, 2) # 10 * 2 = 20 G = batch_norm(lasagne.layers.Conv2DLayer(G, 64, (3, 3), nonlinearity=rectify, pad='full')) # 20 + 3 - 1 = 22 G = batch_norm(lasagne.layers.Conv2DLayer(G, 64, (3, 3), nonlinearity=rectify, pad='full')) # 22 + 3 - 1 = 24 G = batch_norm(lasagne.layers.Conv2DLayer(G, 32, (3, 3), nonlinearity=rectify, pad='full')) # 24 + 3 - 1 = 26 G = batch_norm(lasagne.layers.Conv2DLayer(G, 1, (3, 3), nonlinearity=sigmoid, pad='full')) # 26 + 3 - 1 = 28 G_out = lasagne.layers.get_output(G)</span></span></code> </pre><br></div></div><br><br>  The result is something like this. <br><br><img src="https://habrastorage.org/files/76c/d5f/20b/76cd5f20b6dc49329b3da88f69d2f074.gif"><br><br>  Not exactly perfect, but something definitely similar.  It's funny to watch how the generator <i>first</i> learns to draw with similar strokes, and then struggles a decent time in order to make a regular shape of them.  For example, here the selected characters do not look like numbers, but they clearly represent some kind of characters, that is, the generator went the right way: <br><br><img src="https://habrastorage.org/files/531/dd0/717/531dd07175024149a8632b52f0d84cc7.png"><br><br>  Going further, we take the <a href="http://conradsanderson.id.au/lfwcrop/">LFW Crop</a> face database, first we reduce the faces to the size of MNIST (28x28 pixels) and try to repeat the experiment, only in color.  And immediately notice several patterns: <br><br>  1) Persons train worse.  The number of neurons and layers that I brought here for MNIST is taken slightly with a margin - it can be halved, and it will turn out well.  Persons at the same time turn into an incomprehensible random mess. <br>  2) Colored faces train even worse - which is understandable, of course, the information becomes three times more. <br>  3) Sometimes it is necessary to correct the mutual behavior of the generator and the discriminator: there are situations when one drives the other into a dead end, and the game stops.  This usually happens in a situation where, say, the discriminator is more powerful in a representative sense ‚Äî it can understand such fine details that the generator is still (or not at all) able to distinguish.  Again, the title post describes several heuristics (slow down the discriminator when it gets too good grades, etc.), but everything worked quite well without me - I had enough to correct the settings and the number of neurons at the beginning of the training. <br><br>  And the result: <br><br><img src="https://habrastorage.org/files/299/ab9/632/299ab96323764b7bb93ab513ff0b0ef7.gif"><br><br>  Not bad, not bad, but I still want something of the same quality as on the KDPV! <br><br><h1>  Full-size example and walk in recipe space </h1><br>  I loaded the regretful GT 650M with a full-sized (64x64) LFW Crop and left it overnight.  Approximately 30 eras (per 10,000 persons) passed by morning, and the end result looked like this: <br><br><img src="https://habrastorage.org/files/9ba/ce6/7c1/9bace67c1690413b8f0365cad9ff4dac.jpg"><br><br>  What a beauty.  If anyone needs character portraits for a zombie apocalypse, let me know!  I have a lot of them. <br>  The quality was not very good, but something similar to the situation with MNIST happened - our generator learned to cope with visual noises and vagueness, to draw eyes, noses and mouths properly, and now he has a problem called ‚Äúhow to combine them correctly‚Äù. <br><br>  Let's now think again what we have drawn.  All these faces are spat out by the same network, and a neural network is a deterministic thing through and through, just a sequence of multiplications and additions (and nonlinearities, okay).  I did not add any randomization, dropout, etc. to the generator.  So how do people get different?  Obviously, the only source of randomization that the network can use is the same input noise that we used to call the ‚Äúmeaningless‚Äù parameter.  Now it turns out that it turns out to be quite important - in this noise all the parameters of the output face are encoded, and all that the rest of the network does is simply read the input ‚Äúrecipe‚Äù and apply paint according to it. <br><br>  And the recipes are not discrete (I did not have time to say about this, but a simple uniform distribution of numbers from 0 to 1 was taken as noise).  True, we still do not know what number in the recipe is what exactly encodes, hmm - and even "does something meaningful encode any single number?"  Well, why do we need all this then? <br><br>  First, knowing now that the input noise is a recipe, we can control it.  Uniform noise, to put it bluntly, was not a very good idea - now every bit of noise can encode anything with the same probability.  We can apply to the input, say, normal noise (distributed over Gauss) - then noise values ‚Äã‚Äãclose to the center will occur frequently and encode something common (such as skin color), and rare outliers something special and rare ( for example, glasses on the face).  People who wrote the DCGAN article <a href="https://github.com/Newmu/dcgan_code">found a</a> few semantic pieces of the recipe, and used them to put glasses on people or make them frown at will. <br><br>  Secondly ... have you seen the meme on <a href="">‚Äúimage enhancing‚Äù</a> from the CSI series?  A thing that all people who are familiar with computers have long laughed at: the powerful FBI algorithm magically increases the resolution of the picture.  So, we may still have to take our words back, because why not make our generator's life a little easier, and instead of giving noise to the input, give, say, a <i>smaller</i> version of our original?  Then, instead of drawing faces from the head, the generator will just have to ‚Äúdraw them‚Äù - and this task clearly looks simpler than the first one. <br><br>  I, unfortunately, did not reach this point, but here there is an excellent <a href="https://swarbrickjones.wordpress.com/2016/01/13/enhancing-images-using-deep-convolutional-generative-adversarial-networks-dcgans/">post</a> demonstrating how this is done with impressive illustrations. <br><br>  Well and thirdly, you can have some fun.  Since we know that recipes are not discrete, there are transition states between any two recipes.  We take two noise vectors, interpolate them and feed the generator.  Repeat, until you get bored, or until the people in the room seriously start to worry, why are you looking at agonizing zombies so closely. <br><br><img src="https://habrastorage.org/files/695/3ca/d7a/6953cad7aa17483aafaa548a88be063a.gif"><br><br><h1>  Conclusion </h1><br>  1) Adversarial networks are fun. <br>  2) If you decide to try to train them yourself - it is easier to peek at the ready-made recipes than to play with the parameters. <br>  3) Joshua Bengio <a href="https://www.quora.com/What-is-the-most-exciting-machine-learning-research-paper-you-read-in-2015">named</a> DCGAN and LAPGAN (which is image enhancing) among the most impressive pieces in machine learning in 2015 <s>and it was after this that I read about them, of course</s> <br>  4) Another blog was recently a good <a href="http://www.inference.vc/deep-learning-is-easy/">post</a> on the topic of ‚Äúdeep learning is easy, try something harder‚Äù - just for people <s>like me</s> who are hooked on a popular topic and don‚Äôt really know where to go next.  Adversarial networks is a good option (and also mentioned in the post as one of the new promising areas), because there are a lot of interesting things, and control over the recipes is only one of the most promising things. <br>  5) How to translate "adversarial networks" into Russian?  "Warring networks"?  "Rival networks"? </div><p>Source: <a href="https://habr.com/ru/post/275429/">https://habr.com/ru/post/275429/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../275417/index.html">DevFest Kaliningrad-2015: photo report</a></li>
<li><a href="../275419/index.html">Android application development contest for students</a></li>
<li><a href="../275421/index.html">New podcasts about professional development for Android</a></li>
<li><a href="../275425/index.html">DevTips: Web Developer Tips (33-48)</a></li>
<li><a href="../275427/index.html">Pro trackpoint and mouse emulation</a></li>
<li><a href="../275431/index.html">Hibernate envers. Substitution ID of the user who made the change</a></li>
<li><a href="../275435/index.html">Redux Tutorial from Library Creator</a></li>
<li><a href="../275439/index.html">Working with Arduino from a C # application</a></li>
<li><a href="../275441/index.html">Experience installing SolidWorks on a Windows 7 virtual machine on a Ubuntu host OS</a></li>
<li><a href="../275443/index.html">LastPass users are vulnerable to the simplest phishing attack in Chrome</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>