<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Huge open dataset Russian speech</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Speech recognition specialists have long lacked a large open corpus of oral Russian, so only large companies could afford to engage in this task, but ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Huge open dataset Russian speech</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/getpro/habr/post_images/942/772/451/942772451cd966834f98da1416356590.jpg" alt="image"><br><br>  Speech recognition specialists have long lacked a large open corpus of oral Russian, so only large companies could afford to engage in this task, but they were not in a hurry to share their experiences. <br><br>  We are in a hurry to correct this lasting misunderstanding for years. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      So, we bring to your attention a data set of 4000 hours of annotated speech, collected from various online sources. <br><br>  Details under the cut. <a name="habracut"></a><br><br>  Here is the data for the current version 0.3: <br><div class="scrollable-table"><table><tbody><tr><th>  Data type </th><th>  annotation </th><th>  Quality </th><th>  Phrases </th><th>  Clock </th><th>  GB </th></tr><tr><td>  Books </td><td>  alignment </td><td>  95% / clean </td><td>  1.1M </td><td>  1.511 </td><td>  166 </td></tr><tr><td>  Calls </td><td>  ASR </td><td>  70% / noisy </td><td>  837K </td><td>  812 </td><td>  89 </td></tr><tr><td>  Generated (Russian addresses) </td><td>  Tts </td><td>  100% / 4 votes </td><td>  1,7M </td><td>  754 </td><td>  81 </td></tr><tr><td>  Speech from YouTube videos </td><td>  subtitles </td><td>  95% / noisy </td><td>  786K </td><td>  724 </td><td>  78 </td></tr><tr><td>  Books </td><td>  ASR </td><td>  70% / noisy </td><td>  124K </td><td>  116 </td><td>  13 </td></tr><tr><td>  Other datasets </td><td>  reading and alignment </td><td>  99% / clean </td><td>  17K </td><td>  43 </td><td>  five </td></tr></tbody></table></div><br>  But you immediately <a href="https://github.com/snakers4/open_stt/">link to the site of our corps</a> . <br><br><h4>  Will we develop the project further? </h4><br>  Our work on this is not finished, we want to get at least 10 thousand hours of annotated speech. <br><br>  And then we are going to make open and commercial models for speech recognition using this dataset.  And we offer you to join: help us improve dataset, use it in your tasks. <br><br><h4>  Why is our goal 10 thousand hours? </h4><br>  There are various studies of the generalization of neural networks in speech recognition, but it is known that good generalization does not work on datasets for less than 1000 hours.  The figure of the order of 10 thousand hours is already considered acceptable in most cases, and then depends on the specific task. <br><br><h4>  What else can be done to improve the quality of recognition, if there is still not enough data? </h4><br>  Often, you can adapt the neural network to your speakers through the recital of the speakers of the texts. <br>  You can also adjust the neural network to a dictionary from your subject area (language model). <br><br><h4>  How did we do this? </h4><br><ul><li>  Found channels with high-quality subtitles on YouTube, downloaded audio and subtitles </li><li>  Gave audio for recognition to other speech recognition systems. </li><li>  Reading addresses with robo voices </li><li>  Audiobooks and texts of books were found on the Internet, after which they were broken into fragments in pauses and compared with one another (the so-called ‚Äúalignment‚Äù task) </li><li>  Added small Russian datasets available on the Internet. </li><li>  After that, the files were converted into a single format (16-bit wav, 16 kHz, mono, hierarchical arrangement of files on the disk). </li><li>  Metadata was saved in a separate file manifest.csv. </li></ul><br><h3>  How to use it: </h3><br><h4>  File DB </h4><br>  The location of files is determined by their hashes, like this: <br><br><pre><code class="python hljs">target_format = <span class="hljs-string"><span class="hljs-string">'wav'</span></span> wavb = wav.tobytes() f_hash = hashlib.sha1(wavb).hexdigest() store_path = Path(root_folder, f_hash[<span class="hljs-number"><span class="hljs-number">0</span></span>], f_hash[<span class="hljs-number"><span class="hljs-number">1</span></span>:<span class="hljs-number"><span class="hljs-number">3</span></span>], f_hash[<span class="hljs-number"><span class="hljs-number">3</span></span>:<span class="hljs-number"><span class="hljs-number">15</span></span>]+<span class="hljs-string"><span class="hljs-string">'.'</span></span>+target_format)</code> </pre> <br><h4>  Reading files </h4><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> utils.open_stt_utils <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> read_manifest <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> scipy.io <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> wavfile <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> pathlib <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Path manifest_df = read_manifest(<span class="hljs-string"><span class="hljs-string">'path/to/manifest.csv'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> info <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> manifest_df.itertuples(): sample_rate, sound = wavfile.read(info.wav_path) text = Path(info.text_path).read_text() duration = info.duration</code> </pre><br>  The manifest files contain triples: the name of the audio file, the name of the file with the text description, and the phrase duration in seconds. <br><br><h4>  Filter only files of a certain length </h4><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> utils.open_stt_utils <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> (plain_merge_manifests, check_files, save_manifest) train_manifests = [ <span class="hljs-string"><span class="hljs-string">'path/to/manifest1.csv'</span></span>, <span class="hljs-string"><span class="hljs-string">'path/to/manifest2.csv'</span></span>, ] train_manifest = plain_merge_manifests(train_manifests, MIN_DURATION=<span class="hljs-number"><span class="hljs-number">0.1</span></span>, MAX_DURATION=<span class="hljs-number"><span class="hljs-number">100</span></span>) check_files(train_manifest) save_manifest(train_manifest, <span class="hljs-string"><span class="hljs-string">'my_manifest.csv'</span></span>)</code> </pre><br><h3>  What to read or watch in Russian, to get better acquainted with the task of speech recognition? </h3><br>  Recently, as part of the <a href="https://dlcourse.ai/">Deep Learning</a> course, we recorded a lecture on speech recognition (and a bit of synthesis) <a href="https://dlcourse.ai/">on our fingers</a> .  Perhaps it will be useful to you! <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/JpS0LzEWr-4" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><h4>  Licensing issues </h4><br><ul><li>  We lay out dataset under a double license: for non-commercial purposes, we offer a license <a href="https://creativecommons.org/licenses/by-nc/4.0/">cc-by-nc 4.0</a> , for commercial purposes - use after an agreement with us. </li><li>  As usual in such cases, all rights to use the data included in the data remain with their owners.  Our rights apply to dataset itself.  For scientific and educational purposes, there are separate rules for this, see the legislation of your country. </li></ul><br>  Once again <a href="https://github.com/snakers4/open_stt/">, the project site for those who did not see the link above</a> . </div><p>Source: <a href="https://habr.com/ru/post/450760/">https://habr.com/ru/post/450760/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../45075/index.html">Vogue - Fashionable Deep Zoom</a></li>
<li><a href="../450752/index.html">‚ÄúI have only one training method: just working‚Äù - an interview with Ryan Dahl (Node.js, Deno)</a></li>
<li><a href="../450754/index.html">Wheelchair racing: Russian pilot became a winner in the CYBATHLON championship in Tokyo</a></li>
<li><a href="../450756/index.html">About combat incapacitants</a></li>
<li><a href="../450758/index.html">factory_trace gem will help clean your factories</a></li>
<li><a href="../450762/index.html">"Peronet" based on pigeons is still the fastest way to transfer large amounts of information</a></li>
<li><a href="../450768/index.html">X-ray data transmission in open space</a></li>
<li><a href="../45077/index.html">Windows system hit the top 10 most powerful supercomputers in the world</a></li>
<li><a href="../450770/index.html">Plane crash in Sheremetyevo: historical analogies</a></li>
<li><a href="../450772/index.html">‚ÄúPay attention‚Äù # 3: Digest of articles on grocery thinking, behavioral psychology and productivity</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>