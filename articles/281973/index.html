<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Text Recognition from a Video Stream: The Future of Mobile OCR</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Recently, we quite often tell in a blog about our recognition technologies that work on mobile devices and recognize photos taken by cameras of these ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Text Recognition from a Video Stream: The Future of Mobile OCR</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/files/1f2/ca1/9b9/1f2ca19b92b94710a2c3f32c69ce7b61.png" align="left">  Recently, we quite often tell in a blog about our recognition technologies that work on mobile devices and recognize photos taken by cameras of these devices.  Now we move on and learn to work not with photos, but with a video stream.  And today we want to tell you in more detail what this means and where in everyday life text recognition from a video stream can be useful. <br><br>  <i>By the way, now we are expanding the team engaged in creating a product for text recognition from a video stream on smartphones.</i>  <i>If you are an Android or iOS developer with experience writing high-load applications and you have a desire to develop new technologies with us, hurry to respond to the <a href="https://hh.ru/vacancy/13320029">vacancy</a> .</i> <br><br><h1>  About video streaming and recognition </h1><br>  To begin with, let's say which video stream we work with. <a name="habracut"></a>  A video stream is a sequence of frames received from the device's camera, in other words, what we see on the smartphone screen when we launch the standard Camera application. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/files/95c/975/156/95c975156977486b9e95787769aabed8.png"><br><br>  <i>Photo of the menu fragment</i> <br><br><img src="https://habrastorage.org/files/000/e91/44b/000e9144b7224cc7ab4cd89a78837307.png"><img src="https://habrastorage.org/files/ab5/63a/45b/ab563a45b27c4ef1b736a84253601a66.png"><img src="https://habrastorage.org/files/d08/de4/ec1/d08de4ec1b6647fe885e4eab142b7219.png"><br><br>  <i>Frames from a video stream with a menu fragment</i> <br><br>  If you compare a single frame of a video stream with a photo, you can see that its quality is lower: the resolution (dpi) of the frame is smaller, the image is often out of focus and blurred, and digital noise is also present.  The presence of such defects is absolutely not surprising, because we are not robots to hold the phone in our hands absolutely motionless :), besides, insufficient lighting due to the lack of flash operation.  This makes the task of recognizing a video stream much more difficult than recognizing a photo, but the benefits that can be gained in the end are worth the effort to solve it: <br><br>  <b>Improving the quality of recognition</b> <br>  We <a href="https://habrahabr.ru/company/abbyy/blog/275631/">have already talked</a> about our technologies that allow us to quickly check the suitability of a photo for recognition.  In the case of a video stream, you can go even further and immediately choose from the image stream, the most suitable for processing.  Yes, many quality shots are worse than photos, but some may turn out better, there are plenty to choose from. <br><br>  In addition, a significant part of the errors in the recognition results is due to random noise, glare, defocus, etc.  These defects do not repeat from frame to frame, therefore, a symbol that was incorrectly recognized on one frame can be correctly recognized on the next one.  By aggregating text from several frames this way, you can improve the quality and achieve even better recognition results than for the photo. <br><br>  <b>More convenient applications</b> <br>  Recognition from a video stream requires almost no action from the user.  There is no need to click on the button "take a picture", to ensure that all the necessary text in the photo was in focus.  Simply point the camera at the text and recognition will start automatically.  In addition, since text processing is performed directly "off-frame", the results can be displayed instantly, for example, on top of the original text (to simplify the task of verifying the results) <br><br><img src="https://habrastorage.org/files/ce4/e45/b04/ce4e45b047ec4d1cbbe41bc81872c208.png"><br><br>  or, on the contrary, depending on the recognized text, supplement the frame with special pictures, inscriptions, etc., i.e.  create so-called applications of augmented reality.  In addition, when recognizing from a video stream, the image is not saved anywhere and does not clog the memory of the device. <br><br>  All this brings joy to the user and makes the application convenient. <br><br><h1>  How can video stream recognition be useful? </h1><br>  In our future articles, we will describe in more detail how best to work with the video stream, but for now let's see where this technology can be applied. <br><br><h2>  Keyboard Alternative </h2><br>  One of the most obvious scenarios is replacing text input from the keyboard with input from a video stream.  Probably everyone has been in a situation where there is a booklet in their hands, on which the necessary e-mail address is written, and you have to manually drive it into the browser line.  It would be much more convenient and faster to just point the camera of the phone at it. <br><br>  In order to provide real-time processing and catch up with the constantly changing scenes in the viewfinder, you need to recognize it very quickly.  To achieve this, you have to resort to many different means.  First, enable all device processor cores using parallel recognition.  In this case, it is possible to recognize in parallel several frames taken with a slight delay, or to break the processing of one frame into several stages performed in different workflows.  Also, to increase the processing speed, one has to use various hardware acceleration tools available on the device. <br><br><h2>  Instant Translator </h2><br>  Another task is translation.  Arriving in an exotic country, it is difficult to navigate on the streets and in restaurants, since all the inscriptions on the signs, in the menu, etc.  in an unknown language, and the locals may simply not speak English.  For example, here‚Äôs what you can see on the streets and in restaurants of a Chinese city: <br><br><img src="https://habrastorage.org/files/215/054/396/215054396ae3473c87b0cc30728b6f6c.png"><img src="https://habrastorage.org/files/c1c/f06/2cc/c1cf062ccd164d83988bb438ade581fb.png"><br><br>  The application-translator in such a situation, of course, can help, but only if you correctly type all the necessary hieroglyphs.  It is more convenient if the application allows you to take a picture of the text, and then automatically recognize and translate it.  However, it will be problematic to place the entire restaurant menu on one photo.  Have to take pictures several times.  But using text recognition from a video stream, you can translate instantly: the user points the camera at the text, the application behind the scenes recognizes and translates, and on the screen substitutes the source text for its translation, like this: <br><br><img src="https://habrastorage.org/files/b04/273/5ee/b042735eea524d3abc0ef4fc34976bd6.png"><br><br>  Those.  you get such a kind of augmented reality, in which everything is written in a language you can understand. <br>  The need to recognize and translate text on objects around us (for example, on signs that are surrounded by foliage trees; the menu where dishes are painted nearby, etc.) leads to additional difficulties, namely the need to determine where frames, in fact, is the text.  The methods used in FineReader for analyzing binarized images, sharpened for processing text documents, are not suitable in this case.  After binarization (translation into a black and white look), ordinary objects often become similar to text - for example, the windows of buildings can form a whole line: <br><br><img src="https://habrastorage.org/files/364/383/c12/364383c12a3449d7b90eb1be905346ee.png"><br><br><img src="https://habrastorage.org/files/121/ba6/66c/121ba666c3524a0eabb748ed8e0a912d.png"><br><br>  <i>Binarized image</i> <br><br><img src="https://habrastorage.org/files/c20/23b/092/c2023b092e62484493c6d3476431dda3.png"><br><br>  For the processing of frames of a general form, one has to resort to more complex algorithms, to use a special object classifier trained on packages of images of signs and street signs.  The categorizer allows you to understand whether there are letters and lines in the image, separating them from garbage.  Such a mechanism is well described in the <a href="http://www.comp.nus.edu.sg/~cs4243/projects/text_natural_scene.pdf">article</a> . <br><br><h2>  Data capture </h2><br>  Another area for the application of recognition from the video stream is the extraction of data from documents (identity documents, payments, etc.).  Currently, almost all banks in their mobile applications offer the service of payment of housing and communal payments.  In order to make such a payment, now you have to manually reprint long lines of numbers in which you can easily make a mistake (subscriber code, personal account number, etc.).  And automatic recognition of the data needed for payment will simplify and speed up this process. <br><br><h2>  "Smart Camera" </h2><br>  One of the most interesting scenarios can be called ‚Äúsmart camera‚Äù.  We are talking about the usual application "Camera", which is on every smartphone, supplemented by the recognition functionality of the video stream.  When you hover such a camera on a business card, for example, it will automatically create the corresponding contact in the phone book, for a QR code, open the desired link in the browser, for an invitation to an event, create an event in the calendar, etc.  Often, users take pictures of a piece of document if they need to remember the information written there, and the smart camera automatically recognizes the text before the user has time to click on the ‚Äútake a picture‚Äù button and offers to save the recognized data as a note or reminder. <br><br>  But you have to keep in mind that creating a ‚Äúsmart camera‚Äù is fraught with additional difficulties.  The constant operation of such a demanding process as recognition will greatly discharge the device battery.  And practice shows that recognition will need no more than 10-20% of the total time of use of the camera.  Still, photos of cats and selfies are more popular than photos of documents, business cards, bar codes combined.  Therefore, it is necessary to somehow regulate the power consumption of the camera application.  For example, use a special fast text detector, which will analyze the frame and give an answer whether there is text on it or not.  And then for frames with text, additionally call recognition. <br><br>  That is all that they wanted to talk about.  If you have ideas, where else could the recognition technology from the video stream be useful, let's discuss in the comments. <br><br>  <i>Olga Titova,</i> <i><br></i>  <i>product department for developers</i> </div><p>Source: <a href="https://habr.com/ru/post/281973/">https://habr.com/ru/post/281973/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../281963/index.html">April 20 all day, first time online - IT Director Briefing 2016</a></li>
<li><a href="../281965/index.html">What kind of library to work with HTTP in Android choose?</a></li>
<li><a href="../281967/index.html">JavaScript API Development: 5 Principles for Writing Embedded Scripts</a></li>
<li><a href="../281969/index.html">The great Russian firewall is around the corner.</a></li>
<li><a href="../281971/index.html">JetCat: microQt for those who are easier</a></li>
<li><a href="../281975/index.html">Two international conferences in St. Petersburg in June: Experimental Algorithms and Computer Science in Russia</a></li>
<li><a href="../281979/index.html">Quick start for custom docker container on OpenShift platform</a></li>
<li><a href="../281981/index.html">Develop HTML5 games in Intel XDK. Part 7. Design of the game</a></li>
<li><a href="../281983/index.html">Creating a Debian package from scratch</a></li>
<li><a href="../281985/index.html">For the year, Google analyzed 760,000 hacking sites and announced a new tool to alert webmasters.</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>