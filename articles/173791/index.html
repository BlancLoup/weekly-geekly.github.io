<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Visibility through the turbulent atmosphere. Computer correction of images of remote objects</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Author retelling of two publications with a demo film. 

 A solution is proposed to improve the visibility of distant objects observed through a rando...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Visibility through the turbulent atmosphere. Computer correction of images of remote objects</h1><div class="post__text post__text-html js-mediator-article">  Author retelling of two publications with a demo film. <br><br>  A solution is proposed to improve the visibility of distant objects observed through a randomly inhomogeneous atmosphere.  The method is based on real-time processing of sequential shots taken with a digital video camera with a long-focus lens.  The film shows, it seems to me, quite spectacular results. <br><br><a name="habracut"></a><br><h4>  Astronomical retreat. </h4><br>  Anyone who looked through a telescope at high magnification, for example, at the moon, observed a trembling, blurry and changeable image, only occasionally ‚Äúclearing up‚Äù at the moments of fading of air fluctuations.  Areas of space with different densities of air can be imagined as a set of weak irregular random lenses, constantly appearing and disappearing with great frequency. <br>  In astronomy, the classical methods of adaptive optics (wavefront sensors and high-speed deformable mirrors) are used to correct images distorted by atmospheric turbulence.  These are quite complex and expensive systems, available only for large and extra large telescopes, but with a significant positive effect.  Here is a case in point (taken from: Ralf Flicker. Methods of Multi-Conjugate Adaptive Optics for Astronomy, Lund Observatory, Sweden, 2003). 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/storage2/a97/ebb/be4/a97ebbbe45cb7d66d092344325430824.jpg"><br><br>  The left photo is a section of the starry sky, photographed with a long exposure.  Random distortion, superimposed on each other, lead to a significant blurring of the image, with the result that many stars are simply not visible, while others merge with each other.  In the center - the same part of the sky, photographed using an adaptive mirror.  A wavefront sensor, aimed at a bright (supporting) star just below the central cluster, measures wavefront distortions at several points in the entrance aperture.  The computer calculates and delivers control signals through high-voltage amplifiers to piezoelectric pushers.  These pushers, pressing on a flexible mirror from behind in different places, bend it so as to compensate for distortion.  This procedure occurs hundreds of times per second.  In this way, it is possible to improve the image in a certain region near the reference star.  As can be seen from the middle photo, the image does not improve at the edges, because there are other distortions in different parts of the image, other than those measured by the sensor in the center.  With the help of any tricks (multi-conjugate adaptive systems with several reference stars and mirrors), you can expand the area of ‚Äã‚Äãthe improved image - the photo on the right.  By the way, the angular size of this area in the sky is only 90 seconds, or 1/20 of the lunar disk. <br><br>  For a telescope used in ‚Äúterrestrial conditions,‚Äù of course, there is no point in using such a complex technique as an adaptive optical system.  Not only because of the complexity and high cost of living, but also because there are no bright anchor points by which it would be possible to determine the distortion of the wave front.  Unlike stars, distant surface objects, as a rule, have low contrast and length.  And also because the turbulence in the surface layer is significantly higher than in the high-mountain observatories. <br>  Therefore, computational methods for improving the visibility of distant objects in terrestrial conditions, based on post-detector image processing, have, I believe, a good perspective. <br>  First, consider what kind of distortion. <br><br><h4>  A simplified model of image formation in the atmosphere. </h4><br>  In the first approximation, one can adopt a model of imaging of an object that takes into account the passage of a light flux through a randomly inhomogeneous medium described in [1].  It includes three factors that distort the final image in different ways. <br><br>  The first factor is random changes in the wavefront slope within the aperture.  Simply put, large-scale irregularities in air density act as large weak prisms, tilting the light rays slightly in different directions, causing the image to tremble.  Jitter can be removed by measuring the offset of the current frame relative to some reference frame and shifting the image back by the amount of this offset. <br><br>  The second factor is small-scale density fluctuations, which lead to random (for each frame) distortion of fine image details.  Smart people [2,3], based on the theory of atmospheric turbulence and statistical optics, suggest the following method.  Since, due to the stochastic nature of fluctuations, it is impossible to correct each frame, it is necessary to apply statistics.  Time-averaged distortions can theoretically be computed and obtain an optical transfer function that is quite specific for a given state of the atmosphere.  In other words, the averaged image is the result of the action of an atmosphere-specific (non-Gaussian) smoothing filter.  Applying a reverse filter to the image, theoretically we should get a diffraction-quality image. <br><br>  The third factor is the diffraction distortion associated with the finite receiving aperture and with which nothing can be done.  The ideal image of a point will always not be a point, but a disk with rings (the so-called Airy picture). <br><br>  Thus, if we have a sequential set of images of an object, randomly distorted by a turbulent atmosphere, then the image recovery requires the sequential execution of the following operations.  Measurement of random displacements of the image, elimination of these displacements, averaging of centered images, calculation of the inverse optical transfer function, filtering of the averaged image.  Performing these operations continuously with each subsequent frame, we gradually get the corrected image [4].  By applying the procedure to different parts of the frame, it is possible to calculate the optical flow (displacement vector of each pixel as a function of time) over the entire image and expand the adjustable field of view [5]. <br><br><h4>  Algorithm. </h4><br>  Offset Correction.  In the reference frame, choose a square with a size of several dozen pixels, inside which there are more or less contrasting details.  In the current frame it is necessary to find a square of the same size, best of all coinciding with the reference one.  The comparison of squares is made by direct calculation of the mutual correlation function S (p, q): <br><br>  S (p, q) = ‚àë mod [In (x + p, y + q) - I <sub>0n</sub> (x, y)], <br><br>  where I <sub>n</sub> (x, y), I <sub>0n</sub> (x, y) are the brightness of the pixels of the current nth frame and the reference;  x, y - coordinates of square pixels;  p, q - coordinates of the search area, approximately equal in size to the reference square;  summation over all pixels of a square. <br>  The minimum of S (p, q), meaning the place of the best match, is found using the well-known two-step method of searching for extremes of multidimensional functions.  The coordinates of the minimum p <sub>min</sub> , q <sub>min</sub> determine the displacement vector of the current frame relative to the reference.  Then the square from the current frame shifts to the reference frame and is summed with it, forming a new reference frame.  This is the accumulation of the useful signal in the reference square.  The summation is performed recursively with a coefficient R of the order of 0.01‚Äì0.05: <br><br>  I <sub>0n + 1</sub> (x, y) = (1 - R) * I <sub>0n</sub> (x, y) + R * I <sub>n</sub> (x + p <sub>min</sub> , y + q <sub>min</sub> ) <br><br>  Roughly, we can say that the averaging required for further filtering occurs over a moving sample of several dozen frames.  After that, the image bounded by the square becomes generally stable, unlike the rest of the frame. <br><br>  Filtration.  Or elimination of residual blurring of the obtained averaged image due to the influence of small-scale turbulence.  This residual blur, for example, for one bright point, is a spot with a bell-shaped brightness distribution, the width of which depends on the intensity of turbulence and is several times larger than the diffraction disk.  The role of filtering is to transform this diffuse spot into a diffraction-limited Airy picture.  Image filtering and obtaining the final result I (x, y) is performed by two-dimensional direct Fourier transform (operator F) of the averaged image I <sub>0n + 1</sub> (x, y), multiplying the obtained spectrum by the inverse optical transfer function H (x, y), calculated in [2,3], and inverse Fourier transform (operator F <sup>-1</sup> ): <br><br>  I (x, y) = F <sup>-1</sup> [F (I <sub>0n + 1</sub> (x, y)) * H (x, y)], <br><br>  Where <br>  H (x, y)] = [arccos (r) - r * (1 - r <sup>2</sup> ) <sup>1/2</sup> ] * exp [3.44 * rr <sup>5/3</sup> * (1 - r <sup>1/3</sup> )]; <br>  r = (x <sup>2</sup> + y <sup>2</sup> ) <sup>1/2</sup> / D; <br>  rr = (x <sup>2</sup> + y <sup>2</sup> ) <sup>1/2</sup> / d; <br>  D is a quantity depending on the relative aperture of the optical system; <br>  d is a quantity depending on the intensity of turbulence (Fried parameter for the atmosphere). <br><br><h4>  Technical implementation. </h4><br>  The MTO-1000, Vario-Goir-1T, Sigma telephoto lenses with an entrance aperture diameter from 70 to 140 mm and focal lengths from 200 to 5000 mm were used as the optical system.  While I did not have a high-speed video camera, I had to use the Raster Tecknolodgy camera RT-1000DC and observe only fixed objects.  The main results in the film are obtained with her.  As can be seen in the episode with the car number, you need to wait a few seconds until the image "appears." <br>  The episodes with the tower and the building - an attempt to implement the expansion of the corrected area on the entire frame.  I had to work with pre-recorded video files, because the amount of computation is very large, and in general there are still many unsolved problems. <br>  The last episode of the film (‚ÄúThe Snowstorm‚Äù) was filmed quite recently with the JAI network camera RM-6740, the frame rate is 200 Hz, the time for receiving the corrected image is less than 1 second.  In this episode, an additional effect of noise reduction (in the form of falling snow) is observed in the correction area. <br><br><iframe width="420" height="315" src="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://www.youtube.com/embed/avo3LRTWU3k%3Ffeature%3Doembed&amp;xid=17259,15700022,15700186,15700190,15700253&amp;usg=ALkJrhhxOnL84Mm15TBcJNMqttnxWZFomA" frameborder="0" allowfullscreen=""></iframe><br><br>  Literature <br><br>  1. Optics of the Atmosphere and the Ocean, 11, 522 (1998). <br>  2. Goodman J. Statistical Optics (M .: Mir, 1988). <br>  3. Fried DLJ Opt.  Soc.  Am., 56, 1372 (1966). <br>  4. Quantum electronics, Vol. 40, No. 5 (2010), pp.418-420. <br>  5. Quantum electronics, v.41, No. 5 (2011), pp. 475-478. </div><p>Source: <a href="https://habr.com/ru/post/173791/">https://habr.com/ru/post/173791/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../173777/index.html">A bit of "organic" * in the five-inch compartment</a></li>
<li><a href="../173781/index.html">Low cost IEMs with great sound from SoundMAGIC (E10 and PL30 models)</a></li>
<li><a href="../173783/index.html">Quantum mechanics for all, for nothing, and let no one leave offended: part two</a></li>
<li><a href="../173785/index.html">Restore a broken Coreldraw file</a></li>
<li><a href="../173787/index.html">One task, three tools: cPanel, ISPmanager and Plesk</a></li>
<li><a href="../173795/index.html">Sudoku solution methods</a></li>
<li><a href="../173797/index.html">Developing Blueprints plugins in Atlassian Confluence</a></li>
<li><a href="../173799/index.html">Human revolution</a></li>
<li><a href="../173811/index.html">Russian has become the second most popular language of the Internet</a></li>
<li><a href="../173815/index.html">Don Jones "Creating a unified IT monitoring system in your environment." Chapter 2. Elimination of management practices for individual sites in IT management</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>