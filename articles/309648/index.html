<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>WaveNet: a new model for generating human speech and music</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Our cloud platform Voximplant is not only telephone and video calls. It is also a set of "batteries", which we are constantly improving and expanding....">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>WaveNet: a new model for generating human speech and music</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/files/68b/d7b/01e/68bd7b01ebf34ed6bc06993e4f6088ea.jpg" align="right" height="400">  Our cloud platform Voximplant is not only telephone and video calls.  It is also a set of "batteries", which we are constantly improving and expanding.  One of the most popular features: the ability to synthesize speech by simply calling the JavaScript <b>say</b> method during a call.  Developing your own speech synthesizer - for the best idea, we still specialize in a telecom backend written in <b>pluses</b> and capable of processing thousands of simultaneous calls and supplying each of them with JavaScript logic in real time.  We use partner solutions and closely monitor everything new in the industry.  I would like to move away from the ‚ÄúIron Woman‚Äù meme in a few years :) An article, an adapted translation of which we made this weekend, talks about WaveNet, a model for generating sound (sound waves).  In it, we look at how WaveNet can generate speech that is similar to the voice of any person, and also sounds much more natural than any existing Text-to-Speech system, improving the quality by more than 50%. <br><br>  We will also demonstrate that the same network can be used to create other sounds, including music, and show some automatically generated examples of musical compositions (pianos). <br><a name="habracut"></a><br><br clear="all"><h3>  Talking machines </h3><br>  Allowing people and cars to communicate in a voice is people's long-held dream of interaction between them.  The ability of computers to understand human speech has improved significantly over the past few years thanks to the use of deep neural networks (a good example is <a href="https://research.googleblog.com/2015/09/google-voice-search-faster-and-more.html">Google Voice Search</a> ).  However, speech generation - a process commonly referred to as <a href="https://en.wikipedia.org/wiki/Speech_synthesis">speech synthesis</a> or text-to-speech (TTS) - is still based on the use of so-called <a href="https://scholar.google.com/citations%3Fview_op%3Dview_citation%26hl%3Den%26user%3DEs-YRKMAAAAJ%26citation_for_view%3DEs-YRKMAAAAJ:u5HHmVD_uO8C">concatenative TTS</a> .  It uses a large database of short fragments of speech recorded by one person.  The fragments are then combined to form phrases.  With this approach, it is difficult to modify the voice without recording a new database: for example, change to the voice of another person, or add an emotional coloring. <br><br>  This has led to a large demand for parametric TTS, where all the information needed to create speech is stored in the model parameters and the nature of speech can be controlled through the model settings.  However, the parametric TTS still doesn‚Äôt sound as natural as the concatenative option, at least in the case of languages ‚Äã‚Äãlike English.  Existing parametric models usually generate sound, driving the output signal through special handlers, called <a href="https://en.wikipedia.org/wiki/Vocoder">vocoders</a> . 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      WaveNet changes the paradigm by generating a sound signal by sample.  This not only leads to a more natural sound of speech, but also allows you to create any sounds, including music. <br><br><h3>  WaveNets </h3><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/f50/0aa/c4e/f500aac4e565ea6efaaf0c542c82dd0b.gif" alt="image"></div><br>  Usually, researchers avoid modeling audio samples, because they need to be generated a lot: up to 16,000 samples per second or more, of a strictly defined form on any time scale.  Building an autoregressive model in which each sample depends on all previous samples is not an easy task. <br><br>  Nevertheless, our models <a href="https://arxiv.org/abs/1601.06759">PixelRNN</a> and <a href="https://arxiv.org/abs/1606.05328">PixelCNN</a> , published earlier this year, showed that it is possible to generate complex natural images not only one pixel at a time, but also one color channel at a time, which requires thousands of image predictions.  This inspired us to adapt 2-dimensional PixelNets to the one-dimensional WaveNet. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/2fe/b25/464/2feb25464260ad8a96c983bb85340fee.gif" alt="image"></div><br><br>  The animation above shows the WaveNet device.  This is a <a href="https://ru.wikipedia.org/wiki/%25D0%25A1%25D0%25B2%25D1%2591%25D1%2580%25D1%2582%25D0%25BE%25D1%2587%25D0%25BD%25D0%25B0%25D1%258F_%25D0%25BD%25D0%25B5%25D0%25B9%25D1%2580%25D0%25BE%25D0%25BD%25D0%25BD%25D0%25B0%25D1%258F_%25D1%2581%25D0%25B5%25D1%2582%25D1%258C">convolutional neural network</a> , where the layers have different dilatation factors and allow its receptive field to grow exponentially with depth and cover thousands of time segments. <br><br>  During training, incoming sequences are sound waves from voice recording examples.  After training, you can use the network to generate synthetic phrases.  At each sampling step, the value is calculated from the probability distribution calculated by the network.  This value is then returned to the input and a new prediction is made for the next step.  Creating samples in this way is quite a resource-intensive task, but we found that it is necessary to generate complex, realistic sounds. <br><br><h3>  Improving the State of the Art </h3><br>  We trained WaveNet using Google TTS datasets, so we were able to evaluate the quality of its work.  The following graphs show the quality on a scale from 1 to 5 in comparison with the best TTS from Google (parametric and concatenative) and in comparison with the real speech of a living person, using MOS (Mean Opinion Scores).  MOS is a standard way to do subjective tests of sound quality, 100 sentences were used in the test and 500 more grades were collected.  As we can see, WaveNets significantly reduced the gap between the quality of synthesized and real speech for English and Chinese (the difference from previous synthesis methods is more than 50%). <br><br>  For both Chinese and English, Google‚Äôs current TTS is considered one of the best in the world, so such a significant improvement for both languages ‚Äã‚Äãwith one model is a great achievement. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/769/0c9/5d2/7690c95d27df03d1ce3ed08c04fb3bb8.png" alt="image"></div><br><br>  Here are a few examples so you can listen and compare: <br><br>  English (US English) <br><br>  Parametric <br>  <a href="">Example ‚Ññ1</a> <br>  <a href="">Example 2</a> <br><br>  Concatenative <br>  <a href="">Example ‚Ññ1</a> <br>  <a href="">Example 2</a> <br><br>  WaveNet <br>  <a href="">Example ‚Ññ1</a> <br>  <a href="">Example 2</a> <br><br>  Mandarin Chinese <br><br>  Parametric <br>  <a href="">Example ‚Ññ1</a> <br>  <a href="">Example 2</a> <br><br>  Concatenative <br>  <a href="">Example ‚Ññ1</a> <br>  <a href="">Example 2</a> <br><br>  WaveNet <br>  <a href="">Example ‚Ññ1</a> <br>  <a href="">Example 2</a> <br><br><h3>  Understand what to say </h3><br>  To use WaveNet for text-to-speech, you need to clarify what the text is.  We do this by transforming the text into a sequence of linguistic and phonetic characteristics (each contains information about the current phoneme, syllable, word, etc.) and send them to WaveNet.  This means that network predictions depend not only on previous audio samples, but also on the text that we want to convert to speech. <br><br>  If we train the network without textual data, it will still be able to generate speech, but in this case, it will need to come up with something to say.  As can be seen from the examples below, this leads to some similarity of chatter, in which real words are interspersed with generated sounds similar to words: <br><br>  <a href="">Example ‚Ññ1</a> <br>  <a href="">Example 2</a> <br>  <a href="">Example number 3</a> <br>  <a href="">Example 4</a> <br>  <a href="">Example number 5</a> <br>  <a href="">Example 6</a> <br><br>  Notice that sounds that are not speech, such as breathing and mouth movements, are also occasionally generated by WaveNet;  This shows the greater flexibility of the model for generating audio data. <br><br>  Also, as you can see from these examples, one WaveNet network is able to study the characteristics of different voices, male and female.  To give her the opportunity to choose the right voice for each statement, we set the condition for the network to use the identity of the person speaking.  What is even more interesting, we found that training in many different speaking people improves the quality of modeling for one specific voice, compared to training only with the voice of this one person, which implies some form of knowledge transfer during training. <br><br>  By changing the personality of the speaker, we can make the network say the same things with different voices: <br><br>  <a href="">Example ‚Ññ1</a> <br>  <a href="">Example 2</a> <br>  <a href="">Example number 3</a> <br>  <a href="">Example 4</a> <br><br>  Similarly, we can transmit additional information to the model input, for example, about emotions or accents to make speech even more diverse and interesting. <br><br><h3>  Music Creation </h3><br>  Since WaveNets can be used to simulate any audio, we decided that it would be interesting to try generating music.  Unlike the scenario with TTS, we did not configure the network to play something specific (by notes), we, on the contrary, made it possible for the network to generate what it wants.  After training the network on the input from classical piano music, she created several charming pieces: <br><br>  <a href="">Example ‚Ññ1</a> <br>  <a href="">Example 2</a> <br>  <a href="">Example number 3</a> <br>  <a href="">Example 4</a> <br>  <a href="">Example number 5</a> <br>  <a href="">Example 6</a> <br><br>  WaveNets offer many new features for TTS, automatic music creation and audio modeling in general.  The fact that the approach to creating 16KHz audio using step-by-step creation of samples using a neural network in general works already amazing, but it turned out that this approach allowed achieving the result of surpassing the most advanced modern TTS systems.  We are enthusiastic about other possible uses. <br><br>  For more detailed information we recommend reading <a href="https://drive.google.com/file/d/0B3cxcnOkPx9AeWpLVXhkTDJINDQ/view">our written</a> work on this topic. <br><br>  <font color="gray">Picture to attract attention taken from the movie Ex Machina</font> </div><p>Source: <a href="https://habr.com/ru/post/309648/">https://habr.com/ru/post/309648/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../309630/index.html">Expert Opinions on Google‚Äôs 20% Rule</a></li>
<li><a href="../309632/index.html">Creating selling sites using STM model</a></li>
<li><a href="../309636/index.html">Functional security, Part 2 of 7. IEC 61508: Who should be, Sherlock Holmes or Date Tutashkhia?</a></li>
<li><a href="../309644/index.html">Baruch Sadogursky and Kirill Tolkachev about DevOps on jug.msk.ru</a></li>
<li><a href="../309646/index.html">Cable Management and PUE: How are they connected?</a></li>
<li><a href="../309650/index.html">Happy programmer's day: 10 myths about magicians of codes and numbers</a></li>
<li><a href="../309652/index.html">Identification of road network problems using Yandex.Probok. Lecture in Yandex</a></li>
<li><a href="../309654/index.html">We program "Megaprocessor"</a></li>
<li><a href="../309656/index.html">44 most popular projects on Product Hunt over the summer of 2016</a></li>
<li><a href="../309658/index.html">Qualification of fellow programmers: expectation and reality</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>