<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Monitoring of engineering infrastructure in the data center. Part 4. Network infrastructure: physical equipment</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Part 1. Monitoring of engineering infrastructure in the data center. Highlights. 
 Part 2. How is the monitoring of power supply in the data center. 
...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Monitoring of engineering infrastructure in the data center. Part 4. Network infrastructure: physical equipment</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/webt/s4/nr/cu/s4nrcud-is-0-nodcw59se3-u9y.jpeg"><br><br>  <a href="https://habrahabr.ru/company/dataline/blog/319446/">Part 1. Monitoring of engineering infrastructure in the data center.</a>  <a href="https://habrahabr.ru/company/dataline/blog/319446/">Highlights.</a> <br>  <a href="https://habrahabr.ru/company/dataline/blog/324610/">Part 2. How is the monitoring of power supply in the data center.</a> <br>  <a href="https://habrahabr.ru/company/dataline/blog/338966/">Part 3. Monitoring of cold supply by the example of the NORD-4 data center.</a> <br>  Part 4. Network infrastructure: physical equipment. <br><br>  Hi, Habr!  My name is Alexey Bagaev, I am the head of the network department in the DataLine. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Today, I will continue a series of articles on monitoring the infrastructure of our data centers and talk about how we have organized network monitoring.  This is a fairly voluminous topic, so in order to avoid confusion, I have divided it into two articles.  This discussion will focus on monitoring at the physical level, and next time we will look at the logical level. <br><br>  First, I will describe our approach to network monitoring, and then I will tell you in detail about all the parameters of network equipment that we monitor. <br><br><blockquote>  <b>Content:</b> <br>  <a href="https://habr.com/ru/company/dataline/blog/344188/">Our approach</a> <br>  <a href="https://habr.com/ru/company/dataline/blog/344188/">Network monitoring and network monitoring</a> <br>  <a href="https://habr.com/ru/company/dataline/blog/344188/">Network Hosts Status</a> <br>  <a href="https://habr.com/ru/company/dataline/blog/344188/">Temperature readings</a> <br>  <a href="https://habr.com/ru/company/dataline/blog/344188/">Status of the fans in the switches</a> <br>  <a href="https://habr.com/ru/company/dataline/blog/344188/">Power Module Status</a> <br>  <a href="https://habr.com/ru/company/dataline/blog/344188/">Port status</a> <br>  <a href="https://habr.com/ru/company/dataline/blog/344188/">Processor status</a> <br>  <a href="https://habr.com/ru/company/dataline/blog/344188/">Control Plane Policy: the effect of traffic on CPU usage</a> <br>  <a href="https://habr.com/ru/company/dataline/blog/344188/">RAM monitoring</a> <br>  <a href="https://habr.com/ru/company/dataline/blog/344188/">Small bonus</a> <br></blockquote><a name="habracut"></a><br><a name="ONE"></a><h2>  Our approach </h2><br>  Our practice of ‚Äúmonitoring everything‚Äù has been going on for more than five years.  In some areas we do not reinvent the wheel and act by standard methods, but somewhere, by virtue of specificity, we resort to our solutions.  In particular, this concerns the monitoring of the logical level of the network, but, as I said earlier, this is the topic of a future article. <br><br>  In the case of polling the physical layer of the network, everything is quite simple.  The monitoring system of the network infrastructure is based on the open-source tools of Nagios and Cacti.  Just in case, let me remind them of their differences: Nagios records events in real time, and Cacti aggregates statistics, builds graphs and tracks the dynamics of indicators in the long term. <br><br>  The state of the network equipment is monitored through requests using the standard SNMP protocol: <br>  <i>request server ‚Äì agent: GetRequest</i> and <i>agent ‚Äì ‚Äã‚Äãserver: Trap.</i> <br><br>  In the OS of all managed network equipment there are MIB-bases.  The required OID of the object, as a rule, we find using the <i>SNMPWalk command</i> or using the <i>MIB Browser</i> tool.  You can follow this <a href="https://www.reddit.com/r/networking/comments/3yjh0f/decent_mib_browser/">link</a> to the English branch Reddit, in the comments there are several sensible recommendations on this topic. <br><br>  Of course, the equipment is periodically changing and modernizing, and we are updating the monitoring system for new tasks.  Before entering a new host into the product, in parallel with testing, we add this host to the monitoring system and determine the list of objects that we will be tracking. <br><br>  We collect the main metrics of the connected equipment, from the most elementary it is a check for <i>UP / DOWN</i> . <br><br>  In general, we are interested in: <br><br><ul><li>  external factors (temperature, nutrition, etc.); </li><li>  port status (current state, availability); </li><li>  processor status; </li><li>  memory; </li><li>  specificity of "iron" depending on the type of equipment. </li></ul><br>  It cannot be said that a node is more important than the others.  The productive network is also productive in Africa.  ‚ÄúClogged‚Äù memory or an overloaded processor can cause network degradation in general and customer problems in particular.  Macro task in monitoring network iron - timely prevention and troubleshooting before they make themselves known. <br><br><a name="TWO"></a><h2>  Network monitoring and network monitoring </h2><br>  In monitoring the network, we use two ways to access equipment: <i>in-band</i> and <i>out-of-band</i> .  Out-of-band is preferable for us: with such a scheme, the traffic of the monitoring system does not follow the productive links that are used to provide services to customers. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f70/798/84a/f7079884a771fe34421abd3ac0f03f5a.png"><br>  <i>Our monitoring network.</i> <br><br>  We have a special network for monitoring: it is connected by dedicated links to the ports on each network host.  Even if there are problems with productive links, monitoring will work without fail. <br><br>  It often happens that the problem on one link makes a significant part of the network inaccessible for monitoring.  This complicates the work of the support service and slows down the troubleshooting process.  The <i>out-of-band</i> scheme solves this problem. <br><br>  Not all hosts manage to connect <i>out-of-band</i> , and in these cases we use <i>in-band</i> when monitoring traffic goes along with productive.  Oddly enough, despite the obvious shortcomings of this scheme, it has its advantage - reliability. <br><br>  Productive links are backed up by protocols at the L2 and L3 level: if the main link fails, traffic ‚Äúmoves‚Äù to another link.  Nagios can react to this with a flap of services, but the support service will remain in monitoring. <br><br>  Then I will go in order for all the monitoring nodes of the physical network equipment. <br><br><a name="THREE"></a><h2>  Network Hosts Status </h2><br>  We check the availability of the host by sending ICMP requests to its management IP addresses.  Typically, this is a dedicated IP in the equipment control network. <br><br>  Once a minute, the host is checked by running the <i>check_ping</i> plugin for Nagios.  Each call is followed by sending four ICMP requests at 1 second intervals.  The screenshot below shows that the last check was completed with a result of 0% packet loss.  The average response time of the RTA (round trip average) was 2.47 milliseconds.  This is the norm. <br><br><img src="https://habrastorage.org/webt/6f/_e/bj/6f_ebjwy3-gejc-uxeoor_td1ew.png"><br>  <i>Check the status of the host.</i>  <i>UP status: 0% packet loss, average RTA time 2.47 ms.</i>  <i>UPD:</i> <i><br></i>  <i>screenshot changed, thanks for editing <a href="https://habrahabr.ru/users/tortortor/" class="user_link">Tortortor</a></i> <br><br>  How do we understand that a malfunction has occurred?  Of course, it is impossible to entrust the monitoring of all the numbers to the common man: engineers monitor the condition of the equipment in the convenient interface of Nagios.  It has already set proven thresholds for triggering the status of <i>WARNING</i> (approaching undesirable indicators) and <i>CRITICAL</i> (critical threshold exceeding, expert intervention is required). <br><br>  Take a close look at the Performance Data table from the previous screenshot: the Value column contains the current value of the Packet loss parameter.  <i>WARNING</i> is issued when reaching 80% of the lost packets of the total number of sent, <i>CRITICAL</i> - at 100. The RTA (Round Trip Average), equal to 2.47 ms, means the average response time.  A warning will be issued upon reaching 3 ms, the critical threshold is set to 5 ms. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/48e/dda/216/48edda2168e4dd1f2b77bcf44e041db0.png"><br><br>  On the same screen, you can get a brief summary of the following indicators: <br><br><ul><li>  Next Scheduled Active Check - the time of the next check; </li><li>  Last State Change - when the state was last changed; </li><li>  Last Notification - the last notification issued by the system; </li><li>  Is Scheduled Downtime - Whether the inactivity time is scheduled. </li></ul><br><a name="FOUR"></a><h2>  Temperature readings </h2><br>  Recently, my colleagues talked about the monitoring of <a href="https://habrahabr.ru/company/dataline/blog/338966/">cold supply</a> in machine rooms, where they mentioned that for each cold corridor there are three temperature sensors.  These sensors take the overall performance along the corridor and make it possible to judge the operation of the cooling system itself. <br><br>  To monitor the network infrastructure, you need to know the readings of the temperature sensors from each piece of equipment.  This allows you to identify and eliminate not only possible overheating of the hosts, but also to determine at the early stage local overheating of the racks. <br><br>  To get the status of the device, we send a request of the form <i>snmpwalk &lt;parameters&gt; &lt;device&gt; |</i>  <i>grep &lt;what are we looking for&gt;</i> and get a list of all OIDs by the specified filters. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/cd8/a4d/aa9/cd8a4daa94c940be4342d4ed1b0558bc.png"><br>  <i>Request temperature readings on the Cisco ASR9006 router.</i> <br><br>  Having studied the conclusion, we make a more detailed request: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/bb7/187/ee3/bb7187ee3fb558efec44c414caebf4e8.png"><br>  <i>Make a request parameter Inlet Temperature Sensordie to remove the temperature values.</i> <br><br>  And even more detailed: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/38c/b72/b11/38cb72b11d28ed12e1c43a7d562f0350.png"><br>  <i>Select the parameters NP1 and NP2.</i> <br><br>  As a result, we get the OID <i>1.3.6.1.4.1.9.9.91.1.1.1.1.4.index</i> and we can track the readings of the desired temperature sensor.  In our example, the value is 590, i.e. 59 degrees Celsius. <br><br>  In the graphical representation of Nagios, the survey results are as follows: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/573/1d2/685/5731d268549fcafb0620623469ef5596.png"><br><br>  In the screenshot we see the following: <br><br><ul><li>  Temperature 0/0, 0/1, 0/2 - line card sensors of the ASR9006 router; </li><li>  RSP - sensor card Route Switch Processor; </li><li>  RSP / CPU - CPU temperature sensor of the Route Switch Processor card. </li></ul><br><a name="FIVE"></a><h2>  Status of the fans in the switches </h2><br>  To ensure that the equipment does not overheat, we use the cooling system of our data center and the system of cold and hot corridors to ensure a constant flow of air into the rack from the cold corridor and simultaneous ‚Äúblowing out‚Äù of the heated air into the hot corridor.  The role of ‚Äúpumps‚Äù that pump air through the equipment is performed by the fans inside the switches ‚Äî not to be confused with the fans on the racks.  We monitor their status to prevent equipment overheating. <br><br>  If the fan stops, we will have a certain amount of time to replace it, otherwise the equipment may suffer. <br><br>  To get the current status of the fan, make a request similar to the one above: <br><br>  <i>iso.3.6.1.4.1.9.9.117.1.1.2.1.2.24330783 = INTEGER: 2</i> <br>  Answer 2 means ON.  The fan works, Nagios does not panic. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/bef/581/79f/bef58179f90752d784edcdca7ee249e0.png"><br>  <i>This displays the status of the fans in Nagios.</i> <br><br>  A small remark: when setting up monitoring systems, our specialists use the values ‚Äã‚Äãobtained under test loads and ‚Äúcrash tests‚Äù as threshold values.  Getting out of the "normal" range warns of an impending problem, and we have time to "smooth" troubleshooting.  At the same time, in many cases, in real time, we have a rather simple indication of ‚Äúworking / not working‚Äù. <br><br><a name="SIX"></a><h2>  Power Module Status </h2><br>  This indicator is very obvious and does not need comments.  We only mention that the alert system will inform us about the malfunction and / or lack of power in the power supply units of the network equipment themselves. <br><br>  If the power is lost, the service on duty will quickly figure out the reason.  This could be a problem with the power cable, a lack of power at this input, or a problem directly with the unit itself.  Having received the notification, the engineer will take measures and restore the normal operation of the equipment. <br><br>  Power Modules OID: <i>1.3.6.1.4.1.9.9.117.1.1.2.1.2.index</i> <br>  We send a request and get the status: <i>iso.3.6.1.4.1.9.9.117.1.1.2.1.2.53196292 = INTEGER: 2</i> <br><br>  Power module is OK. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f0e/3f6/fed/f0e3f6fed05c953298af5c375983f40b.png"><br>  <i>So the state of the power modules is monitored at Nagios.</i> <br><br><a name="SEVEN"></a><h2>  Port status </h2><br>  To track backbone and subscriber connections, we monitor the following parameters: <br><br><ul><li>  port availability; </li><li>  signal level (for optical ports); </li><li>  traffic volume (port speed); </li><li>  mistakes. </li></ul><br>  I'll tell you about each parameter separately. <br><br>  To check the operational status of the port, we produce a standard OID request. <br><br>  Enter the OID of the desired port: <i>1.3.6.1.2.1.2.2.1.8.ififdex</i> <br>  We <i>get the</i> answer: <i>iso.3.6.1.2.1.2.2.1.8.1073741829 = INTEGER: 2</i> <br><br><img src="https://habrastorage.org/getpro/habr/post_images/aed/647/c72/aed647c722d38e35fb4db291b28d7076.png"><br>  <i>Visualization of the answer in Nagios.</i> <br><br>  If the port is optical, check the signal level on the optics. <br><br>  1. Check the outgoing signal: <br><br>  OID: <i>1.3.6.1.4.1.9.9.91.1.1.1.1.4.txindex</i> <br>  Answer: <i>iso.3.6.1.4.1.9.9.91.1.1.1.1.4.6869781 = INTEGER: 8580</i> <br><br>  2. Then we check the incoming signal: <br><br>  OID: <i>1.3.6.1.4.1.9.9.91.1.1.1.1.4.rxindex</i> <br>  Answer: <i>iso.3.6.1.4.1.9.9.9.11.1.1.1.4.63630989 = INTEGER: 2499</i> <br><br>  Decipher the numbers in the examples above.  The request returns the value in milliwatts to us and shows four decimal places.  That is, the figures above mean 0.8 mW and 0.2 mW.  Next, the built-in function of the Cacti template converts the value to dBm (decibel-milliWatt). <br><br>  Statistics on attenuation levels on optical links is useful when analyzing network problems.  Cacti allows you to see the dynamics of degradation and find the cause of problems on the link. <br><br>  We had an unusual case with a signal on one of the optical paths.  The graph below shows a dip in the optical signal reception level.  This failure lasted a whole week, but then the level abruptly ‚Äúbounced off‚Äù to its normal state.  What could it be, we can only guess.  Perhaps some contractor did work in the telephone sewer, and then quietly returned everything to the site. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f92/294/626/f92294626428dbee57d92cf90784a8ac.png"><br>  <i>Signal statistics on the optical path in Cacti.</i> <br><br>  Another very important parameter is the throughput (speed) of the ports.  We need to get real-time information about the degree of congestion of network links. <br>  This metric allows us to plan traffic and manage network capacity.  In addition, with statistics on link throughput, we can analyze the effects of a DDoS attack and take steps to reduce the impact of DDoS attacks in the future. <br><br>  To get a summary of the number of received and sent packets of information, we use the queries again: <br><br>  1. Received packages <br><br>  OID: <i>1.3.6.1.2.1.31.1.1.1.6.ifindex</i> <br>  Answer: <i>iso.3.6.1.2.1.31.1.1.1.6.1073741831 = Counter64: 109048713968</i> <br><br>  2. Sent packages <br><br>  OID: <i>1.3.6.1.2.1.31.1.1.1.10.ifindex</i> <br>  Answer: <i>iso.3.6.1.2.1.31.1.1.1.10.1073741831 = Counter64: 67229991783</i> <br><br>  The numbers received in the queries above are the number of bytes.  The difference in these values ‚Äã‚Äãfor N seconds / N is the bandwidth in bytes.  If we multiply by eight, we get the bit / s.  Those.  monitoring requests a value once a minute, compares it with the previous one, calculates the difference between two values, translates a byte into a bit and obtains the bit rate / s. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/0e1/34a/fa9/0e134afa9546079756117ed796366613.png"><br>  <i>Graph of data transfer rate in Cacti.</i> <br><br>  Often, our subscribers experience the degradation of Internet channels due to the overflow of the bandwidth allocated for them.  It is difficult to immediately determine the cause of degradation: a symptom on the subscriber‚Äôs side is partial packet loss.  To quickly recognize this problem in Nagios, we set the trigger thresholds to the bandwidth of each subscriber channel. <br><br>  In the Nagios dashboard it looks like this: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b7e/a41/fca/b7ea41fca8bb14937acac628b46d0be8.png"><br><br>  Detailed output: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/4bb/22a/a50/4bb22aa50ab6a8b884279dd2c7b43dd1.png"><br><br>  Exceeding the 80 Gbit / s speed threshold on a 100-gigabit channel is considered dangerous; in such cases, we take measures to unload the channel or expand it.  Remember, you always need to leave ‚Äúspace for maneuver‚Äù, i.e.  free bandwidth in case of rapid traffic growth.  This may be the peak attendance of a resource, backup or, in the worst case, DDoS. <br><br>  Finally, we monitor errors for each port.  Using error statistics, we localize and fix the problem. <br><br>  1. Find out the number of received packets with errors: <br><br>  OID: <i>1.3.6.1.2.1.2.2.1.14</i> . <i>Ifindex</i> <br>  Answer: <i>iso.3.6.1.2.1.2.2.1.14.1073741831 = Counter32: 0</i> <br><br>  2. Check the number of packages that were not sent, because  contained errors: <br><br>  OID: <i>1.3.6.1.2.1.2.2.1.20.ifindex</i> <br>  Answer: <i>iso.3.6.1.2.1.2.2.1.20.1073741831 = Counter32: 0</i> <br><br><img src="https://habrastorage.org/getpro/habr/post_images/eb7/4cf/32e/eb74cf32e657f49fbac051df53386605.png"><br>  <i>Statistics in Cacti records the number of errors in the transmission of packets per second.</i> <br><br>  The indicators <i>Discards In / Out</i> and <i>Errors In / Out</i> on the chart are consolidated counters of all the possible reasons why the data packet could not be transmitted to higher-level protocols. <br><br>  To track errors and find out about problems with links, Nagios has an alert system for each OID.  However, errors can not always be traced promptly, therefore, in order to timely notify the engineers on duty, Nagios has additionally configured a service for monitoring errors at ports. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/764/ed9/e4c/764ed9e4cb22eb0cb6f3919f54544910.png"><br>  <i>This is how error checking on ports in Nagios looks like.</i> <br><br>  Perhaps these are all the key metrics of the ports that we monitor. <br><br>  I will mention only one important point: when you restart a switch with a Cisco IOS operating system, for example Cisco Catalyst 6500, the port-ifindex correspondence changes.  This inevitably leads to the need to reconfigure SNMP requests in the monitoring system.  To fix the interface index values ‚Äã‚Äã(ifindex), you need to enter the <i>snmp ifmib ifindex persist command</i> in global IOS mode, then after reloading the ifindex in the MIB will remain unchanged. <br><br><a name="EIGHT"></a><h2>  Processor status </h2><br>  A processor load close to 100% can adversely affect the health of a network host or the network as a whole.  This is the case when we should instantly find out about exceeding the allowable thresholds.  For this, as you already understood, we use Nagios.  Studying the graphics from Cacti and watching the system in real time, we understand the trends and cyclical operation of the processors.  All this helps engineers to find and neutralize problems before they affect the network. <br><br>  We make a request for the state of the processor of network devices: <br><br>  OID: <i>1.3.6.1.4.1.9.9.109.1.1.1.1.7.index</i> <br>  Answer: <i>iso.3.6.1.4.1.9.9.109.1.1.1.1.7.2098 = gauge32: 2</i> <br><br>  We get the CPU load per minute. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/24b/d16/90a/24bd1690abbffe8c4215f33e7a6b5f76.png"><br>  <i>CPU load status in Nagios.</i> <br><br>  Open detailed information about the state of the processor.  Again, look at the <i>Performance Data</i> item in the screenshot below.  It contains information on the current processor load and threshold values.  The current load is 3%.  The warning system will give a 50% load and will give a <i>CRITICAL</i> signal at 70% load. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/ce5/4f8/054/ce54f8054ba5b45f24f5aef133e82bdc.png"><br>  <i>Detailed information about the state of the processor.</i>  <i>All indicators are normal.</i> <br><br><a name="NINE"></a><h2>  Control Plane Policy: the effect of traffic on CPU usage </h2><br>  This indicator complements the above basic information on CPU usage.  Part of the incoming traffic is processed by the processor, and we track its type and quantity separately.  An increased CPU load can be caused by a DDoS attack, as well as quite valid traffic (ICMP, ARP requests, etc.), which is simply too much. <br><br>  Processing an excessive amount of data, any processor can boot "to the eyeballs" and can not handle service traffic, such as routing protocols - <i>routing updates</i> or <i>hello / keepalive-packages</i> .  Accordingly, the interaction with the neighboring network equipment will stop, and the service will degrade or fall. <br><br>  Here is a real example: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e1f/ec9/db4/e1fec9db4e88846d7224a8d501213fa5.png"><br>  <i>IPv6 routing protocol packet rate.</i> <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e68/707/ec2/e68707ec2c7bede749d2896597ead108.png"><br>  <i>CPU Load Schedule.</i> <br><br>  The graphs show how IPv6 routing protocol packets begin to load the switch CPUs.  This fact can be overlooked in a timely manner and with an increase in the flow of IPv6-packets to get a very painful incident on the network. <br><br>  Using stress tests on network equipment, we determined which traffic by type and number leads to problems on network devices, and we set the optimal threshold values ‚Äã‚Äãfor each of them to <i>control plane policing</i> .  The graphs below show jumps in the values ‚Äã‚Äãabove the threshold. <br><br>  An example of monitoring CoPP (control plane policing) on ‚Äã‚Äãone of the switches in production: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/6b6/b54/2fb/6b6b542fb7c5e2e654e61bf34186d257.png"><br>  <i>The number of bits per second of traffic packets.</i>  <i>ICMP going to CPU processing.</i> <br><br><img src="https://habrastorage.org/getpro/habr/post_images/888/d12/543/888d125433ddcf98fed6e0b3eb52025b.png"><br>  <i>UDP packets.</i> <br><br>  Observing these indicators, we can prevent the increased load on the processor and maintain the stability of the network.  As is the case with the rest of the monitoring data, we collect history using Cacti and display the current situation on monitors using Nagios. <br><br><a name="TEN"></a><h2>  RAM monitoring </h2><br>  One of the most dangerous situations in the case of RAM is memory leak.  It is important to warn and eliminate it in a timely manner, as in small intervals (day, week) a slow but inevitable decrease in free memory can simply be overlooked. <br><br>  Partially solve this problem allows the collection of long-term statistics in Cacti.  We can track down memory overflows and plan a technology window for rebooting equipment.  Unfortunately, in most cases, this is the only absolute method to ‚Äúcure‚Äù a leak. <br><br>  Here is another example from the life of our network: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/57b/11b/7f3/57b11b7f31f4096406ac4fceeef57d7d.png"><br><br>  During the next analysis of monitoring indicators, engineers discovered the dynamics of decreasing the amount of free memory on one of the switches.  The changes were almost imperceptible at short intervals of time, but if we increase the time scale, say up to a month, there appeared a trend towards a gradual decrease in free memory.  When memory is full, the consequences for the switch can be unpredictable, even to the oddities in the behavior of routing protocols.  For example, part of the routes may cease to be announced to its neighbor.  Or it will randomly start to refuse peer-link on the VSS system. <br><br>  The situation described above ended quite well.  We agreed with the customers of the technical window and overloaded the switch. <br><br>  So let's continue.  Cacti plots help determine the exact time of the start of a leak, and by comparing the logs, we find and ‚Äúcure‚Äù the cause. <br><br>  Make a request to load RAM: <br><br>  OID: <i>1.3.6.1.4.1.9.9.221.1.1.1.1.18.index</i> <br>  The answer: <i>iso.3.6.1.4.1.9.9.221.1.1.1.1.18.52690955.1 = Counter64: 2734644292</i> <br><br>  The value indicates the number of bytes from the memory pool used by the operating system. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/071/a3d/ced/071a3dcedf5c8b399349364d9b8098fa.png"><br>  <i>Statistics of loading RAM in Cacti.</i> <br><br>  The engineer on duty ensures that there are no anomalous drops or a trend for permanent filling of free memory using the <i>Memory Usage</i> parameter.  The graph in Cacti shows memory for processes, I / O, shared memory, the amount of free / used memory. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/441/b54/624/441b54624056f94ea3daea084aed3774.png"><br>  <i>The current value of the free RAM of the switch is unloading from Nagios.</i> <br><br>  At the time of the creation of the screenshot, 45503272 bytes of the OP were free, the response thresholds were set: for <i>WARNING</i> - in the range from 35651584 to 39845888 bytes, for <i>CRITICAL</i> - from 0 to 35651584 bytes. <br><br><a name="ELEVEN"></a><h2>  Small bonus </h2><br>  I will write a few words about how the monitoring system alerts us to emergency situations. <br><br>  In our own "kitchen" we do not use additional email or SMS alerts, as the engineers on duty do an excellent job with monitoring the indicators on the screens.  The exceptions are some critical indicators, about the changes that we need to know immediately and regardless of the human factor.  For these indicators, we set up an e-mail or SMS distribution.  At the request of the client, we can set up separate alerts for each response.  Here everything is individual.  When any parameter in Nagios reaches the <i>hard</i> state, the system notifies the customer through the channel that we set up for it. <br><br>  And one more trifle, but pleasant.  The monitoring system not only allows you to quickly respond to events, but also helps the attendants to quickly resolve the problem.  We do this by placing a link to the instructions on the host or the Nagios service: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/535/50c/bc6/53550cbc67b8b24924156c6f787eb0df.png"><br><br>  The link to the resource with the instruction is under the icon ‚ÄúRed Book‚Äù (View Extra Host Notes), as a knowledge base with instructions we use Redmine.  The duty officer can follow the link and clarify the sequence of actions for troubleshooting.  On the left in the screenshot there is a picture in the form of a phone, it is possible to find out the department responsible for this service, and, in case of difficulties, the incident escalates to this division of the production directorate. <br><br>  In conclusion, I want to draw your attention to the rather critical vulnerability of the SNMP protocol (versions 1, 2c and 3) in the Cisco IOS and XE operating systems.  The vulnerability allows an attacker to gain complete control over the system or initiate a reboot of the operating system of the attacked host.  Cisco announced the <a href="https://tools.cisco.com/security/center/content/CiscoSecurityAdvisory/cisco-sa-20170629-snmp">vulnerability</a> on June 29, 2017, and it was closed in new software releases released after mid-July.  If it is not possible to update the software for any reason, as a temporary solution, Cisco recommends that you disable the following MIB bases: <br><br><ul><li>  ADSL-LINE-MIB </li><li>  ALPS-MIB </li><li>  CISCO-ADSL-DMT-LINE-MIB </li><li>  CISCO-BSTUN-MIB </li><li>  CISCO-MAC-AUTH-BYPASS-MIB </li><li>  CISCO-SLB-EXT-MIB </li><li>  CISCO-VOICE-DNIS-MIB </li><li>  CISCO-VOICE-NUMBER-EXPANSION-MIB </li><li>  TN3270E-RT-MIB </li></ul><br>  This monitoring network infrastructure hardware ends.  Ask questions in the comments, and I‚Äôll tell you about monitoring the network infrastructure at the logical level next time. </div><p>Source: <a href="https://habr.com/ru/post/344188/">https://habr.com/ru/post/344188/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../344178/index.html">Postmortem Shadow Tactics: Blades of the Shogun</a></li>
<li><a href="../344180/index.html">Trading supervised: an example of a business monitoring system</a></li>
<li><a href="../344182/index.html">Examination of internal FPGA defects: we are looking for a black cat in a dark room</a></li>
<li><a href="../344184/index.html">Development patterns: MVC vs MVP vs MVVM vs MVI</a></li>
<li><a href="../344186/index.html">How many English words do you need to learn to communicate and read articles? (spoiler: 3000)</a></li>
<li><a href="../344190/index.html">SEO or AdWords? What is more profitable for a b2b company in 2017</a></li>
<li><a href="../344192/index.html">Python literature review for beginners</a></li>
<li><a href="../344194/index.html">Search for an object in an image using a perceptual hash</a></li>
<li><a href="../344196/index.html">DevDay on functional</a></li>
<li><a href="../344198/index.html">Dependent events and statistical fluctuations or why the ‚Äúwaterfall‚Äù will die</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>