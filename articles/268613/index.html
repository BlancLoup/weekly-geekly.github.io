<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Using hardlinks (hardlink) for Synology DSM incremental backup</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="The DSM system is quite convenient and, by default, modules are installed in the system that cover 95% of the needs of an ordinary (and not so much) u...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Using hardlinks (hardlink) for Synology DSM incremental backup</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/files/9f7/bf7/6ea/9f7bf76ea3a24f938876559fd716cf5d.png"><br><br>  The DSM system is quite convenient and, by default, modules are installed in the system that cover 95% of the needs of an ordinary (and not so much) user, which is called ‚Äúout of the box‚Äù. <br><br>  There is also a built-in backup system: Backup &amp; Replication.  Simple, clear and reliable.  As a network destination, it can use either a similar Synology or rsync server. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Unfortunately, this system does not know how to make incremental backup.  The most primitive way to get around this is to set up a separate backup for each day of the week.  Thus, we will have 7 folders with backups, but the obvious disadvantage is the storage of a full copy in each folder - the volume may be such that not everyone will allow himself such a repository. <br><br>  So - let's configure a full incremental backup. <br><a name="habracut"></a><br>  First we need a server with a disk sufficient to store archives of important data.  Where exactly it will be installed - it depends on the capabilities of each.  For example, it can be a virtual hosting or an old system or a virtual machine on a work computer.  You can argue about the reliability of the backup server, but even its very presence is a huge plus to the safety of your personal data.  Again, if you enable mail notifications in DSM, you will know daily if there were any errors during the backup and you will quickly bring back the ‚Äúfallen‚Äù server for storing backup copies. <br><br>  The way that the server will communicate with Synology (or vice versa) everyone will choose for himself - it can be a VPN, a local area network or the usual Internet.  I prefer VPN, but the description of the connection settings is beyond the scope of this article (there may be nuances and I will describe this later). <br><br>  Now the size of the disk on which the archives will be stored. <br><br>  The contents of the home storage can be confidently divided into: Cinema, Music, Photos, and regular user documents. <br>  And if in case of loss of the data of the Cinema it is possible and not difficult to download again, the Music is very likely too, then you cannot restore the Photos and personal files anymore.  The amount of such data from my personal experience does not exceed 50-100GB.  For example, we will make a daily and weekly backup.  Take the maximum: 100GB + 100GB - we need a 200GB drive.  I think?  Nowadays it is a rarity, but 500GB is easy to find! <br><br>  Next, I will talk about the example of a virtual machine, but the basic idea applies to any Linux-based system (possibly FreeBSD). <br><br>  So, we install the Ubuntu server, and activate SSH and rsync on it: <br>  The file system must have hardlink support.  Therefore, we leave the default ext-4. <br><br>  In principle, rsync can also be run on Windows, but we need support for hardlinks, and I'm not sure that rsync can work correctly with Windows Junction. <br><br>  I will clarify the security model on the server - it will be quite simple: <br><br>  - separate user for login (for Synology) <br>  - Restriction on the folder for the IP address at the rsync level <br>  - verification of users at the rsync level - is absent, although it can be easily configured <br>  - if the server is located in unreliable networks on it, it is recommended to enable the firewall and restrict access by IP. <br><br>  We‚Äôll start the setup - we will create a folder for storing archives and give everyone the rights to it: <br><br><pre><code class="bash hljs"><span class="hljs-variable"><span class="hljs-variable">$sudo</span></span> mkdir -p /bakstorage/syno <span class="hljs-variable"><span class="hljs-variable">$sudo</span></span> chmod 777 /bakstorage/syno</code> </pre> <br>  On the server, we need to create an ordinary user, under which Synology will add backup copies: <br><br><pre> <code class="bash hljs"><span class="hljs-variable"><span class="hljs-variable">$sudo</span></span> adduser backup</code> </pre><br>  We rule rsync config: <br><br><pre> <code class="hljs pgsql">cat /etc/rsyncd.conf #  : motd file=/etc/motd <span class="hljs-keyword"><span class="hljs-keyword">log</span></span> file=/var/<span class="hljs-keyword"><span class="hljs-keyword">log</span></span>/rsyncd #    [syno] # IP address  Synology hosts allow = <span class="hljs-number"><span class="hljs-number">192.168</span></span>.xx # ,   <span class="hljs-keyword"><span class="hljs-keyword">comment</span></span> = Syno archive #   ,          <span class="hljs-type"><span class="hljs-type">path</span></span> = /bakstorage/syno #     use chroot = yes <span class="hljs-keyword"><span class="hljs-keyword">lock</span></span> file = /var/<span class="hljs-keyword"><span class="hljs-keyword">lock</span></span>/rsyncd <span class="hljs-keyword"><span class="hljs-keyword">read</span></span> <span class="hljs-keyword"><span class="hljs-keyword">only</span></span> = <span class="hljs-keyword"><span class="hljs-keyword">no</span></span> list = yes uid = nobody gid = nogroup <span class="hljs-keyword"><span class="hljs-keyword">strict</span></span> modes = yes ignore errors = <span class="hljs-keyword"><span class="hljs-keyword">no</span></span> ignore nonreadable = yes transfer logging = <span class="hljs-keyword"><span class="hljs-keyword">no</span></span> timeout = <span class="hljs-number"><span class="hljs-number">600</span></span> refuse <span class="hljs-keyword"><span class="hljs-keyword">options</span></span> = checksum dry-run dont compress = *.gz *.tgz *.zip *.z *.rpm *.deb *.iso *.bz2 *.tbz</code> </pre><br>  And put it in autoload: <br><br><pre> <code class="bash hljs"><span class="hljs-variable"><span class="hljs-variable">$sudo</span></span> update-rc.d rsync defaults</code> </pre><br>  Reboot, check that everything is up. <br><br>  Now we set up archiving in DSM.  Create Network Backup Destination: <br><br><img src="https://habrastorage.org/files/129/bea/210/129bea2106ac4fe091b9323e86295f10.png"><br><br>  Create a ‚ÄúData Backup Task‚Äù, then create a task for daily backup.  Mark the folders you need to save: <br><br><img src="https://habrastorage.org/files/e2f/497/a18/e2f497a185e34e35b9d96bf301a510dd.png"><br><br>  Mark applications (optional): <br><br><img src="https://habrastorage.org/files/52c/00a/36b/52c00a36b25f48f2b74295f9f7a536b4.png"><br><br>  And most importantly - we make it daily (the last option): <br><br><img src="https://habrastorage.org/files/4ed/b0d/24d/4edb0d24ddde4233a23d1c114b76b2a8.png"><br><br>  We exit to the main application window, select the created task and click ‚ÄúBackup now‚Äù - the first copy will take a lot of time.  Subsequent will be performed much faster - only new or modified files will be transferred. <br><br>  After copying is set up and working (you can watch it for several days) - proceed to the next section and add incremental copying.  To do this, we use the excellent rsync property: <br><br><blockquote>  If the original file was changed, and the destination file is hardlink, then when copying, the hardlink is ‚Äúbroken‚Äù and the destination file is replaced with the modified version. <br></blockquote><br><br>  Based on the above rsync property, all we need is to make a copy of the folder with the archive after the backup, with the command: <b>cp -al</b> <br><br>  This will create a complete copy, but all the files inside will be hardlink, so no additional disk space will be occupied.  Well, except that under the tree directories and subdirectories.  Let's call it snapshot creation.  By the way: for a folder of 100GB in size, creating a snapshot takes no more than a minute. <br><br>  We can execute this command at any time, after the intended completion of the backup or, for example, an hour before it. <br>  Thus, if the backup starts at 3:00 and lasts 6 hours (a very unfavorable scenario - usually all changes are copied an order of magnitude faster), then snapshot will be done at 10 am - so that we can make sure that everything worked as it should during the day. <br><br>  The next step is to store N snapshots and automatically delete the oldest ones.  By the way, when implementing such a deletion, folders that are older than N days are usually deleted.  But if archiving has not been done for a long time (for various reasons), it is likely that all folders with archives will be deleted as obsolete, and there will be no new ones!  Therefore, we are learning this. <br><br>  Below are the scripts that will do all this work for us: <br><br><pre> <code class="bash hljs">sudo cat /root/rotate_daily.sh <span class="hljs-comment"><span class="hljs-comment">#!/bin/bash #   echo -n "Started: " date # ,   ,   ,     if [[ /bakstorage/syno/daily -nt /bakstorage/syno/daily_full ]]; then #    - ¬´¬ª   /root/rotate_folders.sh /bakstorage/syno/daily_full 3 #     echo "Copying current backup..." cp -al /bakstorage/syno/daily /bakstorage/syno/daily_full else #  -     ‚Äî    echo "No today backup found!" fi</span></span></code> </pre><br><pre> <code class="bash hljs">sudo cat /root/rotate_folders.sh <span class="hljs-comment"><span class="hljs-comment">#!/bin/bash # ver 1.0 path=$1 hold=$2 if [ -z $2 ]; then cat &lt;&lt;EOT Rotate folders script. Usage: $0 &lt;path_to_folder_prefix&gt; &lt;folders_to_hold&gt; Warning! Folders deleted and renamed by mask: path_to_folder_prefix* so please be sure that no any folders in the path Example: $0 /var/backup/daily 2 The result will be: /var/backup/daily -&gt; /var/backup/daily.1 /var/backup/daily.1 -&gt; /var/backup/daily.2 /var/backup/daily.2 -&gt; Deleted EOT exit 1 fi num=$(ls -d $path* | wc -l) let "num=num-hold" if [ $num -gt 0 ]; then echo "ROTATE_FOLDERS: Found to delete: $num" del=$(ls -d $path* | sort | tail -n $num) echo "ROTATE_FOLDERS: Deleting folder(s):" echo "$del..." rm -r $del else echo "ROTATE_FOLDERS: Nothing to delete." fi # rename let "start=$hold-1" for i in $(seq $start -1 0); do let "y=i+1" if [ $i -eq 0 ]; then echo "ROTATE_FOLDERS: Renaming folders $path to $path.1 ..." mv "$path" "$path.1" else echo "ROTATE_FOLDERS: Renaming folders $path.$i to $path.$y ..." mv "$path.$i" "$path.$y" fi done</span></span></code> </pre><br>  Do not forget to make both scripts executable: <br><br><pre> <code class="bash hljs">chmod 750 /root/rotate_folders.sh chmod 750 /root/rotate_daily.sh</code> </pre><br>  Add to cron: <br><br><pre> <code class="bash hljs"><span class="hljs-variable"><span class="hljs-variable">$sudo</span></span> crontab -e 0 10 * * * /root/rotate_daily.sh &gt;&gt;/var/<span class="hljs-built_in"><span class="hljs-built_in">log</span></span>/rotate_daily.log 2&gt;&amp;1</code> </pre><br>  Note that all output will be recorded in the file: <b>/var/log/rotate_daily.log</b> <br><br>  Actually, with daily copying everything! <br><br>  If we want to add a weekly backup, you can go two ways: <br><br>  1. Set it up by analogy and in parallel with the daily.  This way you will have a completely autonomous set of folders weekly, weekly.1 weekly.2, etc.  which will not intersect with daily folders.  But in this case it will take up as much extra space on the disk as the daily archives. <br><br>  2. Modify the script and once a week create an additional snapshot of the daily folder in the weekly folder, and then also rename the weekly folder to weekly.1, weekly.2, etc. In this case, only modified files will usually take up additional space very few, but if any file is corrupted, it will be corrupted in all folders at once! <br><br>  By the way - the above technique can be applied not only to backups in Synology DSM, but to any system that supports rsync and hardlink. <br><br>  Successful setting! </div><p>Source: <a href="https://habr.com/ru/post/268613/">https://habr.com/ru/post/268613/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../268599/index.html">Enable HTTP / 2 in NGINX for the site</a></li>
<li><a href="../268605/index.html">Primary key - GUID or autoincrement? Part two</a></li>
<li><a href="../268607/index.html">Volker Simonis - Interiors of SAP JVM [Meeting JUG in St. Petersburg]</a></li>
<li><a href="../268609/index.html">Rust in details: we write scalable chat from scratch, part 1</a></li>
<li><a href="../268611/index.html">The digest of interesting materials for the mobile # 124 developer (October 5-11)</a></li>
<li><a href="../268615/index.html">Programming with YII2: get down to work</a></li>
<li><a href="../268617/index.html">Create a REST service on Rust. Part 4: go to the REST API</a></li>
<li><a href="../268619/index.html">Ode to a good vendor: choose a platform for launching a VoIP SaaS project</a></li>
<li><a href="../268621/index.html">Server clustering of markers on the map. From theory to practice</a></li>
<li><a href="../268623/index.html">Email Privacy Notice: Not a Good Idea</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>