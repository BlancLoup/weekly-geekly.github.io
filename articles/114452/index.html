<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Algorithms for image contour selection</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="In the light of recent articles on image processing, I would like to talk a little about contour extraction algorithms: Roberts, Prewitt and Sobel met...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Algorithms for image contour selection</h1><div class="post__text post__text-html js-mediator-article">  In the light of recent articles on image processing, I would like to talk a little about contour extraction algorithms: Roberts, Prewitt and Sobel methods (these methods are taken for consideration as the most well-known and frequently used). <br><br><a name="habracut"></a>  I will not bother with volume theory, but I will confine myself to the minimum information necessary for understanding the essence of algorithms. <br>  All of these methods are based on one of the basic properties of the brightness signal - <b><i>discontinuity</i></b> .  The most common way to search for gaps is to process an image using a <i>sliding mask</i> , also called a <i>filter, core, window, or pattern</i> , which is a kind of square matrix corresponding to a specified group of pixels of the original image.  Matrix elements are called <b><i>coefficients</i></b> .  Handling such a matrix in any local transformations is called <b><i>filtering</i></b> or <b><i>spatial filtering</i></b> . <br><br>  The spatial filtering scheme is illustrated in the figure below (see Figure 1). 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/storage/habraeffect/a2/61/a261ed54c2f7cf97b861acf0cb1d82d6.png" alt="image"><br>  <b>Figure 1.</b> Spatial filtering scheme <br><br>  The process is based on simply moving the filter mask from point to point in the image;  at each point (x, y), the filter response is calculated using pre-defined links.  In the case of linear spatial filtering, the response is given by the sum of the product of the filter coefficients and the corresponding pixel values ‚Äã‚Äãin the area covered by the filter mask.  For a 3x3 mask element shown in Figure 1, the result (response) <b><i>R of the</i></b> linear filtering at the point <u><b><i>(x, y) of the</i></b></u> image will be: <br><br> <b><img src="https://habrastorage.org/storage/habraeffect/71/62/716261c172e441cc966f1959c6d8dc6b.png" alt="image"></b>  <b>(1.1)</b> <br><br>  that, as can be seen, is the sum of the products of the mask coefficients by the pixel values ‚Äã‚Äãdirectly under the mask.  In particular, we note that the coefficient <b><i>w (0, 0)</i></b> stands at <b><i>f (x, y)</i></b> , indicating that the mask is centered at the point <u><b><i>(x, y)</i></b></u> . <br><br>  When detecting differences in brightness, discrete analogs of first and second order derivatives are used.  For simplicity, one-dimensional derivatives will be considered. <br><br>  The first derivative of the one-dimensional function <b><i>f (x)</i></b> is defined as the difference of the values ‚Äã‚Äãof neighboring elements: <br><br> <b><img src="https://habrastorage.org/storage/habraeffect/88/9b/889bd99edf7f2401ee6170383e0d6682.png" alt="image"></b>  <b>(1.2)</b> <br><br>  Here, the record is used in the form of a partial derivative in order to preserve the same notation in the case of two variables <b><i>f (x, y)</i></b> , where it is necessary to deal with partial derivatives along two spatial axes.  The use of the partial derivative does not change the substance of the consideration. <br><br>  Similarly, the second derivative is defined as the difference of the neighboring values ‚Äã‚Äãof the first derivative: <br><br> <b><img src="https://habrastorage.org/storage/habraeffect/08/d7/08d71fd18701713cd9fe9cbb5505e12e.png" alt="image"></b>  <b>(1.3)</b> <br><br>  The calculation of the first derivative of a digital image is based on various discrete approximations of a two-dimensional gradient.  By definition, the image gradient <i><b>f (x, y)</b></i> at the point <b><i>(x, y)</i></b> is a vector [2]: <br><br> <b><img src="https://habrastorage.org/storage/habraeffect/06/80/0680c97aa5c8715cc93051627992c1d0.png" alt="image"></b>  <b>(1.4)</b> <br><br>  As is known from the course of mathematical analysis, the direction of the gradient vector coincides with the direction of the maximum rate of change of the function <i><b>f</b></i> at the point <b><i>(x, y)</i></b> [2]. <br>  An important role in the detection of contours is played by the modulus of this vector, which is denoted by <b><i>‚àáf</i></b> and is equal to <br><br> <b><img src="https://habrastorage.org/storage/habraeffect/9f/50/9f50a63ccbde7885f7e8021f58d82f78.png" alt="image"></b>  <b>(1.5)</b> <br><br>  This value is equal to the value of the maximum rate of change of the function <b><i>f</i></b> at the point <u><b><i>(x, y)</i></b></u> , and the maximum is reached in the direction of the vector <b><i>‚àáf</i></b> .  The value of <b><i>‚àáf is</i></b> also often called the gradient. <br><br>  The direction of the gradient vector is also an important characteristic.  Let <b><i>Œ± (x, y) be the</i></b> angle between the direction of the vector <b><i>‚àáf</i></b> at the point <u><b><i>(x, y)</i></b></u> and the <b><i>x</i></b> axis.  As is known from mathematical analysis [2], <br><br> <b><img src="https://habrastorage.org/storage/habraeffect/88/2e/882e640ab5371273642bb5d88a8c2f56.png" alt="image"></b>  <b>(1.6)</b> <br><br>  From here it is easy to find the direction of the contour at the point <u><i><b>(x, y)</b></i></u> , which is perpendicular to the direction of the gradient vector at that point.  And you can calculate the image gradient by calculating the partial derivatives <i><b>f / ‚àÇx</b></i> and <i><b>‚àÇf / ‚àÇy</b></i> for each point. <br><br><h5>  Roberts operator </h5><br><br>  Let the 3x3 area shown in the figure below (see Fig. 2) be the brightness values ‚Äã‚Äãin the neighborhood of some image element. <br><br><img src="https://habrastorage.org/storage/habraeffect/49/31/4931ed936e16553f39cd504fde053c4d.png" alt="image"><br>  <b>Figure 2.</b> The neighborhood 3x3 inside the image <br><br>  One of the easiest ways to find the first partial derivatives at <img src="https://habrastorage.org/storage/habraeffect/59/eb/59eb2d558af4948d5496a3a3afcbf116.png" alt="image">  consists in applying the following cross gradient Roberts operator [1]: <br><br> <b><img src="https://habrastorage.org/storage/habraeffect/d3/f1/d3f1ea48b22330125fa020efc20c9baf.png" alt="image"></b>  <b>(1.7)</b> <br>  and <br> <b><img src="https://habrastorage.org/storage/habraeffect/39/bd/39bd55e28faee35952912b54e36b3bbe.png" alt="image"></b>  <b>(1.8)</b> <br><br>  These derivatives can be implemented by processing the entire image using the operator, described by masks in Figure 3, using the filtering procedure described earlier. <br><br><img src="https://habrastorage.org/storage/habraeffect/80/01/80010783e0c31112c4ae59f1e288a06a.png" alt="image"><br>  <b>Figure 3.</b> Roberts operator masks <br><br>  The implementation of masks with dimensions of 2x2 is not very convenient, since  they have no clearly defined central element, which significantly affects the result of filtering.  But this ‚Äúminus‚Äù generates a very useful feature of this algorithm - high speed image processing. <br><br><h5>  Operator Prewitt </h5><br><br>  The Prewitt operator, as well as the Roberts operator, operates on the 3x3 image area shown in Figure 2, only the use of such a mask is given by other expressions: <br><br> <b><img src="https://habrastorage.org/storage/habraeffect/58/23/582314e6a5ee32896a7a3dcbe6c37235.png" alt="image"></b>  <b>(1.9)</b> <br>  and <br> <b><img src="https://habrastorage.org/storage/habraeffect/b3/a6/b3a69231b2f15447cae49e01d9f8ae2b.png" alt="image"></b>  <b>(1.10)</b> <br><br>  In these formulas, the difference between the sums in the upper and lower rows of a 3x3 neighborhood is an approximate value of the derivative along the <b><i>x</i></b> axis, and the difference between the sums along the first and last columns of this neighborhood is the derivative along the <b><i>y</i></b> axis.  To implement these formulas, use the operator described by the masks in Figure 4, which is called the Prewitt operator. <br><br><img src="https://habrastorage.org/storage/habraeffect/db/e7/dbe71ce3b210031550ba06a02620ce49.png" alt="image"><br>  <b>Figure 4.</b> Prewitt operator masks <br><br><h5>  Sobel operator </h5><br><br>  The Sobel operator also uses the 3x3 image area shown in Figure 2. It is quite similar to the Prewitt operator, and the modification is to use the weighting factor 2 for the middle elements: <br><br> <b><img src="https://habrastorage.org/storage/habraeffect/91/73/91731286dd11c63ac593c7e704dd82a5.png" alt="image"></b>  <b>(1.11)</b> <br>  and <br> <b><img src="https://habrastorage.org/storage/habraeffect/da/b1/dab1c775fed9ba7065345d7112f563f6.png" alt="image"></b>  <b>(1.12)</b> <br><br>  This increased value is used to reduce the smoothing effect by adding more weight to the midpoints. <br><br>  The masks used by the Sobel operator are shown in the figure below (see Fig. 5). <br><br><img src="https://habrastorage.org/storage/habraeffect/64/ee/64eecd288b768740a5348978717307ba.png" alt="image"><br>  <b>Figure 5.</b> Sobel operator masks <br><br>  The masks discussed above are used to obtain the components of the gradient <img src="https://habrastorage.org/storage/habraeffect/46/17/4617c9e4d4fcee768ffa6b60d936124f.png" alt="image">  .  To calculate the magnitude of the gradient, these components must be used together: <br><br> <b><img src="https://habrastorage.org/storage/habraeffect/c1/7a/c17a76ca4b5eba9cc8c3016dee765baa.png" alt="image"></b>  <b>(1.14)</b> <br>  or <br> <b><img src="https://habrastorage.org/storage/habraeffect/42/4d/424d7b9e0eda408d079d15b8ea298804.png" alt="image"></b>  <b>(1.15)</b> <br><br>  Well, in the end I will demonstrate the results of image processing (see Figures 6-8) by the described methods. <br><br><img src="https://habrastorage.org/storage/habraeffect/de/3b/de3b5ac548be0ef1305ec74195cede41.png" alt="image"><br>  <b>Figure 6.</b> Original image ‚Ññ1 <br><br><img src="https://habrastorage.org/storage/habraeffect/3f/51/3f51ea149099040c1689b3530efdc7c3.png" alt="image"><br>  <b>Figure 7.</b> The original image number 2 <br><br><img src="https://habrastorage.org/storage/habraeffect/37/ac/37ac512d05f041b1045c1a9cc183f600.png" alt="image"><br>  <b>Figure 8.</b> Original image ‚Ññ3 <br><br>  The results of the processing by the methods of Roberts, Prewitt and Sobel are shown below: <br><img src="https://habrastorage.org/storage/habraeffect/c9/88/c988bc8c351edbd75e9dfb13a66dc104.png" alt="image"><br><img src="https://habrastorage.org/storage/habraeffect/a8/39/a8395ff9340ad79a83591ef985ecb936.png" alt="image"><br><img src="https://habrastorage.org/storage/habraeffect/f6/f0/f6f0813eff5766bcaa29fbac3b1e07db.png" alt="image"><br>  <b>Figure 9.</b> Original images after Roberts processing <br><br><img src="https://habrastorage.org/storage/habraeffect/af/1d/af1d2db74f10d263489f38ad7b4c2793.png" alt="image"><br><img src="https://habrastorage.org/storage/habraeffect/81/d9/81d9aac695073e2433d038ee917a64fc.png" alt="image"><br><img src="https://habrastorage.org/storage/habraeffect/03/c1/03c11acfb3bc0a929f4633ddbfff18bf.png" alt="image"><br>  <b>Figure 10</b> .  Original images after processing by Prewitt <br><br><img src="https://habrastorage.org/storage/habraeffect/c7/18/c7180d4c51dc9b6a885c72b50fd6e464.png" alt="image"><br><img src="https://habrastorage.org/storage/habraeffect/87/a6/87a68af138812482c771fdf7480f4ed8.png" alt="image"><br><img src="https://habrastorage.org/storage/habraeffect/47/61/47612d21648c0d19f9b3f56cbb189be2.png" alt="image"><br>  <b>Figure 11.</b> Source images after Sobel processing <br><br><h5>  Bibliography </h5><br><ol><li>  R. Gonzalez, R. Woods Digital Image Processing - M: Technosphere, 2005 - 1007s </li><li>  Kudryavtsev L.V.  A short course of mathematical analysis - M .: Science, 1989 - 736s </li><li>  Anisimov B.V.  Recognition and digital image processing - M .: Higher.  School, 1983 - 295s </li></ol></div><p>Source: <a href="https://habr.com/ru/post/114452/">https://habr.com/ru/post/114452/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../114446/index.html">Barracuda crouched</a></li>
<li><a href="../114447/index.html">Tale of how I became an iPhone software developer</a></li>
<li><a href="../114448/index.html">Once there was the smallest server ...</a></li>
<li><a href="../114449/index.html">W3C Adopts Microsoft's Tracking Protection Technology for Standardization</a></li>
<li><a href="../114450/index.html">Assessing the harmfulness of files using sandboxes, Part 2. Analysis offline</a></li>
<li><a href="../114453/index.html">Belarus faces 38 years in prison for setting up CallService.biz</a></li>
<li><a href="../114454/index.html">Initializr - HTML5 based project generator</a></li>
<li><a href="../114456/index.html">Thunderbolt - like a bolt from the blue</a></li>
<li><a href="../114457/index.html">We collect Mini Bedlam Cube</a></li>
<li><a href="../114459/index.html">Little coders</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>