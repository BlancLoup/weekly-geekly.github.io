<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Internal device llst, part 3. Magic JIT, or how to speed up a virtual machine 50 times</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="In the last article, we showed with humbug how the speed of calculations can vary depending on how the method is executed and its contents. Now we can...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Internal device llst, part 3. Magic JIT, or how to speed up a virtual machine 50 times</h1><div class="post__text post__text-html js-mediator-article"> <a href="http://xkcd.com/303"><img src="https://habrastorage.org/getpro/habr/post_images/4da/691/587/4da69158767d80d5a74303404dc0b2ec.png" align="left" alt="XKCD 303"></a> <br>  In the <a href="http://habrahabr.ru/post/191250/">last article,</a> we showed with <a href="https://habrahabr.ru/users/humbug/" class="user_link">humbug</a> how the speed of calculations can vary depending on how the method is executed and its contents.  Now we can look under the hood of a virtual machine and understand how and why this happens. <br><br>  Earlier, we became acquainted with the <a href="http://ru.wikipedia.org/wiki/Smalltalk">Smalltalk language</a> , or rather with its micro implementation of <a href="http://en.wikipedia.org/wiki/Little_Smalltalk">Little Smalltalk</a> .  Understood with the syntax of the language, the format of the objects in memory and a set of basic instructions.  Now we have come close to the issues of interaction between Smalltalk and <a href="http://ru.wikipedia.org/wiki/LLVM">LLVM</a> (for the sake of this, the whole series of articles was started). <br><br>  Now we have all the necessary knowledge base in order to understand what is being done in <a href="http://llst.org/">our JIT compiler</a> .  In this article, we will learn how Smalltalk bytecodes are converted to LLVM IR code, how code is compiled and executed, and why it works faster than software interpretation.  The most impatient can look at shellcast ( <a href="http://showterm.io/94fe5d4c659f513c16918">one</a> and <a href="http://showterm.io/af34f7f243239b4d7da47">two</a> ) with tsiferkami and running lines (do not forget about the possibility of scrolling). <br><a name="habracut"></a>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h4>  Introduction </h4><br>  Both <a href="http://ru.wikipedia.org/wiki/%25D0%25A2%25D0%25A0%25D0%2598%25D0%2597">TRIZ</a> and common sense considerations tell us that: <br><br><ul><li>  The quickest thing to do is to prove that you don‚Äôt need to; </li><li>  Instead of doing something quickly, you can not get into a fever, but try to do it in advance; </li><li>  Do not do the same job twice (especially if you can not do it at all). </li></ul><br>  These principles go far beyond the limits of human relations and find application in various fields.  Including in computer science.  Many understand the benefits of using <a href="http://ru.wikipedia.org/wiki/%25D0%259A%25D1%258D%25D1%2588">caches</a> .  Some have heard of <a href="http://ru.wikipedia.org/wiki/%25D0%259B%25D0%25B5%25D0%25BD%25D0%25B8%25D0%25B2%25D1%258B%25D0%25B5_%25D0%25B2%25D1%258B%25D1%2587%25D0%25B8%25D1%2581%25D0%25BB%25D0%25B5%25D0%25BD%25D0%25B8%25D1%258F">lazy calculations</a> .  Well, with a counterexample in the face of a senseless, time-consuming bureaucracy, everyone faced. <br><br>  <a href="http://ru.wikipedia.org/wiki/JIT-%25D0%25BA%25D0%25BE%25D0%25BC%25D0%25BF%25D0%25B8%25D0%25BB%25D1%258F%25D1%2586%25D0%25B8%25D1%258F">JIT compilers</a> also have in their arsenal a lot in common with the above considerations.  Our project is no exception.  We will see how the code is executed in the traditional way, and what can be done to improve performance. <br><br><h4>  Differences of the virtual machine from the real processor </h4><br>  The Smalltalk virtual machine is stack-oriented: <br><br><ol><li>  When performing operations, operands are added to the stack; </li><li>  The operation performed removes the required number of operands from the stack; </li><li>  The result is placed back on top of the stack and can be used as an operand for the next operation. </li></ol><br>  The advantages of this approach are the simplicity of the virtual machine code and the ease of implementation of a series of calculations.  Of course, there are drawbacks, the main one being that you have to juggle values ‚Äã‚Äãby placing and removing them from the stack in order to allow the machine to perform some action on them.  Judge for yourself: in the example described in the <a href="http://habrahabr.ru/post/191250/">last article</a> ( <code>Collection&gt;&gt;sort:</code> we repeatedly put the values ‚Äã‚Äãon the stack just to immediately remove them, copy them to the instance of the Array class, and then put the object on the stack again ( <b>markArguments</b> does <b>this</b> ). <br><br>  Of course, this is all done for a reason.  Stacking organization of the machine makes it very easy to record sequences of actions without introducing complex operations.  For example, when calculating arithmetic expressions with brackets, the stack is used as a temporary storage of intermediate values.  According to such principles from time immemorial, engineering calculators were designed using the <a href="http://ru.wikipedia.org/wiki/%25D0%259E%25D0%25B1%25D1%2580%25D0%25B0%25D1%2582%25D0%25BD%25D0%25B0%25D1%258F_%25D0%25BF%25D0%25BE%25D0%25BB%25D1%258C%25D1%2581%25D0%25BA%25D0%25B0%25D1%258F_%25D0%25BD%25D0%25BE%25D1%2582%25D0%25B0%25D1%2586%25D0%25B8%25D1%258F">reverse Polish notation</a> . <br><br>  However, from the point of view of modern processor architecture, Smalltalk is very inconvenient.  Most operations are done with memory.  The principle of locality is not maintained (the objects are all scattered in a heap far from each other).  Constantly generated new objects, which leads to garbage collection and the next shuffling of a large amount of memory.  All memory operations are addressed indirectly.  Finally, a large number of small methods make it impossible to adequately assign registers. <br><br>  Modern processors in the total are registered.  Registers are much faster than RAM, so you can expect greater performance from direct operations on them.  The presence of a volume data cache can significantly reduce the cost of access to memory (while respecting the principle of locality), but, as will be shown below, we achieve success largely due to the principal reduction in the number of memory operations themselves, rather than by moving them to registers. <br><br>  Thus, in order to effectively execute Smalltalk code on the processor, it is necessary to find a way to convert stack logic into register code. <br><br><h4>  JIT compiler stack </h4><br>  <a href="http://llvm.org/docs/LangRef.html">The intermediate</a> code <a href="http://llvm.org/docs/LangRef.html">representation</a> in LLVM uses <a href="http://ru.wikipedia.org/wiki/SSA">SSA</a> notation.  In this notation, there are no variables in our usual form.  All computation is a graph.  Each calculation result (node) can be given a name, and this name can be used in further calculations (link two nodes).  And, once the designated name can not change its value (re-assigning the value of the same name is not allowed).  The name refers only to the point of the program (and the data) where it was announced.  In those places where you still have to work with memory, <a href="http://llvm.org/docs/LangRef.html">the alloca instruction is</a> used, which allocates the memory area of ‚Äã‚Äãthe requested size, as well as the <b>load</b> and <b>store</b> instructions for reading and writing, respectively. <br><br>  Let's once again turn our attention to the Smalltalk bytecodes needed to initialize the <code>left</code> variable from the sort method described earlier: <br><pre> <code class="smalltalk hljs"><span class="hljs-comment"><span class="hljs-comment">"left &lt;- List new"</span></span> <span class="hljs-number"><span class="hljs-number">0023</span></span> <span class="hljs-type"><span class="hljs-type">PushLiteral</span></span> <span class="hljs-number"><span class="hljs-number">4</span></span> <span class="hljs-number"><span class="hljs-number">0024</span></span> <span class="hljs-type"><span class="hljs-type">MarkArguments</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-number"><span class="hljs-number">0025</span></span> <span class="hljs-type"><span class="hljs-type">SendMessage</span></span> new <span class="hljs-number"><span class="hljs-number">0026</span></span> <span class="hljs-type"><span class="hljs-type">AssignTemporary</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">0027</span></span> <span class="hljs-type"><span class="hljs-type">DoSpecial</span></span> popTop</code> </pre><br>  Another example is the beginning of a block from the same method: <br><pre> <code class="smalltalk hljs"><span class="hljs-number"><span class="hljs-number">0037</span></span> <span class="hljs-type"><span class="hljs-type">PushArgument</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-comment"><span class="hljs-comment">"criteria"</span></span> <span class="hljs-number"><span class="hljs-number">0038</span></span> <span class="hljs-type"><span class="hljs-type">PushTemporary</span></span> <span class="hljs-number"><span class="hljs-number">3</span></span> <span class="hljs-comment"><span class="hljs-comment">"x"</span></span> <span class="hljs-number"><span class="hljs-number">0039</span></span> <span class="hljs-type"><span class="hljs-type">PushTemporary</span></span> <span class="hljs-number"><span class="hljs-number">2</span></span> <span class="hljs-comment"><span class="hljs-comment">"mediane"</span></span> <span class="hljs-number"><span class="hljs-number">0040</span></span> <span class="hljs-type"><span class="hljs-type">MarkArguments</span></span> <span class="hljs-number"><span class="hljs-number">3</span></span> <span class="hljs-number"><span class="hljs-number">0041</span></span> <span class="hljs-type"><span class="hljs-type">SendMessage</span></span> value:value: <span class="hljs-comment"><span class="hljs-comment">"  "</span></span> <span class="hljs-number"><span class="hljs-number">0042</span></span> <span class="hljs-type"><span class="hljs-type">DoSpecial</span></span> branchIfFalse <span class="hljs-number"><span class="hljs-number">52</span></span></code> </pre><br>  In either case, it is clear that a large number of simple memory operations are performed.  Basic <b>push</b> instructions can be converted to a pair of assembly instructions.  It is only necessary to copy the pointer (and in fact we work only with pointers to the structures of objects) from one memory region by the offset of the variable index to another region by the offset of the stack top index. <br><br>  The implementation of the above ideas in the IR code may look something like this: <br><pre> <code class="hljs perl">define void @pushValueToStack(%TContext* %context, i32 %index, %TObject* %value) { %stackPointer = getelementptr inbounds %TContext* %context, i32 <span class="hljs-number"><span class="hljs-number">0</span></span>, i32 <span class="hljs-number"><span class="hljs-number">4</span></span> %stack = load %TObjectArray** %stackPointer %stackObject = bitcast %TObjectArray* %stack to %TObject* call %TObject** @setObjectField(%TObject* %stackObject, i32 %index, %TObject* %value) ret void } define %TObject** @setObjectField(%TObject* %object, i32 %index, %TObject* %value) { %fieldPointer = call %TObject** @getObjectFieldPtr(%TObject* %object, i32 %index) store %TObject* %value, %TObject** %fieldPointer ret %TObject** %fieldPointer } define %TObject** @getObjectFieldPtr(%TObject* %object, i32 %index) { %fields = getelementptr inbounds %TObject* %object, i32 <span class="hljs-number"><span class="hljs-number">0</span></span>, i32 <span class="hljs-number"><span class="hljs-number">2</span></span> %fieldPointer = getelementptr inbounds [<span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">x</span></span> %TObject*]* %fields, i32 <span class="hljs-number"><span class="hljs-number">0</span></span>, i32 %index ret %TObject** %fieldPointer }</code> </pre><br>  Yes, it will work and, converted to native code, will be faster than its equivalent implementation for the interpreter.  But the final performance of such a JIT VM will be surprisingly low.  The thing is that the memory operations themselves have not gone away.  We simply transferred them to low-level code, getting rid of the "wrapper" of the software VM. <br><br>  To really speed up the virtual machine, you need to use the LLVM capabilities that we provide, namely SSA, along with a rich set of optimization passes. <br><br>  If we recall the purpose of the <b>push</b> and <b>markArgument instructions</b> , it becomes clear that the stack is used here only to bind some value (argument, literal, constant or temporary variable) with the corresponding cell of the argument array, which is determined by the position of the corresponding <b>push</b> instruction. <br><br>  The SSA notation allows you to do this directly, bypassing the stack.  All we need to do is ‚Äúremember‚Äù which objects we prepared to be placed in an array of arguments, and then copy them immediately at the place of future use.  Since the stored values ‚Äã‚Äãwill also be accessed sequentially according to the <a href="http://ru.wikipedia.org/wiki/LIFO">LIFO</a> principle, it is reasonable to use a stack for storing references.  This <i>stack of values</i> exists and is used only at compile time.  The already generated, ‚Äúcorrect‚Äù code will be executed. <br><br>  This principle works so well that the JIT versions of methods do not use the normal context stack at <i>all</i> .  It is not even initialized when creating a context in the JIT code, and this is a minus one allocation for <i>each</i> message sent. <br><br>  Thus, we obtain the following algorithm for optimized message sending: <br><ol><li>  Instead of pushing an object onto the context stack ( <b>push</b> ), we load the value from the memory into the variable ( <b>load</b> ) and put it on the compiler value stack; </li><li>  Processing the <b>markArguments</b> instruction, we create an argument object, and then sequentially remove elements from the value stack and write ( <b>store</b> ) them in a row to the slots of the created argument array; </li><li>  Call the <b>sendMessage</b> stub handler. </li></ol><br>  It turns out that instead of four memory operations ( <b>load</b> values, <b>store</b> values ‚Äã‚Äãper stack, <b>load</b> values ‚Äã‚Äãfrom the stack and <b>store</b> in the array of arguments), we left only two ( <b>load</b> values ‚Äã‚Äãand <b>store</b> in the array). <br><br>  People familiar with LLVM may argue that such empty memory operations are effectively removed by the optimizer passes and without help.  Indeed, in the simplest case it is.  But the real code that we have to generate looks much more complicated.  This is primarily due to the need to add special markers and value references to ensure the correct operation of the garbage collector. <br><br><h4>  Methods and Functions </h4><br>  As it works, the virtual machine creates its JIT version for each method from the image.  It is a functional equivalent of the method, but is already implemented in the native instructions of the processor.  JIT functions are created when you first send a message that has not been sent yet.  For example, when sending the message <code>List&gt;&gt;sort:</code> first, a message handler will be found, which is the <code>Collection&gt;&gt;sort:</code> method (since the <code>List</code> class does not have the <code>sort:</code> method, but inherits from <code>Collection</code> ).  Then the virtual machine will try to find the JIT function with the same name and will not find it.  The JIT compiler will be called, which, by the body of the method <code>Collection&gt;&gt;sort:</code> will create an equivalent function.  Then this function will be called with the same parameters that were intended for the normal message.  The next time the package is sent, the compiler will not be called, but an existing version of the method will be taken. <br><br><h4>  Message sending </h4><br>  As we remember from the previous article, sending a message to a virtual machine requires: <br><br><ol><li>  Remove values ‚Äã‚Äãfrom the stack and create an array of arguments (made a separate step in <b>markArguments</b> ); </li><li>  Find the method in the hierarchy that will process the message; </li><li>  Create a context object and fill in the fields; </li><li>  Switch to the execution of the new context. </li></ol><br>  At this stage, we cannot influence the procedure for searching the destination method, since the virtual machine has no information about the types of objects.  More specifically, this information is available only at the time of the call and cannot be used to predict the future type of objects.  Therefore, the message search mechanism remains the same and is called using the system function <code>sendMessage()</code> , registered in the module.  This function allows you to access the program VM from the JIT code and ask it to find the message recipient.  Then the control is transferred to the JIT version of the found method. <br><br>  A software VM creates all objects only on the heap, since it has no other memory.  In the case of a JIT VM, we can significantly reduce memory overhead by placing some objects on the stack.  Such objects are: <br><br><ul><li>  Array of arguments; </li><li>  Context object; </li><li>  Array of temporary variables. </li></ul><br>  The lifetime of these objects is not less than the execution time of the method itself (since they always have references from active contexts), so they can be placed on the stack.  When exiting the method, the stack collapses to the previous frame, automatically freeing the occupied memory.  Strictly speaking, the speed of memory allocation on the stack and in the heap is about the same.  Both there and there it is only necessary to move the pointer to the size of the allocated memory and return the resulting value.  But in the case of a bunch, this can lead to the need for garbage collection, which already takes considerable time.  The more often this happens, the more efficient the stack variant will work. <br><br><h4>  Statistics </h4><br>  The ideal end result of the JIT compiler can be represented as follows: <br><br><ul><li>  All involved Smalltalk methods are converted to functions. </li><li>  Each message sending is converted to a direct function call (and not a search stub) </li><li>  Once there are direct calls, the code of blocks and small functions is built in at the place of its use bypassing the parcels. </li></ul><br>  The main problem on the way to achieving RBI is the uncertainty of the type of object from call to call.  Consider once again the Collection &gt;&gt; sort method already known to us: <br><br><pre> <code class="smalltalk hljs">sort: criteria | left right mediane | (<span class="hljs-keyword"><span class="hljs-keyword">self</span></span> size &lt; <span class="hljs-number"><span class="hljs-number">32</span></span>) ifTrue: [ ^ <span class="hljs-keyword"><span class="hljs-keyword">self</span></span> insertSort: criteria ]. mediane &lt;- <span class="hljs-keyword"><span class="hljs-keyword">self</span></span> popFirst. left &lt;- <span class="hljs-type"><span class="hljs-type">List</span></span> new. right &lt;- <span class="hljs-type"><span class="hljs-type">List</span></span> new. <span class="hljs-keyword"><span class="hljs-keyword">self</span></span> do: [ :x | (criteria value: x value: mediane) ifTrue: [ left add: x ] ifFalse: [ right add: x ] ]. left &lt;- left sort: criteria. right &lt;- right sort: criteria. right add: mediane. ^ left appendList: right</code> </pre><br><br>  What can be said about the types of variables used?  Without the execution context and the calling code, nothing definite can be said.  This is both the strengths and weaknesses of Smalltalk.  Strong, because this code will work equally efficiently, regardless of the class of the descendant.  It sorts the list and array in the same way.  Weak, since we cannot do optimization at the compilation stage, relying on knowledge of object types. <br><br>  We have a cunning plan that allows us to get a result close to the optimal one.  And his name is call statistics.  As the program runs, the sendMessage handler is invoked, which, in addition to its main job, also updates the statistics of which classes are involved in sending messages. <br><br>  By postulating that the class hierarchy does not change as the program runs, we will be able to insert direct calls instead of conditions.  Unfortunately, the harsh reality and here gives us a surprise.  For example, collecting statistics, we got the following results: out of 10 consecutive calls, 10 times the variable turned out to be the <code>String</code> class.  But this does not mean that it will be so next time.  Passing through the collection of objects, we can meet a variety of classes.  Finally, even a method that previously returned a <code>String</code> instance may suddenly return <b>nil</b> , simply because the <s>stars</s> were <s>formed</s> this way. <br><br>  Therefore, even with call statistics, the maximum that we can do at this stage is to insert direct calls <i>, provided</i> that the type of the variable is one of the known ones.  In reality, this causes the patcher to insert switch blocks that check the class of the object and transfer control to the corresponding function. <br><br><h4>  Type inference </h4><br>  In the future, it is planned to make a full-fledged type deduction using <a href="http://habrahabr.ru/post/125250/">the Hindley-Milner algorithm</a> and additional heuristics.  Then, in those places where the variable type was derived completely, it will be possible to make direct calls without any checks.  This can have a great effect on the performance and the ability to fully inline the called method into the calling code. <br><br>  For example, looking at the <code>Collection&gt;&gt;sort:</code> method described above, a careful reader may notice that the <code>left</code> and <code>right</code> variables are always initialized by instances of the <code>List</code> class.  The virtual machine can understand this from the following considerations: <br><br><ol><li>  The variable <code>left</code> initialized by the result of the expression <code>List new</code> </li><li>  In the <code>List new</code> expression, <code>List new</code> takes no parameters and has a fixed action object ( <code>List</code> ) </li><li>  Sending a <code>#new</code> message to a <code>List</code> object is processed by the <code>List&gt;&gt;new</code> method </li><li>  The <code>List&gt;&gt;new</code> method returns the result of the expression <code>super new</code> </li><li>  In the current context, it will be <code>List super</code> that is, <code>Collection</code> </li><li>  Sending a <code>#new</code> message to a <code>Collection</code> object is handled by the <code>Object&gt;&gt;new</code> method </li><li>  The <code>Object&gt;&gt;new</code> method contains the primitive 7, which always returns an object of a known class (axiom) </li></ol><br>  Then the expressions are folded in the reverse order, which leads to the statement: "The variable <code>left</code> initialized by an object of the <code>List</code> class". <br><br>  Knowing the class of variables <code>left</code> and <code>right</code> , the remainder of the method can also be optimized.  The operations <code>#add:</code> <code>#sort:</code> and <code>#appendList:</code> are compiled using direct method calls without additional conditions. <br><br>  In fact, a thorough type inference is desirable but not necessary.  It is enough to know that the type of the variable <i>does not change</i> from call to call.  And what exactly it will be, we will find out at the first actual message sending.  Everything together will allow to exclude type checking during program execution, reduce code size and untie the hands of the optimizer. <br><br><h4>  Compilation </h4><br>  Those who read up to this point, but have a weak idea of ‚Äã‚Äãwhat <a href="http://ru.wikipedia.org/wiki/Low_Level_Virtual_Machine">LLVM is</a> , I advise you to read the numerous and quite good posts on Habr√©, or the articles <a href="http://www.aosabook.org/en/llvm.html">Hacker's introduction to LLVM</a> and <a href="http://llvm.org/docs/LangRef.html">LLVM Language Reference Manual</a> .  In English, of course. <br><br>  So, LLVM takes as its input an IR representation written in the form of chains of instructions.  The instructions are organized in essence, called <i>basic blocks</i> .  A feature of such a unit is that it has only one input and one output.  This is done intentionally, for convenience.  Inside the block can be placed any instructions, except those that transfer control.  That is, conditional jumps, return, overshoot, and exception catching instructions cannot be in the middle of a block (function calls are valid if they do not throw exceptions).  If this is still necessary, then the block in this place is divided into two, so that the problem instruction (in LLVM terminology, it is called the <i>terminator</i> ) is in the tail of the first half.  Thus, the entire function consists of a set of basic blocks and transitions between them (the transition instructions themselves operate not with addresses, but with block identifiers, to which control should be transferred). <br><br>  Our task is to read the bytecodes of the method and recreate it in the IR code, preserving the logic of the transitions, and eventually get a functional equivalent.  Of course, this does not mean that we should repeat the operations of bytecodes word for word, but we need to ensure correctness. <br><br>  The first problem is that the bytecodes of the method are written together, in one array.  Naturally, there are no base blocks there, and all the jump addresses are recorded in the offset system relative to the beginning of the array.  Therefore, the first thing we need is to build the correspondence between the offsets in the transition instructions and the base blocks.  Now this is done by passing bytecodes beforehand ( <a href="">scanForBranches</a> method <a href="">from MethodCompiler.cpp</a> ) <br><br>  Having the ‚Äúfish‚Äù in the hands of the future blocks of the method, we begin to ‚Äúfill‚Äù it with instructions.  The packing itself takes place sequentially.  We go from the beginning of the method, translating the Smalltalk instructions into the corresponding operations in the IR code.  Recall that <b>push</b> instructions are not directly encoded: instead, we <a href="">push the TDeferredValue</a> structure (see also <a href="">TStackValue</a> ), which describes the necessary delayed action, <a href="">onto the</a> value stack.  Then, when in the code we stumble upon an operation that removes such a value from the stack, we perform a deferred action and get the actual name that can already be used.  In simple cases, of which the majority, actions are postponed for just a couple of instructions, so the actual position of the operation in the code does not change.  In essence, there is a logical linking of two places in the code, without the need to enter intermediate values ‚Äã‚Äã(or use the context stack).  How exactly the transfer of the value in the present code will be implemented is decided by the LLVM. <br><br>  For example, if in bytecodes we had: <br><pre> <code class="smalltalk hljs"><span class="hljs-comment"><span class="hljs-comment">"left &lt;- List new"</span></span> <span class="hljs-number"><span class="hljs-number">0023</span></span> <span class="hljs-type"><span class="hljs-type">PushLiteral</span></span> <span class="hljs-number"><span class="hljs-number">4</span></span> <span class="hljs-number"><span class="hljs-number">0024</span></span> <span class="hljs-type"><span class="hljs-type">MarkArguments</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-number"><span class="hljs-number">0025</span></span> <span class="hljs-type"><span class="hljs-type">SendMessage</span></span> new <span class="hljs-number"><span class="hljs-number">0026</span></span> <span class="hljs-type"><span class="hljs-type">AssignTemporary</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">0027</span></span> <span class="hljs-type"><span class="hljs-type">DoSpecial</span></span> popTop</code> </pre><br>  ... then when compiling this piece, the sequence of actions will be as follows: <br><br><ol><li>  Create a pending operation "put the fourth literal on the stack." </li><li>  The markArguments instruction requires removing the value from the stack.  This leads to the execution of a deferred operation: create the name <code>lit0</code> , to which we bind the read operation of the fourth element from the array of literals.  This name is put on the stack of values ‚Äã‚Äãof the current base unit. </li><li>  Create an array of one element, associate it with the name <code>args0</code> .        .     ,      ,      (  <code>lit0</code> ).  , : <code>args0[0] = lit0</code> . </li><li>    sendMessage,         <code>args0</code> .        (     ,    ). </li><li>   temp0,       .       <code>temp0</code> . </li><li>         ( <b>popTop</b> ). </li></ol><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">At first glance, it is scary, but in fact, it all comes together in just a few assembly instructions. In particular, when forming an array of arguments, we left only the necessary memory operations: read the literal, write it into an array, send a message, and write the result in a temporary variable.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Software VM for the same set of operations is forced to repeatedly read and write memory when working with the stack. It puts the value into the context stack only to immediately get it back and then write it into an array of arguments. It again puts the pointer to the created array of arguments on the stack, then pulls it out of the stack and uses it when sending a message, the result of which is put on the stack again for a couple of moments, etc. Each extra operation is a loss of performance. Even with modern processors and fat data caches.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In our country, even an array of arguments is not created on the heap, but located in the real call flow stack. Therefore, allocation and filling of the array occurs quickly. The most important thing is that LLVM, operating with IR, is free to do all kinds of optimizations that we do not see directly, but which it considers appropriate. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">For example, it may happen that the same temp value is used twice in a row. Then, instead of re-reading the value, LLVM can use the previous name (if it does not affect the result). And these little things recruited a whole bunch. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">... We have considered a variant in which the stack of compiler values ‚Äã‚Äãis used locally. But things get a lot more complicated when transition operations come into play. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">All </font><b><font style="vertical-align: inherit;">push</font></b><font style="vertical-align: inherit;"> operations</font></font><b><font style="vertical-align: inherit;"></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">performed on a local stack of values ‚Äã‚Äãof the current base unit. </font><font style="vertical-align: inherit;">The operations of taking values ‚Äã‚Äãfrom the stack may be non-local. </font><font style="vertical-align: inherit;">In this case, the value is removed from the block above the transition hierarchy. </font><font style="vertical-align: inherit;">For example: there are two basic blocks X and Y. Block X consists of operations </font></font><code>pushTemporary 0</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">and</font></font><code><code><code>branch ,        Y. ,   Y    markArguments 1</code> ,      .   ,     Y        .        ,   Y    X,     .     . <br> <br>     Y      X <sub>1</sub> ..X <sub>n</sub> ,      <a href="http://llvm.org/docs/LangRef.html">œÜ-</a> ,          SSA.             X <sub>i</sub> ,           ,     .      ,      . <br> <br>      ,    <a href="">MethodCompiler::TJitContext::popValue()</a>   <a href="https://github.com/0x7CFE/llst/blob/v_0.3/doc/JITcompilation.txt">JITCompilation.txt</a>  . <br> <br>  <br>  ,  ,      ¬´ ¬ª.        ,   ,           .     <code>Collection&gt;&gt;sort:</code>     ,      .   ,       ,    . <br> <br>   ,         . ,       ,       .     ,    . <br> <br>       ,         .  ,       10%  ,  ,     ‚Äî  . ,   :</code></code> <h4> <code><code><code>branch ,        Y. ,   Y    markArguments 1</code> ,      .   ,     Y        .        ,   Y    X,     .     . <br> <br>     Y      X <sub>1</sub> ..X <sub>n</sub> ,      <a href="http://llvm.org/docs/LangRef.html">œÜ-</a> ,          SSA.             X <sub>i</sub> ,           ,     .      ,      . <br> <br>      ,    <a href="">MethodCompiler::TJitContext::popValue()</a>   <a href="https://github.com/0x7CFE/llst/blob/v_0.3/doc/JITcompilation.txt">JITCompilation.txt</a>  . <br> <br>  <br>  ,  ,      ¬´ ¬ª.        ,   ,           .     <code>Collection&gt;&gt;sort:</code>     ,      .   ,       ,    . <br> <br>   ,         . ,       ,       .     ,    . <br> <br>       ,         .  ,       10%  ,  ,     ‚Äî  . ,   :</code></code> </h4> <code><code><code>branch ,        Y. ,   Y    markArguments 1</code> ,      .   ,     Y        .        ,   Y    X,     .     . <br> <br>     Y      X <sub>1</sub> ..X <sub>n</sub> ,      <a href="http://llvm.org/docs/LangRef.html">œÜ-</a> ,          SSA.             X <sub>i</sub> ,           ,     .      ,      . <br> <br>      ,    <a href="">MethodCompiler::TJitContext::popValue()</a>   <a href="https://github.com/0x7CFE/llst/blob/v_0.3/doc/JITcompilation.txt">JITCompilation.txt</a>  . <br> <br>  <br>  ,  ,      ¬´ ¬ª.        ,   ,           .     <code>Collection&gt;&gt;sort:</code>     ,      .   ,       ,    . <br> <br>   ,         . ,       ,       .     ,    . <br> <br>       ,         .  ,       10%  ,  ,     ‚Äî  . ,   :</code></code> </div><p>Source: <a href="https://habr.com/ru/post/197474/">https://habr.com/ru/post/197474/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../197464/index.html">The ninth Forum for IT directors "Efficiency in our genes!"</a></li>
<li><a href="../197466/index.html">How I hacked Habrahabr</a></li>
<li><a href="../197468/index.html">A couple of shortcomings in creating a web application on Go</a></li>
<li><a href="../197470/index.html">Comet Halley? She flew away, but promised to return ...</a></li>
<li><a href="../197472/index.html">7 useful books for the head</a></li>
<li><a href="../197476/index.html">UNPIVOT</a></li>
<li><a href="../197484/index.html">Organization of a shared calendars and contacts service for corporate use based on free software</a></li>
<li><a href="../197486/index.html">ECM-systems: is it possible to master playfully, or five kopecks in defense of gamification</a></li>
<li><a href="../197488/index.html">We put Avaya Contact Recorder (Linux)</a></li>
<li><a href="../197494/index.html">JavaFX - the unprincipled HelloWorld</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>