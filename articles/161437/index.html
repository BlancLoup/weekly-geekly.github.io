<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>MapReduce 2.0. What is modern digital elephant?</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="If you are ITchnik, then you can‚Äôt just take it and go to work on January 2 : review the third season of the psychic battle or recording the Gordon pr...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>MapReduce 2.0. What is modern digital elephant?</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/getpro/habr/post_images/344/e1c/df0/344e1cdf0b3e428a669913e36c5528c1.png"><br><br>  If you are ITchnik, then <em>you can‚Äôt just take it and go to work on January 2</em> : review the third season of the psychic battle or recording the Gordon program on NTV (a matter of <strike>mental abilities of</strike> taste). <br>  It cannot be because other employees will definitely have gifts for you: the secretary has run out of coffee, the MP has deadlines, and the database administrator has <strike>amnesia</strike> memory. <br>  It turned out that the engineers at the Hadoop team also love to pamper each other with New Year's surprises. <br><br><h3>  2008 </h3><br>  <em>January 2.</em>  Lacking a detailed description of the emotional and psychological state of those participating in the events described below, I will immediately turn to the fact: the Map-Reduce 2.0 task has been set up for <a href="https://issues.apache.org/jira/browse/MAPREDUCE-279">MAPREDUCE-279</a> .  Leaving a joke about the number, I‚Äôll note that before the 1st stable version of Hadoop there is just under 4 years. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      During this time, the Hadoop project will evolve from a small innovative snowball, launched in 2005, to a large snow <strike>com</strike> , impending on IT, in 2012. <br>  Below we will make an attempt to find out what value the January task of MAPREDUCE-279 played (and I am sure it will play in 2013) in the evolution of the Hadoop platform. <a name="habracut"></a><br><br><h3>  2011 </h3><br>  In February 2011, Yahoo engineers delighted the world with the article ‚ÄúThe Next Generation of Apache Hadoop MapReduce‚Äù [2].  In October 2011, the Apache Software Foundation published in its wiki-work entitled ‚ÄúApache Hadoop NextGen MapReduce (YARN)‚Äù [1].  On December 27, the world saw the inscription on the Apache Software Foundation website: <br><blockquote>  ... release 1.0.0 available.  After six years of gestation, Hadoop reaches 1.0.0! </blockquote>  and link the stable version of Hadoop v1.0. <br><br><h3>  2012 </h3><br>  Hadoop 2.0.0-alpha became available for download at the end of May.  In May, the book ‚ÄúHadoop: The Definitive Guide, Third Edition‚Äù (by Tom White) was published, where YARN was given a significant amount.  In early June, Tom White made a presentation of ‚ÄúMapReduce 2.0‚Äù ( <a href="http://vimeo.com/43474797">video</a> ) at the Chicago Hadoop User Group.  In the same month, Cloudera announced the support for Hadoop 2.0.0 Alpha in its CDH4 product.  A little later, Hortonworks also announced support for Hadoop 2.0 in its distributions. <br><br>  On September 17, the Apache Software Foundation published that YARN and MapReduce v2 are available in Hadoop 0.23.3. <br><br>  <em>Below, we will look at the approaches to distributed computing in the classic Hadoop MapReduce and the new architecture, describe the techniques and components that implement the concepts of the new model, and compare the classical and 2.0 architectures.</em> <br><br><h2>  1. Hadoop MapReduce Classic </h2><br>  <strong>Hadoop</strong> is a popular software framework for building distributed applications for massive parallel processing (MPP) data. <br><br>  Hadoop includes the following components: <br><ul><li>  <em>HDFS</em> - distributed file system; </li><li>  <em>Hadoop MapReduce</em> is a program model (framework) for performing distributed calculations for large amounts of data within the map / reduce paradigm. </li></ul><br>  The concepts embodied in the <a href="http://www.codeinstinct.pro/2012/08/mapreduce-design.html">Hadoop MapReduce architecture</a> and <a href="http://www.codeinstinct.pro/2012/08/hdfs-design.html">the HDFS structure</a> caused a number of bottlenecks in the components themselves, including single points of failure.  This ultimately determined the limitations of the Hadoop platform as a whole. <br><br>  The latter include: <br><ul><li>  Hadoop cluster <em>scalability limitation</em> : ~ 4K compute nodes;  ~ 40K parallel tasks; <br></li><li>  <em>Strong connectedness of the</em> distributed computing framework and client libraries implementing the distributed algorithm.  Consequently: <ul><li>  Lack of support for an alternative software model for performing distributed computing: in Hadoop v1.0, only the map / reduce model is supported. </li></ul></li><li>  <em>The presence of single points of failure</em> and, as a consequence, the impossibility of use in environments with high requirements for reliability; <br></li><li>  <em>Version compatibility issues</em> : the requirement for a one-time update of all computing nodes in the cluster when upgrading the Hadoop platform (installing a new version or service pack); <br></li><li>  Lack of support for work with updateable / streaming data. <br></li></ul><br>  The new Hadoop architecture aimed to remove many of the above limitations. <br>  On the very architecture of Hadoop 2.0 and the limitations that it allowed to overcome, and let's talk below. <br><br><h2>  2. Hadoop MapReduce Next </h2><br>  Major changes have been made to the Hadoop MapReduce distributed computing component. <br><br>  The classic Hadoop MapReduce was a single <em>JobTracker</em> process and an arbitrary number of <em>TaskTracker</em> processes. <br><br>  In the new Hadoop MapReduce architecture, JobTracker‚Äôs resource management and task life cycle planning / coordination functions were divided into 2 separate components: <br><ul><li>  ResourceManager resource manager; <br></li><li>  <em>ApplicationMaster</em> scheduler and coordinator. <br></li></ul><br>  Consider each component in more detail. <br><br><h3>  ResourceManager </h3><br>  <strong>ResourceManager</strong> (RM) is a global resource manager whose task is to allocate the resources requested by applications and monitor the compute nodes on which these applications run. <br><br>  ResourceManager, in turn, includes the following components: <br><ul><li>  <em>Scheduler</em> - the scheduler responsible for the allocation of resources among the requested resources applications. <br>  Scheduler is a ‚Äúclean‚Äù scheduler: it does not monitor or track application status. <br></li><li>  <em>ApplicationsManager</em> (AsM) is the component responsible for starting ApplicationMaster instances, as well as monitoring the nodes (containers) on which execution takes place and restarting the "dead" nodes. <br></li></ul><br>  It is worth noting that the Scheduler in the ResourceManager is a plugin component (pluggable).  There are 3 types of Scheduler: FIFO scheduler (default), Capacity scheduler and Fair scheduler.  In the Hadoop version 0.23, the first 2 types of schedulers are supported, the 3rd is not. <br><br>  Resources are requested from RM for the abstract concept of <em>Container</em> , which will be discussed later, and which can be set such parameters as the required processor time, the amount of RAM, the required network bandwidth.  As of December 2012, only the ‚ÄúRAM‚Äù parameter is supported. <br><br>  The introduction of RM makes it possible to treat cluster nodes as computational resources, which qualitatively enhances the utilization of cluster resources. <br><br><h3>  Applicationmaster </h3><br>  <strong>ApplicationMaster</strong> (AM) is the component responsible for planning the life cycle, coordinating and tracking the execution status of a distributed application.  Each application has its own ApplicationMaster instance. <br><br>  At this level, it is just worth considering YARN. <br><br><a name="yarn"></a>  <strong>YARN</strong> (Yet Another Resource Negotiator) is a software framework for running distributed applications (which the ApplicationMaster instance is).  YARN provides the components and APIs needed to develop distributed applications of various types.  The framework itself assumes responsibility for the allocation of resources in response to requests for resources from running applications and the responsibility for tracking the status of application execution. <br><br>  The YARN model is more general (generic) than the model implemented in the classic Hadoop MapReduce. <br><br>  Thanks to YARN on the Hadoop cluster, it is possible to run not only ‚Äúmap / reduce‚Äù applications, but also distributed applications created using: Open MPI, Spark, Apache HAMA, Apache Giraph, etc.  It is possible to implement other distributed algorithms (here it is the power of the OOP!).  Detailed <a href="http://wiki.apache.org/hadoop/WritingYarnApps">instructions are</a> described in the Apache Wiki. <br><br>  In turn, <strong>MapReduce 2.0</strong> (or MR2, or MRv2) is a framework for performing distributed computing within the map / reduce program model that lies above the YARN level. <br><br>  The division of responsibility for resource management and application life-cycle planning / coordination between the components of the ResourceManager and ApplicationMaster made the Hadoop platform more distributed.  That, in turn, had a positive impact on the scalability of the platform. <br><br><h3>  Nodemanager </h3><br>  <strong>NodeManager</strong> (NM) - an agent running on a compute node, whose duties include: <br><ul><li>  tracking of used computing resources (CPU, RAM, network, etc.); <br></li><li>  sending reports on the resources used to the ResourceManager / Scheduler resource manager scheduler. <br></li></ul><br><h3>  Interaction protocols </h3><br>  Control commands and status transfer to various components of the Hadoop platform are made through the following protocols: <br><ul><li>  <em>ClientRMProtocol</em> - client interaction protocol with the ResourceManager for starting, checking the status and closing applications. <br><img alt="Hadoop MapReduce 2.0. ClientRMProtocol" src="https://habrastorage.org/getpro/habr/post_images/f41/728/b78/f41728b7807b63efc3b4243633acb077.png"><br></li><li>  <em>AMRMProtocol</em> is a protocol for communicating ApplicationMaster instances with a ResourceManager for subscribing / unsubscribing AM, sending a request and receiving resources from RM. <br><img alt="Hadoop MapReduce 2.0. AMRMProtocol" src="https://habrastorage.org/getpro/habr/post_images/34c/270/048/34c27004889f138502c19e28cd5e9d8d.png"><br></li><li>  <em>ContainerManager</em> - ApplicationMaster interaction protocol with NodeManager to start / stop and obtain the status of containers under NM control. <br><img alt="Hadoop MapReduce 2.0. ContainerManager" src="https://habrastorage.org/getpro/habr/post_images/389/918/23f/38991823fcdf741e68a2bc4cb59309fb.png"><br></li></ul><br><h2>  3. Hadoop MapReduce.  Vis-√†-vis </h2><br>  Part 1 of Hadoop MapReduce Classic gave an introduction to the Hadoop platform and describes the main limitations of the platform.  Part 2 of Hadoop MapReduce Next described the concepts and components introduced into the new version of the Hadoop MapReduce distributed computing framework. <br><br>  We will discuss how the YARN, MR2 concepts and components implementing these concepts changed the distributed computing architecture on the Hadoop platform, and how these changes helped (or not) get around the existing limitations of the platform. <br><br>  - About terminology <br>  Since the discussion below will deal with the comparison of the classic and "2.0" versions of Hadoop MapReduce, in order to avoid: <br><ul><li>  ambiguities associated with the discussed version, and / or </li><li>  endless updates of the version in question </li></ul>  I will continue to adhere to the following <em>conditional</em> terminology: <br><ul><li>  <em>Hadoop MapReduce 1.0</em> - ‚Äúclassic‚Äù plain (unless otherwise noted) Hadoop MapReduce; <br></li><li>  <em>Hadoop MapReduce 2.0</em> is YARN and MapReduce v2.0. <br></li></ul>  - <h3>  Architecture </h3><br>  In Hadoop MapReduce 1.0, the cluster has a single JobTracker node that distributes tasks across multiple TaskTracker nodes that directly perform tasks. <br><br><div style="text-align:center;"><img alt="Hadoop MapReduce. Job job" src="https://habrastorage.org/getpro/habr/post_images/e78/ff5/f57/e78ff5f5741461bcfcb8633b64143e84.png"></div><br><br>  In the new Hadoop MapReduce architecture, the responsibility for resource management and scheduling / coordination over the application lifecycle is divided between ResourceManager (per-cluster) and ApplicationMaster (per-application), respectively. <br><br>  Each compute node is divided into an arbitrary number of <em>Containers</em> containing a predetermined number of resources: CPU, RAM, etc.  Monitoring containers is conducted by NodeManager (per-node). <br><br><div style="text-align:center;"><img alt="Hadoop MapReduce 2.0. Job job" src="https://habrastorage.org/getpro/habr/post_images/d62/874/b59/d62874b595575788798bd4449353185b.png"></div><br><br>  Below is an illustration of the interaction of the individual components of Hadoop MapReduce in the classic version of the architecture. <br><br><div style="text-align:center;"><img alt="Hadoop MapReduce. Interaction" src="https://habrastorage.org/getpro/habr/post_images/dc7/039/031/dc70390314738e3c5e1cc8df81955112.png"></div><br><br>  and YARN-like architecture (new types of communication between components are highlighted in bold). <br><br><div style="text-align:center;"><img alt="Hadoop MapReduce 2.0. Interaction" src="https://habrastorage.org/getpro/habr/post_images/457/4a3/885/4574a38857853f42f86a8691ea84e54c.png"></div><br><br>  Next, we consider how the new architecture of Hadoop MapReduce influenced such aspects of the platform as availability, scalability, and resource utilization. <br><br><h3>  Availability </h3><br>  In Hadoop MapReduce 1.0, a JobTracker crash causes JobTracker to restart with reading the status from special logs, which ultimately leads to cluster downtime. <br><br>  In the new version of the accessibility solution, although they have not risen to a qualitatively new level, still things are no worse.  Hadoop MapReduce 2.0 high availability task is solved in the following way: the state of the components ResourceManager and ApplicationMaster is saved and the system of automatic restart of the listed components is ensured in the event of a failure with loading the last successfully saved state. <br><br>  For ResourceManager, Apache ZooKeeper is maintaining state.  And if the resource manager fails, a new RM process is created with a state that was before the failure.  Thus, the consequences of RM failure are reduced to the fact that all scheduled and running applications will be restarted. <br><br>  ApplicationMaster uses its own checkpoint mechanism.  During operation, AM maintains its state in HDFS.  If AM becomes unavailable, then RM restarts it with a state from snapshot. <br><br><h3>  Scalability </h3><br>  Developers working with Hadoop MapReduce 1.0 have repeatedly pointed out that the limit of scalability of the Hadoop cluster lies in the area of ‚Äã‚Äã4K machines.  The main reason for this limitation is that the JobTracker node spends a considerable amount of its resources on tasks related to the application life cycle.  The latter can be attributed to tasks specific to a particular application, and not to the cluster as a whole. <br><br>  The division of responsibility for tasks related to different levels between ResourceManager and ApplicationMaster was, perhaps, the main know-how of Hadoop MapReduce 2.0. <br><br>  It is planned that Hadoop MapReduce 2.0 can work on clusters of up to 10K + compute nodes, which is a significant advance in comparison with the classic version of Hadoop MapReduce. <br><br><h3>  Recycling </h3><br>  Low utilization of resources due to the hard division of cluster resources into map- and reduce-slots is often also the object of criticism of the classical Hadoop MapReduce.  The concept of slots in MapReduce 1.0 has been replaced by the concept of universal <em>containers</em> - a set of interchangeable isolated resources. <br><br>  The introduction of the concept of ‚Äú <em>Container</em> ‚Äù in Hadoop MapReduce 2.0, in fact, added another feature to the Hadoop platform - <em>multi</em> - <em>tenancy</em> .  Attitude to cluster nodes as computational resources will eliminate the negative effect of slots on resource utilization. <br><br><h3>  Connectedness </h3><br>  One of the architectural problems of Hadoop MapReduce 1.0 was the strong connectivity of 2, in fact, not interdependent systems: a framework for distributed computing and client libraries that implement a distributed algorithm. <br><br>  This connectivity has led to the inability to run on an MPI Hadoop cluster or other alternative distributed map / reduce algorithms. <br><br>  In the new architecture, the YARN distributed computing framework and the computing framework within the map / reduce software model based on the YARN-MR2 framework were selected. <br><br>  MR2 is an application-specific framework provided by ApplicationMaster, while YARN is ‚Äúrepresented‚Äù by the ResourceManager and NodeManager components and is completely independent of the specificity of the distributed algorithm. <br><br><h3>  Behind the scenes </h3><br>  A holistic picture will not be, if not to mention 2 aspects: <br>  1. The article considered only the distributed computing framework. <br>  Beyond the scope of this article are changes related to the data warehouse.  The most notable of these are the high availability of the HDFS name node and the HDFS name node federation. <br>  2. The above will be implemented only in Hadoop v2.0 (an alfa version is available at the time of writing this article).  So YARN and MR2 are already available in Hadoop v0.23, but without the support of high availability NameNode. <br><br>  Separately, I note that at the June 2012 Chicago HUG conference, which I mentioned in the introduction, Tom White said that Hadoop 2.0 Alpha still has work related to performance, security, and ResourceManager. <br><br><h2>  Conclusion </h2><br>  The Hadoop project in 2010 was pleasantly surprised by <em>ideas</em> , in 2011 - by the <em>speed of distribution</em> , in 2012 I was struck by the <em>scale of the changes</em> . <br><br>  I will not waste your time on a ‚Äútraditional‚Äù summary of what YARN and MR2 have changed in the Hadoop platform.  This is without a doubt a qualitative leap for the platform. <br><br>  Now Hadoop looks like a de-facto industry standard in tasks related to Big Data.  The future release of version 2.0 will give developers an open, fault-tolerant, superbly scalable, extensible tool for mass-parallel processing, not ‚Äúfixated‚Äù solely on the map / reduce software model. <br><br>  Sounds unbelievable.  It is even more incredible that this is a very near reality.  Only one thing remains - to <em>be ready for this reality</em> . <br><br><h2>  List of sources </h2><br>  [1] <a href="http://hadoop.apache.org/docs/r0.23.0/hadoop-yarn/hadoop-yarn-site/YARN.html">Apache Hadoop NextGen MapReduce (YARN)</a> .  Apache Software Foundation, 2011. <br>  [2] Arun C Murthy.  <a href="http://developer.yahoo.com/blogs/hadoop/posts/2011/02/mapreduce-nextgen/">The Next Generation of Apache Hadoop MapReduce</a> .  Yahoo 2011 <br>  [3] Ahmed Radwan.  <a href="http://blog.cloudera.com/blog/2012/02/mapreduce-2-0-in-hadoop-0-23/">MapReduce 2.0 in Hadoop 0.23</a> .  Cloudera, 2012. <br>  [4] Tom White.  Hadoop: The Definitive Guide, 3rd Edition.  O'Reilly Media / Yahoo Press, 2012. <br>  [5] <a href="http://hadoop.apache.org/docs/current/api/org/apache/hadoop/yarn/api/package-summary.html">Apache Hadoop Main 2.0.2-alpha API</a> .  Apache Software Foundation, 2012. <br><br><h2>  Postscript and other experiences of the author </h2><br>  * Cloudera allows you to download the CDH4 distribution (with YARN support) to run on a local machine in pseudo-distributed mode.  <a href="https://ccp.cloudera.com/display/CDH4DOC/Installing%2BCDH4%2Bon%2Ba%2BSingle%2BLinux%2BNode%2Bin%2BPseudo-distributed%2BMode">Distribution and instructions</a> . </div><p>Source: <a href="https://habr.com/ru/post/161437/">https://habr.com/ru/post/161437/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../161421/index.html">How a programmer became a product manager</a></li>
<li><a href="../161427/index.html">More than DDOS protection</a></li>
<li><a href="../161429/index.html">About healthy reflection and honesty</a></li>
<li><a href="../161431/index.html">Only 25 developers get 50% of profits in the App Store and Play</a></li>
<li><a href="../161433/index.html">Virtualization index</a></li>
<li><a href="../161439/index.html">New ICS firmware (6.1.1.B.1.54) for Sony Xperia P, U, go and sola</a></li>
<li><a href="../161443/index.html">Installing Prosody v0.8 (Jabber Server) with LDAP Authentication</a></li>
<li><a href="../161447/index.html">AWS: RDS Micro instances are now available in VPC</a></li>
<li><a href="../161449/index.html">Stubborn Maverick Huang Zhang and his Meizu smartphones</a></li>
<li><a href="../161451/index.html">NASA talked about the new rover and other Mars exploration plans</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>