<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>TJBOT as an illustration of IBM Watson services</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hi, Habr! In the spring of 2019, the next Think Developers Workshop was held, where everyone could assemble a TJBota cardboard robot running IBM Watso...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>TJBOT as an illustration of IBM Watson services</h1><div class="post__text post__text-html js-mediator-article">  Hi, Habr!  In the spring of 2019, the next Think Developers Workshop was held, where everyone could assemble a TJBota cardboard robot running IBM Watson Services.  Under the cat there is a detailed instruction, from what and how to assemble such a robot, useful links and simple recipes that demonstrate some of the cognitive capabilities of Watson services, as well as a small announcement of two July seminars about Watson Services in the Moscow office of IBM. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/sz/da/wu/szdawu-surn1rikward-thsn57e.png" alt="image"></div><br><a name="habracut"></a><br>  IBM Watson services is a cognitive system that can process natural language, recognize patterns and learn.  For convenient use of these services in any application there is an API. <br><br>  TJBot is an open source project designed to help get access to Watson services.  This is a robot that can be made by each of raspberry pi and ready-made artificial intelligence.  You can revive TJBot using recipes. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Recipes are step-by-step instructions that help you connect TJBot to Watson services, such as Speech to Text, Visual Recognition, and Language Translator.  Recipes are based on the Raspberry Pi. <br><br><h3>  What is needed for TJBot </h3><br><ul><li>  Raspberry Pi 3 + SD card with pre-installed OS </li><li>  Usb microphone </li><li>  Bluetooth speaker or speaker with 3.5mm.  audio jack </li><li>  Servo </li><li>  NeoPixel RGB LED (8mm) </li><li>  Wiring mom mom and dad mom </li><li>  Raspberry Pi Camera </li><li>  Power Supply </li><li>  Case (can be printed on a 3D printer or laser cut out of cardboard. The necessary layouts are <a href="https://ibmtjbot.github.io/">here</a> ) </li></ul><br><img src="https://habrastorage.org/webt/_g/nt/qz/_gntqzyt-xiwhicse9bgy6gyksy.png"><br><br>  Instructions for assembling the case can be found <a href="https://www.instructables.com/id/Build-TJ-Bot-Out-of-Cardboard/">here</a> . <br><br>  Wiring diagram of the diode and servo to the board in the picture below. <br><br><img src="https://habrastorage.org/webt/p9/ha/vg/p9havg5oykyg-hrm1bocavxvfqg.png" alt="image"><br><br>  The case is assembled ‚Äúaround‚Äù the board, so it is necessary to write the OS to the memory card in advance. <br><br>  The easiest way to install <a href="https://www.raspberrypi.org/downloads/noobs/">NOOBS</a> , but any other Linux will do.  Before installing NOOBS, format the memory card, download the archive with the installation files and export them to a computer.  Next, you need to transfer files from the NOOBS folder to the memory card.  When you first start raspberry (with a pre-inserted memory card), the OS installation menu will open.  Detailed instructions can be found <a href="https://projects.raspberrypi.org/en/projects/raspberry-pi-setting-up">here</a> . <br><br><h3>  Software preparations </h3><br>  The first step is to install the packages: <br><br><pre><code class="bash hljs">curl -sL http://ibm.biz/tjbot-bootstrap | sudo sh ‚Äì</code> </pre> <br>  Now download the ready-made recipes from the githab: <br><br><pre> <code class="bash hljs">git <span class="hljs-built_in"><span class="hljs-built_in">clone</span></span> https://github.com/ibmtjbot/tjbot.git</code> </pre><br>  Go to the directory with the recipe: <br><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> tjbot / recipes / speech_to_text</code> </pre><br>  This folder contains the config.js configuration file and the stt.js script file. <br><br>  Install npm: <br><br><pre> <code class="bash hljs">sudo apt-get install npm</code> </pre> <br><h3>  Connecting Watson services </h3><br>  To use the Watson services, you need to do the following steps. <br><br>  Go to this <a href="http://cloud.ibm.com/">site</a> . <br><br><img src="https://habrastorage.org/webt/ih/cc/_0/ihcc_02huxat4scvowxowcjutyc.png" alt="image"><br><br>  Register and go to the directory.  In the catalog we look for ‚Äúspeech to text‚Äù.  Speech to text is a service used to translate speech to text.  Access to the API can be found <a href="https://cloud.ibm.com/apidocs/speech-to-text">here</a> . <br><br><img src="https://habrastorage.org/webt/9c/wk/dx/9cwkdxz6uj-ooxto4lmoujqjegk.png" alt="image"><br><br>  Text to speech and Visual Recognition will also be needed when we work with image recognition.  Click on speech to text, get on the page with a description of this component and plans for use. <br><br><img src="https://habrastorage.org/webt/uv/31/pi/uv31pidkj-2za05y0ojbv1khdo0.png" alt="image"><br><br>  We have enough free plan.  We click on create, then in the menu on the left we go to Service Credentials. <br><br><img src="https://habrastorage.org/webt/dx/ti/5s/dxti5scdsq3vrgnmgkwap2c9yhk.png" alt="image"><br><br>  From here you need to copy the credentials and APIKEY and paste them into the config.js file. <br><br><pre> <code class="javascript hljs"><span class="hljs-comment"><span class="hljs-comment">// Create the credentials object for export exports.credentials = {}; // Watson Speech to Text // https://www.ibm.com/watson/services/speech-to-text/ exports.credentials.speech_to_text = { "apikey": "...", "iam_apikey_description": "...", "iam_apikey_name": "...", "iam_role_crn": "...", "iam_serviceid_crn": "...", "url": "https://gateway-lon.watsonplatform.net/speech-to-text/api" };</span></span></code> </pre><br>  Now, if we want to add another Watson service, in the configuration file we need to add a block with apikey and url wrapped in the following construction for each service: <br><br><pre> <code class="javascript hljs">exports.credentials.[ text_to_speech/visual_recognition/speech_to_text ] = { ‚Ä¶ };</code> </pre><br><h3>  TjBota Revitalization </h3><br>  Consider a file with an executable bot script stt.js.  It has a ready-made diskoParty () function for testing bot operation and without using Watson services.  This function makes the bot diode blink in different colors. <br><br><pre> <code class="javascript hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">discoParty</span></span></span><span class="hljs-function">(</span><span class="hljs-params"></span><span class="hljs-function"><span class="hljs-params"></span>) </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (i = <span class="hljs-number"><span class="hljs-number">0</span></span>; i &lt; <span class="hljs-number"><span class="hljs-number">30</span></span>; i++) { setTimeout(<span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function">(</span><span class="hljs-params"></span><span class="hljs-function"><span class="hljs-params"></span>) </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> randIdx = <span class="hljs-built_in"><span class="hljs-built_in">Math</span></span>.floor(<span class="hljs-built_in"><span class="hljs-built_in">Math</span></span>.random() * tjColors.length); <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> randColor = tjColors[randIdx]; tj.shine(randColor); }, i * <span class="hljs-number"><span class="hljs-number">250</span></span>); } } discoParty();</code> </pre><br>  In the same script there is a function that allows you to switch the color of the diode using the speech of the developer. <br><br>  Run the script: <br><br><pre> <code class="bash hljs">sudo node stt.js</code> </pre><br>  Tell the bot ‚Äúturn the light blue‚Äù to switch the diode color to blue, ‚Äúturn the light on‚Äù to turn on the diode, or ‚Äúturn the light off‚Äù to turn it off.  Supported colors for recognition (while only English is supported): yellow, green, orange, purple, magenta, red, blue, aqua and white. <br><br>  TjBot has a lot of basic functions.  For example, to check the servo, you can use the tj.wave () function, which causes the bot to greet you with a flick of the handle.  These functions with short descriptions can be found <a href="https://github.com/ibmtjbot/tjbotlib">here</a> . <br><br>  Now consider the following script that uses both visual recognition and text to speech. <br><br>  Text to speech is a service that converts typed text to speech using various voices, keys and languages.  Its API can be found at the following <a href="https://cloud.ibm.com/apidocs/text-to-speech">link</a> .  Visual recognition service allows you to describe what is shown in the picture.  He recognizes the faces of people with the definition of their approximate age and sex, food, dishes, objects and knows how to look for similar images.  The API for this service can be found <a href="https://cloud.ibm.com/apidocs/visual-recognition">here</a> .  With the help of these services we will teach the bot to see and speak.  Based on the image received from the camera, Watson services (visual recognition) will send us a json-tagged image as an answer, and text to speech will help voice them. <br><br>  First of all, create credentials on cloud.ibm.com.  Copy them and paste them into the config.js configuration file. <br><br>  Next, edit the executable script stt.js.  We find in it the following lines: <br><br><pre> <code class="javascript hljs"><span class="hljs-comment"><span class="hljs-comment">// these are the hardware capabilities that our TJ needs for this recipe var hardware = ['led', 'microphone'];</span></span></code> </pre><br>  The hardware array contains the bot devices used.  If we want to use a servo drive in the script, it will be necessary to sign into the ‚Äúservo‚Äù array, if we need a camera, then we will add it to the ‚Äúcamera‚Äù array, to use the column, we will sign the ‚Äúspeaker‚Äù. <br>  So, our script will use a column and a camera, respectively, we sign it into the hardware array. <br><br><pre> <code class="javascript hljs"><span class="hljs-comment"><span class="hljs-comment">// these are the hardware capabilities that our TJ needs for this recipe var hardware = ['led', 'servo', 'camera', 'speaker', 'microphone']; // set up TJBot's configuration var tjConfig = { log: { level: 'verbose' }, speak: { language: 'en-US', // see TJBot.prototype.languages.speak voice: undefined, // use a specific voice; if undefined, a voice is chosen based on robot.gender and speak.language speakerDeviceId: "plughw:0,0" // plugged-in USB card 1, device 0; see aplay -l for a list of playback devices }, listen: { microphoneDeviceId: "plughw:1,0", // plugged-in USB card 1, device 0; see arecord -l for a list of recording devices inactivityTimeout: -1, // -1 to never timeout or break the connection. Set this to a value in seconds eg 120 to end connection after 120 seconds of silence language: 'en-US' // see TJBot.prototype.languages.listen }, };</span></span></code> </pre><br>  From the basic functions of the tj-library, we need the functions tj.see () and tj.speak (). <br><br>  The tj.see () function creates a photo (the object is saved in the tmp folder), sends it to the cloud with Watson services, analyzes the image and issues a json object consisting of tags - words describing the photo (you can choose different descriptions and confidence levels) and reliability percentage of these tags.  We will display the content of the response of services in the console. <br><br>  The tj.speak () function can turn text using Watson services into an audio file and then play it back.  Also, if a person is found in a photo using the Watson services, TJBot will wave a pen. <br><br><pre> <code class="javascript hljs"><span class="hljs-comment"><span class="hljs-comment">// instantiate our TJBot! var tj = new TJBot(hardware, tjConfig, credentials); tj.see().then(function(objects){ var tags = objects.map(function(object){ return object.class; }); if (tags.includes('person')){ tj.wave(); } console.log(tags); for(var i=0;i&lt;tags.length;i++){ tj.speak(tags[i]); } });</span></span></code> </pre><br>  This recipe shows how easy it is to use Watson services in your project.  A brief description of these services and links to them have already been in this <a href="https://habr.com/ru/company/ibm/blog/331206/">article</a> .  You can try all the Watson services for free. <br><br>  Also, very soon in the Moscow office of IBM will be held seminars where you can get acquainted with other features of Watson services. <br><br>  On July 9, 2019, the Unveil AI Blackbox with IBM Watson OpenScale workshop will be held on the new cloud-based product - Watson OpenScale.  At this event you will be able to get acquainted with the principles of operation of neural networks, try to create and train a neural network and test it using the Watson AI OpenScale platform.  At the event you must first register at this <a href="https://ibmdbg.timepad.ru/event/978064/">link</a> . <br><br>  On July 10, 2019, the seminar ‚ÄúRecognition of images and video in the IBM cloud‚Äù will take place.  In this workshop, you can learn how to integrate artificial intelligence into your application using Watson Studio.  A detailed description of the event and a link to register <a href="https://ibmdbg.timepad.ru/event/978076/">here</a> . </div><p>Source: <a href="https://habr.com/ru/post/458374/">https://habr.com/ru/post/458374/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../458358/index.html">Meinim is still legally: the experience of mining lightcoins in 2019</a></li>
<li><a href="../45836/index.html">About Subtitles and Lyrics on the iPhone and iPod Touch</a></li>
<li><a href="../458362/index.html">Single row multiplication table</a></li>
<li><a href="../458364/index.html">Fishnet Cases - How Microsoft Azure Helps with a Phishing Attack</a></li>
<li><a href="../458370/index.html">How fast results helped Ivan</a></li>
<li><a href="../458376/index.html">Not a regular programming language</a></li>
<li><a href="../458378/index.html">Use Avocode for site layout. Overview for beginners. Bonus - register a 30-day trial period</a></li>
<li><a href="../458382/index.html">Why do we teach this?</a></li>
<li><a href="../458384/index.html">HP 3D Structured Light Scanner Pro S3 3D Scanner Review and Testing</a></li>
<li><a href="../458388/index.html">Deep (Learning + Random) Forest and parsing articles</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>