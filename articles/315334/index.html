<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>A bit about Windows VM disk performance in Proxmox VE. Results of ZFS and MDADM + LVM benchmarks</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="If anyone is interested, we recently tested the read / write performance inside the windows of the machine on the node with Proxmox 4.3. 


 The host ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>A bit about Windows VM disk performance in Proxmox VE. Results of ZFS and MDADM + LVM benchmarks</h1><div class="post__text post__text-html js-mediator-article"><p><img src="https://habrastorage.org/files/25d/8c0/9c1/25d8c09c109b4386935f99576c54f5a0.png" alt="image"></p><br><p>  If anyone is interested, we recently tested the read / write performance inside the windows of the machine on the node with Proxmox 4.3. </p><br><p>  The host system was installed on raid10 implemented in two different ways (zfs and mdadm + lvm) </p><br><p>  Tests were conducted on a Windows guest, as the performance of this particular OS was primarily of interest. </p><br><p>  <em>I have to admit, this is the second version of the article, the first one was a fatal error:</em> <em><br></em>  <em>zfs was tested on local storage, and not on zvol, because</em>  <em>I thought to the last that proxmox does not support zvol.</em> <em><br></em>  <em>Many thanks to <a href="https://habrahabr.ru/users/winduzoid/" class="user_link">winduzoid</a> for noticing this misunderstanding.</em> </p><br><a name="habracut"></a><br><p>  <em>The thought of writing this article made comments to a recent article about <a href="https://habrahabr.ru/post/315086/">Installing PROXMOX 4.3 on Soft-RAID 10 GPT</a> from <a href="https://habrahabr.ru/users/vasyakrg/" class="user_link">vasyakrg</a> .</em>  <em>Not for the sake of holivar, but I decided to publish our recent results.</em> </p><br><h3 id="vodnye-dannye">  Water data: </h3><br><h5 id="noda">  But yes: </h5><br><p>  <strong>CPU:</strong> Intel¬Æ Core (TM) i7-3820 CPU @ 3.60GHz <br>  <strong>RAM:</strong> 20GB (1334 MHz) <br>  <strong>HDD:</strong> 4x500GIB (ST500NM0011, ST500NM0011, ST3500418AS, WDC WD5000AAKX-22ERMA0) <br>  <strong>SSD:</strong> 250GiB (PLEXTOR PX-256M5Pro) <br>  <strong>OS:</strong> Proxmox Virtual Environment 4.3-10 </p><br><h5 id="virtualnaya-mashina">  Virtual machine: </h5><br><p>  <strong>CPU:</strong> 8 (1 sockets, 8 cores) <br>  <strong>RAM:</strong> 6.00 GiB <br>  <strong>HDD:</strong> 60 GiB (virtio) <br>  <strong>OS:</strong> Windows Server 2008 R2 Server Standard (full installation) SP1 [6.1 Build 7601] (x64) </p><br><p>  All results are obtained using the <strong>CrystalDiskMark 5.2.0 x64</strong> utility. <br>  Each test was conducted in <strong>5 iterations of 32GB</strong> . <br>  No additional tweaks and changes not specified in the article were made either in the hypervisor configuration or in the virtual machine configuration.  That is, just a freshly installed Proxmox and a restored virtual machine with Windows was used. </p><br><h3 id="rezultaty">  Results: </h3><br><p>  So the results themselves: </p><br><div class="spoiler">  <b class="spoiler_title">raid10 (mdadm) + lvm, cache = none</b> <div class="spoiler_text"><pre><code class="hljs objectivec">----------------------------------------------------------------------- CrystalDiskMark <span class="hljs-number"><span class="hljs-number">5.2</span></span><span class="hljs-number"><span class="hljs-number">.0</span></span> x64 (C) <span class="hljs-number"><span class="hljs-number">2007</span></span><span class="hljs-number"><span class="hljs-number">-2016</span></span> hiyohiyo Crystal Dew World : http:<span class="hljs-comment"><span class="hljs-comment">//crystalmark.info/ ----------------------------------------------------------------------- * MB/s = 1,000,000 bytes/s SATA/600 = 600,000,000 bytes/s * KB = 1000 bytes, KiB = 1024 bytes Sequential Read (Q= 32,T= 1) : 274.338 MB/s Sequential Write (Q= 32,T= 1) : 171.358 MB/s Random Read 4KiB (Q= 32,T= 1) : 3.489 MB/s 851.8 IOPS Random Write 4KiB (Q= 32,T= 1) : 0.927 MB/s 226.3 IOPS Sequential Read (T= 1) : 233.437 MB/s Sequential Write (T= 1) : 183.158 MB/s Random Read 4KiB (Q= 1,T= 1) : 0.522 MB/s 127.4 IOPS Random Write 4KiB (Q= 1,T= 1) : 2.499 MB/s 610.1 IOPS Test : 32768 MiB E: 0.1% (0.1/60.0 GiB) (x5) Interval=5 sec Date : 2016/11/08 15:21:41 OS : Windows Server 2008 R2 Server Standard (full installation) SP1 6.1 Build 7601 (x64)</span></span></code> </pre> </div></div><br><div class="spoiler">  <b class="spoiler_title">raid10 (mdadm) + lvm, cache = writeback</b> <div class="spoiler_text"><pre> <code class="hljs objectivec">----------------------------------------------------------------------- CrystalDiskMark <span class="hljs-number"><span class="hljs-number">5.2</span></span><span class="hljs-number"><span class="hljs-number">.0</span></span> x64 (C) <span class="hljs-number"><span class="hljs-number">2007</span></span><span class="hljs-number"><span class="hljs-number">-2016</span></span> hiyohiyo Crystal Dew World : http:<span class="hljs-comment"><span class="hljs-comment">//crystalmark.info/ ----------------------------------------------------------------------- * MB/s = 1,000,000 bytes/s SATA/600 = 600,000,000 bytes/s * KB = 1000 bytes, KiB = 1024 bytes Sequential Read (Q= 32,T= 1) : 1084.752 MB/s Sequential Write (Q= 32,T= 1) : 503.291 MB/s Random Read 4KiB (Q= 32,T= 1) : 31.148 MB/s 7604.5 IOPS Random Write 4KiB (Q= 32,T= 1) : 203.832 MB/s 49763.7 IOPS Sequential Read (T= 1) : 1890.617 MB/s Sequential Write (T= 1) : 268.878 MB/s Random Read 4KiB (Q= 1,T= 1) : 33.369 MB/s 8146.7 IOPS Random Write 4KiB (Q= 1,T= 1) : 54.938 MB/s 13412.6 IOPS Test : 32768 MiB E: 0.1% (0.1/60.0 GiB) (x5) Interval=5 sec Date : 2016/11/08 14:55:15 OS : Windows Server 2008 R2 Server Standard (full installation) SP1 6.1 Build 7601 (x64)</span></span></code> </pre> </div></div><br><div class="spoiler">  <b class="spoiler_title">raid10 (zfs), cache = none</b> <div class="spoiler_text"><pre> <code class="hljs objectivec">----------------------------------------------------------------------- CrystalDiskMark <span class="hljs-number"><span class="hljs-number">5.2</span></span><span class="hljs-number"><span class="hljs-number">.0</span></span> x64 (C) <span class="hljs-number"><span class="hljs-number">2007</span></span><span class="hljs-number"><span class="hljs-number">-2016</span></span> hiyohiyo Crystal Dew World : http:<span class="hljs-comment"><span class="hljs-comment">//crystalmark.info/ ----------------------------------------------------------------------- * MB/s = 1,000,000 bytes/s SATA/600 = 600,000,000 bytes/s * KB = 1000 bytes, KiB = 1024 bytes Sequential Read (Q= 32,T= 1) : 1428.912 MB/s Sequential Write (Q= 32,T= 1) : 281.715 MB/s Random Read 4KiB (Q= 32,T= 1) : 76.261 MB/s 18618.4 IOPS Random Write 4KiB (Q= 32,T= 1) : 64.809 MB/s 15822.5 IOPS Sequential Read (T= 1) : 1337.939 MB/s Sequential Write (T= 1) : 247.119 MB/s Random Read 4KiB (Q= 1,T= 1) : 27.926 MB/s 6817.9 IOPS Random Write 4KiB (Q= 1,T= 1) : 21.005 MB/s 5128.2 IOPS Test : 32768 MiB E: 0.1% (0.1/60.0 GiB) (x5) Interval=5 sec Date : 2016/11/16 14:42:05 OS : Windows Server 2008 R2 Server Standard (full installation) SP1 6.1 Build 7601 (x64)</span></span></code> </pre> </div></div><br><div class="spoiler">  <b class="spoiler_title">raid10 (zfs), cache = writeback</b> <div class="spoiler_text"><pre> <code class="hljs objectivec">----------------------------------------------------------------------- CrystalDiskMark <span class="hljs-number"><span class="hljs-number">5.2</span></span><span class="hljs-number"><span class="hljs-number">.0</span></span> x64 (C) <span class="hljs-number"><span class="hljs-number">2007</span></span><span class="hljs-number"><span class="hljs-number">-2016</span></span> hiyohiyo Crystal Dew World : http:<span class="hljs-comment"><span class="hljs-comment">//crystalmark.info/ ----------------------------------------------------------------------- * MB/s = 1,000,000 bytes/s SATA/600 = 600,000,000 bytes/s * KB = 1000 bytes, KiB = 1024 bytes Sequential Read (Q= 32,T= 1) : 379.678 MB/s Sequential Write (Q= 32,T= 1) : 373.262 MB/s Random Read 4KiB (Q= 32,T= 1) : 12.409 MB/s 3029.5 IOPS Random Write 4KiB (Q= 32,T= 1) : 150.885 MB/s 36837.2 IOPS Sequential Read (T= 1) : 931.972 MB/s Sequential Write (T= 1) : 187.517 MB/s Random Read 4KiB (Q= 1,T= 1) : 14.106 MB/s 3443.8 IOPS Random Write 4KiB (Q= 1,T= 1) : 54.419 MB/s 13285.9 IOPS Test : 32768 MiB E: 0.1% (0.1/60.0 GiB) (x5) Interval=5 sec Date : 2016/11/16 14:21:47 OS : Windows Server 2008 R2 Server Standard (full installation) SP1 6.1 Build 7601 (x64)</span></span></code> </pre> </div></div><br><p>  Later we added a caching SSD to our zfs pool. </p><br><div class="spoiler">  <b class="spoiler_title">raid10 (zfs + ssd), cache = none</b> <div class="spoiler_text"><pre> <code class="hljs objectivec">----------------------------------------------------------------------- CrystalDiskMark <span class="hljs-number"><span class="hljs-number">5.2</span></span><span class="hljs-number"><span class="hljs-number">.0</span></span> x64 (C) <span class="hljs-number"><span class="hljs-number">2007</span></span><span class="hljs-number"><span class="hljs-number">-2016</span></span> hiyohiyo Crystal Dew World : http:<span class="hljs-comment"><span class="hljs-comment">//crystalmark.info/ ----------------------------------------------------------------------- * MB/s = 1,000,000 bytes/s SATA/600 = 600,000,000 bytes/s * KB = 1000 bytes, KiB = 1024 bytes Sequential Read (Q= 32,T= 1) : 1518.768 MB/s Sequential Write (Q= 32,T= 1) : 312.825 MB/s Random Read 4KiB (Q= 32,T= 1) : 157.763 MB/s 38516.4 IOPS Random Write 4KiB (Q= 32,T= 1) : 96.962 MB/s 23672.4 IOPS Sequential Read (T= 1) : 1474.409 MB/s Sequential Write (T= 1) : 236.638 MB/s Random Read 4KiB (Q= 1,T= 1) : 28.693 MB/s 7005.1 IOPS Random Write 4KiB (Q= 1,T= 1) : 24.380 MB/s 5952.1 IOPS Test : 32768 MiB E: 0.1% (0.1/60.0 GiB) (x5) Interval=5 sec Date : 2016/11/16 17:07:45 OS : Windows Server 2008 R2 Server Standard (full installation) SP1 6.1 Build 7601 (x64)</span></span></code> </pre> </div></div><br><div class="spoiler">  <b class="spoiler_title">raid10 (zfs + ssd), cache = writeback</b> <div class="spoiler_text"><pre> <code class="hljs objectivec">----------------------------------------------------------------------- CrystalDiskMark <span class="hljs-number"><span class="hljs-number">5.2</span></span><span class="hljs-number"><span class="hljs-number">.0</span></span> x64 (C) <span class="hljs-number"><span class="hljs-number">2007</span></span><span class="hljs-number"><span class="hljs-number">-2016</span></span> hiyohiyo Crystal Dew World : http:<span class="hljs-comment"><span class="hljs-comment">//crystalmark.info/ ----------------------------------------------------------------------- * MB/s = 1,000,000 bytes/s SATA/600 = 600,000,000 bytes/s * KB = 1000 bytes, KiB = 1024 bytes Sequential Read (Q= 32,T= 1) : 353.932 MB/s Sequential Write (Q= 32,T= 1) : 401.659 MB/s Random Read 4KiB (Q= 32,T= 1) : 30.015 MB/s 7327.9 IOPS Random Write 4KiB (Q= 32,T= 1) : 110.644 MB/s 27012.7 IOPS Sequential Read (T= 1) : 923.238 MB/s Sequential Write (T= 1) : 167.356 MB/s Random Read 4KiB (Q= 1,T= 1) : 31.210 MB/s 7619.6 IOPS Random Write 4KiB (Q= 1,T= 1) : 56.429 MB/s 13776.6 IOPS Test : 32768 MiB E: 0.1% (0.1/60.0 GiB) (x5) Interval=5 sec Date : 2016/11/16 17:24:12 OS : Windows Server 2008 R2 Server Standard (full installation) SP1 6.1 Build 7601 (x64)</span></span></code> </pre> </div></div><br><p>  For the sake of interest, we also launched tests on a single SSD: </p><br><div class="spoiler">  <b class="spoiler_title">ssd + lvm, cache = none</b> <div class="spoiler_text"><pre> <code class="hljs objectivec">----------------------------------------------------------------------- CrystalDiskMark <span class="hljs-number"><span class="hljs-number">5.2</span></span><span class="hljs-number"><span class="hljs-number">.0</span></span> x64 (C) <span class="hljs-number"><span class="hljs-number">2007</span></span><span class="hljs-number"><span class="hljs-number">-2016</span></span> hiyohiyo Crystal Dew World : http:<span class="hljs-comment"><span class="hljs-comment">//crystalmark.info/ ----------------------------------------------------------------------- * MB/s = 1,000,000 bytes/s SATA/600 = 600,000,000 bytes/s * KB = 1000 bytes, KiB = 1024 bytes Sequential Read (Q= 32,T= 1) : 526.147 MB/s Sequential Write (Q= 32,T= 1) : 361.292 MB/s Random Read 4KiB (Q= 32,T= 1) : 189.502 MB/s 46265.1 IOPS Random Write 4KiB (Q= 32,T= 1) : 78.780 MB/s 19233.4 IOPS Sequential Read (T= 1) : 456.598 MB/s Sequential Write (T= 1) : 368.912 MB/s Random Read 4KiB (Q= 1,T= 1) : 18.632 MB/s 4548.8 IOPS Random Write 4KiB (Q= 1,T= 1) : 32.528 MB/s 7941.4 IOPS Test : 32768 MiB F: 0.1% (0.1/60.0 GiB) (x5) Interval=5 sec Date : 2016/11/09 12:56:31 OS : Windows Server 2008 R2 Server Standard (full installation) SP1 6.1 Build 7601 (x64)</span></span></code> </pre> </div></div><br><div class="spoiler">  <b class="spoiler_title">ssd + lvm, cache = writeback</b> <div class="spoiler_text"><pre> <code class="hljs objectivec">----------------------------------------------------------------------- CrystalDiskMark <span class="hljs-number"><span class="hljs-number">5.2</span></span><span class="hljs-number"><span class="hljs-number">.0</span></span> x64 (C) <span class="hljs-number"><span class="hljs-number">2007</span></span><span class="hljs-number"><span class="hljs-number">-2016</span></span> hiyohiyo Crystal Dew World : http:<span class="hljs-comment"><span class="hljs-comment">//crystalmark.info/ ----------------------------------------------------------------------- * MB/s = 1,000,000 bytes/s SATA/600 = 600,000,000 bytes/s * KB = 1000 bytes, KiB = 1024 bytes Sequential Read (Q= 32,T= 1) : 1587.672 MB/s Sequential Write (Q= 32,T= 1) : 524.242 MB/s Random Read 4KiB (Q= 32,T= 1) : 248.953 MB/s 60779.5 IOPS Random Write 4KiB (Q= 32,T= 1) : 320.532 MB/s 78254.9 IOPS Sequential Read (T= 1) : 2481.313 MB/s Sequential Write (T= 1) : 825.351 MB/s Random Read 4KiB (Q= 1,T= 1) : 58.060 MB/s 14174.8 IOPS Random Write 4KiB (Q= 1,T= 1) : 59.725 MB/s 14581.3 IOPS Test : 32768 MiB F: 0.1% (0.1/60.0 GiB) (x5) Interval=5 sec Date : 2016/11/09 13:28:20 OS : Windows Server 2008 R2 Server Standard (full installation) SP1 6.1 Build 7601 (x64)</span></span></code> </pre> </div></div><br><h3 id="grafiki">  Charts: </h3><br><p>  For clarity, I decided to draw a few graphs </p><br><h5 id="skorost-na-posledovatelnoe-chtenie-i-zapis">  Sequential read and write speed: </h5><br><p><img src="https://habrastorage.org/files/de9/8a5/516/de98a551664145deb5e4810eb9c7c14c.png" alt="image"><br><img src="https://habrastorage.org/files/e76/828/b3e/e76828b3e507402ba25ba3e02cb9f13d.png" alt="image"></p><br><h5 id="skorost-na-sluchaynoe-chtenie-i-zapis">  Random read and write speed: </h5><br><p><img src="https://habrastorage.org/files/b4e/ffc/57a/b4effc57a66249a9882eecfdaa00d9b1.png" alt="image"><br><img src="https://habrastorage.org/files/850/adf/8a7/850adf8a7d3e488289ae5b45773b78b1.png" alt="image"></p><br><h5 id="kolichestvo-iops-na-sluchaynoe-chtenie-i-zapis">  The number of IOPS for random reading and writing: </h5><br><p><img src="https://habrastorage.org/files/96d/05c/76e/96d05c76e74e40d69d2a19882ea3465f.png" alt="image"><br><img src="https://habrastorage.org/files/4eb/874/1ae/4eb8741ae6f7462194fe139cc0b03ef1.png" alt="image"></p><br><h3 id="vyvody">  Findings: </h3><br><p>  Despite the fact that the results were rather unusual, and sometimes even strange, you can see that raid10 compiled on zfs, with the <code>cache=none</code> option for the disk, showed a better result than raid10 compiled on mdadm + lvm for both reading and record <br>  However, with the option <code>cache=writeback</code> raid10 compiled on mdadm + lvm goes ahead noticeably. </p><br><p>  How much the <code>cache=writeback</code> increases the risk of data loss I haven‚Äôt been able to figure out yet, but there is a message on the <a href="https://forum.proxmox.com/threads/zfs-cache-writeback-safe.21186/">official</a> proxmox <a href="https://forum.proxmox.com/threads/zfs-cache-writeback-safe.21186/">forum</a> that this information is outdated in new versions of the kernel and qemu, it is recommended, in any case, for disks hosted in zfs. </p><br><blockquote>  newer kernels and newer version are in place now.  for zfs, cache = writeback is the recommended setting. <br></blockquote><p>  In addition, <a href="https://habrahabr.ru/users/ilyaevseev/" class="user_link">IlyaEvseev</a> in his <a href="https://habrahabr.ru/post/176823/">article</a> wrote that writeback cache gives good results for Windows virtual machines. </p><br><blockquote>  According to a subjective assessment, writeback is optimal for Windows VMs, none is for Linux VMs and FreeBSD VMs. <br></blockquote><p>  This is probably all, if you have any suggestions on how else you can increase the performance of disk operations on a guest machine, I‚Äôll be happy to hear them. </p></div>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <p>Source: <a href="https://habr.com/ru/post/315334/">https://habr.com/ru/post/315334/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../315324/index.html">Digital Transformation 2016</a></li>
<li><a href="../315326/index.html">In simple words: how machine learning works</a></li>
<li><a href="../315328/index.html">How to determine hot leads in 3 steps to make a sale and why 95% of companies do not know how</a></li>
<li><a href="../315330/index.html">Developer: Airbag</a></li>
<li><a href="../315332/index.html">How to lose a few million, working incomprehensibly with whom</a></li>
<li><a href="../315336/index.html">Why companies with well-described business processes are doomed to extinction</a></li>
<li><a href="../315338/index.html">Easter eggs solution from CTF announcement from Bi.Zone</a></li>
<li><a href="../315340/index.html">Creating and testing a firewall in Linux, Part 1.1 Virtual Lab</a></li>
<li><a href="../315342/index.html">How we tested interface usability</a></li>
<li><a href="../315344/index.html">The first winners of the Telegram BotPrize will receive $ 200,000</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>