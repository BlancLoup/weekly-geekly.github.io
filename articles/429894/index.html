<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Using the Fish eye camera on a Raspberry Pi 3 with ROS - part 2</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Good afternoon, dear readers of Habr! This is the second part of the story about using the fish eye camera on the Raspberry Pi 3. The first part can b...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Using the Fish eye camera on a Raspberry Pi 3 with ROS - part 2</h1><div class="post__text post__text-html js-mediator-article">  Good afternoon, dear readers of Habr!  This is the second part of the story about using the fish eye camera on the Raspberry Pi 3. The first part can be found <a href="https://habr.com/post/417251/">here</a> .  In this article I will talk about the calibration of the fish eye camera and the use of the camera in the detection of objects using the find_object_2d package.  Who cares, I ask under the cat. <br><a name="habracut"></a><br><h2>  Calibrate the fish eye camera using camera_calibration </h2><br>  Here I describe the calibration procedure based on the official <a href="http://wiki.ros.org/camera_calibration/Tutorials/MonocularCalibration">manual</a> on the ros.org portal. <br><br>  For calibration, we need a camera-calibration package.  We can install it with apt: <br><br><pre><code class="bash hljs">sudo apt-get install ros-kinetic-camera-calibration</code> </pre> <br>  We will need a checkerboard template.  Download the template from the official <a href="http://wiki.ros.org/camera_calibration/Tutorials/MonocularCalibration">manual</a> on ros.org and print it.  For convenience, I pasted it on a plywood board: 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/webt/cz/qp/g8/czqpg8rutw1ut-h7ogrjqxwnytk.jpeg" alt="image"><br><br>  Let's run the calibration program: <br><br><pre> <code class="bash hljs">rosrun camera_calibration cameracalibrator.py --size 8x6 --square 0.108 image:=/usb_cam/image_raw camera:=/usb_cam</code> </pre><br>  We get the picture: <br><br><img src="https://habrastorage.org/webt/_n/t0/ib/_nt0ib2ohbvxtk8lomsx197swke.png" alt="image"><br><br>  Move the template a little and wait until the template is highlighted in the frame (colored lines with dots will not appear on the template). <br><br><img src="https://habrastorage.org/webt/dm/du/yn/dmduyniktnl1joqutysbtv9ugf8.png" alt="image"><br><br><img src="https://habrastorage.org/webt/ir/w3/fq/irw3fq6yv4z-bfzictvsqlht93c.png" alt="image"><br><br>  Move the template a little more to the side.  To successfully perform the calibration, we need to perform a series of pattern movements in front of the camera from side to side so that the pattern falls into all angular positions in the camera's field of view (left, right, top and bottom).  To the right of the camera image window in the program window there is a registration panel with three progress bars: <br><br><ul><li>  X captures the movement of the pattern in the left / right direction (horizontal) in the field of view of the camera </li><li>  Y captures the movement of the pattern in the direction of the top / bottom (horizontal) in the field of view of the camera </li><li>  Size captures the approach / removal of the pattern from the camera and the slope relative to the camera. </li><li>  Skew fixes the slope of the pattern to the left, right, up and down (bevel). </li></ul><br>  Thus, for successful calibration, it is important that the template is in different corners of the frame, it occupies the entire frame and is also tilted to the left, right, up and down. <br><br>  Calibrating the fish eye camera on the Raspberry Pi can take quite a long time, so please be patient.  My calibration procedure took 20 minutes. <br><br>  When the calibration is complete, the Calibrate button should be activated (highlighted in color): <br><br><img src="https://habrastorage.org/webt/lq/d-/d2/lqd-d26xbjyaishe5noij5oan1k.png" alt="image"><br><br>  We can also see the calibration results in the terminal: <br><br><img src="https://habrastorage.org/webt/5c/jv/kt/5cjvktr9rxlpwwfq0kfk1kk3b7o.png" alt="image"><br><br>  If you are satisfied with the result, press the COMMIT button.  The program window closes and you see the message ‚Äúwriting calibration data to ...‚Äù in the terminal. <br><br>  Check that the specified file was created: <br><br><pre> <code class="bash hljs">ll ~/.ros/camera_info/head_camera.yaml -rw-rw-r-- 1 vladimir vladimir 592 Apr 14 14:02 /home/vladimir/.ros/camera_info/head_camera.yaml</code> </pre><br>  Calibration complete.  Now the obtained calibration data can be used in visual localization and SLAM algorithms in ROS. <br><br><h2>  Detection of objects using find_object_2d </h2><br>  Install the <a href="http://wiki.ros.org/find_object_2d">package is</a> quite simple.  Install it from the apt repository in Ubuntu 16.04 for ROS Kinetic: <br><br><pre> <code class="bash hljs">sudo apt-get install ros-kinetic-find-object-2d <span class="hljs-built_in"><span class="hljs-built_in">source</span></span> /opt/ros/kinetic/setup.bash</code> </pre><br>  Run the ROS master and rqt_image_view: <br><br><pre> <code class="bash hljs">roscore roslaunch usb_cam usb_cam-test.launch</code> </pre><br>  Use the following command to start the detector node: <br><br><pre> <code class="bash hljs">rosrun find_object_2d find_object_2d image:=/usb_cam/image_raw</code> </pre><br>  The detection program window will open: <br><br><img src="https://habrastorage.org/webt/6l/_u/kb/6l_ukb-8wjw2cylfuloapxtpdzk.png" alt="image"><br><br>  Here we will see the flow from the camera and the result of the detection of characteristic features on objects. <br>  To begin with, we will conduct a detector training at our facilities.  Place the first object in front of the camera: <br><br><img src="https://habrastorage.org/webt/2y/hs/nb/2yhsnbkbcr9452owc41wpl_yzxs.png" alt="image"><br><br>  Right-click on the Objects left pane in the window and the Add objects from scene option will open.  Select this option and the add object window will open: <br><br><img src="https://habrastorage.org/webt/r3/ey/56/r3ey56zvh_td0ap_etfqdi-nvem.png" alt="image"><br><br>  After selecting the best position for the object, click the Take Picture button to take a picture of the object: <br><br><img src="https://habrastorage.org/webt/ao/h6/qk/aoh6qkj0aktn86zjxmwlyn-stg4.png" alt="image"><br><br>  We need to select the object in the picture.  Use the mouse cursor to select the object: <br><br><img src="https://habrastorage.org/webt/ar/l-/6c/arl-6c6qqj88nxbrh1sh7w3fhxw.png" alt="image"><br><br>  Click the Next button to cut the object in the picture and proceed to the next step.  After cropping the image, we get the total number of characteristic features found on the object.  It remains only to click the End button to add an object to the database of trained detector objects.  Here we see the last step of the procedure for adding an object: <br><br><img src="https://habrastorage.org/webt/ma/jh/pa/majhpayey9z1nntt0i4eaegq6jq.png" alt="image"><br><br>  As a result, we trained the detector on the same site.  Now you can try detecting an object in the scene: <br><br><img src="https://habrastorage.org/webt/q6/vb/7u/q6vb7uerpmydbkvpncoz3buc5d8.png" alt="image"><br><br>  Draw the position of the detected object in the terminal: <br><br><pre> <code class="bash hljs">rosrun find_object_2d print_objects_detected</code> </pre><br>  The output will be: <br><br><pre> <code class="bash hljs">Object 1 detected, Qt corners at (259.387238,103.530960) (448.684052,79.495495) (282.419050,240.049667) (458.438938,199.656717) --- Object 1 detected, Qt corners at (255.340408,104.615120) (451.348079,75.302353) (284.672425,230.382223) (452.696585,197.625600) --- Object 1 detected, Qt corners at (253.440521,102.973320) (447.226440,76.793541) (278.530854,238.918013) (454.377219,197.526599) ---</code> </pre><br>  Let's display the list of topics: <br><br><pre> <code class="bash hljs">rostopic list</code> </pre><br>  Two new topics appeared in the list: / objects and / objectsStamped. <br><br>  Let's display information about the detected objects: <br><br><pre> <code class="bash hljs">rostopic <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> /objects</code> </pre><br><pre> <code class="bash hljs">layout: dim: [] data_offset: 0 data: [1.0, 266.0, 177.0, 0.7527905702590942, 0.060980819165706635, 0.00022385441116057336, 0.3012462854385376, 0.8929792046546936, 0.0008534671505913138, 334.9065856933594, 182.55294799804688, 1.0] ---</code> </pre><br>  Here, the second and third values ‚Äã‚Äã(266.0, 177.0) represent the width and height of the object.  All other values ‚Äã‚Äãin the data field represent a 3x3 homography matrix (used to calculate the position and orientation of the object, as well as the scale and shift values). <br><br>  As observations show, find_object_2d does not cope well with the detection of objects with weak texture or without texture (textureless).  In addition, the detector is ineffective in detecting an object at a large angle to the object (if we observe the object from the side), or at a large distance from the object. <br><br><img src="https://habrastorage.org/webt/pk/1f/ot/pk1fotpptvtwoym3g6p5g3lfgty.png" alt="image"><br><br>  After you finish working with the detector, find_object_2d will offer us to save the added objects to disk. <br><br>  That's all for now.  Good luck to everyone and see you soon! </div><p>Source: <a href="https://habr.com/ru/post/429894/">https://habr.com/ru/post/429894/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../429880/index.html">Pix4D - from photos to measurements</a></li>
<li><a href="../429882/index.html">Control of RGB LEDs via the UDB unit of PSoC microcontrollers from Cypress</a></li>
<li><a href="../429884/index.html">Conference Prostor 2018: questions and answers about the future of storage systems</a></li>
<li><a href="../429890/index.html">Open webinar "Generative competitive networks"</a></li>
<li><a href="../429892/index.html">xonsh - python as shell replacement</a></li>
<li><a href="../429898/index.html">DMS (Dealership Management System) - Implementation of Information EcoSystems for Dealer Networks Management</a></li>
<li><a href="../429902/index.html">Page Rank in the Web 2.0 era - Part 1</a></li>
<li><a href="../429904/index.html">Funny and sad stories about the development of computer games</a></li>
<li><a href="../429908/index.html">How to use korutiny in prode and sleep well at night</a></li>
<li><a href="../429910/index.html">AppsConf Rises</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>