<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Hadoop Part 1: Deploying a Cluster</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="The continuous growth of data and an increase in the speed of their generation raises the problem of their processing and storage. Not surprisingly, t...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Hadoop Part 1: Deploying a Cluster</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/getpro/habr/post_images/1d0/d0a/9af/1d0d0a9af1b9218ff24fa1b1a471211e.png" alt="hadoop" width="715" height="536"><br><br>  The continuous growth of data and an increase in the speed of their generation raises the problem of their processing and storage.  Not surprisingly, the ‚ÄúBig Data‚Äù theme is one of the most talked about in today's IT community. <br><br>  There are quite a lot of materials on the theory of ‚Äúbig data‚Äù in specialized journals and on websites today.  But from theoretical publications it is far from always clear how one can use appropriate technologies to solve specific practical problems. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      One of the most well-known and discussed projects in the field of distributed computing is Hadoop, a freely distributed set of utilities, libraries and a framework for developing and executing distributed computing programs developed by the Apache Software Foundation. <br><br>  We have been using Hadoop for a long time to solve our own practical problems.  The results of our work in this area are worth sharing with the general public.  This article is the first in a series about Hadoop.  Today we will talk about the history and structure of the Hadoop project, and also show, using the example of the Hadoop Cloudera distribution, how the cluster is deployed and configured. <br><br>  <b>Carefully, under a cat a lot of traffic.</b> <br><a name="habracut"></a><br><h2>  A bit of history </h2><br>  Hadoop author - Doug Cutting, creator of Apache Lucene, the famous text search library.  The name of the project is the name that Doug's son came up with for his plush yellow elephant. <br><br>  Cutting created Hadoop while working on the Nutch project, an open source web search system.  The Nutch project was launched in 2002, but very soon its developers realized that the existing architecture is unlikely to scale to billions of web pages.  In 2003, an article was published describing the distributed file system GFS (Google File System) used in Google projects.  Such a system could easily cope with the task of storing large files generated by crawling and indexing sites.  In 2004, the Nutch development team took up the implementation of such an open source system - NDFS (Nutch Distributed File System). <br><br>  In 2004, Google introduced the MapReduce technology to a wide audience.  Already at the beginning of 2005, Nutch developers created a full-fledged implementation of MapReduce based on Nutch;  shortly thereafter, all the main Nutch algorithms were adapted to use MapReduce and NDFS.  In 2006, Hadoop was allocated to an independent subproject under the Lucene project. <br><br>  In 2008, Hadoop became one of the leading Apache projects.  By that time, it was already successfully used in companies such as Yahoo !, Facebook and Last.Fm.  Today, Hadoop is widely used both in commercial companies and in scientific and educational institutions. <br><br><h2>  Hadoop project structure </h2><br>  The Hadoop project includes the following subprojects: <br><ul><li>  Common - a set of components and interfaces for distributed file systems and general input / output; </li><li>  Map Reduce is a distributed computing model designed for parallel computing over very large (up to several petabytes) data volumes; </li><li>  HDFS is a distributed file system running on large clusters of typical machines. </li></ul><br><br>  Previously, Hadoop included other subprojects, which are now stand-alone products of the Apache Software Foundation: <br><ul><li>  Avro - serialization system for inter-language RPC calls and long-term data storage; </li><li>  Pig is a data flow control language and execution environment for analyzing large amounts of data; </li><li>  Hive - distributed data storage;  it manages data stored in HDFS and provides a SQL-based query language for working with this data; </li><li>  HBase - non-relational distributed database; </li><li>  ZooKeeper - distributed coordination service;  provides primitives for building distributed applications; </li><li>  Sqoop - a tool for transferring data between structured storage and HDFS; </li><li>  Oozie is a service for recording and scheduling Hadoop jobs. </li></ul><br><br><h2>  Hadoop distributions </h2><br>  Today Hadoop is a complex system consisting of a large number of components.  Installing and configuring such a system yourself is a very difficult task.  Therefore, many companies today offer ready-made Hadoop distributions, which include deployment, administration and monitoring tools. <br><br>  Hadoop distributions are distributed both under commercial (products of companies such as Intel, IBM, EMC, Oracle) and under free (products of Cloudera, Hortonworks and MapR companies) licenses.  We will tell you more about the Cloudera Hadoop distribution. <br><br><h2>  Cloudera hadoop </h2><br>  Cloudera Hadoop is a completely open distribution created with the active participation of Apache Hadoop developers Doug Cutting and Mike Cafarella.  It is distributed in both free and paid version, known as Cloudera Enterprise. <br><br>  At the time when we became interested in the Hadoop project, Cloudera provided the most complete and complete solution among the open source Hadoop distributions.  For all the time there was not a single significant problem, and the cluster successfully survived several major updates, which were fully automatic.  And now, after almost a year of experiments, we can say that we are satisfied with the choice made. <br><br>  Cloudera Hadoop includes the following main components: <br><ul><li>  Cloudera Hadoop (CDH) - the actual Hadoop distribution; </li><li>  Cloudera Manager is a tool for deploying, monitoring, and managing a Hadoop cluster. </li></ul><br><br>  The components of Cloudera Hadoop are distributed in binary packages called <a rel="nofollow" href="http://blog.cloudera.com/blog/2013/05/faq-understanding-the-parcel-binary-distribution-format/" title="Read more">parsels</a> .  Compared to standard packages and package managers, parsels have the following advantages: <br><ul><li>  ease of loading: each parcel is one file in which all the necessary components are combined; </li><li>  internal consistency: all components inside the parsell are thoroughly tested, debugged and consistent with each other, so the likelihood of problems with component incompatibility is very small; </li><li>  Differentiation of distribution and activation: you can first install parsels on all managed nodes, and then activate them with a single action;  thanks to this, the system is updated quickly and with minimal downtime; </li><li>  updates ‚Äúon the go‚Äù: when a minor version is updated, all new processes (tasks) will be automatically launched under this version, already running tasks will continue to be executed in the old environment until they are completed.  However, upgrading to a new major version is only possible through a full restart of all cluster services, and therefore all current tasks; </li><li>  a simple reversal of changes: in case of any problems with the new version of CDH, it can be easily rolled back to the previous one. </li></ul><br><br><h2>  Hardware requirements </h2><br>  Hardware requirements for deploying Hadoop is a fairly complex topic.  Different requirements are made to different nodes within the cluster.  You can read more about this, for example, in the <a rel="nofollow" href="http://hadoop.intel.com/pdfs/IDH-InstallGuide_R2-4-1_EN.pdf">recommendations</a> of Intel or in the <a rel="nofollow" href="http://blog.cloudera.com/blog/2013/08/how-to-select-the-right-hardware-for-your-new-hadoop-cluster/">blog</a> of Cloudera.  The general rule: more memory and disks!  RAID controllers and other enterprise joys are not necessary due to the very architecture of Hadoop and HDFS, designed to work on typical simple servers.  The use of 10GB network cards is justified with data volumes of more than 12TB per node. <br><br>  The Cloudera blog provides the following list of hardware configurations for various boot options: <br><ul><li>  "Light" configuration (1U) - 2 six-core processors, 24-64 GB of memory, 8 hard drives with a capacity of 1-2 TB; </li><li>  rational configuration (1U) - 2 six-core processors, 48-128 GB of memory, 12-16 hard drives (1 or 2 TB) connected directly through the controller of the motherboard; </li><li>  "Heavy" configuration for storage (2U): 2 six-core processors, 48-96 GB of memory, 16-24 hard drives.  With multiple failures in the nodes in this configuration, a sharp increase in network traffic occurs; </li><li>  configuration for intensive computing: 2 six-core processors, 64-512 GB of memory, 4-8 hard drives with a capacity of 1-2 TB. </li></ul><br><img src="https://habrastorage.org/getpro/habr/post_images/910/333/7a5/9103337a5ef927c5ae5188b423c2d4ce.png" alt="CPU-disk" width="720" height="384"><br><br>  Note that in the case of server rental, losses from a poorly chosen configuration are not as terrible as when purchasing their servers.  If necessary, you can modify the leased servers or replace them with more suitable for your tasks. <br><br>  We proceed directly to the installation of our cluster. <br><br><h2>  Install and configure the OS </h2><br>  For all servers we will use CentOS 6.4 in a minimal installation, but other distributions can be used: Debian, Ubuntu, RHEL, etc.  Required packages are publicly available at archive.cloudera.com and are installed by standard package managers. <br><br>  On the Cloudera Manager server, we recommend using software or hardware RAID1 and one root partition, you can put it on a separate partition / var / log /.  On servers that will be added to the hadoop cluster, we recommend creating two partitions: <br><ul><li>  "/" 50-100GB in size under the OS and software Cloudera Hadoop; </li><li>  ‚Äú/ Dfs‚Äù over LVM to all available disks for HDFS data storage; </li><li>  ‚ÄúSwap‚Äù is better to make very small, about 500MB.  Ideally, servers should not swap at all, but if this happens, a small swap will save the processes from OOM-killer. </li></ul><br><br>  On all servers, including the Cloudera Manager server, you need to disable SELinux and the firewall.  Of course, you can not do this, but then you have to spend a lot of time and effort to fine-tune security policies.  To ensure security, it is recommended to isolate the cluster as much as possible from the outside world at the network level, for example, using a hardware firewall or an isolated VLAN (access to mirrors through a local proxy). <br><br><pre>  # vi / etc / selinux / config # turn off SElinux
 SELINUX = disabled
 # system-config-firewall-tui # turn off the firewall and save the settings
 # reboot </pre><br><br>  We offer examples of ready-made kickstart files for the automatic installation of Cloudera Manager servers and cluster nodes. <br><div class="spoiler">  <b class="spoiler_title">Example cloudera_manager.ks</b> <div class="spoiler_text"><pre> install text reboot ### General url --url http://mirror.selectel.ru/centos/6.4/os/x86_64 # disable SELinux for CDH selinux --disabled rootpw supersecretpasswrd authconfig --enableshadow --enablemd5 # Networking firewall - -disabled network --bootproto = static --device = eth0 --ip = 1.2.3.254 --netmask = 255.255.255.0 --gateway = 1.2.3.1 --nameserver = 188.93.16.19.109.234.159.91,188.93.17.19 - -hostname = cm.example.net # Regional keyboard us lang en_US.UTF-8 timezone Europe / Moscow ### Partitioning zerombr yes bootloader --location = mbr --driveorder = sda, sdb clearpart --all --initlabel part raid .11 --size 1024 --asprimary --ondrive = sda part raid.12 --size 1 --grow --asprimary --ondrive = sda part raid.21 --size 1024 --asprimary --ondrive = sdb part raid.22 --size 1 --grow --asprimary --ondrive = sdb raid / boot --fstype ext3 --device md0 --level = RAID1 raid.11 raid.21 raid pv.01 --fstype ext3 - device md1 - level = RAID1 raid.12 raid.22 volgroup vg0 pv.01 logvol swap - vgname = vg0 - size = 12288 - name = swap - fstyp  e = ext4 logvol / --vgname = vg0 --size = 1 --grow --name = vg0-root --fstype = ext4% packages @Base wget ntp% post - erroronfail chkconfig ntpd on wget -q -O / etc / yum.repos.d / cloudera-manager.repo http://archive.cloudera.com/cm4/redhat/6/x86_64/cm/cloudera-manager.repo rpm --import http: //archive.cloudera. com / cdh4 / redhat / 6 / x86_64 / cdh / RPM-GPG-KEY-cloudera yum -y install jdk yum -y install cloudera-manager-daemons yum -y install cloudera-manager-server yum -y install cloudera-manager- server-db </pre><br></div></div><br><div class="spoiler">  <b class="spoiler_title">Example node.ks</b> <div class="spoiler_text"><pre> install
 text
 reboot

 ### General
 url --url http://mirror.selectel.ru/centos/6.4/os/x86_64
 # disable SELinux for CDH
 selinux --disabled
 rootpw nodeunifiedpasswd
 authconfig --enableshadow --enablemd5
 # Networking
 firewall --disabled
 network --bootproto = static --device = eth0 --ip = 1.2.3.10 --netmask = 255.255.255.0 --gateway = 1.2.3.1 --nameserver = 188.93.16.19,109.234.159.91,188.93.17.19 --hostname = node.example.net
 # Regional
 keyboard us
 lang en_US.UTF-8
 timezone Europe / Moscow

 ### Partitioning
 zerombr yes
 bootloader --location = mbr --driveorder = sda
 clearpart --all - initlabel
 part / boot --fstype ext3 --size 1024 --asprimary --ondrive = sda
 part pv.01 --fstype ext3 --size 1 --grow --asprimary --ondrive = sda
 # repeat for every hard drive 
 part pv.01 --fstype ext3 --size 1 --grow --asprimary --ondrive = sdb
 part pv.01 --fstype ext3 --size 1 --grow --asprimary --ondrive = sdc

 volgroup vg0 pv.01     
 logvol swap --vgname = vg0 --size = 512 --name = swap --fstype = ext4
 logvol / --vgname = vg0 --size = 51200 --name = vg0-root --fstype = ext4
 logvol / dfs --vgname = vg0 --size = 1 --grow --name = dfs --fstype = ext4

 % packages
 @Base
 wget
 ntp

 % post --erroronfail
 chkconfig ntpd on
</pre><br></div></div><br><br><h2>  Installing Cloudera Manager </h2><br>  Let's start by installing Cloudera Manager, which will then deploy and configure our future Hadoop cluster on servers. <br><br>  Before installation, you must make sure that: <br><ul><li>  all servers included in the cluster are accessible via ssh, and they have the same root password (or the public ssh key is added); </li><li>  all nodes must have access to standard package repositories (have access to the Internet or access to a local repository / proxy); </li><li>  all servers in the cluster have access to archive.cloudera.com or to a local repository with the necessary installation files; </li><li>  ntp is installed on all servers and time synchronization is configured; </li><li>  all the nodes in the cluster and the CM server are configured with DNS and PTR records (or all the hosts must be registered in the / etc / hosts of all servers). </li></ul><br><br>  Add a Cloudera mirror and install the necessary packages: <br><pre>  # wget -q -O /etc/yum.repos.d/cloudera-manager.repo http://archive.cloudera.com/cm4/redhat/6/x86_64/cm/cloudera-manager.repo
 # rpm --import http://archive.cloudera.com/cdh4/redhat/6/x86_64/cdh/RPM-GPG-KEY-cloudera
 # yum -y install jdk
 # yum -y install cloudera-manager-daemons
 # yum -y install cloudera-manager-server
 # yum -y install cloudera-manager-server-db </pre><br><br>  At the end of the installation, we launch the standard database (for simplicity, we will use it, although you can connect any third-party) and the CM service itself: <br><br><pre>  # /etc/init.d/cloudera-scm-server-db start
 # /etc/init.d/cloudera-scm-server start </pre><br><br><h2>  Deploying Cloudera Hadoop Cluster </h2><br>  After installing Cloudera Manager, you can forget about the console, all further interaction with the cluster we will implement using the Cloudera Manager web interface.  By default, Cloudera Manager uses port 7180.  You can use either the DNS name or the IP address of the server.  We enter this address in the browser line. <br>  A login window will appear on the screen.  Login and password for login - standard (admin, admin).  Of course, they need to be changed immediately. <br>  A window opens with an offer to choose the version of Cloudera Hadoop: free, trial for 60 days or a paid license: <br><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/079/c6b/23d/079c6b23d9c6f7e2b3c17e3fee291038.png" alt="01" width="1280" height="1000"></a> <br><br>  Select the free (Cloudera Standard) version.  Trial or paid license can be activated later at any time when you are already comfortable with the work with the cluster. <br><br>  During installation, the Cloudera Manager service will connect over SSH to the servers in the cluster;  it performs all actions on the servers on behalf of the user specified in the menu, the default is root. <br><br>  Next, Cloudera Manager will ask you to specify the addresses of the hosts where Cloudera Hadoop will be installed: <br><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/d04/c85/f8a/d04c85f8a6c43c8c3179f1e43de12e78.png" alt="03" width="1280" height="1000"></a> <br><br>  Addresses can be specified by list and by mask, for example: <br><ul><li>  10.1.1. [1-4] means that the cluster will include nodes with IP addresses 10.1.1.1, 10.1.1.2, 10.1.1.3, 10.1.1.4 </li><li>  host [07-10] .example.com - host07.example.com, host08.example.com, host09.example.com, host10.example.com. </li></ul><br><br>  After that click on the Search button.  Cloudera Manager will detect the specified hosts, and a list of them will be displayed on the screen: <br><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/c9d/0c8/0db/c9d0c80dba8168d47f6e89728805db8a.png" alt="04" width="1280" height="1000"></a> <br><br>  We check once again whether all the necessary hosts are included in this list (you can add new hosts by clicking the New Search button).  Then click on the Continue button.  The repository selection window will open: <br><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/bb8/568/57e/bb856857e00bee221398b798ba5a7ae4.png" alt="05" width="1280" height="1000"></a> <br><br>  As a method of installation, we recommend choosing the installation with parsels, we have already described their advantages earlier.  Parsels are installed from the archive.cloudera.org repository.  In addition to the CDH parsell, you can install the SOLR search tool and a database based on Hadoop IMPALA from the same repository. <br><br>  After selecting the installments for installation, click on the Continue button.  In the next window, specify the parameters for access via SSH (login, password or private key, port number for connection): <br><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/971/371/e0a/971371e0a944cdd9024343bfbccc2e1a.png" alt="06" width="1280" height="1000"></a> <br><br>  After that click on the button Continue.  The installation process will start: <br><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/09e/f61/87d/09ef6187de6115bb3ce89691a6b416ab.png" alt="07" width="1280" height="1000"></a> <br><br>  Upon completion of the installation, a table with a summary of the installed components and their versions will be displayed on the screen: <br><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/5d5/2c7/a86/5d52c7a86ab639634ab6a225a36270be.png" alt="14" width="1280" height="1000"></a> <br><br>  Once again, we check whether everything is in order, and click on the Continue button.  A window will appear asking you to select the components and services of Cloudera Hadoop to be installed: <br><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/bad/d51/630/badd51630db4b4ff8151b4b93f6dde92.png" alt="sixteen" width="1280" height="1000"></a> <br><br>  For example, we will install all the components by selecting the ‚ÄúAll Services‚Äù option, later it will be possible to install or delete any services.  Now you need to specify which components of Cloudera Hadoop will be installed on specific hosts.  We recommend that you trust the default selection; in more detail, recommendations on the location of roles on nodes can be found in the documentation for a specific service. <br><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/b3a/5db/63d/b3a5db63d084a1eecb1596faeff3ea6a.png" alt="17" width="1280" height="1000"></a> <br><br>  Click the Continue button and proceed to the next step - setting up the database: <br><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/d29/7a4/a9d/d297a4a9d5b9c96579221961368806c6.png" alt="nineteen" width="1280" height="1000"></a> <br><br>  By default, all information related to monitoring and managing the system is stored in the PostgreSQL database that we installed with the Cloudera Manager.  Other databases can also be used - in this case, select Use Custom Database from the menu.  After setting the necessary parameters, we check the connection with the ‚ÄúTest Connection‚Äù database, and if successful, click on the ‚ÄúContinue‚Äù button to proceed to setting up the elements in the cluster: <br><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/850/10d/c80/85010dc803a392e132bb05827445b911.png" alt="20" width="1280" height="1000"></a> <br><br>  Click the Continue button and start the cluster setup process.  The adjustment is displayed on the screen: <br><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/c82/3c6/ad9/c823c6ad9791dca8c7f30167fd537897.png" alt="21" width="1280" height="1000"></a> <br><br>  When the configuration of all components is completed, go to the dashboard of our cluster.  For example, here is the dashboard of our test cluster: <br><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/dd9/f9e/bd4/dd9f9ebd4d2710e2c782cf27a9d50d53.png" alt="status" width="1744" height="775"></a> <br><br><h2>  Instead of conclusion </h2><br>  In this article, we tried to introduce you to installing the Hadoop cluster and to show that when using ready-made distributions, such as Cloudera Hadoop, this takes very little time and effort.  I recommend to continue acquaintance with Hadoop with the book of Tom White ‚ÄúHadoop: The Definitive Guide‚Äù, there is an edition in Russian. <br><br>  Working with Cloudera Hadoop on the example of specific usage scenarios will be discussed in the following articles of the cycle.  The upcoming publication will be devoted to Flume, a universal tool for collecting logs and other data. <br><br>  For those who can not comment on posts on Habr√©, we invite to our <a href="http://slc.tl/y4psj">blog</a> . </div><p>Source: <a href="https://habr.com/ru/post/198534/">https://habr.com/ru/post/198534/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../198518/index.html">Performa 475 + Dial-Up Internet</a></li>
<li><a href="../198522/index.html">I invite you to the II All-Russian Linux Administration Olympiad</a></li>
<li><a href="../198526/index.html">GeeXboX is fully ported to Raspberry Pi</a></li>
<li><a href="../198530/index.html">Moscow City Court began to satisfy the first claims of anti-piracy copyright holders</a></li>
<li><a href="../198532/index.html">Fukami, part 1: turnips with tentacles</a></li>
<li><a href="../198536/index.html">How I chose SED - what vendors are silent about</a></li>
<li><a href="../198540/index.html">Productive PHP network server</a></li>
<li><a href="../198542/index.html">Developer meeting with students of MIPT or "How to assemble Badoo on the knee"</a></li>
<li><a href="../198544/index.html">PHP RUtils - a small library for processing Russian text</a></li>
<li><a href="../198548/index.html">Google protects sites from DDoS attacks and helps circumvent censorship</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>