<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Developing games for children using Intel Perceptual Computing. Clifford Adventures Example</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="We offer you a shortened translation of an article highlighting the development of a series of interactive educational games for young children ‚ÄúThe A...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Developing games for children using Intel Perceptual Computing. Clifford Adventures Example</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/files/b45/2a4/d6e/b452a4d6e2a2488fa3b9103c0677e0e3.jpg"><br>  We offer you a shortened translation of an article highlighting the development of a series of interactive educational games for young children ‚ÄúThe Adventures of Clifford‚Äù from the company Scholastic Interactive.  The diverse use of gestures and voices in this game was made possible thanks to the <a href="https://software.intel.com/en-us/vcsource/tools/perceptual-computing-sdk">Intel Perceptual Computing SDK 2013</a> technology in conjunction with the Creative Senz3D * camera.  It also discusses new methods for recognizing gestures and voices using perceptual computations, methods of solving problems with the SDK. <br><a name="habracut"></a><br><h4>  Educational game concept </h4>  In a series of four interactive episodes about Clifford, players view the plot and interact with it.  The game involves children in action, offering various ways to ‚Äúhelp‚Äù Clifford with certain gestures and statements.  Thanks to Scholastic's interactive technology, Clifford responds to the voice and movements of children.  During the plot of the game, they watch animated excerpts of each adventure and actively contribute to the heroes by touching the screen or giving answers to questions.  The plot develops as the child interacts with the game.  Each game is designed to develop basic literacy skills and can be repeated as many times as desired. <br>  The Intel Perceptual Computing SDK 2013 includes APIs, code samples, and tutorial on how to interpret gestures and speech.  Developers can easily combine the capabilities of the SDK in speech recognition, hand and finger gestures, facial expressions, augmented reality technology and background subtraction, creating software for various devices.  The use of a microphone, camera, touch screen, positioning functions and geolocation, widely used on tablets, laptops, transformers and all-in-one computers, enhances the multidimensionality of the perception of new applications. <br><br><h4>  Intel Perceptual Computing Platform Development </h4>  Adaptation of perceptual computation to the analysis of movements and voices of children carries with it a number of difficulties.  Scholastic comprehensively tested each prototype in order to evaluate the design of the game and the reality of passing its levels.  This helped to identify potential problems that could be faced by the target audience, and to find solutions for them. <br>  Some aspects of this work may be of particular interest in terms of perceptual calculations.  They are listed below. <br><br><h5>  Voice recognition calibration </h5>  To ensure acceptable voice recognition quality, it was necessary to conduct a series of checks.  The child's voice changes as he grows older, especially at the age for which the Clifford series is intended.  Therefore, it was necessary to achieve a level of calibration so that the children's voice and speech constructs were recognized correctly. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/files/261/290/dfb/261290dfb3d648a8b3810bdb56d733bb.jpg"><br>  <i>Episode of the game, requiring speech participation of the player</i> <br><br><h5>  Recognition and localization of gestures </h5>  In one of the Clifford Adventure games, the child is required to help the dog catch toys falling from the tree.  To do this, you need to "grab" the basket on the screen with your hand and move it in different directions. <br>  Special algorithms were developed that recognize gestures and correlate them with touch coordinates, so that the basket on the screen moves in the direction of the child‚Äôs hand.  Small players took part in testing with pleasure.  Previously, the developers mistakenly believed that the child's gestures to hold the object on the screen would not be much different from the gestures of an adult.  But working with children made it necessary to revise the design of the game so that it perceived their fuzzy movements. It was not easy to teach the sensors to understand the child's sweeping, often erroneous and chaotic gestures of a child consisting of many touches.  It took a lot of work to define the prototypes of gestures and to select their most common configurations.  The touch registration area has been expanded so that even an inaccurate gesture is recognized and causes the desired application response. <br>  For example, in another mini-game, children help Clifford to remove weeds from the garden.  Instead of forcing players to take a weed and move a hand upwards, pulling it out, the developers chose to grab and open the movement of the palm, denoting pulling and throwing out. <br><br>  Below is a fragment of the game code that calibrates the player‚Äôs gestures in a training exercise where you need to rotate the ball with your hands.  In the episode shown in the figure below, exponential smoothing was used for more precise control of the object and ease of movement.  It isolates or at least approximately calculates the random movements of the player that the program should ignore. <br><br><img src="https://habrastorage.org/files/27d/248/9d8/27d2489d8f614094ab5516d62fd01076.jpg"><br>  <i>Ball rotation</i> <br><br><pre><code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">void</span></span> TutorialActivity::MoveHandHandler(Hand^hand) { D2D_POINT_2F normalizedTouchPos = {hand-&gt;x*GetWidth(), hand-&gt;y*GetHeight()}; <span class="hljs-comment"><span class="hljs-comment">//calc distance //exponential smoothing float new x = m_gestureBallSpin-&gt;GetPosition().x*0.9f + normalizedTouchPos.x*0.1f ; float new y = m_gestureBallSpin-&gt;GetPosition().y*0.9f + normalizedTouchPos.y*0.1f ; m gestureBallSpin-&gt;SetPosition(new x, new y); float x = m_gestureBallSpin-&gt;GetPosition().x - m_EEhand-&gt;GetPosition().x; float y = m_gestureBallSpin-&gt;GetPosition().y - m_EEhand-&gt;GetPosition().y; if(sqrt(x*x + y*y) &lt; 400) { SetTutorialState(TUTORIAL_MOVEYOURHAND_DONE); //there it is m_EEhand-&gt;FadeTo(0,0.5f); if( !m_tutorialIsStopping ) { m_moveTutorial[5]-&gt;Play([this](SoundInstance^, bool reachedEnd) { m gestureBallSpin-&gt;MoveTo(GetWidth()*0.5f, -GetHeight(), 0.5f); GoToSprinkleHandState(); }); } } }</span></span></code> </pre> <br><br><h4>  Troubleshooting Intel Perceptual Computing SDK </h4>  Intel's SDK gives a real effect of immersion in the game, players get an immediate program response to their actions.  This creates a sense of physical participation in what is happening.  However, the developers are faced with some limitations in the ability to recognize complex movements and voice reactions of children. <br><br><h5>  Gestures </h5>  The camera that perceives gestures is focused at a distance of about 60‚Äì90 cm. Therefore, small movements are recorded better than sweeping or complex movements that go beyond this range.  The optimal set of gestures was determined by trial and error.  Specialists had to think about different environmental conditions, lighting and distance to the camera. <br>  From the point of view of the SDK, API and other technologies used, it is easy to develop initial gestures, because there are training exercises, code samples and structures used in the SDK.  After setting up the development environment, you can perform a training exercise, such as finger tracking, to study the interaction of sensors and code in the SDK. <br><br><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">include</span></span></span><span class="hljs-meta"> </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">"gesture render.h"</span></span></span><span class="hljs-meta"> #</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">include</span></span></span><span class="hljs-meta"> </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">"pxcgesture.h"</span></span></span><span class="hljs-meta"> class GesturePipeline: public UtilPipeline { public: GesturePipeline (void):UtilPipeline(),m_render(</span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">L"Gesture Viewer"</span></span></span><span class="hljs-meta">) { EnableGestureO ; } virtual void PXCAPI OnGesture(PXCGesture::Gesture *data) { </span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">if</span></span></span><span class="hljs-meta"> (data-&gt;active) m_gdata = (*data); } virtual void PXCAPI OnAlert(PXCGesture::Alert *data) { switch (data-&gt;label) { case PXCGesture::Alert::LABEL_FOV_TOP: wprintf_s(</span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">L"******** Alert:   .\n"</span></span></span><span class="hljs-meta">); break; case PXCGesture::Alert::LABEL_FOV_BOTTOM: wprintf_s(</span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">L"******** Alert:   .\n"</span></span></span><span class="hljs-meta">); break; case PXCGesture::Alert::LABEL_FOV_LEFT: wprintf_s(</span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">L"******** Alert:   .\n"</span></span></span><span class="hljs-meta">); break; case PXCGesture::Alert::LABEL_FOV_RIGHT: wprintf_s(</span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">L"******** Alert:   .\n"</span></span></span><span class="hljs-meta">); break; } } virtual bool OnNewFrame(void) { return m_render.RenderFrame(Querylmage(PXCImage::IMAGE TYPE DEPTH),QueryGesture() ,&amp;m gdata); } protected: GestureRender m render; PXCGesture::Gesture m gdata; };</span></span></code> </pre><br><br>  Programmers found that the SDK lacks different coordinate systems for gestures.  It had to fill their own development. <br><br><img src="https://habrastorage.org/files/d0a/f66/e4d/d0af66e4d7064a8bba2c6db57f023be1.jpg"><br>  <i>Visual gesture coordinate chart</i> <br><br>  Initially, the development team used the node [8] .positionImage.x / y approach, ignoring the depth data, since they were not required to interpret gestures.  But later a more optimal approach was found.  A ‚Äúdeep image‚Äù was used and the nearest pixel was searched for, on the basis of which the gesture was effectively determined.  Then an exponential smoothing was added. <br><br><h5>  Voice recognition </h5>  Voice recognition in the game was highly dependent on the devices and the plot.  On some devices and in some situations it worked well, in other conditions it did not work at all. <br>  The game should prompt the children about the command to be pronounced so that it will be recorded using a microphone.  The function should work even against the background of extraneous sounds and musical accompaniment of the game.  Voice recognition can work in speech detection mode when the program tries to determine what you have said, or in dictionary mode, when what is said is compared with your dictionary, which is determined in the case of a given game by the user. <br>  At first, the experts tried the first mode and set it up to record any sounds, based on the fact that the speech of young children is not always clearly articulated.  But the results were unsatisfactory.  Then it was decided to switch to the dictionary mode.  It works well if words are pronounced distinctly.  The developers tried to add word variations to the dictionary in order to increase the likelihood of their recognition (for example, <i>tractor - tlaktol - teaktol</i> ).  However, the dictionary mode did not give the expected results, because the more in the dictionary of units, the higher the probability of error.  I had to look for a compromise between the size of the list of words and the potential share of errors.  In the final version, the list of permissible words was minimized to allow the child to simply interact with the game. <br><br><h4>  Conclusion </h4>  The testing phase was fun.  Developers have gained valuable experience working with children, end users of the application.  And it was even more pleasant to see the finished game in use.  One of our senior specialists showed her to her three-year-old daughter, and we all were very happy to hear that the girl was playing ‚ÄúThe Adventures of Clifford‚Äù with great interest and excitement. <br>  Now Scholastic can't wait to apply its technology in new projects.  Together with Symbio, we are working on a new game based on the Intel RealSense 3D SDK, which is planned to be released this fall. <a href="http://www.intel.com/content/www/us/en/architecture-and-technology/realsense-overview.html">Intel RealSense</a> technology, announced at CES 2014, is a new image of Intel Perceptual Computing, an SDK with an intuitive user interface and speech recognition, gestures, hand movements and facial expressions in combination with improved 3D cameras.  Intel RealSense provides developers with additional features such as use in scanning, editing, 3D printing, and augmented reality technology.  Thanks to them, users can manipulate scanned 3D objects using the latest touch control technology. </div><p>Source: <a href="https://habr.com/ru/post/237227/">https://habr.com/ru/post/237227/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../237215/index.html">How to create an effective form of gathering contacts: everything you wanted to know, but were afraid to ask</a></li>
<li><a href="../237217/index.html">A bit about iptables, iproute2 and emulation of network problems</a></li>
<li><a href="../237219/index.html">Let's play a game</a></li>
<li><a href="../237221/index.html">SDR / SDN - how the new architecture is implemented in a real cellular network</a></li>
<li><a href="../237225/index.html">BitTorrent Bleep: protected instant messenger from BitTorrent</a></li>
<li><a href="../237229/index.html">New trailer for Final Fantasy XV and a moment of nostalgia</a></li>
<li><a href="../237231/index.html">Recommendations for the application for the App Store, strict rules on IDFA and $ 2.5 billion for Minecraft are the main mobile news for the week</a></li>
<li><a href="../237233/index.html">Why people do not grow: the more growth options, the worse</a></li>
<li><a href="../237235/index.html">How we had to learn how to manage poppies in the corporate network</a></li>
<li><a href="../237237/index.html">C ++ meetings in Russia</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>