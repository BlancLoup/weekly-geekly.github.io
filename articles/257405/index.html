<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Recognizing users' physical activity with examples on R</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="The problem of recognizing the physical activity of users (Human activity Recognition or HAR) came across to me earlier only as training tasks. Having...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Recognizing users' physical activity with examples on R</h1><div class="post__text post__text-html js-mediator-article">  The problem of recognizing the physical activity of users (Human activity Recognition or HAR) came across to me earlier only as training tasks.  Having discovered the possibilities of the <a href="http://topepo.github.io/caret/index.html">Caret R Package</a> , a convenient wrapper for over 100 machine learning algorithms, I decided to try it for HAR.  The <a href="http://archive.ics.uci.edu/ml/">UCI Machine Learning Repository</a> has several data sets for such experiments.  Since the topic with <a href="http://archive.ics.uci.edu/ml/datasets/Weight%2BLifting%2BExercises%2Bmonitored%2Bwith%2BInertial%2BMeasurement%2BUnits">dumbbells</a> for me is not very close, I chose to recognize the <a href="http://archive.ics.uci.edu/ml/datasets/Human%2BActivity%2BRecognition%2BUsing%2BSmartphones">activity of smartphone users</a> . <br><a name="habracut"></a><br><h4>  Data </h4><br>  The data in the set was obtained from thirty volunteers with Samsung Galaxy S II attached to the belt.  The signals from the gyroscope and accelerometer were specially processed and transformed into 561 signs.  For this, multistage filtering, Fourier transform and some standard statistical transformations were used, 17 functions altogether: from the mathematical expectation to the calculation of the angle between the vectors.  I‚Äôm missing the details of processing, they can be found in the repository.  The training sample contains 7352 cases, the test sample contains 2947. Both samples are marked with tags corresponding to six activities: walking, walking_up, walking_down, sitting, standing and laying. <br><br>  As a basic algorithm for experiments, I chose Random Forest.  The choice was based on the fact that RF has a built-in mechanism for assessing the importance of variables, which I wanted to experience, since the prospect of self-selection of signs from the 561 variable scared me a little.  I also decided to try the support vector machine (SVM).  I know that this is a classic, but I didn‚Äôt have to use it before, it was interesting to compare the quality of the models for both algorithms. <br><br>  Having downloaded and unpacked the archive with the data, I realized that I would have to tinker with it.  All parts of the set, the names of signs, activity labels were in different files.  To upload files to R, I used the <i>read.table ()</i> function.  It was necessary to prohibit the automatic conversion of rows into factor variables, as it turned out that there are duplicate variable names.  In addition, the names contained incorrect characters.  This problem was solved by the following construction with the <i>sapply ()</i> function, which in R often replaces the standard for loop: 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <pre><code class="hljs lua">editNames &lt;- <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(x)</span></span></span></span> { y &lt;- var_names[x,<span class="hljs-number"><span class="hljs-number">2</span></span>] y &lt;- <span class="hljs-built_in"><span class="hljs-built_in">sub</span></span>(<span class="hljs-string"><span class="hljs-string">"BodyBody"</span></span>, <span class="hljs-string"><span class="hljs-string">"Body"</span></span>, y) y &lt;- <span class="hljs-built_in"><span class="hljs-built_in">gsub</span></span>(<span class="hljs-string"><span class="hljs-string">"-"</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>, y) y &lt;- <span class="hljs-built_in"><span class="hljs-built_in">gsub</span></span>(<span class="hljs-string"><span class="hljs-string">","</span></span>, <span class="hljs-string"><span class="hljs-string">"_"</span></span>, y) y &lt;- paste0(<span class="hljs-string"><span class="hljs-string">"v"</span></span>,var_names[x,<span class="hljs-number"><span class="hljs-number">1</span></span>], <span class="hljs-string"><span class="hljs-string">"_"</span></span>,y) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span>(y) } new_names &lt;- sapply(<span class="hljs-number"><span class="hljs-number">1</span></span>:nrow(var_names), editNames)</code> </pre> <br>  I stuck all the parts of the sets using the <i>rbind ()</i> and <i>cbind ()</i> functions.  The first connects the rows of the same structure, the second column of the same length. <br>  After I prepared a training and test sample, the question arose about the need for data preprocessing.  Using the <i>range ()</i> function in a loop, calculated a range of values.  It turned out that all signs are within [-1,1] and it means that neither normalization nor scaling is necessary.  Then I checked for signs with a highly biased distribution.  For this, I used the skewness () function from the <a href="http://cran.r-project.org/web/packages/e1071/e1071.pdf">e1071</a> package: <br><br><pre> <code class="hljs lisp">SkewValues &lt;- apply(<span class="hljs-name"><span class="hljs-name">train_data</span></span>[,<span class="hljs-number"><span class="hljs-number">-1</span></span>], <span class="hljs-number"><span class="hljs-number">2</span></span>, skewness) head(<span class="hljs-name"><span class="hljs-name">SkewValues</span></span>[order(<span class="hljs-name"><span class="hljs-name">abs</span></span>(<span class="hljs-name"><span class="hljs-name">SkewValues</span></span>),decreasing = TRUE)],<span class="hljs-number"><span class="hljs-number">3</span></span>)</code> </pre><br>  <i>Apply ()</i> is a function from the same category as <i>sapply ()</i> , used when something needs to be done in columns or rows.  train_data [, - 1] - a data set without a dependent variable Activity, 2 indicates that it is necessary to calculate the value by columns.  This code prints the three worst variables: <br><br><pre> v389_fBodyAccJerkbandsEnergy57_64 v479_fBodyGyrobandsEnergy33_40 v60_tGravityAcciqrX
 14.70005 12.33718 12.18477 
</pre><br>  The closer these values ‚Äã‚Äãare to zero, the less is the distortion of the distribution, and here it is, frankly, rather big.  In this case, caret has a BoxCox transformation implementation.  <a href="http://appliedpredictivemodeling.com/">I read</a> that Random Forest is not sensitive to such things, so I decided to leave the signs as they are and at the same time to see how the SVM will cope with this. <br><br>  It remains to choose the model quality criterion: Accuracy accuracy or accuracy or Kappa acceptance criterion.  If the cases of classes are unevenly distributed, you need to use Kappa, this is the same Accuracy only taking into account the probability to randomly ‚Äúpull out‚Äù one or another class.  By making <i>summary ()</i> for the Activity column, checked the distribution: <br><br><pre>      WALKING WALKING_UP WALKING_DOWN SITTING STANDING LAYING 
         1226 1073 986 1286 1374 1407
</pre><br>  Cases are distributed almost equally, except maybe walking_down (some of the volunteers apparently did not really like to go down the stairs), which means you can use Accuracy. <br><br><h4>  Training </h4><br>  Trained RF model on the full set of features.  For this, the following construction on R was used: <br><pre> <code class="hljs django"><span class="xml"><span class="xml">fitControl </span><span class="hljs-tag"><span class="xml"><span class="hljs-tag">&lt;</span></span><span class="hljs-name"><span class="xml"><span class="hljs-tag"><span class="hljs-name">-</span></span></span></span><span class="xml"><span class="hljs-tag"> </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">trainControl</span></span></span></span><span class="xml"><span class="hljs-tag">(</span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">method</span></span></span></span><span class="xml"><span class="hljs-tag">=</span></span><span class="hljs-string"><span class="xml"><span class="hljs-tag"><span class="hljs-string">"cv"</span></span></span></span><span class="xml"><span class="hljs-tag">, </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">number</span></span></span></span><span class="xml"><span class="hljs-tag">=</span></span><span class="hljs-string"><span class="xml"><span class="hljs-tag"><span class="hljs-string">5)</span></span></span></span><span class="xml"><span class="hljs-tag"> </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">set.seed</span></span></span></span><span class="xml"><span class="hljs-tag">(</span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">123</span></span></span></span><span class="xml"><span class="hljs-tag">) </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">forest_full</span></span></span></span><span class="xml"><span class="hljs-tag"> &lt;</span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">-</span></span></span></span><span class="xml"><span class="hljs-tag"> </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">train</span></span></span></span><span class="xml"><span class="hljs-tag">(</span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">Activity</span></span></span></span><span class="xml"><span class="hljs-tag">~</span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">.</span></span></span></span><span class="xml"><span class="hljs-tag">, </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">data</span></span></span></span><span class="xml"><span class="hljs-tag">=</span></span><span class="hljs-string"><span class="xml"><span class="hljs-tag"><span class="hljs-string">train_data,</span></span></span></span><span class="xml"><span class="hljs-tag"> </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">method</span></span></span></span><span class="xml"><span class="hljs-tag">=</span></span><span class="hljs-string"><span class="xml"><span class="hljs-tag"><span class="hljs-string">"rf"</span></span></span></span><span class="xml"><span class="hljs-tag">, </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">do.trace</span></span></span></span><span class="xml"><span class="hljs-tag">=</span></span><span class="hljs-string"><span class="xml"><span class="hljs-tag"><span class="hljs-string">10,</span></span></span></span><span class="xml"><span class="hljs-tag"> </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">ntree</span></span></span></span><span class="xml"><span class="hljs-tag">=</span></span><span class="hljs-string"><span class="xml"><span class="hljs-tag"><span class="hljs-string">100,</span></span></span></span><span class="xml"><span class="hljs-tag"> </span></span><span class="hljs-attr"><span class="xml"><span class="hljs-tag"><span class="hljs-attr">trControl</span></span></span></span><span class="xml"><span class="hljs-tag"> = </span></span><span class="hljs-string"><span class="xml"><span class="hljs-tag"><span class="hljs-string">fitControl)</span></span></span></span></span></span></code> </pre><br>  It provides k-fold cross-validation with k = 5.  By default, three models are trained with different mtry values ‚Äã‚Äã(the number of signs that are randomly selected from the entire set and are considered as a candidate for each branching tree), and then the best one is selected by accuracy.  The number of trees for all models is the same ntree = 100. <br><br>  To determine the quality of the model on the test sample, I took the <i>confusionMatrix (x, y)</i> function from caret, where x is the vector of predicted values, and y is the vector of values ‚Äã‚Äãfrom the test sample.  Here is part of her issue: <br><br><pre>               Reference
 Prediction WALKING WALKING_UP WALKING_DOWN SITTING STANDING LAYING
   WALKING 482 38 17 0 0 0
   WALKING_UP 7,426 37 0 0 0
   WALKING_DOWN 7 7 366 0 0 0
   SITTING 0 0 0 433 51 0
   STANDING 0 0 0 58 481 0
   LAYING 0 0 0 0 0 537
 Overall Statistics
                Accuracy: 0.9247          
                  95% CI: (0.9145, 0.9339)
</pre><br>  Training on the full set of features took about 18 minutes on a laptop with an Intel Core i5.  It could have been done several times faster on OS X, using several processor cores using the <a href="http://cran.r-project.org/web/packages/doMC/doMC.pdf">doMC</a> package, but for Windows there is no such thing, as <a href="http://cran.r-project.org/web/packages/doMC/doMC.pdf">far</a> as I know. <br><br>  Caret supports several SVM implementations.  I chose svmRadial (SVM with a core - a radial basis function), it is often used with caret, and is a general tool when there is no special information about the data.  To train a model with SVM, simply change the value of the method parameter in the <i>train ()</i> function to svmRadial and remove the do.trace and ntree parameters.  The algorithm showed the following results: Accuracy on the test sample - 0.952.  In this case, the training of the model with five-fold cross-validation took a little more than 7 minutes.  Left a note on the memory: do not grab immediately for the Random Forest. <br><br><h4>  Importance of variables </h4><br>  You can get the results of the built-in assessment of the importance of variables in RF using the <i>varImp ()</i> function from the caret package.  The construction of the <i>plot</i> view <i>(varImp (model), 20) will</i> reflect the relative importance of the first 20 signs: <br><img src="//habrastorage.org/files/049/bf7/7da/049bf77da5314aed87fd8978950cd2e2.png"><br>  "Acc" in the title indicates that this variable was obtained by processing the signal from the accelerometer, "Gyro", respectively, from the gyroscope.  If you look closely at the graph, you can make sure that there are no data from the gyroscope among the most important variables, which is surprising and inexplicable for me personally.  (‚ÄúBody‚Äù and ‚ÄúGravity‚Äù are two components of the signal from the accelerometer, t and f are the time and frequency domains of the signal). <br><br>  Substituting in RF attributes, selected by importance, meaningless exercise, he had already selected and used them.  But with the SVM can happen.  I started with 10% of the most important variables and began to increase by 10% each time controlling the accuracy, finding the maximum, reduced the step first to 5%, then to 2.5%, and finally to one variable.  The result - the maximum of accuracy was in the area of ‚Äã‚Äã490 signs and amounted to 0.9545, which is better than the value on the full set of signs by only a quarter percent (an extra pair of correctly classified cases).  This work could be automated, as part of the caret is the implementation of RFE (Recursive feature elimination), it recursively removes and adds one variable each and controls the accuracy of the model.  There are two problems with it, RFE works very slowly (inside Random Forest), for a data set that is similar in number of features and cases, the process would take about a day.  The second problem is the accuracy on the training sample, which RFE evaluates, it is not at all the same as the accuracy on the test sample. <br><br>  The code that extracts from varImp and orders, in descending order of importance, the names of a given number of attributes, looks like this: <br><pre> <code class="hljs lua">imp &lt;- varImp(model)<span class="hljs-string"><span class="hljs-string">[[1]]</span></span> vars &lt;- rownames(imp)[order(imp$Overall, decreasing=TRUE)][<span class="hljs-number"><span class="hljs-number">1</span></span>:<span class="hljs-number"><span class="hljs-number">56</span></span>]</code> </pre><br><h4>  Feature filtering </h4><br>  To clear my conscience, I decided to try some other method of selecting signs.  I chose to filter features based on the calculation of the information gain ratio (it is found as an information gain or information gain), a synonym for Kullback-Leibler divergence.  IGR is a measure of the differences between the probability distributions of two random variables. <br><br>  To calculate IGR, I used the <i>information.gain ()</i> function from the <a href="http://cran.r-project.org/web/packages/FSelector/FSelector.pdf">FSelector</a> package.  The package needs a JRE to work.  Incidentally, there are other tools that allow you to select features based on entropy and correlation.  The IGR values ‚Äã‚Äãare inverse to the ‚Äúdistance‚Äù between the distributions and normalized [0.1], i.e.  the closer to one the better.  After calculating the IGR, I ordered the list of variables in descending order of IGR, the first 20 looked like this: <br><img src="//habrastorage.org/files/601/3fc/4fa/6013fc4faf154d13b373836fc825250f.png"><br>  IGR gives a completely different set of "important" signs, with important only five coincided.  There is no gyroscope in the top again, but there are a lot of signs with the X component.  The maximum IGR value is 0.897, the minimum is 0. After receiving an ordered list of features, it acted with it as well as with importance.  Checked on SVM and RF, significantly increase the accuracy did not work. <br><br>  I think that the selection of signs in similar tasks does not always work, and there are at least two reasons.  The first reason is related to the construction of features.  The researchers, who prepared the data set, tried to "survive" all the information from the signals from the sensors and did it for sure consciously.  Some signs give more information, some less (only one variable turned out to be zero with an IGR).  This is clearly seen if you plot graphs of the values ‚Äã‚Äãof attributes with different IGR levels.  For definiteness, I chose the 10th and 551st.  It is seen that for a sign with a high IGR, the points are well visually separable, with a low IGR - they resemble a color mixture, but obviously they carry some piece of useful information. <br><img src="//habrastorage.org/files/4ea/874/5b1/4ea8745b13b44353a329243c8ee266d3.png"><br><img src="//habrastorage.org/files/bf0/9dd/51e/bf09dd51ec724e85855990eb53348084.png"><br>  The second reason is related to the fact that the dependent variable is a factor with more than two levels (here - six).  Reaching maximum accuracy in one class, we deteriorate in the other.  This can be shown on the mismatch matrices for two different sets of features with the same accuracy: <br><pre> Accuracy: 0.9243, 561 variables
               Reference
 Prediction WALKING WALKING_UP WALKING_DOWN SITTING STANDING LAYING
   WALKING 483 36 20 0 0 0
   WALKING_UP 1 428 44 0 0 0
   WALKING_DOWN 12 7 356 0 0 0
   SITTING 0 0 0 433 45 0
   STANDING 0 0 0 58 487 0
   LAYING 0 0 0 0 0 537

 Accuracy: 0.9243, 526 variables
               Reference
 Prediction WALKING WALKING_UP WALKING_DOWN SITTING STANDING LAYING
   WALKING 482 40 16 0 0 0
   WALKING_UP 8,425 41 0 0 0
   WALKING_DOWN 6 6 363 0 0 0
   SITTING 0 0 0 429 44 0
   STANDING 0 0 0 62 488 0
   LAYING 0 0 0 0 0 537
</pre><br>  In the upper variant, there are fewer errors in the first two classes, in the lower variant, in the third and fifth. <br><br>  Summing up: <br>  1. SVM ‚Äúmade‚Äù Random Forest in my task, works twice as fast and gives a better model. <br>  2. It would be correct to understand the physical meaning of variables.  And, it seems, on a gyroscope in some devices you can save. <br>  3. The importance of variables from RF can be used to select variables with other teaching methods. <br>  4. Selection of features based on filtering does not always improve the quality of the model, but at the same time reduces the number of features, reducing training time with a slight loss in quality (when using 20% ‚Äã‚Äãof important variables, the accuracy in SVM was only 3% lower than the maximum). <br><br>  The code for this article can be found in my <a href="http://github.com/khmelkoff/HAR">repository</a> . <br><br>  A few additional links: <br><ul><li>  <a href="http://machinelearningmastery.com/feature-selection-with-the-caret-r-package/">Feature Selection</a> with the Caret R Package </li><li>  <a href="https://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm">Random Forests</a> , Leo Breiman and Adele Cutler </li></ul><br><br>  <b>UPD:</b> <br>  On the advice of <a href="http://habrahabr.ru/users/kenoma/" class="user_link">kenoma</a> , a major component analysis (PCA) was done.  Used a variant with the caret preProcess function: <br><pre> <code class="hljs haskell"><span class="hljs-title"><span class="hljs-title">pca_mod</span></span> &lt;- preProcess(train_data[,<span class="hljs-number"><span class="hljs-number">-1</span></span>], method=<span class="hljs-string"><span class="hljs-string">"pca"</span></span>, thresh = <span class="hljs-number"><span class="hljs-number">0.95</span></span>) pca_train_data &lt;- predict(pca_mod, newdata=train_data[,<span class="hljs-number"><span class="hljs-number">-1</span></span>]) dim(pca_train_data) # [<span class="hljs-number"><span class="hljs-number">1</span></span>] <span class="hljs-number"><span class="hljs-number">7352</span></span> <span class="hljs-number"><span class="hljs-number">102</span></span> pca_train_data$<span class="hljs-type"><span class="hljs-type">Activity</span></span> &lt;- train_data$<span class="hljs-type"><span class="hljs-type">Activity</span></span> pca_test_data &lt;- predict(pca_mod, newdata=test_data[,<span class="hljs-number"><span class="hljs-number">-1</span></span>]) pca_test_data$<span class="hljs-type"><span class="hljs-type">Activity</span></span> &lt;- test_data$<span class="hljs-type"><span class="hljs-type">Activity</span></span></code> </pre><br>  A cutoff of 0.95, it turned out 102 components. <br>  RF accuracy on the test sample: 0.8734 (5% lower than accuracy on the full set) <br>  SVM accuracy: 0.9386 (one percent lower).  I think this result is quite good, so the advice was useful. </div><p>Source: <a href="https://habr.com/ru/post/257405/">https://habr.com/ru/post/257405/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../257389/index.html">How we did the cloud automation system of the restaurant business</a></li>
<li><a href="../257393/index.html">Offline data handling in a mobile application using Couchbase Lite</a></li>
<li><a href="../257397/index.html">Layout of responsive emails: a detailed guide (part 2)</a></li>
<li><a href="../257401/index.html">We get acquainted with Fabric.js. Part 4</a></li>
<li><a href="../257403/index.html">The first 6 lectures of the online school Android developers</a></li>
<li><a href="../257407/index.html">We issue a digital certificate and verify the signature using BouncyCastle</a></li>
<li><a href="../257409/index.html">Discrete Fourier Transform of the Fractal Brownian Motion</a></li>
<li><a href="../257413/index.html">Trojan-Downloader.Win32.Cabby.cemx - Part One - Unpacking</a></li>
<li><a href="../257415/index.html">Typographer - the story continues</a></li>
<li><a href="../257417/index.html">120 servers in 30 days: tenders and other nuances of working with government agencies</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>