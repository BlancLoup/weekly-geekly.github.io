<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Likelihood, P-values ‚Äã‚Äãand reproducibility crisis</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Or: How the transition from the publication of P-values ‚Äã‚Äãto the publication of likelihood functions will help to cope with the crisis of reproducibil...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Likelihood, P-values ‚Äã‚Äãand reproducibility crisis</h1><div class="post__text post__text-html js-mediator-article">  <b>Or: How the transition from the publication of P-values ‚Äã‚Äãto the publication of likelihood functions will help to cope with the crisis of reproducibility: personal opinion of Eliezer Yudkovsky.</b> <br><br><img src="https://habrastorage.org/getpro/habr/post_images/50b/6fd/964/50b6fd9646a39b7f1e1887ebb515fb65.png" alt="If you look at the KDPV, you‚Äôll find out if you‚Äôre at"><br><br>  <i>Translator's commentary: Yudkovsky, the author of <a href="http://hpmor.ru/">HPMOR</a> , the creator of <a href="https://www.lesswrong.com/">Lesswrong</a> and so on and so forth, stated his position on the use of Bayesian statistics in the natural sciences in the form of a dialogue.</i>  <i>Just such a classic dialogue from antiquity or the Renaissance, with characters setting out ideas, exchanging barbs interspersed with convoluted arguments and inevitably blunt Simplicio.</i>  <i>The dialogue is quite long, about twenty minutes of reading, but in my opinion, it's worth it.</i> 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <div class="spoiler">  <b class="spoiler_title">Disclaimers</b> <div class="spoiler_text"><ul><li>  This dialogue was written by a <a href="https://arbital.com/p/bayes_reasoning/">proponent of the Bayesian approach</a> .  The replicas of the Scientist in the dialogue below may not even pass the <a href="https://www.econlib.org/archives/2011/06/the_ideological.html">Turing ideological test</a> for imaginationism.  It is possible that they do not pay tribute to the arguments and counterarguments of the advocates of the frequency approach to probability. </li><li>  The author does not expect that the proposals described below will be accepted by the wide scientific community in the next ten years.  However, it was worth writing. </li></ul><br>  If you are not familiar with the Bayes rule, there is a <a href="https://arbital.com/p/bayes_rule_guide/">detailed introduction</a> on Arbital. <br></div></div><br>  <b>Moderator:</b> Good evening.  Today in our studio: A <b>scientist</b> , a practicing specialist in the field of ... chemical psychology or something like that;  his opponent is <b>Bayesian</b> , who intends to prove that the crisis of reproducibility in science can be somehow overcome by replacing the P-values ‚Äã‚Äãwith something from Bayesian statistics ... <br>  <b>Student:</b> Sorry, how do you spell it? <br>  <b>Moderator:</b> ... and, finally, not understanding anything Student to my right. <br><a name="habracut"></a><br>  <b>Moderator: Bayesian</b> , could you start by telling you what the essence of your proposal is? <br>  <b>Bayesian:</b> Roughly speaking, the essence is this.  Suppose we have a coin.  We throw it up six times and watch the series OOOOOOOR <i>(approx. Lane: here and hereinafter O - Orel, R - Reshka)</i> .  Should we suspect that something is wrong with the coin? <br>  <b>Scientist:</b> No. <br>  <b>Bayesian:</b> The coin is just for example.  Suppose we offer a sample of volunteers a plate with two cookies: one with green dressing and one with red.  The first five people take the green cookies, and the sixth takes the red.  Is it true that people prefer cookies with green dressing, or is it better to consider such a result as random? <br>  <b>Student:</b> Probably, one may <i>suspect</i> that maybe people prefer green dressing.  At least, psychology students who tend to volunteer in strange experiments, like green sprinkling more.  Even after six observations, one may suspect so much, although I suspect that there is some kind of trick here. <br>  <b>Scientist:</b> I think this is not yet suspicious.  Many which hypotheses look promising at N = 6, but not confirmed at N = 60. <br>  <b>Bayesian:</b> Personally, I would suspect that our volunteers do not <i>prefer red dressing</i> , or at least prefer it not very much.  But in general, I came up with these examples only to show how P-values ‚Äã‚Äãare considered in modern scientific statistics and what is wrong with them from the Bayesian point of view. <br>  <b>Scientist:</b> Can't you think of a more realistic example with 30 volunteers? <br>  <b>Bayesian:</b> Yes, but the Student doesn‚Äôt understand anything. <br>  <b>Student:</b> That's for sure. <br>  <b>Bayesian:</b> So, dear experts: Eagle, eagle, eagle, eagle, eagle, tails.  Attention, question: will you call this result ‚Äústatistically significant‚Äù or not? <br>  <b>Scientist:</b> Mr. Leading, it is not significant.  Under the null hypothesis that a coin is honest (or with a similar null hypothesis that the color of the dressing does not affect the choice of cookies), the same or a more pronounced result can be obtained in 14 out of 64 cases. <br>  <b>Student:</b> Yeah.  I understand correctly: This is because we consider the outcomes of OOOOOOO and  as ‚Äúthe same or more pronounced,‚Äù there are a total of 14, and the total possible outcomes for 6 throws are 2 <sup>6</sup> = 64.  14/64 is 22%, which is above 5%, so the result is not considered significant at the level of p &lt;0.05.  So? <br>  <b>Scientist:</b> Right.  I would also note that in practice, even at the outcome of OOOOOOO, it is not worth stopping the experiment and writing an article about the fact that the coin always falls out of an eagle. <br>  <b>Bayesian:</b> The fact is that if you can <i>stop</i> throwing a coin at any time, you will have to ask yourself: "How likely is it that I will find a moment to stop the experiment in which the number of eagles will look public?" And this is in the P-values ‚Äã‚Äãparadigm is a completely different story. <br>  <b>Scientist:</b> I meant only that only six experiments - this is not serious, even if we study the color of the cookies.  But yes, you are right too. <br>  <b>Student:</b> Why is it important at all, can I stop throwing a coin or can't I? <br>  <b>Bayesian:</b> What a wonderful question. <br>  <b>Scientist:</b> The thing is, P-values ‚Äã‚Äãare complicated.  You can not just take the numbers, throw them into the program and publish what this program will issue.  If you decide in advance to flip a coin exactly six times, and then stop regardless of the result, then the result of OOOOOO or PPPPPP will be obtained on average 2 times out of 64, or in 3.1% of cases.  This is significant at p &lt;0.05.  But suppose that in reality you are a false and shameless forger.  Or just an incompetent student who himself does not understand what he is doing.  Instead of choosing the number of shots in advance, you throw and throw a coin until you get a result that looks statistically significant.  It <i>would be</i> statistically significant <i>if</i> you decided to throw a coin exactly the same amount in advance.  But in fact, you did not decide in advance.  You decided to stop only after you got the results.  So you can not do. <br>  <b>Student:</b> Okay, I read about it somewhere, but I didn‚Äôt understand what was wrong with that.  This is my research, and I should know better if there is enough data or not. <br>  <b>Scientist:</b> The whole point of P-values ‚Äã‚Äãis to create a test that the null hypothesis cannot pass.  To make sure, in other words, that smoke without fire happens not too often.  To do this, it is necessary to organize research in such a way as not to generate ‚Äústatistically significant‚Äù discoveries in the absence of the desired phenomenon.  If you flip a coin exactly six times (and decide on this number in advance), then the probability of receiving from an honest coin six eagles or six tails is less than 5%.  If you throw a coin <i>as many</i> times <i>as you like</i> , and after each throw you recalculate the P-value ( <i>pretending</i> that the number of throws was known in advance), then the chance to get less than p &lt;0.05 is <i>much more than</i> 5% sooner or later.  Therefore, such an experiment detects smoke without fire much more often than in 1 out of 20 cases. <br>  Bayesian: Personally, I like to formulate this problem like this: let's say you throw a coin and get OOOOOR.  If at the same time you are in the slave only to Allah (for Allah is wise, knowing) the depths of your heart have determined the number of shots <i>in advance</i> , then the result does not matter;  p = 0.22.  If, after three months of fasting, you brought a vow to Saint Francis to throw a coin <i>until the tails fell</i> , then the same result is statistically significant with a quite good p = 0.03.  Because the chance that with probabilities of 1: 1 tails will have to wait six or more shots, 1/32. <br>  <b>Student:</b> What? <br>  <b>Scientist:</b> It is rather a parody, of course.  In practice, no one will throw a coin until a single tail falls and then stop.  But in general, Bayesian is right, P-values ‚Äã‚Äãdo exactly that.  Strictly speaking, we are trying to find out how rare the result is among those that we <i>could</i> get.  A person who tosses a coin before the first tails can get the results {R, OR, OOR, OOOR, OOOOR, OOOOOR ...} and so on.  The class of results in which six or more shots are made is {OOOOOR, OOOOOOR, OOOOOOOOO ...}, the total probability of which is 1/64 + 1/128 + 1/256 ... = 1/32.  A person throwing a coin exactly six times gets one of the results of the class {, OOOOO, OOOORO, OOOOORR ...}, in which 64 elements.  For the purposes of our experiment, OOOOOR is equivalent to OOOORO, OOOROO and others the same.  So yes, this is all pretty counter-intuitive.  If we really carried out the first experiment - OOOOOR would be a significant result, which is unlikely with an honest coin.  And if we carried out the second experiment - OOOOOR would not have been significant, because even with an honest coin from time to time <i>something similar</i> happens. <br>  <b>Bayesian:</b> You do not accidentally worry that the results of the experiment depend on what you think? <br>  <b>Scientist:</b> This is a matter of conscience.  Any kind of research will cost little if you lie about their results, that is, literally telling the truth about which side the coin fell out.  If you lie about <i>what kind of experiment was conducted</i> - the effect will be the same.  So you just have to honestly say what rules were used for throwing.  Of course, the contents of the head of a scientist are less obvious than the side with which the coin lies.  Therefore, it is always possible to tweak the analysis parameters, not to write how the number of subjects was determined, choose the statistical test that confirms your favorite hypothesis ... You can think of a lot of things if you wish.  And it will be easier than falsifying the original data.  In English, this is called p-hacking.  And in practice, of course, much less obvious ways of creating smoke without fire are used than the stupid null hypothesis invented after the fact.  This is a serious problem, and to some extent a crisis of reproducibility is connected with it, although it is not clear to which one. <br>  <b>Student: Does</b> this ... sound reasonable?  Probably, this is one of those things that you have to deal with and search through a bunch of examples for a long time, and then everything will become clear? <br>  <b>Bayesian:</b> No. <br>  <b>Student: I</b> mean? <br>  <b>Bayesian:</b> In the sense of "Student, you were right from the very beginning."  If what the experimenter <i>thinks</i> doesn‚Äôt affect the side by which the coin falls, then his thoughts should not affect the fact that the results of the throw tell us about the universe.  My dear Student, the statistics you are taught is nothing more than a heap of crooked crutches that you haven't even bothered to do internally consistent.  For God's sake, she gives out <i>different</i> wrong results depending on what's going on in your head!  And this is a much more serious problem than the tendency of some scientists to slightly lie in the ‚ÄúMaterials and Methods‚Äù. <br>  <b>Scientist:</b> This is ... a serious statement, to say the least.  But tell me, I ask you: what are we, the unfortunate, to do? <br>  <b>Bayesian:</b> Analyze as follows: this particular OOOOOP result can be obtained with six shots of a perfectly balanced coin with a probability of 1/64, or approximately 1.6%.  Suppose we already suspected that our coin was not perfectly balanced.  And not just imperfectly, but in such a way that it fell on an eagle on average five out of six times.  This, of course, is a wild simplification, but I will move on to realistic hypotheses a bit later.  And so, this hypothetical shulersky coin gives out OOOOOR sequence with probability (5/6) <sup>5</sup> * (1/6) <sup>1</sup> .  This is about 6.7%.  So we have two hypotheses: "The coin is the most common" and "The coin falls out of an eagle in 5/6 cases."  This particular result in the second case <i>is 4.3 times more likely</i> than in the first.  The probability of the LLCOOP sequence for another hypothetical cheat coin, which in 5 cases out of six falls on a tail, is 0.01%.  So if someone suddenly thought that this second coin was before us, then we now have a good argument <i>against</i> his hypothesis.  This particular result is 146 times more likely for an honest coin than for a coin that falls out of an eagle only once out of six.  Similarly, our hypothetical lovers of red cookies would be much less likely to eat green. <br>  <b>Student:</b> Okay, I seem to understand math.  But, frankly, I do not catch, what is its meaning. <br>  <b>Bayesian: Let me</b> explain now, but first note the following: the results of my calculations do not depend on <i>why the</i> coin was planted exactly six times.  Maybe after the sixth shot you decided that there was already enough data.  Maybe, after a series of five shots, <a href="https://en.wikipedia.org/wiki/Namagiri_Thayar">Namagiri Tayyar</a> appeared in your dream and advised you to throw the coin again.  Coin anyway.  The fact remains: this particular series of OOOOOR for an honest coin is four times less likely than for a coin that falls out of an eagle five times out of six. <br>  <b>Scientist:</b> I agree, your calculations have at least one useful property.  What's next? <br>  <b>Bayesian:</b> And then you publish the results in a journal.  It is desirable together with the raw data, because then anyone can calculate the plausibility of any hypothesis.  Suppose someone unexpectedly became interested in the hypothesis ‚ÄúA coin falls out of an eagle 9 times out of 10, not 5 times out of 6‚Äù. In this case, the series of observations of the LLCOOR has a probability of 5.9%, which is slightly less than our hypothesis about five eagles out of six throws (6 , 7%), but 3.7 times more than the hypothesis that the coin is perfectly balanced (1.6%).  It is impossible to think up all possible hypotheses in advance, and it is not necessary.  It is enough to publish complete data - then anyone who has a hypothesis will be able to easily calculate the likelihood he needs.  The Bayesian paradigm requires the publication of raw data, because the focus is precisely on a <i>specific result</i> , and not on a class of supposedly identical outcomes. <br>  <b>Scientist:</b> In this I agree with you, the publication of complete data sets is one of the most important steps to overcome the reproducibility crisis.  But personally, I don‚Äôt understand what I should <i>do</i> with all these ‚ÄúAnd it‚Äôs so much more likely than B‚Äù. <br>  <b>Student:</b> Me too. <br>  <b>Bayesian:</b> It's not entirely trivial ... did you read our <a href="https://arbital.com/p/bayes_rule_guide/">introduction to Bayes rule</a> ? <br>  <b>Student:</b> Great.  Here are just another three-page statistical textbook, and I did not have enough. <br>  <b>Bayesian: You</b> can actually <a href="https://arbital.com/p/bayes_rule_fast_intro/">read</a> it <a href="https://arbital.com/p/bayes_rule_fast_intro/">in an hour</a> .  It's just that this is literally <i>not trivial</i> , that is, it requires an explanation.  But okay, in the absence of a full introduction, I will try to think of something.  Most likely, it will <i>sound</i> reasonable - and the logic is <i>indeed</i> correct - but not a fact that is self-evident.  Go.  There is a theorem that proves the correctness of the following arguments: <br>  <i>(Bayesian gains air)</i> <br>  <b>Bayesian:</b> Let's say Professor Plume and Miss Scarlet are suspected of murder.  After examining the biographies of both, we assume that it would be twice as easy for a professor to kill a man than Miss Scarlet.  With this assumption, let's start.  It turns out, however, that the deceased was poisoned.  We know that if Professor Plume is about to kill someone, he will use poison with a probability of 10% (and in 9 cases out of 10 he will prefer, for example, a revolver).  Miss Scarlet, if she decides to kill, uses poison with a probability of 60%.  In other words, the professor‚Äôs use of poison <i>is six times less likely</i> than Miss Scarlet‚Äôs use of poison.  Since we have new information, namely the method of murder, we must update our assumption and assume that Plume is about three times less likely killer: 2 * 1/6 = 1/3. <br>  <b>Student:</b> Not sure I understood that.  What does the phrase "Professor Plume mean three times less likely murderer than Miss Scarlet"? <br>  <b>Bayesian:</b> It means that if we do not have other suspects, then the probability that the victim was killed by Plume is 1/4.  The remaining 3/4 make up the probability that the killer is Miss Scarlet.  Therefore, the probability of the professor's guilt is three times lower than that of Miss Scarlet. <br>  <b>Scientist:</b> And now I want to know what you mean by "probability of guilt."  Plume either committed the murder, or he did not commit it.  We cannot consider a sample of the killings and find that Plume is indeed guilty of a quarter of them. <br>  <b>Bayesian:</b> I was hoping not to get into this, but oh well.  My good Scientist, I mean that if you offered me a bet with 1: 1 bets on whether Plume killed the victim or not, I would bet that he did not.  But if under the terms of the betting, I would pay you $ 1 in case of his innocence, and you pay me $ 5 in the event of his guilt, I would gladly bet on the guilt.  The 2012 presidential election was held only once, and Obama's Probability of Victory is the same conceptually vague thing as Plume's Guilt Probability.  But if on November 7 you were offered to bet $ 10 on Obama and promised $ 1000 in case of his victory, then you would hardly refuse such a bet.  In general, when prediction markets and large liquid pools of bets accept 6: 4 bets on an event, this event occurs in about 60% of cases.  Markets and pools are <i>well calibrated</i> by probabilities in this range.  If they were calibrated poorly, that is, if the events that are being bid at 6-4, happened 80% of the time, then someone would have noticed and enriched themselves at the expense of such rates.  At the same time, he would raise the price of the rate until the market becomes well calibrated.  And since events with a market estimate of a probability of 70% do occur about 7 times out of 10, I don‚Äôt understand why to insist that such a probability does not make sense. <br>  <b>Student:</b> I admit, it <i>sounds</i> convincing.  But for sure it only seems to me, and in fact there are a whole bunch of tricky arguments for and against. <br>  <b>Bayesian:</b> <a href="https://arbital.com/p/probability_interpretations/">There really is a</a> <b>bunch of</b> arguments, but the general conclusion from it is that your intuitive presentation is pretty close to the truth. <br>  <b>Scientist:</b> Well, we'll come back to this.  And what if there are two agents, both in your terms ‚Äúwell calibrated‚Äù, but one of them claims ‚Äú60%‚Äù and the other says ‚Äú70%‚Äù? <br>  <b>Bayesian:</b> Suppose I toss a coin and do not see which side it fell.  In this case, my ignorance is not information about a coin, it is information about me.  It exists in the head, not in the surrounding world, just as the white spots on the map do not mean that there is no territory in this place.  If you looked at the coin, but I didn‚Äôt, it‚Äôs quite reasonable that you and I are in different states of uncertainty about it.  Given that I am not one hundred percent certain, it makes sense for me to express my uncertainty in terms of probability.  There are <a href="https://arbital.com/p/coherence_theorems/">three hundred theorems</a> that claim that if someone‚Äôs expression of uncertainty is <i>not</i> in fact a distribution of probability, then, in general, that‚Äôs what he needs.  For some reason, it always turns out that if an agent‚Äôs thinking under conditions of uncertainty violates any of the standard axioms of probability theory, the earth opens up, water turns into blood, and dominated strategies and obviously losing stakes spill out of heaven. <br>  <b>Scientist:</b> Well, here I was wrong.  We will come back to this, too, but first answer my question: what should we do with plausibility after we received them? <br>  <b>Bayesian:</b> According to the laws of probability theory, these likelihoods <i>are</i> evidence.<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">They are the ones who force us to change our a priori probabilities from 2: 1 in favor of Plume to 3: 1 in favor of Scarlet. If I have two hypotheses and the likelihood of data for both, then I should change my opinion in the manner described above. If I change it somehow differently - then the heavens open, strategies pour in, and so on. Bayes theorem: this is not just a statistical method, it is a LAW. </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Student: I</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> apologize, but I still do not understand. Suppose we are conducting an experiment. And, let's say, the results obtained six times more likely if Herr Troopa was killed by Professor Plume than they would have been if Miss Scarlet was the killer </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. The student obviously confused the likelihood of poison use by two killers</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . To arrest us professors or not?</font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Scientist:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> I think, first we need to come up with a more or less realistic a priori probability, for example, " </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">a priori</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> I believe that the probability of killing the Troupe by Plume is 20%." Then it must be multiplied by a likelihood ratio of 6: 1, and the ratio of a posteriori probabilities of 3: 2, which Plume did kill the Troupe, is obtained. Then you can say that Plume is guilty with a probability of 60%, and then let the prosecutor's office understand. </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bayesovets: </font></font></b> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">None</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . For heaven's sake! Do you really think Bayesian statistics work that way? </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Scientist:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Does she work wrong? I have always believed that its main advantage is that it gives us a posteriori probabilities, which P-values ‚Äã‚Äãdo not really give, and the main drawback is that it requires a prior probabilities. Since they have to be taken more or less from the ceiling, the correctness of a posteriori probabilities can be challenged to the end of time. </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bayesian:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Articles should be published </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">likelihood</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . More precisely, it is necessary to publish raw data and calculate for them a few likelihoods of interest. But certainly not a posteriori probabilities. </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Student:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> I'm confused again. What is a posteriori probabilities? </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bayesian: </font></font></b> <a href="https://arbital.com/p/posterior_probability/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">A posteriori probability</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">- This is a statement like "With a probability of 60% of Herr. The troupe was killed by Professor Plume." As my colleague has already noted, such statements do not follow from P-values. And, in my opinion, they have no place in experimental articles, because these are </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">not the results of an experiment</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Student:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> But ... ok, Scientist, a question for you: let's say we got results with p &lt;0.01, that is, something with a probability of less than 1% with the null hypothesis "Professor Plume did not kill Herr Troupe". To arrest us or not? </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Scientist:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">First, it is not a realistic null hypothesis. Most likely, the null hypothesis will be something like "Nobody killed Herr Troupe" or "all suspects are equally guilty." But even if the null hypothesis described by you worked, even if we could reject Plume's innocence with p &lt;0.01, it would still be impossible to say that Plume is guilty with a probability of 99%. P-values ‚Äã‚Äãof this are not reported to us. </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Student:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> And </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">what</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> do they report then? </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Scientist:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> They report that the observed data are included in a certain class of possible outcomes, and that the results of this class are observed in less than 1% of cases if the null hypothesis is correct. More p-value means </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">nothing</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. You can not just go and move from p &lt;0.01 to "Professor Plume is guilty with a probability of 99%." A Bayesian is more likely to be able to better explain why. In general, in science one cannot interpret one thing as something else. Figures denote exactly what they denote, no more and no less. </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Student:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Generally excellent. At first I did not understand what I should do with plausibility, and </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">now</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> I still do not understand what I should do with P-values. What experiment is required to finally send Plume to prison? </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Scientist:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> In practice? If another pair of experiments in other laboratories confirms his guilt with p &lt;0.01, then most likely he is </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">really</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> guilty. </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bayesian:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">A ‚Äúcrisis of reproducibility‚Äù is when the matter is later raised and it turns out that he did </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">not</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> commit murder. </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Scientist:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> In general, yes. </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Student:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Somehow it turns out unpleasant. </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Scientist:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Life is generally an unpleasant thing. </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Student:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> So ... Bayesean, you probably have a similar answer? Something like the fact that if the likelihood ratio is large enough, say, 100: 1, then in practice can we assume that the corresponding hypothesis is true? </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bayesian:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Yes, but it is somewhat more complicated. Suppose I throw a coin 20 times and get OOOROOOROROROROOOOOOORROR. The catch is that the plausibility of the hypothesis ‚ÄúThe coin is guaranteed to issue a sequence of OOOROOOROROROOOOOOORROR‚Äù is higher than the plausibility of the hypothesis ‚ÄúCoin equiprobably drops out like an eagle or tails‚Äù is about a million times. In practice, if you did not hand me this hypothesis in a sealed envelope before the start of the experiment, I will consider it strongly retrained. I will have to give this hypothesis a penalty for complexity of </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">at least</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 2 </font><font style="vertical-align: inherit;">: </font></font><sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">20</font></font></sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : 1, because the sequence description alone takes 20 bits. In other words, to lower the prior probability so much that it more than compensates for the likelihood advantage. And this is not the only underwater rock. But </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">nevertheless</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, if you understand how and why the Bayes rule works - then in each case you can understand along the way. If the ratio of credibility for Plume versus any other suspect is 1000: 1, and there are only six suspects at all, then it can be assumed that the a priori probability was hardly much more than 10: 1 against the fact that he was a murderer. If so, then we can assume that he is guilty with a probability of 99%. </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Scientist:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> But nevertheless, it‚Äôs </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">not</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> worth </font><font style="vertical-align: inherit;">writing in the article </font><font style="vertical-align: inherit;">? </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bayesian:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Right. How to formulate ... The key condition for Bayesian analysis is that the </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">whole</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">relevant information. You can‚Äôt exclude data from analysis just because you don‚Äôt like it. This is actually the key condition of science as such, regardless of the statistics used. There are a lot of articles, the conclusions of which turned out just because some factor was not taken into account or the sample was unrepresentative in some parameter. I'm talking about what? And besides, how do I (as an experimenter) know what ‚Äúall relevant information‚Äù is? Who am I to calculate a posteriori probabilities? Maybe someone has published an article in which there are additional data and additional likelihoods that I should have taken into account, but I have not read it yet. So I just publish my data and my likelihood functions - and that‚Äôs it! I can not say that I considered </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">everything</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">arguments and now I can offer reliable a posteriori probabilities. And even if I could, then in a week another article may come out, and these probabilities will become obsolete. </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Student:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Roughly speaking, the experimenter just has to publish his data, calculate some likelihood for them and that's all? And then someone else will decide how to deal with them? </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bayesian:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Someone will have to choose a priori probabilities ‚Äî equal, or with maximum entropy, or with penalties for complexity, or some other ‚Äî then try to collect all possible data, calculate likelihoods, make sure that the result is </font></font><a href="https://arbital.com/p/strictly_confused/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">not crazy</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , and so on. other And they still have to recount if a new article comes out in a week. </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Student:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">It sounds quite </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">laborious</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bayesian:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> It would be much worse if we took up the meta-analysis of P-values. Updating Bayesian probabilities is </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">much</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> easier. It is enough to simply </font></font><a href="https://arbital.com/p/bayes_rule_multiple/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">multiply the</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> old a posteriori probabilities by new </font></font><a href="https://arbital.com/p/bayes_rule_functional/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">likelihood functions</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> and normalize them.</font></font> Everything.<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">If experiment 1 gives a likelihood ratio of 4: 1 for hypotheses A and B, and experiment 2 gives a likelihood ratio of 9: 1 for them, then together they give a ratio of 36: 1. That's all. </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Student:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> And you can't do that with P-values? One experiment with p = 0.05 and another experiment with p = 0.01 does not mean that actually p &lt;0.0005? </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Scientist: </font></font></b> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">No</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bayesian:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Dear viewers, please pay attention to my arrogant smile. </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Scientist:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> But I still worry about the need to invent a priori probabilities. </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bayesian:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> And why does she bother you more than the fact that everyone decided to consider one experiment and two replications with p &lt;0.01 criterion of Truth? </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Scientist:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> You want to say that the choice of a priori values ‚Äã‚Äãis no more subjective than the interpretation of P-values? </font></font> Hm<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">I wanted to say that the requirement, say, p &lt;0.001 should guarantee objectivity. </font><font style="vertical-align: inherit;">But then you will answer that the figure 0.001 (instead of 0.1 or 1e-10) is also sucked from the finger. </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bayesian:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> And add to this that it is less effective to require any arbitrary P-value than to suck a prior probability from the same finger. </font><font style="vertical-align: inherit;">One of the first theorems that threatened violators of probability axioms with Egyptian punishments was proved by Abraham Wald in 1947. </font><font style="vertical-align: inherit;">He tried to describe all the </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">acceptable strategies</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , calling the strategy some way to react to what you are observing. </font><font style="vertical-align: inherit;">Of course, different strategies under different circumstances can be more or less profitable. </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Acceptable strategy</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">He called one that is not dominated by any other strategy under all possible conditions. So, Wald discovered that the class of acceptable strategies coincides with the class of strategies that contain a probability distribution, update it based on observations according to Bayes' rule, and optimize the utility function. </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Student:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Excuse me, is it possible in Russian? </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bayesian:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> If you do something in connection with what you observe and get more or less money, for example, depending on what the real world is, then one of two things is true. </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Either</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> your strategy in some sense contains a probability distribution and updates it according to Bayes rule, </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">or</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">there is some other strategy that is never inferior to yours, and sometimes surpasses it. That is, for example, you say: ‚ÄúI will not quit smoking until I see an article proving the connection between smoking and cancer at p &lt;0.0001‚Äù. At least theoretically, there is a way to say ‚ÄúIn my opinion, the link between smoking and cancer exists with a probability of 0.01%. What are your likelihoods? ‚Äù, Which will be no worse than the first formulation, no matter what a priori probabilities of the existence of such a connection. </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Scientist:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Really? </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bayesian:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Yeah. The Bayesian revolution began with this theorem; since then it has been slowly gaining momentum. It should be noted that Wald proved his theorem a couple of decades after the invention of P-values. This, in my opinion, explains how it happened that all modern science was tied up with obviously ineffective statistics. </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Scientist:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> So you propose to throw out P-values ‚Äã‚Äãand instead publish only likelihood ratios? </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bayesian:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> In short, yes. </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Scientist:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Something I do not really believe in ideal solutions that are suitable for any conditions. I suspect - please do not consider it an insult - that you are an idealist. In my experience, in different situations different tools are needed and it would be unwise to throw out all but one. </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bayesian:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Well, I am ready to explain what I am an idealist and what is not. Likelihood functions alone will not resolve the reproducibility crisis. It cannot be completely resolved by simply ordering everyone to use more efficient statistics. The popularity of open access journals does not depend on the choice between plausibility and P-values. Problems with the review system also do not depend on it. </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Scientist:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> And everything else, therefore, depends? </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bayesovets:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Not everything, but they have a lot what </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">to help</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Let's count. </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bayesian:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">First of all. Likelihood functions do not force us to draw a line between ‚Äústatistically significant‚Äù and ‚Äúinsignificant‚Äù results. An experiment cannot have a ‚Äúpositive‚Äù or ‚Äúnegative‚Äù outcome. What is called the null hypothesis is now just one of the hypotheses that is not fundamentally different from all the others. If you throw a coin and get an OORRRROOO - one cannot say that the experiment could not ‚Äúreject the null hypothesis at p &lt;0.05‚Äù or ‚Äúreproduce the previously obtained result‚Äù. He merely added data that supports the hypothesis of an honest coin against the 5/6 eagles hypothesis with a likelihood ratio of 3.78: 1. So with the massive acceptance of Bayesian statistics, the results of such experiments will be less likely to go to the table. Not at all,because the editors of magazines have unexpected results that are more interesting than honest coins, and this must be dealt with directly. But P-values ‚Äã‚Äãdo not just do not struggle with this approach, they are his</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">stimulate</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ! It is because of him that p-hacking exists at all. So the transition to the likelihood will not bring happiness to all and a gift, but it </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">will definitely help</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bayesian:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Secondly. The likelihood system emphasizes the importance of the source data much more and will stimulate their publication wherever possible, because Bayesian analysis is based on how likely </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">these particular</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> results are in a particular model. The system of P-values, on the contrary, forces the researcher to consider the data as just one of the members of the class of ‚Äúequally extreme‚Äù results. Some scientists like to keep all their precious data with them; it's not just statistics. But P-values </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">stimulate</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">and this, because for the article, it‚Äôs not the data itself that is important, but whether they belong to a particular class. Once this is established, all the information contained in them as if collapses into a single bit of "significance" or "insignificance." </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bayesian:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Thirdly. From the point of view of probability theory, from the Bayes point of view, different magnitudes of effects are different hypotheses. This is logical, because they correspond to different likelihood functions and, accordingly, different probabilities of the observed data. If one experiment found an effect of 0.4, and another experiment found a ‚Äústatistically significant‚Äù value of the same effect of 0.1, then the experiment </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">did not reproduce.</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">and we don't know what the effect really is. This will avoid a fairly common situation where the magnitude of the ‚Äústatistically significant‚Äù effect all decreases and decreases with increasing sample size. </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bayesian:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Fourth. Likelihood functions greatly simplify data integration and meta-analysis. They may even help us </font></font><a href="https://arbital.com/p/strictly_confused/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">notice</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> that data is collected in heterogeneous conditions or that we do not consider the true hypothesis. In this case, either all the functions will be close to zero for all possible parameters, or the best hypothesis will give a much lower likelihood on the combined data </font></font><a href="https://arbital.com/p/strictly_confused/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">than it itself predicts</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . A more rigorous approach to reproducibility allows you to quickly understand whether such an experiment can be considered a repeat of such and such.</font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bayesian:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Fifth. Likelihood functions do not depend on what they think about them. These are objective statements about the data. If you publish the likelihood values, then there is only one way to deceive the reader - to falsify the data itself. P-hacking will not work. </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Scientist:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> This is what I </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">strongly</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> doubt. Suppose I decide to convince you that the coin often drops out of an eagle, although in fact it is honest. I will take a coin, I will throw it until I accidentally get a little more eagles, and then I‚Äôll stop. What then? </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bayesian:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Go ahead. If you do not falsify the data, you will not deceive me. </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Scientist:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The question was about what would happen if I checked the likelihood ratio after each roll and stopped as soon as it supported my favorite theory. </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bayesian:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> As an idealist, seduced by the deceptive beauty of the theory of probability, I answer you: as long as you give me honest raw data, I can and must do only one thing - multiply according to Bayes' rule. </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Scientist:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Really? </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bayesian:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Seriously. </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Scientist:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> So you don't care that I can check the likelihood ratio until I like it? </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bayesian:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Go ahead. </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Scientist:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Okay. Then I will write a script on Python, which simulates a throw of an honest coin </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">to</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, say, 300 times, and see how often I manage to get a 20: 1 ratio in favor of the ‚Äúcoin eagle drops in 55% of cases‚Äù ... What? </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bayesian:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Just a funny coincidence. When I first found out about this and doubted that the likelihood relationship could not be deceived in any tricky way, I wrote the same program on Python. Later, one friend of mine also learned about the likelihood relationship and also wrote </font></font><a href="https://gist.github.com/Soares/941bdb13233fd0838f1882d148c9ac14"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">the same program, also for some reason on Python</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . He launched it and discovered that the 20: 1 ratio for the hypothesis "55% of the eagles" was found at least once in 1.4% of the throws. If you require, for example, 30: 1 or 50: 1, their frequency drops even faster. </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Scientist:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">If you count your one and a half percent P-value, it looks good. But this is a very rude way to fool analysis; perhaps there are more complex and effective? </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bayesian:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> I was ... about five years old, probably, if not less, when I first learned about addition. One of my earliest memories. I sat, added 3 to 5 and tried to think of some way not to get 8. Which, of course, is very nice and generally an important step towards understanding what addition is (and mathematics in general). But now this is exactly what is nice, because we are adults and we understand that 5 plus 3 is inevitably equal to 8. The script, which constantly tests the likelihood ratio, does the same thing that I did in childhood. Having understood the theory, I realized that attempts to deceive Bayes' rule are </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">obviously</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">doomed. It's like trying to decompose 3 in some tricky way into 2 and 1 and add them separately to 5, or try to add first 1, and only then 2. Neither that nor 7 or 9 will work. The result of the addition is a </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">theorem</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , and it doesn't matter what sequence of operations we perform. If it is really equivalent to adding 3 to 5, then nothing can be obtained at the output, except 8. Probability theory theorems are also theorems. If the script could really work, it would mean a contradiction in probability theory, which means a contradiction in Peano arithmetic, on which the analysis of probabilities is built using rational numbers. What you and I tried to do - </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">exactly</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">as difficult as adding 3 and 5 in standard axioms of arithmetic and getting 7. </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Student:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Uh, why? </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Scientist:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> I did not understand either. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bayesian: Let </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">e</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> denote observation, </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">H</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> denote the hypothesis </font><font style="vertical-align: inherit;">,! </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">X</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> denotes "not X", P ( </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">H</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ) denotes the probability of the hypothesis, and P ( </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">X | Y</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ) denotes the </font></font><a href="https://arbital.com/p/conditional_probability/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">conditional probability of</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> X, provided that Y is true. There is a theorem showing that </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">P (H) = P ( </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">H | e</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ) * P ( </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">e</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> )) + (P ( </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">H |! e</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ) * P ( </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">! e</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ) </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Therefore, for the probability functions there is </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">no</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">arbitrarily complex analog of p-hacking, apart from data falsification, because no procedure known to the Bayesian agent will force it to update its a priori probabilities in a deliberately incorrect direction. For every change that we can get from watching </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">an e</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , there is a inverse variation that can be expected from the observation </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">! An e</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Student:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> What? </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Scientist:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> I did not understand either. </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bayesian:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Okay, </font><b><font style="vertical-align: inherit;">let's put</font></b><font style="vertical-align: inherit;"> it off until math and see ... yes, to the crisis of reproducibility. The scientist said that he is suspicious of ideal universal solutions. But in my opinion, the transition to likelihood functions </font><i><font style="vertical-align: inherit;">should</font></i><font style="vertical-align: inherit;"> really</font></font><i><font style="vertical-align: inherit;"></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">solve many problems at once. Suppose ... now come up with. Suppose a certain corporation has major accounting problems. These problems are connected with the fact that all accounting uses floating point numbers; and it would be still half the problem, but three different implementations are used (approximately in one third of the corporation each), so it turns out that God knows all. Someone, for example, takes 1.0, adds 0.0001 a thousand times, then subtracts 0.1 and gets 0.999999999999989. Then he travels to another floor, repeats the calculations on their computers and gets 1.000000000000004. And everyone thinks that this is necessary. And the error, suppose, is really HUGE, all three implementations are the fruit of an unnatural union of cave paintings and Roman numerals. So due to the differences between them, it is possible to get quite tangible differences in the results. Of courseeveryone picks up the sales in such a way that their quarterly reports converge. Therefore, it is considered a good result if the budget of the department does not contradict at least to itself, and the department of cognitive priming is likely to go bankrupt 20 years ago. And then I come out, all in white, and say: ‚ÄúGood afternoon. And what if instead of your three implementations, you will use this cool thing, which cannot be manipulated in a similar way and which will solve half of your problems. ‚Äùwhich cannot be manipulated in a similar way and which will solve half of your problems. ‚Äùwhich cannot be manipulated in a similar way and which will solve half of your problems. ‚Äù</font></font><br> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">( </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bayesian</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , in the voice of the </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Scientist</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> )</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : "I am suspicious of such universal solutions," the chief accountant replies to me. ‚ÄúDo not consider it an insult, but you, my friend, are an idealist. In my experience, different entries of floating-point numbers are well suited for different operations, so you shouldn‚Äôt immediately throw out all the tools except one. ‚Äù </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bayesian:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> To which I answer him:‚Äú Maybe it sounds too bold, but I'm going to demonstrate you are </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">perfect</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">a representation of fractions in which the results do not depend on the order in which you add numbers or on whose computer the calculations take place. Maybe in 1920, when your system was just being created, it required too much memory. But now is not the year 1920, you can afford not to save computing resources. Especially since you have there how many, 30 million bank accounts? This is really nonsense. Yes, my presentation has its flaws. For example, square roots are taken much more difficult. But how often, honestly, do you need to take the square root of someone's salary? For most real-world tasks, this system is not inferior to yours, and besides, it cannot be fooled without faking input values. ‚ÄùThen I explain to them,how to represent an integer of arbitrary length in memory and how to represent a rational number as a ratio of two integers. That is what we would now call a self-evident way of representing</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">real</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> rational numbers in computer memory. The only and unique system of theorems about rational numbers, for which floating-point numbers are just an approximation. And if you handle an unfortunate 30 million bills; if </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">in practice</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> your approximations at the same time do not converge with each other or with yourself; if they also allow everyone to steal your money; if, finally, the yard is not 1920 and you can afford normal computers, then the need to transfer accounting to </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">real</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> rational numbers is pretty obvious. Similarly, Bayes' rule and its corollaries are the </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">only</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> system of theorems about probabilities based on axioms and rigorously proved. And so p-hacking does not work in it.</font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Scientist:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> This is ... bold. Even if everything you say is true, practical difficulties remain. The statistics that we use now has been forming for more than a decade; she proved her worth. How did your light Bayesian path show itself in practice? </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bayesian:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> It is almost never used in the natural sciences. In machine learning, where, as it is more modest to say, it is quite easy to see that the model is incorrect - because the AI ‚Äã‚Äãbased on it does not work - so, in machine learning, I last saw the frequency approach to probability ten years ago. And I can't remember </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">a single one.</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">work in which the AI ‚Äã‚Äãwould consider the P-value of some hypothesis. If probability at all somehow appears in the study, then it is almost certainly Bayesian. If something is classified by unitary codes, then the cross entropy is minimized, but not ... I do not even know </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">what</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> could be the analogue of P-values ‚Äã‚Äãin AI. I would venture to suggest that this is what it is. The statistics in machine learning either works, or does not, and this is immediately obvious: the AI ‚Äã‚Äãeither does what it should or tupit. And in the natural sciences, all are primarily needed publications. Since it so happened that it is customary to specify P-values ‚Äã‚Äãin the articles, and for non-reproducible results we don‚Äôt punish - we have what we have. </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Scientist:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">So you are a mathematician or programmer rather than a natural scientist? For some reason, this does not surprise me. I have no doubt that a more successful statistical apparatus may exist, but the experience of using P-values ‚Äã‚Äãis also worth something. Yes, now they are often twisted in one way or another, but we know how to do it, and begin to understand how to deal with it. The pitfalls of the P-values ‚Äã‚Äãare at least known. In any new system they will be too. But that's exactly where - it turns out only in decades. Perhaps they will be even more dangerous than the current. </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bayesian:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Yes, thieving accountants will probably come up with some new exciting manipulations with rational numbers. Especially in those cases where the exact operations still turn out to be too computationally expensive and will have to be approximated somehow. But I still believe that if the same experimental psychology right now breaks the crisis of reproducibility, and if this crisis is clearly associated with the use of P-values, which, frankly, are nothing more than a bunch of conflicting crutches - then you should at least </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">try to</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> use more rational method. Although I also do not call for all to demolish and rebuild again. In practice, you can start to abandon the P-values ‚Äã‚Äãin any one area (at least in psychology) and see what happens. </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Scientist:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">And how are you going to persuade psychologists to such an experiment? </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bayesian:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> I have no idea. Frankly, I do not really expect anyone to change anything. Most likely, people will simply use the P-values ‚Äã‚Äãuntil the end of the centuries.</font></font> So it goes.<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">But there is a </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">chance</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> that the idea will still be popular. I was pleasantly surprised by how quickly Open Access took root. I was pleasantly surprised by the fact that the crisis of reproducibility was generally noticed, and moreover, people care about it. It is possible that the P-values ‚Äã‚Äãwill still be pulled out onto the market square and upturned with a large crowd ( </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">comment lane: at least one psychological journal </font></font><a href="https://www.tandfonline.com/doi/full/10.1080/01973533.2015.1012991"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">in 2015 refused to test null hypotheses</font></font></a></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ). If so, I will be pleasantly surprised. In this case, it turns out that my work on popularizing </font></font><a href="https://arbital.com/p/bayes_rule/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bayesian rules</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> and </font></font><a href="https://arbital.com/p/bayes_rule_guide/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">plausibility</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> was not in vain. </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Scientist:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> It may also turn out that nobody </font><i><font style="vertical-align: inherit;">likes</font></i><font style="vertical-align: inherit;"> plausibility in experimental science.</font></font><i><font style="vertical-align: inherit;"></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, and P-values ‚Äã‚Äãare all considered convenient and useful. </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bayesian:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> If the university course of statistics was so monstrous that when one thinks about the theory of probability, they are shaky, then yes, the changes will have to come from the outside. I personally hope that our dear Student will read a </font></font><a href="https://arbital.com/p/bayes_rule_guide/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">short and rather fascinating introduction to Bayesian probability theory</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , compare it with his awesome textbook on statistics and be begging you for the next six months, ‚ÄúWell, please, can I just calculate the likelihood and everything, please, well, allow ". </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Student:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Uh ... well, I read him first, okay? </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bayesian:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dear Student, think about your choice. </font><font style="vertical-align: inherit;">Some changes in science occur only because students grow in an environment of different ideas and choose the right ones. </font><font style="vertical-align: inherit;">This is Max Planck‚Äôs famous aphorism, and Max Planck will not say nonsense. </font><font style="vertical-align: inherit;">Ergo, the ability of science to distinguish bad ideas from good ones depends solely on the students' intelligence. </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Scientist:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Well, this is already ... </font></font><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Moderator:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> And this is where we complete our transmission.</font></font> Thanks for attention! </div><p>Source: <a href="https://habr.com/ru/post/430190/">https://habr.com/ru/post/430190/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../430178/index.html">Chinese artificial sun ...</a></li>
<li><a href="../430180/index.html">Conversations with the "Higher Mind". Contact with a different mind</a></li>
<li><a href="../430182/index.html">CodeOne 2018, like JavaOne, but only in mask</a></li>
<li><a href="../430186/index.html">Lazy computing in everyday life</a></li>
<li><a href="../430188/index.html">HTTP / 2 configuration using the example of Apache 2.4, PHP 7 and Ubuntu 18.04 LTS</a></li>
<li><a href="../430194/index.html">Hyde: creating serverless applications</a></li>
<li><a href="../430196/index.html">Go lintpack: composable linters manager</a></li>
<li><a href="../430198/index.html">From the Geiger counter, matches and arduins. Part One - Theory</a></li>
<li><a href="../430200/index.html">Nvidia stock price fell amid a collapse of the cryptocurrency market and declining interest in mining</a></li>
<li><a href="../430202/index.html">Writing a system of pairwise interacting particles in C ++ using DirectX 11</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>