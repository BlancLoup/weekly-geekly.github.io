<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Water rendering in screen space</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="My last task in technical graphics / rendering was finding a good solution for rendering water. In particular, the rendering of thin and fast moving w...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Water rendering in screen space</h1><div class="post__text post__text-html js-mediator-article"><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/216/ca8/1f5/216ca81f5eb506eab2dbcfc730a904b4.png" alt="image"></div><br>  My last task in technical graphics / rendering was finding a good solution for rendering water.  In particular, the rendering of thin and fast moving water jets on the basis of particles.  Last week I thought of good results, so I will write an article about it. <br><br>  I don‚Äôt really like the approach of voxelized / marching cubes when rendering water (see, for example, rendering a fluid simulation in Blender).  When the volume of water is on the same scale as the grid used for rendering, the movement is noticeably discrete.  This problem can be solved by increasing the grid resolution, but for thin jets over relatively long distances in real time, this is simply impractical, because it greatly affects the execution time and the memory taken.  (There is a precedent for using sparse voxel structures that improves the situation. But I'm not sure how well this works for dynamic systems. In addition, this is not the level of complexity I would like to work with.) <br><br>  The first alternative I explored was meshes from M√ºller's Screen Space Meshes.  They use rendering of water particles to the depth buffer, smoothing it, recognizing connected fragments of similar depth, and building a mesh from the result using marching squares.  Today, this method has probably already become <i>more</i> applicable than in 2007 (since now we can create a mesh in the compute shader), but it is still associated with a greater level of complexity and cost than I would like. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      In the end, I found Simon Green's presentation with GDC 2010 ‚ÄúScreen Space Fluid Rendering For Games‚Äù.  It starts in the same way as Screen Space Meshes: from particle rendering to the depth buffer and its smoothing.  But instead of building the mesh, the resulting buffer is used for shading and compositing the fluid in the main scene (by explicitly recording the depth.) I decided to implement just such a system. <br><a name="habracut"></a><br><h3>  Training </h3><br>  Several previous projects in Unity have taught me not to deal with the limitations of rendering the engine.  Therefore, the fluid buffers are rendered by a second camera with a smaller depth of field, so that it is rendered in front of the main scene.  Each fluid system exists on a separate rendering layer;  the main chamber excludes a layer of water, and the second chamber renders only water.  Both cameras are child elements of an empty object to ensure their mutual orientation. <br><br>  This scheme means that I can render almost anything in the fluid layer, and it will look like I expect it.  In the context of my demo scene, this means that several streams and splashes from subemitters can merge together.  In addition, this will allow other water systems to be mixed in, for example, volumes based on height fields, which can then be rendered equally.  (I haven't tested it yet.) <br><br>  The source of water in my scene is a standard particle system.  In fact, no fluid simulation is performed.  This in turn means that the particles overlap each other in a not entirely physical way, but the end result looks acceptable in practice. <br><br><h3>  Fluid buffer rendering </h3><br>  The first step in this technique is the rendering of the base fluid buffer.  This is an off-screen buffer that contains (at the current stage of my implementation) the following: the width of the fluid, the motion vector in the screen space, and the noise value.  In addition, we render the depth buffer by explicitly writing the depth from the fragment shader to turn each quadrangle of the particle into a spherical (well, actually elliptical) ‚Äúball‚Äù. <br><br>  The depth and width calculations are fairly simple: <br><br><pre><code class="cpp hljs">frag_out o; float3 N; N.xy = i.uv*<span class="hljs-number"><span class="hljs-number">2.0</span></span> - <span class="hljs-number"><span class="hljs-number">1.0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">float</span></span> r2 = dot(N.xy, N.xy); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (r2 &gt; <span class="hljs-number"><span class="hljs-number">1.0</span></span>) discard; Nz = <span class="hljs-built_in"><span class="hljs-built_in">sqrt</span></span>(<span class="hljs-number"><span class="hljs-number">1.0</span></span> - r2); float4 pixel_pos = float4(i.view_pos + N * i.size, <span class="hljs-number"><span class="hljs-number">1.0</span></span>); float4 clip_pos = mul(UNITY_MATRIX_P, pixel_pos); <span class="hljs-keyword"><span class="hljs-keyword">float</span></span> depth = clip_pos.z / clip_pos.w; o.depth = depth; <span class="hljs-keyword"><span class="hljs-keyword">float</span></span> thick = Nz * i.size * <span class="hljs-number"><span class="hljs-number">2</span></span>;</code> </pre> <br>  (Of course, depth calculations can be simplified; we need only z and w from the clip position.) <br><br>  A little later we will return to the fragment shader for the sake of motion vectors and noise. <br><br>  The fun starts in the vertex shader, and it is here that I deviate from the Green technique.  The goal of this project is to render high-speed water jets;  it can be realized with the help of spherical particles, but to create a continuous jet will require a huge number of them.  Instead, I will stretch the quadrangles of the particles based on their speed, which in turn stretches the depth balls, making them not spherical, but elliptical.  (Because depth calculations are based on UVs that do not change, it all just works.) <br><br>  Experienced Unity users may wonder why I simply do not use the built-in Stretched Billboard mode found in the Unity particle system.  Stretched Billboard performs unconditional stretching along the velocity vector in the space of the world.  In the general case, this is quite suitable, but it leads to a very noticeable problem when the velocity vector is co-directed with the forward vector of the camera (or very close to it).  Billboard stretches the screen, which makes its two-dimensional nature very noticeable. <br><br>  Instead, I use a camera-directed billboard and project the velocity vector onto the plane of the particle, using it to stretch the quad.  If the velocity vector is perpendicular to the plane (sent to or away from the screen), then the particle remains unstretched and spherical, as it should, and when it is tilted, the particle stretches in that direction, which is what we need. <br><br>  Leave a long explanation, here is a fairly simple function: <br><br><pre> <code class="cpp hljs"><span class="hljs-function"><span class="hljs-function">float3 </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">ComputeStretchedVertex</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(float3 p_world, float3 c_world, float3 vdir_world, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> stretch_amount)</span></span></span><span class="hljs-function"> </span></span>{ float3 center_offset = p_world - c_world; float3 stretch_offset = dot(center_offset, vdir_world) * vdir_world; <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> p_world + stretch_offset * lerp(<span class="hljs-number"><span class="hljs-number">0.25f</span></span>, <span class="hljs-number"><span class="hljs-number">3.0f</span></span>, stretch_amount); }</code> </pre> <br>  To calculate the motion vector of the screen space, we calculate two sets of vector positions: <br><br><pre> <code class="cpp hljs">float3 vp1 = ComputeStretchedVertex( vertex_wp, center_wp, velocity_dir_w, rand); float3 vp0 = ComputeStretchedVertex( vertex_wp - velocity_w * unity_DeltaTime.x, center_wp - velocity_w * unity_DeltaTime.x, velocity_dir_w, rand); o.motion_0 = mul(_LastVP, float4(vp0, <span class="hljs-number"><span class="hljs-number">1.0</span></span>)); o.motion_1 = mul(_CurrVP, float4(vp1, <span class="hljs-number"><span class="hljs-number">1.0</span></span>));</code> </pre> <br>  Notice that since we compute the motion vectors in the main pass and not in the speed vectors pass, Unity does not provide us with a previous or undistorted current projection from view.  To fix this, I added a simple script to the corresponding particle systems: <br><br><pre> <code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-keyword"><span class="hljs-keyword">class</span></span> <span class="hljs-title"><span class="hljs-title">ScreenspaceLiquidRenderer</span></span> : <span class="hljs-title"><span class="hljs-title">MonoBehaviour</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> Camera LiquidCamera; <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> ParticleSystemRenderer m_ParticleRenderer; <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> <span class="hljs-keyword"><span class="hljs-keyword">bool</span></span> m_First; <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> Matrix4x4 m_PreviousVP; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">Start</span></span></span><span class="hljs-function">(</span><span class="hljs-params"></span><span class="hljs-function"><span class="hljs-params"></span>)</span></span> { m_ParticleRenderer = GetComponent(); m_First = <span class="hljs-literal"><span class="hljs-literal">true</span></span>; } <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">OnWillRenderObject</span></span></span><span class="hljs-function">(</span><span class="hljs-params"></span><span class="hljs-function"><span class="hljs-params"></span>)</span></span> { Matrix4x4 current_vp = LiquidCamera.nonJitteredProjectionMatrix * LiquidCamera.worldToCameraMatrix; <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (m_First) { m_PreviousVP = current_vp; m_First = <span class="hljs-literal"><span class="hljs-literal">false</span></span>; } m_ParticleRenderer.material.SetMatrix(<span class="hljs-string"><span class="hljs-string">"_LastVP"</span></span>, GL.GetGPUProjectionMatrix(m_PreviousVP, <span class="hljs-literal"><span class="hljs-literal">true</span></span>)); m_ParticleRenderer.material.SetMatrix(<span class="hljs-string"><span class="hljs-string">"_CurrVP"</span></span>, GL.GetGPUProjectionMatrix(current_vp, <span class="hljs-literal"><span class="hljs-literal">true</span></span>)); m_PreviousVP = current_vp; } }</code> </pre> <br>  I cache the previous matrix manually, because Camera.previousViewProjectionMatrix gives incorrect results. <br><br>  ¬Ø \ _ („ÉÑ) _ / ¬Ø <br><br>  (This method also violates rendering rendering; it may be wise to set global matrix constants in practice rather than using them for each material.) <br><br>  Let's return to the fragment shader: we use the projected positions to calculate the motion vectors of the screen space: <br><br><pre> <code class="cpp hljs">float3 hp0 = i.motion_0.xyz / i.motion_0.w; float3 hp1 = i.motion_1.xyz / i.motion_1.w; float2 vp0 = (hp0.xy + <span class="hljs-number"><span class="hljs-number">1</span></span>) / <span class="hljs-number"><span class="hljs-number">2</span></span>; float2 vp1 = (hp1.xy + <span class="hljs-number"><span class="hljs-number">1</span></span>) / <span class="hljs-number"><span class="hljs-number">2</span></span>; <span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">if</span></span></span><span class="hljs-meta"> UNITY_UV_STARTS_AT_TOP vp0.y = 1.0 - vp0.y; vp1.y = 1.0 - vp1.y; #</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">endif</span></span></span><span class="hljs-meta"> float2 vel = vp1 - vp0;</span></span></code> </pre> <br>  (Motion vector calculations are almost unchanged from <a href="https://github.com/keijiro/ParticleMotionVector/blob/master/Assets/ParticleMotionVector/Shaders/Motion.cginc" rel="nofollow">https://github.com/keijiro/ParticleMotionVector/blob/master/Assets/ParticleMotionVector/Shaders/Motion.cginc</a> ) <br><br>  Finally, the last value in the fluid buffer is noise.  I use a stable random number for each particle to select one of the four noises (packed in a single texture).  It then scales to speed and unit minus particle size (therefore, fast and small particles are noisier).  This noise value is used in the shading pass to distort the normals and add a layer of foam.  Green's work uses three-channel white noise, but in a newer work (‚ÄúScreen Space Fluid Rendering with Curvature Flow‚Äù) it is proposed to use Perlin noise.  I use Voronoi noise / cellular noise with different scales: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/743/9f4/c0b/7439f4c0beebbc16cbfa536c516b2fcf.png"></div><br><h3>  Mixing problems (and workarounds) </h3><br>  And here the first problems of my implementation appear.  To correctly calculate the thickness of the particles are mixed additively.  Since mixing affects all outputs, this means that noise and motion vectors are also mixed additively.  The additive noise suits us perfectly, but not the additive vectors, and if you leave them as they are, you get a disgusting time anti-aliasing (TAA) and motion blur.  To solve this problem, when rendering the fluid buffer, I simply multiply the motion vectors by the thickness and divide by the total thickness in the shading passage.  This gives us a weighted average motion vector for all overlapping particles;  not exactly what we need (strange artifacts are created when crossing several jets), but quite acceptable. <br><br>  The more difficult problem is depth;  for the correct rendering of the depth buffer, we need to have both depth recording and depth checking being active at the same time.  This can cause problems if the particles are not sorted (since the difference in rendering order can cause the output data of particles overlapped by others to be cut off).  Therefore, we order the Unity particle system to sort the particles by depth, and then we cross our fingers and hope.  that the systems will also be rendered in depth.  We * will * have cases of imposing systems (for example, the intersection of two jets of particles) that are processed incorrectly, which will lead to a smaller thickness.  But this does not happen very often, and does not greatly affect the appearance. <br><br>  Most likely, the correct approach would be to completely separate rendering of the depth and color buffers;  The cost for this will be rendering in two passes.  It is worth studying this issue when setting up the system. <br><br><h3>  Depth smoothing </h3><br>  Finally, the most important thing in the technique of Green.  We have rendered a bunch of spherical balls to the depth buffer, but in reality the water does not consist of ‚Äúballs‚Äù.  So now we take this approximation and blur it so that it looks more like a liquid surface. <br><br>  The naive approach is to apply the Gaussian noise to the entire depth buffer.  It creates strange results - smoothes distant points more strongly than close ones, and blurs the edges of the silhouettes.  Instead, we can change the blur radius in depth, and use a two-sided blur to save edges. <br><br>  Here there is only one problem: such changes make the blur inseparable.  Shared blur can be performed in two passes: blur horizontally and then vertically.  Unshared blur is performed in one pass.  This distinction is important because the split blur scales linearly (O (w) + O (h)), and the non-separable scale quadratically (O (w * h)).  Large-scale indivisible blur quickly becomes inapplicable in practice. <br><br>  As adults, responsible developers, we can make an obvious move: close your eyes, pretend that two-way noise * is * separable, and still implement it with separate horizontal and vertical aisles. <br><br>  Green, in his presentation, demonstrated that although this approach <i>creates</i> artifacts in the resulting result (especially during normal reconstruction), the shading phase hides them well.  When working with narrower jets of water that I create, these artifacts are even less noticeable and do not really affect the result. <br><br><h3>  Shading </h3><br>  We finally finished working with the fluid buffer.  We now turn to the second part of the effect: shading and compositing the main image. <br><br>  Here we face a variety of Unity rendering constraints.  I decided to light the water only with the light of the sun and skybox;  supporting additional sources of illumination requires either several passes (it is wasteful!) or building a search structure for lighting on the GPU side (expensive and quite difficult).  In addition, since Unity does not provide access to shadow maps, and directional lighting sources (directional lights) use screen space shadows (based on the depth buffer rendered by opaque geometry), we do not have access to information about shadows from the source of sunlight.  You can attach a command buffer to the source of sunlight to create a shadow map of screen space specifically for water, but so far I have not done so. <br><br>  The last stage of shading is controlled through a script, and uses a command buffer for sending draw calls.  This is <i>necessary</i> because the motion vector texture (used for temporary anti-aliasing (TAA) and motion blur) cannot be used for direct rendering with Graphics.SetRenderTarget ().  In the script attached to the main camera, we write the following: <br><br><pre> <code class="cs hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">Start</span></span></span><span class="hljs-function">(</span><span class="hljs-params"></span><span class="hljs-function"><span class="hljs-params"></span>)</span></span> { <span class="hljs-comment"><span class="hljs-comment">//... m_QuadMesh = new Mesh(); m_QuadMesh.subMeshCount = 1; m_QuadMesh.vertices = new Vector3[] { new Vector3(0, 0, 0.1f), new Vector3(1, 0, 0.1f), new Vector3(1, 1, 0.1f), new Vector3(0, 1, 0.1f), }; m_QuadMesh.uv = new Vector2[] { new Vector2(0, 0), new Vector2(1, 0), new Vector2(1, 1), new Vector2(0, 1), }; m_QuadMesh.triangles = new int[] { 0, 1, 2, 0, 2, 3, }; m_QuadMesh.UploadMeshData(false); m_CommandBuffer = new CommandBuffer(); m_CommandBuffer.Clear(); m_CommandBuffer.SetProjectionMatrix( GL.GetGPUProjectionMatrix( Matrix4x4.Ortho(0, 1, 0, 1, -1, 100), false)); m_CommandBuffer.SetRenderTarget( BuiltinRenderTextureType.CameraTarget, BuiltinRenderTextureType.CameraTarget); m_CommandBuffer.DrawMesh( m_QuadMesh, Matrix4x4.identity, m_Mat, 0, m_Mat.FindPass("LIQUIDCOMPOSITE")); m_CommandBuffer.SetRenderTarget( BuiltinRenderTextureType.MotionVectors, BuiltinRenderTextureType.Depth); m_CommandBuffer.DrawMesh( m_QuadMesh, Matrix4x4.identity, m_Mat, 0, m_Mat.FindPass("MOTION")); }</span></span></code> </pre> <br>  Color and motion vector buffers cannot be simultaneously rendered using MRT (multi render targets).  I could not find out the reason.  In addition, they require binding to different depth buffers.  Fortunately, we are recording depth into <i>both of</i> these depth buffers, so re-projection of temporary anti-aliasing works fine (oh, this is the pleasure of working with the black box engine). <br><br>  In each frame, we throw out the composite render from OnPostRender (): <br><br><pre> <code class="cs hljs"><span class="hljs-function"><span class="hljs-function">RenderTexture </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">GenerateRefractionTexture</span></span></span><span class="hljs-function">(</span><span class="hljs-params"></span><span class="hljs-function"><span class="hljs-params"></span>)</span></span> { RenderTexture result = RenderTexture.GetTemporary(m_MainCamera.activeTexture.descriptor); Graphics.Blit(m_MainCamera.activeTexture, result); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> result; } <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">OnPostRender</span></span></span><span class="hljs-function">(</span><span class="hljs-params"></span><span class="hljs-function"><span class="hljs-params"></span>)</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (ScreenspaceLiquidCamera &amp;&amp; ScreenspaceLiquidCamera.IsReady()) { RenderTexture refraction_texture = GenerateRefractionTexture(); m_Mat.SetTexture(<span class="hljs-string"><span class="hljs-string">"_MainTex"</span></span>, ScreenspaceLiquidCamera.GetColorBuffer()); m_Mat.SetVector(<span class="hljs-string"><span class="hljs-string">"_MainTex_TexelSize"</span></span>, ScreenspaceLiquidCamera.GetTexelSize()); m_Mat.SetTexture(<span class="hljs-string"><span class="hljs-string">"_LiquidRefractTexture"</span></span>, refraction_texture); m_Mat.SetTexture(<span class="hljs-string"><span class="hljs-string">"_MainDepth"</span></span>, ScreenspaceLiquidCamera.GetDepthBuffer()); m_Mat.SetMatrix(<span class="hljs-string"><span class="hljs-string">"_DepthViewFromClip"</span></span>, ScreenspaceLiquidCamera.GetProjection().inverse); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (SunLight) { m_Mat.SetVector(<span class="hljs-string"><span class="hljs-string">"_SunDir"</span></span>, transform.InverseTransformVector(-SunLight.transform.forward)); m_Mat.SetColor(<span class="hljs-string"><span class="hljs-string">"_SunColor"</span></span>, SunLight.color * SunLight.intensity); } <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> { m_Mat.SetVector(<span class="hljs-string"><span class="hljs-string">"_SunDir"</span></span>, transform.InverseTransformVector(<span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Vector3(<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>))); m_Mat.SetColor(<span class="hljs-string"><span class="hljs-string">"_SunColor"</span></span>, Color.white); } m_Mat.SetTexture(<span class="hljs-string"><span class="hljs-string">"_ReflectionProbe"</span></span>, ReflectionProbe.defaultTexture); m_Mat.SetVector(<span class="hljs-string"><span class="hljs-string">"_ReflectionProbe_HDR"</span></span>, ReflectionProbe.defaultTextureHDRDecodeValues); Graphics.ExecuteCommandBuffer(m_CommandBuffer); RenderTexture.ReleaseTemporary(refraction_texture); } }</code> </pre> <br>  And this is where CPU participation ends, only shaders come later. <br><br>  Let's start with the passage of motion vectors.  This is what the whole shader looks like: <br><br><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">include</span></span></span><span class="hljs-meta"> </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">"UnityCG.cginc"</span></span></span><span class="hljs-meta"> sampler2D _MainDepth; sampler2D _MainTex; struct appdata { float4 vertex : POSITION; float2 uv : TEXCOORD0; }; struct v2f { float2 uv : TEXCOORD0; float4 vertex : SV_POSITION; }; v2f vert(appdata v) { v2f o; o.vertex = mul(UNITY_MATRIX_P, v.vertex); o.uv = v.uv; return o; } struct frag_out { float4 color : SV_Target; float depth : SV_Depth; }; frag_out frag(v2f i) { frag_out o; float4 fluid = tex2D(_MainTex, i.uv); </span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">if</span></span></span><span class="hljs-meta"> (fluid.a == 0) discard; o.depth = tex2D(_MainDepth, i.uv).r; float2 vel = fluid.gb / fluid.a; o.color = float4(vel, 0, 1); return o; }</span></span></code> </pre> <br>  The speed in screen space is stored in the green and blue channel of the fluid buffer.  Since rendering the buffer we scaled the speed by thickness, we again divide the total thickness (located in the alpha channel) to get a weighted average speed. <br><br>  It is worth noting that when working with large volumes of water, another method of processing the velocity buffer may be required.  As we render without blending, motion vectors for everything <i>behind the</i> water are lost, destroying the TAA and motion blur of these objects.  When working with thin streams of water is not a problem, but can interfere when working with a pool or a lake, when we need TAA or motion blur objects to be clearly visible through the surface. <br><br>  The main pass of shading is more interesting.  Our first priority after masking with the help of the thickness of the liquid is to reconstruct the position and the normal of the viewing space (view space). <br><br><pre> <code class="cpp hljs"><span class="hljs-function"><span class="hljs-function">float3 </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">ViewPosition</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(float2 uv)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">float</span></span> clip_z = tex2D(_MainDepth, uv).r; <span class="hljs-keyword"><span class="hljs-keyword">float</span></span> clip_x = uv.x * <span class="hljs-number"><span class="hljs-number">2.0</span></span> - <span class="hljs-number"><span class="hljs-number">1.0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">float</span></span> clip_y = <span class="hljs-number"><span class="hljs-number">1.0</span></span> - uv.y * <span class="hljs-number"><span class="hljs-number">2.0</span></span>; float4 clip_p = float4(clip_x, clip_y, clip_z, <span class="hljs-number"><span class="hljs-number">1.0</span></span>); float4 view_p = mul(_DepthViewFromClip, clip_p); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> (view_p.xyz / view_p.w); } <span class="hljs-function"><span class="hljs-function">float3 </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">ReconstructNormal</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(float2 uv, float3 vp11)</span></span></span><span class="hljs-function"> </span></span>{ float3 vp12 = ViewPosition(uv + _MainTex_TexelSize.xy * float2(<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>)); float3 vp10 = ViewPosition(uv + _MainTex_TexelSize.xy * float2(<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">-1</span></span>)); float3 vp21 = ViewPosition(uv + _MainTex_TexelSize.xy * float2(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>)); float3 vp01 = ViewPosition(uv + _MainTex_TexelSize.xy * float2(<span class="hljs-number"><span class="hljs-number">-1</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>)); float3 dvpdx0 = vp11 - vp12; float3 dvpdx1 = vp10 - vp11; float3 dvpdy0 = vp11 - vp21; float3 dvpdy1 = vp01 - vp11; <span class="hljs-comment"><span class="hljs-comment">// Pick the closest float3 dvpdx = dot(dvpdx0, dvpdx0) &gt; dot(dvpdx1, dvpdx1) ? dvpdx1 : dvpdx0; float3 dvpdy = dot(dvpdy0, dvpdy0) &gt; dot(dvpdy1, dvpdy1) ? dvpdy1 : dvpdy0; return normalize(cross(dvpdy, dvpdx)); }</span></span></code> </pre> <br>  This is a costly way of reconstructing the position of the viewing space: we take a position in the clip space and perform the inverse operation of the projection. <br><br>  After we have obtained the method for reconstructing positions, with the normals everything is simpler: we calculate the position of the neighboring points in the depth buffer and build a tangent basis on them.  To work with the edges of the silhouettes, we perform sampling in both directions and select the closest point in the view space for the reconstruction of the normal.  This method works surprisingly well and causes problems only in the case of very thin objects. <br><br>  This means that we perform five separate backward projection operations (for the current point and four adjacent ones) per pixel.  There is a less expensive way, but this post is already too long, so I will leave it for later. <br><br>  The resulting normals are: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/b2c/0ed/7f6/b2c0ed7f6cfcc66473ff4e5380c46894.png"></div><br>  I distort this computed normal with the help of the derivatives of the noise value from the fluid buffer scaled by the force parameter and normalized by splitting the jet thickness (for the same reason as for the speed): <br><br><pre> <code class="cpp hljs">N.xy += NoiseDerivatives(i.uv, fluid.r) * (_NoiseStrength / fluid.a); N = normalize(N);</code> </pre> <br>  We can finally proceed to the very shading.<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Water shading consists of three main parts: specular reflection, specular refraction and foam. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Reflection is a standard GGX, entirely taken from the standard Unity shader. (With one correction, the correct F0 equal to 2% is used for water.) </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">With refraction it is more and more interesting. For correct refraction, raytracing is required (or raymarching for an approximate result). Fortunately, refraction is less intuitive to the eye than reflection, and therefore incorrect results are not so noticeable. Therefore, we shift the UV sample for the refraction texture by x and y normals, scaled by thickness and force parameter:</font></font><br><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">float</span></span> aspect = _MainTex_TexelSize.y * _MainTex_TexelSize.z; float2 refract_uv = (i.grab_pos.xy + N.xy * float2(<span class="hljs-number"><span class="hljs-number">1</span></span>, -aspect) * fluid.a * _RefractionMultiplier) / i.grab_pos.w; float4 refract_color = tex2D(_LiquidRefractTexture, refract_uv);</code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">(Note that correlation is used; it is </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">optional</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ‚Äî after all, this is just an approximation, but adding it is quite simple.) </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">This refracted light passes through the liquid, so part of it is absorbed:</font></font><br><br><pre> <code class="cpp hljs">float3 water_color = _AbsorptionColor.rgb * _AbsorptionIntensity; refract_color.rgb *= <span class="hljs-built_in"><span class="hljs-built_in">exp</span></span>(-water_color * fluid.a);</code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Notice that _AbsorptionColor is defined in exactly the opposite way expected: the values ‚Äã‚Äãof each channel indicate the amount of </font><font style="vertical-align: inherit;">light </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">absorbed</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , not transmitted. </font><font style="vertical-align: inherit;">Therefore, _AbsorptionColor with the value (1, 0, 0) does not give red, but turquoise (teal). </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Reflection and refraction are mixed using Fresnel coefficients:</font></font><br><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">float</span></span> spec_blend = lerp(<span class="hljs-number"><span class="hljs-number">0.02</span></span>, <span class="hljs-number"><span class="hljs-number">1.0</span></span>, <span class="hljs-built_in"><span class="hljs-built_in">pow</span></span>(<span class="hljs-number"><span class="hljs-number">1.0</span></span> - ldoth, <span class="hljs-number"><span class="hljs-number">5</span></span>)); float4 clear_color = lerp(refract_color, spec, spec_blend);</code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Up to this point, we played by the rules (mostly) and used physical shading. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">He is quite good, but he has a problem with water. </font><font style="vertical-align: inherit;">Its a bit hard to see:</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/ff2/4f2/ba2/ff24f2ba2dad5dc6fe7714ad3fd55124.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">To eliminate it, let's add some foam. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Foam appears when water is turbulent and air mixes with water to form bubbles. </font><font style="vertical-align: inherit;">Such bubbles create all sorts of variations of reflection and refraction, which gives all the water a sense of diffused lighting. </font><font style="vertical-align: inherit;">I will model this behavior with wrapped diffuse lighting:</font></font><br><br><pre> <code class="cpp hljs">float3 foam_color = _SunColor * saturate((dot(N, L)*<span class="hljs-number"><span class="hljs-number">0.25f</span></span> + <span class="hljs-number"><span class="hljs-number">0.25f</span></span>));</code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> It is added to the final color using a special factor, depending on the noise of the fluid and a softened Fresnel coefficient: </font></font><br><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">float</span></span> foam_blend = saturate(fluid.r * _NoiseStrength) * lerp(<span class="hljs-number"><span class="hljs-number">0.05f</span></span>, <span class="hljs-number"><span class="hljs-number">0.5f</span></span>, <span class="hljs-built_in"><span class="hljs-built_in">pow</span></span>(<span class="hljs-number"><span class="hljs-number">1.0f</span></span> - ndotv, <span class="hljs-number"><span class="hljs-number">3</span></span>)); clear_color.rgb += foam_color * saturate(foam_blend);</code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wrapped ambient lighting is normalized to conserve energy, so that it can be used as an approximation of scattering. </font><font style="vertical-align: inherit;">The mixing of the foam color is more noticeable. </font><font style="vertical-align: inherit;">It is quite a clear violation of the law of conservation of energy. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">But in general, everything looks good and makes the jet more noticeable:</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/216/ca8/1f5/216ca81f5eb506eab2dbcfc730a904b4.png"></div><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Further work and improvements </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Much can be improved in the created system. </font></font><br><br><ul><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Use multiple colors. </font><font style="vertical-align: inherit;">Currently, the absorption is calculated only at the last shading stage and uses constant color and brightness for all the liquid on the screen. </font><font style="vertical-align: inherit;">Supporting different colors is possible, but requires a second color buffer and solving the absorption integral for each particle in the rendering process of the basic fluid buffer. </font><font style="vertical-align: inherit;">This could potentially be a costly operation.</font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Full coverage. </font><font style="vertical-align: inherit;">Having access to the lighting search structure on the GPU side (either built by hand or linked to the new Unity HD rendering pipeline), we can properly light the water with an arbitrary number of light sources and create the correct ambient lighting.</font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Improved refraction. </font><font style="vertical-align: inherit;">With the help of blurred mip-textures of the background texture, we can better simulate the refraction for rough surfaces. </font><font style="vertical-align: inherit;">In practice, this is not very useful for small jets of fluid, but can be useful for large volumes.</font></font></li></ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> If I had the opportunity, I would improve this system to a loss of pulse, but at the moment it can be called complete. </font></font></div><p>Source: <a href="https://habr.com/ru/post/420495/">https://habr.com/ru/post/420495/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../420479/index.html">Deploying dependencies into the Apache Ignite.NET service</a></li>
<li><a href="../420487/index.html">Business requests the right to personal user data</a></li>
<li><a href="../420489/index.html">New ARM processors will be able to contend with the Core i5</a></li>
<li><a href="../420491/index.html">My way is a warrior, or how I prepared an application for life in Sailfish</a></li>
<li><a href="../420493/index.html">Can the American food ordering service become Amazon in the world of restaurants?</a></li>
<li><a href="../420497/index.html">Vegetable Singularity: Kroger Launches Robocouriers for Fruit and Vegetable Customers in Arizona</a></li>
<li><a href="../420499/index.html">Anatomy of recommendation systems. Part one</a></li>
<li><a href="../420501/index.html">Linux in RAM: debirf way 2018</a></li>
<li><a href="../420503/index.html">JS Developer Day, different cities and communities - one holiday</a></li>
<li><a href="../420505/index.html">Will OpenAI Five win the professional team at The International?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>