<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Neural networks: Lecture 2 (+ example in PHP).</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="The combination of neurons connected in one way or another is called an artificial neural network or simply a neural network. 
 The law by which neuro...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Neural networks: Lecture 2 (+ example in PHP).</h1><div class="post__text post__text-html js-mediator-article">  The combination of neurons connected in one way or another is called an artificial neural network or simply a neural network. <br>  The law by which neurons are connected to a network is called the structure or network topology. <br><br>  Many neurons are not connected to each other, but connected to other neurons is called the neuron layer. <br>  Networks are of 2 types: single-layer, multi-layered. <br><br><h4>  Simple perceptron </h4><br>  A simple perceptron consists of a 1st neuron (one layer) with n inputs and a threshold activation function. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Because the network outputs are +1 or -1.  That perceptron is effective for solving the problem of classifying 2 classes. <br><a name="habracut"></a><br><br>  If the output is +1, then the input vector belongs to the I-class, otherwise - to the II class. <br><br>  First, at the 0-step of training, the weights of the input of the perceptron are set randomly. <br>  The essence of learning is to change the weights. <br><br>  To implement the training procedure for any neural network, including for a simple perceptron, a training sample consisting of vectors, which are called training vectors, is formed <u>before the beginning</u> , and each training vector consists of 2 parts: <br><ol><li>  Those values ‚Äã‚Äãthat are fed to the input </li><li>  What should be from our point of view at the output of the network when components from 1st part are fed to the network input </li></ol><br>  General view of the training vector: (x1, x2, ..., Xn, {+1, -1}). <br><br>  Generally speaking, the second part can be empty, in which case it is said that learning takes place without a teacher. <br>  If there is - with a teacher. <br><br>  The training sample vectors are fed to the input of the network and, according to the applied vectors, the weights Wi, i = 1, n, vary during the training procedure. <br><br>  For a simple perceptron, the procedure is as follows. <br><ol><li>  We input the components of the 1st part of the training sample vector Xp = (X <sub>1</sub> <sup>p</sup> , ..., X <sub>n</sub> <sup>p</sup> ), p = 1, P.  P is the index of the vector of the training sample.  At this stage, the output is y = (X <sub>p</sub> ). </li><li>  Compare the network output with the desired value. <br>  y (xp)?  d (xp), <br>  <i>- d (xp) - the desired value</i> <br>  <i>- y (xp) - network value</i> <br>  If y (xp) == d (xp) (as necessary), then p = p + 1, go to step 1. <br>  Otherwise, step 3. <br></li><li>  New i-weight value: Wi (t) = Wi (t-1) + d (Xp) * Xi. <br>  p = p + 1, step 1 </li></ol><br><br>  Generally speaking, the procedure is complete if all vectors have passed. <br>  2 cases are possible: <br>  - training sample is not enough for network training <br>  - training was completed much earlier than the end of the sample. <br><br>  <b>The convergence theorem (Novikov)</b> : <br>  If there is a set of weights W * capable of dividing class 2 using a simple perceptron, then the proposed algorithm converges to some solution that does not necessarily coincide with W *, and it converges in a finite number of steps. <br><br>  <b>Proof</b> . <br>  Due to the use of the sign function in the definition of a neuron, we can assume that || W * || = 1. <br>  We introduce the cosine of the angle between the current value of the set of weights and W *. <br><br>  cos angle = (W, W *) / || W ||. <br><br>  (1) (W (t + 1), W *) = (W (t), W *) + d (X) * (X, W *). <br>  Since W * is an exact solution, then | (W *, X) |&gt; = delta&gt; 0. <br><br>  As soon as the learning procedure takes place, the current set of vectors W (t) incorrectly classifies the current vector X, which means d (x) * (x, W *) = | (X, W *) |, and therefore we have ( 1)&gt; = (W (t), W *) + delta. <br><br>  ||  W (t + 1) ||  ** 2 = || W (t) || ** 2 + || X || ** 2 + 2d (X) * (x, w (t)). <br><br>  By virtue of the same logic, if learning occurs, then the signs are d (x) * (X, W (T)) &lt;0 &lt;W <sup>2</sup> + M <sup>2</sup> . <br><br>  Where M is the radius of the n-dimensional ball, inside which all vectors of the training sample are located. <br>  Their final number, hence such a ball exists. <br><br>  After t-steps, we have an inequality. <br>  (1)&gt; (W (0), W *) + tdelta. <br><br>  || W (t + 1) ||  &lt;((W <sup>2</sup> (0) + tM <sup>2</sup> )) <sup>1/2</sup> <br><br>  Hence the angle cos is&gt; + inf. <br><br>  The resulting contradiction proves that there is some t <sub>max</sub> after which the weights do not change, which means the convergence of the learning algorithm in a finite number of steps. <br><br>  Proven. <br><br>  <u>Remarks 1</u> : If we set W (0) = 0, then from the cosine equality t <sub>max</sub> = M <sup>2</sup> / Delta. <br>  Obviously, t <sub>max</sub> here the greater the variation of the sample vectors and the greater, the smaller the distance between the classes. <br><br>  <u>Remark 2</u> : Essential when forming the existence of W *. <br>  If classes are inseparable, then a simple perceptron is not enough to solve the problem. <br><img src="http://pic.ipicture.ru/uploads/080923/AbapXWarfm.png"><br><br>  A classic example of a task that a simple perceptron cannot solve is XOR. <br><br>  <b>UPD</b> Example implementing a simple perceptron. <br>  Written on PHP5. <br>  In the example, the weights grid is already given. <br>  A perceptron responds that they gave at the entrance, square or straight ... <br><br>  In order not to litter with example, he made a separate <a href="http://rapidshare.com/files/147798237/percept.rar.html">archive</a> . <br>  Or look <a href="http://anton.in.ua/blog/%3Fp%3D16">here</a> . <br></div><p>Source: <a href="https://habr.com/ru/post/40659/">https://habr.com/ru/post/40659/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../40652/index.html">Leica S2 with a matrix of 30 * 45 mm</a></li>
<li><a href="../406547/index.html">Overview of boards on SoC ARM + FPGA. Part one. Xilinx World</a></li>
<li><a href="../40656/index.html">Future network</a></li>
<li><a href="../40657/index.html">Chrome Attic - a look at the source code</a></li>
<li><a href="../40658/index.html">ITunes AppStore navigation</a></li>
<li><a href="../40660/index.html">Application Architecture - Hot Spots</a></li>
<li><a href="../40663/index.html">about freelance tv</a></li>
<li><a href="../40664/index.html">Interestingly, what kind of music do Habralyuds listen to?</a></li>
<li><a href="../40666/index.html">Google Books Search now on any site.</a></li>
<li><a href="../40667/index.html">Universal bacteria-manufacturers</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>