<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Neural Matching: how to adapt content for Google</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="The search engines are not very logic, it is a fact. But they are trying. And SEO-specialists are trying to answer - trying to achieve the utmost rele...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Neural Matching: how to adapt content for Google</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/webt/lk/ma/zj/lkmazjjzfmqxe_oudbr040wnxaa.png"><br><br><p>  The search engines are not very logic, it is a fact.  But they are trying.  And SEO-specialists are trying to answer - trying to achieve the utmost relevance of the pages, based on the guesses and experiments. </p><br><p>  Recently, Google has pleased the new ranking factor - Neural Matching.  We read that experts are writing about it, and collected some techniques that will help write more relevant texts for requests. </p><br><p>  And by the way, NM is not LSI for you, everything is a bit more complicated. </p><a name="habracut"></a><br><p>  In September 2018, Danny Sullivan <a href="https://twitter.com/dannysullivan/status/1044276380098158593">tweeted</a> that in the past few months, Google has been using the AI-method of neural matching (Neural Matching) to better link words with concepts.  This algorithm influenced the results of issuing 30% of requests worldwide. </p><br><img src="https://habrastorage.org/webt/yy/-v/rm/yy-vrmtdddxadr5lr2ga9ve_bpc.png"><br><br><p>  We were in no hurry to write about the new algorithm, waited for an explanation from Google and research in this area.  But things are still there - mostly commentators show the same screenshots and tell about the transition from search by words to search by intent.  And also refer to the <a href="https://arxiv.org/pdf/1711.08611.pdf">Deep Relevance Matching Model (DRMM)</a> . </p><br><p>  Let's try to figure out what kind of animal this Neural Matching is and how to adapt the content on the site for it. </p><br><h2>  Neural Matching Work Examples </h2><br><p>  Danny Sullivan outlined what Neural Matching is.  He gave an example of the issue for the query ‚Äúwhy does my TV look strange‚Äù.  The user enters such a request when he does not yet know what a soap opera effect is.  But Google, thanks to a new algorithm, knows exactly what is needed: </p><br><img src="https://habrastorage.org/webt/29/e8/db/29e8db4mufa5fo6__hfkgx5cqwi.jpeg">
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <p>  In Russian, a similar story: </p><br><img src="https://habrastorage.org/webt/gh/2p/io/gh2pioe4hfrdgbhvtnqf9x0cfim.jpeg"><br><br><p>  Another example.  You met in the apartment "beautiful" insect and have no idea what his name is: </p><br><img src="https://habrastorage.org/webt/vw/pb/uy/vwpbuy5onwfkytpq1pc0zgl366i.jpeg"><br><br><p>  We go to Google, enter a set of signs and in the first position we get the relevant answer: </p><br><img src="https://habrastorage.org/webt/e6/cs/k5/e6csk5pof2yvfsuy1e8fx8jrwcc.jpeg"><br><br><p>  The introduction of Neural Matching is due to the fact that users do not always know what they are looking for and do not always correctly formulate requests.  Danny Sullivan showed several such "wrong" requests: </p><br><img src="https://habrastorage.org/webt/mr/yu/-e/mryu-exwhyt5ms9hk8fae5elxei.jpeg"><br><br><p>  The goal of Neural Matching is to determine the true search <a href="https://promopult.ru/library/%25D0%2598%25D0%25BD%25D1%2582%25D0%25B5%25D0%25BD%25D1%2582">content</a> (intent) and produce the correct results. </p><br><img src="https://habrastorage.org/webt/xl/dg/ks/xldgks3lrvdsq__mpesljf8kuze.jpeg"><br><br><p>  To determine the intent, not separate words are used, but entities and connections between them.  See how it works - using the example of ‚Äúgetting drunk what to do‚Äù and ‚Äúgetting drunk at night‚Äù requests. </p><br><p>  Each request contains the same entity - ‚Äúgot drunk‚Äù.  But combining it with an entity ‚Äúfor the night‚Äù signals the search engine that the user means overeating.  And the intoxication is most likely connected with the essence of ‚Äúwhat to do‚Äù. </p><br><img src="https://habrastorage.org/webt/5n/oh/dd/5nohddwwhblfa7jv31wsjd4qemk.jpeg"><br><br><p>  How does Google define intent - are semantics similar?  The search engine compares how often the entities combined in the request are found side by side on the pages.  In addition, statistics on requests are taken into account (users, when entering a request to get drunk at night, more often click on articles about overeating). </p><br><p>  <strong>Another example.</strong>  The user enters the phrase "put the window."  This is just the ‚Äúwrong‚Äù request that Danny Sullivan is talking about.  Google understands that a man by ‚Äúput‚Äù implies something different than a simple installation of windows, and displays in the TOP the correct results from his point of view: </p><br><img src="https://habrastorage.org/webt/ph/ss/tg/phsstgnyk01bjxf-mud-ojw0xm4.jpeg"><br><br><p>  At the same time, only one page from TOP-6 contains the word ‚Äúdeliver‚Äù (meaning ‚Äúsupplier of windows‚Äù, and not ‚Äúinstall windows by myself‚Äù).  On the remaining pages of the TOP-6, there is not a single word ‚Äúto deliver,‚Äù or even single-root words.  Although below are mixed up the results like "How to put the windows yourself", etc. </p><br><p>  This leads to a paradoxical at first glance conclusion: in order to occupy high positions in many words, it is not necessary to saturate texts with semantics similar to a search query.  Content relevance is assessed by a set of entities (marker phrases) that are likely to satisfy the search content. </p><br><p>  <strong>This changes the approach to writing SEO texts: before, the key point was the keys, now the needs of the audience.</strong> </p><br><h2>  Document Relevance Ranking and Neural Matching - how will this affect SEO? </h2><br><p>  Roger Montti in the article for the Search Engine Journal <a href="https://www.searchenginejournal.com/google-neural-matching/271125/">suggested</a> that the Neural Matching algorithm could work based on the Document Relevance Ranking (DRR) method.  The method is described in the article ‚Äú <a href="https://ai.google/research/pubs/pub47324%3Futm_source%3DSearchengines.ru%26utm_campaign%3D41d7961c0d-EMAIL_CAMPAIGN_2018_10_12_10_00%26utm_medium%3Demail%26utm_term%3D0_f320dfafbf-41d7961c0d-92315617%26mc_cid%3D41d7961c0d%26mc_eid%3D65b3abcd6c">Deep Relevance Ranking using Enhanced Document-Query Interactions,</a> ‚Äù published on the Google AI website. </p><br><p>  The essence of the DRR method is that when determining the relevance of a document, its text is used exclusively.  Other factors ‚Äî links, anchors, mentions, on-page SEO ‚Äî don't matter. </p><br><p>  Are these links no longer needed at all?  Not certainly in that way.  Ranking by the described DRR method is part of the overall ranking algorithm.  At the first stage, the issue is formed taking into account all the ranking factors (links, keys, ‚Äúmobility‚Äù, geolocation, etc.).  So the search engine eliminates low-grade content and identifies reputable sites.  At the second stage, DRR enters the work - among the best results, it selects the most relevant (but takes into account only the text). </p><br><p>  In practice, it may look like this.  There are two sites: very reputable and young.  The young site contains super-content, which has no analogues in the niche, saturated with details and specifics.  But since the authoritative site leads more links, its page takes the first position, and the page of the young site - the tenth.  And here comes the DRR - the search engine scans the texts and understands that the content of the young site is more meaningful than that of the authoritative.  The consequence is the relocation of a young site to a higher position. </p><br><h2>  How to make content under Neural Matching </h2><br><p>  Whether Neural Matching works on the basis of DRR or not is not so important.  It is important that the search intent here "steers".  Not long "footcloths", not keyword density, not synonymizing. </p><br><img src="https://habrastorage.org/webt/dt/ii/wn/dtiiwnnqwbx9vjsxwepwf7mqu8g.jpeg"><br><br><p>  Before you create content, decide: </p><br><ul><li>  for whom he is (it is best to conduct research, create portraits of users and write for them); </li><li>  why is it needed (which task closes); </li><li>  what is in it what competitors do not have (what value it contributes). </li></ul><br><p>  To increase the relevance of texts, in addition to basic queries, use closely related entities.  If the text is written by an expert, then such entities will most certainly be in the text.  Another thing is when a copywriter‚Äôs TK is put in - in this case it is necessary to define entities and indicate them in the task. </p><br><p>  Consider ways to collect entities on the example of the category of the online store "Gasoline Generators". </p><br><h3>  1. Search for questions / answers </h3><br><p>  To identify user needs, you can use forums, comments on articles in blogs, discussions in social networks.  It all works.  But it's easier to go to the <a href="https://otvet.mail.ru/">Answers@Mail.ru</a> (or Western analogue - <a href="https://www.quora.com/">Quora</a> ), enter a query in the search, go through the questions and highlight the entities associated with the main keys. </p><br><p>  On request, "petrol generators" mail.ru issues 1624 questions.  Go through the list and select the entities that characterize the needs of the target audience. </p><br><img src="https://habrastorage.org/webt/bb/rp/gx/bbrpgxdk8i4hlbdoqywhvthybns.jpeg"><br><br><img src="https://habrastorage.org/webt/_u/qz/x-/_uqzx-_imraetz4jcbwgdzd1t7i.jpeg"><br><br><p>  After the selection of entities, we think which content is suitable for them.  For example, gasoline consumption for 1 hour and how to use the generator (for welding, for the boiler, for lighting, etc.) should be indicated in the description of specific products.  In the description of the ‚ÄúGasoline Generators‚Äù heading you can briefly describe how gasoline differ from gas, inverter, etc. And problems with the work of generators are described in the article for the blog. </p><br><p>  Handling questions in QA services is painstaking, but it allows you to highlight the real needs of the audience, which you could not guess. </p><br><p>  You can try to simplify the work using the <a href="https://answerthepublic.com/">Answer The Public service</a> .  He collects questions, comparisons and various formulations that are found on the network with the entry of a given phrase. </p><br><img src="https://habrastorage.org/webt/9o/ab/7y/9oab7ytgb171vqysbqcfdz5lako.jpeg"><br><br><p>  The only drawback is the English language service.  Translation of the search phrase partially solves the problem.  But in the commercial segment it is worth remembering about the peculiarities of the markets (what Russians care about may be useless to Russians). </p><br><h3>  2. Parsing association phrases </h3><br><p>  Under the search results, the block ‚ÄúTogether with ... often looking for‚Äù is displayed - here are collected the phrases that the search engine himself associates with the original phrase (‚Äúgasoline generators‚Äù). </p><br><img src="https://habrastorage.org/webt/x7/7j/ec/x77jec90jb_u-uekbe3woungduw.jpeg"><br><br><p>  The analysis of phrases-associations allows to identify related entities: 5 kW, 3 kW, 10 kW, inverter, 1 kW. </p><br><p>  It remains to consider how to include them in the content.  For example, in the description of the ‚Äúgasoline generators‚Äù heading, it is worth mentioning for what purposes generators of different power (1, 3, 5, 10 kW) and type (inverter, conventional, etc.) are suitable. </p><br><p>  If you have a lot of initial requests, manually build associations for a long time - use a <a href="https://promopult.ru/tools/association_phrases.html%3Futm_medium%3Dpaid_article%26utm_source%3Dhabr%26utm_campaign%3Dblog%26utm_term%3D1444b12f5f9c18d6%26utm_content%3Dassociation_phrases">parser</a> . </p><br><h3>  3. Parsing search hints </h3><br><p>  Hints are another source for matching related entities. </p><br><img src="https://habrastorage.org/webt/oj/h4/nw/ojh4nwxgw_kkzlt3reyjy1xcyxq.jpeg"><br><br><p>  We fill up the list of entities collected from associations: auto-start, diesel, 380 volts, silent.  These are words that characterize user problems well. </p><br><p>  There is also a <a href="https://promopult.ru/tools/search_suggestions.html%3Futm_medium%3Dpaid_article%26utm_source%3Dhabr%26utm_campaign%3Dblog%26utm_term%3D1444b12f5f9c18d6%26utm_content%3Dsearch_suggestions">parser</a> for collecting hints. </p><br><p>  In principle, the considered methods are enough to get an idea of ‚Äã‚Äãthe needs of the audience.  But if you want to work out the semantics even more deeply, here are two optional ways. </p><br><h3>  4. Selection of quasi-synonyms </h3><br><p>  Quasi-synonyms (semantic associates) call words that are similar in meaning but not interchangeable in different contexts.  For example, the words ‚Äúgenerator‚Äù and ‚Äúautogenerator‚Äù are synonymous in the text on automotive parts, but in the text on types of generators, they will not be. </p><br><p> Quasi-synonyms are determined on the basis of the frequency of their occurrence in the texts.  To solve this problem there is a service <a href="http://rusvectores.org/ru/associates/">RusVect≈çrƒìs</a> (section "Related words").  Enter the word of interest, select all available models and parts of speech and start the search. </p><br><img src="https://habrastorage.org/webt/b_/ai/7o/b_ai7ocf_ou2w4bdnb9udf5ryr4.png"><br><br><p>  As a result, you will receive 10 of the most significant associates for each search model.  It is not necessary to blindly use them when forming TK - there will be a lot of ‚Äúgarbage‚Äù (parsing associations based on search engine data is still preferable).  Nevertheless, you can reveal interesting words.  For example, we see that the words "gas generator", "inverter", "gas generator", "contactor", etc. are associated with the word "generator". </p><br><h3>  5. Parsing the texts of competitors </h3><br><p>  To identify the needs of the audience, this method is not the best.  Firstly, it is not known when the content was created on competitors' sites (during this time, search preferences could shift).  Secondly, there is no guarantee that competitors thoroughly analyzed the problems of the audience and created texts based on them. </p><br><p>  On the other hand, if you use this method as an auxiliary method, then there is a chance to identify entities that you might have missed. </p><br><p>  So, we enter in the search for the main query ‚Äúgasoline generators‚Äù, copy the relevant texts from the sites in the TOP-10 and <a href="https://advego.com/text/seo/">select the</a> semantics with the help of <a href="https://advego.com/text/seo/">Advego</a> : </p><br><img src="https://habrastorage.org/webt/cg/lq/wi/cglqwipgfx17du32ihhr0zb7j_y.jpeg"><br><br><p>  We supplement the list of relevant entities: 4-stroke, emergency, autonomous, uninterrupted, for summer cottage, for nature, etc. </p><br><p>  Putting it all together and get the TZ, optimized for Neural Matching. </p><br><h2>  Terms of Reference: make Neural Matching, not LSI </h2><br><p>  After the relevant entities are collected, you must write the text.  But it is not enough just to indicate the keys and the list of synonyms and related words in the TOR, as is usually done when ordering <a href="https://promopult.ru/subscribe.html%3Fid%3D339">LSI texts</a> . </p><br><img src="https://habrastorage.org/webt/w1/xs/jo/w1xsjohqyrbq40nwr7updfkyeoi.png"><br><br><p>  <em>Example TOR for LSI-text</em> </p><br><p>  On the basis of such TK - just with a list of words - sometimes we get quite strange texts. </p><br><p>  A common practice for copywriters is to write a text, and only then enter the given words in it.  This is easier, because you do not need to be interrupted to select and insert words in the process of composing a text.  But such inserts in hindsight can break - and often break - the logic and style of the text. </p><br><p>  The text under Neural Matching is about users and their needs, not about keys and plus-words.  Therefore, purely marketing pieces appear in TK: consumer descriptions and their motives.  Keys and plus-words fade into the background - they are used as markers, and not as obligatory elements.  Their place is occupied by the information needs of the audience. </p><br><img src="https://habrastorage.org/webt/mi/na/fe/minafe6tad3qlamzsal5e0kxf2m.png"><br><br><p>  <em>Example TK under Neural Matching</em> </p><br><p>  Such TK allows the author to clearly understand for whom the text, why and under what circumstances it will be read.  Such TK not only throws out the words to be used, but gives directions on what to write in order to use these words. </p><br><p>  Neural Matching, when optimizing pages for search, shifts the focus from purely pure mechanics to marketing.  In fact, this trend is not observed the first year.  Just Neural Matching is another step towards search engine optimization with a human face. </p><br><p>  Optimizing content for Neural Matching takes time and head work.  It is much easier to throw keys from SJ into TZ, compare the plus-words and tell the copywriter: ‚ÄúWrite for people‚Äù.  But in the conditions of the development of AI-search, this approach will be less and less effective. </p></div><p>Source: <a href="https://habr.com/ru/post/455575/">https://habr.com/ru/post/455575/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../455559/index.html">How can a quantum computer hack modern encryption systems and reduce the cost of ammonia production?</a></li>
<li><a href="../455563/index.html">Small business: automate or not?</a></li>
<li><a href="../455565/index.html">Can the mind fake the universe?</a></li>
<li><a href="../455569/index.html">Welcome to Tarantool Conference June 17</a></li>
<li><a href="../455571/index.html">DB Cursors in Doctrine</a></li>
<li><a href="../455577/index.html">SDL 2 Tutorials: Lesson 3 - Events</a></li>
<li><a href="../455579/index.html">Tupperware: Facebook's ‚Äúkiller‚Äù Kubernetes?</a></li>
<li><a href="../455582/index.html">Navigation in the store: through augmented reality to the desired shelf</a></li>
<li><a href="../455584/index.html">User interview by internal company forces: through mistakes to discoveries</a></li>
<li><a href="../455586/index.html">Robotics lecture series by Professor Gregor Sch√∂ner, Director of the Institute of Neuroinformatics (INI) Bochum, Germany</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>