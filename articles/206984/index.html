<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Lock-free data structures. Inside RCU</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="In this article, I will continue to familiarize the community with the technicians who provide writing of lock-free containers, advertise (along the w...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Lock-free data structures. Inside RCU</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/getpro/habr/post_images/faf/9c1/2ec/faf9c12ecadd0926ae483bd3acf62670.png" align="right"><br>  In this article, I will continue to familiarize the community with the technicians who provide writing of lock-free containers, advertise (along the way, I hope, not too obtrusively) my library <a href="http://libcds.sourceforge.net/">libcds</a> . <br><br>  It will be a question of one more technique of safe release of memory for lock-free containers - RCU.  This technique differs significantly from the previously considered a la Hazard Pointer algorithms. <br><br>  Read - Copy Update (RCU) is a synchronization technique designed for ‚Äúalmost read-only,‚Äù that is, rarely modifiable, data structures.  Typical examples of such a structure are map and set ‚Äî in which most of the operations are search, that is, reading data.  It is believed that for a typical map, more than 90% of the called operations are key searches, so it is important that the search operation be the fastest;  In principle, search synchronization is not needed - in the absence of writers, readers can work in parallel.  RCU provides the least overhead just for read operations. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Where did the name Read - Copy Update come from?  Initially the idea was very simple: there is some rarely changeable data structure.  If we need <i>to change</i> it, then we make a <i>copy of it</i> and make a change - add or delete data - in the copy.  At the same time, parallel readers work with the original, unchanged structure.  At some safe moment in time when there are no readers, we can replace the data structure with a modified copy.  As a result, all subsequent readers will see the changes made by the writer. <br><br><a name="habracut"></a><br>  The creator and active popularizer of RCU technology is Paul McKenney.  He heads a whole school of "RCU lovers", from which many well-known scientists in the field of lock-free and unconventional synchronization schemes have emerged, and he is also "the main RCU" in the Linux kernel (Linux-kernel RCU maintainer) and the author of <a href="http://www2.rdrop.com/users/paulmck/RCU/">several works</a> on RCU . <br><br><img src="https://habrastorage.org/getpro/habr/post_images/638/781/a6f/638781a6f9d3e183a5fc7f9648b98741.png" align="right"><br>  RCU was introduced into the Linux kernel in 2002, and since then it has grown more and more into kernel code, see the figure to the right.  For a long time, it was positioned as a synchronization technique for the core of the operating system.  Since the kernel has full control over all threads, both user and system, it is quite simple in the kernel to determine that a safe point in time for replacing data with a modified copy.  But we are interested in the application of RCU, is it possible?  Before answering this question, let's take a closer look at the RCU theory and terminology used in it. <br><br><h1>  General description RCU </h1><br><br>  The above description of the RCU idea is very simplistic.  As we know, having atomic operations, we can not make a copy of the data, but change the data structure ‚Äúon the fly‚Äù in parallel with its reading.  Then the ‚Äúreader‚Äù becomes a stream that performs any operation, except for removing an element from the data structure.  A writer is a stream that removes something from a structure.  Deletion should be done at the time when no one ‚Äústepped‚Äù on the data to be deleted, otherwise we will get a bunch of difficult-to-find problems - from ABA-problems to memory corruption.  The RCU solves all these problems, and in a way that is different from the Hazard Pointers scheme discussed earlier. <br><br>  RCU readers run in the read-side critical section.  When entering such a critical section, the reader calls the function <code>rcu_read_lock()</code> , on exit - <code>rcu_read_unlock()</code> .  These are very lightweight functions, with virtually no effect on performance;  in the Linux kernel, they weigh nothing at all (zero-overhead). <br>  If the flow is not in the critical reading section, then the flow is said to be at rest (quiescent state, quiescent-state).  Any period of time in which each stream was at least once in a quiescent-state is called a <i>grace period</i> .  Each critical reading section that began before the grace period must end before the grace period ends.  Each grace period is guaranteed to be finite, since any critical reading section is finite (it is understood that the number of threads is finite, as well as that we are good programmers and avoid endless loops, as well as the collapse of the thread). <br><br><img src="https://habrastorage.org/getpro/habr/post_images/5f4/942/8ee/5f49428ee84d78af466ea34b5193b071.png" align="right"><br>  A stream writer deleting an element from a data structure excludes the element from the structure and then waits for the end of the grace period.  The end of the grace-period means that no reader has access to the element to be deleted (see the figure, the ‚Äúreads‚Äù rectangles on it are critical read sections).  Therefore, a stream writer can safely physically remove an item. <br>  The deletion is performed in two stages: the first stage, ‚Äúremoval‚Äù, atomically removes the element from the data structure, but does not produce a physical free of memory.  Instead, the writer declares the beginning of the grace-period by calling the special primitive <code>synchronize_rcu()</code> and waits for it to end.  A deleted item can be accessed only by those readers who have declared their critical reading section in parallel with the writer (in the figure such sections are highlighted in gray).  By definition, all such readers will finish their work before the end of the grace-period.  At the end of the grace-period, that is, when all critical reading sections initiated or active during the grace-period are completed, the second stage of deletion begins - ‚Äúreclamation‚Äù - that is, the physical deletion of memory under the element. <br><br>  As you can see, the RCU synchronization technique is quite simple.  The question remains - how to determine the end of the grace-period in the user code?  The original RCU is heavily honed to the Linux kernel, where it is much easier to determine, since we have full control over all threads.  For the user space-code, the approaches of the original RCU are not applicable. <br><br><h1>  User-space RCU </h1><br>  The decision was given in 2009 by M.Desnoyers, a representative of the P. McKenney school, in <a href="http://publications.polymtl.ca/206/1/2009_MathieuDesnoyers.pdf">his dissertation</a> , Chapter 6 of which is called: User-Level Implementations of RCU. <br>  M.Desnoyers offers 3 user-space RCU (URCU) solutions: <br><ul><li>  Quiescent-State-Based Reclamation RCU is a very easy scheme for readers, but requiring streams <i>outside the</i> critical reading section to <i>periodically</i> declare "I am in a quiescent-state."  This solution is not suitable for the general purpose library, which is <a href="http://libcds.sourceforge.net/">libcds</a> , so I will not consider it. </li><li>  A general-purpose user space RCU (General-Purpose URCU) is an algorithm suitable for a general implementation, which I will describe below. </li><li>  User-space RCU on signals (RCU via Signal Handling) is also an interesting algorithm based on signals (suitable for * nix-systems, inapplicable to Windows).  Implemented in the libcds library, shows performance slightly worse than general-purpose RCU.  I will not consider it in this article; I am interested in referring to M.Desnoyers thesis and to the source codes libcds. </li></ul><br><br><h2>  General-Purpose URCU </h2><br><br>  M.Desnoyers so thoroughly and thoroughly parses the URCU algorithm that I can only follow it, changing only the name of some variables and functions to match the ones adopted in libcds. <br><br>  In the URCU scheme, two variables are defined: <br><pre> <code class="cpp hljs"><span class="hljs-built_in"><span class="hljs-built_in">std</span></span>::atomic&lt;<span class="hljs-keyword"><span class="hljs-keyword">uint32_t</span></span>&gt; g_nGlobalCtl(<span class="hljs-number"><span class="hljs-number">1</span></span>) ; <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">struct</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">thread_record</span></span></span><span class="hljs-class"> {</span></span> <span class="hljs-built_in"><span class="hljs-built_in">std</span></span>::atomic&lt;<span class="hljs-keyword"><span class="hljs-keyword">uint32_t</span></span>&gt; nThreadCtl; thread_record * pNext; thread_record(): nThreadCtl(<span class="hljs-number"><span class="hljs-number">0</span></span>), pNext(<span class="hljs-literal"><span class="hljs-literal">nullptr</span></span>) {} };</code> </pre><br>  The <code>thread_record</code> structure contains local data for the thread and links all such objects to the list of RCU streams. <br>  The <code>nThreadCtl</code> 31 bits of <code>nThreadCtl</code> contain the URCU call nesting depth counter (yes, the URCU allows almost unlimited nesting of the critical reading sections), the high bit determines the identifier of the grace-period at the moment the stream enters the critical reading section.  In the described scheme, only two identifiers for a grace-period are sufficient. <br>  The high-order bit of the <code>g_nGlobalCtl</code> global variable contains the identifier of the current grace-period, the low-order bits serve to initialize the <code>nThreadCtl</code> per-thread variables and are not changed. <br>  The functions <code>access_lock</code> and <code>access_unlock</code> respectively, are used to enter / exit the critical reading section: <br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">static</span></span> <span class="hljs-keyword"><span class="hljs-keyword">uint32_t</span></span> <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> c_nControlBit = <span class="hljs-number"><span class="hljs-number">0x80000000</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">static</span></span> <span class="hljs-keyword"><span class="hljs-keyword">uint32_t</span></span> <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> c_nNestMask = c_nControlBit ‚Äî <span class="hljs-number"><span class="hljs-number">1</span></span>; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">access_lock</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>{ thread_record * pRec = get_thread_record(); assert( pRec != <span class="hljs-literal"><span class="hljs-literal">nullptr</span></span> ); <span class="hljs-keyword"><span class="hljs-keyword">uint32_t</span></span> tmp = pRec-&gt;nThreadCtl.load( <span class="hljs-built_in"><span class="hljs-built_in">std</span></span>::memory_order_relaxed ); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> ( (tmp &amp; c_nNestMask) == <span class="hljs-number"><span class="hljs-number">0</span></span> ) { pRec-&gt;nThreadCtl.store(g_nGlobalCtl.load( <span class="hljs-built_in"><span class="hljs-built_in">std</span></span>::memory_order_relaxed ), <span class="hljs-built_in"><span class="hljs-built_in">std</span></span>::memory_order_relaxed ); <span class="hljs-built_in"><span class="hljs-built_in">std</span></span>::thread_fence( <span class="hljs-built_in"><span class="hljs-built_in">std</span></span>::memory_order_acquire ); } <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> pRec-&gt;nThreadCtl.fetch_add( <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-built_in"><span class="hljs-built_in">std</span></span>::memory_order_relaxed ); } <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">access_unlock</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>{ thread_record * pRec = get_thread_record(); assert( pRec != <span class="hljs-literal"><span class="hljs-literal">nullptr</span></span> ); pRec-&gt;nThreadCtl.fetch_sub( <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-built_in"><span class="hljs-built_in">std</span></span>::memory_order_release ); }</code> </pre><br>  When entering the critical section of the URCU, it is checked whether the call is nested or not.  If the call is nested (that is, the counter in the lower 31 bits is not zero), the nesting counter is simply incremented.  If the call is not nested, the variable <code>nThreadCtl</code> current thread is assigned the value of the global variable <code>g_nGlobalCtl</code> ;  it is thus marked that the input to the critical section was made in a certain grace-period (the high bit <code>g_nGlobalCtl</code> ), and the one in the low bits <code>g_nGlobalCtl</code> initializes the nesting counter of the current stream.  At the first, outermost entrance to the critical section, a acquire-memory barrier is applied.  It guarantees that the following code will not be moved (‚Äúoptimized‚Äù) upstream of the barrier by either the processor or the compiler.  This ensures the visibility of the current grace-period of the thread to all processors - if this order is disturbed, the URCU algorithm will be scattered.  When entering the <i>embedded</i> critical section of the barrier is not required, since the current grace-period (high bit) does not change. <br>  When exiting the critical section ( <code>access_unlock</code> ), the nesting counter in the current thread's <code>access_unlock</code> simply decremented.  The release semantics of the atomic operation is applied;  in fact, the release-barrier is needed here only when exiting the uppermost critical section (when moving from 1 to 0 of the nesting counter); when exiting the nested critical section, there is enough relaxed semantics.  The release barrier is required when resetting the counter, because when the nesting counter moves from 1 to 0, the declaration ‚Äúthe stream no longer uses RCU‚Äù actually occurs, that is, the exit from the grace period, which is critical for the URCU algorithm, is a violation of the order by the compiler or processor will lead to the inoperability of the algorithm.  Recognizing the ‚Äú0 - ‚Äã‚Äãnot 0‚Äù situations in the code will require a conditional transition, which is unlikely to add performance to the <code>access_unlock</code> function, and the basic pattern of using the critical sections of the URCU is without nesting, therefore, the release semantics is always used here. <br><br>  As you can see, the code from the readers is quite lightweight.  Atomic read-write and thread-local data are used.  Of course, this is not zero-overhead, but still much better than a mutex or CAS. <br><br>  The flow writer must make sure that the grace period is completed before physically removing an element.  The end of the grace period is one of two things: <br><ul><li>  The <code>nThreadCtl</code> bits (nesting counter) of the <code>nThreadCtl</code> each thread are zero, which means that the thread is not in the critical section of the URCU </li><li>  The <code>nThreadCtl</code> high bit <code>nThreadCtl</code> not match the high <code>g_nGlobalCtl</code> high bit, which means that the reader entered the critical section after the beginning of the grace period </li></ul><br>  These conditions are verified by the following function: <br><pre> <code class="cpp hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">bool</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">check_grace_period</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">( thread_record * pRec )</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">uint32_t</span></span> <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> v = pRec-&gt;nThreadCtl.load( <span class="hljs-built_in"><span class="hljs-built_in">std</span></span>::memory_order_relaxed ); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> (v &amp; general_purpose_rcu::c_nNestMask) &amp;&amp; ((( v ^ g_nGlobalCtl.load( <span class="hljs-built_in"><span class="hljs-built_in">std</span></span>::memory_order_relaxed )) &amp; ~c_nNestedMask )); }</code> </pre><br>  Before physical deletion, the writer calls the <code>synchronize</code> function, which waits for the end of the current grace-period: <br><pre> <code class="cpp hljs"><span class="hljs-built_in"><span class="hljs-built_in">std</span></span>::mutex g_Mutex ; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">synchronize</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-built_in"><span class="hljs-built_in">std</span></span>::atomic_thread_fence( <span class="hljs-built_in"><span class="hljs-built_in">std</span></span>::memory_order_acquire ); { cds::lock::scoped_lock&lt;<span class="hljs-built_in"><span class="hljs-built_in">std</span></span>::mutex&gt; sl( g_Mutex ); flip_and_wait(); flip_and_wait(); } <span class="hljs-built_in"><span class="hljs-built_in">std</span></span>::atomic_thread_fence( <span class="hljs-built_in"><span class="hljs-built_in">std</span></span>::memory_order_release ); }</code> </pre><br>  Here, <code>g_Mutex</code> is a global mutex for the URCU algorithm (yes, yes! URCU is still a <i>synchronization</i> technique, so there is nowhere without the mutex).  Thus, only one thread writer can go into <code>synchronize</code> .  Do not forget that RCU is positioned for ‚Äúalmost read-only‚Äù data, so no particular push on this mutex is expected. <br>  The writer waits for the grace-period to end by calling the <code>flip_and_wait</code> function: <br><pre> <code class="cpp hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">flip_and_wait</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>{ g_nGlobalCtl.fetch_xor( c_nControlBit, <span class="hljs-built_in"><span class="hljs-built_in">std</span></span>::memory_order_seq_cst ); <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (thread_record* pRec = g_ThreadList.head(<span class="hljs-built_in"><span class="hljs-built_in">std</span></span>::memory_order_acquire); pRec!= <span class="hljs-literal"><span class="hljs-literal">nullptr</span></span>; pRec = pRec-&gt;m_pNext ) { <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> ( check_grace_period( pRec )) { sleep( <span class="hljs-number"><span class="hljs-number">10</span></span> ); <span class="hljs-comment"><span class="hljs-comment">//  10  CDS_COMPILER_RW_BARRIER ; } } }</span></span></code> </pre><br>  This function changes the grace-period identifier, which means the beginning of a new grace-period, with the help of the atomic <code>fetch_xor</code> and waits (by calling <code>check_grace_period</code> ) until all <code>check_grace_period</code> threads have completed this new grace-period.  In pseudocode, waiting occurs at a simple sleep of 10 milliseconds; in the real libcds code, a template parameter is used that defines the back-off strategy. <br><br>  Why <code>flip_and_wait</code> writer call <code>flip_and_wait</code> twice?  For clarification, consider the following sequence of actions with two threads A and B. Suppose that the call to <code>flip_and_wait</code> <code>synchronize</code> only one: <br><ul><li>  <code>access_lock</code> A calls <code>access_lock</code> .  In the body of this function, it is determined that the call is not nested, the global <code>g_nGlobalCtl</code> is read, but so far not assigned to the variable <code>nThreadCtl</code> thread (everything is done in parallel, so this situation is quite acceptable) </li><li>  Thread B calls <code>synchronize</code> .  The first <code>flip_and_wait</code> , which changes the bit ID of the grace-period in <code>g_nGlobalCtl</code> .  The current grace-period identifier becomes 1 </li><li>  Since there is no one in the critical section of the URCU (remember that thread A has not yet managed to assign the value to its variable <code>nThreadCtl</code> ), thread B completes <code>synchronize</code> </li><li>  <code>nThreadCtl</code> A performs the assignment of its variable <code>nThreadCtl</code> .  Recall that the stream read the old grace-period value of 0 </li><li>  <code>access_lock</code> A terminates <code>access_lock</code> and continues execution in the critical section. </li><li>  Thread B calls <code>synchronize</code> again (apparently, it wants to delete something again).  Again, the current grace-period is <code>g_nGlobalCtl</code> in <code>g_nGlobalCtl</code> , so its identifier is now 0. </li></ul><br>  But flow A in the critical section that started <i>earlier</i> than B changed the grace-period!  Violation of the semantics of URCU, which will eventually lead to the entire bouquet - from ABA to memory corruption.  Recall: <code>synchronize</code> is called by the writer before physically removing memory for an item <br><br>  Calling <code>flip_and_wait</code> twice, that is, twice waiting for the end of the grace-period, we solve the above problem, the cause of which is the competitive execution of threads. <br><div class="spoiler">  <b class="spoiler_title">Another solution</b> <div class="spoiler_text">  You can, of course, solve this problem in a different way, if you use a counter instead of the bit ID of the grace-period.  But here a problem arises, which we have already seen in the article about the tagged pointer algorithm, the counter is prone to overflow!  For reliability, the counter should be 32-bit, then the overflow is not terrible for us.  But such a counter makes it necessary to have a 64-bit atomic type on 32-bit platforms.  This type either does not exist or it is rather inefficient.  Or we will have to abandon the nesting of critical sections of the URCU, which is also not very convenient. <br>  Therefore, we <code>flip_and_wait</code> dwell on a common solution with a bit as the identifier of the grace-period and calling two <code>flip_and_wait</code> <br></div></div><br><br><h2>  Implementing URCU in libcds </h2><br><img src="https://habrastorage.org/getpro/habr/post_images/b73/c45/db0/b73c45db0890ef91918d09616eac1cac.png" align="right"><br>  The URCU algorithm described above is good for everyone, except that you need to call up a rather heavy <code>synchronize</code> <i>before each</i> deletion.  Is there any way to improve this? <br>  Yes, it is possible, with the same method as in the Hazard Pointer algorithm, using delayed deletion.  Instead of deleting, we will put elements into some buffer.  The <code>synchronize</code> function will be called only when the buffer is full.  Unlike the Hazard Pointer, in the URCU the buffer will be common to all threads (in general, you can make per-thread buffers, nothing interferes with this). <br>  Moreover, in order not to slow down the writer, who has a share to clean the buffer when it overflows, the buffer cleaning functionality, that is, the actual deletion, can be assigned to a separate thread. <br><br>  The libcds library has <i>five</i> implementations of URCU, they all live in the <code>cds::urcu</code> : <br><ul><li>  <code>general_instant</code> is an implementation that exactly follows the described URCU algorithm: each deletion causes a <code>synchronize</code> , no buffering.  If deleting is quite a frequent operation, that is, the structure is not too ‚Äúalmost read-only‚Äù, this implementation is rather slow. </li><li>  <code>general_buffered</code> - implementation with a general lock-free buffer of a predefined size.  <a href="http://www.1024cores.net/">Dmitry Vyukov's queue</a> is used as a lock-free buffer - <code>cds::container::VyukovMPMCCycleQueue</code> .  The performance of such an implementation is comparable to the Hazard Pointer </li><li>  <code>general_threaded</code> is similar to <code>general_buffered</code> , but clearing buffers is done by the selected thread.  Such an implementation is slightly inferior to <code>general_buffered</code> due to additional synchronization with the selected stream, but does not slow down the writers </li><li>  <code>signal_buffered</code> is an analogue of <code>general_buffered</code> , but is based on the signal-handled URCU.  Not for Windows systems </li><li>  <code>signal_threaded</code> is the analogue of <code>general_threaded</code> for signal-handled URCU.  Also not for windows </li></ul><br><br>  Such an abundance of implementations of URCU raises the problem of writing container specializations under URCU.  The fact is that the implementation of containers for the URCU scheme is significantly different from the implementation for the Hazard Pointer.  Therefore, a separate specialization for URCU is required.  I would like to have one specialization, not five. <br>  To facilitate the writing of the specialization under the URCU, the wrapper class <code>cds::urcu::gc</code> was introduced: <br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">template</span></span> &lt;<span class="hljs-keyword"><span class="hljs-keyword">typename</span></span> RCUimpl&gt; <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">gc</span></span></span><span class="hljs-class">;</span></span></code> </pre><br>  where <code>RCUimpl</code> is one of the URCU implementations: <code>general_instant</code> , <code>general_buffered</code> , etc. With such a wrapper, the specialization for the URCU is easy to write and it will be the only one: <br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">template</span></span> &lt; <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">RCU</span></span></span><span class="hljs-class">, </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">typename</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Key</span></span></span><span class="hljs-class">, </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">typename</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Value</span></span></span><span class="hljs-class">, </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Traits</span></span></span><span class="hljs-class"> &gt; </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">SplitListMap</span></span></span><span class="hljs-class">&lt; cds::urcu::gc&lt; RCU &gt;, Key, Value, Traits &gt; ...</span></span></code> </pre><br><br>  It should be noted that in libcds, the main function of the URCU algorithm during deletion is not <code>synchronize</code> , but <code>retire_ptr</code> .  This function places the item to be removed in the URCU buffer and at the right time (for example, when the buffer is full) calls <code>synchronize</code> .  So an explicit call to <code>synchronize</code> not required, although it is valid.  In addition, this solution unifies the interface URCU and Hazard Pointer. <br><br>  All the listed URCU algorithms are implemented in a typical libcds manner: for each there is a global singleton object, which is initialized by calling the wrapper object constructor <code>cds::urcu::gc&lt;cds::urcu::general_buffered&lt;&gt; &gt;</code> at the beginning of <code>main()</code> after calling <code>cds::Initialize()</code> : <br><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">include</span></span></span><span class="hljs-meta"> </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;cds/init.h&gt; //cds::Initialize  cds::Terminate #include &lt;cds/gc/general_buffered.h&gt; // general_buffered URCU int main(int argc, char** argv) { //  libcds cds::Initialize() ; { //  general_buffered URCU  cds::urcu::gc&lt;cds::urcu::general_buffered&lt;&gt; &gt; gbRCU ; //  main thread  lock-free  // main thread    //   libcds cds::threading::Manager::attachThread() ; // , libcds    //     ... } //  libcds cds::Terminate() ; }</span></span></span></span></code> </pre><br><br>  As with the Hazard Pointer schema, each thread using URCU containers must be initialized in a special way: <br><pre> <code class="cpp hljs"><span class="hljs-comment"><span class="hljs-comment">// cds::threading::Manager #include &lt;cds/threading/model.h&gt; int myThreadEntryPoint(void *) { //     libcds cds::threading::Manager::attachThread() ; //        // lock-free  libcds ... //    libcds cds::threading::Manager::detachThread() ; return 0; }</span></span></code> </pre><br><br>  Using libcds URCU containers is completely transparent: just declare a container object with a URCU gc, and that's it.  All the specifics of working with the URCU is hidden inside the URCU container specialization.  No external synchronization is required when accessing such a container. <br><div class="spoiler">  <b class="spoiler_title">UPD: Oops!</b> <div class="spoiler_text">  <i>"No external synchronization is required"</i> - this is something I got excited about. <br>  In fact, some methods of some URCU containers require prior entry to the critical reading section.  As a rule, these are methods for removing (retrieving) an element of a container.  The URCU can provide us with the ability to <i>return a</i> pointer to an item found by key.  This possibility is a rare exception in the lock-free world, where the return of the death pointer is usually similar, since an element can be removed at any time by a competing stream.  But in order to work safely with the returned pointer to the item, we need to be in the critical reading section.  So in this case, you should explicitly call <code>access_lock</code> before calling the container method, and after completing work with the pointer, <code>access_unlock</code> , and the best (exception-safe) technique will be to use scoped-lock in a separate code block. <br>  In the description of each method of the URCU container of the libcds library, it is noted whether this method should be called - in the critical section or not. <br></div></div><br>  If you decide to make your own container class based on the Uccu implementation of libcds, you should study the internal structure of the URCU container containers in detail.  In principle, there is nothing supernatural: when entering the method, call <code>gc::access_lock()</code> , upon exit - <code>gc::access_unlock()</code> (here <code>gc</code> is one of the URCU implementations; for security exceptions it is better to use the scoped lock technique instead of calling functions) .  The only subtle point is the removal of the element: the deletion method must also be included in the critical section of the reading, but the physical removal of the element by calling <code>gc::retire_ptr</code> must be done <i>outside the</i> critical section, otherwise deadlock is possible: the <code>gc::retire_ptr</code> method may trigger <code>synchronize</code> inside. <br><br>  Libcds defines URCU specializations for all set and map classes.  URCU specializations for queue and stack containers are undefined; they are not ‚Äúalmost read-only‚Äù containers, so the URCU is not for them. <br><br><div class="spoiler">  <b class="spoiler_title">Lock-free data structures</b> <div class="spoiler_text">  <a href="http://habrahabr.ru/company/ifree/blog/195770/">Start</a> <br>  Basics: <br><ul><li>  <a href="http://habrahabr.ru/company/ifree/blog/195948/">Atomicity and atomic primitives</a> </li><li>  <a href="http://habrahabr.ru/company/ifree/blog/196548/">Where did the memory barriers go from</a> </li><li>  <a href="http://habrahabr.ru/company/ifree/blog/197520/">Memory model</a> </li></ul><br>  Inside: <br><ul><li> <a href="http://habrahabr.ru/company/ifree/blog/202190/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Memory management circuits</font></font></a> </li><li> <a href="http://habrahabr.ru/company/ifree/blog/206984/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">RCU</font></font></a> </li><li> <a href="http://habrahabr.ru/company/ifree/blog/216013/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Stack evolution</font></font></a> </li><li> <a href="http://habrahabr.ru/company/ifree/blog/219201/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Another treatise</font></font></a> </li><li> <a href="http://habrahabr.ru/post/230349/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Queue dissection</font></font></a> </li><li> <a href="http://habrahabr.ru/post/250383/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Concurrent maps: warm up</font></font></a> </li><li> <a href="http://habrahabr.ru/post/250523/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Concurrent maps: rehash, no rebuild</font></font></a> </li><li>  <a href="http://habrahabr.ru/post/250815/">Concurrent maps: skip list</a> </li><li> <a href="https://habrahabr.ru/post/251267/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Concurent maps: trees</font></font></a> </li><li>  <a href="https://habrahabr.ru/post/314948/">Iterators: multi-level array</a> </li><li> <a href="https://habrahabr.ru/post/317882/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Iterable list</font></font></a> </li></ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Outside: </font></font><br><ul><li> <a href="http://habrahabr.ru/company/ifree/blog/196834/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Introduction to libcds</font></font></a> </li></ul><br></div></div></div><p>Source: <a href="https://habr.com/ru/post/206984/">https://habr.com/ru/post/206984/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../206966/index.html">Released unattached jailbreak for iOS 7.x</a></li>
<li><a href="../206968/index.html">A passion for programming. Chapter 13. Find a Mentor</a></li>
<li><a href="../206972/index.html">Google Platform. 10+ years</a></li>
<li><a href="../206974/index.html">Computer generated acoustic field generation</a></li>
<li><a href="../206980/index.html">Cubli: robotic cube with almost perfect balancing</a></li>
<li><a href="../206986/index.html">Colossus Google's distributed file system</a></li>
<li><a href="../206988/index.html">A selection of specialized software for a web developer under the Android OS</a></li>
<li><a href="../206992/index.html">"Debriefing" - Episode 52 - Chief of IDEA</a></li>
<li><a href="../206994/index.html">Fads of abstractions</a></li>
<li><a href="../206996/index.html">DSL on Scala for working with HTML forms</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>