<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Increase the randomness of the fact that it is [probably] [almost] random</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="random numbers are tastier if they are slightly peppered 

 We will combine theory with practice - we will show that it is possible to improve the ent...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Increase the randomness of the fact that it is [probably] [almost] random</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/webt/g9/kh/sg/g9khsgflhymunz9z4_dd9qww1ny.jpeg"><br>  <i>random numbers are tastier if they are slightly peppered</i> <br><br>  We will combine theory with practice - we will show that it is possible to improve the entropy of random sequences, after which we will look at the source codes that do this. <br><br>  I really wanted to write about the fact that high-quality, that is, highly entropic, random number generation is critically important in solving a huge number of problems, but this is probably superfluous.  I hope everyone knows this very well. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      In pursuit of qualitative random numbers, people invent very ingenious devices (see, for example, <a href="https://habr.com/company/ua-hosting/blog/418321/">here</a> and <a href="https://habr.com/company/mailru/blog/408181/">here</a> ).  In principle, quite good sources of randomness are built into the API of operating systems, but this is a serious matter, and we are always a little bit worried about the worm of doubt: is the RNG good enough that I use, and is it not spoiled by third parties? <br><a name="habracut"></a><br><h3>  Little theory </h3><br>  <b>To begin, let us show that with the right approach, the quality of the existing RNG cannot be degraded.</b>  The simplest correct approach is to overlay any other <i>main</i> sequence through the XOR operation.  <i>The main</i> sequence may be, for example, a systemic RNG, which we already consider to be quite good, but there are still some doubts, and we have a desire to make sure.  <i>An additional</i> sequence can be, for example, a pseudo-random number generator, the output of which looks good, but we know that its real entropy is very low.  <i>The resulting</i> sequence is the result of applying the XOR operation to the bits of the main and additional sequences.  <b>Significant nuance: the</b> main and additional sequences must be independent of each other.  That is, their entropy must be taken from fundamentally different sources, the interdependence of which cannot be calculated. <br><br>  Denote as <b><i>x the</i></b> next bit of the main sequence, and <b><i>y</i></b> - the corresponding bit of the additional sequence.  Bit of the resulting sequence is denoted as <b><i>r</i></b> : <br>  r = x‚äïy <br><br>  <b>The first attempt to prove.</b>  Let's try to go through the informational entropy <b><i>x</i></b> , <b><i>y</i></b> and <b><i>r</i></b> .  The probability of zero <b><i>x is</i></b> denoted as <b><i>p <sub>x0</sub></i></b> , and the probability of zero <b><i>y</i></b> as <b><i>p <sub>y0</sub></i></b> .  Informational entropies <b><i>x</i></b> and <b><i>y are</i></b> calculated using the Shannon formula: <br><br>  H <sub>x</sub> = - (p <sub>x0</sub> log <sub>2</sub> p <sub>x0</sub> + (1 ‚àí p <sub>x0</sub> ) log <sub>2</sub> (1 ‚àí p <sub>x0</sub> )) <br>  H <sub>y</sub> = - (p <sub>y0</sub> log <sub>2</sub> p <sub>y0</sub> + (1 ‚àí p <sub>y0</sub> ) log <sub>2</sub> (1 ‚àí p <sub>y0</sub> )) <br><br>  A zero in the resulting sequence appears when the input has two zeroes or two ones.  The probability of zero r: <br><br>  p <sub>r0</sub> = p <sub>x0</sub> p <sub>y0</sub> + (1 ‚àí p <sub>x0</sub> ) (1 ‚àí p <sub>y0</sub> ) <br>  H <sub>r</sub> = - (p <sub>r0</sub> log <sub>2</sub> p <sub>r0</sub> + (1 ‚àí p <sub>r0</sub> ) log <sub>2</sub> (1 ‚àí p <sub>r0</sub> )) <br><br>  In order to prove the non-deterioration of the main sequence, it is necessary to prove that <br>  <b><i>Hr - Hx ‚â• 0</i></b> for any values ‚Äã‚Äãof <b><i>p <sub>x0</sub></i></b> and <b><i>p <sub>y0</sub></i></b> .  I failed to prove this analytically, but the visualized calculation shows that the increase in entropy forms a smooth surface, which is not going anywhere to go to minus: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/mb/un/5x/mbun5xdlkm3zmxc-7brg5lypo4q.png"></div><br>  For example, if we add a strongly skewed additional with <i>p <sub>y0</sub></i> = 0.1 to the skewed main signal c <i>p <sub>x0</sub></i> = 0.3 (entropy 0.881), we get the result <i>p <sub>r0</sub></i> = 0.66 with entropy 0.925. <br><br>  So, entropy cannot be spoiled, but this is not yet accurate.  Therefore, we need a second attempt.  However, through entropy, it is also possible to carry out the proof.  Scheme (all the steps are quite simple, you can do it yourself): <br><br><ol><li>  We prove that the entropy has a maximum at the point <i>p <sub>0</sub></i> = 1/2. </li><li>  We prove that for any <i>p <sub>x0</sub></i> and <i>p <sub>y0, the</sub></i> value of <i>p <sub>r0</sub></i> cannot be further from 1/2 than <i>p <sub>x0</sub></i> . </li></ol><br>  <b>The second attempt to prove.</b>  Through the ability to guess.  Suppose an attacker has a priori some information about the main and additional sequences.  The possession of information is expressed in the ability with some probability to guess in advance the values ‚Äã‚Äãof <b><i>x</i></b> , <b><i>y</i></b> and, as a result, <b><i>r</i></b> .  The probabilities of guessing <b><i>x</i></b> and <b><i>y are</i></b> denoted respectively by <b><i>g <sub>x</sub></i></b> and <b><i>g <sub>y</sub></i></b> (from the word guess).  Bit of the resulting sequence is guessed either when both values ‚Äã‚Äãare guessed correctly, or when both are wrong, therefore the probability of guessing is as follows: <br>  g <sub>r</sub> = g <sub>x</sub> g <sub>y</sub> + (1 ‚àí g <sub>x</sub> ) (1 ‚àí g <sub>y</sub> ) = 2 g <sub>x</sub> g <sub>y</sub> - g <sub>x</sub> - g <sub>y</sub> + 1 <br><br>  When we have a perfect guessler, we have <b><i>g</i></b> = 1.  If we don‚Äôt know anything, <b><i>g</i></b> is ... no, not zero, but 1/2.  It is this probability of guessing is obtained if we make a decision by tossing a coin.  A very interesting case is when <b><i>g</i></b> &lt;1/2.  On the one hand, such a diviner somewhere inside of itself has data about the predictable value, but for some reason it inverts its output, and thus it becomes <i>worse than a coin</i> .  Please remember the phrase ‚Äúworse than a coin,‚Äù it will be useful to us below.  From the point of view of the mathematical theory of communication (and, as a consequence, the quantitative information theory we are used to), this situation is absurd, since it will no longer be information theory, but disinformation theory, but in life we ‚Äã‚Äãhave this situation more often than we would like . <br><br>  Consider the limiting cases: <br><br><ul><li>  <b><i>g <sub>x</sub> = 1</i></b> , that is, the sequence <b><i>x is</i></b> completely predictable: <br>  g <sub>r</sub> = g <sub>x</sub> g <sub>y</sub> + (1 ‚àí g <sub>x</sub> ) (1 ‚àí g <sub>y</sub> ) = 1 g <sub>y</sub> + (1 - 1) (1 ‚àí g <sub>y</sub> ) = g <sub>y</sub> <br>  That is, the probability of guessing the result is equal to the probability of guessing the additional sequence. </li><li>  <b><i>g <sub>y</sub> = 1</i></b> : Same as above.  The probability of guessing the result is equal to the probability of guessing the main sequence. </li><li>  <b><i>g <sub>x</sub> = 1/2</i></b> , that is, the sequence <b><i>x is</i></b> completely unpredictable: <br>  g <sub>r</sub> = 2 g <sub>x</sub> g <sub>y</sub> - g <sub>x</sub> - g <sub>y</sub> + 1 = 2/2 g <sub>y</sub> - 1/2 - g <sub>y</sub> +1 = g <sub>y</sub> - g <sub>y</sub> + 1/2 = 1/2 <br>  That is, the addition of any additional sequence does not impair the overall unpredictability of the main one. </li><li>  <b><i>g <sub>y</sub> = 1/2</i></b> : Same as above.  Adding a completely unpredictable extra sequence makes the result completely unpredictable. </li></ul><br>  In order to prove that adding an extra sequence to the main one doesn‚Äôt help an attacker, we need to find out under what conditions <b><i>g <sub>r</sub></i></b> can be greater than <b><i>g <sub>x</sub></i></b> , that is, <br><br>  2 g <sub>x</sub> g <sub>y</sub> - g <sub>x</sub> - g <sub>y</sub> + 1&gt; g <sub>x</sub> <br><br>  Transfer g <sub>x</sub> from the right to the left and g <sub>y</sub> and 1 to the right: <br><br>  2 g <sub>x</sub> g <sub>y</sub> - g <sub>x</sub> - g <sub>x</sub> &gt; g <sub>y</sub> - 1 <br>  2 g <sub>x</sub> g <sub>y</sub> - 2 g <sub>x</sub> &gt; g <sub>y</sub> - 1 <br>  We put in the left part 2g <sub>x</sub> for the brackets: <br>  2 g <sub>x</sub> (g <sub>y</sub> - 1)&gt; g <sub>y</sub> - 1 <br>  Since we have g <sub>y</sub> less than unity (we have already considered the limiting case when g <sub>y</sub> = 1), we will turn g <sub>y</sub> ‚àí1 into 1 ‚àí g <sub>y</sub> , not forgetting to change ‚Äúmore‚Äù to ‚Äúless‚Äù: <br>  2 g <sub>x</sub> (1 - g <sub>y</sub> ) &lt;1 - g <sub>y</sub> <br><br>  We reduce ‚Äú1 ‚àí g <sub>y</sub> ‚Äù and obtain the condition under which adding an additional sequence improves the guessing situation for an attacker: <br><br>  2 g <sub>x</sub> &lt;1 <br>  g <sub>x</sub> &lt;1/2 <br><br>  That is, <b><i>g <sub>r</sub></i></b> can be greater than <b><i>g <sub>x</sub></i></b> only when guessing the main sequence is <i>worse than a coin</i> .  Then, when our predictor is busy conscious sabotage. <br><br>  <b>A few additional considerations about entropy.</b> <br><br><ol><li>  Entropy is an extremely mythologized concept.  Informational - including.  It really hinders.  Often, informational entropy is represented as some subtle matter that is either objectively present in the data or not.  In fact, informational entropy is not something that is present in the signal itself, but a quantitative assessment of the a priori awareness of the message recipient regarding the message itself.  That is, it is not only about the signal, but also about the recipient.  If the recipient knows nothing about the signal in advance, the information entropy of the transmitted binary unit is exactly 1 bit regardless of how the signal was received and what it is. </li><li>  We have an entropy addition theorem, according to which the total entropy of independent sources is equal to the sum of the entropies of these sources.  If we connected the main sequence with the additional one through concatenation, we would save the entropies of the sources, but we would get a bad result, because in our problem we need to estimate not the total entropy, but the specific entropy, in terms of a separate bit.  The concatenation of sources gives us the specific entropy of the result, which is equal to the arithmetic mean of the sources, and the entropy weak additional sequence naturally worsens the result.  The use of the XOR operation leads to the fact that we lose some of the entropy, but we are guaranteed to have a resultant entropy no worse than the maximum entropy of the terms. </li><li>  Cryptographers have a dogma: the use of pseudo-random number generators is an unforgivable arrogance.  Because these generators have a small specific entropy.  But we just found out that if you do everything right, entropy becomes a barrel of honey, which cannot be spoiled by any amount of tar. </li><li> If we have only 10 bytes of real entropy, spread out over kilobytes of data, from a formal point of view, we have only 1% of specific entropy, which is very bad.  But if these 10 bytes are spread out qualitatively, and apart from brute force there is no way to calculate these 10 bytes, everything does not look so bad.  10 bytes is 2 <sup>80</sup> , and if our brute force per second goes through a trillion variants, we will need an average of 19 thousand years to learn how to guess the next sign. </li></ol><br>  As mentioned above, informational entropy is a relative value.  Where for one subject the specific entropy is 1, for another it may well be 0. Moreover, the one from whom 1 may have no way of knowing the true state of affairs.  Systemic RNG issues a stream that is indistinguishable for us from a truly random one, but we can only hope that it is really random <i>for everyone</i> .  And believe.  If paranoia suggests that the quality of the main RNG may suddenly turn out to be unsatisfactory, it makes sense to err with the help of an extra. <br><br><h3>  Implementation of the summing RNG on Python </h3><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> random <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Random, SystemRandom <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> random <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> BPF <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> _BPF, RECIP_BPF <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> _RECIP_BPF <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> functools <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> reduce <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> _reduce <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> operator <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> xor <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> _xor <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">CompoundRandom</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(SystemRandom)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__new__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(cls, *sources)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">"""Positional arguments must be descendants of Random"""</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> all(isinstance(src, Random) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> src <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> sources): <span class="hljs-keyword"><span class="hljs-keyword">raise</span></span> TypeError(<span class="hljs-string"><span class="hljs-string">"all the sources must be descendants of Random"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> super().__new__(cls) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, *sources)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">"""Positional arguments must be descendants of Random"""</span></span> self.sources = sources super().__init__() <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">getrandbits</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, k)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">"""getrandbits(k) -&gt; x. Generates an int with k random bits."""</span></span> <span class="hljs-comment"><span class="hljs-comment">########         : return _reduce(_xor, (src.getrandbits(k) for src in self.sources), 0) def random(self): """Get the next random number in the range [0.0, 1.0).""" ########  ,   SystemRandom   .  ... return self.getrandbits(_BPF) * _RECIP_BPF</span></span></code> </pre> <br>  Usage example: <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">&gt;&gt;&gt; </span></span><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> random_xe <span class="hljs-comment"><span class="hljs-comment"># &lt;&lt;&lt;    &gt;&gt;&gt; from random import Random, SystemRandom &gt;&gt;&gt; #  : &gt;&gt;&gt; myrandom1 = random_xe.CompoundRandom(SystemRandom(), Random()) &gt;&gt;&gt; #    Random: &gt;&gt;&gt; myrandom1.random() 0.4092251189581082 &gt;&gt;&gt; myrandom1.randint(100, 200) 186 &gt;&gt;&gt; myrandom1.gauss(20, 10) 19.106991205743107</span></span></code> </pre> <br>  The main stream is taken as the SystemRandom considered correct, and the standard PRNG Random is taken as an additional stream.  The meaning of this, of course, is not very much.  A standard PRNG is definitely not the supplement for which all this was worth starting up.  You can instead marry two system RNGs together: <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">&gt;&gt;&gt; </span></span>myrandom2 = random_xe.CompoundRandom(SystemRandom(), SystemRandom())</code> </pre> <br>  There is even less sense in this (although this is the reason why Bruce Schneier recommends this in Applied Cryptography), because the above calculations are valid only for independent sources.  If the system‚Äôs RNG is compromised, the result will also be compromised.  In principle, the flight of fantasy in the search for a source of additional entropy is not limited by anything (in our world, confusion occurs much more often than order), but as a simple solution I will offer the PRNG HashRandom, also implemented in the random_xe library. <br><br><h3>  PRNG based stream cyclic hashing </h3><br>  In the simplest case, you can take a relatively small amount of initial data (for example, ask the user to drum on the keyboard), calculate their hash, and then cyclically add a hash to the input of the hashing algorithm and take the following hashes.  Schematically, this can be represented as: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ka/fk/ei/kafkeiisv_tow0ib7kibsqwhbuy.png"></div><br><br>  The cryptoresistance of this process is based on two assumptions: <br><br><ol><li>  The task of restoring the original data to the hash value is unbearably difficult. </li><li>  According to the hash value, it is impossible to restore the internal state of the hashing algorithm. </li></ol><br>  After consulting with the internal paranoid, he recognized the second assumption as superfluous, and therefore in the final implementation of the PRNG scheme the scheme is a bit complicated: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/rv/mp/hz/rvmphzdunz3q25vy61tm65okwv4.png"></div><br><br>  Now if an attacker managed to get the value of Hash 1r, he will not be able to calculate the next value of Hash 2r, since he does not have the value of Hash 2h, which he cannot find out without calculating the counter-hashing function.  Thus, the crypto-resistance of this scheme corresponds to the crypto-resistance of the hashing algorithm used. <br><br>  Usage example: <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">&gt;&gt;&gt; </span></span><span class="hljs-comment"><span class="hljs-comment">#  ,  HashRandom     '123': &gt;&gt;&gt; myrandom3 = random_xe.CompoundRandom(SystemRandom(), random_xe.HashRandom('123')) &gt;&gt;&gt; #    Random: &gt;&gt;&gt; myrandom3.random() 0.8257149881148604</span></span></code> </pre> <br>  The default algorithm is SHA-256.  If you want something else, you can transfer the desired type of hashing algorithm to the constructor by the second parameter.  For example, let's make a composite RNG, summing up the following: <br><br>  1. Systemic RNG (this is holy). <br>  2. User input processed by the SHA3-512 algorithm. <br>  3. The time spent on this input processed by SHA-256. <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">&gt;&gt;&gt; </span></span><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> getpass <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> getpass &gt;&gt;&gt; <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> time <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> perf_counter &gt;&gt;&gt; <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> hashlib <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> sha3_512 <span class="hljs-comment"><span class="hljs-comment">#    : &gt;&gt;&gt; def super_myrandom(): t_start = perf_counter() return random_xe.CompoundRandom(SystemRandom(), random_xe.HashRandom( getpass('  :'), sha3_512), random_xe.HashRandom(perf_counter() - t_start)) &gt;&gt;&gt; myrandom4 = super_myrandom()   : &gt;&gt;&gt; myrandom4.random() 0.35381173716740766</span></span></code> </pre> <br>  <b>Findings:</b> <br><br><ol><li>  If we are not sure of our random number generator, we can easily and incredibly cheaply solve this problem. </li><li>  Solving this problem, we can‚Äôt do worse.  Only better.  And it is mathematically proven. </li><li>  One should not forget to try to make the used sources of entropy independent. </li></ol><br>  The sources of the library are on <a href="https://github.com/amaslyaev/random_xe">GitHub</a> . </div><p>Source: <a href="https://habr.com/ru/post/423093/">https://habr.com/ru/post/423093/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../423083/index.html">How I became a developer at ABBYY</a></li>
<li><a href="../423085/index.html">Fine-tuning load balancing</a></li>
<li><a href="../423087/index.html">Don't push my eyes</a></li>
<li><a href="../423089/index.html">Programmers at MBLT DEV 2018</a></li>
<li><a href="../423091/index.html">Flutter for Android developers. How to create a UI for an Activity using Flutter</a></li>
<li><a href="../423095/index.html">What's new showed on Apple presentation</a></li>
<li><a href="../423097/index.html">Tasks and solutions for the PostgreSQL fighter</a></li>
<li><a href="../423099/index.html">Steam has allowed erotica, porn and violence in games</a></li>
<li><a href="../423101/index.html">Expanding LINSTOR for Proxmox</a></li>
<li><a href="../423103/index.html">Python podcasts: that's all we found</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>