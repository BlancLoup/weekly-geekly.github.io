<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>10 ways to backup in PostgreSQL</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Many conversations about backups begin with the saying that people fall into two categories ... and so I belong to those people who make backups. Prop...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>10 ways to backup in PostgreSQL</h1><div class="post__text post__text-html js-mediator-article">  Many conversations about backups begin with the saying that people fall into two categories ... and so I belong to those people who make backups.  Properly configured backups and validation of backups reinforces sleep.  And the presence of pre-written and lost instructions for recovery generally enhances digestion and immunity.  So, while working with PostgreSQL, I happened to set up backups often, while the conditions and requirements were very different.  However, the set of tools with rare exceptions remained unchanged.  In this article I will share my experience in how to take backup copies of PostgreSQL. <br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/e7b/533/0ca/e7b5330caebcbb95f7f0029c5641b8dc.jpg" alt="image"></div><br><a name="habracut"></a><br>  If you consider backup as a very specific process, then there are two simple questions: <br>  1. from where to run the backup? <br>  2. What tools should I use for backup? <br><br>  There are two possible answers to the first question: you can run the backup task from a dedicated backup server, in my opinion this is the most suitable option.  Either run the task directly from the database server, this is in case there is no dedicated backup server. <br><br>  Everything is much more interesting with tools.  Here I distinguish two groups, basic tools and auxiliary ones.  The main ones are those that actually perform the backup.  Auxiliary are those that add something special to the backup process, such as archiving, encryption, load management, etc. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      In the PostgreSQL bundle there are 2 utilities that allow you to make backup copies, these are <a href="http://www.postgresql.org/docs/9.3/static/app-pgdump.html">pg_dump</a> / <a href="http://www.postgresql.org/docs/9.3/static/app-pg-dumpall.html">pg_dumpall</a> and <a href="http://www.postgresql.org/docs/9.3/static/app-pgbasebackup.html">pg_basebackup</a> .  In addition, it is possible to use file copy utilities, such as rsync, tar, cp, etc. <br>  So, what tool to run backup? <br>  pg_dump - suitable for cases when you need to make a backup copy of the table, database, schema or data. <br>  pg_basebackup - suitable for cases when you need to backup the entire database cluster or set up a <a href="http://www.postgresql.org/docs/current/static/warm-standby.html">hot standby replica</a> . <br>  rsync / tar / cp - also used for copying the entire cluster. <br><br>  When PostgreSQL 9.0 was just released, the backup was done using rsync, but already in 9.1 pg_basebackup appeared, which has some advantages over rsync: <br><ul><li>  pg_basebackup does not require ssh access, but requires access to the database specified in <a href="http://www.postgresql.org/docs/9.3/static/auth-pg-hba-conf.html">pg_hba.conf</a> ; </li><li>  pg_basebackup is richer in functionality (copying WAL, creating recovery.conf, built-in gzip compression, etc.); </li><li>  pg_basebackup does not require a separate function call <a href="http://www.postgresql.org/docs/9.3/static/functions-admin.html">pg_start_backup / pg_stop_backup</a> as required when using rsync / tar / cp; </li><li>  pg_basebackup performs faster copying than rsync by using streaming replication protocol. </li></ul><br>  but there are some drawbacks: <br><ul><li>  pg_basebackup goes out-of-the-box, and accordingly requires an installed postgres; </li><li>  pg_basebackup has no built-in functions for limiting copying speed (they promise only in 9.4); </li><li>  pg_basebackup requires the wal_level = hot_standby, max_wal_senders options in postgresql.conf. </li></ul><br><br>  Here I will consider pg_basebackup, although pg_dump can also be used in the methods listed below. <br><br>  1. Simple and no frills backup from the backup server to the / backup directory (the directory must be previously created): <br><pre><code class="bash hljs">backup@backup ~ $ pg_basebackup -x -h db01.example.com -U backup -D /backup</code> </pre> <br>  2. Copying with low priority IO operations using ionice, for cases when it is necessary to reduce the load on disk I / O from backup: <br><pre> <code class="bash hljs">postgres@db01 ~ $ ionice -c 3 pg_basebackup -x -h db01.example.com -U backup -D /backup</code> </pre><br>  3. Copying with compression in bzip2, for cases when you need to use a non-standard compression algorithm for pg_basebackup (gzip).  Here we transfer data via standard output (stdout) to standard input (stdin) to the bzip2 program. <br><pre> <code class="bash hljs">backup@backup ~ $ pg_basebackup -x --format=tar -h db01.example.com -U backup -D - |bzip2 -9 &gt; /backup/db01/backup-$(date +%Y-%m-%d).tar.bz2</code> </pre><br>  4. Copying with compression in several streams (use lbzip2 and use 6 cores).  In this scenario, you can use idle kernels and speed up the compression process. <br><pre> <code class="bash hljs">backup@backup ~ $ pg_basebackup -x --format=tar -h db01.example.com -U backup -D - |lbzip2 -n 6 -9 &gt; /backup/db01/backup-$(date +%Y-%m-%d).tar.bz2</code> </pre><br>  5. Here copying is started on the database server.  The generated backup is sent to the remote server via ssh. <br><pre> <code class="bash hljs">postgres@db01 ~ $ pg_basebackup -x --format=tar -h 127.0.0.1 -U backup -D - |ssh backup@backup.example.com <span class="hljs-string"><span class="hljs-string">"tar xf - -C /backup/"</span></span></code> </pre><br>  6. Here, copying is also started on the database server and is sent to the remote server, but already with archiving in 6 streams using lbzip2. <br><pre> <code class="bash hljs">backup@backup ~ $ pg_basebackup -x --format=tar -h 127.0.0.1 -U backup -D - |ssh backup@backup.example.com <span class="hljs-string"><span class="hljs-string">"lbzip2 -n 6 -9 &gt; /backup/db01/backup-</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$(date +%Y-%m-%d)</span></span></span><span class="hljs-string">.tar.bz2"</span></span></code> </pre><br>  7. Copying to a remote server with limited bandwidth up to 10Mb using pv and then archiving on the remote side.  This option is for cases when you need to transfer without loading the network. <br><pre> <code class="bash hljs">backup@backup ~ $ pg_basebackup -x --format=tar -h 127.0.0.1 -U backup -D - |pv -r -b -L 10M |ssh backup@backup.example.com <span class="hljs-string"><span class="hljs-string">"bzip2 -9 &gt; /backup/db01/backup-</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$(date +%Y-%m-%d)</span></span></span><span class="hljs-string">.tar.bz2"</span></span></code> </pre><br>  It is worth noting here that c 9.4 in pg_basebackup already has the ability to limit the transfer rate (-r, --max-rate). <br>  8. Copy runs on the backup server, and then split the stream into two parts.  One stream is compressed with bzip2 (the backup itself) and the second stream is copied via tar into a temporary directory for further validation.  The method is rarely used, but the implementation itself is interesting here. <br><pre> <code class="bash hljs">backup@backup ~ $ pg_basebackup -x --format=tar -h db01.example.com -U backup -D - |tee &gt;(bzip2 -9 -c &gt; /backup/db01/backup-$(date +%d-%b-%Y).tar.bz2) |tar xf - -C /backup/validation/</code> </pre><br>  9. Copying with the use of lbzip2 on both nodes, for cases when the network has a small bandwidth, the stream is first compressed, then transmitted over the network and then decompressed on the remote side.  Here, tar is used and pg_start_backup ('label_name') is required on the postgres side. <br><pre> <code class="bash hljs">postgres@master <span class="hljs-comment"><span class="hljs-comment"># cd /var/lib/pgsql/9.3/data postgres@master # tar cfO - ./ |lbzip2 -n 2 -5 |ssh postgres@standby "lbunzip2 -c -n 2 |tar xf - -C /var/lib/pgsql/9.3/data"</span></span></code> </pre><br>  10. Backup with encryption via GPG, for cases when you need to encrypt a backup.  You should first create the keys via gpg --gen-key (in my case the keys are created with the name backup) <br><pre> <code class="bash hljs">backup@backup ~ $ pg_basebackup -x --format=tar -h db01.example.com -U backup -D - |gpg -r backup -e |bzip2 -9 &gt; /backup/db01/backup-$(date +%d-%b-%Y).tar.bz2</code> </pre><br>  To decrypt the backup, run this command. <br><pre> <code class="bash hljs">backup@backup ~ $ bzcat /backup/backup-09-May-2014.tar.bz2 |gpg -r backup -d |tar xf - -C /example/dir/</code> </pre><br>  That's all, let's summarize the tools: <br><ul><li>  pg_basebackup is a utility for creating postgres backups; </li><li>  <a href="http://lbzip2.org/">lbzip2</a> - bzip2 compression using several cores - if you need to pack faster (analogs: <a href="http://compression.ca/pbzip2/">pbzip2</a> , <a href="http://zlib.net/pigz/">pigz</a> ); </li><li>  ionice - class and priority adjustment for the I / O scheduler (you can also use nice to adjust the process priority for the scheduler CPU); </li><li>  <a href="http://linux.die.net/man/1/pv">pv</a> - control the amount of data transmitted through the pipe, and so on.  we use to limit the amount of data transferred per unit of time (analogue is <a href="http://linux.die.net/man/1/throttle">throttle</a> ); </li><li>  <a href="http://www.gnu.org/software/tar/">tar</a> is an archiving utility, needed for auxiliary purposes when bzip2 / gzip compression is not used; </li><li>  tee - reading from stdin with writing to stdout and other files (it is part of coreutils); </li><li>  <a href="https://www.gnupg.org/">gpg</a> - solves the problem of encryption. </li></ul><br>  Thank you all for your attention! </div><p>Source: <a href="https://habr.com/ru/post/222311/">https://habr.com/ru/post/222311/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../222299/index.html">The most popular trends of SEO-2014 according to Forbes</a></li>
<li><a href="../222303/index.html">Psychology of robots and smart computers: how it works and where to learn it. Lecture of Maxim Musin in Yandex</a></li>
<li><a href="../222305/index.html">PHPCI: Continuous Integration System for PHP Projects</a></li>
<li><a href="../222307/index.html">Mobile application development in Embarcadero FireMonkey (FMX 6)</a></li>
<li><a href="../222309/index.html">Dr. Dre has actually confirmed the sale of Apple's Beats</a></li>
<li><a href="../222313/index.html">Marketing for Startups: A Quantum Model</a></li>
<li><a href="../222315/index.html">Birdly project: Feel like a bird with Oculus Rift</a></li>
<li><a href="../222317/index.html">Reduce function</a></li>
<li><a href="../222319/index.html">Connect your Macbook Pro to a 10G Ethernet network</a></li>
<li><a href="../222321/index.html">What is meant by apt?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>