<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>We are developing a real-time fulltext-search system for error-logs based on ClickHouse from Yandex</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="In this article I will talk about how to develop a system for indexing and full-text search for error logs (or any other logs) based on a Yandex datab...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>We are developing a real-time fulltext-search system for error-logs based on ClickHouse from Yandex</h1><div class="post__text post__text-html js-mediator-article">  In this article I will talk about how to develop a system for indexing and full-text search for error logs (or any other logs) based on a Yandex database called ClickHouse.  About the base Yandex wrote on Habr√© first <a href="https://habrahabr.ru/company/yandex/blog/273305/">when the base was closed</a> , and then <a href="https://habrahabr.ru/company/yandex/blog/303282/">when they zaopensorsili it</a> .  The database is primarily intended for analytics and for the implementation of the Yandex.Metrica service, but it can be used for anything, if it is suitable for you to load data in batches, delete them too in huge batches and never update individual lines. <br><br><h1>  What do we do </h1><br>  We will implement a system for indexing and searching by error logs.  At the same time, it is believed that you have already managed to deliver the logs to the central server (or several servers) and have already inserted the message texts themselves into the database, that is, you already have a table in some database of the following form: <br><br><pre><code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">CREATE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">TABLE</span></span> Messages ( message_id <span class="hljs-built_in"><span class="hljs-built_in">BIGINT</span></span> PRIMARY <span class="hljs-keyword"><span class="hljs-keyword">KEY</span></span> AUTO_INCREMENT, created_ts DATETIME, message_text <span class="hljs-built_in"><span class="hljs-built_in">BLOB</span></span> )</code> </pre> 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      We will learn to quickly give search results for such a log (that is, always sorted by time) and index it in real time. <br><br><a name="habracut"></a><br><h1>  Why not ElasticSearch / Sphinx / MySQL / other_solution? </h1><br>  It seems to me interesting to see what ClickHouse is, and what tasks can be solved with its help.  The purpose of the article is to give people an overview and food for thought, rather than give a ready-made solution.  Elastic, Sphinx and others are ready-made search engines, whereas ClickHouse is a general-purpose database from which you can make everything you want.  Also, I have an opinion that the search system presented in the article based on ClickHouse will cope with the task of searching for logs better than Sphinx, and at the same time you will not need to use 2 types of indexes (real-time and normal).  Your experience may be different, so I recommend that you first try to make a prototype before implementing such a system in production. <br><br><h1>  Server installation </h1><br>  Assign the installation task ClickHouse ( <a href="https://github.com/yandex/ClickHouse">github</a> ) to your system administrator, or <a href="https://hub.docker.com/r/yandex/clickhouse-server/">put it yourself from the docker</a> , if you do not want to solve anything, or you are just too lazy.  If you are going to compile yourself from source codes, <a href="https://habrahabr.ru/company/yandex/blog/303282/">you will need up to 30 GB of space</a> , keep this in mind. <br><br><h1>  Client installation </h1><br>  If you do not have curl or php for some reason, install them.  Further examples will use curl as an API to the database and PHP for writing an indexing and searching system. <br><br><h1>  Prepare data structures for the index </h1><br>  As a rule, the structures for full-text search in search engines are very simple.  The structure is called <a href="https://ru.wikipedia.org/wiki/%25D0%2598%25D0%25BD%25D0%25B2%25D0%25B5%25D1%2580%25D1%2582%25D0%25B8%25D1%2580%25D0%25BE%25D0%25B2%25D0%25B0%25D0%25BD%25D0%25BD%25D1%258B%25D0%25B9_%25D0%25B8%25D0%25BD%25D0%25B4%25D0%25B5%25D0%25BA%25D1%2581">Inverted Index</a> , and we will implement it, in a slightly simplified form.  We will use the default engine recommended for data that has both a primary key and a date - <a href="https://clickhouse.yandex/reference_ru.html">MergeTree</a> : <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">CREATE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">TABLE</span></span> FT ( EventDate <span class="hljs-built_in"><span class="hljs-built_in">Date</span></span>, word_id UInt32, message_id UInt64 ) <span class="hljs-keyword"><span class="hljs-keyword">ENGINE</span></span>=MergeTree(EventDate, (word_id, message_id), <span class="hljs-number"><span class="hljs-number">8192</span></span>);</code> </pre><br><br>  To create a table in the database, you can use the following command: <br><br><pre> <code class="bash hljs">$ cat create.sql | curl <span class="hljs-string"><span class="hljs-string">'http:/hostname:8123/?query='</span></span> --data-binary @-</code> </pre><br>  In this command, the create.sql file should contain the request that needs to be executed, and the hostname is the host with ClickHouse raised, 8123 is the default port. <br><br>  In the above structure, word_id is the id of the word in the dictionary (which we will create later, the word_text =&gt; word_id is stored in the dictionary), and message_id is the id of the corresponding entry in the table with logs (analogous to document_id for Sphinx). <br><br>  Parameters for the MergeTree engine: the first EventDate field indicates the name of the column with the date of the event, the second column (word_id, message_id) defines the primary key (in fact, the usual index) and 8192 is the setting that affects the granularity of the index, we will leave it by default. <br><br>  MergeTree sorts the data by the primary key and splits it by date, so the search for a specific day and a specific word with sorting by message_id should be very fast. <br><br><h1>  Create dictionary structures </h1><br>  In order to fill this index, we need a dictionary-type structure, which is needed to store numbers in ClickHouse instead of strings.  A dictionary can be created in the database, and if it is MySQL, the structure will look like this: <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">CREATE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">TABLE</span></span> Words ( <span class="hljs-keyword"><span class="hljs-keyword">id</span></span> <span class="hljs-built_in"><span class="hljs-built_in">int</span></span>(<span class="hljs-number"><span class="hljs-number">11</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">unsigned</span></span> <span class="hljs-keyword"><span class="hljs-keyword">NOT</span></span> <span class="hljs-literal"><span class="hljs-literal">NULL</span></span> AUTO_INCREMENT, word <span class="hljs-built_in"><span class="hljs-built_in">varchar</span></span>(<span class="hljs-number"><span class="hljs-number">150</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">COLLATE</span></span> ascii_bin <span class="hljs-keyword"><span class="hljs-keyword">NOT</span></span> <span class="hljs-literal"><span class="hljs-literal">NULL</span></span> <span class="hljs-keyword"><span class="hljs-keyword">DEFAULT</span></span> <span class="hljs-string"><span class="hljs-string">''</span></span>, PRIMARY <span class="hljs-keyword"><span class="hljs-keyword">KEY</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">id</span></span>), <span class="hljs-keyword"><span class="hljs-keyword">UNIQUE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">KEY</span></span> word (word) ) <span class="hljs-keyword"><span class="hljs-keyword">ENGINE</span></span>=<span class="hljs-keyword"><span class="hljs-keyword">InnoDB</span></span> <span class="hljs-keyword"><span class="hljs-keyword">DEFAULT</span></span> <span class="hljs-keyword"><span class="hljs-keyword">CHARSET</span></span>=<span class="hljs-keyword"><span class="hljs-keyword">ascii</span></span> <span class="hljs-keyword"><span class="hljs-keyword">COLLATE</span></span>=ascii_bin;</code> </pre><br>  Pay attention to the ASCII-comparison, it allows you to greatly increase the performance of text indexes in the case when all words are in English.  If you do not have all the logs in English, I <s>recommend reviewing your views;</s> comparison can be left as default (utf8_unicode_ci). <br><br><h1>  Indexing process </h1><br>  In order to manage the indexing process and to initiate the initial indexing, you can create a separate table in MySQL with a queue for messages that we have not yet indexed: <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">CREATE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">TABLE</span></span> IndexQueue ( message_id <span class="hljs-built_in"><span class="hljs-built_in">bigint</span></span>(<span class="hljs-number"><span class="hljs-number">20</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">unsigned</span></span> <span class="hljs-keyword"><span class="hljs-keyword">NOT</span></span> <span class="hljs-literal"><span class="hljs-literal">NULL</span></span> <span class="hljs-keyword"><span class="hljs-keyword">DEFAULT</span></span> <span class="hljs-string"><span class="hljs-string">'0'</span></span>, shard_id <span class="hljs-built_in"><span class="hljs-built_in">int</span></span>(<span class="hljs-number"><span class="hljs-number">11</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">NOT</span></span> <span class="hljs-literal"><span class="hljs-literal">NULL</span></span>, PRIMARY <span class="hljs-keyword"><span class="hljs-keyword">KEY</span></span> (shard_id,message_id) );</code> </pre><br><br>  To populate this table for the first time, you can use the following query: <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">INSERT</span></span> <span class="hljs-keyword"><span class="hljs-keyword">IGNORE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">INTO</span></span> IndexQueue (message_id, shard_id) <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> message_id, message_id % <span class="hljs-number"><span class="hljs-number">4</span></span> <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> Messages</code> </pre><br><br>  Here 4 is the number of indexer threads that we will use.  In PHP7, the code from the example below gives a performance of approximately 3.5 mb / s for one process; in 4 threads, 14 MB / s is obtained accordingly.  If you write more error logs than 14 MB / sec, then you probably need to fix your production as soon as possible and you aren‚Äôt that the full text search is a bit behind :). <br><br>  The indexer algorithm will be as follows: <br><ol><li>  View entries in the queue (IndexQueue) for the specified shard </li><li>  Select a stack of records and select words in each message and put them into an $ index array of the form message_id =&gt; array (word1, ..., wordN) </li><li>  For each word, find the corresponding word_id in the dictionary, and if there is no such word yet, then add </li><li>  Insert in the index in the ClickHouse records for all the words of all messages </li></ol><br><br>  Below is a slightly simplified code for parsing the queue and indexing, you will have to modify it yourself if you want to use it in your home: <br><br><div class="spoiler">  <b class="spoiler_title">Simplified PHP Indexer Implementation</b> <div class="spoiler_text"><pre> <code class="php hljs"><span class="hljs-keyword"><span class="hljs-keyword">const</span></span> CH_HOST = <span class="hljs-string"><span class="hljs-string">'&lt;hostname&gt;:8123'</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> MAX_WORD_LEN = <span class="hljs-number"><span class="hljs-number">150</span></span>; <span class="hljs-comment"><span class="hljs-comment">//   ,    Words $mysqli = mysql_connect(...); //    $limit = 10000; //       $shard_id = intval($argv[1] ?? 0); //   (   ,   ,   0) echo "Indexing shard $shard_id\n"; while ($mysqli-&gt;query('SELECT MAX(message_id) FROM IndexQueue WHERE shard_id = ' . $shard_id)-&gt;fetch_row()[0]) { $index = ""; $start = microtime(true); $ids = []; foreach ($mysqli-&gt;query('SELECT message_id FROM IndexQueue WHERE shard_id = ' . $shard_id . ' ORDER BY message_id LIMIT ' . $limit)-&gt;fetch_all() as $row) { $ids[] = $row[0]; } if (empty($ids)) { break; } $message_texts = $mysqli-&gt;query('SELECT message_id, `message_text` FROM Messages WHERE message_id IN(' . implode(', ', $ids) . ')')-&gt;fetch_all(MYSQLI_ASSOC); $unknown_words = []; $msg_words = []; $total_length = 0; foreach ($message_texts as $msg) { $msg_id = $msg['message_id']; $text = $msg['message_text']; $total_length += strlen($text); $words = array_unique( array_filter( preg_split('/\W+/s', $text), function($a) { $len = strlen($a); return $len &gt;= 2 &amp;&amp; $len &lt;= MAX_WORD_LEN; } ) ); foreach ($words as $word) { $unknown_words[$word] = true; } $msg_words[$msg_id] = $words; } if (!count($message_texts)) { $mysqli-&gt;query('DELETE FROM IndexQueue WHERE shard_id = ' . $shard_id . ' AND message_id IN(' . implode(', ', $ids) . ')'); continue; } if (!count($unknown_words)) { var_dump($message_texts); die("Empty message texts!\n"); } $words_res = $mysqli-&gt;query('SELECT word, id FROM Words WHERE word IN(' . INstr(array_keys($unknown_words)) . ')')-&gt;fetch_all(MYSQLI_ASSOC); $word_ids = []; foreach ($words_res as $row) { $word_ids[$row['word']] = $row['id']; unset($unknown_words[$row['word']]); } if (count($unknown_words)) { echo "Inserting " . count($unknown_words) . " words into dictionary\n"; $values = []; foreach ($unknown_words as $word =&gt; $_) { $values[] = "('" . $mysqli-&gt;escape_string($word) . "')"; } $mysqli-&gt;query('INSERT IGNORE INTO Words (word) VALUES ' . implode(',', $values)); $words_res = $mysqli-&gt;query('SELECT word, id FROM Words WHERE word IN(' . INstr(array_keys($unknown_words)) . ')')-&gt;fetch_all(MYSQLI_ASSOC)); foreach ($words_res as $row) { $word_ids[$row['word']] = $row['id']; unset($unknown_words[$row['word']]); } } if (count($unknown_words)) { die("Could not fill dictionary\n"); } foreach ($msg_words as $msg_id =&gt; $words) { foreach ($words as $word) { //   ,  unix timestamp  message_id      32  $index .= date('Ym-d', $msg_id &gt;&gt; 32) . "\t" . $word_ids[$word] . "\t" . $msg_id . "\n"; } } $ch = curl_init('http://' . CH_HOST . '/?query=' . rawurlencode('INSERT INTO FT FORMAT TabSeparated')); curl_setopt($ch, CURLOPT_POSTFIELDS, $index); curl_setopt($ch, CURLOPT_RETURNTRANSFER, 1); $res = curl_exec($ch); if ($res !== "") { die($res . "\n"); } $mysqli-&gt;query('DELETE FROM IndexQueue WHERE shard_id = ' . $shard_id . ' AND message_id IN(' . implode(', ', $ids) . ')'); echo "Speed " . round($total_length / 1024 / (microtime(true) - $start), 2) . " KiB/sec\n"; } function INstr(array $values) { global $mysqli; $res = []; foreach ($values as $v) $res[] = "'" . $mysqli-&gt;escape_string($v) . "'"; return implode(',', $res); }</span></span></code> </pre><br></div></div><br><br><h1>  Index Search </h1><br>  We do not need ranking algorithms when searching, which Elastic, Sphinx and other solutions are so rich with, and we just need sorting by date, so the search will be extremely simple.  In fact, to find something for the query ‚Äúhello world 111‚Äù, we first need to find the word_id in the dictionary (suppose it will be 1, 2 and 3, respectively) and execute the following query: <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> message_id <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> FT <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> word_id <span class="hljs-keyword"><span class="hljs-keyword">IN</span></span>(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">GROUP</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> message_id <span class="hljs-keyword"><span class="hljs-keyword">HAVING</span></span> uniq(word_id) = <span class="hljs-number"><span class="hljs-number">3</span></span> <span class="hljs-keyword"><span class="hljs-keyword">ORDER</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> message_id <span class="hljs-keyword"><span class="hljs-keyword">DESC</span></span> <span class="hljs-keyword"><span class="hljs-keyword">LIMIT</span></span> <span class="hljs-number"><span class="hljs-number">50</span></span></code> </pre><br><br>  Please note that every document we are looking for must contain all the words from the query, so we write HAVING uniq (word_id) = 3 (uniq (word_id) is an analogue of COUNT (DISTINCT word_id) in ordinary SQL databases) where 3 is the number of different words in the query. <br><br>  We assume that sorting by message_id will mean sorting by time.  This can be achieved by recording UNIX TIMESTAMP events in seconds in the first 32 bits of message_id, and microseconds of events (if any) and random numbers in the second half. <br><br><h1>  results </h1><br>  To test the performance of this solution, I took a database of error-logs from our 3-GB development server (1.6 million events) and indexed it.  The indexer showed an indexing speed of 3.5 MB / s per stream, which was more than enough for my case.  At the moment we use Sphinx for full-text search by error-logs, so I can roughly compare the performance of these two solutions, since they work in approximately the same conditions on the same hardware.  Indexing with Sphinx (at least, the construction of a non-realtime index) is several times faster per core, but keep in mind that the sphinx indexer is written in C ++, and ours is in PHP :). <br><br>  To calculate the hardest query for ClickHouse (and, obviously, for Sphinx too), I decided to find the most popular words in the index: <br><pre> <code class="sql hljs">$ echo '<span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> word_id, <span class="hljs-keyword"><span class="hljs-keyword">count</span></span>() <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> cnt <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> FT <span class="hljs-keyword"><span class="hljs-keyword">GROUP</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> word_id <span class="hljs-keyword"><span class="hljs-keyword">ORDER</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> cnt <span class="hljs-keyword"><span class="hljs-keyword">DESC</span></span> <span class="hljs-keyword"><span class="hljs-keyword">LIMIT</span></span> <span class="hljs-number"><span class="hljs-number">5</span></span><span class="hljs-string"><span class="hljs-string">' | curl '</span></span><span class="hljs-keyword"><span class="hljs-keyword">http</span></span>://hostname:<span class="hljs-number"><span class="hljs-number">8123</span></span>/?<span class="hljs-keyword"><span class="hljs-keyword">query</span></span>=<span class="hljs-string"><span class="hljs-string">' --data-binary @- 5 1669487 187 1253489 183 1217494 159 1216255 182 1199507</span></span></code> </pre><br><br>  The request took 130 ms with a total number of records of 86 million, impressive!  (on the test machine 2 cores). <br><br>  So, if you take the top 5 and turn word_id into normal words, then the request for execution will be the following: ‚Äúphp wwwrun _packages ScriptFramework badoo‚Äù.  These words are found in almost every message and can be safely thrown out of the index, but I left them to check the search performance. <br><br>  Execute the query in ClickHouse: <br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> message_id <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> FT <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> word_id <span class="hljs-keyword"><span class="hljs-keyword">IN</span></span>(<span class="hljs-number"><span class="hljs-number">189</span></span>, <span class="hljs-number"><span class="hljs-number">159</span></span>, <span class="hljs-number"><span class="hljs-number">187</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>, <span class="hljs-number"><span class="hljs-number">183</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">GROUP</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> message_id <span class="hljs-keyword"><span class="hljs-keyword">HAVING</span></span> uniq(word_id) = <span class="hljs-number"><span class="hljs-number">5</span></span> <span class="hljs-keyword"><span class="hljs-keyword">ORDER</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> message_id <span class="hljs-keyword"><span class="hljs-keyword">DESC</span></span> <span class="hljs-keyword"><span class="hljs-keyword">LIMIT</span></span> <span class="hljs-number"><span class="hljs-number">51</span></span></code> </pre><br><br>  And a similar query in Sphinx: <br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> message_id <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> FT <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">MATCH</span></span>(<span class="hljs-string"><span class="hljs-string">'php wwwrun _packages ScriptFramework badoo'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">ORDER</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> message_id <span class="hljs-keyword"><span class="hljs-keyword">DESC</span></span> <span class="hljs-keyword"><span class="hljs-keyword">LIMIT</span></span> <span class="hljs-number"><span class="hljs-number">51</span></span></code> </pre><br><br>  Times of request execution (both daemons can use both cores to execute a request, everything fits into RAM): <br><br>  <b>ClickHouse:</b> 700 ms <br>  <b>Sphinx:</b> 1500 ms <br><br>  Given that Sphinx can rank the results, and our system does not, Sphinx has a very good time.  Do not forget that during the execution of the request, both daemons should have combined the results for ~ 6 million documents (1.2 million documents per word) and did it on a modest 2 cores.  It is possible that with proper adjustment, the times specified in this (slightly synthetic) test will be swapped, but nevertheless, I am very pleased with the results and it can be safely said that ClickHouse is very good for building real-time search from the logs. <br><br>  Thank you for reading the article to the end and I hope you enjoyed it. <br><br>  PS I am not an employee of Yandex and is not connected with Yandex in any way, I just wanted to try their database for a real task :). <br><br><h1>  Links </h1><br><ol><li>  <a href="https://clickhouse.yandex/">ClickHouse website</a> </li><li>  <a href="https://habrahabr.ru/company/yandex/blog/273305/">Article on Habr√© to open-source</a> </li><li>  <a href="https://habrahabr.ru/company/yandex/blog/303282/">Open-source article on Habr√©</a> </li><li>  <a href="https://github.com/yandex/ClickHouse">Github</a> </li><li>  <a href="https://hub.docker.com/r/yandex/clickhouse-server/">Clickhouse docker</a> </li></ol><br><br>  * UPD: * It is better to use the <a href="https://clickhouse.yandex/reference_ru.html">uniqUpTo (N)</a> function, since uniq is approximate, although it gives a very accurate result with the number of elements less than 65536. </div><p>Source: <a href="https://habr.com/ru/post/304602/">https://habr.com/ru/post/304602/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../304590/index.html">Optimization of the web service tips for postal addresses and name</a></li>
<li><a href="../304594/index.html">systemd: getty-like service for htop</a></li>
<li><a href="../304596/index.html">Introducing 3CX v15 Release Candidate</a></li>
<li><a href="../304598/index.html">Design stages, mistakes and advantages</a></li>
<li><a href="../304600/index.html">We get a domain name, DNS and SSL certificate free then</a></li>
<li><a href="../304604/index.html">Spryker performance and scalability concept</a></li>
<li><a href="../304606/index.html">ORM in cis magento</a></li>
<li><a href="../304608/index.html">Making a cool single page application on basis.js - part 2</a></li>
<li><a href="../304612/index.html">Seminars on introducing everything: from verilog and digital logic to micro-architecture of embedded processors and RTOS</a></li>
<li><a href="../304616/index.html">A polynomial algorithm for a combinatorial problem (P = NP?)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>