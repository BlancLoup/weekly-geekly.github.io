<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Mythbusters: Automatic Google Recaptcha Solution</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hello! I embody interesting ideas in python and talk about what came of it. Last time I tried to find anomalies on the property price map. Just. This ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Mythbusters: Automatic Google Recaptcha Solution</h1><div class="post__text post__text-html js-mediator-article"><img width="300" height="240" align="left" src="https://habrastorage.org/files/663/55d/522/66355d522fba43c3a33799b765dd7584.jpg">  Hello!  I embody interesting ideas in python and talk about what came of it.  Last <a href="https://habrahabr.ru/post/265783/">time</a> I tried to find anomalies on the property price map.  Just.  This time the idea was to build a system that would be able to solve the very popular Google Recaptcha 2.0 now, based on some algorithms and a large base of training examples. <br>  Google Recaptcha 2.0 is a set of images (9 or 16 square pictures under one instruction), among which the user, in order to confirm his rationality, needs to select all images of one category.  This is <b>NOT</b> about building a machine learning system - we‚Äôll recognize the captcha! <br><a name="habracut"></a><br><img width="200" height="300" align="right" src="https://habrastorage.org/files/d14/97f/8a5/d1497f8a5f0c4da98f5f8cb8178d712a.png">  If the reader does not want to go into the details of the technical plan and the romance of research, then the conclusion of the whole article will be concentrated near the <abbr title="Big Red Graphics">BCG</abbr> at the end. <br>  The training samples of the captcha for this study were kindly provided by the anti- <a href="https://rucaptcha.com/">captcha</a> service RuCaptcha.com, which developed an API for accessing the samples of the resolved captchas specifically for my research. <br>  It is worth noting that Google does not have a very large set of instructions for captchas (example: Select all images with recreational vehicle) in all major languages ‚Äã‚Äãof the world, and some instructions are much more common.  Further in the article under the type will be meant exactly the instructions for the captcha. <br><br><h2>  Thousands of images </h2><br>  After uploading and sorting a trial batch of images, I began to manually disassemble different types of captchas.  First of all, I built md5 sums from all captcha of one type in the hope of finding a match.  The easiest way did not work - there was simply no coincidence.  Why?  - I have the right! <br>  Strolling through the eyes of the image icons, we found something interesting.  Here, for example, 4 identical limousine: <br><div style="text-align:center;"><img src="https://habrastorage.org/files/abe/833/573/abe8335735524f299e0e91108a030260.png"></div><br>  Identical, but not quite - this is noticeable in the size of the wheels in the lower left corners.  Why were limousines chosen for comparison?  It was easiest to look through their eyes - the pictures of road signs or street names merge into one, and it was easy to search for similar limousines or pickups.  Having appreciated images of different types in my eyes, in many I saw recurring captchas with different deformations - stretching, compression or displacement.  Having found a suitable function of image similarity and having collected a sufficient base, one could hope for some success. <br><br><h4>  Perceptive hash </h4>  Almost all search queries lead to it.  On Habr√©, you can find quite a lot of articles on perceptual hash ( <a href="https://habrahabr.ru/post/205398/">1</a> , <a href="https://habrahabr.ru/post/237307/">2</a> , <a href="https://habrahabr.ru/post/120562/">3</a> , <a href="https://habrahabr.ru/post/219139/">4</a> ).  The python library <a href="https://pypi.python.org/pypi/ImageHash">ImageHash</a> , which uses the NumPy and SciPy packages, was also quickly found. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      How does Perceptive Hash work?  In short: <br><br><pre><code class="python hljs">dct = scipy.fftpack.dct(scipy.fftpack.dct(pixels, axis=<span class="hljs-number"><span class="hljs-number">0</span></span>), axis=<span class="hljs-number"><span class="hljs-number">1</span></span>) dctlowfreq = dct[:hash_size, :hash_size] med = numpy.median(dctlowfreq) diff = dctlowfreq &gt; med</code> </pre> <br><ol><li>  The image is compressed to the size of hash_size. </li><li>  From the value of the resulting pixel is taken discrete Fourier transform. </li><li>  From the Fourier transform is considered the median. </li><li>  The Fourier transform matrix is ‚Äã‚Äãcompared with the median and as a result we get the matrix of zeros and ones. </li></ol><br>  Thus, we can distinguish from the image some invariant that will not change with minor changes in the original image.  Standard hash_size is equal to 8 and it showed itself well on trial comparisons.  One of the remarkable properties of this hash is that they can be compared and their difference looks like a natural number. <br>  Now I will explain.  The image hash is a matrix of zeros or ones (zero is below the median, and one is above).  To find the difference, the matrices are compared element by element and the difference value equals the number of different elements in the same positions.  A sort of XOR on the matrix. <br><br><h2>  Tens of thousands of images </h2><br>  Perceptual hash well defined the similarity between the same limousine, but with different deformations, and the difference between completely different images.  However, the hash is more suitable for describing the forms depicted in the picture: with an increase in the number of caps, matches in the shape of objects are inevitable, but not in the content of the picture (with a certain trigger threshold, of course). <br>  So it happened.  With the increase in the captcha base, there was a growing need to add another comparative value for images. <br>  The objective color characteristic of the image can be described by a histogram of the intensity of colors.  The distance function for two histograms (also known as the difference function) is the sum of the standard deviations of the histogram elements.  Pretty good bunch is obtained. <br><br><div class="spoiler">  <b class="spoiler_title">The paragraph about the selection of the boundaries of the operation and the mechanism for finding similar images</b> <div class="spoiler_text">  The maximum allowable differences for the hashes were set manually: <br><ol><li>  We have trigger thresholds for perceptual hash and histrogram differences: <i>max phash distance</i> and <i>max histogram distance</i> </li><li>  For all images of the same type, we build groups similar, where each captcha corresponds to a pair of numbers ‚Äî the distance to the ‚Äúhead‚Äù of the <i>phash distance</i> and <i>histogram distance groups</i> </li><li>  Open the entire group of images and visually check for errors </li><li>  In the case of false positives, adjust one of the thresholds. </li></ol><br>  In paragraph 1, I mentioned that the group has a ‚Äúchapter‚Äù: When searching for similar images, the captcha is compared not with the entire base, but only with the heads of groups of similar images.  In each group it is guaranteed that all the images are similar with the head, but their similarity with each other is not guaranteed.  This way some winnings in speed. <br>  A little later, I learned about <a href="https://habrahabr.ru/post/120343/">greedy search</a> algorithms, but it was too late.  In theory, such a knee-length algorithm searches for the first, rather than the most appropriate image, as in the greedy search algorithm.  However, this only hinders when searching for all types of instructions at once. <br></div></div><br>  On the one hand, considering the fact that the difference <i>between phash</i> and <i>images</i> that are very close in shape will be zero, and imagining that the percentage of false positives will be low enough, you might think that using only a perceptual hash will be faster than using two hashes.  But what does practice say? <br><br>  For comparison, I used two samples of captcha of different types of 4000 images.  One type has a good "similarity", and the other - on the contrary.  By similarity (she's compressibility) I mean the probability that 2 random images of the same type with given thresholds will be the same in terms of hashes.  The evaluation results are as follows: <br><br><pre> <code class="python hljs">instructions : phash only : both hashes   (  !) : <span class="hljs-number"><span class="hljs-number">0.001</span></span>% : <span class="hljs-number"><span class="hljs-number">0.002</span></span>%  : <span class="hljs-number"><span class="hljs-number">52.97</span></span>% : <span class="hljs-number"><span class="hljs-number">60.12</span></span>%</code> </pre><br>  More than half of the images of limousines are similar to each other, wow!  When using both hashes, the result is still better, but what about the performance? <br><br><pre> <code class="python hljs">instructions : phash only : both hashes   (  !) : <span class="hljs-number"><span class="hljs-number">31.37</span></span>s : <span class="hljs-number"><span class="hljs-number">31.06</span></span>s  : <span class="hljs-number"><span class="hljs-number">17.85</span></span>s : <span class="hljs-number"><span class="hljs-number">17.23</span></span>s</code> </pre><br>  Surprisingly, using both hashes was faster than using only perceptual hash with zero maximum deviation.  Of course, this is due to the difference in the number of image comparison operations, and this, moreover, that comparing a histogram of 300 values ‚Äã‚Äãis slower than comparing perceptual hashes of 8 bytes in size by 28.7%! <br><br><h2>  Hundreds of thousands of images </h2><br>  Performance problems made themselves felt on a really large sample size.  For the most popular types, the search time for similar images on my laptop was already seconds.  Required search optimization with minimal loss of accuracy. <br>  Changing the accuracy of phash didn't seem like a good idea to me.  Therefore, we will look closely at the histogram of the intensity of colors of a captcha: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/a7e/e43/4bb/a7ee434bb0e74bb7a7ff84b2b893ef56.png"></div><br><br>  If I were asked to briefly describe this histogram, then I would say this: ‚ÄúA sharp peak at the abscissa value of 55, then a gradual reduction in the graph and two local minima at 170 and 220‚Äù.  If we take more graphs of histograms from similar caps, then we note that these graphs repeat in form with each other with small errors in the position of maxima and minima (extremes).  So why not use these values ‚Äã‚Äãin order to deliberately cut off the unlike? <br>  Okay Google, how to find extremes in the graph on python? <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> scipy.signal <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> argrelextrema mins = argrelextrema(histogram, np.less)[<span class="hljs-number"><span class="hljs-number">0</span></span>] maxs = argrelextrema(histogram, np.greater)[<span class="hljs-number"><span class="hljs-number">0</span></span>]</code> </pre><br>  The <i>argrelextrema</i> function <i>description</i> says it all: Calculate the relative extrema of data. <br>  However, our histogram is too jagged and there are much more local extremums than necessary.  It is necessary to smooth the function: <br><br><pre> <code class="python hljs">s = numpy.r_[x[window_len<span class="hljs-number"><span class="hljs-number">-1</span></span>:<span class="hljs-number"><span class="hljs-number">0</span></span>:<span class="hljs-number"><span class="hljs-number">-1</span></span>],x,x[<span class="hljs-number"><span class="hljs-number">-1</span></span>:-window_len:<span class="hljs-number"><span class="hljs-number">-1</span></span>]]</code> </pre><br>  We average the graph by the sliding window algorithm.  The window size was chosen experimentally so that the number of minima or maxima was on average 2, and stopped at a value of 100 pixels.  The result of this algorithm is a beautiful, smooth and ... extended schedule.  Extended even on window size. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/50e/6d2/bef/50e6d2bef76a40e3a177ba9cb978453a.png"></div><br>  The positions of extrema shift accordingly: <br><br><pre> <code class="python hljs">mins = array([ <span class="hljs-number"><span class="hljs-number">50</span></span>, <span class="hljs-number"><span class="hljs-number">214</span></span>, <span class="hljs-number"><span class="hljs-number">305</span></span>]) maxs = array([<span class="hljs-number"><span class="hljs-number">116</span></span>, <span class="hljs-number"><span class="hljs-number">246</span></span>])</code> </pre><br><div class="spoiler">  <b class="spoiler_title">Extremum distribution statistics</b> <div class="spoiler_text">  For all the available images with two local minima (or maxima) I summed up the statistics of their positions.  On the graphs there were huge peaks (up to 100x), which, for clarity, had to be shortened. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/eca/459/cfc/eca459cfcea34e95a403c940ee8018fc.png"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/files/2d9/861/993/2d9861993fad4b86abc564b111927098.png"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/files/9b4/a1e/02a/9b4a1e02aaae431aa0f09a362d5493fc.png"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/files/3b9/adb/018/3b9adb018f5a48199e98b35d366c8380.png"></div><br><img align="right" height="100" width="100" src="https://habrastorage.org/files/1c5/ee6/483/1c5ee648372b4a538cd98bdbabb62375.png"><img align="right" height="100" width="100" src="https://habrastorage.org/files/aa3/447/41f/aa344741f278430da7595d5462a668d4.png"><img align="right" height="100" width="100" src="https://habrastorage.org/files/336/da9/e15/336da9e15bae4df9a38536ded23dac28.png">  Extreme graphs can be visually divided into two parts at 101. Why does this happen?  After filtering, it turned out that these are two completely different and almost non-intersecting groups of images, with about 200k images of different types located to the left of the mark.  Such a tricky distribution gives the dark captcha like those on the right.  A similar situation, but with images much lighter, can be observed at the minima. <br></div></div><br>  Comparing many graphs of similar captchas, I found that the allowable deviation from the positions of local extremes would be 3-4 pixels.  By adjusting this value downwards, greater filtering and acceleration of the algorithm can be achieved by decreasing compressibility. <br><br>  Of course, there could be recognition errors in the captcha from RuCaptcha.  To combat them, a captcha rating system was introduced.  If the md5 of the new captcha is already contained in the database, but with a different type of instruction, then the old captcha increases the <i>failure</i> counter, and if the type of the old captcha coincides with the new one, then the <i>popularity</i> counter increases.  Thus, a natural adjustment of wrong decisions is introduced - when looking for similar ones, only captchas with <i>popularity&gt; failure</i> are taken into account. <br><br><h2>  My first million </h2><br>  For all the time of research work, more than a million solved caps were collected.  For data storage, the PostgreSQL database was used, in which it was convenient to store hashes and histogram value arrays.  Speaking of histogram storage - to calculate the distance between two histograms, it is not necessary to store all <i>255 + window_size</i> values.  When using half or even a third of the array values, the accuracy of the distance drops slightly, but it saves disk space. <br><br>  For this sample captcha statistics will be very accurate. <br>  Below are data on the most ‚Äúcompressible‚Äù and most popular captcha (3 lines each): <br><br><pre> <code class="python hljs">       (%)  <span class="hljs-number"><span class="hljs-number">15274</span></span> <span class="hljs-number"><span class="hljs-number">5508</span></span> <span class="hljs-number"><span class="hljs-number">64</span></span>   <span class="hljs-number"><span class="hljs-number">2453</span></span> <span class="hljs-number"><span class="hljs-number">928</span></span> <span class="hljs-number"><span class="hljs-number">62</span></span>  <span class="hljs-number"><span class="hljs-number">5261</span></span> <span class="hljs-number"><span class="hljs-number">2067</span></span> <span class="hljs-number"><span class="hljs-number">61</span></span>   (  !) <span class="hljs-number"><span class="hljs-number">201872</span></span> <span class="hljs-number"><span class="hljs-number">189473</span></span> <span class="hljs-number"><span class="hljs-number">6</span></span>    <span class="hljs-number"><span class="hljs-number">137893</span></span> <span class="hljs-number"><span class="hljs-number">134695</span></span> <span class="hljs-number"><span class="hljs-number">2</span></span>    <span class="hljs-number"><span class="hljs-number">94569</span></span> <span class="hljs-number"><span class="hljs-number">92824</span></span> <span class="hljs-number"><span class="hljs-number">2</span></span></code> </pre><br>  <a href="https://ru.wikipedia.org/wiki/%25D0%2597%25D0%25B0%25D0%25BA%25D0%25BE%25D0%25BD_%25D0%259F%25D0%25B0%25D1%2580%25D0%25B5%25D1%2582%25D0%25BE">Pareto's law</a> in its pure form: 11% of instructions give ~ 80% of all captcha (and 20% of instructions give 91% of all captcha).  And statistics is not in favor of the most compressible types. <br><br>  <a href="https://www.google.com/recaptcha/intro/index.html">Google itself</a> says so: <br>  <i>CAPTCHA reCAPTCHA</i> <i><br></i>  <i>Every time our CAPTCHAs are solved, that human effort helps to digitize the text, annotate images, and build it up.</i>  <i>Maps, and solve hard AI problems.</i> <br><br>  Hinting that through the decision of captchas by people he ensures their automatic rotation.  Google made a bid for a small set of instructions with a good level of image rotation, such as road signs or street names. <br><br><img align="left" width="230" height="340" src="https://habrastorage.org/files/5d2/31c/61a/5d231c61ad7a42ecb2d07b2b807f3e4b.png">  The task did not include an item about checking for a real Google reCaptcha, so as an alternative, I will use the following algorithm for all new training images: <br><ol><li>  The input is captcha 3x3 or 4x4 and is divided into 9 or 16 images, respectively. </li><li>  According to the algorithms described above, for all 9 or 16 images, a similar one is selected for <b>ALL</b> types in the database </li><li>  Image indices of the found solution are compared with the indices of the reference solution. </li><li>  If the difference (the number of different indices) between solutions is 50% or more, then the captcha is considered unsolved. </li></ol><br>  In the example to the left, if the data from the database (automatic solution) says that the correct indices are 0, 1, 3, and the reference solution is 0, 1, 4, then the indices differ by indices 3 and 4. In this example, 2 matching and 2 different index, i.e.  captcha is not solved. <br><br>  Since in most caps 3x3 3 (+ -1) indexes are correct, such an algorithm will give similar results as on natural <i>reCaptcha</i> . <br>  In paragraph 2, the solution could be selected in different ways: <br><ul><li>  For each image, do a search on <b>ALL</b> image types in the database and then select only those that correspond to the type of instruction.  This approach will allow you to find out the statistics of the decisions and on the non-target images too, and also check the effect of false positives on the accuracy of the decisions. </li><li>  For each image search only one type of instruction.  Such a search is much faster and does not give false positives from the first method in principle. </li></ul><br>  Below is collected the dynamics of the results of solving for several days: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/b17/b6c/96f/b17b6c96f97541649eb8f93ab5c5afb3.png"></div><br>  On average, the assembled system guessed google captchas with a probability of 12.5%, thereby leading a weighty argument in favor of Google solutions. <br><br>  To my surprise, the leader in the number of solutions was one of the most poorly compressed captcha (statistics for several samples): <br><br><pre> <code class="python hljs">   (%)  (%)    <span class="hljs-number"><span class="hljs-number">142</span></span> <span class="hljs-number"><span class="hljs-number">14.03</span></span> <span class="hljs-number"><span class="hljs-number">2</span></span>   (  !) <span class="hljs-number"><span class="hljs-number">80</span></span> <span class="hljs-number"><span class="hljs-number">7.91</span></span> <span class="hljs-number"><span class="hljs-number">6</span></span>  <span class="hljs-number"><span class="hljs-number">68</span></span> <span class="hljs-number"><span class="hljs-number">6.72</span></span> <span class="hljs-number"><span class="hljs-number">40</span></span>  (   ) <span class="hljs-number"><span class="hljs-number">58</span></span> <span class="hljs-number"><span class="hljs-number">5.73</span></span> <span class="hljs-number"><span class="hljs-number">43</span></span>   (  ) <span class="hljs-number"><span class="hljs-number">58</span></span> <span class="hljs-number"><span class="hljs-number">5.73</span></span> <span class="hljs-number"><span class="hljs-number">43</span></span>   <span class="hljs-number"><span class="hljs-number">57</span></span> <span class="hljs-number"><span class="hljs-number">5.63</span></span> <span class="hljs-number"><span class="hljs-number">43</span></span></code> </pre><br>  And there were slightly more non-targeted caps (55%) than target (45%).  Target captchas are those whose images when searching among the entire database (and not just for one type of instruction) are successfully found and their type corresponds to the type of captcha instruction.  In other words - there are 3 images with limousines and 3.66 images with any other types in the average 3x3 captcha for limousines. <br><br>  The study showed that, based on the perceptual hash and color histograms, it is impossible to build a captcha solution system, even using huge training samples.  This <i>reCapthca</i> result <i>is</i> achieved due to the proper rotation of the most popular types of caps. <br><br>  I am grateful to RuCaptcha for the pleasant communication and, with their permission, spread the training sample into the open access to the yandex disk (hurry to download, the disc is paid for a month): <br><ol><li>  <a href="https://yadi.sk/d/CNJQ5uOwqfykL">yadi.sk/d/CNJQ5uOwqfykL</a> </li><li>  <a href="https://yadi.sk/d/gnTU-qwnqfykM">yadi.sk/d/gnTU-qwnqfykM</a> </li><li>  <a href="https://yadi.sk/d/6vTTjhJaqfykV">yadi.sk/d/6vTTjhJaqfykV</a> </li></ol>  Yandex disk does not know how to download files larger than 10 gigabytes, therefore, researchers are faced with the task of gluing a tar archive of 3 parts. <br><br>  My thoughts on machine learning don't leave me on the same sample :) In the meantime, I am sharing the <a href="https://github.com/ajaxtpm/reCaptcha">source code of the</a> system in python. </div><p>Source: <a href="https://habr.com/ru/post/280812/">https://habr.com/ru/post/280812/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../280800/index.html">Site links in Active Directory. We destroy the stereotype</a></li>
<li><a href="../280802/index.html">The digest of interesting materials from the world of Drupal # 19</a></li>
<li><a href="../280804/index.html">The effect of shirts on mobile shaders</a></li>
<li><a href="../280806/index.html">SSO for beauty and monster</a></li>
<li><a href="../280810/index.html">Use an Intel RealSense camera with TouchDesigner. Part 1</a></li>
<li><a href="../280814/index.html">Framework fastcgi container</a></li>
<li><a href="../280816/index.html">About the UHD-resolution restaurant table and other interactive technologies from Kodisoft</a></li>
<li><a href="../280818/index.html">As I wrote the library under IEC 870-5-104 on Arduino using Wireshark</a></li>
<li><a href="../280820/index.html">The digest of interesting materials from the world of MODX # 1</a></li>
<li><a href="../280822/index.html">Reading large amounts of data in Python / Postgresql</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>