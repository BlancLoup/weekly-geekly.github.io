<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Neural networks for dummies. Start</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="It so happened that at the university the topic of neural networks successfully passed my specialty, despite the great interest on my part. Attempts o...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Neural networks for dummies. Start</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/storage2/fff/111/d8f/fff111d8f4aec1900edbf40a8bbfed9d.png"><br><br>  It so happened that at the university the topic of neural networks successfully passed my specialty, despite the great interest on my part.  Attempts of self-education were several times broken by an ignorant brow on the indestructible walls of the citadel of science in the guise of incomprehensible terms and confusing explanations in the dry language of university textbooks. <br><br>  In this article (a series of articles?) I will try to highlight the topic of neural networks from the point of view of the uninitiated person, in simple language, with simple examples, putting everything on the shelves, and not ‚Äúa neuron array forms a perceptron that works according to a well-known, proven scheme‚Äù. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Interested please under the cat. <br><a name="habracut"></a><br><h5>  Goals </h5><br>  What are neural networks for? <br>  A neural network is a learning system.  It acts not only in accordance with a given algorithm and formulas, but also on the basis of past experience.  A sort of child who each time adds a puzzle, making fewer and fewer mistakes. <br><br>  And, as is customary to write in fashionable authors, a neural network consists of neurons. <br>  Here you need to make a stop and figure it out. <br><img src="https://habrastorage.org/storage2/aac/7ff/6e4/aac7ff6e4fc53133990508637ec0dd2d.png"><br><br>  Let's agree that a neuron is just some kind of imaginary black box, which has a bunch of inlets and one exit. <br>  Moreover, both incoming and outgoing information can be analog (most often it will be so). <br><br>  How the output signal is formed from the heap input - defines the internal algorithm of the neuron. <br><br>  For example, we will write a small program that will recognize simple images, say, the letters of the Russian language on raster images. <br>  We agree that in the initial state our system will have an ‚Äúempty‚Äù memory, i.e.  a kind of newborn brain, ready for battle. <br>  In order to make it work correctly, we will need to spend time learning. <br><br>  Dodging the tomatoes flying into me, I will say that we will write in Delphi (at the time of writing this article was at hand).  If the need arises, I will help translate the example into other languages. <br><br>  I also ask you to take the quality of the code lightly - the program was written in an hour, just to deal with the topic, such code is hardly applicable for serious tasks. <br><br>  So, based on the task - how many options can there be?  That's right, as many letters as we will be able to identify.  There are only 33 of them in the alphabet, so let's stop. <br><br>  Next, we will define the input data. In order not to bother too much - we will feed the input bitmap 30x30 as a bitmap: <br><img src="https://habrastorage.org/storage2/c47/09c/2b5/c4709c2b5682bf6e0bcaa58c7b796fd6.png"><br><br>  In the end, you need to create 33 neurons, each of which will have 30x30 = 900 inputs. <br>  Create a class for our neuron: <br><br><pre><code class="delphi hljs"><span class="hljs-keyword"><span class="hljs-keyword">type</span></span> Neuron = <span class="hljs-keyword"><span class="hljs-keyword">class</span></span> <span class="hljs-keyword"><span class="hljs-keyword">name</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">string</span></span>; <span class="hljs-comment"><span class="hljs-comment">//    ‚Äì ,     input: array[0..29,0..29] of integer; //    3030 output:integer; //    ,   memory:array[0..29,0..29] of integer; //         end;</span></span></code> </pre> <br><br>  Create an array of neurons, by the number of letters: <br><br><pre> <code class="delphi hljs"><span class="hljs-keyword"><span class="hljs-keyword">For</span></span> i:=<span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> <span class="hljs-number"><span class="hljs-number">32</span></span> <span class="hljs-keyword"><span class="hljs-keyword">do</span></span> <span class="hljs-keyword"><span class="hljs-keyword">begin</span></span> neuro_web[i]:=Neuron.Create; neuro_web[i].output:=<span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-comment"><span class="hljs-comment">//    neuro_web[i].name:=chr(Ord('A')+i); //      end;</span></span></code> </pre><br><br>  Now the question is where will we store the ‚Äúmemory‚Äù of the neural network when the program is not working? <br>  In order not to go deep into INI or, God forbid, databases, I decided to store them in the same 30x30 bitmap images. <br>  Here, for example, the memory of the neuron "K" after running the program in different fonts: <br><br><img width="100" src="https://habrastorage.org/storage2/229/f5a/8c4/229f5a8c436e874c13ae929752e94e8a.png"><br><br>  As can be seen, the most saturated areas correspond to the most frequently encountered pixels. <br>  We will load ‚Äúmemory‚Äù into each neuron when it is created: <br><pre> <code class="delphi hljs">p:=TBitmap.Create; p.LoadFromFile(ExtractFilePath(Application.ExeName)+<span class="hljs-string"><span class="hljs-string">'\res\'</span></span>+ neuro_web[i].<span class="hljs-keyword"><span class="hljs-keyword">name</span></span>+<span class="hljs-string"><span class="hljs-string">'.bmp'</span></span>)</code> </pre><br><br>  At the beginning of the untrained program, the memory of each neuron will be a white spot 30x30. <br><br>  The neuron will recognize this: <br><br>  - Take the 1st pixel <br>  - Compare it with 1m pixel in memory (there is a value of 0..255) <br>  - Compare the difference with a certain threshold <br>  - If the difference is less than the threshold - we believe that at this point the letter is similar to the one in memory, add +1 to the weight of the neuron. <br><br>  And so on all the pixels. <br><br>  The weight of a neuron is a certain number (up to 900 in theory), which is determined by the degree of similarity of the processed information with the stored in memory. <br>  At the end of the recognition we will have a set of neurons, each of which believes that he is right for some percent.  These percentages are the weight of the neuron.  The greater the weight, the more likely that this particular neuron is right. <br><br>  Now we will feed the program an arbitrary image and run through each neuron through it: <br><br><pre> <code class="delphi hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> x:=<span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> <span class="hljs-number"><span class="hljs-number">29</span></span> <span class="hljs-keyword"><span class="hljs-keyword">do</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> y:=<span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> <span class="hljs-number"><span class="hljs-number">29</span></span> <span class="hljs-keyword"><span class="hljs-keyword">do</span></span> <span class="hljs-keyword"><span class="hljs-keyword">begin</span></span> n:=neuro_web[i].memory[x,y]; m:=neuro_web[i].input[x,y]; <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> ((abs(mn)&lt;<span class="hljs-number"><span class="hljs-number">120</span></span>)) <span class="hljs-keyword"><span class="hljs-keyword">then</span></span> <span class="hljs-comment"><span class="hljs-comment">//    if m&lt;250 then neuro_web[i].weight:=neuro_web[i].weight+1; //  ,     ,        if m&lt;&gt;0 then begin if m&lt;250 then n:=round((n+(n+m)/2)/2); neuro_web[i].memory[x,y]:=n; end else if n&lt;&gt;0 then if m&lt;250 then n:=round((n+(n+m)/2)/2); neuro_web[i].memory[x,y]:=n; end;</span></span></code> </pre><br><br>  As soon as the cycle for the last neuron ends, we choose from all the one that has more weight: <br><br><pre> <code class="delphi hljs"><span class="hljs-keyword"><span class="hljs-keyword">if</span></span> neuro_web[i].weight&gt;max <span class="hljs-keyword"><span class="hljs-keyword">then</span></span> <span class="hljs-keyword"><span class="hljs-keyword">begin</span></span> max:=neuro_web[i].weight; max_n:=i; <span class="hljs-keyword"><span class="hljs-keyword">end</span></span>;</code> </pre><br><br>  It is for this max_n value that the program will tell us what, in its opinion, we have slipped to it. <br>  At first, this will not always be true, so you need to make a learning algorithm. <br><br><pre> <code class="delphi hljs">s:=InputBox(<span class="hljs-string"><span class="hljs-string">'Enter the letter'</span></span>, <span class="hljs-string"><span class="hljs-string">' ,    '</span></span>+neuro_web[max_n].<span class="hljs-keyword"><span class="hljs-keyword">name</span></span>, neuro_web[max_n].<span class="hljs-keyword"><span class="hljs-keyword">name</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i:=<span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> <span class="hljs-number"><span class="hljs-number">32</span></span> <span class="hljs-keyword"><span class="hljs-keyword">do</span></span> <span class="hljs-keyword"><span class="hljs-keyword">begin</span></span> <span class="hljs-comment"><span class="hljs-comment">//   if neuro_web[i].name=s then begin //     for x:=0 to 29 do begin for y:=0 to 29 do begin p.Canvas.Pixels[x,y]:=RGB(neuro_web[i].memory[x,y],neuro_web[i].memory[x,y], neuro_web[i].memory[x,y]); //     end; end; p.SaveToFile(ExtractFilePath(Application.ExeName)+'\res\'+ neuro_web[i].name+'.bmp');</span></span></code> </pre><br><br>  The memory update itself will do this: <br><br><pre> <code class="delphi hljs">n:=round(n+(n+m)/<span class="hljs-number"><span class="hljs-number">2</span></span>);</code> </pre><br><br>  Those.  if this point in the memory of a neuron is missing, but the teacher says that it is in this letter - we remember it, but not completely, but only half.  With further study, the impact of this lesson will increase. <br><br>  Here are a few iterations for the letter G: <br><br><img src="http://habrastorage.org/storage2/2e3/ebb/d41/2e3ebbd411de50fe89f9a6bb30871b6f.png"><img src="http://habrastorage.org/storage2/c31/c1f/ff0/c31c1fff051a0057cd3eb7aa6980482c.png"><img src="http://habrastorage.org/storage2/a0a/d6d/57d/a0ad6d57d05ca738e54b4bd72c867b2f.png"><img src="http://habrastorage.org/storage2/78a/10d/bf0/78a10dbf07aedc7e10a5ae2d59b5daab.png"><br><br>  At this, our program is ready. <br><br><h5>  Training </h5><br>  Let's start learning. <br>  We open the images of the letters and patiently point the program at its errors: <br><br><img src="http://habrastorage.org/storage2/463/24d/474/46324d474bd33904eec431000d9ebc67.png"><br><br>  After some time, the program will begin to stably identify even letters that are not familiar to it earlier: <br><br><img src="http://habrastorage.org/storage2/446/441/bba/446441bba07a6f081b397ae0eb2961dc.png"><br><br><h5>  Conclusion </h5><br>  The program is one continuous flaw - our neural network is very stupid, it is not protected from user errors during training, and the recognition algorithms are simple as a stick. <br>  But it gives basic knowledge about the functioning of neural networks. <br><br>  If this article is of interest to respected habravchan, I will continue the cycle, gradually complicating the system, introducing additional links and weights, consider some of the popular neural network architectures, etc. <br><br>  You can mock our freshly born intellect by downloading the program along with the source code <a href="">here</a> . <br><br>  For this I will take my leave, thanks for reading. <br><br>  <b>UPD:</b> We got a blank for the neural network.  So far it is not yet, but in the next article we will try to make it a full-fledged neural network. <br>  Thank you <a href="http://habrahabr.ru/users/Shultc/">Shultc</a> for the comment. </div><p>Source: <a href="https://habr.com/ru/post/143129/">https://habr.com/ru/post/143129/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../143119/index.html">+1 extension for Mozilla Firefox</a></li>
<li><a href="../143122/index.html">Facebook allows you to specify whether the account owner agrees to donate internal organs</a></li>
<li><a href="../143123/index.html">The first tablet on Windows 8 from HP</a></li>
<li><a href="../143124/index.html">Podcast "Notes on Qt" s01e03</a></li>
<li><a href="../143127/index.html">Extending Ruby with Ruby: borrowing Python function decorators</a></li>
<li><a href="../143130/index.html">Leisure Suit Larry will come again!</a></li>
<li><a href="../143131/index.html">+1 extension for Opera</a></li>
<li><a href="../143133/index.html">Electricity and water from the air - we descend from heaven to earth</a></li>
<li><a href="../143134/index.html">The company RIM introduced the OS BlackBerry 10</a></li>
<li><a href="../143135/index.html">Personal approach</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>