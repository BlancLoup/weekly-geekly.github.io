<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>AMD APP SDK: Compute Abstraction Layer (CAL)</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="In the first part, I talked about AMD Intermediate Language (IL) technology. In this article, as you can guess from the title, we will discuss the sec...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>AMD APP SDK: Compute Abstraction Layer (CAL)</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/storage2/0b1/efd/1f9/0b1efd1f9889a4d5688c3d6910ff3701.png" alt="AMD APP" title="AMD Accelerated Parallel Processing" align="right">  In the <a href="http://habrahabr.ru/blogs/hi/138954/" title="AMD Intermediate Language (IL)">first part,</a> I talked about AMD Intermediate Language (IL) technology.  In this article, as you can guess from the title, we will discuss the second component: AMD Compute Abstraction Layer (CAL).  These two technologies are inseparable from each other: it is impossible to use one without using the other.  Therefore, for further understanding I recommend to familiarize with the first part. <br><br>  I will try to highlight the main aspects of work at the top level with an AMD GPU, I will describe the limitations of this technology and possible problems when working with it.  Who cares, I ask under the cat. <br><br><a name="habracut"></a><h2>  Instead of introducing </h2><br>  <i>When I first started to deal with programming under AMD GPU, I was asked what I use for this.</i>  <i>"ATI <abbr title="Compute Abstraction Layer">CAL</abbr> " - I replied.</i>  <i>‚ÄúYes, ATI is really <abbr title="Compute Abstraction Layer">CAL</abbr> ‚Äù - was my answer.</i> <br>  In general, I do not know how to pronounce the abbreviation <abbr title="Compute Abstraction Layer">CAL</abbr> , but I pronounce it through ‚ÄúO‚Äù so as not to embarrass people. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      For brevity, we denote the program described in the first part by <i>the kernel</i> .  Under the kernel, I will mean both the source code of the program and the compiled binary code that is loaded onto the GPU.  I will not give the full text of any program that works with the GPU through the AMD <abbr title="Compute Abstraction Layer">CAL</abbr> , but just tell you about the main points of the work: <br><ul><li>  driver initialization </li><li>  getting information on all supported GPUs </li><li>  memory allocation and copying </li><li>  compiling and loading the kernel on the GPU </li><li>  kernel launch </li><li>  synchronization with the CPU </li></ul><br>  To get started, we need two header files from the AMD <abbr title="Accelerated Parallel Processing">APP</abbr> SDK: <br><ul><li>  <b>cal.h</b> - describes the basic functions of the driver, the functions have the prefix <i>"cal"</i> (library aticalrt.dll) </li><li>  <b>calcl.h</b> - describes the main functions of the text core compiler in binary code, the functions have the prefix <i>"calcl"</i> (library aticalcl.dll) </li></ul><br>  As you can see, unlike Nvidia CUDA, which has a Run-time <abbr title="Application programming interface">API</abbr> and Driver <abbr title="Application programming interface">API</abbr> , only Driver <abbr title="Application programming interface">API is</abbr> available for AMD.  Therefore, for your application to work, do not forget to link to the appropriate libraries. <br><br>  Most called functions return a value of type CALresult.  A total of 11 return codes are available.  The most important for us is the code CAL_RESULT_OK, equal to 0 (indicating the successful completion of the call). <br><br>  So let's go. <br><br><h2>  Driver initialization </h2><br>  <b>Rule number 1:</b> before starting work with the GPU, <s>wash your hands,</s> initialize the driver with the following call: <br><pre><code class="cpp hljs">CALresult result = calInit();</code> </pre> <br>  <b>Rule number 2:</b> after working with the GPU, do not forget to <s>wash away to</s> complete the work correctly.  This is done by the following call: <br><pre> <code class="cpp hljs">CALresult result = calShutdown();</code> </pre><br>  These two calls should always be paired.  There may be several of them (such pairs of calls) in the program, but never work with the GPU outside of these calls: this behavior may entail a <i>hardware exception</i> . <br><br><h2>  Getting GPU info </h2><br>  Find out the number of <i>supported</i> GPUs (they can be less than the total number of AMD GPUs in the system): <br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">unsigned</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> deviceCount = <span class="hljs-number"><span class="hljs-number">0</span></span>; CALresult result = calDeviceGetCount( &amp;deviceCount );</code> </pre><br>  In this article I will indicate where the GPU identifier is used, but I will work with the GPU under identifier 0. In general, this identifier takes values ‚Äã‚Äãfrom 0 to (deviceCount-1). <br><br>  Find out information about the GPU: <br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">unsigned</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> deviceId = <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-comment"><span class="hljs-comment">//  GPU CALdeviceinfo deviceInfo; CALresult result = calDeviceGetInfo( &amp;deviceInfo, deviceId ); CALdeviceattribs deviceAttribs; deviceAttribs.struct_size = sizeof( deviceAttribs ); CALresult result = calDeviceGetAttribs( &amp;deviceAttribs, deviceId );</span></span></code> </pre><br>  The most important thing in the CALdeviceinfo structure is the identifier of the GPU chip.  It is here called Device Kernel <abbr title="Instruction Set Architecture">ISA</abbr> : <br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">typedef</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">struct</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">CALdeviceinfoRec</span></span></span><span class="hljs-class"> {</span></span> CALtarget target; <span class="hljs-comment"><span class="hljs-comment">/**&lt; Device Kernel ISA */</span></span> CALuint maxResource1DWidth; <span class="hljs-comment"><span class="hljs-comment">/**&lt; Maximum resource 1D width */</span></span> CALuint maxResource2DWidth; <span class="hljs-comment"><span class="hljs-comment">/**&lt; Maximum resource 2D width */</span></span> CALuint maxResource2DHeight; <span class="hljs-comment"><span class="hljs-comment">/**&lt; Maximum resource 2D height */</span></span> } CALdeviceinfo;</code> </pre><br>  The remaining fields of the structure determine the maximum size of the texture memory by two coordinates, which can be allocated on this GPU. <br><br>  Much more interesting is the CALdeviceattribs structure, which is responsible for the attributes of the GPU (I will give only a few structure fields): <br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">typedef</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">struct</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">CALdeviceattribsRec</span></span></span><span class="hljs-class"> {</span></span> CALtarget target; <span class="hljs-comment"><span class="hljs-comment">/**&lt; Asic identifier (  Device Kernel ISA) */</span></span> CALuint localRAM; <span class="hljs-comment"><span class="hljs-comment">/**&lt;   GPU RAM   */</span></span> CALuint wavefrontSize; <span class="hljs-comment"><span class="hljs-comment">/**&lt;  warp'a (      ) */</span></span> CALuint numberOfSIMD; <span class="hljs-comment"><span class="hljs-comment">/**&lt;   */</span></span> CALboolean computeShader; <span class="hljs-comment"><span class="hljs-comment">/**&lt;   Compute Shader */</span></span> CALuint pitch_alignment; <span class="hljs-comment"><span class="hljs-comment">/**&lt;        calCreateRes */</span></span> <span class="hljs-comment"><span class="hljs-comment">/*   */</span></span> } CALdeviceattribs;</code> </pre><br>  <b>Rule number 3:</b> field CALdeviceattribs.pitch_alignment is measured in <b>memory elements</b> , and not in bytes.  The memory element is a 1, 2 or 4 component vector of 8, 16 or 32 bit registers. <br><br>  And now let's take a close look at what values ‚Äã‚Äãthe CALdeviceinfo.target field can take (it is CALdeviceattribs.target): <br><pre> <code class="cpp hljs"><span class="hljs-comment"><span class="hljs-comment">/** Device Kernel ISA */</span></span> <span class="hljs-keyword"><span class="hljs-keyword">typedef</span></span> <span class="hljs-keyword"><span class="hljs-keyword">enum</span></span> CALtargetEnum { CAL_TARGET_600, <span class="hljs-comment"><span class="hljs-comment">/**&lt; R600 GPU ISA */</span></span> CAL_TARGET_610, <span class="hljs-comment"><span class="hljs-comment">/**&lt; RV610 GPU ISA */</span></span> CAL_TARGET_630, <span class="hljs-comment"><span class="hljs-comment">/**&lt; RV630 GPU ISA */</span></span> CAL_TARGET_670, <span class="hljs-comment"><span class="hljs-comment">/**&lt; RV670 GPU ISA */</span></span> CAL_TARGET_7XX, <span class="hljs-comment"><span class="hljs-comment">/**&lt; R700 class GPU ISA */</span></span> CAL_TARGET_770, <span class="hljs-comment"><span class="hljs-comment">/**&lt; RV770 GPU ISA */</span></span> CAL_TARGET_710, <span class="hljs-comment"><span class="hljs-comment">/**&lt; RV710 GPU ISA */</span></span> CAL_TARGET_730, <span class="hljs-comment"><span class="hljs-comment">/**&lt; RV730 GPU ISA */</span></span> CAL_TARGET_CYPRESS, <span class="hljs-comment"><span class="hljs-comment">/**&lt; CYPRESS GPU ISA */</span></span> CAL_TARGET_JUNIPER, <span class="hljs-comment"><span class="hljs-comment">/**&lt; JUNIPER GPU ISA */</span></span> CAL_TARGET_REDWOOD, <span class="hljs-comment"><span class="hljs-comment">/**&lt; REDWOOD GPU ISA */</span></span> CAL_TARGET_CEDAR, <span class="hljs-comment"><span class="hljs-comment">/**&lt; CEDAR GPU ISA */</span></span> CAL_TARGET_RESERVED0, CAL_TARGET_RESERVED1, CAL_TARGET_WRESTLER, <span class="hljs-comment"><span class="hljs-comment">/**&lt; WRESTLER GPU ISA */</span></span> CAL_TARGET_CAYMAN, <span class="hljs-comment"><span class="hljs-comment">/**&lt; CAYMAN GPU ISA */</span></span> CAL_TARGET_RESERVED2, CAL_TARGET_BARTS, <span class="hljs-comment"><span class="hljs-comment">/**&lt; BARTS GPU ISA */</span></span> } CALtarget;</code> </pre><br>  It turns out that this field indicates the chip on which the GPU is built.  Thus, it‚Äôs impossible to find out exactly how the GPU in the world is called (for example, Radeon HD 3850) with the help of AMD <abbr title="Compute Abstraction Layer">CAL</abbr> !  This is such a convenient technology ... But it was interesting to observe that, for example, the Radeon HD 5750 and Radeon HD 6750 are actually the same video card!  They differ only slightly in the frequency of memory (within a few percent). <br><br>  Another note: in this list there is no Evergreen GPU, which I mentioned in the first part.  My guess is that the Evergreen family of GPUs start with a Cypress chip (CAL_TARGET_CYPRESS).  All that was before was the previous generation without the support of new buns (cyclic shift, support for operation flags and 64-bit operations). <br><br>  For further work, we need to create a device descriptor (device) with which we will interact with the GPU: <br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">unsigned</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> deviceId = <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-comment"><span class="hljs-comment">//  GPU CALdevice device; CALresult result = calDeviceOpen( &amp;device, deviceId ); CALcontext context; result = calCtxCreate( &amp;context, device );</span></span></code> </pre><br>  Context is required to work within your application with this GPU.  All work with the GPU is done using this context.  As soon as you delete the context, all allocated resources are considered to be freed, and all unfinished tasks on the GPU are forcibly terminated. <br><br>  Do not forget about the pair calls after finishing work with the device: <br><pre> <code class="cpp hljs">calCtxDestroy( context ); calDeviceClose( device );</code> </pre><br>  Calls must go in exactly this order, otherwise we get a <i>hardware exception</i> . <br><br>  So, we have created a device and context for it, now we can proceed to <br><br><h2>  Memory allocation </h2><br>  To work with memory, you need to allocate a <i>resource</i> .  According to the documentation, the resource can be located in local memory (local memory = stream processor memory) and remote memory (remote memory = system memory).  As I understand it, remote memory is nothing but RAM, while local memory is the memory of the GPU itself. <br><br>  Why do I need remote memory if there is a local memory?  First, it is needed to share the same memory among multiple GPUs.  That is, remote memory can be allocated once and work with it from several GPUs.  Secondly, not all GPUs support direct access to their memory (see <i>‚ÄúObtaining direct memory access‚Äù</i> below). <br><br><pre> <code class="cpp hljs">CALresource resource; <span class="hljs-keyword"><span class="hljs-keyword">unsigned</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> memoryWidth; <span class="hljs-keyword"><span class="hljs-keyword">unsigned</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> memoryHight; CALformat memoryFormat; <span class="hljs-keyword"><span class="hljs-keyword">unsigned</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> flags; <span class="hljs-comment"><span class="hljs-comment">//      // 1D  CALresult result = calResAllocRemote1D( &amp;resource, &amp;device, 1, memoryWidth, memoryFormat, flags ); /*         GPU,    -     ,   -      (1   ) */ // 2D  CALresult result = calResAllocRemote2D( &amp;resource, &amp;device, 1, memoryWidth, memoryHeight, memoryFormat, flags ); //      // 1D  CALresult result = calResAllocLocal1D( &amp;resource, device, memoryWidth, memoryFormat, flags ); /*  ,       ,       */ // 2D  CALresult result = calResAllocLocal2D( &amp;resource, device, memoryWidth, memoryHeight, memoryFormat, flags );</span></span></code> </pre><br>  The width and height of the allocated resource is measured in memory <b>elements</b> . <br>  The memory element itself is described by the memoryFormat parameter: <br><pre> <code class="cpp hljs"><span class="hljs-comment"><span class="hljs-comment">//  ,         /** Data format representation */ typedef enum CALformatEnum { CAL_FORMAT_UNORM_INT8_1, /**&lt; 1 component, normalized unsigned 8-bit integer value per component */ CAL_FORMAT_UNORM_INT8_4, /**&lt; 4 component, normalized unsigned 8-bit integer value per component */ CAL_FORMAT_UNORM_INT32_1, /**&lt; 1 component, normalized unsigned 32-bit integer value per component */ CAL_FORMAT_UNORM_INT32_4, /**&lt; 4 component, normalized unsigned 32-bit integer value per component */ CAL_FORMAT_SNORM_INT8_1, /**&lt; 1 component, normalized signed 8-bit integer value per component */ CAL_FORMAT_SNORM_INT8_4, /**&lt; 4 component, normalized signed 8-bit integer value per component */ CAL_FORMAT_SNORM_INT32_1, /**&lt; 1 component, normalized signed 32-bit integer value per component */ CAL_FORMAT_SNORM_INT32_4, /**&lt; 4 component, normalized signed 32-bit integer value per component */ CAL_FORMAT_UNSIGNED_INT8_1, /**&lt; 1 component, unnormalized unsigned 8-bit integer value per component */ CAL_FORMAT_UNSIGNED_INT8_4, /**&lt; 4 component, unnormalized unsigned 8-bit integer value per component */ CAL_FORMAT_SIGNED_INT8_1, /**&lt; 1 component, unnormalized signed 8-bit integer value per component */ CAL_FORMAT_SIGNED_INT8_4, /**&lt; 4 component, unnormalized signed 8-bit integer value per component */ CAL_FORMAT_UNSIGNED_INT32_1, /**&lt; 1 component, unnormalized unsigned 32-bit integer value per component */ CAL_FORMAT_UNSIGNED_INT32_4, /**&lt; 4 component, unnormalized unsigned 32-bit integer value per component */ CAL_FORMAT_SIGNED_INT32_1, /**&lt; 1 component, unnormalized signed 32-bit integer value per component */ CAL_FORMAT_SIGNED_INT32_4, /**&lt; 4 component, unnormalized signed 32-bit integer value per component */ CAL_FORMAT_UNORM_SHORT_565, /**&lt; 3 component, normalized 5-6-5 RGB image. */ CAL_FORMAT_UNORM_SHORT_555, /**&lt; 4 component, normalized x-5-5-5 xRGB image */ CAL_FORMAT_UNORM_INT10_3, /**&lt; 4 component, normalized x-10-10-10 xRGB */ CAL_FORMAT_FLOAT32_1, /**&lt; A 1 component, 32-bit float value per component */ CAL_FORMAT_FLOAT32_4, /**&lt; A 4 component, 32-bit float value per component */ CAL_FORMAT_FLOAT64_1, /**&lt; A 1 component, 64-bit float value per component */ CAL_FORMAT_FLOAT64_2, /**&lt; A 2 component, 64-bit float value per component */ } CALformat;</span></span></code> </pre><br>  It is a pity that 64-bit operations on old video cards (not Evergreen) can be performed only with float data ... <br><br>  <b>Rule number 4:</b> the element format describes only the way in which the GPU will interpret the data lying in this element.  Physically, an element always occupies <b>16</b> bytes of memory. <br><br>  This can be understood if we recall that in the first part we described the resource as follows: <br><pre> <code class="hljs lisp">dcl_resource_id(<span class="hljs-number"><span class="hljs-number">0</span></span>)_type(<span class="hljs-number"><span class="hljs-number">2</span></span>d,unnorm)_fmtx(<span class="hljs-name"><span class="hljs-name">uint</span></span>)_fmty(<span class="hljs-name"><span class="hljs-name">uint</span></span>)_fmtz(<span class="hljs-name"><span class="hljs-name">uint</span></span>)_fmtw(<span class="hljs-name"><span class="hljs-name">uint</span></span>)</code> </pre><br>  And according to the AMD <abbr title="Intermediate Language">IL</abbr> language specification, fmtx-fmtw values ‚Äã‚Äãare required.  That is, the following code (like it would be possible to describe a texture with elements of type 1-component vector) is incorrect: <br><pre> <code class="hljs lisp">dcl_resource_id(<span class="hljs-number"><span class="hljs-number">0</span></span>)_type(<span class="hljs-number"><span class="hljs-number">2</span></span>d,unnorm)_fmtx(<span class="hljs-name"><span class="hljs-name">uint</span></span>)</code> </pre><br>  <b>Rule number 5:</b> respect the types that you declare in the kernel and when allocating a resource.  If they do not match, you can not bind the resource to the kernel. <br><br>  <b>Rule number 6:</b> for constant memory, the type of the element must always be of type <b>float</b> . <br><br>  Why this is done is not clear to me, since you can still load integer values ‚Äã‚Äãfrom constant memory (which we do in the example). <br><br>  A couple more words about the flags that are needed when allocating memory: <br><pre> <code class="cpp hljs"><span class="hljs-comment"><span class="hljs-comment">/** CAL resource allocation flags **/</span></span> <span class="hljs-keyword"><span class="hljs-keyword">typedef</span></span> <span class="hljs-keyword"><span class="hljs-keyword">enum</span></span> CALresallocflagsEnum { CAL_RESALLOC_GLOBAL_BUFFER = <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-comment"><span class="hljs-comment">/**&lt; used for global import/export buffer */</span></span> CAL_RESALLOC_CACHEABLE = <span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-comment"><span class="hljs-comment">/**&lt; cacheable memory? */</span></span> } CALresallocflags;</code> </pre><br>  I never worked with the second flag, when it gives an advantage, I do not know.  And judging by the question mark in the comments of the authors themselves, they also do not know (smile). <br>  But the first flag is needed to allocate a global buffer (‚Äúg []‚Äù). <br><br>  Now apply the theory in practice.  Bearing in mind the example described in the previous article, we will also set the kernel launch parameters: <br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">unsigned</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> blocks = <span class="hljs-number"><span class="hljs-number">4</span></span>; <span class="hljs-comment"><span class="hljs-comment">//  4  unsigned int threads = 64; //  64    //    cb0 CALresource constantResource; CALresult result = calResAllocLocal1D( &amp;constantResource, device, 1, CAL_FORMAT_FLOAT32_4, 0 ); //    i0 CALresource textureResource; result = calResAllocLocal2D( &amp;textureResource, device, threads, blocks, CAL_FORMAT_UNSIGNED_INT32_4, 0 ); //    g[] CALresource globalResource; result = calResAllocLocal1D( &amp;globalResource, device, threads * blocks, CAL_FORMAT_UNSIGNED_INT32_4, CAL_RESALLOC_GLOBAL_BUFFER );</span></span></code> </pre><br>  After the resources are no longer needed, they will need to be released: <br><pre> <code class="cpp hljs">calResFree( constantResource ); calResFree( textureResource ); calResFree( globalResource );</code> </pre><br><h2>  Copy memory </h2><br><h3>  Gaining direct memory access </h3><br>  If the GPU supports <i>mapping</i> its memory (mapping the addresses of its memory into the address space of the process), then we can get a pointer to this memory, and then work with it, like with any other memory: <br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">unsigned</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> pitch; <span class="hljs-keyword"><span class="hljs-keyword">unsigned</span></span> <span class="hljs-keyword"><span class="hljs-keyword">char</span></span>* mappedPointer; CALresult result = calResMap( (CALvoid**)&amp;mappedPointer, &amp;pitch, resource, <span class="hljs-number"><span class="hljs-number">0</span></span> ); <span class="hljs-comment"><span class="hljs-comment">//    ,   ,   </span></span></code> </pre><br>  And after we finish working with memory, you need to free the pointer: <br><pre> <code class="cpp hljs">CALresult result = calResUnmap( resource );</code> </pre><br>  <b>Rule number 7:</b> always remember that when working with GPU memory, <i>alignment</i> must be considered.  This alignment is characterized by the <i>pitch</i> variable. <br><br>  <b>Rule number 8:</b> pitch is measured in <b>elements</b> , not in bytes. <br><br>  Why do you need to know about this alignment?  The fact is that, unlike RAM, the memory of a GPU is not always a contiguous area.  This is especially evident when working with textures.  Let me explain this with an example: if you want to work with a texture of 100x100 elements, and the calResMap () function returns a pitch value equal to 200, this means that the GPU will actually work with a 200x100 texture, just in each line of the texture only the first 100 will be taken into account items. <br><br>  Copying to GPU memory taking into account the pitch value can be organized as follows: <br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">unsigned</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> pitch; <span class="hljs-keyword"><span class="hljs-keyword">unsigned</span></span> <span class="hljs-keyword"><span class="hljs-keyword">char</span></span>* mappedPointer; <span class="hljs-keyword"><span class="hljs-keyword">unsigned</span></span> <span class="hljs-keyword"><span class="hljs-keyword">char</span></span>* dataBuffer; CALresult result = calResMap( (CALvoid**)&amp;mappedPointer, &amp;pitch, resource, <span class="hljs-number"><span class="hljs-number">0</span></span> ); <span class="hljs-keyword"><span class="hljs-keyword">unsigned</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> width; <span class="hljs-keyword"><span class="hljs-keyword">unsigned</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> height; <span class="hljs-keyword"><span class="hljs-keyword">unsigned</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> elementSize = <span class="hljs-number"><span class="hljs-number">16</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>( pitch &gt; width ) { <span class="hljs-keyword"><span class="hljs-keyword">for</span></span>( uint index = <span class="hljs-number"><span class="hljs-number">0</span></span>; index &lt; height; ++index ) { <span class="hljs-built_in"><span class="hljs-built_in">memcpy</span></span>( mappedPointer + index * pitch * elementSize, dataBuffer + index * width * elementSize, width * elementSize ); } } <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> { <span class="hljs-built_in"><span class="hljs-built_in">memcpy</span></span>( mappedPointer, dataBuffer, width * height * elementSize ); }</code> </pre><br>  Naturally, the data in the dataBuffer must be prepared according to the type of element.  But at the same time remember that the element is always 16 bytes in size. <br>  That is, for the CAL_FORMAT_UNSIGNED_INT16_2 format element, its byte-by-memory representation will be as follows: <br><pre> <code class="cpp hljs"><span class="hljs-comment"><span class="hljs-comment">// w - word, 16  // wi.j - i- word, j-  // x -  [ w0.0 | w0.1 | x | x ][ w1.0 | w1.1 | x | x ][ x | x | x | x ][ x | x | x | x ]</span></span></code> </pre><br><h3>  Copying data between resources </h3><br>  Data is not copied directly between resources, but between their context-mapped values.  The copy operation is asynchronous, therefore, to find out about the completion of the copy operation, use the system object of the type CALevent: <br><pre> <code class="cpp hljs">CALresource inputResource; CALresource outputResource; CALmem inputResourceMem; CALmem outputResourceMem; <span class="hljs-comment"><span class="hljs-comment">//     CALresult result = calCtxGetMem( &amp;inputResourceMem, context, inputResource ); result = calCtxGetMem( &amp;outputResourceMem, context, outputResource ); //   CALevent syncEvent; result = calMemCopy( &amp;syncEvent, context, inputResourceMem, outputResourceMem, 0 ); //    ,   ,    //     while( calCtxIsEventDone( context, syncEvent ) == CAL_RESULT_PENDING );</span></span></code> </pre><br><h2>  Compiling and loading the kernel on the GPU </h2><br>  <i>‚ÄúDeath of Koshchey in a needle, needle in an egg, egg in a duck, duck in a hare, hare in a chest ...‚Äù</i> <br><br>  The process of loading the kernel on a GPU can be described as follows: the source (txt) is compiled into an object, then one or several object users are linked into an image, which is then loaded into a GPU module, and then can be obtained from the module a pointer to the kernel entry point (using this pointer we will be able to launch the kernel for execution). <br><br>  And now, how it is implemented: <br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">const</span></span> <span class="hljs-keyword"><span class="hljs-keyword">char</span></span>* kernel; <span class="hljs-comment"><span class="hljs-comment">//       // ,   GPU  unsigned int deviceId = 0; //  GPU CALdeviceinfo deviceInfo; CALresult result = calDeviceGetInfo( &amp;deviceInfo, deviceId ); //   CALobject obj; result = calclCompile( &amp;obj, CAL_LANGUAGE_IL, kernel, deviceInfo.target ); //     CALimage image; result = calclLink( &amp;image, &amp;obj, 1 ); //   -  ,  -   //     ,   result = calclFreeObject( obj ); //     CALmodule module; result = calModuleLoad( &amp;module, context, image ); //      CALfunc function; result = calModuleGetEntry( &amp;function, context, module, "main" );</span></span></code> </pre><br>  <b>Rule number 9:</b> the entry point to the kernel is always the same, since there is only one function after the link - the function "main". <br><br>  That is, unlike Nvidia CUDA, there can be only one global main function in the AMD <abbr title="Compute Abstraction Layer">CAL</abbr> core. <br><br>  As you can see, the compiler can only handle the source code written in <abbr title="Intermediate Language">IL</abbr> . <br><br>  Loading the image into the module is due to the fact that the image needs to be loaded into the selected GPU context.  Consequently, the described compilation process must be done for each GPU (except for the case when 2 identical GPUs: it is enough to compile and link once, but you still have to load the image into the module for each card). <br><br>  I want to draw attention to the possibility of linking several object students.  Maybe someone this opportunity is useful.  In my opinion, it can be applied in the case of different implementations of the same subfunction: these implementations can be transferred to different object managers, since AMD <abbr title="Intermediate Language">IL</abbr> does not have preprocessor directives like #ifdef. <br><br>  After the kernel completes execution on the GPU, it will be necessary to release the corresponding resources: <br><pre> <code class="cpp hljs">CALresult result = calclFreeImage( image ); result = calModuleUnload( context, <span class="hljs-keyword"><span class="hljs-keyword">module</span></span> );</code> </pre><br><h2>  Run the kernel for execution </h2><br><h3>  Setting kernel startup options </h3><br>  So, we have dedicated resources, full memory, and a compiled kernel.  It remains only to bind resources to our specific kernel and start it.  To do this, you need to get its startup parameters from the kernel, and the resource to map to the context. <br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">const</span></span> <span class="hljs-keyword"><span class="hljs-keyword">char</span></span>* memoryName; <span class="hljs-comment"><span class="hljs-comment">//    ,       //      CALname kernelParameter; CALresult result = calModuleGetName( &amp;kernelParameter, context, module, memoryName ); //     CALmem resourceMem; result = calCtxGetMem( &amp;resourceMem, context, resource ); //         result = calCtxSetMem( context, kernelParameter, resourceMem );</span></span></code> </pre><br>  And now we do it within the framework of our example: <br><pre> <code class="cpp hljs">CALname kernelParameter; CALmem resourceMem; <span class="hljs-comment"><span class="hljs-comment">//      CALresult result = calModuleGetName( &amp;kernelParameter, context, module, "cb0" ); result = calCtxGetMem( &amp;resourceMem, context, constantResource ); result = calCtxSetMem( context, kernelParameter, resourceMem ); //      result = calModuleGetName( &amp;kernelParameter, context, module, "i0" ); result = calCtxGetMem( &amp;resourceMem, context, textureResource ); result = calCtxSetMem( context, kernelParameter, resourceMem ); //      result = calModuleGetName( &amp;kernelParameter, context, module, "g[]" ); result = calCtxGetMem( &amp;resourceMem, context, globalResource ); result = calCtxSetMem( context, kernelParameter, resourceMem );</span></span></code> </pre><br>  After the kernel completes execution on the GPU, it will be necessary to unbind the resources from the kernel.  This can be done like this: <br><pre> <code class="cpp hljs">CALname kernelParameter; <span class="hljs-comment"><span class="hljs-comment">//      CALresult result = calModuleGetName( &amp;kernelParameter, context, module, "cb0" ); result = calCtxSetMem( context, kernelParameter, 0 ); //      result = calModuleGetName( &amp;kernelParameter, context, module, "i0" ); result = calCtxSetMem( context, kernelParameter, 0 ); //      result = calModuleGetName( &amp;kernelParameter, context, module, "g[]" ); result = calCtxSetMem( context, kernelParameter, 0 );</span></span></code> </pre><br>  Now the kernel knows where to get the data.  It remains the case for small: <br><br><h3>  Kernel startup </h3><br>  As you remember, in the first part I mentioned the shaders <abbr title="Pixel shader">PS</abbr> and <abbr title="Compute shader">CS</abbr> .  You can find out if the latter is supported by the attributes of the GPU (see above). <br><br>  <abbr title="Pixel shader">PS</abbr> Launch: <br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">unsigned</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> blocks = <span class="hljs-number"><span class="hljs-number">4</span></span>; <span class="hljs-comment"><span class="hljs-comment">//  4  unsigned int threads = 64; //  64    CALdomain domain; domain.x = 0; domain.y = 0; domain.width = threads; domain.height = blocks; CALevent syncEvent; CALresult result = calCtxRunProgram( &amp;syncEvent, context, function, &amp;domain ); while( calCtxIsEventDone( context, syncEvent ) == CAL_RESULT_PENDING );</span></span></code> </pre><br>  Here, function is the entry point into the kernel that we got at the stage of loading the kernel on the GPU (see above <i>‚ÄúCompiling and loading the kernel on the GPU‚Äù</i> ). <br><br>  <b>Rule number 10:</b> <abbr title="Pixel shader">PS</abbr> does not know the value of threads within itself, it must be passed through memory (in our example this is done through constant memory). <br><br>  <abbr title="Compute shader">CS</abbr> Launch: <br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">unsigned</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> blocks = <span class="hljs-number"><span class="hljs-number">4</span></span>; <span class="hljs-comment"><span class="hljs-comment">//  4  unsigned int threads = 64; //  64    CALprogramGrid programGrid; programGrid.func = function; programGrid.flags = 0; programGrid.gridBlock.width = threads; programGrid.gridBlock.height = 1; programGrid.gridBlock.depth = 1; programGrid.gridSize.width = blocks; programGrid.gridSize.height = 1; programGrid.gridSize.depth = 1; CALevent syncEvent; CALresult result = calCtxRunProgramGrid( &amp;syncEvent, context, &amp;programGrid ); while( calCtxIsEventDone( context, syncEvent ) == CAL_RESULT_PENDING );</span></span></code> </pre><br>  <b>Rule No. 11: the</b> value of threads must correspond to the value punched in the source code of the kernel.  The kernel will be started anyway, but you can either go beyond the memory (running fewer threads than declared in the kernel), or not all input data will be processed (starting more threads than was announced in the kernel). <br><br>  Done!  The kernel is running, and if everything went well, then the processed memory is in the output memory (‚Äúg []‚Äù).  It remains only to copy them outside (see above, section <i>"Copying memory"</i> ). <br><br><h2>  Useful features </h2><br>  It remains only to mention some features that can be useful in everyday life. <br><pre> <code class="cpp hljs">CALresult result; <span class="hljs-comment"><span class="hljs-comment">//     CALdevicestatus status; result = calDeviceGetStatus( &amp;status, device ); //      GPU  result = calCtxFlush( context ); //       ( ) CALfunc function; CALfuncInfo functionInfo; result = calModuleGetFuncInfo( &amp;functionInfo, context, module, function ); /*      ,       (     ,      ) */ //        aticalrt.dll const char* errorString = calGetErrorString(); //        aticalcl.dll () const char* errorString = calclGetErrorString();</span></span></code> </pre><br><h2>  Inter-Thread Synchronization </h2><br>  Unlike Nvidia CUDA, you do not need to perform additional actions with the context if you are working with a GPU from different threads.  But there are still some limitations. <br><br>  <b>Rule # 12:</b> All <abbr title="Compute Abstraction Layer">CAL</abbr> compiler functions <b>are not</b> thread safe.  Within one application, only one thread can work with the compiler at a time. <br><br>  <b>Rule # 13:</b> All the functions of the main <abbr title="Compute Abstraction Layer">CAL</abbr> library that work with a specific context / device descriptor (context / device) <b>are</b> thread safe.<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">All other functions </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">are not</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> thread safe. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Rule # 14:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Only one application thread at a time can work with a specific context.</font></font><br><br><h2>  Conclusion </h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">I tried to describe the most accessible technology AMD </font></font><abbr title="Compute Abstraction Layer"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">CAL</font></font></abbr><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> and AMD </font></font><abbr title="Intermediate Language"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">IL</font></font></abbr><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , so that anyone could write from scratch a simple application for AMD GPU. </font><font style="vertical-align: inherit;">The main thing is to always remember one golden rule: RTFM! </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Hope you enjoyed reading.</font></font><br><br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Links for information </font></font></h2><br><ul><li> <a href="http://developer.amd.com/sdks/AMDAPPSDK/documentation/Pages/default.aspx" title="AMD Accelerated Parallel Processing SDK"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">AMD Accelerated Parallel Processing SDK</font></font></a> </li><li> <a href="http://developer.amd.com/sdks/amdappsdk/assets/AMD_CAL_Programming_Guide_v2.0.pdf" title="AMD Compute Abstraction Layer (CAL)"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">AMD Compute Abstraction Layer (CAL)</font></font></a> </li><li> <a href="http://developer.amd.com/sdks/AMDAPPSDK/assets/AMD_Intermediate_Language_(IL)_Specification_v2.pdf" title="AMD Intermediate Language (IL)"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">AMD Intermediate Language (IL)</font></font></a> </li></ul></div><p>Source: <a href="https://habr.com/ru/post/139049/">https://habr.com/ru/post/139049/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../139042/index.html">Login page in the admin site of the city council of Dnepropetrovsk</a></li>
<li><a href="../139044/index.html">Setting up document processing on FAST</a></li>
<li><a href="../139045/index.html">Interesting future: Furniture-transformer!</a></li>
<li><a href="../139046/index.html">The story of Panda and iOS</a></li>
<li><a href="../139048/index.html">Popular About Amazon Web Services: CloudFront [continued]</a></li>
<li><a href="../139051/index.html">Sites * .narod.ru work on ZX Spectrum</a></li>
<li><a href="../139053/index.html">We collect our counters via the collectd protocol</a></li>
<li><a href="../139054/index.html">Virtual reality: why are enemies always red and you always behind green ones?</a></li>
<li><a href="../139056/index.html">IBM says they are ready to create quantum computers</a></li>
<li><a href="../139057/index.html">PocketBook Pro 612</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>