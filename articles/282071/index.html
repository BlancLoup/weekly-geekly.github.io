<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>What does the convolutional neural network look at when it sees nudity?</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Last week at Clarifai, we formally announced our NSFW, Not Safe for Work) recognition model . 

 Warning and disclaimer. This article contains images ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>What does the convolutional neural network look at when it sees nudity?</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/files/7e4/eb1/075/7e4eb1075f174ff48aff09e7d0434402.jpeg"><br><br>  Last week at Clarifai, we formally announced our <a href="http://blog.clarifai.com/moderate-filter-or-curate-adult-content-with-clarifais-nsfw-model/">NSFW, Not Safe for Work) recognition model</a> . <br><br>  <i>Warning and disclaimer.</i>  <i>This article contains images of nudity for scientific purposes.</i>  <i>We ask not to read further those who are under 18 or who are offended by nudity.</i> 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <hr><br>  Automatic identification of nude photos has been a central computer vision problem for more than two decades, and because of its rich history and well-defined task, it has become an excellent example of how technology has evolved.  I use the problem of detecting obscenity to explain how the training of modern convolutional networks differs from the research conducted in the past. <br><a name="habracut"></a><br><h3>  Back in 1996 ... </h3><br><img src="https://habrastorage.org/files/6db/93a/f24/6db93af248354fa39662545a1cda23fa.png"><br><br>  One of the first works in this area had a simple and understandable title: ‚ÄúSearch for nudity,‚Äù by Margaret Fleck and others. It was published in the mid-90s and is a good example of what computer vision specialists did before mass distribution of convolutional networks.  In part 2 of the scientific article, they give a generalized description of the technique: <br><br><blockquote>  Algorithm: <br><ul><li>  First, find images with large areas of skin-colored pixels. </li><li>  Then, in these areas, find elongated areas and group them into possible human limbs or combined groups of limbs, using specialized grouping modules that contain a significant amount of information about the structure of the object. </li></ul></blockquote><br>  Skin detection was carried out by filtering the color space, and grouping of skin regions was carried out using human figure modeling as ‚Äúa set of almost cylindrical parts, where the individual outlines of the parts and the connections between the parts are limited to the skeleton geometry (section 2).  The development methods of such an algorithm become more understandable if we study Figure 1 in a scientific article, where the authors showed some of the grouping rules that were compiled manually. <br><br><img src="https://habrastorage.org/files/a44/45e/f0b/a4445ef0b6eb4c498f72a79b3b80ec6f.png"><br><br>  The scientific article talks about ‚Äú60% recognition accuracy and 52% recall on an uncontrolled sample of 138 images of naked people.‚Äù  The authors also show examples of correctly recognized images and false positives with visualization of the areas that the algorithm processed. <br><br><img src="https://habrastorage.org/files/eef/feb/9ab/eeffeb9ab03d49b29b27d5b49ffb530c.png"><br><br><img src="https://habrastorage.org/files/ad4/3d5/e4f/ad43d5e4f16445a9a61d69e35eec43ec.png"><br><br>  The main problem with manual drafting of rules is that the complexity of the model is limited by the patience and imagination of the researchers.  In the next section, we will see how a convolutional neural network trained to perform the same task demonstrates a much more complex representation of the same data. <br><br><h3>  Now in 2014 ... </h3><br>  Instead of inventing formal rules to describe how input should be presented, depth learning researchers come up with network architectures and data sets that will allow the AI ‚Äã‚Äãsystem to master these views directly from the data.  However, due to the fact that the researchers do not indicate exactly how the network should respond to the given input data, a new problem arises: how to understand what the neural network is responding to? <br><br><img src="https://habrastorage.org/files/1df/b21/8d1/1dfb218d149f4fd1924a932517f4d783.png"><br><br>  To understand the actions of the convolutional neural network, it is necessary to interpret the activity of the trait at various levels.  In the rest of the article, we explore the early version of our NSFW model, highlighting activity from the top level down to the level of the pixel space at the input.  This will allow you to see which specific input patterns caused a certain activity on the feature map (that is, why, in fact, the image is marked as "NSFW"). <br><br>  <b>Barrier sensitivity</b> <br>  The illustration below shows photographs of <a href="https://en.wikipedia.org/wiki/Lenna">Lena</a> <a href="http://www.cs.cmu.edu/~chuck/lennapg/lenna.shtml">S√∂derberg</a> after applying 64x64 sliding windows in increments of 3 of our NSFW model to the cropped / obscured versions of the original image. <br><br><img src="https://habrastorage.org/files/cf9/d01/1d1/cf9d011d191a4df4a8d11ced8a06a189.png"><br><br>  To build a heatmap on the left, we sent each window to our convolutional neural network and averaged the NSFW score for each pixel.  When a neural network encounters a fragment filled with skin, it tends to evaluate it as ‚ÄúNSFW‚Äù, which leads to the appearance of large red areas on Lena‚Äôs body.  To create a heat map on the right, we systematically obscured parts of the original image and noted -1 as the NSFW rating (that is, the SFW rating).  When most of the NSFW regions are closed, the ‚ÄúSFW‚Äù score increases, and we see higher values ‚Äã‚Äãon the heat map.  For clarity, here are examples of images that we gave to the convolutional neural network for each of the two experiments above. <br><br><img src="https://habrastorage.org/files/28b/af6/3c9/28baf63c90bc44d4af2982309f35601a.png"><br><br>  One of the remarkable features of these experiments is that they can be carried out even if the classifier is an absolute ‚Äúblack box‚Äù.  Here is a snippet of code that reproduces these results through our APIs: <br><br><pre><code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># NSFW occlusion experiment from StringIO import StringIO import matplotlib.pyplot as plt import numpy as np from PIL import Image, ImageDraw import requests import scipy.sparse as sp from clarifai.client import ClarifaiApi CLARIFAI_APP_ID = '...' CLARIFAI_APP_SECRET = '...' clarifai = ClarifaiApi(app_id=CLARIFAI_APP_ID, app_secret=CLARIFAI_APP_SECRET, base_url='https://api.clarifai.com') def batch_request(imgs, bboxes): """use the API to tag a batch of occulded images""" assert len(bboxes) &lt; 128 #convert to image bytes stringios = [] for img in imgs: stringio = StringIO() img.save(stringio, format='JPEG') stringios.append(stringio) #call api and parse response output = [] response = clarifai.tag_images(stringios, model='nsfw-v1.0') for result,bbox in zip(response['results'], bboxes): nsfw_idx = result['result']['tag']['classes'].index("sfw") nsfw_score = result['result']['tag']['probs'][nsfw_idx] output.append((nsfw_score, bbox)) return output def build_bboxes(img, boxsize=72, stride=25): """Generate all the bboxes used in the experiment""" width = boxsize height = boxsize bboxes = [] for top in range(0, img.size[1], stride): for left in range(0, img.size[0], stride): bboxes.append((left, top, left+width, top+height)) return bboxes def draw_occulsions(img, bboxes): """Overlay bboxes on the test image""" images = [] for bbox in bboxes: img2 = img.copy() draw = ImageDraw.Draw(img2) draw.rectangle(bbox, fill=True) images.append(img2) return images def alpha_composite(img, heatmap): """Blend a PIL image and a numpy array corresponding to a heatmap in a nice way""" if img.mode == 'RBG': img.putalpha(100) cmap = plt.get_cmap('jet') rgba_img = cmap(heatmap) rgba_img[:,:,:][:] = 0.7 #alpha overlay rgba_img = Image.fromarray(np.uint8(cmap(heatmap)*255)) return Image.blend(img, rgba_img, 0.8) def get_nsfw_occlude_mask(img, boxsize=64, stride=25): """generate bboxes and occluded images, call the API, blend the results together""" bboxes = build_bboxes(img, boxsize=boxsize, stride=stride) print 'api calls needed:{}'.format(len(bboxes)) scored_bboxes = [] batch_size = 125 for i in range(0, len(bboxes), batch_size): bbox_batch = bboxes[i:i + batch_size] occluded_images = draw_occulsions(img, bbox_batch) results = batch_request(occluded_images, bbox_batch) scored_bboxes.extend(results) heatmap = np.zeros(img.size) sparse_masks = [] for idx, (nsfw_score, bbox) in enumerate(scored_bboxes): mask = np.zeros(img.size) mask[bbox[0]:bbox[2], bbox[1]:bbox[3]] = nsfw_score Asp = sp.csr_matrix(mask) sparse_masks.append(Asp) heatmap = heatmap + (mask - heatmap)/(idx+1) return alpha_composite(img, 80*np.transpose(heatmap)), np.stack(sparse_masks) #Download full Lena image r = requests.get('https://clarifai-img.s3.amazonaws.com/blog/len_full.jpeg') stringio = StringIO(r.content) img = Image.open(stringio, 'r') img.putalpha(1000) #set boxsize and stride (warning! a low stride will lead to thousands of API calls) boxsize= 64 stride= 48 blended, masks = get_nsfw_occlude_mask(img, boxsize=boxsize, stride=stride) #viz blended.show()</span></span></code> </pre> <br>  Although such experiments make it easy to see the result of the classifier, they have a drawback: the generated visualizations are often quite vague.  This makes it difficult to truly understand what the neural network is really doing and to understand what can go wrong during its training. <br><br>  <b>Deploying Neural Networks (Deconvolutional Networks)</b> <br>  After learning the network on a given set of data, we would like to take an image and a class, and ask the neural network for something like, ‚ÄúHow can we change this image to better fit the specified class?‚Äù.  For this, we use a deploying neural network, as described in section 2 of the above-mentioned scientific article of Seiler and Fergus 2014: <br><br><blockquote>  A developmental neural network can be represented as a convolutional neural network that uses the same components (filtering, pooling), but vice versa, so instead of displaying pixels for attributes, it does the opposite.  To study the specific activation of the convolutional neural network, we set all other activations in this layer to zero and skip the feature maps as input parameters to the attached layer of the deploying neural network.  Then we successfully produce 1) unpling;  2) correction and 3) filtering to restore activity in the lower layer, which gave rise to the selected activation.  Then the procedure is repeated until we reach the original pixel layer. <br><br>  [...] <br><br>  The procedure is similar to the reverse propagation of one strong activation (as opposed to ordinary gradients), for example, calculating <img src="https://habrastorage.org/files/73b/758/620/73b758620e98467f990bd5fae9e961ff.gif">  where <img src="https://habrastorage.org/files/f02/2c3/8fd/f022c38fdaf746db8d308cda82f98890">  Is an element of the feature map with strong activation, and <img src="https://habrastorage.org/files/733/107/6f0/7331076f0ae44e7b998caf6623b87ce8.gif">  - the original image. </blockquote><br>  Here is the result obtained from the reversing neural network, which was given the task to show the necessary changes in Lena's photo to make it look more like pornography (note: the reaming neural network used here only works with square images, so we added Lena's photo to the square): <br><br><img src="https://habrastorage.org/files/c52/d8a/a6f/c52d8aa6f7f047019144d66b1a98817a.jpeg"><br><br>  <a href="https://dsp.stackexchange.com/questions/18631/who-is-barbara-test-image">Barbara</a> is a more decent version of Lena.  If you believe the neural network, you can fix it by adding red color to the lips. <br><br><img src="https://habrastorage.org/files/f37/6e2/24d/f376e224d2b64dfca96afdfec90e5138.jpeg"><br><br>  The next frame with <a href="https://en.wikipedia.org/wiki/Ursula_Andress">Ursula Andress</a> in the role of Honey Rider from the film ‚ÄúDoctor Nou‚Äù with James Bond won the first place in <a href="http://news.bbc.co.uk/2/hi/entertainment/3250386.stm">the 2003 poll</a> for the ‚Äúsexiest moment in the history of cinema‚Äù. <br><br><img src="https://habrastorage.org/files/7e4/eb1/075/7e4eb1075f174ff48aff09e7d0434402.jpeg"><br><br>  The outstanding result of the above experiments is that the neural network was able to understand that the red lips and navels are the "NSFW" indicators.  Most likely, this means that we have not included a sufficient number of images of red lips and navels in our training data set "SFW".  If we only evaluated our model by studying the accuracy / completeness and ROC curves (shown below, a set of test images: 428,271), we would never have discovered this fact, because our test set has the same drawback.  This shows the fundamental difference between rule-based classifiers and modern AI research.  Instead of processing the features manually, we reshape the data set until the feature improves. <br><br><img src="https://habrastorage.org/files/05f/d4a/a17/05fd4aa178bc45b79050d8157c4f6e86.png"><br><br>  In the end, to check the reliability, we launched a reversing neural network on hardcore pornography to make sure that the learned signs really correspond to objects that obviously belong to NSFW. <br><br><img src="https://habrastorage.org/files/d8e/9ae/e02/d8e9aee02930458d8bfd438784acc3e9.png"><br><br>  Here we clearly see that the convolutional neural network correctly assimilated the objects ‚Äúpenis‚Äù, ‚Äúanus‚Äù, ‚Äúvagina‚Äù, ‚Äúnipple‚Äù and ‚Äúbuttocks‚Äù - those objects that our model should recognize.  Moreover, the detected signs are much more detailed and complex than the researchers can manually describe, and this explains the significant success that we have achieved using convolutional neural networks to recognize obscene photos. </div><p>Source: <a href="https://habr.com/ru/post/282071/">https://habr.com/ru/post/282071/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../282049/index.html">Preemptivity: how to take away the processor</a></li>
<li><a href="../282053/index.html">Andrei Ershov: ‚ÄúTwo Views of Programming‚Äù</a></li>
<li><a href="../282057/index.html">Xamarin Development Workshop: Technology Overview and Dive into Solution Development</a></li>
<li><a href="../282065/index.html">How it is made: mobile cross-platform engine</a></li>
<li><a href="../282067/index.html">From the command line for knowledge</a></li>
<li><a href="../282073/index.html">Summit comes to us ...</a></li>
<li><a href="../282075/index.html">Week before the 5th International Mobile Conference MBLT16</a></li>
<li><a href="../282077/index.html">Chat bot development for Bitrix24</a></li>
<li><a href="../282079/index.html">Low FPS while scrolling the page. Problem solving background-attachment: fixed</a></li>
<li><a href="../282081/index.html">Mathematical model of perception (Part 1)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>