<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>How we taught iPhone football clubs to recognize</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hi, Habr! 

 My name is Igor Litvinenko, I have been developing for mobile devices for more than three years, mainly for iOS. In DataArt I study the p...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>How we taught iPhone football clubs to recognize</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/files/256/4c8/048/2564c80485ec4cd29f809717a01a7b2a.png"><br><br>  Hi, Habr! <br><br>  My name is Igor Litvinenko, I have been developing for mobile devices for more than three years, mainly for iOS.  In DataArt I study the promotion of various tasks related to computer vision: image processing, the development of augmented reality programs, the use of neural networks, and so on, with specifics for mobile devices.  Today I want to tell you about our research / fun project related to football. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Instead of introducing and a long speech on the development of modern technologies and pattern recognition, let us immediately proceed to the formulation of the problem. <br><br><h5>  Formulation of the problem </h5><br>  It is necessary to develop a mobile application that would show current information on football clubs, teams, the latest matches.  For ease of use of the original killer feature of the application will be the ability to display information about the team when you hover the phone on its logo.  The application should also work without an internet connection.  The estimated number of recognizable teams is about a hundred (we were no longer choosing here. We just wanted to cover all the clubs in the main football leagues in England).  Another feature is the ability to "repaint" the user interface based on the last recognized logo. <br><a name="habracut"></a><br><img src="https://habrastorage.org/files/2f4/b3b/142/2f4b3b142df2493d950a462c07c7514d.png"><br><br><h5>  Requirements analysis and search for ready-made solutions </h5><br>  It is clear that it will be necessary to solve the problem of recognizing a particular image in the video stream.  However, the requirement to work offline, to be honest, seriously reduces the set of solutions.  So, we can no longer use ready-made cloud solutions or perform complex recognition on the server side.  Those.  all calculations should be done only on the client side. <br><br>  The second problem is the large number and complexity of recognition objects.  It's no secret that the logos of football teams rarely resemble each other.  Moreover, few logos have a simple form and can be applied on any surface (in a magazine with a glare, on an arbitrary background, slightly changed colors, and even in the form of a monochrome tattoo). <br><br>  An additional complicating factor is that the image on the flag will definitely be deformed: the flag is not a solid surface. <br><br>  One last thing: the logo always has a certain angle of rotation in comparison with the reference view.  In the simple case, it will be a turn along one axis, in the worst case, a turn along all three axes. <br><br>  At some point we realized that we had a task in our hands, very similar to the creation of marker augmented reality, where the logos of football clubs would be markers.  I will a little explain this moment. <br><br>  By and large, the huge task of augmented reality can be divided into two subtasks: finding the marker, determining the rotation angle in 3D, displaying content on top of the marker, applying the necessary transformations to it.  We need only the results of solving the first problem, and then we ourselves. <br><br>  We decided not to reinvent the wheel, but to take a ready-made math engine.  But, as usual, the devil is in the details.  As a rule, all ready-made commercial engines put a limit on the number of markers that can be found simultaneously in one session.  I prefer not to say about non-commercial ones: that the quality of recognition, that the stability of recognition there is clearly not good enough.  The maximum with which they can work well is to find simple markers surrounded by a black frame, which is clearly not our option. <br><br>  You could still dig in the direction of OpenCV, but it would take a lot of time, and the result would be a little better than communicating with most non-commercial engines.  After a brief digging, it turned out that the ideal solution to our problem is Vuforia from Qualcomm.  How, what and why - read below. <br><br><h5>  Why we chose Vuforia </h5><br>  <a href="https://developer.vuforia.com/">Vuforia</a> is one of the few engines that provide exactly marker recognition, tracking (tracking in a video frame) and the calculation of rotation angles.  KFOR does not contain any code to simplify the rendering of your objects and only uses OpenGL ES in the examples.  In fact, this was not necessary in our project: we show an information screen.  However, if we were solving the classical problem of augmented reality, this would be a serious disadvantage.  Although Vuforia has the Unity plugin for such a task, I still find it more convenient to use a complex solution (the same MetaIO is much more convenient in this matter).  We have highlighted the following Vuforia benefits: <br><br><ul><li>  First, the product has been around for quite some time, and is being developed by its manufacturer of mobile processors.  This suggests that the product is optimized for mobile phones. </li><li>  Secondly, absolutely free without restrictions.  Of course, there are a lot of paid services like recognition in the cloud and so on, but it is quite possible to do with the free version. </li><li>  Thirdly, the documentation, the developer forum and the community.  There you can often find answers to questions.  And, of course, examples of the use of each opportunity engine </li><li>  Cherry on the cake - there is a version for most of the popular mobile platforms, in case we need to partie our solution. </li></ul><br><br><h5>  The technical part of the integration </h5><br>  Vuforia itself is the library we need to add to the project.  However, for its operation, it is necessary to change some compilation flags.  The most painless way to connect Vuforia is to get an example from the official site and isolate the code for interaction from there.  This code is common to all projects, t. H. Just bring it into a more reusable form. <br>  To start the code for EAGLView <br><br><div class="spoiler">  <b class="spoiler_title">A lot of code under the spoiler</b> <div class="spoiler_text"><pre><code class="objectivec hljs">MSImageRecognitionEAGLView.mm - (<span class="hljs-keyword"><span class="hljs-keyword">void</span></span>)dealloc { [<span class="hljs-keyword"><span class="hljs-keyword">self</span></span> deleteFramebuffer]; <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> ([EAGLContext currentContext] == _context) { [EAGLContext setCurrentContext:<span class="hljs-literal"><span class="hljs-literal">nil</span></span>]; } } - (<span class="hljs-keyword"><span class="hljs-keyword">id</span></span>)initWithCoder:(<span class="hljs-built_in"><span class="hljs-built_in">NSCoder</span></span> *)aDecoder{ <span class="hljs-keyword"><span class="hljs-keyword">self</span></span> = [<span class="hljs-keyword"><span class="hljs-keyword">super</span></span> initWithCoder:aDecoder]; <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">self</span></span>){ vapp = [MSImageRecognitionSession sharedSession]; [<span class="hljs-keyword"><span class="hljs-keyword">self</span></span> setup]; } <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-keyword"><span class="hljs-keyword">self</span></span>; } - (<span class="hljs-keyword"><span class="hljs-keyword">id</span></span>)initWithFrame:(<span class="hljs-built_in"><span class="hljs-built_in">CGRect</span></span>)frame{ <span class="hljs-keyword"><span class="hljs-keyword">self</span></span> = [<span class="hljs-keyword"><span class="hljs-keyword">super</span></span> initWithFrame:frame]; <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">self</span></span>){ vapp = [MSImageRecognitionSession sharedSession]; [<span class="hljs-keyword"><span class="hljs-keyword">self</span></span> setup]; } <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-keyword"><span class="hljs-keyword">self</span></span>; } - (<span class="hljs-keyword"><span class="hljs-keyword">id</span></span>)initWithFrame:(<span class="hljs-built_in"><span class="hljs-built_in">CGRect</span></span>)frame appSession:(MSImageRecognitionSession *) app { <span class="hljs-keyword"><span class="hljs-keyword">self</span></span> = [<span class="hljs-keyword"><span class="hljs-keyword">super</span></span> initWithFrame:frame]; <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">self</span></span>) { vapp = app; [<span class="hljs-keyword"><span class="hljs-keyword">self</span></span> setup]; } <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-keyword"><span class="hljs-keyword">self</span></span>; } - (<span class="hljs-keyword"><span class="hljs-keyword">void</span></span>)setup { <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (<span class="hljs-literal"><span class="hljs-literal">YES</span></span> == [vapp isRetinaDisplay]) { [<span class="hljs-keyword"><span class="hljs-keyword">self</span></span> setContentScaleFactor:<span class="hljs-number"><span class="hljs-number">2.0</span></span>f]; } _context = [[EAGLContext alloc] initWithAPI:kEAGLRenderingAPIOpenGLES2]; <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (_context != [EAGLContext currentContext]) { [EAGLContext setCurrentContext:_context]; } offTargetTrackingEnabled = <span class="hljs-literal"><span class="hljs-literal">NO</span></span>; } - (<span class="hljs-keyword"><span class="hljs-keyword">void</span></span>)finishOpenGLESCommands { <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (_context) { [EAGLContext setCurrentContext:_context]; glFinish(); } } - (<span class="hljs-keyword"><span class="hljs-keyword">void</span></span>)freeOpenGLESResources { [<span class="hljs-keyword"><span class="hljs-keyword">self</span></span> deleteFramebuffer]; glFinish(); } - (<span class="hljs-keyword"><span class="hljs-keyword">void</span></span>) setOffTargetTrackingMode:(<span class="hljs-built_in"><span class="hljs-built_in">BOOL</span></span>) enabled { offTargetTrackingEnabled = enabled; } - (<span class="hljs-keyword"><span class="hljs-keyword">void</span></span>)renderFrameQCAR { [<span class="hljs-keyword"><span class="hljs-keyword">self</span></span> setFramebuffer]; glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT); QCAR::State state = QCAR::Renderer::getInstance().begin(); QCAR::Renderer::getInstance().drawVideoBackground(); glEnable(GL_DEPTH_TEST); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (offTargetTrackingEnabled) { glDisable(GL_CULL_FACE); } <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> { glEnable(GL_CULL_FACE); } glCullFace(GL_BACK); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(QCAR::Renderer::getInstance().getVideoBackgroundConfig().mReflection == QCAR::VIDEO_BACKGROUND_REFLECTION_ON) glFrontFace(GL_CW); <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> glFrontFace(GL_CCW); glDisable(GL_DEPTH_TEST); glDisable(GL_CULL_FACE); glDisableVertexAttribArray(vertexHandle); glDisableVertexAttribArray(normalHandle); glDisableVertexAttribArray(textureCoordHandle); QCAR::Renderer::getInstance().end(); [<span class="hljs-keyword"><span class="hljs-keyword">self</span></span> presentFramebuffer]; } - (<span class="hljs-keyword"><span class="hljs-keyword">void</span></span>)createFramebuffer { <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (_context) { glGenFramebuffers(<span class="hljs-number"><span class="hljs-number">1</span></span>, &amp;_defaultFramebuffer); glBindFramebuffer(GL_FRAMEBUFFER, _defaultFramebuffer); glGenRenderbuffers(<span class="hljs-number"><span class="hljs-number">1</span></span>, &amp;_colorRenderbuffer); glBindRenderbuffer(GL_RENDERBUFFER, _colorRenderbuffer); [_context renderbufferStorage:GL_RENDERBUFFER fromDrawable:(<span class="hljs-built_in"><span class="hljs-built_in">CAEAGLLayer</span></span>*)<span class="hljs-keyword"><span class="hljs-keyword">self</span></span>.layer]; GLint framebufferWidth; GLint framebufferHeight; glGetRenderbufferParameteriv(GL_RENDERBUFFER, GL_RENDERBUFFER_WIDTH, &amp;framebufferWidth); glGetRenderbufferParameteriv(GL_RENDERBUFFER, GL_RENDERBUFFER_HEIGHT, &amp;framebufferHeight); glGenRenderbuffers(<span class="hljs-number"><span class="hljs-number">1</span></span>, &amp;depthRenderbuffer); glBindRenderbuffer(GL_RENDERBUFFER, depthRenderbuffer); glRenderbufferStorage(GL_RENDERBUFFER, GL_DEPTH_COMPONENT16, framebufferWidth, framebufferHeight); glFramebufferRenderbuffer(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0, GL_RENDERBUFFER, _colorRenderbuffer); glFramebufferRenderbuffer(GL_FRAMEBUFFER, GL_DEPTH_ATTACHMENT, GL_RENDERBUFFER, depthRenderbuffer); glBindRenderbuffer(GL_RENDERBUFFER, _colorRenderbuffer); } } - (<span class="hljs-keyword"><span class="hljs-keyword">void</span></span>)deleteFramebuffer { <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (_context) { [EAGLContext setCurrentContext:_context]; <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (_defaultFramebuffer) { glDeleteFramebuffers(<span class="hljs-number"><span class="hljs-number">1</span></span>, &amp;_defaultFramebuffer); _defaultFramebuffer = <span class="hljs-number"><span class="hljs-number">0</span></span>; } <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (_colorRenderbuffer) { glDeleteRenderbuffers(<span class="hljs-number"><span class="hljs-number">1</span></span>, &amp;_colorRenderbuffer); _colorRenderbuffer = <span class="hljs-number"><span class="hljs-number">0</span></span>; } <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (depthRenderbuffer) { glDeleteRenderbuffers(<span class="hljs-number"><span class="hljs-number">1</span></span>, &amp;depthRenderbuffer); depthRenderbuffer = <span class="hljs-number"><span class="hljs-number">0</span></span>; } } } - (<span class="hljs-keyword"><span class="hljs-keyword">void</span></span>)setFramebuffer { <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (_context != [EAGLContext currentContext]) { [EAGLContext setCurrentContext:_context]; } <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (!_defaultFramebuffer) { [<span class="hljs-keyword"><span class="hljs-keyword">self</span></span> performSelectorOnMainThread:<span class="hljs-keyword"><span class="hljs-keyword">@selector</span></span>(createFramebuffer) withObject:<span class="hljs-keyword"><span class="hljs-keyword">self</span></span> waitUntilDone:<span class="hljs-literal"><span class="hljs-literal">YES</span></span>]; } glBindFramebuffer(GL_FRAMEBUFFER, _defaultFramebuffer); } - (<span class="hljs-built_in"><span class="hljs-built_in">BOOL</span></span>)presentFramebuffer { glBindRenderbuffer(GL_RENDERBUFFER, _colorRenderbuffer); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> [_context presentRenderbuffer:GL_RENDERBUFFER]; } MSImageRecognitionSession.mm <span class="hljs-meta"><span class="hljs-meta">#import </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">"MSImageRecognitionSession.h"</span></span></span><span class="hljs-meta"> #import </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;QCAR/QCAR.h&gt;</span></span></span><span class="hljs-meta"> #import </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;QCAR/QCAR_iOS.h&gt;</span></span></span><span class="hljs-meta"> #import </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;QCAR/Tool.h&gt;</span></span></span><span class="hljs-meta"> #import </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;QCAR/Renderer.h&gt;</span></span></span><span class="hljs-meta"> #import </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;QCAR/CameraDevice.h&gt;</span></span></span><span class="hljs-meta"> #import </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;QCAR/VideoBackgroundConfig.h&gt;</span></span></span><span class="hljs-meta"> #import </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;QCAR/UpdateCallback.h&gt;</span></span></span><span class="hljs-meta"> #import </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;QCAR/TrackerManager.h&gt;</span></span></span><span class="hljs-meta"> #import </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;QCAR/ImageTracker.h&gt;</span></span></span><span class="hljs-meta"> #import </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;QCAR/Trackable.h&gt;</span></span></span><span class="hljs-meta"> #import </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;QCAR/DataSet.h&gt;</span></span></span><span class="hljs-meta"> #import </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;QCAR/TrackableResult.h&gt;</span></span></span><span class="hljs-meta"> #import </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;QCAR/TargetFinder.h&gt;</span></span></span><span class="hljs-meta"> #import </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;QCAR/Trackable.h&gt;</span></span></span><span class="hljs-meta"> #import </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;QCAR/ImageTarget.h&gt;</span></span></span><span class="hljs-meta"> #import </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;AVFoundation/AVFoundation.h&gt;</span></span></span><span class="hljs-meta"> namespace { // --- Data private to this unit --- // NSerror domain for errors coming from the Sample application template classes static NSString * const MSImageRecognitionSessionErrorDomain = @</span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">"ImageRecognitionSessionErrorDomain"</span></span></span><span class="hljs-meta">; static const int MS_QCARInitFlags = QCAR::GL_20; // instance of the seesion used to support the QCAR callback there should be only one instance of a session at any given point of time static MSImageRecognitionSession* __sharedInstance = nil; static BOOL __initialized = NO; // camera to use for the session QCAR::CameraDevice::CAMERA mCamera = QCAR::CameraDevice::CAMERA_DEFAULT; // class used to support the QCAR callback mechanism class VuforiaApplication_UpdateCallback : public QCAR::UpdateCallback { virtual void QCAR_onUpdate(QCAR::State&amp; state); } qcarUpdate; } static inline void MSDispatchMain(void (^block)(void)) { dispatch_async(dispatch_get_main_queue(), block); } NSString * const MSImageRecognitionCloudAccessKey = @</span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">"MSImageRecognitionCloudAccessKey"</span></span></span><span class="hljs-meta">; NSString * const MSImageRecognitionCloudSecretKey = @</span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">"MSImageRecognitionCloudSecretKey"</span></span></span><span class="hljs-meta">; @interface MSImageRecognitionSession () { CGSize _boundsSize; UIInterfaceOrientation _interfaceOrientation; dispatch_queue_t _dispatchQueue; QCAR::DataSet **_dataSets; NSInteger _dataSetsCount; BOOL _isCloudRecognition; } @property (atomic, readwrite) BOOL cameraIsActive; @property (nonatomic, copy) MSImageRecognitionBlock recognitionBlock; @end @implementation MSImageRecognitionSession // Determine whether the device has a retina display + (BOOL)isRetinaDisplay { // If UIScreen mainScreen responds to selector displayLinkWithTarget:selector: and the scale property is 2.0, then this is a retina display return ([[UIScreen mainScreen] respondsToSelector:@selector(displayLinkWithTarget:selector:)] &amp;&amp; 2.0 == [UIScreen mainScreen].scale); } - (BOOL) isRetinaDisplay{ return [[self class] isRetinaDisplay]; } #pragma mark - Cleanup - (void)cleanupSession:(MSImageRecognitionCompletionBlock)completion; { MSImageRecognitionCompletionBlock blockCopy = completion ? [completion copy] : nil; dispatch_async(_dispatchQueue, ^{ self.recognitionBlock = nil; if(_dataSets) { delete[] _dataSets; _dataSets = NULL; } if(blockCopy) { MSDispatchMain(^{ blockCopy(YES, nil); }); } }); } #pragma mark - Init + (instancetype)sharedSession { static dispatch_once_t onceToken; dispatch_once(&amp;onceToken, ^{ __sharedInstance = [MSImageRecognitionSession new]; }); return __sharedInstance; } - (id)init { self = [super init]; if(self) { QCAR::registerCallback(&amp;qcarUpdate); _interfaceOrientation = UIInterfaceOrientationPortrait; _dispatchQueue = dispatch_queue_create(</span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">"imageRecognitionSession.queue.FlagRecognition"</span></span></span><span class="hljs-meta">, DISPATCH_QUEUE_SERIAL); } return self; } - (void)initializeSessionOnCloud:(BOOL)isCloudRecognition withCompletion:(MSImageRecognitionCompletionBlock)completion { dispatch_async(_dispatchQueue, ^{ _isCloudRecognition = isCloudRecognition; NSError *error = nil; MSImageRecognitionCompletionBlock blockCopy = completion ? [completion copy] : nil; if(!__initialized &amp;&amp; ![self initialize:&amp;error]) { NSLog(@</span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">"Failed to initialize image recognition session: %@"</span></span></span><span class="hljs-meta">, error); } MSDispatchMain(^{ if(blockCopy) blockCopy(error == nil, error); }); }); } // Initialize the Vuforia SDK - (BOOL)initialize:(NSError **)error { DLog(@</span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">""</span></span></span><span class="hljs-meta">); NSParameterAssert(error); self.cameraIsActive = NO; self.cameraIsStarted = NO; // If this device has a retina display, we expect the view bounds to have been scaled up by a factor of 2; this allows it to calculate the size and position of // the viewport correctly when rendering the video background. The ARViewBoundsSize is the dimension of the AR view as seen in portrait, even if the orientation is landscape CGSize screenSize = [[UIScreen mainScreen] bounds].size; if ([MSImageRecognitionSession isRetinaDisplay]) { screenSize.width *= 2.0; screenSize.height *= 2.0; } _boundsSize = screenSize; // Initialising QCAR is a potentially lengthy operation, so perform it on a background thread QCAR::setInitParameters(MS_QCARInitFlags); // QCAR::init() will return positive numbers up to 100 as it progresses towards success. Negative numbers indicate error conditions NSInteger initSuccess = 0; do { initSuccess = QCAR::init(); } while (0 </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;= initSuccess &amp;&amp; 100 &gt;</span></span></span><span class="hljs-meta"> initSuccess); if(initSuccess != 100) { *error = [self errorWithCode:E_INITIALIZING_QCAR]; return NO; } [self prepareAR]; __initialized = YES; return YES; } - (void)prepareAR { // Tell QCAR we've created a drawing surface QCAR::onSurfaceCreated(); // Frames from the camera are always landscape, no matter what the orientation of the device. Tell QCAR to rotate the video background (and // the projection matrix it provides to us for rendering our augmentation) by the proper angle in order to match the EAGLView orientation switch (_interfaceOrientation) { case UIInterfaceOrientationPortrait: QCAR::setRotation(QCAR::ROTATE_IOS_90); break; case UIInterfaceOrientationPortraitUpsideDown: QCAR::setRotation(QCAR::ROTATE_IOS_270); break; case UIInterfaceOrientationLandscapeLeft: QCAR::setRotation(QCAR::ROTATE_IOS_180); break; case UIInterfaceOrientationLandscapeRight: QCAR::setRotation(1); break; } if(UIInterfaceOrientationIsPortrait(_interfaceOrientation)) { QCAR::onSurfaceChanged(_boundsSize.width, _boundsSize.height); } else { QCAR::onSurfaceChanged(_boundsSize.height, _boundsSize.width); } } #pragma mark - AR control - (void)resumeAR:(MSImageRecognitionCompletionBlock)block { dispatch_async(_dispatchQueue, ^{ NSError *error = nil; MSImageRecognitionCompletionBlock blockCopy = block ? [block copy] : nil; QCAR::onResume(); // if the camera was previously started, but not currently active, then we restart it if ((self.cameraIsStarted) &amp;&amp; (! self.cameraIsActive)) { // initialize the camera if (! QCAR::CameraDevice::getInstance().init(mCamera)) { [self errorWithCode:E_INITIALIZING_CAMERA error:&amp;error]; MSDispatchMain(^{ if(blockCopy) blockCopy(NO, error); }); return; } // start the camera if (!QCAR::CameraDevice::getInstance().start()) { [self errorWithCode:E_STARTING_CAMERA error:&amp;error]; MSDispatchMain(^{ if(blockCopy) blockCopy(NO, error); }); return; } self.cameraIsActive = YES; } MSDispatchMain(^{ if(blockCopy) blockCopy(YES, nil); }); }); } - (void)pauseAR:(MSImageRecognitionCompletionBlock)block { dispatch_async(_dispatchQueue, ^{ MSImageRecognitionCompletionBlock blockCopy = block ? [block copy] : nil; if (self.cameraIsActive) { NSError *error = nil; // Stop and deinit the camera if(! QCAR::CameraDevice::getInstance().stop()) { [self errorWithCode:E_STOPPING_CAMERA error:&amp;error]; MSDispatchMain(^{ if(blockCopy) blockCopy(NO, error); }); return; } if(! QCAR::CameraDevice::getInstance().deinit()) { [self errorWithCode:E_DEINIT_CAMERA error:&amp;error]; MSDispatchMain(^{ if(blockCopy) blockCopy(NO, error); }); return; } self.cameraIsActive = NO; } QCAR::onPause(); MSDispatchMain(^{ if(blockCopy) blockCopy(YES, nil); }); }); } - (void)startAR:(MSImageRecognitionCompletionBlock)block recognitionBlock:(MSImageRecognitionBlock)recognitionBlock; { __block NSError * error_ = nil; __block BOOL isSuccess = YES; MSImageRecognitionCompletionBlock blockCopy = block ? [block copy] : nil; self.recognitionBlock = recognitionBlock; if ([AVCaptureDevice respondsToSelector:@selector(requestAccessForMediaType:completionHandler:)]) { // Completion handler will be dispatched on a separate thread [AVCaptureDevice requestAccessForMediaType:AVMediaTypeVideo completionHandler:^(BOOL granted) { if (YES == granted) { isSuccess = [self startCamera:QCAR::CameraDevice::CAMERA_BACK viewWidth:_boundsSize.width andHeight:_boundsSize.height error:&amp;error_]; if (isSuccess) { self.cameraIsActive = YES; self.cameraIsStarted = YES; } } else { UIAlertView * alert = [[UIAlertView alloc] initWithTitle:@</span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">"Permissions Error"</span></span></span><span class="hljs-meta"> message:@</span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">"Please allow to use camera in Settings &gt; Privacy &gt; Camera"</span></span></span><span class="hljs-meta"> delegate:nil cancelButtonTitle:@</span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">"Okay"</span></span></span><span class="hljs-meta"> otherButtonTitles: nil]; [alert show]; } self.cameraIsActive = NO; self.cameraIsStarted = NO; MSDispatchMain(^{ if(blockCopy) blockCopy(isSuccess, error_); }); }]; } else { isSuccess = [self startCamera:QCAR::CameraDevice::CAMERA_BACK viewWidth:_boundsSize.width andHeight:_boundsSize.height error:&amp;error_]; if (isSuccess) { self.cameraIsActive = YES; self.cameraIsStarted = YES; } if(blockCopy) blockCopy(isSuccess, error_); } } // Stop QCAR camera - (void)stopAR:(MSImageRecognitionCompletionBlock)block { dispatch_async(_dispatchQueue, ^{ NSError *error = nil; MSImageRecognitionCompletionBlock blockCopy = block ? [block copy] : nil; // Stop the camera if (self.cameraIsActive) { // Stop and deinit the camera QCAR::CameraDevice::getInstance().stop(); QCAR::CameraDevice::getInstance().deinit(); self.cameraIsActive = NO; } self.cameraIsStarted = NO; // ask the application to stop the trackers if(![self stopTrackers]) { [self errorWithCode:E_STOPPING_TRACKERS error:&amp;error]; MSDispatchMain(^{ if(blockCopy) blockCopy(NO, error); }); return; } // ask the application to unload the data associated to the trackers if(![self deactivateDataSets]) { [self errorWithCode:E_UNLOADING_TRACKERS_DATA error:&amp;error]; MSDispatchMain(^{ if(blockCopy) blockCopy(NO, error); }); return; } // ask the application to deinit the trackers [self deinitTrackers]; // Pause and deinitialise QCAR QCAR::onPause(); // QCAR::deinit(); MSDispatchMain(^{ if(blockCopy) blockCopy(YES, nil); }); }); } // stop the camera - (void)stopCamera:(MSImageRecognitionCompletionBlock)block { dispatch_async(_dispatchQueue, ^{ NSError *error = nil; MSImageRecognitionCompletionBlock blockCopy = block ? [block copy] : nil; if (self.cameraIsActive) { // Stop and deinit the camera QCAR::CameraDevice::getInstance().stop(); QCAR::CameraDevice::getInstance().deinit(); self.cameraIsActive = NO; } else { [self errorWithCode:E_CAMERA_NOT_STARTED error:&amp;error]; MSDispatchMain(^{ if(blockCopy) blockCopy(NO, error); }); return; } self.cameraIsStarted = NO; // Stop the trackers if(![self stopTrackers]) { [self errorWithCode:E_STOPPING_TRACKERS error:&amp;error]; MSDispatchMain(^{ if(blockCopy) blockCopy(NO, error); }); return; } MSDispatchMain(^{ if(blockCopy) blockCopy(YES, nil); }); }); } // Start QCAR camera with the specified view size - (BOOL)startCamera:(QCAR::CameraDevice::CAMERA)camera viewWidth:(float)viewWidth andHeight:(float)viewHeight error:(NSError **)error { // initialize the camera if (! QCAR::CameraDevice::getInstance().init(camera)) { [self errorWithCode:-1 error:error]; return NO; } // start the camera if (!QCAR::CameraDevice::getInstance().start()) { [self errorWithCode:-1 error:error]; return NO; } // we keep track of the current camera to restart this // camera when the application comes back to the foreground mCamera = camera; // ask the application to start the tracker(s) if(![self startTrackers]) { [self errorWithCode:-1 error:error]; return NO; } // configure QCAR video background [self configureVideoBackgroundWithViewWidth:viewWidth andHeight:viewHeight]; // Cache the projection matrix const QCAR::CameraCalibration&amp; cameraCalibration = QCAR::CameraDevice::getInstance().getCameraCalibration(); _projectionMatrix = QCAR::Tool::getProjectionGL(cameraCalibration, 2.0f, 5000.0f); return YES; } #pragma mark - Trackers management /*! * @brief Trying to connect to cloud database * @param keys Dictionary that should contains access keys for the cloud DB. Must contain values for MSImageRecognitionCloudAccessKey and MSImageRecognitionCloudSecretKey keys. Cannot be nil. * @param completion Completion block. */ - (void)loadCloudTrackerForKeys:(NSDictionary *)keys withCompletion:(MSImageRecognitionCompletionBlock)completion { NSParameterAssert(keys[MSImageRecognitionCloudAccessKey] &amp;&amp; keys[MSImageRecognitionCloudSecretKey]); MSImageRecognitionCompletionBlock blockCopy = completion ? [completion copy] : nil; NSError *error = nil; if([self initTracker:&amp;error]) { [self loadCloudTrackerWithAccessKey:keys[MSImageRecognitionCloudAccessKey] andPrivateKey:keys[MSImageRecognitionCloudSecretKey] error:&amp;error]; } MSDispatchMain(^{ if(blockCopy) blockCopy(error == nil, error); }); } - (void)loadBundledDataSets:(NSArray *)dataSetFilesNames withCompletion:(MSImageRecognitionCompletionBlock)completion { dispatch_async(_dispatchQueue, ^{ NSError *error = nil; MSImageRecognitionCompletionBlock blockCopy = completion ? [completion copy] : nil; if([self initTracker:&amp;error]) { _dataSetsCount = dataSetFilesNames.count; _dataSets = new QCAR::DataSet*[_dataSetsCount]; NSInteger idx = 0; for(NSString *fileName in dataSetFilesNames) { QCAR::DataSet *dataSet = [self loadBundleDataSetWithName:fileName]; if (dataSet == NULL) { NSLog(@</span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">"Failed to load datasets"</span></span></span><span class="hljs-meta">); error = [self errorWithCode:E_LOADING_TRACKERS_DATA]; break; } if (![self activateDataSet:dataSet]) { NSLog(@</span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">"Failed to activate dataset"</span></span></span><span class="hljs-meta">); error = [self errorWithCode:E_LOADING_TRACKERS_DATA]; break; } _dataSets[idx++] = dataSet; } if(error) { if(_dataSets) { delete[] _dataSets; } } } MSDispatchMain(^{ if(blockCopy) blockCopy(error == nil, error); }); }); } - (BOOL)initTracker:(NSError **)error { NSParameterAssert(error); QCAR::TrackerManager&amp; trackerManager = QCAR::TrackerManager::getInstance(); QCAR::Tracker* trackerBase = trackerManager.initTracker(QCAR::ImageTracker::getClassType()); if (!trackerBase){ trackerBase = trackerManager.getTracker(QCAR::ImageTracker::getClassType()); } if (!trackerBase) { NSLog(@</span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">"Failed to initialize ImageTracker."</span></span></span><span class="hljs-meta">); *error = [self errorWithCode:E_INIT_TRACKERS]; return NO; } if(_isCloudRecognition) { QCAR::TargetFinder* targetFinder = static_cast</span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;QCAR::ImageTracker*&gt;</span></span></span><span class="hljs-meta">(trackerBase)-&gt;getTargetFinder(); if (!targetFinder) { NSLog(@</span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">"Failed to get target finder."</span></span></span><span class="hljs-meta">); *error = [self errorWithCode:E_INIT_TRACKERS]; return NO; } } NSLog(@</span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">"Successfully initialized ImageTracker."</span></span></span><span class="hljs-meta">); return YES; } - (void)deinitTrackers { QCAR::TrackerManager&amp; trackerManager = QCAR::TrackerManager::getInstance(); trackerManager.deinitTracker(QCAR::ImageTracker::getClassType()); } - (BOOL)startTrackers { QCAR::TrackerManager&amp; trackerManager = QCAR::TrackerManager::getInstance(); QCAR::Tracker* tracker = trackerManager.getTracker(QCAR::ImageTracker::getClassType()); if(tracker == 0) { return NO; } tracker-&gt;start(); if(_isCloudRecognition) { QCAR::ImageTracker* imageTracker = static_cast</span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;QCAR::ImageTracker*&gt;</span></span></span><span class="hljs-meta">(tracker); QCAR::TargetFinder* targetFinder = imageTracker-&gt;getTargetFinder(); assert (targetFinder != 0); targetFinder-&gt;startRecognition(); } return YES; } - (BOOL)stopTrackers { QCAR::TrackerManager&amp; trackerManager = QCAR::TrackerManager::getInstance(); QCAR::ImageTracker* imageTracker = static_cast</span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;QCAR::ImageTracker*&gt;</span></span></span><span class="hljs-meta">(trackerManager.getTracker(QCAR::ImageTracker::getClassType())); if (!imageTracker) { NSLog(@</span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">"ERROR: failed to get the tracker from the tracker manager"</span></span></span><span class="hljs-meta">); return NO; } imageTracker-&gt;stop(); DLog(@</span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">"INFO: successfully stopped tracker"</span></span></span><span class="hljs-meta">); if(_isCloudRecognition) { // Stop cloud based recognition: QCAR::TargetFinder* targetFinder = imageTracker-&gt;getTargetFinder(); assert(targetFinder != 0); targetFinder-&gt;stop(); DLog(@</span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">"INFO: successfully stopped cloud tracker"</span></span></span><span class="hljs-meta">); } return YES; } #pragma mark - DataSet loading - (BOOL)loadCloudTrackerWithAccessKey:(NSString *)accessKey andPrivateKey:(NSString *)privateKey error:(NSError **)error { QCAR::TrackerManager&amp; trackerManager = QCAR::TrackerManager::getInstance(); QCAR::ImageTracker* imageTracker = static_cast</span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;QCAR::ImageTracker*&gt;</span></span></span><span class="hljs-meta">(trackerManager.getTracker(QCAR::ImageTracker::getClassType())); if (imageTracker == NULL) { NSLog(@</span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">"&gt;doLoadTrackersData&gt;Failed to load tracking data set because the ImageTracker has not been initialized."</span></span></span><span class="hljs-meta">); *error = [self errorWithCode:E_LOADING_TRACKERS_DATA]; return NO; } // Initialize visual search: QCAR::TargetFinder* targetFinder = imageTracker-&gt;getTargetFinder(); if (targetFinder == NULL) { NSLog(@</span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">"&gt;doLoadTrackersData&gt;Failed to get target finder."</span></span></span><span class="hljs-meta">); *error = [self errorWithCode:E_LOADING_TRACKERS_DATA]; return NO; } NSDate *start = [NSDate date]; // Start initialization: if (targetFinder-&gt;startInit([accessKey cStringUsingEncoding:NSUTF8StringEncoding], [privateKey cStringUsingEncoding:NSUTF8StringEncoding])) { targetFinder-&gt;waitUntilInitFinished(); NSDate *methodFinish = [NSDate date]; NSTimeInterval executionTime = [methodFinish timeIntervalSinceDate:start]; NSLog(@</span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">"waitUntilInitFinished Execution Time: %f"</span></span></span><span class="hljs-meta">, executionTime); } int resultCode = targetFinder-&gt;getInitState(); if ( resultCode != QCAR::TargetFinder::INIT_SUCCESS) { if (resultCode == QCAR::TargetFinder::INIT_ERROR_NO_NETWORK_CONNECTION) { NSLog(@</span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">"CloudReco error:QCAR::TargetFinder::INIT_ERROR_NO_NETWORK_CONNECTION"</span></span></span><span class="hljs-meta">); } else if (resultCode == QCAR::TargetFinder::INIT_ERROR_SERVICE_NOT_AVAILABLE) { NSLog(@</span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">"CloudReco error:QCAR::TargetFinder::INIT_ERROR_SERVICE_NOT_AVAILABLE"</span></span></span><span class="hljs-meta">); } else { NSLog(@</span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">"CloudReco error:%d"</span></span></span><span class="hljs-meta">, resultCode); } int initErrorCode = (resultCode == QCAR::TargetFinder::INIT_ERROR_NO_NETWORK_CONNECTION ? QCAR::TargetFinder::UPDATE_ERROR_NO_NETWORK_CONNECTION : QCAR::TargetFinder::UPDATE_ERROR_SERVICE_NOT_AVAILABLE); *error = [self cloudRecognitionErrorForCode:initErrorCode]; return NO; } else { NSLog(@</span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">"cloud target finder initialized"</span></span></span><span class="hljs-meta">); return YES; } } - (QCAR::DataSet *)loadBundleDataSetWithName:(NSString *)dataFile { DLog(@</span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">"loadImageTrackerDataSet (%@)"</span></span></span><span class="hljs-meta">, dataFile); QCAR::DataSet * dataSet = NULL; QCAR::TrackerManager&amp; trackerManager = QCAR::TrackerManager::getInstance(); QCAR::ImageTracker* imageTracker = static_cast</span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;QCAR::ImageTracker*&gt;</span></span></span><span class="hljs-meta">(trackerManager.getTracker(QCAR::ImageTracker::getClassType())); if (NULL == imageTracker) { NSLog(@</span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">"ERROR: failed to get the ImageTracker from the tracker manager"</span></span></span><span class="hljs-meta">); return NULL; } else { dataSet = imageTracker-&gt;createDataSet(); if (NULL != dataSet) { DLog(@</span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">"INFO: successfully loaded data set"</span></span></span><span class="hljs-meta">); // Load the data set from the app's resources location if (!dataSet-&gt;load([dataFile cStringUsingEncoding:NSASCIIStringEncoding], QCAR::DataSet::STORAGE_APPRESOURCE)) { NSLog(@</span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">"ERROR: failed to load data set"</span></span></span><span class="hljs-meta">); imageTracker-&gt;destroyDataSet(dataSet); dataSet = NULL; } } else { NSLog(@</span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">"ERROR: failed to create data set"</span></span></span><span class="hljs-meta">); } } return dataSet; } - (BOOL)activateDataSet:(QCAR::DataSet *)theDataSet { BOOL success = NO; // Get the image tracker: QCAR::TrackerManager&amp; trackerManager = QCAR::TrackerManager::getInstance(); QCAR::ImageTracker* imageTracker = static_cast</span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;QCAR::ImageTracker*&gt;</span></span></span><span class="hljs-meta">(trackerManager.getTracker(QCAR::ImageTracker::getClassType())); if (imageTracker == NULL) { NSLog(@</span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">"Failed to load tracking data set because the ImageTracker has not been initialized."</span></span></span><span class="hljs-meta">); } else { // Activate the data set: if (!imageTracker-&gt;activateDataSet(theDataSet)) { NSLog(@</span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">"Failed to activate data set."</span></span></span><span class="hljs-meta">); } else { NSLog(@</span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">"Successfully activated data set."</span></span></span><span class="hljs-meta">); success = YES; } } return success; } - (BOOL)deactivateDataSets { // Get the image tracker: QCAR::TrackerManager&amp; trackerManager = QCAR::TrackerManager::getInstance(); QCAR::ImageTracker* imageTracker = static_cast</span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;QCAR::ImageTracker*&gt;</span></span></span><span class="hljs-meta">(trackerManager.getTracker(QCAR::ImageTracker::getClassType())); if (imageTracker == NULL) { NSLog(@</span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">"Failed to unload tracking data set because the ImageTracker has not been initialized."</span></span></span><span class="hljs-meta">); return NO; } if(_isCloudRecognition) { QCAR::TargetFinder* finder = imageTracker-&gt;getTargetFinder(); finder-&gt;deinit(); } else { for(int i = 0; i </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt; _dataSetsCount; i++) { QCAR::DataSet *dataSet = _dataSets[i]; if(dataSet != NULL) { if (imageTracker-&gt;</span></span></span><span class="hljs-meta">deactivateDataSet(dataSet)) { DLog(@</span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">"Dataset was deactivated succesfullty"</span></span></span><span class="hljs-meta">); if(imageTracker-&gt;destroyDataSet(dataSet)) { DLog(@</span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">"Dataset was destroyed succesfullty"</span></span></span><span class="hljs-meta">); } else { NSLog(@</span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">"Failed to destroy dataset"</span></span></span><span class="hljs-meta">); } } else { NSLog(@</span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">"Failed to deactivate data set."</span></span></span><span class="hljs-meta">); } } } } return YES; } #pragma mark - Camera setup // Configure QCAR with the video background size - (void)configureVideoBackgroundWithViewWidth:(float)viewWidth andHeight:(float)viewHeight { // Get the default video mode QCAR::CameraDevice&amp; cameraDevice = QCAR::CameraDevice::getInstance(); QCAR::VideoMode videoMode = cameraDevice.getVideoMode(QCAR::CameraDevice::MODE_DEFAULT); // Configure the video background QCAR::VideoBackgroundConfig config; config.mEnabled = true; config.mSynchronous = true; config.mPosition.data[0] = 0.0f; config.mPosition.data[1] = 0.0f; // Determine the orientation of the view. Note, this simple test assumes // that a view is portrait if its height is greater than its width. This is // not always true: it is perfectly reasonable for a view with portrait // orientation to be wider than it is high. The test is suitable for the // dimensions used in this sample if (UIInterfaceOrientationIsPortrait(_interfaceOrientation)) { // --- View is portrait --- // Compare aspect ratios of video and screen. If they are different we // use the full screen size while maintaining the video's aspect ratio, // which naturally entails some cropping of the video float aspectRatioVideo = (float)videoMode.mWidth / (float)videoMode.mHeight; float aspectRatioView = viewHeight / viewWidth; if (aspectRatioVideo </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt; aspectRatioView) { // Video (when rotated) is wider than the view: crop left and right // (top and bottom of video) // --============-- // - = = _ // - = = _ // - = = _ // - = = _ // - = = _ // - = = _ // - = = _ // - = = _ // --============-- config.mSize.data[0] = (int)videoMode.mHeight * (viewHeight / (float)videoMode.mWidth); config.mSize.data[1] = (int)viewHeight; } else { // Video (when rotated) is narrower than the view: crop top and // bottom (left and right of video). Also used when aspect ratios // match (no cropping) // ------------ // - - // - - // ============ // = = // = = // = = // = = // = = // = = // = = // = = // ============ // - - // - - // ------------ config.mSize.data[0] = (int)viewWidth; config.mSize.data[1] = (int)videoMode.mWidth * (viewWidth / (float)videoMode.mHeight); } } else { // --- View is landscape --- float temp = viewWidth; viewWidth = viewHeight; viewHeight = temp; // Compare aspect ratios of video and screen. If they are different we // use the full screen size while maintaining the video's aspect ratio, // which naturally entails some cropping of the video float aspectRatioVideo = (float)videoMode.mWidth / (float)videoMode.mHeight; float aspectRatioView = viewWidth / viewHeight; if (aspectRatioVideo &lt; aspectRatioView) { // Video is taller than the view: crop top and bottom // -------------------- // ==================== // = = // = = // = = // = = // ==================== // -------------------- config.mSize.data[0] = (int)viewWidth; config.mSize.data[1] = (int)videoMode.mHeight * (viewWidth / (float)videoMode.mWidth); } else { // Video is wider than the view: crop left and right. Also used // when aspect ratios match (no cropping) // ---====================--- // - = = - // - = = - // - = = - // - = = - // ---====================--- config.mSize.data[0] = (int)videoMode.mWidth * (viewHeight / (float)videoMode.mHeight); config.mSize.data[1] = (int)viewHeight; } } // Calculate the viewport for the app to use when rendering TagViewport viewport; viewport.posX = ((viewWidth - config.mSize.data[0]) / 2) + config.mPosition.data[0]; viewport.posY = (((int)(viewHeight - config.mSize.data[1])) / (int) 2) + config.mPosition.data[1]; viewport.sizeX = config.mSize.data[0]; viewport.sizeY = config.mSize.data[1]; self.viewport = viewport; DLog(@"VideoBackgroundConfig: size: %d,%d", config.mSize.data[0], config.mSize.data[1]); DLog(@"VideoMode:w=%dh=%d", videoMode.mWidth, videoMode.mHeight); DLog(@"width=%7.3f height=%7.3f", viewWidth, viewHeight); DLog(@"ViewPort: X,Y: %d,%d Size X,Y:%d,%d", viewport.posX,viewport.posY,viewport.sizeX,viewport.sizeY); // Set the config QCAR::Renderer::getInstance().setVideoBackgroundConfig(config); } #pragma mark - Error handling // build a NSError - (NSError *)errorWithCode:(int) code { return [NSError errorWithDomain:MSImageRecognitionSessionErrorDomain code:code userInfo:nil]; } - (void)errorWithCode:(int) code error:(NSError **) error{ if (error != NULL) { *error = [self errorWithCode:code]; } } - (NSError *)cloudRecognitionErrorForCode:(int)code { NSString *description; NSString *suggestion; switch (code) { case QCAR::TargetFinder::UPDATE_ERROR_NO_NETWORK_CONNECTION: description = @"Network Unavailable"; suggestion = @"Please check your internet connection and try again."; break; case QCAR::TargetFinder::UPDATE_ERROR_REQUEST_TIMEOUT: description = @"Request Timeout"; suggestion = @"The network request has timed out, please check your internet connection and try again."; break; case QCAR::TargetFinder::UPDATE_ERROR_SERVICE_NOT_AVAILABLE: description = @"Service Unavailable"; suggestion = @"The cloud recognition service is unavailable, please try again later."; break; case QCAR::TargetFinder::UPDATE_ERROR_UPDATE_SDK: description = @"Unsupported Version"; suggestion = @"The application is using an unsupported version of Vuforia."; break; case QCAR::TargetFinder::UPDATE_ERROR_TIMESTAMP_OUT_OF_RANGE: description = @"Clock Sync Error"; suggestion = @"Please update the date and time and try again."; break; case QCAR::TargetFinder::UPDATE_ERROR_AUTHORIZATION_FAILED: description = @"Authorization Error"; suggestion = @"The cloud recognition service access keys are incorrect or have expired."; break; case QCAR::TargetFinder::UPDATE_ERROR_PROJECT_SUSPENDED: description = @"Authorization Error"; suggestion = @"The cloud recognition service has been suspended."; break; case QCAR::TargetFinder::UPDATE_ERROR_BAD_FRAME_QUALITY: description = @"Poor Camera Image"; suggestion = @"The camera does not have enough detail, please try again later"; break; default: description = @"Unknown error"; suggestion = [NSString stringWithFormat:@"An unknown error has occurred (Code %d)", code]; break; } return [NSError errorWithDomain:MSImageRecognitionSessionErrorDomain code:code userInfo:@{NSLocalizedDescriptionKey : description, NSLocalizedRecoverySuggestionErrorKey : suggestion}]; } #pragma mark - QCAR callback - (void) QCAR_onUpdate:(QCAR::State *) state { if(_isCloudRecognition) { QCAR::TrackerManager&amp; trackerManager = QCAR::TrackerManager::getInstance(); QCAR::ImageTracker* imageTracker = static_cast&lt;QCAR::ImageTracker*&gt;</span></span></span><span class="hljs-meta">(trackerManager.getTracker(QCAR::ImageTracker::getClassType())); QCAR::TargetFinder* finder = imageTracker-&gt;getTargetFinder(); // Check if there are new results available: const int statusCode = finder-&gt;updateSearchResults(); if (statusCode </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt; 0) { // Show a message if we encountered an error: NSLog(@"update search result failed:%d", statusCode); if (statusCode == QCAR::TargetFinder::UPDATE_ERROR_NO_NETWORK_CONNECTION) { //TODO } } else if (statusCode == QCAR::TargetFinder::UPDATE_RESULTS_AVAILABLE) { for (int i = 0; i &lt; finder-&gt;</span></span></span><span class="hljs-meta">getResultCount(); ++i) { const QCAR::TargetSearchResult* result = finder-&gt;getResult(i); // Check if this target is suitable for tracking: if (result-&gt;getTrackingRating() &gt; 0) { // Create a new Trackable from the result: QCAR::Trackable* newTrackable = finder-&gt;enableTracking(*result); if (newTrackable != 0) { // Avoid entering on ContentMode when a bad target is found // (Bad Targets are targets that are exists on the CloudReco database but not on our own book database) NSLog(@</span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">"Successfully created new trackable '%s' with rating '%d'."</span></span></span><span class="hljs-meta">, newTrackable-&gt;getName(), result-&gt;getTrackingRating()); NSString *name = [[NSString alloc] initWithUTF8String:newTrackable-&gt;getName()]; if(name.length) { DLog(@</span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">"recognized image with name: %@"</span></span></span><span class="hljs-meta">, name); MSDispatchMain(^{ self.recognitionBlock(name); }); } } else { NSLog(@</span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">"Failed to create new trackable."</span></span></span><span class="hljs-meta">); } } } } } else { for (int i = 0; i </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt; state-&gt;</span></span></span><span class="hljs-meta">getNumTrackableResults(); ++i) { // Get the trackable const QCAR::TrackableResult* result = state-&gt;getTrackableResult(i); const QCAR::Trackable&amp; trackable = result-&gt;getTrackable(); NSString *name = [[NSString alloc] initWithUTF8String:trackable.getName()]; if(name.length) { DLog(@</span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">"recognized image with name: %@"</span></span></span><span class="hljs-meta">, name); MSDispatchMain(^{ self.recognitionBlock(name); }); } } } } //////////////////////////////////////////////////////////////////////////////// // Callback function called by the tracker when each tracking cycle has finished void VuforiaApplication_UpdateCallback::QCAR_onUpdate(QCAR::State&amp; state) { if (__sharedInstance != nil) { [__sharedInstance QCAR_onUpdate:&amp;state]; } } @end #endif</span></span></code> </pre> <br></div></div><br><br>  In our ViewController, you first need to load the dataset (a little more about it).  To do this, do the following: <br><pre> <code class="objectivec hljs">[[MSImageRecognitionSession sharedSession] loadBundledDataSets:[<span class="hljs-keyword"><span class="hljs-keyword">self</span></span>.class dataSets] withCompletion:^(<span class="hljs-built_in"><span class="hljs-built_in">BOOL</span></span> success, <span class="hljs-built_in"><span class="hljs-built_in">NSError</span></span> *error) { MSImageRecognitionViewController *strongSelf = weakSelf; <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(!strongSelf || !_isAppeared) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span>; [strongSelf onLoadARDoneWithResult:success error:error]; }];</code> </pre><br><br>  And the final settings, if everything is loaded: <br><pre> <code class="objectivec hljs">- (<span class="hljs-keyword"><span class="hljs-keyword">void</span></span>)onLoadARDoneWithResult:(<span class="hljs-built_in"><span class="hljs-built_in">BOOL</span></span>)success error:(<span class="hljs-built_in"><span class="hljs-built_in">NSError</span></span> *)error { <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(success) { __<span class="hljs-keyword"><span class="hljs-keyword">weak</span></span> MSImageRecognitionViewController *weakSelf = <span class="hljs-keyword"><span class="hljs-keyword">self</span></span>; [[MSImageRecognitionSession sharedSession] startAR:^(<span class="hljs-built_in"><span class="hljs-built_in">BOOL</span></span> success, <span class="hljs-built_in"><span class="hljs-built_in">NSError</span></span> *error) { weakSelf.activityIndicator.hidden = <span class="hljs-literal"><span class="hljs-literal">YES</span></span>; weakSelf.cloudRecognitionSwitch.enabled = <span class="hljs-literal"><span class="hljs-literal">YES</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(!_isAppeared) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(error) { [weakSelf showAlertWithError:error]; } } recognitionBlock:^(<span class="hljs-built_in"><span class="hljs-built_in">NSString</span></span> *recognizedName) { MSImageRecognitionViewController *strongSelf = weakSelf; <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(!strongSelf || !_isAppeared) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span>; [MSFlurryAnalytics sendScreenName:kFlurryScreenSuccessRecognition]; performCompletionBlockWithData(strongSelf.recognizeCompletion, <span class="hljs-literal"><span class="hljs-literal">YES</span></span>, <span class="hljs-literal"><span class="hljs-literal">nil</span></span>, recognizedName); [strongSelf.presentingViewController dismissViewControllerAnimated:<span class="hljs-literal"><span class="hljs-literal">YES</span></span> completion:<span class="hljs-literal"><span class="hljs-literal">nil</span></span>]; }]; } <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(error) { [<span class="hljs-keyword"><span class="hljs-keyword">self</span></span> showAlertWithError:error]; <span class="hljs-keyword"><span class="hljs-keyword">self</span></span>.activityIndicator.hidden = <span class="hljs-literal"><span class="hljs-literal">YES</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">self</span></span>.cloudRecognitionSwitch.enabled = <span class="hljs-literal"><span class="hljs-literal">YES</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">self</span></span>.view.backgroundColor = <span class="hljs-literal"><span class="hljs-literal">nil</span></span>; } }</code> </pre><br><br>  This technical integration is over.  Now let's talk about data organization. <br><br>  Vuforia cannot use raw pictures as markers.  They need to be preprocessed and formed into datasets, which we will later put into the application bundle and load.  To create a dataset, you need to go to the portal <br>  <b>Develop -&gt; Target Manager -&gt; Create \ Select Database</b> . <br><br>  And then add all the pictures.  After that just click <b>Download Database</b> .  You will get two files on output: xml with a description and bin with highlighted key points. <br><br>  For the connection of the logo and the command in the database, each logo as a tag has an id command in the database.  Thus, when finding a picture, Vuforia tells us that it has found a target with a tag like this (method - <b>(void) QCAR_onUpdate: (QCAR :: State *) state</b> in the <b>MSImageRecognitionSession</b> class).  We follow this tag to the base and get the team we need. <br><br>  That's all for today.  Next time I will tell you how we added Today Extension and Watch Extension to the application. <br><br>  Github: <a href="https://github.com/DataArt/FootballClubsRecogniser/tree/master/iOS">github.com/DataArt/FootballClubsRecogniser/tree/master/iOS</a> <br>  AppStore: <a href="https://itunes.apple.com/us/app/football-clubs-recognizer/id658920969%3Fmt%3D8">itunes.apple.com/us/app/football-clubs-recognizer/id658920969?mt=8</a> </div><p>Source: <a href="https://habr.com/ru/post/256385/">https://habr.com/ru/post/256385/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../256373/index.html">CCTV on OS X</a></li>
<li><a href="../256377/index.html">Hacken und minen</a></li>
<li><a href="../256379/index.html">First sales experience at Unity Asset Store</a></li>
<li><a href="../256381/index.html">RS analysis (analysis of the fractal structure of time series)</a></li>
<li><a href="../256383/index.html">Get a grant for network security training in the Netherlands</a></li>
<li><a href="../256387/index.html">Ionic Framework - working with the camera</a></li>
<li><a href="../256389/index.html">Scrum sprint simulation. We solve problems of interaction with the client and within the team.</a></li>
<li><a href="../256393/index.html">How to make Xamarin Studio a little better?</a></li>
<li><a href="../256397/index.html">Transferring a project from iOS designers to developers</a></li>
<li><a href="../256401/index.html">Compare Visual Studio Community 2013 with Visual Studio 2013 Express. Features of the license agreement</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>