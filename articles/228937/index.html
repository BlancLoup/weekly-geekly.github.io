<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Page-cache, or how RAM and files are interconnected</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Earlier we learned how the kernel manages the virtual memory of the process, but we dropped the work with files and I / O. In this article, we will lo...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Page-cache, or how RAM and files are interconnected</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/getpro/habr/post_images/d41/e19/445/d41e194452f0d1df9c5ec039d5143ec2.png"><br><br>  Earlier we learned <a href="http://habrahabr.ru/company/smart_soft/blog/226315/">how the kernel manages the virtual memory of the</a> process, but we dropped the work with files and I / O.  In this article, we will look at the important and often misleading question of what is the relationship between RAM and file operations, and how it affects system performance. <br><a name="habracut"></a><br>  As for working with files, the operating system should solve two important problems.  The first problem is the surprisingly low speed of hard drives ( <a href="http://duartes.org/gustavo/blog/post/what-your-computer-does-while-you-wait/">especially search operations</a> ) compared to the speed of RAM.  The second problem is the possibility of <i>sharing a</i> file once loaded into RAM by different programs.  Looking at the processes using <a href="http://technet.microsoft.com/en-us/sysinternals/bb896653.aspx">Process Explorer</a> , we will see that about 15 MB of RAM in each process is spent on common DLL-libraries.  My computer is currently running 100 processes, and if it were not possible to share files in memory, then about 1.5 GB of memory would be spent <i>only on shared DLLs</i> .  This, of course, is unacceptable.  In Linux, programs also use shared libraries like ld.so, libc, and others. <br><br>  Fortunately, both problems can be solved, as they say, in one fell swoop - with the help of a <b>page cache</b> .  The page cache is used by the kernel to store fragments of files, each fragment having a size of one page.  In order to better illustrate the idea of ‚Äã‚Äãa page cache, I came up with a program called <b>render</b> , which opens the <b>scene.dat</b> file, reads it in 512 byte portions and copies them to the allocated space on the heap.  The first read operation will be performed as shown in the figure above. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      After 12 KB has been read, a bunch of render processes and related physical pages will look like this: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d5d/ead/971/d5dead97145bbd057dd990df471fc33c.png"><br>  It seems that everything is simple, but in reality everything happens a lot.  First, even despite the fact that our program uses the usual read () calls, as a result of their execution in the page cache there will be three 4-kilobyte pages with the contents of the scene.dat file.  Many people are surprised, but <b>all standard file I / O operations work through a page cache</b> .  On Linux on the x86 platform, the kernel represents the file as a sequence of 4-kilobyte fragments.  If you request the reading of just one byte from a file, this will result in the 4-kilobyte fragment containing the given byte being completely read from the disk and placed in the page cache.  Generally speaking, this makes sense, because, firstly, the performance with continuous reading from the disk (sustained disk throughput) is quite high, and, secondly, programs usually read more than one byte from a certain area of ‚Äã‚Äãthe file.  The page cache knows what place in the file each cached fragment has;  This is pictured as # 0, # 1, etc.  Windows use 256-kilobyte fragments (called ‚Äú <b>view</b> ‚Äù), which are similar in their purpose to pages in the Linux page cache. <br><br>  When using normal read operations, the data first gets into the page cache.  The programmer has access to the data in portions, through a buffer, and from it he copies them (in our example) to the area on the heap.  This approach is extremely inefficient - not only is the computational resources of the processor spent and it has a negative effect on the <a href="http://duartes.org/gustavo/blog/post/intel-cpu-caches/">processor caches</a> , but there is also a <b>waste of RAM to store copies of the same data</b> .  If you look at the previous picture, you will see that the contents of the scene.dat file are stored in duplicate at once;  any new process working with this file will copy this data again.  Thus, this is what we have achieved - we somewhat reduced the problem of latency when reading from a disk, but otherwise failed completely.  However, a solution to the problem exists - this is <b>‚Äúmemory-mapped files‚Äù</b> : <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e11/128/64f/e1112864f0e267bc42756c59098ec480.png"><br>  When a programmer uses the mapping of files to memory, the kernel maps virtual pages directly to physical pages in the page cache.  This allows you to achieve significant performance gains - in <a href="http://www.amazon.com/Windows-Programming-Addison-Wesley-Microsoft-Technology/dp/0321256190/">Windows System Programming, they</a> write about accelerating program execution time by 30% or more compared to standard file I / O operations.  Similar figures, only now for Linux and Solaris, are given in the book <a href="http://www.amazon.com/Programming-Environment-Addison-Wesley-Professional-Computing/dp/0321525949/">Advanced Programming in the Unix Environment</a> .  Using this mechanism, you can write programs that will use much less RAM (although much here also depends on the features of the program itself). <br><br>  As always, the main thing in terms of performance is <a href="http://duartes.org/gustavo/blog/post/performance-is-a-science/">measurement and visual results</a> .  But even without it, the display of files in memory quite pays for itself.  The programming interface is quite pleasant and allows you to read files as normal bytes in memory.  For the sake of all the advantages of this mechanism, you will not have to sacrifice anything special, for example, the readability of the code will not suffer in any way.  As the saying goes, the flag is in your hands - do not be afraid to experiment with your <a href="http://habrahabr.ru/company/smart_soft/blog/185226/">address space</a> and calling <a href="http://man7.org/linux/man-pages/man2/mmap.2.html">mmap</a> in Unix-like systems, calling <a href="http://msdn.microsoft.com/en-us/library/aa366537(VS.85).aspx">CreateFileMapping</a> in Windows, as well as various wrapping functions available in high-level programming languages. <br><br>  When a file is mapped into memory, its contents get there not immediately, but gradually - as the processor catches <a href="">page faults</a> caused by accessing unloaded sections of the file.  The handler for such a page fault will <a href="">find the necessary page frame</a> in the page cache and <a href="">perform the mapping of the virtual page</a> into the given page frame.  If the required data has not been previously cached in the page cache, a disk read operation will be initiated. <br><br>  And now, the question.  Imagine that the render program has completed its execution, and there are no any child processes left either.  Will the pages in the page cache that store fragments of the <i>scene.dat</i> file be <i>immediately released</i> ?  Many people think that yes - but that would be ineffective.  In general, if you try to analyze the situation, here‚Äôs what comes to mind: quite often we create a file in one program, it completes its execution, then the file is used in another program.  The page cache should provide for such situations.  <i>And in general</i> , why should the kernel, <i>in principle,</i> get rid of the contents of the page cache?  We remember that the speed of the hard disk is five orders of magnitude slower than the RAM.  And if it happens that the data have previously been cached, then we are very lucky.  That is why nothing is removed from the page cache, at least as long as there is free RAM.  The page cache <i>does not</i> depend on any particular process; on the contrary, it is such a resource that the entire system shares.  A week later, run the render again, and if the scene.dat file is still in the page cache, well, we are lucky!  That is why the page cache size gradually grows, and then its growth suddenly stops.  No, not because the operating system is a complete garbage that eats up the whole operative.  Because it should be so.  Unused RAM is also a kind of wasted resource.  It is better to use as much RAM as possible for the paging cache than not to use at all. <br><br>  When the program makes a <a href="http://man7.org/linux/man-pages/man2/write.2.html">write ()</a> call, the data is simply copied to the corresponding page in the page cache, and it is marked with the ‚Äúdirty‚Äù flag.  Writing directly to the hard disk itself <b>does not</b> happen immediately, and there is no point in blocking the program while waiting for the disk subsystem to become available.  This behavior has its disadvantage - if the computer falls into the blue screen, the data may never get to the disk.  That is why critical files, such as database transaction log files, need to be synchronized with a special <a href="http://man7.org/linux/man-pages/man2/fsync.2.html">fsync ()</a> call (but in general, there is also a hard disk controller cache, so you cannot be absolutely sure that the write operation is successful).  The read () call, on the other hand, blocks the program until the disk becomes available and the data is not read.  In order to somewhat mitigate this problem, the operating systems use the so-called.  ‚ÄúEager loading method‚Äù (eager loading), and an example of this method is <b>‚Äúread ahead‚Äù</b> .  When read-ahead is enabled, the kernel proactively loads a certain number of file fragments into the page cache, thus anticipating subsequent read requests.  You can help the kernel with the choice of optimal parameters for read ahead, choosing a parameter depending on how you are going to read the file - sequentially or in a random order (calls <a href="http://man7.org/linux/man-pages/man2/madvise.2.html">madvise ()</a> , <a href="http://man7.org/linux/man-pages/man2/readahead.2.html">readahead ()</a> , on Windows - <a href="http://msdn.microsoft.com/en-us/library/aa363858(VS.85).aspx">cache hints</a> ).  Linux <a href="">uses read-ahead</a> for memory-mirrored files;  About Windows, I'm not sure.  Finally, you can not use the page cache at all - the <a href="http://man7.org/linux/man-pages/man2/open.2.html">O_DIRECT</a> flags in Linux and <a href="http://msdn.microsoft.com/en-us/library/cc644950(VS.85).aspx">NO_BUFFERING</a> in Windows are responsible for this;  databases do this quite often. <br><br>  File mapping into memory can be of two types - either <b>private</b> or <b>shared</b> .  These terms refer only to how the system will react to <b>changes</b> in the in-memory data: in the case of shared mappings, any changes to the data will be flushed to disk or will be visible in other processes;  in the case of private mappings, this will not happen.  To implement private-mapping, the kernel relies on the <b>copy-on-write</b> mechanism, which is based on the specific use of entries in page-tables.  In the following example, our render program, as well as the render3d program (and I have a talent for inventing program names!), Create a private-mapping for the scene.dat file.  Then, render writes to the virtual memory area that is assigned to the file: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/7e2/0f0/155/7e20f01551c72eb7955f41db2189ed8e.png"><br><br>  The fact that the entries in the page-tables are read-only (see figure) should not confuse us;  and this <i>does not</i> mean that the mapping will be available only for reading.  This is simply a technique by which the kernel shares the page with different processes and delays the need to create a copy of the page until the very last moment.  Looking at the picture you understand that the term ‚Äúprivate‚Äù is probably not the most successful, but if you remember that it describes only the behavior when data <i>changes</i> , then everything is fine.  The mapping mechanism has one more feature.  Suppose there are two programs that are not related to the "parent process - child process" relationship.  Programs work with the same file, but it is mapped differently - in one program it is private-mapping, in the other - shared-mapping.  So, a program with private mapping (let's call it ‚Äúthe first program‚Äù) will see all the changes made by the second program to a certain page, <i>until the first program tries to write something to this page</i> (which will lead to a separate copy of the page for the first program).  Those.  as soon as the copy-on-write mechanism is completed, changes made by other programs will not be visible.  The kernel does not guarantee this behavior, but in the case of x86 processors, this is what happens;  and this has a definite meaning, even from the point of view of the same API. <br><br>  As for shared-mapping, here the situation is as follows.  Pages are set to read / write permissions, and they are simply mapped to the page cache.  Thus, whoever makes changes to the page, all processes will see it.  In addition, the data is reset to the hard disk.  Finally, if the pages in the previous figure would be really read-only, then the page fault caught when accessing them would cause a segmentation fault, rather than working out the copy-on-write logic. <br><br>  Shared libraries are also mapped to memory like any other files.  There is nothing special about this - all the same private mapping available to the programmer through an API call.  The following is an example showing a part of the address space of two copies of the render program using the file-to-memory mechanism.  In addition, the corresponding areas of physical memory are shown.  Thus, we can link together the concepts we met in this article: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/134/ca8/a74/134ca8a741c16d0764189fd1f896c8a0.png"><br><br>  This concludes our series of three articles on the basics of memory.  I hope the information was useful for you and allowed you to make a general idea on this topic. <br><br>  Links to articles in the series: <br><br><ul><li>  Process memory organization <br>  <a href="http://habrahabr.ru/company/smart_soft/blog/185226/">habrahabr.ru/company/smart_soft/blog/185226</a> <br>  <a href="http://duartes.org/gustavo/blog/post/anatomy-of-a-program-in-memory/">duartes.org/gustavo/blog/post/anatomy-of-a-program-in-memory</a> </li><li>  How the kernel manages memory <br>  <a href="http://habrahabr.ru/company/smart_soft/blog/226315/">habrahabr.ru/company/smart_soft/blog/226315</a> <br>  <a href="http://duartes.org/gustavo/blog/post/how-the-kernel-manages-your-memory/">duartes.org/gustavo/blog/post/how-the-kernel-manages-your-memory</a> </li><li>  Page-cache, or how RAM and files are interconnected <br>  <a href="http://habrahabr.ru/company/smart_soft/blog/227905/">habrahabr.ru/company/smart_soft/blog/227905</a> <br>  <a href="http://duartes.org/gustavo/blog/post/page-cache-the-affair-between-memory-and-files/">duartes.org/gustavo/blog/post/page-cache-the-affair-between-memory-and-files</a> </li></ul><br><br>  The material was prepared by the staff of the company Smart-Soft - <a href="http://smart-soft.ru/">smart-soft.ru</a> . </div><p>Source: <a href="https://habr.com/ru/post/228937/">https://habr.com/ru/post/228937/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../228915/index.html">RZD application redesign: concept</a></li>
<li><a href="../228919/index.html">On the roads of Germany drove a robot truck from Mercedes</a></li>
<li><a href="../228921/index.html">CyberData SIP Alerts</a></li>
<li><a href="../228931/index.html">How does a cloud company finance</a></li>
<li><a href="../228933/index.html">Where data centers live well, or regional features of the IT infrastructure market</a></li>
<li><a href="../228939/index.html">The last day of early registration at WebCamp and additional discounts for Habrahabr readers</a></li>
<li><a href="../228941/index.html">New mobile financial service ... any ideas?</a></li>
<li><a href="../228943/index.html">Vidon.me AV200: the revolution or evolution of Android players or what can come out of XBMC if you add DVDFab to it?</a></li>
<li><a href="../228949/index.html">Working with JSON in Swift</a></li>
<li><a href="../228951/index.html">[Translation] Magic methods in PHP</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>