<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Determination of the dominant signs of classification and the development of a mathematical model of facial expressions</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Content: 
 1. Search and analysis of the optimal color space for the construction of eye-catching objects on a given class of images 
 2. Determinatio...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Determination of the dominant signs of classification and the development of a mathematical model of facial expressions</h1><div class="post__text post__text-html js-mediator-article"><h4>  Content: </h4><br>  1. <a href="http://habrahabr.ru/post/229757/">Search and analysis of the optimal color space for the construction of eye-catching objects on a given class of images</a> <br>  2. <a href="http://habrahabr.ru/post/229817/">Determination of the dominant signs of classification and the development of a mathematical model of facial expressions "</a> <br>  3. <a href="http://habrahabr.ru/post/229895/">Synthesis of optimal facial recognition algorithm</a> <br>  4. <a href="http://habrahabr.ru/post/229949/">Implementation and testing of facial recognition algorithm</a> <br>  5. <a href="http://habrahabr.ru/post/230053/">Creating a test database of images of users' lips in various states to increase the accuracy of the system</a> <br>  6. <a href="http://habrahabr.ru/post/230133">Search for the best open source audio speech recognition system</a> <br>  7. <a href="http://habrahabr.ru/post/231629/">Search for the optimal audio system of speech recognition with closed source code, but having open API, for the possibility of integration</a> <br>  8. <a href="http://habrahabr.ru/post/231821/">Experiment for integrating video extensions into audio speech recognition system with test report</a> <br><br><h4>  Goals </h4><br>  Determine the dominant features of the classification of the object of localization and develop a mathematical model for the task of image analysis of facial expressions. <br><br><h4>  Tasks </h4><br>  Search and analysis of methods of localization of the face, the definition of the dominant signs of classification, the development of a mathematical model optimal for the tasks of recognition of the movement of facial expressions. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h4>  Theme </h4><br>  In addition to determining the optimal color space for constructing eye-catching objects in a given image class, which was carried out at the previous stage of the study, the determination of the dominant signs of classification and the development of a mathematical model of mimic images also plays an important role. <br><br>  To solve this problem, it is necessary, first of all, to set the system to features the modification of the face detection task with a video camera, and then localize the movement of the lips. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/6d5/a5f/9c2/6d5a5f9c2d126d9f6f712934bdf32922.png" alt="image"><br><br>  As for the first task, two types of them should be distinguished: <br>  ‚Ä¢ Face localization; <br>  ‚Ä¢ Face tracking [1]. <br>  Since we are faced with the task of developing a facial recognition algorithm, it is logical to assume that this system will be used by one user who will not move his head too actively.  Therefore, to implement the lip motion recognition technology, it is necessary to take as a basis a simplified version of the detection problem, where there is one and only one face on the image. <br><br>  This means that the search for a face can be carried out relatively rarely (about 10 frames / second or even less).  At the same time, the movements of the speaker‚Äôs lips during a conversation are quite active, and, consequently, the assessment of their contour should be carried out with greater intensity. <br><a name="habracut"></a><br>  The task of finding a person in an image can be solved by existing means.  Today there are several methods for detecting and localizing faces in an image, which can be divided into 2 categories: <br>  1. Empirical recognition; <br>  2. Modeling a face image.  [2]. <br><br>  The first category includes top-down recognition methods based on invariant features of face images, based on the assumption that there are some signs of the presence of faces on the image that are invariant with respect to shooting conditions.  These methods can be divided into 2 subcategories: <br>  1.1.  Detection of elements and features (features) that are characteristic for the image of the face (edges, brightness, color, characteristic shape of facial features, etc.) [3], [4] .; <br>  1.2.  Analysis of the detected features, making decisions on the number and location of faces (empirical algorithm, statistics of the relative position of features, modeling of visual image processes, the use of rigid and deformable patterns, etc.) [5], [6]. <br><br>  For the correct operation of the algorithm, it is necessary to create a database of facial features with subsequent testing.  For a more accurate implementation of empirical methods, models can be used that take into account the possibilities of face transformation, and, therefore, have either an extended set of basic data for recognition, or a mechanism to simulate the transformation on the basic elements.  Difficulties with the construction of a database of a classifier aimed at a very different range of users with individual features, facial features, and so on, helps to reduce the recognition accuracy of this method. <br><br>  The second category includes the methods of mathematical statistics and machine learning.  Methods in this category rely on pattern recognition tools, considering the problem of face detection as a special case of a recognition problem.  The image is put a certain feature vector, which is used to classify the images into two classes: face / not face.  The most common way to obtain a feature vector is to use the image itself: each pixel becomes a component of a vector, turning an n √ó m image into the vector of the space R ^ (n √ó m), where n and m are positive integers.  [7].  The disadvantage of this view is the extremely high dimension of the feature space.  The advantage of this method is to exclude from the whole procedure the construction of a classifier of human participation, as well as the possibility of training the system itself for a specific user.  Therefore, the use of image modeling methods to build a mathematical model of face localization is optimal for solving our problem. <br><br>  With regard to the segmentation of the profile of the face and tracking the position of the points of the lips on the sequence of frames, then to solve this problem, you should also use mathematical modeling methods.  There are several ways to determine the movement of facial expressions, the most famous of which are the use of a mathematical model based on active contour models: <br><br><h4>  Localization of facial expression based on a mathematical model of active contour models </h4><br>  The active contour (snake) is a deformable model, the template of which is specified in the form of a parametric curve, initialized manually by a set of control points lying on an open or closed curve on the input image. <br><br>  To adapt the active contour to the image of the facial expression, it is necessary to conduct the appropriate binarization of the object under study, that is, its conversion into a kind of digital raster images, and then the corresponding assessment of the active contour parameters and the calculation of the feature vector should be carried out. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/03a/61d/165/03a61d165895a1f4f5aea2902e50e7c3.png" alt="image"><br><br>  The active contour model is defined as: <br>  ‚Ä¢ The set of points N; <br>  ‚Ä¢ internal regions of energy of interest (internal elastic energy term); <br>  ‚Ä¢ external areas of energy of interest (external edge based energy term). <br><br>  To improve the quality of recognition, two color classes are distinguished - skin and lips.  The function of belonging to a color class has a value from 0 to 1. <br><br>  The equation of the active contour model (snake) is expressed by the formula v (s) as: <br><img src="https://habrastorage.org/getpro/habr/post_images/32f/7d6/cd9/32f7d6cd9a087c67ab0b7b7e2c247346.png" alt="image"><br>  Where E is the energy of the snake (active contour model).  The first two terms describe the regularity energy of the active contour model (snake).  In our polar coordinate system, v (s) = [r (s), Œ∏ (s)], s from 0 to 1. The third term is the energy related to the external force obtained from the image, the fourth with the pressure force. <br><br>  External force is determined based on the above characteristics.  It is able to shift control points to a certain intensity value.  It is calculated as: <br><img src="https://habrastorage.org/getpro/habr/post_images/ebf/2ef/021/ebf2ef02119cd8a6c0776b2addc2fd23.png" alt="image"><br>  The gradient multiplier (derivative) is calculated at the snake points along the corresponding radial line.  The force increases if the gradient is negative and decreases in the opposite case.  The coefficient before the gradient is a weight factor depending on the topology of the image.  The compressive force is simply a constant, using ¬Ω of the minimum weighting factor.  The best snake shape is obtained by minimizing the energy functional after a certain number of iterations. <br><br>  Consider the basic image processing operations in more detail.  For simplicity, we assume that we have already somehow identified the area of ‚Äã‚Äãthe speaker‚Äôs mouth.  In this case, the basic operations for processing the received image that we need to perform are shown in Fig.  3 <br><br><img src="https://habrastorage.org/getpro/habr/post_images/934/0a3/3d7/9340a33d7d3bd823efc76dbb91468bb6.png" alt="image"><br><br><h4>  Conclusion </h4><br>  To determine the dominant features of the image classification in the course of the research work, the features of the modification of the face detection problem with a video camera were identified.  Among all methods of face localization and detection of the studied area of ‚Äã‚Äãmimicry, the most appropriate for creating a universal recognition system for mobile devices are face image modeling methods. <br>  The development of a mathematical model of images of the movement of facial expression is based on a system of active contour models of binarization of the object under study.  Since this mathematical model allows, after changing the color space from RGB to the YCbCr color model, it is possible to effectively transform the object of interest for its subsequent analysis based on active contour models and to identify clear boundaries of mimic after appropriate image iterations. <br><br><h4>  List of used sources </h4><br>  1. Vezhnevets V., Dyagtereva A. Detection and localization of the face in the image.  CGM Journal, 2003 <br>  2. Ibid. <br>  3. E. Hjelmas and BK Low, Face detection, Journal of Computer vision and image understanding, vol.83, pp.  236-274, 2001. <br>  4. G. Yang and TS Huang, Pattern recognition, vol.27, no.1, pp.53-63, 1994 <br>  5. K. Sobottka and I. Pitas, A novel method for automatic face segmentation, facial feature extraction and tracking, Signal processing: Image communication, Vol.  12, No. 3, pp.  263-281, June, 1998 <br>  6. F. Smeraldi, O. Cormona, and J.Big.un., Saccadic search and image-real-time head tracking, Image Vision Comput.  18, pp.  323-329,200 <br>  7. Gomozov A.A., Kryukov A.F.  Analysis of empirical and mathematical algorithms for recognition of a human face.  Network-journal.  Moscow Power Engineering Institute (Technical University).  ‚Ññ1 (18), 2011 <br><br>  <i>To be continued</i> </div><p>Source: <a href="https://habr.com/ru/post/229817/">https://habr.com/ru/post/229817/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../229805/index.html">Visas for startups: how to open your own business abroad (part 2)</a></li>
<li><a href="../229809/index.html">Formatting Images with Canvas</a></li>
<li><a href="../229811/index.html">WinJS on Windows Phone 8.1</a></li>
<li><a href="../229813/index.html">My corporate communications experience in Social Media</a></li>
<li><a href="../229815/index.html">Available for download WordPress 4.0 Beta 1</a></li>
<li><a href="../229819/index.html">Dialectics of the SATA Revolution</a></li>
<li><a href="../229821/index.html">Yandex in the new CERN experiment: how to find dark matter in just 13 years</a></li>
<li><a href="../229823/index.html">Interview with Chris Lacy - Link Bubble Developer and Action Launcher</a></li>
<li><a href="../229825/index.html">Blacker than black: carbon nanotubes created a coating with a record low reflection coefficient</a></li>
<li><a href="../229827/index.html">The creation of a ‚Äú100% Russian software platform‚Äù has begun</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>