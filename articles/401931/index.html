<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>By becoming smarter, cars start learning almost as much as we</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Research shows that computer models, known as neural networks used in an increasing number of applications, can learn to recognize sequences in data u...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>By becoming smarter, cars start learning almost as much as we</h1><div class="post__text post__text-html js-mediator-article"><h3>  Research shows that computer models, known as neural networks used in an increasing number of applications, can learn to recognize sequences in data using the same algorithms as the human brain. </h3><br><img src="https://habrastorage.org/getpro/geektimes/post_images/c2c/1bf/8e1/c2c1bf8e1a76f607108a26cfb43a4858.jpg" alt="image"><br><br>  The brain solves its canonical problem ‚Äî learning ‚Äî by arranging many of its compounds according to an unknown set of rules.  To uncover these rules, scientists 30 years ago began to develop computer models trying to reproduce the learning process.  Today, in a growing number of experiments, it becomes clear that these models behave in a way very similar to the real brain when performing certain tasks.  Researchers say that this similarity speaks of the basic correspondence between the brain and computer learning algorithms. <br><br>  The algorithm used by the computer model is called <a href="https://ru.wikipedia.org/wiki/%25D0%259C%25D0%25B0%25D1%2588%25D0%25B8%25D0%25BD%25D0%25B0_%25D0%2591%25D0%25BE%25D0%25BB%25D1%258C%25D1%2586%25D0%25BC%25D0%25B0%25D0%25BD%25D0%25B0">the Boltzmann machine</a> .  He was <a href="http://www.learning.cs.toronto.edu/~hinton/absps/cogscibm.pdf">invented by</a> Geoffrey Hinton and Terry Seinovsky in 1983 [in fact, in <a href="https://ru.wikipedia.org/wiki/%25D0%259C%25D0%25B0%25D1%2588%25D0%25B8%25D0%25BD%25D0%25B0_%25D0%2591%25D0%25BE%25D0%25BB%25D1%258C%25D1%2586%25D0%25BC%25D0%25B0%25D0%25BD%25D0%25B0">1985</a> - approx.  trans.].  It looks very promising as a simple theoretical explanation of several processes occurring in the brain - development, memory formation, recognition of objects and sounds, the cycle of sleep and wakefulness. <br><a name="habracut"></a><br>  "This is the best opportunity we have today for understanding the brain," said Sue Becker, a professor of psychology, neuroscience and behavior at the University.  McMaster in Hamilton, Ontario.  ‚ÄúI don‚Äôt know a model describing a wider range of phenomena related to learning and brain structure.‚Äù 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Hinton, a pioneer in the field of AI, always wanted to understand the rules by which the brain strengthens the connection or weakens it - that is, the learning algorithm.  ‚ÄúI decided that in order to understand something, it must be built,‚Äù he says.  Following the reductionist approach of physicists, he plans to create simple computer models of the brain using different learning algorithms and see "which ones will work," says Hinton, who works partly at Toronto University as a computer science professor, and partly at Google. <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/e09/ca7/de6/e09ca7de64952922dee2dc5c0e51d154.png" alt="image"><br>  <i>Multilayer neural networks consist of layers of artificial neurons with weighted connections between them.</i>  <i>The incoming data is sent to the cascade of signals by layers, and the algorithm determines the change in the weights of each connection.</i> <br><br>  In the 1980s and 1990s, Hinton, the great-great-great-great grandson of the nineteenth-century logic of George Buhl, whose work formed the basis of modern computer science, invented several machine learning algorithms.  Algorithms that control how a computer learns from data are used in computer models called ‚Äúartificial neural networks‚Äù - the web of interconnected virtual neurons that transmit signals to their neighbors, turning on or off, or ‚Äútriggered‚Äù.  When data is fed into the network, this leads to a cascade of positives, and based on the picture of these positives, the algorithm chooses to increase or decrease the weights of connections, or synapses, between each pair of neurons. <br><br>  For decades, many Hinton computer models have subsided.  But thanks to advances in processor power, advances in understanding the brain and algorithms, neural networks play an ever-increasing role in neuroscience.  Sejnowski, head of the Computational Laboratory of Neurobiology at the Institute of Biological Research.  Salk in La Jolie (California), says: ‚ÄúThirty years ago we had very rough ideas;  Now we are starting to check some of them. ‚Äù <br><br><h2>  Brain machines </h2><br>  Hinton‚Äôs early attempts to reproduce the brain were limited.  Computers could execute its learning algorithms on small neural networks, but the scaling of models very quickly overloaded the processors.  In 2005, Hinton discovered that if the neural networks are divided into layers and the algorithms are run separately on each layer, approximately repeating the structure and development of the brain, the process becomes more efficient. <br><br>  Although Hinton published his discovery in <a href="http://www.sciencemag.org/content/313/5786/504.short">two</a> <a href="">well-known journals</a> , neural networks were out of fashion by that time, and he "struggled to get people interested," said Li Deng, a lead researcher at Microsoft Research.  However, Deng knew Hinton and decided to try out his ‚Äúdepth learning‚Äù method in 2009, quickly recognizing his potential.  In subsequent years, learning algorithms are used in practice in a growing number of applications, such as Google Now‚Äôs personal assistant or voice search feature on Microsoft Windows phones. <br><br>  One of the most promising algorithms, the Boltzmann machine, is named after the 19th century Austrian physicist Ludwig Boltzmann, who developed the physics section dealing with a large number of particles, known as statistical mechanics.  Boltzmann discovered an equation that gives the probability of possessing a molecular gas of a certain energy when it reaches equilibrium.  If the molecules are replaced by neurons, the result will tend to the same equation. <br><br>  The network synapses begin with a random distribution of weights, and the weights are gradually adjusted according to a fairly simple procedure: the generated response scheme in the process of acquiring data by the machine (such as images or sounds) is compared to the random response scheme of the machine that occurs when no data is entered. <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/68c/dfb/775/68cdfb7753fc04e80a2940469564726e.jpg" alt="image"><br>  <i>Geoffrey Hinton believes that building computers studying in the same way would be the best approach to understanding the learning processes in the brain.</i> <br><br>  Each virtual synapse tracks both statistical sets.  If the neurons it connects often trigger in close sequence when receiving data than during random operation, the weight of the synapse increases by a quantity proportional to the difference.  But if two neurons more often work together during random operation, then the synapse connecting them is considered too strong and weakened. <br><br>  The most commonly used version of the Boltzmann machine works best after the ‚Äúworkout‚Äù, reworking thousands of examples of data sequentially on each layer.  First, the lower layer of the network receives raw data in the form of images or sounds, and, in the manner of retinal cells, neurons work if they detect contrasts in their data section, such as switching from light to dark.  Their triggering may trigger the activation of neurons associated with them, depending on the weight of the synapse connecting them.  As the triggering of pairs of virtual neurons is constantly compared with the background statistics, meaningful connections between neurons gradually appear and strengthen.  The weights of synapses are refined, and the categories of sounds and images are embedded in the connections.  Each subsequent layer is trained in a similar way, using data from the layer below it. <br><br>  If you feed the car image of a neural network, trained to detect certain objects in the images, the bottom layer will work if it detects a contrast indicating a face or end point.  These signals will pass to higher level neurons defining angles, parts of wheels, etc.  In the upper level, neurons are triggered only in response to the image of the car. <br><br>  ‚ÄúThe magic of what is happening on the web is that it can generalize,‚Äù says Yann LeCun, director of the Center for Data Science at New York University.  ‚ÄúIf you show her a car she had never seen before, and if the car has some forms and features that are common to the cars shown to her during the training session, she can determine that this is a car.‚Äù <br><br>  Neural networks have recently accelerated their development due to the Hinton multilayer mode, the use of high-speed computer chips for graphics processing and the explosive growth in the number of images and voice recording available for training.  Networks are able to correctly recognize 88% of the words in English, while the average person recognizes 96%.  They can identify cars and thousands of other objects in images with similar accuracy, and have taken a dominant position in machine learning competitions over the past few years. <br><br><h2>  Building a brain </h2><br>  No one knows how to directly figure out the rules by which the brain is trained, but there are many indirect coincidences between the behaviors of the brain and the Boltzmann machine. <br><br>  Both are trained without supervision, using only the patterns that exist in the data.  ‚ÄúYour mother doesn‚Äôt tell you a million times about what is shown in the picture,‚Äù says Hinton.  - You have to learn to recognize things without the advice of others.  After you study the categories, you are informed of the names of these categories.  So kids will learn about dogs and cats, and then they will find out that dogs are called ‚Äûdogs‚Äú and cats are called ‚Äûcats‚Äú. <br><br>  The adult brain is not as flexible as the young one, just as the Boltzmann machine, having trained on 100,000 images of cars, will not change much after seeing another one.  Her synapses have already established the necessary weights for categorizing cars.  But learning does not end there.  New information can be integrated into the structure of both the brain and the Boltzmann machine. <br><br>  Over the past two decades, the study of brain activity in a dream has provided the first evidence that the brain uses an algorithm similar to Boltzmann to incorporate new information and memories into its structure.  Neuroscientists have long known that sleep plays an important role in memory consolidation and helps integrate new information.  In 1995, Hinton and colleagues <a href="http://www.gatsby.ucl.ac.uk/~Dayan/papers/hdfn95.pdf">suggested</a> that sleep plays the role of a baseline in the algorithm, denoting the activity of neurons in the absence of input data. <br><br>  ‚ÄúDuring sleep, you just figure out the base frequency of the neurons,‚Äù says Hinton.  - You find out the correlation of their work in the case when the system works by itself.  And then, if the neurons correlate more, simply increase the weights between them.  And if less, reduce weight. " <br><br>  At the synapse level, ‚Äúthis algorithm can be provided in several ways,‚Äù says Sezhnovsky, an adviser to the presidential administration within the framework of <a href="http://www.whitehouse.gov/infographics/brain-initiative">the BRAIN initiative</a> , a study with a $ 100 million grant, designed to develop new techniques for studying the brain. <br><br>  He says that it‚Äôs easiest for the brain to work with the Boltzmann algorithm, switching from building up synapses during the day to reducing them at night.  <a href="http://tononi.psychiatry.wisc.edu/People/GiulioTononi.php">Giulio Tononi</a> , head of the Center for the Study of Sleep and Consciousness at the University of Wisconsin-Madison, found that gene expression in synapses changes them according to this hypothesis: the genes involved in the growth of synapses are more active during the day, and the genes involved in contraction synapses - at night. <br><br>  Alternatively, ‚Äúthe baseline can be calculated in a dream, and then changes relative to it can be made during the day,‚Äù says Sezhnovsky.  In his lab, detailed computer models of synapses and their supported networks are built to determine how they collect statistics on wakefulness and sleep activity, and when the strength of synapses changes to reflect this difference. <br><br><h2>  Brain problems </h2><br><img src="https://habrastorage.org/getpro/geektimes/post_images/784/a3b/721/784a3b7213087f712c156f1ad62a346d.jpg" alt="image"><br>  <i>Image of the retina, on which different cell types are indicated by different colors.</i>  <i>The color sensitive (purple) are connected to the horizontal (orange), which are connected to the bipolar (green), and those to the cells of the retina and ganglion (purple).</i> <br><br>  The Boltzmann algorithm may turn out to be one of many used by the brain to adjust synapses.  In the 1990s, several independent groups developed a theoretical model of how the visual system effectively encodes the flow of information going to the retina.  The theory postulated that in the lower layers of the visual cortex there is a process of ‚Äúscattered coding‚Äù, similar to image compression, with the result that the later stages of the visual system work more efficiently. <br><br>  Predictions of the model gradually pass more and more rigorous tests.  In a <a href="http://www.ploscompbiol.org/article/info%253Adoi%252F10.1371%252Fjournal.pcbi.1003005">paper</a> published in PLOS Computational Biology, computational neuroscientists from Britain and Australia found that when neural networks using the Products of Experts scattered coding algorithm invented by Hinton in 2002, the same unusual visual data that live cats receive (for example, cats and neural networks study striped images), their neurons produce almost identical unusual connections. <br><br>  ‚ÄúBy the time information reaches the visual cortex, the brain, we believe, presents it as scattered code,‚Äù says Bruno Olshausen, a computational neuroscientist and director of the Redwood Center for Theoretical Neurobiology at the University of California-Berkeley, who helped develop scattered coding theory.  ‚ÄúIt‚Äôs as if Boltzmann‚Äôs machine is sitting in your head and trying to understand the connections between the elements of the scattered code.‚Äù <br><br>  Olshausen and the team used the neural networks of the higher layers of the visual cortex to show how the brain is able to <a href="http://redwood.berkeley.edu/bruno/papers/cadieu-olshausen-nc12.pdf">maintain a stable perception of visual input</a> despite the movement of images.  In another <a href="http://arxiv.org/pdf/1301.0050v1.pdf">study,</a> they found that the activity of the neurons of the visual cortex of cats that observed a black-and-white film is very well described by the Boltzmann machine. <br><br>  One of the possible applications of this work is the creation of neuroprostheses, for example, an artificial retina.  If you figure out how ‚Äúinformation is formatted in the brain, you can understand how to stimulate the brain to make it think that it sees the image,‚Äù says Olshausen. <br><br>  Seznowski says that understanding the algorithms for growing and decreasing synapses will allow researchers to change them and study how the functioning of the neural network is disturbed.  ‚ÄúThen they can be compared to the known problems of people,‚Äù he says.  - Almost all mental disorders can be explained by problems with synapses.  If we can better understand synapses, we can understand how the brain functions normally, how it processes information, how it learns, and what goes wrong if you have, say, schizophrenia. ‚Äù <br><br>  The approach to the study of the brain using neural networks contrasts sharply with the approach of the <a href="http://www.humanbrainproject.eu/">Human Brain Project</a> .  This is the advertised plan of the Swiss neurobiologist Henry Markram to create an accurate simulation of the human brain using a supercomputer.  Unlike the Hinton approach, which begins with a highly simplified model and follows a path of gradual complication, Markram wants to immediately include the largest possible amount of data, up to individual molecules, and hopes that as a result he will have full functionality and consciousness. <br><br>  The project has received funding in the amount of $ 1.3 billion from the European Commission, but Hinton believes that this mega-simulation will fail, stuck in too many moving parts, which no one yet understands. <br><br>  In addition, Hinton does not believe that the brain can only be sorted out by its images.  Such data should be used to create and refine algorithms.  ‚ÄúIt requires theoretical thinking and study of the space of learning algorithms in order to create a theory like the Boltzmann machine,‚Äù he says.  The next step for Hinton is the development of algorithms for training even more brain-like neural networks, such that synapses connect neurons within a single layer, and not just between different layers.  ‚ÄúThe main goal is to understand the benefits that can be gained by complicating the calculations at each stage,‚Äù he says. <br><br>  The hypothesis is that a greater number of connections will lead to an increase in the return loops, which, according to Olshausen, most likely help the brain to ‚Äúfill in the missing parts‚Äù.  The higher layers interfere with the work of neurons from the lower layers dealing with partial information.  ‚ÄúAll this is closely related to consciousness,‚Äù he says. <br><br>  The human brain is still much more complex than any model.  It is larger, denser, more efficient, it has more interconnections and complex neurons - and it simultaneously works with several algorithms.  Olshausen suggests that we understand about 15% of the activity of the visual cortex.  Although the models are progressing, neuroscience is still ‚Äúsimilar to physics before Newton,‚Äù he says.  Nevertheless, he is confident that the process of working on the basis of these algorithms will someday be able to explain the main puzzle of the brain - how data from the senses are transformed into a subjective sense of reality.  Consciousness, says Olshausen, "is something that emerges from reality, a very complex Boltzmann machine." </div><p>Source: <a href="https://habr.com/ru/post/401931/">https://habr.com/ru/post/401931/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../401921/index.html">Mail.ru plans to integrate the Delivery Club and a number of other services into the VKontakte mobile app.</a></li>
<li><a href="../401923/index.html">5 myths about projectors. Myth # 2 - ‚ÄúColor Brightness‚Äù - a projector feature invented by marketers</a></li>
<li><a href="../401925/index.html">Presented by Pi Zero W</a></li>
<li><a href="../401927/index.html">Rocket Fuel Saga - The Other Side</a></li>
<li><a href="../401929/index.html">SpaceX: next year we will send two space tourists to the Moon</a></li>
<li><a href="../401935/index.html">Mozilla Acquired Pocket Deferred Reading Service</a></li>
<li><a href="../401937/index.html">Yandex ignores the 3D Secure check when paying for advertising in Yandex.Direct using bank cards</a></li>
<li><a href="../401939/index.html">Children's carpentry machine PLAYMAT: do-it-yourself woodworking is interesting</a></li>
<li><a href="../401941/index.html">Overview of the new Oco2 security camera</a></li>
<li><a href="../401943/index.html">A brief biography of the Intel Atom family</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>