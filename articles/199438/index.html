<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Pessimal Algorithms and Computational Complication Analysis</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="‚ÄúSimplexity is a process by which nature achieves simple results in complex ways.‚Äù - Bruce Schiff 



 1. Introduction 
 Imagine the following task: w...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Pessimal Algorithms and Computational Complication Analysis</h1><div class="post__text post__text-html js-mediator-article"><blockquote>  ‚ÄúSimplexity is a process by which nature achieves simple results in complex ways.‚Äù - Bruce Schiff <br></blockquote><br><img src="https://habrastorage.org/getpro/habr/post_images/b3e/9a1/587/b3e9a1587003735b8fae939044d592a2.jpg"><br><br><h2>  1. Introduction </h2><br>  Imagine the following task: we have a table of <i>n</i> integer keys <em>A <sub>1</sub> , A <sub>2</sub> , ..., A <sub>n</sub></em> , and an integer value <em>X.</em>  We need to find the index of the number <em>X</em> in this table, <b>but at the same time we are not particularly in a hurry.</b>  <b>In fact, we would like to do it as long as possible.</b> <br><br>  For this task, we could dwell on the most trivial algorithm, namely, iterate over all An <em><sub>n</sub></em> in order and compare them with <em>X.</em>  But, it may happen that <em>X</em> = <em>A <sub>1</sub></em> , and the algorithm stops at the very first step.  Thus, we see that the naive algorithm in the best case has the time complexity <em><a href="http://ru.wikipedia.org/wiki/%25C2%25ABO%25C2%25BB_%25D0%25B1%25D0%25BE%25D0%25BB%25D1%258C%25D1%2588%25D0%25BE%25D0%25B5_%25D0%25B8_%25C2%25ABo%25C2%25BB_%25D0%25BC%25D0%25B0%25D0%25BB%25D0%25BE%25D0%25B5">O (1)</a></em> .  The question arises - can we improve (that is, worsen) this result? 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Of course, we can greatly slow down this algorithm by adding empty cycles to it before the first test of the equality of <em>X</em> and <em>A <sub>1</sub></em> .  But, unfortunately, this method does not suit us, because any fool will notice that the algorithm simply wastes time.  Thus, we need to find such an algorithm, which would nevertheless move towards the goal, despite the lack of enthusiasm, or even the desire to finally reach it. <br><a name="habracut"></a><br>  We can build an algorithm that satisfies this requirement, and which is much better (slower) than a naive algorithm if we sort table <em>A</em> in ascending order.  Then, we will be able to use the slow search procedure, which is presented below: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/623/ce9/12b/623ce912b86915ae6b93ff51221b8dd1.png"><br><br>  The number of comparisons in this algorithm does not depend on either <em>X</em> or <em>A <sub>i</sub></em> and is given by the following recursive formula: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b29/111/1d8/b291111d8ef0cda6bf2a53b51ae605fe.png"><br><br>  From which we get that <br><br><img src="https://habrastorage.org/getpro/habr/post_images/ce0/96b/93d/ce096b93d0ec02c6b517b3af2a27f16d.png"><br><br>  Thus, we obtain a deterioration of <em>n</em> times compared with the naive algorithm.  Note that the lack of enthusiasm for the slow search algorithm is completely unclear from its behavior, because it checks the equality of <em>X</em> and <em>A <sub>i</sub></em> every <em>O (1)</em> operation, never compares the same values, and stops when the desired value is found.  Few search algorithms, honest or not, can be compared with him in performance. <br><br><h2>  2. Summary </h2><br>  The <em>research</em> procedure is an example of a completely new direction of Computer Science (Computer Science) - the design and analysis of unhurried algorithms.  An intuitive, unhurried algorithm that solves problem <em>P</em> , is an algorithm that wastes time in such a clever way that it can fool the average naive observer.  We can write this statement in a strict mathematical language, saying that <em>A</em> is a leisurely algorithm for problem <em>P</em> if and only if <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d32/d3b/f0e/d32d3bf0e6bf9bdf09fd6b28c8fa94d9.png"><br><br>  where, <em>N</em> is a set of naive observers, <em>t</em> is time, <em>W (A, t, w, P)</em> is a predicate, which means <em>‚ÄúA is wasting time t in vain in the way w solving problem P‚Äù</em> , and <em>F (w, o)</em> is a predicate, which means <em>"the way w is confused enough to fool o"</em> .  Regarding the finiteness of the set <em>N,</em> we make no assumptions. <br><br>  When studying slow algorithms, the performance of algorithm <em>A is</em> best described by its inefficiency or execution time in the best case - the minimum (as a function of <em>n</em> ) runtime <em>A</em> for all possible input data of length <em>n</em> .  <strong>The complexity of the task <em>P</em></strong> - the maximum inefficiency among all the slow algorithms that solve the problem <em>P.</em>  An algorithm is called <strong>pessimal</strong> for problem <em>P</em> if the inefficiency of <em>A</em> in the best case asymptotically tends to complexity <em>P.</em> <br><br>  Leisurely algorithms have many important practical applications.  For example, the leisurely search algorithm is particularly applicable to real keys (real not in a mathematical sense, but in the sense that these are physical keys that open doors and cabinets).  The leisurely search algorithm is the only known algorithm that accurately emulates the behavior of a bunch of such keys. <br><br><h2>  3. The task of finding a path in interesting graphs </h2><br><img src="https://habrastorage.org/getpro/habr/post_images/285/f45/6c4/285f456c441becfe833e4338c75ba9d0.jpg"><br><br>  The search in the table can be considered as a special case of the next more general task.  Suppose we have a ‚Äúlabyrinth‚Äù - an undirected graph <em>G</em> with <em>n</em> vertices and a vertex <em>u</em> marked as <em>‚Äúinput‚Äù</em> .  Our task is to find a path from the vertex <em>u</em> to the vertex <em>v</em> , marked as <em>‚Äúexit‚Äù</em> , moving along the maze one edge per unit of time.  Following the classical analysis of algorithms, most likely, we would immediately turn to one of the most efficient algorithms for finding the shortest path in a graph.  However, suppose that this labyrinth is quite interesting inside, and that we would in principle be uncontracted to spend several additional cycles of the algorithm in search of the vertex v.  In fact, we hope ... no, we certainly want the search to take as long as possible.  Given that our sense of duty does not allow us to completely abandon the search, we will not be able to ignore the primitive needs of our human nature for a long time.  In addition, what's wrong with a relaxed approach to solving a problem, if we still do what is needed?  Moreover, we have always been told that ‚Äúyou hurry - you will make people laugh‚Äù, and, in any case, no one needs to be perfect.  Well, and stuff like that ... <br><br>  Taking all this into account, we see that this task fits very well into the subject area of ‚Äã‚Äãour theory. <br><br>  In fact, this task was widely studied in the Theory of Graphs, where it received the name <em>‚Äúthe task of finding the most negligent path‚Äù</em> .  An important section of <em>Mathematical Methods for Operations Research</em> , which is called <em>Anemic Programming</em> , is entirely devoted to ineffective methods for solving this problem.  What do we know about its complexity?  Earlier, as shown by Wagner <sup>[Wagner]</sup> , if we don‚Äôt know anything about finding <em>v</em> , the best time can be as little as <em>O (1)</em> : at every step, even at the very first, we risk stepping on <em>v</em> and failing maze, despite the fact, no matter how much we want to avoid it.  However, as Homer <sup>[Homer]</sup> showed, if the graph is on a plane (or a flat globe), and we have an oracle that, like a compass, shows which direction the target is located, we can delay the moment of arrival to the target until we visit most of vertices of the graph.  In fact, the time for which we can delay this moment is limited not so much by the complexity of the task as by its monotony <sup>[1]</sup> .  The inefficiency of the Homer algorithm is <em>Œ© (n)</em> , which is the lower limit of the complexity of finding the most negligent path. <br>  ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî <br>  <sup>[1]</sup> Also known as boredom. <br><br>  The leisurely search method and the algorithm of Homer's careless path are both based on the same idea, known as the <em>Powerless Descent Method</em> .  We also want to casually mention another important paradigm for the design of leisurely algorithms, which was described by Homer in the same work, and which the author gave the bright name <em>Penelope's Trick</em> .  It is based on the use of a for loop, in which the step oscillates between positive and negative values ‚Äã‚Äãat each iteration.  Unfortunately, this technique (which is now called <em>Method with Return</em> ) has become so famous that even the most naive observer can easily recognize it.  So, now it is only of historical interest. <br><br><h2>  4. Search back </h2><br>  A rather similar task is the systematic enumeration of all <em>n</em> vertices of a connected graph <em>G.</em>  This problem has been well studied in the classical <em>Theory of Algorithms</em> , and is usually solved by the well-known depth search <sup>[Vern]</sup> or width search <sup>[Vern2] algorithms</sup> , in which the time complexity in the best case belongs to <em>Œ© (n)</em> . <br><br>  For a long time, it was considered to be the upper limit of the complexity of the problem, until on October 4, 1984 at 14:17, the community of leisurely algorithms was not shaken by the discovery of the search algorithm that belongs to <em>Œ© (n <sup>2</sup> )</em> due to inefficiency on an important class of graphs.  <em>The search method backwards</em> , as it was named by its inventor, will be described below.  Like its predecessors, the algorithm assigns the vertices v <sub>1</sub> , v <sub>2</sub> , ..., v <sub>n of the</sub> graph <em>G to</em> integers <em>Œª (v <sub>1</sub> )</em> , <em>Œª (v <sub>2</sub> )</em> , ..., <em>Œª (v <sub>n</sub> )</em> from 1 to <em>n</em> .  The algorithm is represented by the <em>bwfs</em> recursive procedure.  We assume that all the numbers <em>Œª (v) are</em> initially zero.  Recursion starts with a call to <em>bwfs (v <sub>l</sub> , 1)</em> . <br><br><img src="https://habrastorage.org/getpro/habr/post_images/196/36a/1e8/19636a1e81157a3e224f1d3fd19b6913.png"><br><br>  We leave the reader an instructive exercise to prove the correctness of the algorithm and show that its inefficiency really belongs to <em>œ¥ (n <sup>2</sup> )</em> for graphs that are straight lines.  An interesting feature from the point of view of the pessimity of consumed memory in this case is that the recursion depth <em>bwfs</em> can reach <em>œ¥ (n <sup>2</sup> )</em> depending on the starting point of the graph.  The inefficiency of this algorithm on ordinary graphs remains an unsolved problem, but, it seems, the algorithm is never faster than <em>O (n‚àön)</em> . <br><br>  An interesting note is that it suffices to remove one of the for loops in order to get a familiar depth search from <em>bwfs</em> .  However, the order in which the vertices of the graph pass for the first time is very strange and confusing, and it is not at all like the order obtained by the depth-depth algorithm. <br><br>  By definition, the numbering back of the graph vertices is the values ‚Äã‚Äãof <em>Œª (v)</em> that were assigned to the vertices by this algorithm.  Like numbering in depth and in width, this numbering has several interesting properties.  Due to the limitation on the size of the text, we will cite only a couple of them.  If the faces of the graph are directed in such a way that the graph is acyclic, then either <em>Œª (head (e)) ‚â• Œª (tail (e)))</em> for all faces <em>e</em> , or <em>Œª (head (e)) ‚â§ Œª (tail (e) )</em> for all faces <em>e</em> .  Moreover, if <em>d</em> is the maximum degree of the vertices of the graph, then for any two adjacent vertices <em>u</em> and <em>v, it</em> is true that <em>| Œª (u) - Œª (v) |</em>  <em>‚â§ d log min (Œª (u), Œª (v))</em> .  These and other properties of <em>numbering back</em> make it very important from the point of view of combinatorics. <br><br><h2>  5. Slow Rescue </h2><br>  No other task shows the power and elegance of a leisurely algorithm as sorting <em>n</em> given numbers.  This task has a long and rich history, the beginnings of which can be traced for a very long time, certainly earlier than the formation of a leisurely algorithm, as a recognized discipline in the second half of last Wednesday.  Thanks to the efforts of many pioneers in the industry, the inefficiency of sorting algorithms has steadily grown from the modest <em>Œ© (n log n)</em> Merge Sort algorithm (Merge Sort) to <em>Œ© (n ‚àö n)</em> Shell Sort (Shell‚Äôs Sort) with certain increments, to <em>Œ© (n <sup>2</sup> )</em> Sort A bubble (Bubble Sort), and finally, to the tricky search algorithm belonging to <em>Œ© (n <sup>3</sup> )</em> , recently described by Bentley <sup>[Bentley]</sup> .  (Apparently, it was first published by Steele, Woods, Finkel, Crispin, and Goodfellow <sup>[SWFCG]</sup> ) <br><br>  One of the most important results of the modern theory of complexity is the proof that the sorting problem can be solved in time Œ© (n <sup>log (n) / (2 + e)</sup> ).  This is the first found problem with non-polynomial complexity.  An elegant algorithm that achieves this kind of inefficiency is called <em>Slowsort</em> and is described below. <br><br>  The <em>Slow-</em> <em><a href="http://ru.wikipedia.org/wiki/%25D0%25A0%25D0%25B0%25D0%25B7%25D0%25B4%25D0%25B5%25D0%25BB%25D1%258F%25D0%25B9_%25D0%25B8_%25D0%25B2%25D0%25BB%25D0%25B0%25D1%2581%25D1%2582%25D0%25B2%25D1%2583%25D0%25B9">Sorted</a></em> Algorithm is an ideal example of the <em><a href="http://ru.wikipedia.org/wiki/%25D0%25A0%25D0%25B0%25D0%25B7%25D0%25B4%25D0%25B5%25D0%25BB%25D1%258F%25D0%25B9_%25D0%25B8_%25D0%25B2%25D0%25BB%25D0%25B0%25D1%2581%25D1%2582%25D0%25B2%25D1%2583%25D0%25B9">Multiply and Surrender</a></em> paradigm, which is perhaps the most important paradigm for the development of slow algorithms.  The idea of ‚Äã‚Äãthe <em>Multiply and Surrender</em> strategy is to replace this task with two or more subtasks, each of which is only slightly simpler than the original, and then continue to multiply the subtasks recursively while it is possible.  At some point, all the subtasks will be so simple that their decision can no longer be postponed, at this point we will be forced to surrender.  Experience shows that in most cases, by this time, the total amount of work done in vain will be significantly greater than if we used a more direct approach. <br><br>  To better understand the strategy of <em>Multiply and Surrender</em> , let's <em>step by step</em> consider the development of the algorithm <em>Slowness</em> .  We can divide the task of sorting the numbers <em>A <sub>1</sub> , A <sub>2</sub> , ..., A <sub>n</sub></em> by increasing into two subtasks: (1) find the maximum of these numbers, (2) sort the rest.  Subtask (1) can be further divided into subtasks: (1.1) find the maximum of the first <em>[n / 2]</em> elements, (1.2) find the maximum of the last <em>[n / 2]</em> elements, (1.3) find the greatest of these two values.  And finally, subtasks (1.1) and (1.2) can be solved by sorting the elements and selecting the last (read maximum) element of the sorted array.  Thus, we multiplied the primary task into three only slightly simpler subtasks (plus overhead): sort the first half, sort the second half, sort all the elements except one.  We will continue to do this recursively until all the multiplied arrays contain no more than one element.  At this point we will have to surrender. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/cac/d8d/47b/cacd8d47bce1a571ed0fafa72f56eb98.png"><br><br>  A recursive definition of the execution time of a <em>Slow-</em> <em>port</em> will look familiar to those who read <em>Section 3</em> .  In general, <em>T (n) = 2T (n / 2) + T (n - 1) is</em> obtained.  <a href="http://ru.wikipedia.org/wiki/%25D0%25A0%25D0%25B0%25D1%2581%25D1%2581%25D1%2582%25D0%25BE%25D1%258F%25D0%25BD%25D0%25B8%25D0%25B5_%25D0%25A5%25D1%258D%25D0%25BC%25D0%25BC%25D0%25B8%25D0%25BD%25D0%25B3%25D0%25B0">The Hamming distance</a> between this formula and the well-known recursive <em>Merge Sort</em> formula <em>(Merge Sort) T (n) = 2T (n / 2) + cn</em> is only 5, but the simple argument about the final differences shows that this is enough for the first equation there was no polynomially bounded solution.  In fact, it can be shown that the solution satisfies the following inequalities <sup>[1]</sup> : <br><br><img src="https://habrastorage.org/getpro/habr/post_images/1c0/bc0/fd9/1c0bc0fd90c7ceb0e3bf77ffb46fe73a.png"><br><br>  for any fixed <em>e&gt; 0</em> and two constants <em>C <sub>a</sub></em> and <em>C <sub>b</sub></em> .  The idea of ‚Äã‚Äãthe proof (and we were told that our article will be published only if it contains at least one proof) is to assume that <em>T (n) = C <sub>1</sub> n <sup>C <sub>2</sub> ln n</sup></em> for some constants.  Then <br><br><img src="https://habrastorage.org/getpro/habr/post_images/1c6/8d2/6d7/1c68d26d7e158c86a9c735b47d6d6f05.png"><br><br>  ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî <br>  <sup>[1]</sup> We use ‚Äúlog‚Äù for log base 2 and ‚Äúln‚Äù for natural logarithms. <br><br>  Assuming that <em>C <sub>2</sub> = 1 / (2 ln 2)</em> , we get <em>T (n) ‚â§ C <sub>b</sub> n <sup>log (n) / 2</sup></em> , and assuming that <em>C <sub>2</sub> = 1 / (((2 + e) ‚Äã‚Äãln 2 )</em> , we obtain that <em>T (n) ‚â• C <sub>a</sub> n <sup>log (n) / (2 + e)</sup></em> for substantially large <em>n</em> .  (The constants C <sub>a</sub> and C <sub>b are</sub> just bogus values ‚Äã‚Äã( <i>orig. <a href="http://en.wikipedia.org/wiki/Fudge_factor">Fudge factor</a></i> ) to launch induction.) Following the spirit of slow algorithmism, the authors will provide more detailed proof in the near future as scanned images of punched cards with proof code on <a href="http://en.wikipedia.org/wiki/Eqn">EQN</a> written on 7 <a href="http://en.wikipedia.org/wiki/EBCDIC">EBCDIC</a> track cassettes with an odd check bit. <br><br>  As a practical application, it is obvious that <em>Slowness</em> is the most suitable algorithm, if suddenly your boss sends you to sort something out to Paris.  One of the good features of this algorithm is that the number of inversions in <em>A</em> does not increase.  So, in a certain sense (in the sense that you are in Paris, all expenses are covered), <em>Slowness</em> never takes the wrong steps. <br><br><h2>  6. Conclusions and unsolved problems </h2><br>  For a long time Computer Science (Computer Science) was engaged only in the study of either the worst or medium scenarios of the algorithms.  In this publication, for the first time we are trying to correct the apparent discrimination of studying the best scenarios, and we can only hope that others will follow us. <br><br>  The Slow Mode analysis has led us to the following assumption, which we call the <em>Increasing Hypothesis (HS)</em> : If the complexity of the problem is <em>O (gf)</em> , where <em>g</em> and <em>f</em> are functions of the length of the input data, and <em>f = o (g)</em> , then the complexity of this problem is <em>Œò (g <sup>f</sup> )</em> . <br><br>  <em>The Augmented Hypothesis (ARC)</em> states that if the complexity of the problem is <em>O (g + f)</em> , then its complexity is <em>(gf)</em> .  Obviously, the <em>ARC</em> implies <em>UG</em> . <br><br>  Proving or disproving the <em>UG</em> is one of the main tasks <em>of the Complexity Theory</em> .  However, we have to end with the sad fact that, most likely, it is impossible to prove the HS because of the well-known incompleteness <a href="http://ru.wikipedia.org/wiki/%25D0%2590%25D0%25BA%25D1%2581%25D0%25B8%25D0%25BE%25D0%25BC%25D1%258B_%25D0%259F%25D0%25B5%25D0%25B0%25D0%25BD%25D0%25BE">of Peano arithmetic</a> . <br><br><h2>  Thanks </h2><br>  We would like to thank Ed Lasowska and Lyle Ramshaw for their unhurried help. <br><br><h2>  Links </h2><br>  [Bentley] DL Bentley, Programming Pearls, CACM, 27 (1984) 287-291 <br>  [Wagner] R. Wagner, <a href="http://ru.wikipedia.org/wiki/%25D0%25A2%25D0%25B0%25D0%25BD%25D0%25B3%25D0%25B5%25D0%25B9%25D0%25B7%25D0%25B5%25D1%2580_(%25D0%25BE%25D0%25BF%25D0%25B5%25D1%2580%25D0%25B0)">Tannh√§user</a> , (French and German libretto), L'avant-sc√®ne, Paris, 1984 <br>  [Vern1] J. Verne, <a href="http://ru.wikipedia.org/wiki/%25D0%259F%25D1%2583%25D1%2582%25D0%25B5%25D1%2588%25D0%25B5%25D1%2581%25D1%2582%25D0%25B2%25D0%25B8%25D0%25B5_%25D0%25BA_%25D1%2586%25D0%25B5%25D0%25BD%25D1%2582%25D1%2580%25D1%2583_%25D0%2597%25D0%25B5%25D0%25BC%25D0%25BB%25D0%25B8_(%25D1%2580%25D0%25BE%25D0%25BC%25D0%25B0%25D0%25BD)">Journey to the Center of the Earth</a> , (English translation), Heritage Press, 1966 <br>  [Vern2] J. Verne, <a href="http://ru.wikipedia.org/wiki/%25D0%2592%25D0%25BE%25D0%25BA%25D1%2580%25D1%2583%25D0%25B3_%25D1%2581%25D0%25B2%25D0%25B5%25D1%2582%25D0%25B0_%25D0%25B7%25D0%25B0_80_%25D0%25B4%25D0%25BD%25D0%25B5%25D0%25B9">Around the World in 80 Days</a> , (English translation), International Collectors Library, 1956 <br>  [Homer] G. Homer, <a href="http://ru.wikipedia.org/wiki/%25D0%2593%25D0%25BE%25D0%25BC%25D0%25B5%25D1%2580">Iliad and Odysseus</a> , translation by Samuel Butler, Encyclopedia Britannica, Chicago, 1952 <br>  [SWFCG] G. Style and others, Hacker's Dictionary, Harper and Row, 1983 <br><br><h2>  Note </h2><br>  The article was published in ACM SIGACT NEWS, 16 (3): 49-53, 1984. <a href="http://citeseerx.ist.psu.edu/viewdoc/download%3Fdoi%3D10.1.1.116.9158%26rep%3Drep1%26type%3Dpdf">After that, it was recast</a> from a bad photocopy by Gordon Lack in 2000.  And at the end of 2013, it was translated into Russian by Valentin Simonov ( <a href="http://habrahabr.ru/users/valyard/" class="user_link">valyard</a> ). <br><br><blockquote>  Unfortunately, during a careful reading of the <i>search</i> algorithm <i>back</i> seemed to be non-working.  Perhaps, when reprinting some details of this algorithm were lost, and we will never know what the authors meant.  And, perhaps, this is a special test for attentiveness, which would correspond to the general spirit of the publication. </blockquote><br>  In any case, this text in some places made me laugh for a very long time.  So, I hope that the translated text will give you as much pleasure. </div><p>Source: <a href="https://habr.com/ru/post/199438/">https://habr.com/ru/post/199438/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../199426/index.html">3/2 N: how to save on reliability increase?</a></li>
<li><a href="../199428/index.html">Applications for Firefox OS will run on Android, Windows, Mac OS X and Linux</a></li>
<li><a href="../199432/index.html">How we accelerated the search in Yandex. Mail and at the same time released 25 servers</a></li>
<li><a href="../199434/index.html">Windows 1.01 - now right in the browser</a></li>
<li><a href="../199436/index.html">The experience of writing a 2D MOBA-platform for several days</a></li>
<li><a href="../199440/index.html">We get the type and size of the image without downloading it entirely, using Python</a></li>
<li><a href="../199446/index.html">American startup has developed a neural network that recognizes popular CAPTCHA with an accuracy of more than 90%</a></li>
<li><a href="../199450/index.html">Motorola supports Phonebloks and creates its modular smartphone Project Ara</a></li>
<li><a href="../199456/index.html">Bind, Call and Apply in JavaScript</a></li>
<li><a href="../199458/index.html">Codementor - earn from your experience</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>