<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Vectorization Advisor, another example - overclocking a fractal</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="We recently wrote about the new Vectorization Advisor. About what it is and why you need it, read the first article . The same post is devoted to the ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Vectorization Advisor, another example - overclocking a fractal</h1><div class="post__text post__text-html js-mediator-article">  We recently <a href="http://habrahabr.ru/company/intel/blog/255731/">wrote</a> about the new Vectorization Advisor.  About what it is and why you need it, read <a href="http://habrahabr.ru/company/intel/blog/255731/">the first article</a> .  The same post is devoted to the analysis of a specific example of optimizing an application using this tool. <br><br>  The application is taken from the examples of the Intel Threading Building Blocks (Intel TBB) library.  It draws a Mandelbrot fractal and is parallelized in streams using Intel TBB.  Those.  it uses the advantages of a multi-core processor - let's see how things are with vector instructions. <br><br><img src="https://habrastorage.org/files/bf7/d45/80e/bf7d4580ee2e470c83f052b251d55f32.png"><br><a name="habracut"></a><br>  Test system: <br>  ‚Ä¢ Laptop with Intel Core i5-4300U (Haswell, 2 cores, 4 hardware streams) <br>  ‚Ä¢ IDE: Microsoft Visual Studio 2013 <br>  ‚Ä¢ Compiler: Intel Composer 2015 update 2 <br>  ‚Ä¢ Intel Advisor XE 2016 Beta <br>  ‚Ä¢ Appendix: Mandelbrot fractal, slightly modified.  See &lt;tbb_install_dir&gt; \ examples \ task_priority 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h1>  1. Assess the situation </h1><br>  So, the first step: measure the basic version, running time: 4.51 seconds.  Next, we launch a Survey analysis in Intel Advisor XE: <br><br><img src="https://habrastorage.org/files/948/c1b/64d/948c1b64df004821ae4c6414cc7f4d4c.png"><br><br>  The column ‚ÄúLoop Type‚Äù says that all cycles are scalar, i.e.  Do not use SIMD instructions.  The most expensive cycle in the file fractal.cpp on line 74. It spends more than 13 seconds of processor time - and we‚Äôll do it.  The column ‚ÄúWhy No Vectorization‚Äù contains a message stating that the compiler was unable to estimate the number of iterations of the cycle, and therefore did not vectorize it.  Double click on the highlighted cycle, look at the code: <br><br><pre><code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">while</span></span> ( ((x*x + y*y) &lt;= <span class="hljs-number"><span class="hljs-number">4</span></span>) &amp;&amp; (iter &lt; max_iterations) ) { xtemp = x*x - y*y + fx0; y = <span class="hljs-number"><span class="hljs-number">2</span></span> * x*y + fy0; x = xtemp; iter++; }</code> </pre> <br>  It becomes clear why the number of iterations is not known at compile time.  Before diving into the details of the algorithm and trying to rewrite while, we will try to go in a simpler way.  Let's see where our cycle comes from - the Top Down tab: <br><br><img src="//habrastorage.org/files/1cb/372/082/1cb372082f4a42d7944ecf2f76c22f7e.png"><br><br><h1>  2. We force vectorization </h1><br>  The next call cycle on line 164. This is a normal-looking for, which the compiler did not vectorize either (Scalar in the Loop Type column), probably not considering it effective.  The diagnostic message suggests trying to force vectoring, for example, using the SIMD directive: <br><br><img src="//habrastorage.org/files/45b/784/eff/45b784effd7c4136bf9975adbb832ba2.png"><br><br>  Follow the advice: <br><br><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">pragma</span></span></span><span class="hljs-meta"> simd </span><span class="hljs-comment"><span class="hljs-meta"><span class="hljs-comment">// forced vectorization for (int y = y0; y &lt; y1; ++y) { fractal_data_array[x - x0][y - y0] = calc_one_pixel(x, y, tmp_max_iterations, tmp_size_x, tmp_size_y, tmp_magn, tmp_cx, tmp_cy, 255); }</span></span></span></span></code> </pre><br>  Reassemble the program and run Survey again.  With <i>#pragma simd, the</i> cycle became not ‚ÄúScalar‚Äù, but ‚ÄúRemainder‚Äù: <br><br><img src="//habrastorage.org/files/2bf/639/a29/2bf639a29881444985eaa84eeca9b24f.png"><br><br>  SIMD cycles, as you know, can be divided into peel, body and remainder.  Body - in fact, a vectorized part, where several iterations are performed at once for a single instruction.  Peel appears if the data is not aligned with the length of the vector, remainder - non-multiple iterations remaining at the end. <br><br>  We only have Remainder.  This means that the cycle was vectorized, but the body was not executed.  The bookmark with recommendations speaks about the inefficiency of such a situation - it is necessary that more iterations be executed in the body, since the remainder here is a regular sequential cycle.  Check how many iterations there are using Trip Counts analysis: <br><br><img src="//habrastorage.org/files/75f/e3c/13c/75fe3c13c259438fa0ee34be1f96e0f6.png"><br><br><h1>  3. Increasing the number of iterations </h1><br>  In our cycle, there are only 8 iterations, which is quite a bit.  If there were more, a vectorized body would have something to perform.  The line number has changed after code modifications, now it is line 179. Let's see how the number of iterations is determined: <br><br><pre> <code class="cpp hljs">tbb::parallel_for(tbb::blocked_range2d&lt;<span class="hljs-keyword"><span class="hljs-keyword">int</span></span>&gt;(y0, y1, inner_grain_size, x0, x1, inner_grain_size), [&amp;] (tbb::blocked_range2d&lt;<span class="hljs-keyword"><span class="hljs-keyword">int</span></span>&gt; &amp;r){ <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> x0 = r.cols().begin(), y0 = r.rows().begin(), x1 = r.cols().end(), y1 = r.rows().end(); ... <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> x = x0; x &lt; x1; ++x) { <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> y = y0; y &lt; y1; ++y) { <span class="hljs-comment"><span class="hljs-comment">//    179 fractal_data_array[x - x0][y - y0] = calc_one_pixel(x, y, tmp_max_iterations, tmp_size_x, tmp_size_y, tmp_magn, tmp_cx, tmp_cy, 255); } } ...</span></span></code> </pre><br>  The cycle of interest to us is called from the parallel loop of the Intel Threading Building Blocks library (Intel TBB).  The iterations of the outer loop are distributed between different threads, each of which receives an object of type <i>tbb :: blocked_range2d</i> - its <i>own</i> local space of iterations.  How small an iteration number can be in this space depends on the parameter, <i>inner_grain_size</i> .  Those.  The value of <i>r.rows (). end ()</i> , which determines the number of loop iterations per line 179, depends on <i>inner_grain_size</i> . <br>  We find in the code this same grain size (there are two for two nested parallel loops): <br><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">int</span></span> grain_size = <span class="hljs-number"><span class="hljs-number">64</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> inner_grain_size = <span class="hljs-number"><span class="hljs-number">8</span></span>;</code> </pre><br>  We are trying to increase the inner_grain_size to 32. Nothing bad is expected from this, just the division of work into Intel TBB threads will be more coarse-grained.  See the result: <br><br><img src="//habrastorage.org/files/0fd/cd8/a9b/0fdcd8a9b7e3442885abf1afc47438a9.png"><br><br>  Now the vectorized body appears in the cycle, we finally achieved real use of SIMD instructions, the cycle is vectorized.  But it's too early to rejoice - the performance has not grown at all. <br><br><h1>  4. Vectorize the function </h1><br>  We look at the recommendations of Advisor XE - one of them talks about calling a serialized (sequential) function.  The fact is that if a vector cycle calls a function, then it needs a vectorized version that can accept parameters by vectors, and not by ordinary scalar variables.  If the compiler could not generate such a vector function, then the regular, sequential version is used.  And it is also called sequentially, nullifying the whole vectorization. <br>  Look again at the loop code: <br><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> y = y0; y &lt; y1; ++y) { <span class="hljs-comment"><span class="hljs-comment">//    179 fractal_data_array[x - x0][y - y0] = calc_one_pixel(x, y, tmp_max_iterations, tmp_size_x, tmp_size_y, tmp_magn, tmp_cx, tmp_cy, 255); }</span></span></code> </pre><br>  Fortunately, the function call here is one: <i>calc_one_pixel</i> .  Since the compiler could not generate a vector version, we will try to help it.  But first, let's look at the memory access patterns, this is useful for explicit vectoring: <br><br><img src="//habrastorage.org/files/356/982/2b6/3569822b699844ebb10f621fcc2b7700.png"><br><br>  The analysis of the Memory Access Patterns of our cycle (along with the called function) tells us that all read or write operations are unit stride with a step of 0. That is,  when accessing external data, the same variable is read or written from each iteration: <br><br><img src="//habrastorage.org/files/fe1/cea/2b6/fe1cea2b6da849389c3c455b40fa5b37.png"><br><br>  This knowledge is useful for us to manually vectorize the function.  We will use the <i>#pragma omp simd directive</i> from the OpenMP 4 standard. It has options defining the parameter access pattern.  For example, ‚Äúlinear‚Äù is used for monotonously growing quantities, mainly iterative variables.  We are also suitable uniform - to access the same data. <br><br><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">pragma</span></span></span><span class="hljs-meta"> omp declare simd uniform(x0, max_iterations, size_x, size_y, magn, cx, cy, gpu) color_t fractal::calc_one_pixel(float x0, float y0, int max_iterations, int size_x, int size_y, float magn, float cx,</span></span></code> </pre><br>  By adding a directive on the definition of the function, we gave the compiler the opportunity to generate its vector version, which can process data arrays instead of the scalar declared.  We get a noticeable increase in speed - the cycle is executed 7.5 seconds instead of 12: <br><br><img src="//habrastorage.org/files/fa6/565/fb3/fa6565fb34a54bceb2f3c342c3c40c87.png"><br><br><h1>  5. Align the data </h1><br>  Let's try to fight other causes of the inefficiency of the vector cycle.  The presence of a peel indicates that the data is not aligned.  Add <i>__declspec (align (32))</i> before defining an array in which the <i>calc_one_pixel</i> results are <i>written</i> : <br><br><pre> <code class="cpp hljs">__declspec(align(<span class="hljs-number"><span class="hljs-number">32</span></span>)) <span class="hljs-keyword"><span class="hljs-keyword">color_t</span></span> fractal_data_array[delta_x][(delta_y / <span class="hljs-number"><span class="hljs-number">16</span></span> + <span class="hljs-number"><span class="hljs-number">1</span></span>) * <span class="hljs-number"><span class="hljs-number">16</span></span>]; <span class="hljs-comment"><span class="hljs-comment">// aligned data for (int x = x0; x &lt; x1; ++x) { #pragma simd for (int y = y0; y &lt; y1; ++y) { fractal_data_array[x - x0][y - y0] = calc_one_pixel(x, y, tmp_max_iterations, tmp_size_x, tmp_size_y, tmp_magn, tmp_cx, tmp_cy, 255); } }</span></span></code> </pre><br>  After that peel disappears: <br><br><img src="//habrastorage.org/files/7a6/95f/e03/7a695fe034a14ed494294412168f2b2f.png"><br><br><h1>  6. Remove the unrolling cycle </h1><br>  In the Advisor XE diagnostics table, you can pay attention to one more thing - the ‚ÄúTransformations‚Äù column says that the compiler has unrolled a cycle (unrolled) with a factor of 2: <br><img src="//habrastorage.org/files/2d0/6ca/239/2d06ca2397f04627b257b28236b20279.png"><br><br>  Those.  in order to optimize the number of iterations reduced by half.  This in itself is not bad, but in the third step we specifically tried to increase them, and it turns out that the compiler does the opposite.  Let's try to disable the scan with <i>#pragma nounroll</i> : <br><br><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">pragma</span></span></span><span class="hljs-meta"> simd #</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">pragma</span></span></span><span class="hljs-meta"> nounroll </span><span class="hljs-comment"><span class="hljs-meta"><span class="hljs-comment">// added unrolling for (int y = y0; y &lt; y1; ++y) { fractal_data_array[x - x0][y - y0] = calc_one_pixel(x, y, tmp_max_iterations, tmp_size_x, tmp_size_y, tmp_magn, tmp_cx, tmp_cy, 255); }</span></span></span></span></code> </pre><br>  After this, the number of iterations is expected to double: <br><br><img src="//habrastorage.org/files/e5a/de5/d3d/e5ade5d3d78c4e1a9ea24620cc92fad3.png"><br><br><h1>  7. Increasing the number of iterations even more. </h1><br>  Manipulations with unrolling allowed to increase the number of iterations, but there was no improvement in performance.  Let's see what happens if we increase <i>grain_size</i> even more, as in step 3. Just empirically test the optimal value: <br><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">int</span></span> grain_size = <span class="hljs-number"><span class="hljs-number">256</span></span>; <span class="hljs-comment"><span class="hljs-comment">// increase from 64 int inner_grain_size = 64; // increase from 8</span></span></code> </pre><br>  It turns out to squeeze a little more, albeit quite a bit: <br><br><img src="//habrastorage.org/files/8ed/ce3/42a/8edce342a279412ca2be27e0b66d8277.png"><br><br><h1>  8. Results </h1><br>  After all the manipulations, the test application runtime was reduced from 4.51 to 1.92 seconds, i.e.  we achieved an acceleration of about 2.3 times.  Let me remind you that our computational test has already been partially optimized - well parallelized by threads on Intel TBB, achieving good acceleration and scalability on multi-core processors.  But due to the fact that the vectorization was not fully used, we still did not receive half of the possible performance.  The first conclusion - <b>vectorization can be of great importance</b> , do not neglect it. <br><br>  Now let's see the effect of various changes: <br><br><img src="//habrastorage.org/files/0b9/529/c81/0b9529c817b74540b33cd1f303aa4413.png"><br><br>  Forcing vectorization and increasing the number of iterations (steps 2 and 3) did not accelerate the program itself.  We received the most important speed increase in step 4 after vectoring the function.  However, this is the cumulative effect of steps 2-4.  For a real cycle vectorization, it was necessary to increase the number of iterations, and force vectorization, and vectorize the function. <br><br>  And the following steps had no special effect, in our case they could be completely skipped.  Step 7 can be more or less attributed to success, and this is due to the fact that in step 3 we did not immediately set a greater number of iterations.  However, the purpose of the post was to show the capabilities of Advisor XE with a specific example, so all the actions performed are described. </div><p>Source: <a href="https://habr.com/ru/post/257309/">https://habr.com/ru/post/257309/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../2573/index.html">Leaders in the spread of viruses - the United States and China</a></li>
<li><a href="../257301/index.html">2.5 million views - did you work well? Time to go on</a></li>
<li><a href="../257303/index.html">Processing and display of signals at the conversion frequency of the ADC</a></li>
<li><a href="../257305/index.html">Implementing Private Fields with WeakMap in JavaScript</a></li>
<li><a href="../257307/index.html">A meeting on Atlassian products took place in Moscow</a></li>
<li><a href="../257315/index.html">Create a simple app for the Apple Watch. Personal experience on the example of Rambler. News</a></li>
<li><a href="../257317/index.html">Apple Watch Human Interface Guideline</a></li>
<li><a href="../257319/index.html">Arbelos</a></li>
<li><a href="../25732/index.html">Tale about vectors</a></li>
<li><a href="../257321/index.html">Another way to connect WS2812B to a microcontroller</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>