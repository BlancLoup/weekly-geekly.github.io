<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Two years with crawlers (web-mining)</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Disclaimer: this topic may be partly self-advertisement, ‚Äúwater‚Äù and nonsense, but, most likely, this is just a classification of information and expe...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Two years with crawlers (web-mining)</h1><div class="post__text post__text-html js-mediator-article">  <i>Disclaimer:</i> this topic may be partly self-advertisement, ‚Äúwater‚Äù and nonsense, but, most likely, this is just a classification of information and experience accumulated over two years of work in the field of scraping, for yourself and those who are interested. <br><br>  Karma is not chasing, it is enough. <br><br>  Under the cut - a small post about the modern market of crawlers / parsers, with classification and features. <br><a name="habracut"></a><br><h4>  Sabzh </h4><br>  We are talking about "spiders", or programs that collect information on the web.  Spiders are different - most climb on the web, some of them are torrents, some are fido / ed2k and other interesting things.  The essence is the same - in a convenient way for the customer to provide the information he needs. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Unfortunately, S. Shulga ( <a href="https://geektimes.ru/users/gatekeeper/" class="user_link">gatekeeper</a> ) overestimated this industry too much - information mining is a popular affair, but nevertheless, there is little use of AI technology, and automated advisers are far away.  Spiders are generally divided into several categories, distinguished by the complexity of the methods used. <br><br><h4>  Classification </h4><br><h6>  Simple crawlers </h6><br>  Cheap, simple scripts, usually in PHP, the task is to consistently deflate the site, save the prices, attributes, photos to the database, it is possible to process.  The cost of projects can look at the bases of freelancers, it is usually ridiculous.  Mostly disposable projects.  Banned by IP or speed requests. <br><br><h6>  Group Crawlers </h6><br>  A similar project I realized for cenugids.lv.  In this case, many (50+) crawlers use the same code base, or rather, this is one crawler with interfaces for several sources (for cenugids.lv these were stores).  It is mainly used to collect information from similar sources (forums, shops). <br><br><h6>  Behavioral Crawlers </h6><br>  It implies the disguise of a bot as a person  The customer usually asks for a certain strategy of behavior - collect information only at lunchtime, 2 pages per minute, for the work week 3-4 days per week, for example.  An interrupt for a ‚Äúvacation‚Äù and a change in the ‚Äúbrowser version‚Äù in accordance with the releases can be included in the TOR. <br><br><h6>  Crash Crawlers </h6><br>  Technically the most cumbersome solution, used to scrape something with the size of c ebay.  Usually consists of several parts - one pulls out from the source of the place where it is worth walking (for example, for a store, these are categories and pages).  This process is quite rare, because  This information is fairly unchanged.  Further, at random intervals, the spider walks through ‚Äúinteresting places‚Äù and collects links to data (for example, products).  These links are again processed with random delays and entered into the database. <br><br>  This process is not periodic, it goes on constantly.  In parallel with it is checking old links - i.e.  let's say every 5 minutes we choose 10 cached goods from the base and check if they are alive, whether the price and attributes have changed. <br><br>  In this, technically the most cumbersome decision, the customer receives data not about the snapshot of the source at some point, but more or less up-to-date information from the database of the crawler itself.  Naturally, with the last update date. <br><br><h4>  Problems and methods </h4><br><br><h6>  Detection </h6><br>  Simply enough (at least looking at the statistics) to understand what your site is being pumped out.  The number of requests equal to the number of pages - what could be more noticeable?  It usually costs by using caching crawler and crawling graphics.  Naturally, it is impossible to stand out for the attendance of the target site. <br><br><h6>  IP Ban </h6><br>  The simplest thing you can run into at the beginning of the war with the admin.  The first way out is to use proxy.  Minus - you need to maintain your infrastructure, update the list of proxy, transfer to the customer, and do so so that it does not collapse in one moment.  With one-time orders, of course, this disappears.  Although, it took me a week to implement such an infrastructure with interfaces. <br><br>  The second option is Tor.  Great P2P network anonymization, with the perfect interface where you can specify the desired country and exit point.  The speed, in principle, with cache solutions, is not so relevant.  The performance is quite good - I still have one client banning all exit points, iptables rules are already over 9000 (at the time of writing 9873), but there is still no result ... <br><br><h6>  Registration / Authorization </h6><br>  A trivial problem solved as you gain experience.  Logged / recorded cookies / entered / parsim.  Captcha breaks just as well. <br><br><h6>  Departure to infinity </h6><br>  A parser can go crazy if the site somehow generates an infinite number of links.  For example, adding osCsid (OsCommerce SessionID) / PHPSESSID each time can make the crawler perceive the link as new.  I saw stores that, in general, generated pseudo-random links when refreshing (thus, for search engines, one product was placed on 50+ pages with different URLs).  Finally, bugs in the source can also generate an unlimited number of links (for example, a store that showed the next link and +5 pages from the current, even somewhere on a 7000+ blank page). <br><br><h6>  Encodings </h6><br>  Oddly enough, the biggest gap is encodings.  cp1251?  HTML entities?  FIVE kinds of "gaps" in the unicode table?  And if the customer requests XML, and one wrong character kills simplexml? <br><br>  The whole list of encoding errors is probably too lazy for me to specify.  I will say simply - in the post-processing of data, in my cravler, the processing of encodings is almost half. <br><br><h4>  Platform </h4><br>  People love PHP.  Typically PHP + simplexml, or PHP + DOM / XPath.  XPath is generally indispensable, but PHP systems have two big drawbacks - they eat and fall off.  At 512 megabytes per crawler is a normal phenomenon when using mbstring, not to mention coredump just when trying to create a +1 tag in XML.  When processing small sites, this is overlooked, but when 50+ megabytes are pumped out of the source at a time ... Therefore, basically, serious players with PHP are leaving. <br><br>  My choice is Python.  In addition to the same XPath, there are libraries for ed2k, kazzaa, torrents, any databases, perfect string processing, speed, stability, and OOP.  Plus, the ability to integrate a mini-server there for issuing data to the client allows not to put extra on the server and remain inconspicuous - for example, did not have time to pick up the issue 15 minutes after midnight - kick it. <br><br><h4>  Conclusion </h4><br>  If anyone is interested, I can describe in a separate article the methods of breaking the captcha, bypassing the protection of the User-Agent, analyzing the issue of servers and parsing non-web sources.  Have questions?  Welcome to kammenti or lichku! </div><p>Source: <a href="https://habr.com/ru/post/92091/">https://habr.com/ru/post/92091/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../92076/index.html">CloudMade Navigation supports maneuver restrictions</a></li>
<li><a href="../92078/index.html">Features of e-commerce in China</a></li>
<li><a href="../92079/index.html">The Truth About Numonyx PCM: A Revolution That Hasn't Happened</a></li>
<li><a href="../92082/index.html">5 most common mistakes of managers</a></li>
<li><a href="../92089/index.html">Infinite scrolling Habra</a></li>
<li><a href="../92092/index.html">Service Asus in the Czech Republic. Little positive</a></li>
<li><a href="../92093/index.html">Ogogonetbuk</a></li>
<li><a href="../92094/index.html">We generate a QR code for PHP</a></li>
<li><a href="../92097/index.html">Twitter swallowed a company specializing in SMS</a></li>
<li><a href="../92098/index.html">Win9x CIH continued</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>