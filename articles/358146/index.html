<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Image Processing: Tensorflow Object Detection API</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="The last few years in the development of deep neural networks is a real revolution: new architectures are emerging, development frameworks for develop...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Image Processing: Tensorflow Object Detection API</h1><div class="post__text post__text-html js-mediator-article">  The last few years in the development of deep neural networks is a real revolution: new architectures are emerging, development frameworks for developers are being improved, and hardware for experiments can be obtained completely free of charge - for example, as part of the <a href="https://colab.research.google.com/">Google colaboratory</a> project.  <a href="https://github.com/tensorflow/models/tree/master/research/object_detection">Anyone</a> who is interested in how to apply pre- <a href="https://github.com/tensorflow/models/tree/master/research/object_detection">trained</a> models from the <a href="https://github.com/tensorflow/models/tree/master/research/object_detection">Tensorflow Object Detection API</a> repository to solve their problem using the power of the Laboratory - welcome under cat. <br><br>  If you do not want to read the article - you can immediately get acquainted with the notebook in the <a href="https://github.com/Dju999/TFFashionDetection/blob/master/TFFashionDetection.ipynb">repository</a> <br><a name="habracut"></a><br><h2>  Top GPU - for all </h2><br>  For training neural networks on large amounts of data, it is better to use GPU: the speed of learning and inference will be higher than on the CPU due to the efficient parallelization of operations across thousands of cores.  Until recently, cards could be used in their calculations, for example, using Amazon cloud instances.  But why pay for something that you can get for free?  Google Collaboration provides access to the <a href="http://www.nvidia.ru/object/tesla-k80-ru.html">Tesla K80</a> card. <br><br>  Access to the card can be obtained through the menu Edit-&gt; Notebook setttings-&gt; Hardware accelerator: 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/webt/ad/nq/ag/adnqagg2tltxwh9wfpjiscadq5k.png"><br><br>  With this card, you can quickly conduct experiments with neural networks - for example, take a steep course on <a href="https://github.com/deepmipt/deep-nlp-seminars">NLP</a> from the guys from DeepPavlov.  The only disadvantage of the service is your card for only 12 hours, this intermediate results need to be saved somewhere - if there is a need to use them in the future. <br><br>  In this article I will tell you how to train a model using Colaboratory and save it for future use.  The article will have little code - all the code that trains the model and interacts with Google Drive (to save intermediate results) is available in <a href="https://github.com/Dju999/TFFashionDetection">my repository</a> . <br><br>  Go! <br><br><h2>  Dataset DeepFashion </h2><br>  For experiments, I will use <a href="http://mmlab.ie.cuhk.edu.hk/projects/DeepFashion.html">Deep Fashion</a> dataset - these are 800k images of garments. <br><br><img src="https://habrastorage.org/webt/nc/l4/zq/ncl4zq50-crvrsyc96giuwxjp5e.png"><br><br>  Images contain tags, as well as in the photo marked bounding boxes.  We will teach the neural network to detect images of clothes in the photo ‚Äî draw a bounding box and classify one of three classes: upper-body, lower-body, and full-body. <br><br><h2>  Data preparation </h2><br>  First, copy DeepFashion yourself to GoogleDrive from the <a href="https://drive.google.com/open%3Fid%3D0B7EVK8r0v71pWGplNFhjc01NbzQ">Category and Attribute Prediction Benchmark</a> directory in the root directory.  We will work a lot with GoogleDrive as with file storage - copy data from there and upload work results (for example, checkpoint models) to Disk. <br><br>  First, let's copy the repository with the code and install the dependencies: <br><br><pre><code class="bash hljs">!rm -r TFFashionDetection !git <span class="hljs-built_in"><span class="hljs-built_in">clone</span></span> https://github.com/Dju999/TFFashionDetection.git !pip install lxml !pip install -U -q PyDrive !pip install tqdm</code> </pre> <br>  You also need to create an auxiliary object for working with the Google Drive file system. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> TFFashionDetection.utils.colab_fs <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> GoogleColabFS fs = GoogleColabFS()</code> </pre> <br>  For more information, see the utils.colab_fs.py file in the repository. <br><br>  Now you need to download DeepFashion datas: <br><br><pre> <code class="python hljs">!python3 /content/TFFashionDetection/utils/dataset_download.py</code> </pre> <br>  There are three directories in the dataset. <br><br><ul><li>  Img - with garments </li><li>  Eval - contains a text file with dataset splitting into train, test, valid </li><li>  Anno - here files with tags, bouncing boxes and other service information </li></ul><br>  Our task is to prepare this data for feeding the neural network: a description of the files in a special format, partitioning into train and test. <br><br><h2>  Detection of images on Tensorflow </h2><br>  Google in 2017 released <a href="https://github.com/tensorflow/models/tree/master/research/object_detection">Object Detection API</a> - a set of models and tools for detecting images.  There are a lot of scripts in the repository for preparing training data, training models and visualizing results - for example, drawing bounding boxes. <br><br>  The code below installs the TF Object Detection API from the github repository into the Google Laboratory environment. <br><br><pre> <code class="bash hljs">! <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> /content; git <span class="hljs-built_in"><span class="hljs-built_in">clone</span></span> https://github.com/tensorflow/models.git <span class="hljs-comment"><span class="hljs-comment">#    object detection  # https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/installation.md !apt-get install protobuf-compiler python-pil python-lxml python-tk !pip install Cython !cd /content; git clone https://github.com/cocodataset/cocoapi.git; cd cocoapi/PythonAPI; make; cp -r pycocotools /content/models/research/ !cd /content/models/research; protoc object_detection/protos/*.proto --python_out=. #  -   !cd /content/models/research; export PYTHONPATH=$PYTHONPATH:`pwd`:`pwd`/slim; python object_detection/builders/model_builder_test.py</span></span></code> </pre><br>  Now you need to prepare the data.  Img has a complex subdirectory structure, where each class of clothing has its own category.  The code below copies all the photos into one directory, and also prepares a description for each file in the form of <a href="http://warmspringwinds.github.io/tensorflow/tf-slim/2016/12/21/tfrecords-guide/">tf.train.Example</a> - the detection model will be taught for all this good <br><br>  The code has the model name ssd_mobilenet_v2_coco_2018_03_29 - you can download a suitable model in <a href="">Detection Zoo</a> .  Modelka can be downloaded another - but then you will need to rewrite the file /content/data_dir/tf_api.config. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> sys <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> os <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np API_PATH = os.path.join(<span class="hljs-string"><span class="hljs-string">'/content'</span></span>, <span class="hljs-string"><span class="hljs-string">'models/research'</span></span>) sys.path.append(API_PATH) DETECTOR_PATH = os.path.join(<span class="hljs-string"><span class="hljs-string">'/content'</span></span>, <span class="hljs-string"><span class="hljs-string">'TFFashionDetection'</span></span>) sys.path.append(DETECTOR_PATH) <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> TFFashionDetection.data_preparator <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> DataPreparator <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> TFFashionDetection.utils.ssd_config <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> write_config data_preparator = DataPreparator() data_preparator.build() write_config(<span class="hljs-string"><span class="hljs-string">'ssd_mobilenet_v2_coco_2018_03_29'</span></span>)</code> </pre><br>  After the cell is completed, you can download the pre-trained model and start training the model.  Frozen inference graph from turnips Object Detetetion will allow you to quickly train your detector.  The path to the directory with the model graph will need to be transferred to the training script /object_detection/train.py. <br><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#   () !python /content/TFFashionDetection/utils/download_tf_zoo_model.py --name ssd_mobilenet_v2_coco_2018_03_29 --dir /content #    !export PYTHONPATH=$PYTHONPATH:/content/models/research/slim:/content/models/research/;python /content/models/research/object_detection/train.py --logtostderr --pipeline_config_path=/content/data_dir/tf_api.config --train_dir=/content/data_dir/checkpoints</span></span></code> </pre><br>  If everything is done correctly, we will see how the logs run and the loss will decrease at each iteration.  When you see that the loss function has ceased to decrease - you can stop learning.  The graph of the model is saved in the directory / content / data_dir / checkpoints - it will need to be saved for further experiments.  Training of the model should be carried out once, then use the resulting graph for the inference. <br><br>  When the model is trained - you need to save it to Google-disk <br><br><pre> <code class="python hljs">!cd /content/data_dir; zip -r checkpoint_save_20180514.zip checkpoints/* <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> os fs = GoogleColabFS() file_name = os.path.join(<span class="hljs-string"><span class="hljs-string">'/content/data_dir'</span></span>, <span class="hljs-string"><span class="hljs-string">'checkpoint_save_20180514.zip'</span></span>) fs.load_to_drive(file_name)</code> </pre><br>  Download from Google Drive in the same way <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> os fs.load_file_from_drive(<span class="hljs-string"><span class="hljs-string">'/content'</span></span>, <span class="hljs-string"><span class="hljs-string">'checkpoint_save_20180514.zip'</span></span>) fs.unzip_file(<span class="hljs-string"><span class="hljs-string">'/content'</span></span>, <span class="hljs-string"><span class="hljs-string">'checkpoint_save_20180514.zip'</span></span>) !mkdir /content/deep_detection_model <span class="hljs-comment"><span class="hljs-comment">#   !export PYTHONPATH=$PYTHONPATH:/content/models/research/slim:/content/models/research/;python /content/models/research/object_detection/export_inference_graph.py --input_type image_tensor --pipeline_config_path=/content/data_dir/tf_api.config --trained_checkpoint_prefix=/content/checkpoints/model.ckpt-2108 --output_directory inference_graph</span></span></code> </pre><br>  For example, select a random photo and feed it to our network for detection: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> sys <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> os <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.pyplot <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> plt plt.switch_backend(<span class="hljs-string"><span class="hljs-string">'agg'</span></span>) sys.path.append(os.path.join(<span class="hljs-string"><span class="hljs-string">'/content'</span></span>, <span class="hljs-string"><span class="hljs-string">'models/research'</span></span>)) <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> object_detection.utils <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> visualization_utils <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> vis_util <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> PIL <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Image <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> Pil_image %matplotlib inline boxes = np.array([oject_detector.img_detections[<span class="hljs-number"><span class="hljs-number">3</span></span>][<span class="hljs-string"><span class="hljs-string">'category_box'</span></span>]]) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">load_image_into_numpy_array</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(image)</span></span></span><span class="hljs-function">:</span></span> (im_width, im_height) = image.size <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> np.array(image.getdata()).reshape( (im_height, im_width, <span class="hljs-number"><span class="hljs-number">3</span></span>)).astype(np.uint8) <span class="hljs-comment"><span class="hljs-comment">#       image = Pil_image.open(file_path) image_np = load_image_into_numpy_array(image) #    bounding boxes vis_util.draw_bounding_boxes_on_image_array(image_np, boxes) #     result_file_path = os.path.join('/content', 'test.png') vis_util.save_image_array_as_png(image_np, result_file_path) #  ,   from IPython.display import Image Image(result_file_path)</span></span></code> </pre><br>  See detection results - lower_body garment <br><br><img src="https://habrastorage.org/webt/s_/-e/tj/s_-etj0lubvgttg_hbyxgetd5bs.png"><br><br><h2>  Conclusion </h2><br>  TF Object Detection API is a cool technology that allows you to use the State-of-the-Art mesh architecture in your models.  And Google Collaboration is an excellent platform for experiments, which allows you to train networks on powerful hardware.  The code from the article <a href="https://github.com/Dju999/TFFashionDetection">is available here</a> . </div><p>Source: <a href="https://habr.com/ru/post/358146/">https://habr.com/ru/post/358146/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../358134/index.html">Cross at EITest: how to eliminate the largest network for the spread of viruses</a></li>
<li><a href="../358136/index.html">Tomographic data segmentation</a></li>
<li><a href="../358140/index.html">Council for open data: openness of the Federal Registration Service and the Federal Property Management Agency, the results of 2017 and plans for the future</a></li>
<li><a href="../358142/index.html">What is the difference Smoke, Sanity, Regression, Re-test and how to distinguish them?</a></li>
<li><a href="../358144/index.html">We invite you on May 26 to Unreal Engine Meetup # 3</a></li>
<li><a href="../358148/index.html">From right to left. What is dir = rtl and how to tame Arabic</a></li>
<li><a href="../358150/index.html">Roskomnadzor: Telegram lock affects 400 resources</a></li>
<li><a href="../358152/index.html">Flask Mega-Tutorial, Part XXIII: Application Programming Interfaces (APIs)</a></li>
<li><a href="../358154/index.html">We brought this day as we could - a notepad in Windows 10 began to understand the unix line feed</a></li>
<li><a href="../358158/index.html">SAS BASE procedures with direct control of the number of processor cores</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>