<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Why not everything is so simple with MongoDB</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="In the past few years, MongoDB has gained immense popularity among developers. Every now and then all kinds of articles appear on the Internet, as the...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Why not everything is so simple with MongoDB</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/files/3d7/138/f13/3d7138f13e884a458527bd3a07202f12.png" align="left">  In the past few years, MongoDB has gained immense popularity among developers.  Every now and then all kinds of articles appear on the Internet, as the regular young popular project threw the familiar RDBMSs to the dustbin of history, took MongoDB as the main database, built the infrastructure around it, and how everything turned out fine.  Even new frameworks and libraries appear, which build their architecture entirely on Mongo ( <a href="https://www.meteor.com/">Meteor.js</a> for example). <br><br>  I have been working for about 3 years on development and support of several projects that use MongoDB as the main database, and in this article I want to tell why in my opinion with MongoDB, not everything is as simple as it is written in the manuals, and why do you should be ready, if you suddenly decide to take MongoDB as the main database in your new fashionable startup :-) <br><br>  Everything described below can be reproduced using the <a href="https://api.mongodb.org/python/">PyMongo</a> library for working with MongoDB from the Python programming language.  However, you will likely encounter similar situations when using other libraries for other programming languages. <br><a name="habracut"></a><br><h2>  PyMongo, problem with Failover and AutoReconnect exception </h2><br>  Almost in all manuals as well as in numerous articles on the Internet it is said that Mongo supports failover out of the box due to the built-in replication mechanism.  In several articles, even in <a href="https://youtu.be/iEnioS8n254%3Ft%3D1139">official courses from 10gen</a> , a very popular example is given, such as if you deploy several mongod processes on one host and set up replication between them, and then kill one of the processes, the replication will not collapse, the new master will be re-elected and everything will be OK.  And this is indeed how it works ... but only on localhost!  In real conditions, everything is a little different. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Let's say let's experiment with virtual machines on Amazon.  Let's raise 5t small machines - 3 for databases, and 2 for test processes writer and reader - one continuously writes values ‚Äã‚Äãto the base, the other reads them. <br><br>  We take CentOS 6.x, put mongodb on it from standard rep, set supervisor.  The configuration of each of the mongod processes at the supervisor is as follows: <br><pre><code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># touch /etc/supervisord.d/mongo.conf [program:mongo] directory=/mnt/mongo command=mongod --dbpath /mnt/mongo/ --logappend --logpath /mnt/mongo/log --port 27017 --replSet abc</span></span></code> </pre> <br>  Configure replication: <br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># mongo --port 27017 &gt; rs.initiate({ _id: 'abc', members: [ {_id: 0, host:'db1:27017'}, {_id: 1, host:'db2:27017'}, {_id: 2, host:'db3:27017'} ] })</span></span></code> </pre><br>  The <b>writer.py</b> process looks like this: <br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> datetime, random, time, pymongo con = pymongo.MongoReplicaSetClient(<span class="hljs-string"><span class="hljs-string">'db1:27017,db2:27017,db3:27017'</span></span>, replicaSet=<span class="hljs-string"><span class="hljs-string">'abc'</span></span>) cl = con.test.entities <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> <span class="hljs-keyword"><span class="hljs-keyword">True</span></span>: time.sleep(<span class="hljs-number"><span class="hljs-number">1</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">try</span></span>: res = cl.insert({ <span class="hljs-string"><span class="hljs-string">'time'</span></span>: time.time(), <span class="hljs-string"><span class="hljs-string">'value'</span></span>: random.random(), <span class="hljs-string"><span class="hljs-string">'title'</span></span>: random.choice([<span class="hljs-string"><span class="hljs-string">'python'</span></span>, <span class="hljs-string"><span class="hljs-string">'php'</span></span>, <span class="hljs-string"><span class="hljs-string">'ruby'</span></span>, <span class="hljs-string"><span class="hljs-string">'java'</span></span>, <span class="hljs-string"><span class="hljs-string">'cpp'</span></span>, <span class="hljs-string"><span class="hljs-string">'javascript'</span></span>, <span class="hljs-string"><span class="hljs-string">'go'</span></span>, <span class="hljs-string"><span class="hljs-string">'erlang'</span></span>]), <span class="hljs-string"><span class="hljs-string">'type'</span></span>: random.randint(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>) }) <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> <span class="hljs-string"><span class="hljs-string">'['</span></span>, datetime.datetime.utcnow(), <span class="hljs-string"><span class="hljs-string">']'</span></span>, <span class="hljs-string"><span class="hljs-string">'wrote:'</span></span>, res <span class="hljs-keyword"><span class="hljs-keyword">except</span></span> pymongo.errors.AutoReconnect, e: <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> <span class="hljs-string"><span class="hljs-string">'['</span></span>, datetime.datetime.utcnow(), <span class="hljs-string"><span class="hljs-string">']'</span></span>, <span class="hljs-string"><span class="hljs-string">'autoreconnect error:'</span></span>, e <span class="hljs-keyword"><span class="hljs-keyword">except</span></span> Exception, e: <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> <span class="hljs-string"><span class="hljs-string">'['</span></span>, datetime.datetime.utcnow(), <span class="hljs-string"><span class="hljs-string">']'</span></span>, <span class="hljs-string"><span class="hljs-string">'error:'</span></span>, e</code> </pre>  As you can see from the listing, the above script every second tries to save the value to the database. <br><br>  But the <b>reader.py</b> process: <br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> datetime, time, random, pymongo con = pymongo.MongoReplicaSetClient(<span class="hljs-string"><span class="hljs-string">'db1:27017,db2:27017,db3:27017'</span></span>, replicaSet=<span class="hljs-string"><span class="hljs-string">'abc'</span></span>) cl = con.test.entities <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> <span class="hljs-keyword"><span class="hljs-keyword">True</span></span>: time.sleep(<span class="hljs-number"><span class="hljs-number">1</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">try</span></span>: res = cl.find_one({<span class="hljs-string"><span class="hljs-string">'type'</span></span>: random.randint(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>)}, sort=[(<span class="hljs-string"><span class="hljs-string">"time"</span></span>, pymongo.DESCENDING)]) <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> <span class="hljs-string"><span class="hljs-string">'['</span></span>, datetime.datetime.utcnow(), <span class="hljs-string"><span class="hljs-string">']'</span></span>, <span class="hljs-string"><span class="hljs-string">'read:'</span></span>, res <span class="hljs-keyword"><span class="hljs-keyword">except</span></span> Exception, e: <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> <span class="hljs-string"><span class="hljs-string">'['</span></span>, datetime.datetime.utcnow(), <span class="hljs-string"><span class="hljs-string">']'</span></span>, <span class="hljs-string"><span class="hljs-string">'error'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> e</code> </pre>  And this script every second tries to read the value from the database. <br><br>  We start the processes <b>writer.py</b> and <b>reader.py</b> in parallel, and then we take a stop-aem machine with a Primary-node in the Amazon console. <br><br><img src="https://habrastorage.org/files/652/0b3/17e/6520b317e3b24d43a5068f024d3ad981.jpg"><br><br>  What should happen logically?  According to the MongoDB documentation, the 'abc' replica has to re-elect a new wizard and this should happen transparently for the <b>writer.py</b> and <b>reader.py scripts</b> , and if you are testing on the locale (i.e., deploying all three processes on the same host), then really and going on.  In our case, the scripts <b>writer.py</b> and <b>reader.py</b> simply hang and remain so suspended until you send them an interrupt signal (even when the new primary is already selected and active). <br><pre> <code class="bash hljs">[ 2015-08-28 21:57:44.694668 ] wrote: 55e0d958671709042a4918b5 [ 2015-08-28 21:57:45.696838 ] wrote: 55e0d959671709042a4918b6 [ 2015-08-28 21:57:46.698918 ] wrote: 55e0d95a671709042a4918b7 [ 2015-08-28 21:57:47.703834 ] wrote: 55e0d95b671709042a4918b8 [ 2015-08-28 21:57:48.712134 ] wrote: 55e0d95c671709042a4918b9 ^CTraceback (most recent call last): File <span class="hljs-string"><span class="hljs-string">"write.py"</span></span>, line 18, <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> &lt;module&gt; <span class="hljs-string"><span class="hljs-string">'type'</span></span>: random.randint(1, 5) File <span class="hljs-string"><span class="hljs-string">"/usr/lib64/python2.6/site-packages/pymongo/collection.py"</span></span>, line 409, <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> insert gen(), check_keys, self.uuid_subtype, client) File <span class="hljs-string"><span class="hljs-string">"/usr/lib64/python2.6/site-packages/pymongo/message.py"</span></span>, line 393, <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> _do_batched_write_command results.append((idx_offset, send_message())) File <span class="hljs-string"><span class="hljs-string">"/usr/lib64/python2.6/site-packages/pymongo/message.py"</span></span>, line 345, <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> send_message <span class="hljs-built_in"><span class="hljs-built_in">command</span></span>=True) File <span class="hljs-string"><span class="hljs-string">"/usr/lib64/python2.6/site-packages/pymongo/mongo_replica_set_client.py"</span></span>, line 1511, <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> _send_message response = self.__recv_msg(1, rqst_id, sock_info) File <span class="hljs-string"><span class="hljs-string">"/usr/lib64/python2.6/site-packages/pymongo/mongo_replica_set_client.py"</span></span>, line 1444, <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> __recv_msg header = self.__recv_data(16, sock) File <span class="hljs-string"><span class="hljs-string">"/usr/lib64/python2.6/site-packages/pymongo/mongo_replica_set_client.py"</span></span>, line 1432, <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> __recv_data chunk = sock_info.sock.recv(length) KeyboardInterrupt</code> </pre><br>  Agree that not a good situation for a system that positions itself as a fault-tolerant out of the box?  Of course, the example is a bit exaggerated - for example, if you use PyMongo and MongoDB in your web project, then it is likely that all python facilities are running under <a href="https://uwsgi-docs.readthedocs.org/en/latest/">uwsgi</a> , and some <a href="http://uwsgi-docs.readthedocs.org/en/latest/FAQ.html">harakiri mode is</a> set up in <a href="https://uwsgi-docs.readthedocs.org/en/latest/">uwsgi</a> , which will <a href="http://uwsgi-docs.readthedocs.org/en/latest/FAQ.html">beat the timeout</a> scripts y ... But nevertheless, I would like to somehow intercept this kind of situation in the code.  For this you need to modify the scripts.  In <b>reader.py</b> script <b>you</b> need to replace: <br><pre> <code class="python hljs">con = pymongo.MongoReplicaSetClient(<span class="hljs-string"><span class="hljs-string">'db1:27017,db2:27017,db3:27017'</span></span>, replicaSet=<span class="hljs-string"><span class="hljs-string">'abc'</span></span>)</code> </pre>  on <br><pre> <code class="python hljs">con = pymongo.MongoReplicaSetClient(<span class="hljs-string"><span class="hljs-string">'db1:27017,db2:27017,db3:27017'</span></span>, replicaSet=<span class="hljs-string"><span class="hljs-string">'abc'</span></span>, socketTimeoutMS=<span class="hljs-number"><span class="hljs-number">5000</span></span>, read_preference=pymongo.ReadPreference.SECONDARY_PREFERRED)</code> </pre><br>  And in the script <b>writer.py</b> : <br><pre> <code class="python hljs">con = pymongo.MongoReplicaSetClient(<span class="hljs-string"><span class="hljs-string">'db1:27017,db2:27017,db3:27017'</span></span>, replicaSet=<span class="hljs-string"><span class="hljs-string">'abc'</span></span>)</code> </pre>  on <br><pre> <code class="python hljs">con = pymongo.MongoReplicaSetClient(<span class="hljs-string"><span class="hljs-string">'db1:27017,db2:27017,db3:27017'</span></span>, replicaSet=<span class="hljs-string"><span class="hljs-string">'abc'</span></span>, socketTimeoutMS=<span class="hljs-number"><span class="hljs-number">5000</span></span>)</code> </pre><br>  What in the end we get.  Repeating the experiment with cutting the Primary node, the <b>reader.py</b> process <b>will</b> continue to work as if nothing had happened (since it refers to the Secondary node, which in our example remains unchanged), but the process <b>writer.py</b> will go to astral for about a minute while throwing <b>AutoReconnect</b> type errors: <br><pre> <code class="bash hljs">[ 2015-08-28 21:49:06.303250 ] wrote: 55e0d75267170904208d3e01 [ 2015-08-28 21:49:07.306277 ] wrote: 55e0d75367170904208d3e02 [ 2015-08-28 21:49:13.313476 ] autoreconnect error: timed out [ 2015-08-28 21:49:24.315754 ] autoreconnect error: No primary available [ 2015-08-28 21:49:33.338286 ] autoreconnect error: No primary available [ 2015-08-28 21:49:44.340396 ] autoreconnect error: No primary available [ 2015-08-28 21:49:53.361185 ] autoreconnect error: No primary available [ 2015-08-28 21:50:04.363322 ] autoreconnect error: No primary available [ 2015-08-28 21:50:13.456355 ] wrote: 55e0d79267170904208d3e09 [ 2015-08-28 21:50:14.459553 ] wrote: 55e0d79667170904208d3e0a [ 2015-08-28 21:50:15.462317 ] wrote: 55e0d79767170904208d3e0b [ 2015-08-28 21:50:16.465371 ] wrote: 55e0d79867170904208d3e0c</code> </pre><br>  Again, it‚Äôs not too healthy for the system, which is positioned as fail-safe, to go down for a minute (I repeat that if you test on the locale, there are no timeouts - everything is smooth), but this is an inevitable evil and <a href="http://docs.mongodb.org/manual/faq/replica-sets/">even written</a> about this <a href="http://docs.mongodb.org/manual/faq/replica-sets/">in the documentation</a> : <br><blockquote>  It varies, but a replica set will select a new primary within a minute. <br>  It can take 10-30 seconds to replica set to declare a primary inaccessible.  This triggers an election.  During the election, the cluster is unavailable for writes. <br>  The election itself may take another 10-30 seconds. <br></blockquote>  But back to our example and to the errors AutoReconnect.  As you probably guessed, we set a timeout of 5 seconds per socket.  If after 5 seconds the PyMongo driver does not receive any response from the database, then it drops the connection and spits out an error.  Not a great solution - suddenly the database is overloaded or the request is very heavy and takes more than 5 seconds to complete (some aggregate function that wools the entire base).  The most important question is why the driver does not try to restart the request itself when it sees that AutoReconnect Error has occurred.  The first reason - the driver does not know what really happened - all of a sudden, ‚Äúnot a single process‚Äù, but the whole replicat ‚Äúlay down‚Äù.  The second reason is duplicates!  It turns out that in case of an AutoReconnect error, the driver does not know whether it managed to write data or failed.  This sounds a bit strange for a base that claims to dominate the world, but this is true, and for our example to work correctly, the script <b>writer.py</b> needs to be rewritten as follows: <br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> datetime, time, random, pymongo <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> pymongo.objectid <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> ObjectId con = pymongo.MongoReplicaSetClient(<span class="hljs-string"><span class="hljs-string">'db1:27017,db2:27017,db3:27017'</span></span>, replicaSet=<span class="hljs-string"><span class="hljs-string">'abc'</span></span>, socketTimeoutMS=<span class="hljs-number"><span class="hljs-number">5000</span></span>) cl = con.test.entities <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> <span class="hljs-keyword"><span class="hljs-keyword">True</span></span>: time.sleep(<span class="hljs-number"><span class="hljs-number">1</span></span>) data = { <span class="hljs-string"><span class="hljs-string">'_id'</span></span>: ObjectId(), ‚Ä¶. } <span class="hljs-comment"><span class="hljs-comment"># Try for five minutes to recover from a failed primary for i in range(60): try: res = cl.insert(data) print '[', datetime.datetime.utcnow(), ']', 'wrote:', res break except pymongo.errors.AutoReconnect, e: print '[', datetime.datetime.utcnow(), ']', 'autoreconnect error:', e time.sleep(5) except pymongo.errors.DuplicateKeyError: break</span></span></code> </pre>  On this topic there is also an <a href="http://emptysqua.re/blog/save-the-monkey-reliably-writing-to-mongodb/">article in the blog of</a> one of the PyMongo developers, as well as a small discussion in <a href="https://jira.mongodb.org/browse/PYTHON-197">JIRA MongoDB</a> <br><br><h2>  Global lock problem </h2><br>  A huge MongoDB reef.  Probably something for which Mongu is most criticized.  Under attack are massive operations carried out on a group of documents.  That is, roughly speaking, several heavy operations of updates on a large group of documents can create performance problems and block the execution of other requests.  Of course, starting <a href="http://docs.mongodb.org/manual/release-notes/2.2/">from version 2.2, the</a> situation improved a little when they learned how to lock lock (lock yielding), and also transferred the lock from the level of the mongod process to the level of the selected database.  In the new version 3.0, the creators claim that with the transition to the alternative WiredTiger engine, the situation should improve, since it uses locks at the document level, and does not block the entire database, as it was in the MMAPv1 engine. <br><br>  I wrote a <a href="https://github.com/dmitry-viskov/mongodb-performance-tests">small benchmark</a> to illustrate the global lock situation.  If you wish, you can do git pull and play all these tests at your place. <br><ul><li>  Consider 1 000 users (value can be changed via config) </li><li>  Each user has 5,000 documents.  That is only 5,000,000 documents in the database.  Each document contains a field that stores some boolean value. </li><li>  The testing process is the parallel execution of 1,000 tasks ‚Äî one for each user.  Each task is updating the boolean field of all 5,000 user documents. </li><li>  In the process of testing by incrementing from 1st to 30th (again, the value can be changed through the config), we increase the number of competitive processes that at a time pick up a pool of tasks. </li><li>  Save the execution time of each task.  We build graphics.  Compare test results for different versions of MongoDB. </li><li>  Alternatively, consider a similar task in MySQL 5.5 (InnoDB).  And compare the results. </li></ul>  Testing was done on an Amazon instance of type <a href="https://aws.amazon.com/ru/ec2/instance-types/">c3.2xlarge</a> (vCPU 8, 15 Gb RAM) with an additionally connected SSD disk for the base (500 Gb, 4000 iOPS) <br><br>  As a result of testing the following has turned out. <br><br>  If we compare the version of MongoDB 2.6 and the version of MongoDB 3.0 (MMAPv1, not WiredTiger), the results do not differ much, although in the case of 30 simultaneous worker processes using MongoDB 3.0, the query execution time is still slightly smaller.  By the way, during testing, if you look at the mongostat <b>utility</b> for the percentage of lock, it will go off scale: <br><br><div class="spoiler">  <b class="spoiler_title">Result of comparing MongoDB 2.6 and MongoDB 3.0 MMAPv1</b> <div class="spoiler_text">  In 15t parallel processes: <br> <a href=""><img src="https://habrastorage.org/files/c1b/a66/9a5/c1ba669a52204a5185d5e958800d851d.png"></a> <br>  In 30 parallel processes: <br> <a href=""><img src="https://habrastorage.org/files/dde/59c/243/dde59c243d6f4bb9a051c2ed99cad66a.png"></a> <br>  mongostat: <br><img src="https://habrastorage.org/files/ea9/2ed/d19/ea92edd19f1d4d28bef805ca70f88437.jpg"><br></div></div><br><br>  When comparing MongoDB 3.0 MMAPv1 and MongoDB 3.0 WiredTiger, the results are strikingly different, which suggests that the effect of locks on the performance of bulk operations is indeed much less when using WiredTiger: <br><br><div class="spoiler">  <b class="spoiler_title">Result of comparing MongoDB 3.0 MMAPv1 and MongoDB 3.0 WiredTiger</b> <div class="spoiler_text">  In 15t parallel processes: <br> <a href=""><img src="https://habrastorage.org/files/2c5/9c3/ddc/2c59c3ddc75e4fb3aa927ed3e34fcba3.png"></a> <br>  In 30 parallel processes: <br> <a href=""><img src="https://habrastorage.org/files/df9/fb7/559/df9fb755991c4750973aa0fc89adef1c.png"></a> <br></div></div><br><br>  Now compare MongoDB 3.0 WiredTiger and MySQL 5.5.  MySQL database was selected solely from individual preferences.  If someone has a desire, you can conduct a similar test on PostgreSQL.  All the logic of working with the base is encapsulated with special adapters.  So for this you only need to write a class, inheriting it from the abstract class <a href="https://github.com/dmitry-viskov/mongodb-performance-tests/blob/master/mongodb_performance_tests/adapters/abstract.py">AbstractDBAdapter</a> and redefining all abstract methods for working with PostgreSQL. <br>  As you know, testing a base out of the box is a thankless and meaningless exercise.  As for MongoDB, alas, everything is bad here.  The base is almost not tyunitsya, minimum settings.  The main principle of MongoDB is to allocate a separate server as a base, and then the base will decide for itself which data to keep in memory and which to drop to disk.  In several sources I heard the opinion that there should be at least enough free memory on the server so that the indexes fit into it.  In the case of MySQL mass settings, and before starting the benchmark, the following setting was made: <br><pre> <code class="bash hljs">max_connections = 10000 query_cache_limit = 32M query_cache_size = 1024M innodb_buffer_pool_size = 8192M innodb_log_file_size = 512M innodb_thread_concurrency = 16 innodb_flush_log_at_trx_commit = 2 thread_cache = 32 thread_cache_size = 16</code> </pre>  And here are the results. <br>  The first thing that catches the eye when performing a test on MySQL is that the total time for the execution of all tasks with an increase in the number of processes ‚Äî workers practically does not change: <pre> <code class="bash hljs">... Run <span class="hljs-built_in"><span class="hljs-built_in">test</span></span> with 5 proceses Test is finished! Save results Full time: 20.7063720226 Run <span class="hljs-built_in"><span class="hljs-built_in">test</span></span> with 6 proceses Test is finished! Save results Full time: 19.1608040333 Run <span class="hljs-built_in"><span class="hljs-built_in">test</span></span> with 7 proceses Test is finished! Save results Full time: 19.0062150955 ‚Ä¶ Run <span class="hljs-built_in"><span class="hljs-built_in">test</span></span> with 15 proceses Test is finished! Save results Full time: 18.5613899231 Run <span class="hljs-built_in"><span class="hljs-built_in">test</span></span> with 16 proceses Test is finished! Save results Full time: 18.4244360924 ‚Ä¶ Run <span class="hljs-built_in"><span class="hljs-built_in">test</span></span> with 29 proceses Test is finished! Save results Full time: 16.8106219769 Run <span class="hljs-built_in"><span class="hljs-built_in">test</span></span> with 30 proceses Test is finished! Save results Full time: 19.3497707844</code> </pre>  The second is of course graphics.  In the case of MySQL, the query execution time fluctuates around 0.001-0.5 seconds and is constant both with 15 handler processes and at 30, while in the case of MongoDB WiredTiger with 15 processes, the query execution time reaches 1.5 seconds, and at 30 - up to 2.5 seconds: <br><br><div class="spoiler">  <b class="spoiler_title">Result of comparing MongoDB 3.0 WiredTiger and MySQL 5.5 InnoDB</b> <div class="spoiler_text">  In 15t parallel processes: <br> <a href=""><img src="https://habrastorage.org/files/bd0/4ea/61f/bd04ea61f08a42349e16897391e5132b.png"></a> <br>  In 30 parallel processes: <br> <a href=""><img src="https://habrastorage.org/files/b21/790/e14/b21790e149bd41f59248bbb3d1fb11e1.png"></a> <br></div></div><br>  What conclusions can be drawn from this? <br><br>  Personally, I see the following pattern for myself when you can use MongoDB in a project: <br><ul><li>  the data scheme fits well with the concept of ‚Äúthick‚Äù weakly coherent documents </li><li>  the lack of transactions is compensated by the atomic nature of operations on documents </li><li>  The business logic of the application does not imply numerous bulk operations on documents. </li></ul><br>  It is also desirable that documents are not removed frequently.  This is connected with another small problem (I decided not to take it to a separate point).  When deleting documents, free disk space is not freed.  MongoDB marks the block on the disk as free and, if convenient, uses this block for a new document.  According to my observations before version 2.6, this strategy worked extremely inefficiently, because after performing <a href="http://docs.mongodb.org/master/reference/command/repairDatabase/">repairDatabase</a> on a long-lived database, it was possible to reduce the size of data and indexes by more than 2 times (!).  Starting from version 2.6 for new collections, the new strategy began to be used to preallocate a disk for new documents ( <a href="http://docs.mongodb.org/master/release-notes/2.6/">usePowerOf2Sizes</a> option) - as a result of its use, the size of the allocated space for new documents became slightly larger than before, but the space after deleting documents became more efficiently.  And in version 3.0 for the MMAPv1 engine, we went even further and once again <a href="http://docs.mongodb.org/master/core/storage/">changed the preallocation strategy</a> , but I haven‚Äôt yet been able to evaluate its production efficiency.  What happens with the WiredTiger engine in terms of preallocating the disk, to be honest, I do not know either.  If you have any information about this - write in the comments :-) </div><p>Source: <a href="https://habr.com/ru/post/265747/">https://habr.com/ru/post/265747/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../265737/index.html">IBM will help Singapore to solve the problem of increasing sea traffic</a></li>
<li><a href="../265739/index.html">Flash to Html5 or secret api Swiffy</a></li>
<li><a href="../265741/index.html">Habr shell: we build a cross-platform ssh server in java application</a></li>
<li><a href="../265743/index.html">Announcement of the fifth meeting of the Java User Group EKB</a></li>
<li><a href="../265745/index.html">RailsClub 2015: Interview with Claudio Bachchigalupo</a></li>
<li><a href="../265749/index.html">Urho3D Editor (Part 1)</a></li>
<li><a href="../265751/index.html">Infobox VPS Review</a></li>
<li><a href="../265753/index.html">Truly responsive letters. Part two. Framework</a></li>
<li><a href="../265755/index.html">How to stop configuring and start living or setting up Puppet in a school classroom on 25 computers</a></li>
<li><a href="../265757/index.html">How I passed the OSCP</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>