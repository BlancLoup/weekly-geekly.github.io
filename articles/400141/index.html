<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Deep learning and Raspberry PI</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="‚ÄúWhat do we have?‚Äù Asked the horned beast, turning. 
 ‚ÄúAldan-3,‚Äù said the bearded. 
 ‚ÄúA rich car,‚Äù I said. ‚Äú[1] 

 Recently, I decided to study deep l...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Deep learning and Raspberry PI</h1><div class="post__text post__text-html js-mediator-article"><blockquote>  ‚ÄúWhat do we have?‚Äù Asked the horned beast, turning. <br>  ‚ÄúAldan-3,‚Äù said the bearded. <br>  ‚ÄúA rich car,‚Äù I said. ‚Äú[1] </blockquote><p>  Recently, I decided to study deep learning.  At work, I was given a new card with CUDA support and the chief expressed his wish that this peak of engineering will allow our laboratory to make a leap forward, or at least, not to lag behind the mass of competitors.  I already had some experience with Tensor Flow, but this time I decided to try Torch.  Attracted that it is written in the language of Lua and C, is quite lightweight and easily extensible through FFI.  And I don't like Python either. </p><br><p>  Recently, I came across an article on Habrahabr, in the process of discussing which I remembered that somewhere in the nightstand I saw Raspberry Pi, the B + model and I wanted to see if I could pick up a torch on it and run something simple. </p><br><a name="habracut"></a><br><p>  Naturally, the first thing I wanted was to see how alexnet and other well-known networks will train on my desktop with a new GPU card.  On github there is a small project in which several popular networks are implemented on <a href="">Torch</a> .  Having played with them, I switched to solving my problems, but I‚Äôm not going to talk about them here. </p><br><p>  Now go to the raspberry (Raspberry PI model B +). </p><br><h2 id="ustanovka">  Installation </h2><br><p>  Copy the torch installer to <a href="http://torch.ch/docs/getting-started.html">Malinka</a> : </p><br><pre><code class="bash hljs">apt-get install git-core git <span class="hljs-built_in"><span class="hljs-built_in">clone</span></span> https://github.com/torch/distro.git ~/torch --recursive</code> </pre> <br><p>  First of all, I decided that I don‚Äôt want to wait until the standard Torch installer compiles OpenBLAS and installs QT with all dependencies, so I decided to do it manually: </p><br><pre> <code class="bash hljs">apt-get install -y build-essential gcc g++ curl cmake libreadline-dev libjpeg-dev libpng-dev ncurses-dev imagemagick libzmq3-dev gfortran libopenblas-base libopenblas-dev</code> </pre> <br><p>  Start compiling torch: </p><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> ~/torch; ./install.sh</code> </pre> <br><p>  My compilation takes only about an hour. </p><br><blockquote>  ‚ÄúAnd what is this lamp with you?‚Äù  - Farfurkis asked suspiciously.  [one] </blockquote><p>  And here we are waiting for the first bummer: the creators of torch: did not expect that it will be compiled on the arm architecture, but without the support of NEON: </p><br><pre> <code class="bash hljs">[ 6%] Building C object lib/TH/CMakeFiles/TH.dir/THVector.co In file included from /home/pi/torch/pkg/torch/lib/TH/THVector.c:2:0: /home/pi/torch/pkg/torch/lib/TH/generic/THVectorDispatch.c: In <span class="hljs-keyword"><span class="hljs-keyword">function</span></span> <span class="hljs-string"><span class="hljs-string">'THByteVector_vectorDispatchInit'</span></span>: /home/pi/torch/pkg/torch/lib/TH/generic/simd/simd.h:64:3: error: impossible constraint <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> <span class="hljs-string"><span class="hljs-string">'asm'</span></span> asm volatile ( <span class="hljs-string"><span class="hljs-string">"cpuid\n\t"</span></span></code> </pre> <br><p>  I had to <a href="https://github.com/torch/torch7/pull/868">fix this case</a> .  And after that, it all worked!  If you are too lazy to do it all yourself and want to quickly try an example, I made an archive with a pre-compiled torch for Raspberry PI -B (without the support of NEON): <a href="">https://github.com/vfonov/deep-pi/releases/download/ v1 / torch_intstall_raspbian_arm6l_20161218.tar.gz</a> , unpacked in / home / pi </p><br><h2 id="testirovanie">  Testing </h2><br><p>  To test, I decided to look at the speed of the <a href="http://yann.lecun.com/exdb/mnist/">MNIST</a> handwriting recognition workout, the corresponding example is in the Torch <a href="https://github.com/torch/demos">set of demos</a> : </p><br><pre> <code class="bash hljs">th train-on-mnist.lua &lt;torch&gt; <span class="hljs-built_in"><span class="hljs-built_in">set</span></span> nb of threads to 4 &lt;mnist&gt; using model: nn.Sequential { [input -&gt; (1) -&gt; (2) -&gt; (3) -&gt; (4) -&gt; (5) -&gt; (6) -&gt; (7) -&gt; (8) -&gt; (9) -&gt; (10) -&gt; output] (1): nn.SpatialConvolutionMM(1 -&gt; 32, 5x5) (2): nn.Tanh (3): nn.SpatialMaxPooling(3x3, 3,3, 1,1) (4): nn.SpatialConvolutionMM(32 -&gt; 64, 5x5) (5): nn.Tanh (6): nn.SpatialMaxPooling(2x2, 2,2) (7): nn.Reshape(576) (8): nn.Linear(576 -&gt; 200) (9): nn.Tanh (10): nn.Linear(200 -&gt; 10) } &lt;warning&gt; only using 2000 samples to train quickly (use flag -full to use 60000 samples) &lt;mnist&gt; loading only 2000 examples &lt;mnist&gt; <span class="hljs-keyword"><span class="hljs-keyword">done</span></span> &lt;mnist&gt; loading only 1000 examples &lt;mnist&gt; <span class="hljs-keyword"><span class="hljs-keyword">done</span></span> &lt;trainer&gt; on training <span class="hljs-built_in"><span class="hljs-built_in">set</span></span>: &lt;trainer&gt; online epoch <span class="hljs-comment"><span class="hljs-comment"># 1 [batchSize = 10] [===================&gt;.................... 471/2000 ....................................] ETA: 2m20s | Step: 92ms</span></span></code> </pre> <br><p>  In general, not bad, for comparison - on the desktop with i5-4590 CPU @ 3.30GHz, without using a GPU: </p><br><pre> <code class="hljs cs">[<span class="hljs-meta"><span class="hljs-meta">=======================&gt;................ 571/2000 ....................................</span></span>] ETA: <span class="hljs-number"><span class="hljs-number">27</span></span>s613ms | Step: <span class="hljs-number"><span class="hljs-number">19</span></span>ms</code> </pre> <br><p>  That is, in this example, the Malinka is about 5 times slower than a modern desktop. </p><br><h2 id="raspoznavaniya-izobrazheniy">  Image recognition </h2><br><blockquote>  now animated "Aldan" sometimes printed at the exit: "I think.  Please do not interfere "[1] </blockquote><p>  Now it's time to make the raspberry recognize images using a trained googlenet.  A second trick was waiting for me here: there are so many parameters in Alexnet that there is not enough memory for Malinka.  But here comes squeezenet and Network-in-Network to the rescue, the author of the latter even made a trained <a href="https://gist.github.com/szagoruyko/0f5b4c5e2d2b18472854">model in the format for torch</a> . </p><br><p>  First you need to transform the model so that it can be used on the ARM architecture (you should not train on Raspberry PI - the results will be ready in a hundred years). </p><br><p>  On the desktop, you need to load the model in the binary format torch, and write in the format 'ascii', then on the malinka - convert back: </p><br><p>  Desktop: </p><br><pre> <code class="lua hljs">model=torch.<span class="hljs-built_in"><span class="hljs-built_in">load</span></span>(<span class="hljs-string"><span class="hljs-string">'blah.t7'</span></span>) torch.save(<span class="hljs-string"><span class="hljs-string">'blah_ascii.t7'</span></span>,model,<span class="hljs-string"><span class="hljs-string">'ascii'</span></span>)</code> </pre> <br><p>  Raspberry PI: </p><br><pre> <code class="lua hljs">model=torch.<span class="hljs-built_in"><span class="hljs-built_in">load</span></span>(<span class="hljs-string"><span class="hljs-string">'blah_ascii.t7'</span></span>,<span class="hljs-string"><span class="hljs-string">'ascii'</span></span>) torch.save(<span class="hljs-string"><span class="hljs-string">'blah_arm.t7'</span></span>,model)</code> </pre> <br><p>  The version for arm can be downloaded <a href="">here</a> . </p><br><p>  I made a little script for working on a malink: <br>  Full text <a href="">here</a> . </p><br><pre> <code class="lua hljs">... <span class="hljs-keyword"><span class="hljs-keyword">local</span></span> m=torch.<span class="hljs-built_in"><span class="hljs-built_in">load</span></span>(prefix..<span class="hljs-string"><span class="hljs-string">'nin_bn_final_arm.t7'</span></span>) ... <span class="hljs-keyword"><span class="hljs-keyword">local</span></span> <span class="hljs-built_in"><span class="hljs-built_in">input</span></span>=image.<span class="hljs-built_in"><span class="hljs-built_in">load</span></span>(prefix..<span class="hljs-string"><span class="hljs-string">"n07579787_ILSVRC2012_val_00049211.JPEG"</span></span>) ... <span class="hljs-keyword"><span class="hljs-keyword">local</span></span> <span class="hljs-built_in"><span class="hljs-built_in">output</span></span>=model:forward(cropped) ...</code> </pre> <br><p>  And voila, we launch it with an image from the <a href="http://image-net.org/download-images">ImageNET</a> test suite: </p><br><pre> <code class="bash hljs">&gt;th test_single.lua n07579787_ILSVRC2012_val_00049211.JPEG loading model:0.57sec Running neural net:13.46sec 25.3%: n07579787: plate 13.8%: n07873807: pizza, pizza pie 8.8%: n04263257: soup bowl 8.0%: n07590611: hot pot, hotpot 7.2%: n07831146: carbonara</code> </pre> <br><p>  Te for 14 seconds Malinka successfully coped with the pattern recognition procedure! </p><br><p>  It is time to make an example more interesting: we attach the interface to the camera from the camera package and the web interface from the display package, and we have an interactive machine that announces to the world in 14 seconds what it sees.  You only need to install the package for working with the camera (luarocks install camera) and for visualization via the web interface (luarocks install display). </p><br><p>  Full text <a href="">here</a> . </p><br><pre> <code class="lua hljs">‚Ä¶ <span class="hljs-comment"><span class="hljs-comment">--   local cam = image.Camera {idx=0,width=iW,height=iH} ... local frame = cam:forward() local cropped = image.crop(frame, w1, h1, w1+oW, h1+oH) -- center patch ‚Ä¶ --    display_sample_in.win=display.image(cropped,display_sample_in) ‚Ä¶ --     local output=model:forward(cropped) ‚Ä¶ --   -   display_output.win=display.text(out_text,display_output)</span></span></code> </pre> <br><p>  Before launching, you must start the daemon from the display package: <code>nohup th -ldisplay.start 8000 0.0.0.0 &amp;</code> </p><br><h3 id="ispytaniya">  Tests </h3><br><p>  Test setup: </p><br><p><img src="https://cloud.githubusercontent.com/assets/628822/21299836/637e738a-c56d-11e6-80a4-c20605527d89.jpg" alt="image"></p><br><p>  Result: </p><br><p><img src="https://cloud.githubusercontent.com/assets/628822/21299835/637e6700-c56d-11e6-9c01-8e600417ac4d.jpg" alt="image"></p><br><p><img src="https://cloud.githubusercontent.com/assets/628822/21299834/637e11ce-c56d-11e6-82e1-c78ebf69004b.jpg" alt="image"></p><br><p><img src="https://cloud.githubusercontent.com/assets/628822/21299833/637df9b4-c56d-11e6-8f06-6c4e22f45957.jpg" alt="image"></p><br><h2 id="zaklyuchenie">  Conclusion </h2><br><p>  So we have an inexpensive machine for image recognition, which you can please your friends during the New Year holidays.  Naturally, the task of classifying an image can be replaced by something more productive, for example, you can easily make a system for identifying a person by physiognomy, there are several examples <a href="http://torch.ch/blog/2016/06/01/deep-fun-with-opencv.html">here,</a> or you can <a href="https://github.com/torch/demos/tree/master/person-detector">identify figures of people</a> on your garden monitoring camera. </p><br><p>  To optimize performance, you can try using <a href="https://github.com/szagoruyko/nnpack.torch">nnpack</a> , or even make an interface to a vector accelerator built into the ramberry processor like <a href="https://github.com/jetpacapp/DeepBeliefSDK">this</a> . </p><br><h2 id="primechaniya">  Notes: </h2><br><p>  Quotes from "Monday begins on Saturday" and "The Tale of the Three" by A. and B. Strugatsky. <br>  Description of the procedure in English and the repository with all the source code is on <a href="https://github.com/vfonov/deep-pi">github</a> . </p></div>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <p>Source: <a href="https://habr.com/ru/post/400141/">https://habr.com/ru/post/400141/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../400131/index.html">Alihistori - smart shopping tools</a></li>
<li><a href="../400133/index.html">Containers of the two-phase immersion cooling system</a></li>
<li><a href="../400135/index.html">NASA launched satellites from a rocket launched from an airplane</a></li>
<li><a href="../400137/index.html">Leaf Browser Alpha - browser with tree tabs</a></li>
<li><a href="../400139/index.html">Overview of CNC laser engravers up to 1 million rubles</a></li>
<li><a href="../400143/index.html">Reported the loss of one of the satellites of the GLONASS system</a></li>
<li><a href="../400145/index.html">HIFIMAN HM901U Audio Player Review</a></li>
<li><a href="../400147/index.html">The nightmare before the new year: what you need to know about cancer</a></li>
<li><a href="../400149/index.html">Why do earthlings do buggy software and hardware</a></li>
<li><a href="../400151/index.html">NIST is asking for help in creating secure post-quantum data encryption methods</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>