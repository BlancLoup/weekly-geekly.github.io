<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Development of acoustic dataset for training neural network</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Once in an interview, one well-known Russian musician said: ‚ÄúWe are working to lie and spit at the ceiling.‚Äù I can not agree with this statement, beca...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Development of acoustic dataset for training neural network</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/webt/n9/ma/ty/n9matyv7rhr8woqlugdb6zw2dea.png"><br><br><p>  Once in an interview, one well-known Russian musician said: ‚ÄúWe are working to lie and spit at the ceiling.‚Äù  I can not agree with this statement, because the fact that it is laziness that is the driving force in the development of technology, there can be no dispute.  Indeed, over the past century alone, we have moved from steam engines to digital industrialization, and now the artificial intelligence that the science fiction writers and futurologists of the past century wrote about is becoming an increasing reality of our world every day.  Computer games, mobile devices, smart watches and more <a name="habracut"></a>  basically use algorithms associated with machine learning mechanisms. </p><br><br>  Nowadays, due to the growth of computing abilities of graphic processors and the large amount of data that has appeared, neural networks have become popular, using which they can solve classification and regression problems, teaching them using prepared data.  There are already a lot of articles already written about how to train neural networks and what frameworks to use for this.  But there is an earlier task, which also needs to be solved, and this is the task of forming an array of data - dataset, for further training of the neural network.  This will be discussed in this article. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/webt/lv/kp/om/lvkpom8mxglgptwgqorih4jz9zu.png"><br><br>  Not so long ago there was a need to build an acoustic classifier of automobile noise capable of distinguishing from a general audio data stream: broken glass, opening doors and operating a car engine in various modes.  Development of the classifier was not difficult, but where to get dataset to meet all the requirements? <br><br>  Google came to the rescue (no offense to Yandex - I‚Äôll talk about its advantages a little later), with the help of which it turned out to select several main clusters containing the necessary data.  I want to note in advance that the sources indicated in this article include a large amount of acoustic information, with various classes, allowing to form data for different tasks.  We now turn to the review of these sources. <br><br>  <a href="https://freesound.org/"><b>Freesound.org</b></a> <br><br><img src="https://habrastorage.org/webt/pf/sz/mj/pfszmjwajssor0c8nask3seztzm.png"><br><br>  Most likely, <i>Freesound.org</i> provides the largest amount of acoustic data, being a joint repository of licensed musical samples, which currently has more than 230,000 copies of sound effects.  Each sound sample can be distributed under a different license, so it is better to get acquainted with the <a href="https://freesound.org/help/faq/">license agreement in</a> advance.  For example, the license <a href="https://creativecommons.org/publicdomain/zero/1.0/">zero (cc0)</a> has the status ‚ÄúWithout copyright‚Äù, and allows you to copy, modify and distribute, including commercial use, and allows you to use the data absolutely legally. <br><br>  For the convenience of finding elements of acoustic information in a variety of freesound.org, the developers have provided an <a href="https://freesound.org/help/developers/">API</a> designed to analyze, search and download data from repositories.  To work with it you need to get access, for this you need to go to the <a href="https://freesound.org/apiv2/apply/">form</a> and fill in all the necessary fields, after which the generation of the individual key will take place. <br><br><img src="https://habrastorage.org/webt/jo/i3/qr/joi3qrdieypz8db5t8kgf0_xrfk.png"><br><br>  The developers of freesound.org provide <a href="https://freesound.org/docs/api/client_libs.html">API</a> for different programming languages, thus allowing to solve the same task with different tools.  The list of supported languages ‚Äã‚Äãand access links to them on GitHub are listed below. <br><br><img src="https://habrastorage.org/webt/m4/mw/8b/m4mw8bp6d82x-oges-p0exzynwm.png"><br><br>  Python was used to achieve this goal, since this beautiful dynamic typing programming language gained its popularity due to its ease of use, completely crossing the myth about the complexity of software development.  <a href="https://github.com/MTG/freesound-python">A module for working with freesound.org</a> for python can be cloned from the github.com repository. <br><br>  Below is the program code, which consists of two parts and demonstrates all the ease of use of this API.  The first part of the program code performs the task of data analysis, the result of which is the density of data distribution for each requested class, and the second part downloads data from the repositories of freesound.org for selected classes.  The distribution density when searching for acoustic information with the keywords <i>glass, engine, door</i> is shown below in a pie chart as an example. <br><br><img src="https://habrastorage.org/webt/uw/io/pm/uwiopmleer-snzvznuzchqsrnvc.png"><br><br>  Sample code for analyzing freesound.org data <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> plotly <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> plotly.graph_objs <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> go <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> freesound <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> os <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> termcolor <span class="hljs-comment"><span class="hljs-comment">#      def histogram(data, filename = "tmp_histogram.html"): data = [ go.Histogram( histfunc="count", x=data, name="count",textfont=dict(size=15) ), ] plotly.offline.plot({ "data": data, "layout": go.Layout(title="Histogram") }, auto_open=True, filename=filename) pass #      freesound.org def freesound_analysis(search_tokens, output, lim_page_count = 1, key = None): lim_page_count = int(lim_page_count) try: client = freesound.FreesoundClient() client.set_token(key,"token") print(termcolor.colored("Authorisation successful ", "green")) except: print(termcolor.colored("Authorisation failed ", "red")) classes = list() for token in search_tokens: try: results = client.text_search(query=token,fields="id,name,previews") output_catalog = os.path.normpath(output) if not os.path.exists(output_catalog): os.makedirs(output_catalog) page_count = int(0) while True: for sound in results: try: classes.append(token) info = "Data has been getter: " + str(sound.name) print(termcolor.colored(info, "green")) except: info = "Data has not been getter: " + str(sound.name) print(termcolor.colored(info, "red")) page_count += 1 if (not results.next) or (lim_page_count == page_count): page_count = 0 break results = results.next_page() except: print(termcolor.colored(" Search is failed ", "red")) histogram(classes) pass</span></span></code> </pre> <br>  Sample code to download freesound.org data <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#   def freesound_download(search_tokens, output, lim_page_count = 1, key = None): lim_page_count = int(lim_page_count) #  .     try: client = freesound.FreesoundClient() client.set_token(key,"token") print(termcolor.colored("Authorisation successful ", "green")) except: print(termcolor.colored("Authorisation failed ", "red")) for token in search_tokens: try: results = client.text_search(query=token,fields="id,name,previews") output_catalog = os.path.normpath(output + "\\" + str(token)) if not os.path.exists(output_catalog): os.makedirs(output_catalog) page_count = int(0) while True: for sound in results: try: sound.retrieve_preview(output_catalog) info = "Saved file: " + str(output_catalog) + str(sound.name) print(termcolor.colored(info, "green")) except: info = str("Sound can`t be saved to " + str(output_catalog) + str(sound.name) ) print(termcolor.colored(info, "red")) page_count += 1 if not results.next or lim_page_count == page_count: page_count = 0 break results = results.next_page() except: print(termcolor.colored(" Search is failed ", "red"))</span></span></code> </pre><br>  A feature of freesound is that audio data analysis can be performed without downloading an audio file, allowing you to get MFCC, spectral energy, spectral centroid and other factors.  Read more about lowlevel information in the <a href="https://freesound.org/docs/api/analysis_docs.html">freesound.ord documentation</a> . <br><br>  Using the freesound.org API, the time spent on sampling and unloading data is minimized, saving working hours on exploring other sources of information, since high accuracy of the acoustic classifier requires volume data with high variability, representing data with different harmonics on one same class of events. <br><br>  <b>YouTube-8M and AudioSet</b> <br><br><img src="https://habrastorage.org/webt/fx/pu/rn/fxpurngrhz_d2b2lvs31fuw0jei.png"><br><br>  I think that youtube is not particularly required in the submission, but still Wikipedia tells us that youtube is a video hosting site that provides video display services to users, forgetting to say that youtube is a huge database, and this source just needs to be used in machine learning and Google Inc provides us with a project called <a href="https://research.google.com/youtube8m/">YouTube-8M Dataset</a> . <br><br>  YouTube-8M Dataset is a data set that includes more than a million video files from YouTube in high quality. If you give more accurate information, then by May 2018 there were 6.1M videos with 3862 classes.  This dataset is distributed under the <a href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International (CC BY 4.0) license</a> .  This license allows you to copy and distribute material in any medium and format. <br><br>  You are probably wondering: where is the video data, when acoustic information is needed for the task, and you will be very right.  The fact is that Google provides not only video content, but also separately allocated a subproject with audio data called <a href="https://research.google.com/audioset/index.html">AudioSet</a> . <br><br><img src="https://habrastorage.org/webt/fb/de/rh/fbderhx9gvzmjbdlqfbv5mt_hsq.png"><br><br>  <a href="https://research.google.com/audioset/index.html">AudioSet</a> - provides a set of data obtained from YouTube clips, where a set of data is presented in a class hierarchy, using <a href="https://research.google.com/audioset//ontology/index.html">an ontology file</a> , its graphical representation is located below. <br><br><img src="https://habrastorage.org/webt/qw/11/r1/qw11r1lissfnhoo39wvvljheyo8.png"><br><br>  This file allows you to get an idea of ‚Äã‚Äãthe nesting of classes, as well as access to youtube videos.  To upload data from the Internet space, you can use the python module - youtube-dl, which allows you to download audio or video content, depending on the required task. <br><br>  AudioSet is a cluster divided into three sets: test, training (balanced) and training (unbalanced) <a href="https://research.google.com/audioset/download.html">datasets</a> . <br><br>  Let's consider this cluster and analyze each of the sets separately in order to have an idea of ‚Äã‚Äãthe classes contained. <br><br>  <b>Training (balanced)</b> <br><br>  According to the documentation, this dataset consists of <i>22,176 segments</i> selected from various videos selected by keywords, providing each class with at least 59 copies.  If you look at the density distribution of root classes in the hierarchy of the set, then we see that the largest group of audio files is represented by the Music class. <br><br><img src="https://habrastorage.org/webt/ke/fa/2c/kefa2c6njxd2_iy-_vp1hj4wkmq.png"><br><br>  Organized classes are decomposed into subsets of classes, making it possible to obtain more detailed information when used.  This balanced training set has a distribution density which shows that there is a balance, but also certain classes stand out from the general form. <br><br><img src="https://habrastorage.org/webt/er/zu/ba/erzuba4ghfkk9dlrsnrq7gfwlq8.png"><br><br>  The distribution of classes, the number of elements which exceeds the average value <br><br><img src="https://habrastorage.org/webt/hm/62/-l/hm62-ltqt7_e93u21qfjinyazzy.png"><br><br>  The average duration of each of the audio files is 10 seconds, a more detailed information is presented on the disk diagram, which shows that the length of the part of the files differs from the main set.  This diagram is also presented. <br><br><img src="https://habrastorage.org/webt/ow/t8/23/owt823euusbns9w2ipjebfjb1tg.png"><br><br>  Diagram of the duration of one and a half percent, other than the average, from a balanced set of audiosets <br><br><img src="https://habrastorage.org/webt/l2/4q/1n/l24q1nriwiyuec2qf7xaciwablg.png"><br><br>  <b>Training (unbalanced)</b> <br><br>  The advantage of this dataset is its size.  Just imagine that, according to the documentation, this set includes 2,042,985 segments and in comparison with a balanced dataset it represents a lot of variation, but the entropy of this set is much higher. <br><br><img src="https://habrastorage.org/webt/1q/hh/q6/1qhhq6fqowmubsrjy9czj-n_w0u.png"><br><br>  In this set, the average duration of each of the audio files is also equal to 10 seconds, the disk diagram for this dataset is presented below. <br><br><img src="https://habrastorage.org/webt/yh/co/uu/yhcouua6nv6nryg5_qu5bzsrbo0.png"><br><br>  Duration chart, other than the average, from an unbalanced audioset set <br><br><img src="https://habrastorage.org/webt/lc/ga/gw/lcgagwcbhncmnsxvjrvouvp0bvy.png"><br><br>  <b>Test set</b> <br><br>  This set is very similar to a balanced set with the advantage that the elements of these sets do not intersect.  Their distribution is presented below. <br><br><img src="https://habrastorage.org/webt/uz/ep/ek/uzepekdo_ccoh3fjevljpx7vdzg.png"><br><br>  The distribution of classes, the number of elements which exceeds the average value <br><br><img src="https://habrastorage.org/webt/y1/6b/p0/y16bp0_grna51h4tgd9_500dht8.png"><br><br>  The average duration of one segment from this dataset is also equal to 10 seconds. <br><br><img src="https://habrastorage.org/webt/wg/i-/jv/wgi-jvqyphgyblijzahtwznpvvm.png"><br><br>  and the remaining part has the duration represented on the disk diagram <br><br><img src="https://habrastorage.org/webt/lp/z9/jz/lpz9jzkcsfevakvk5rp0lwoex-8.png"><br><br>  An example of program code for analyzing and downloading acoustic data in accordance with the selected data set: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> plotly <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> plotly.graph_objs <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> go <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> collections <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Counter <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> os <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> termcolor <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> csv <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> json <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> youtube_dl <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> subprocess <span class="hljs-comment"><span class="hljs-comment">#      def histogram(data,hist_mean= True, filename = "tmp_histogram.html"): if hist_mean == True: cdata = Counter(data) mean_number_classes = np.asarray([cdata[x] for x in cdata]).mean() ldata = list() for name in cdata: if cdata[name] &gt; mean_number_classes: ldata += list(Counter({name:cdata[name]}).elements()) trace_mean_data = go.Histogram(histfunc="count", x=ldata, name="count" ) trace_data = go.Histogram(histfunc="count", x=data, name="count", text="" ) trace = [ trace_data, trace_mean_data] plotly.offline.plot({ "data": trace, "layout": go.Layout(title="stack") }, auto_open=True, filename=filename) pass #       def pie_chart(labels, values = None, filename = "tmp_pie_chart.html", textinfo = 'label+value'): if labels == None: raise Exception("Can not create pie chart, because labels is None") if values == None: data = Counter(labels) labels = list() values = list() for name in data: labels.append(name) values.append(data[name]) trace = go.Pie(labels=labels, values=values,textfont=dict(size=20),hoverinfo='label+percent', textinfo=textinfo, marker=dict(line=dict(color='#000000', width=2)) ) plotly.offline.plot([trace], filename='basic_pie_chart') pass #          def audioset_analysis(audioset_file, inputOntology): if not os.path.exists(inputOntology) or not os.path.exists(audioset_file): raise Exception("Can not found file") with open(audioset_file, 'r') as fe: csv_data = csv.reader(fe) sx = list() with open(inputOntology) as f: data = json.load(f) duration_hist = list() for row in csv_data: if row[0][0] == '#': continue classes = row[3:] try: color = "green" tmp_duration = str(float(row[2]) - float(row[1])) info = str("id: ") + str(row[0]) + str(" duration: ") + tmp_duration duration_hist.append(tmp_duration) for cl in classes: for dt in data: cl = str(cl).strip().replace('"',"") if cl == dt['id'] and len(dt['child_ids']) == 0: sx.append(dt['name']) info += str(" ")+str(dt['name']) + str(",") except: color = "red" info = "File has been pass: " + str(row[0]) continue print(termcolor.colored(info, color)) histogram(sx, filename="audioset_class") pie_chart(duration_hist, textinfo="percent + label", filename="audioset_duration")</span></span></code> </pre><br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#   youtube def youtube_download(filepath, ytid): ydl_opts = { 'format': 'bestaudio/best', 'outtmpl': os.path.normpath(filepath), 'postprocessors': [{ 'key': 'FFmpegExtractAudio', 'preferredcodec': 'wav', 'preferredquality': '192', }], } with youtube_dl.YoutubeDL(ydl_opts) as ydl: ydl.download(['https://www.youtube.com/watch?v={}'.format(ytid)]) pass #    ffmpeg def cutOfPartFile(filename,outputFile, start, end, frequency = 44100): duration = float(end) - float(start) command = 'ffmpeg -i ' command += str(filename)+" " command += " -ar " + str(frequency) command += " -ss " + str(start) command += " -t " + str(duration) + " " command += str(outputFile) subprocess.call(command,shell=True) pass #    yotube        def audioset_converter(incatalog,outcatalog, token = "*.wav", frequency = 44100): find_template = os.path.join(incatalog,token) files = glob(find_template); for file in files: _,name = os.path.split(file) name = os.path.splitext(name)[0] duration = str(name).split("_")[1:3] filename = name.split("_")[0] +"."+ token.split(".")[1]; outfile = os.path.join(outcatalog,filename) cutOfPartFile(file,outfile,start=duration[0],end=duration[1]) #    audioset def audioset_download(audioset_file, outputDataset, frequency = 44100): t,h = os.path.split(audioset_file) h = h.split(".") outputDataset_full = os.path.join(outputDataset,str(h[0])+"_full") outputDataset = os.path.join(outputDataset,str(h[0])) if not os.path.exists(outputDataset): os.makedirs(outputDataset) if not os.path.exists(outputDataset_full): os.makedirs(outputDataset_full) with open(audioset_file, 'r') as fe: csv_data = csv.reader(fe) duration_hist = list() for row in csv_data: if row[0][0] == '#': continue try: color = "green" tmp_duration = str(float(row[2]) - float(row[1])) info = str("id: ") + str(row[0]) + str(" duration: ") + tmp_duration duration_hist.append(tmp_duration) save_full_file = str(outputDataset_full) + str("//")+ str(row[0]).lstrip()+str("_") +str(row[1]).lstrip() + str("_").lstrip() + str(row[2]).lstrip() + str('.%(ext)s') youtube_download(save_full_file,row[0]) except: color = "red" info = "File has been pass: " + str(row[0]) continue print(termcolor.colored(info, color)) audioset_converter(outputDataset_full,outputDataset, frequency = frequency)</span></span></code> </pre><br>  For more detailed information on analyzing the audioset data, or downloading this data from the yotube space in accordance with the <a href="">ontology file</a> and the selected <a href="https://research.google.com/audioset/download.html">audioset set</a> , the program code is freely available in <a href="https://github.com/yurasolovjov/audio_dataset_tools">the GitHub repository</a> . <br><br>  <b><a href="https://urbansounddataset.weebly.com/">urbansound</a></b> <br><br><img src="https://habrastorage.org/webt/sq/me/ww/sqmewwpsn82lf_w5mck-5w8q_ii.png"><br><br>  Urbansound is one of the largest datasets with markup sound events whose classes belong to the urban environment.  This set was called taxonomic (categorical), i.e.  each class is divided into subclasses belonging to it.  Such a set can be represented as a tree. <br><br><img src="https://habrastorage.org/webt/tk/5l/jo/tk5ljok89na3nemguyn86yvtmtm.png"><br><br>  To upload the urbansound data for later use, simply go to the page and click <a href="https://urbansounddataset.weebly.com/download-urbansound.html">download</a> . <br><br>  Since there is no need to use all subclasses in the task, but only a single class associated with the car is needed, it is first necessary to filter the necessary classes using the meta file located in the root of the directory obtained when unzipping the downloaded file. <br><br>  After unloading all the necessary data from these sources, it turned out to form a dataset containing more than 15,000 files.  This amount of data allows you to go to the task of learning the acoustic classifier, but there remains an unresolved question regarding the ‚Äúpurity‚Äù of the data, i.e.  training set includes data not related to the necessary classes of the problem to be solved.  For example, when listening to files from the ‚Äúbroken glass‚Äù class, you can find people talking about ‚Äúhow not to beat the glass well‚Äù.  Therefore, we face the task of filtering data and as a tool for solving this kind of task, a tool is great, the core of which was developed by Belarusian guys and received the strange name ‚ÄúYandex.Toloka‚Äù. <br><br>  <b><a href="https://toloka.yandex.ru/">Yandex.Toloka</a></b> <br><br><img src="https://habrastorage.org/webt/k0/_1/1n/k0_11n7zzpfxckvcqdbqawyw25i.png"><br><br>  Yandex.Toloka is a crowdfunding project created in 2014 to mark up or collect a large amount of data for further use in machine learning.  In fact, this tool allows you to collect, mark up and filter data using a human resource.  Yes, this project not only allows you to solve problems, but also allows other people to earn.  The financial burden in this case falls on your shoulders, but due to the fact that the performers are more than 10,000 interpreters, the results of the work will be obtained in the near future.  A good description of the operation of this tool can be found in the <a href="https://habr.com/company/yandex/blog/305956/">Yandex company blog</a> . <br><br>  In general, the use of money is not particularly difficult, since for publication of the task you just need to register on the <a href="https://toloka.yandex.ru/">site</a> , the minimum amount is 10 US dollars, and a properly executed task.  How to correctly form the task you can see the <a href="https://tech.yandex.ru/toloka/doc/concepts/about-docpage/">documentation of Yandex.Tolok</a> or there is not a bad <a href="https://habr.com/company/ods/blog/358574/">article on Habr√©</a> .  From myself, I want to add to this article that even if the pattern that is suitable for the requirement of your task is missing, then its development will take no more than a few hours of work, with a break for coffee and a cigarette, and the performers can be obtained by the end of the working day. <br><br>  <b>Conclusion</b> <br><br>  In machine learning in solving the problem of classification or regression, one of the primary tasks is the development of a reliable data set - dataset.  This article examined the sources of information with a large amount of acoustic data allowing to form and balance the required data set for a specific task.  The presented program code allows you to simplify the operation of uploading data to a minimum, allowing you to reduce the time to receive data, spend the rest on the development of the classifier. <br><br>  As for my task, after collecting the data, from all the sources presented in this article and the subsequent filtering of the data, it was possible to form the necessary datasets for learning the acoustic classifier based on the neural network.  I hope that this article will allow you and your team to save time and spend it on the development of new technologies. <br><br>  <b>PS</b> A software module developed in python, for analyzing and uploading acoustic data for each of the submitted sources, you can find it in <a href="https://github.com/yurasolovjov/audio_dataset_tools">the github repository</a> </div><p>Source: <a href="https://habr.com/ru/post/427397/">https://habr.com/ru/post/427397/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../427387/index.html">Samsung has announced a new generation of display</a></li>
<li><a href="../427389/index.html">Operation Vk 2.0. A bill on news aggregators has been submitted. "Yandex.News" will be closed if the service does not change the owner</a></li>
<li><a href="../427391/index.html">Junior Tips: Build Good Habits</a></li>
<li><a href="../427393/index.html">Security analysis of corporate wireless network</a></li>
<li><a href="../427395/index.html">"Let me explain: or why a programmer needs a mathematician." A book about how not to be bored in math lectures</a></li>
<li><a href="../427399/index.html">Working with data when building an API based on GraphQL</a></li>
<li><a href="../427401/index.html">Shaders of dissolution and exploration of the world</a></li>
<li><a href="../427403/index.html">API ReportingObserver: a look at the code of web pages from a new point of view</a></li>
<li><a href="../427405/index.html">ES2018 - finally promis method</a></li>
<li><a href="../427407/index.html">Meta-clustering with error minimization, and why I think the brain works that way</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>