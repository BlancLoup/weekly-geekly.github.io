<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Antipattern testing software</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Introduction 
 There are several articles on anti-pattern software development. But most of them talk about the details at the code level and focus on...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Antipattern testing software</h1><div class="post__text post__text-html js-mediator-article"><h1>  Introduction </h1><br>  There are several articles on anti-pattern software development.  But most of them talk about the details at the code level and focus on a particular technology or programming language. <br><br>  In this article, I want to take a step back and list the high-level testing anti-patterns common to all.  I hope you learn some of them regardless of programming language. <br><br><h1>  Terminology </h1><br>  Unfortunately, testing has not yet developed a common terminology.  If you ask a hundred developers, what is the difference between the integration, end-to-end and component test, you get a hundred different answers.  For this article we confine ourselves to such a pyramid of tests: 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/b6d/7a8/3ed/b6d7a83ed09e1a8046529bebfe02836e.png"></div><br>  If you have not seen the pyramid of tests, I strongly recommend that you read it.  Here are some good articles to get you started: <br><br><ul><li>  <a href="https://www.mountaingoatsoftware.com/blog/the-forgotten-layer-of-the-test-automation-pyramid">‚ÄúThe forgotten layer of the pyramid of automatic tests‚Äù</a> (Mike Cohn, 2009) </li><li>  <a href="https://martinfowler.com/bliki/TestPyramid.html">The Pyramid of Tests</a> (Martin Fowler, 2012) </li><li>  <a href="https://testing.googleblog.com/2015/04/just-say-no-to-more-end-to-end-tests.html">‚ÄúGoogle Testing Department Blog‚Äù</a> (Google, 2015) </li><li>  <a href="https://habr.com/post/358950/">‚ÄúThe pyramid of tests in practice‚Äù</a> (Ham Focke, 2018) </li></ul><a name="habracut"></a><br>  The test pyramid itself deserves a separate discussion, especially on the number of tests required for each category.  Here I simply refer to it to define the two lowest categories of tests.  Please note that this article <i>does not</i> mention user interface tests (the top of the pyramid) - mainly for short and because they have their own specific antipatterns. <br><br>  Therefore, we define two main categories of tests: <i>modular</i> (unit tests) and <i>integration</i> tests. <br><br><table><tbody><tr><th>  Tests </th><th>  purpose </th><th>  Requires </th><th>  Speed </th><th>  Complexity </th><th>  Need setting </th></tr><tr><td>  Unit tests </td><td>  class / method </td><td>  source </td><td>  very fast </td><td>  low </td><td>  not </td></tr><tr><td>  Integration tests </td><td>  component / service </td><td>  part of the running system </td><td>  slow </td><td>  average </td><td>  Yes </td></tr></tbody></table><br>  <b>Unit tests are</b> more widely known both in name and in meaning.  These tests accompany the source code and have direct access to it.  Usually they are performed using <a href="https://en.wikipedia.org/wiki/XUnit">xUnit framework</a> or a similar library.  Unit tests work directly on the source and have a complete picture of everything.  One class / method / function (or the smallest unit of work for this particular functionality) is tested, and everything else is simulated / replaced. <br><br>  <b>Integration tests</b> (also referred to as service tests or even component tests) focus on the whole component.  This can be a set of classes / methods / functions, a module, a subsystem, or even an application itself.  They check the component by passing it input data and examining the output.  Some kind of pre-deployment or configuration is usually required.  External systems can be completely simulated or replaced (for example, using DBMS in memory instead of real), and real external dependencies are used according to the situation.  Compared to unit tests, more specialized tools are required either to prepare the test environment or to interact with it. <br><br>  The second category suffers from a blurry definition.  This is where the most disputes about the names.  The ‚Äúscope‚Äù of integration tests is also quite controversial, especially in terms of the nature of access to the application (testing in a <a href="https://en.wikipedia.org/wiki/Black-box_testing">black</a> or <a href="https://en.wikipedia.org/wiki/White-box_testing">white</a> box; whether <a href="https://en.wikipedia.org/wiki/Mock_object">mock objects are</a> allowed or not). <br><br>  The basic rule of thumb is: if the test ... <br><br><ul><li>  uses database </li><li>  uses the network to call another component / application </li><li>  uses an external system (for example, a queue or mail server), </li><li>  reads / writes files or performs other I / O operations, </li><li>  relies not on the source code, but on the application binary, </li></ul><br>  ... this is an integration test, not a unit test. <br><br>  Having dealt with the terms, you can plunge into the list of antipatterns.  Their order roughly corresponds to their prevalence.  The most frequent problems are listed at the beginning. <br><br><h1>  List of antipattern software testing </h1><br><ol><li>  <a href="https://habr.com/ru/post/358178/">Unit tests without integration</a> </li><li>  <a href="https://habr.com/ru/post/358178/">Integration tests without modular</a> </li><li>  <a href="https://habr.com/ru/post/358178/">Wrong type of tests</a> </li><li>  <a href="https://habr.com/ru/post/358178/">Testing the wrong functionality</a> </li><li>  <a href="https://habr.com/ru/post/358178/">Internal implementation testing</a> </li><li>  <a href="https://habr.com/ru/post/358178/">Excessive attention to test coverage</a> </li><li>  <a href="https://habr.com/ru/post/358178/">Unreliable or slow tests</a> </li><li>  <a href="https://habr.com/ru/post/358178/">Manual tests run</a> </li><li>  <a href="https://habr.com/ru/post/358178/">Insufficient attention to the test code</a> </li><li>  <a href="https://habr.com/ru/post/358178/">Failure to write tests for new production bugs</a> </li><li>  <a href="https://habr.com/ru/post/358178/">Attitude towards TDD as a religion</a> </li><li>  <a href="https://habr.com/ru/post/358178/">Writing tests without first reading the documentation</a> </li><li>  <a href="https://habr.com/ru/post/358178/">Bad attitude to unknowing testing</a> </li></ol><br><a name="1"></a><h1>  Antipattern 1. Modular tests without integration </h1><br>  This is a classic problem for small and medium-sized companies.  For the application, only unit tests are created (the base of the pyramid) - and nothing more.  Usually the lack of integration tests is caused by one of the following problems: <br><br><ol><li>  The company has no developers seniors.  There are only juniors who have just graduated from college.  They met only unit tests. </li><li>  At some point, integration tests existed, but they were abandoned because they caused more problems than they brought benefits.  Unit tests are much easier to maintain, so they left only them. </li><li>  The working environment of the application is too ‚Äúcomplicated‚Äù to configure.  Characteristics are ‚Äútested‚Äù in production. </li></ol><br>  I can not say anything about the first paragraph.  Each effective team should have a kind of mentor / leader who shows good practices to other developers.  The second problem is covered in detail in antipatterns <a href="https://habr.com/ru/post/358178/">5</a> , <a href="https://habr.com/ru/post/358178/">7,</a> and <a href="https://habr.com/ru/post/358178/">8</a> . <br><br>  This brings us to the final question ‚Äî the complex setup of the test environment.  Don't get me wrong, some applications are <i>really</i> hard to test.  Once I had to work with a set of REST applications that required special equipment on the host.  This equipment existed only in production, which made integration tests very difficult.  But this is an extreme case. <br><br>  For an ordinary web or server application created by a typical company, setting up a test environment should not be a problem.  With the advent of virtual machines, and recently containers, it is now easier than ever.  Basically, if you are trying to test an application that is difficult to configure, you must first correct the configuration process before you do the tests themselves. <br><br>  But why are integration tests so important at all? <br><br>  The fact is that some types of problems can <i>only</i> detect integration tests.  The canonical example is everything related to DBMS operations.  Transactions, triggers, and any stored database procedures can only be verified using integration tests that affect them.  Any connections to other modules developed by you or external teams require integration tests (they are also contract tests).  Any tests to check performance are integration tests by definition.  Here is a brief overview of why we need integration tests: <br><br><table><tbody><tr><th>  Type of problem </th><th>  Determined by unit tests </th><th>  Determined by integration tests </th></tr><tr><td>  Basic business logic </td><td>  Yes </td><td>  Yes </td></tr><tr><td>  Component Integration Problems </td><td>  not </td><td>  Yes </td></tr><tr><td>  Transactions </td><td>  not </td><td>  Yes </td></tr><tr><td>  Triggers / OBD procedures </td><td>  not </td><td>  Yes </td></tr><tr><td>  Incorrect contracts with other modules / API </td><td>  not </td><td>  Yes </td></tr><tr><td>  Wrong contracts with other systems </td><td>  not </td><td>  Yes </td></tr><tr><td>  Performance / Timeouts </td><td>  not </td><td>  Yes </td></tr><tr><td>  Reciprocal / self-locking </td><td>  possibly </td><td>  Yes </td></tr><tr><td>  Cross Security Issues </td><td>  not </td><td>  Yes </td></tr></tbody></table><br>  Typically, any cross-application problem requires integration tests.  Taking into account the current insanity in microservices, integration tests become even more important as you now have contracts between your own services.  If these services are developed by other groups, you must automatically check if the interface contracts are not violated.  This can be covered only by integration tests. <br><br>  To summarize, if you do not create something extremely isolated (for example, the Linux command line utility), then you really <b>need</b> integration tests to find problems not found by unit tests. <br><br><a name="2"></a><h1>  Antipattern 2. Integration tests without modular </h1><br>  This is the opposite of the previous anti-pattern.  It is more common in large companies and large corporate projects.  Almost always, this situation is associated with developers who believe that unit tests have no real value, and only integration tests can catch regressions.  Many experienced developers consider unit tests to be a waste of time.  Usually, if you ask them, it turns out that sometime in the past, managers demanded an increase in code coverage with tests (see <a href="https://habr.com/ru/post/358178/">antipattern 6</a> ) and forced them to write trivial unit tests. <br><br>  Indeed, theoretically, only integration tests <i>can</i> be in the project.  But in practice, such testing is very expensive (in terms of both development and assembly).  In the table from the previous section, we saw that integration tests can also find business logic errors and therefore are capable of ‚Äúreplacing‚Äù unit tests.  But is such a strategy viable in the long run? <br><br><h3>  Integration tests are complex </h3><br>  Consider an example.  Suppose we have a service with four such methods / classes / functions. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/602/de3/040/602de3040a2fc48bb331d4e658ba540e.png"></div><br>  The number on each module denotes its <a href="https://en.wikipedia.org/wiki/Cyclomatic_complexity">cyclomatic complexity,</a> that is, the number of linearly independent routes through this part of the program code. <br><br>  Developer Mary is acting on a textbook and wants to write unit tests for this service (because she understands the importance of unit tests).  How many tests do you need to write to fully cover all possible scenarios? <br><br>  Obviously, you can write 2 + 5 + 3 + 2 = 12 isolated unit tests that fully cover the <b>business logic of</b> these modules.  Remember that this number is only for one service, and the application Mary is working on has several services. <br><br>  Developer Joe "Growler" does not believe in the value of unit tests.  He believes that this is a waste of time, and decides to write only integration tests for this module.  How many?  He begins to look at all possible routes through all parts of the service. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/bbb/4c9/d1b/bbb4c9d1b5fe12b0bc838b54209e1608.png"><br><br>  Again, it should be obvious that 2 * 5 * 3 * 2 = 60 code routes are possible.  Does this mean Joe will actually write 60 integration tests?  Of course not!  He will be cunning.  First, try to select a subset of integration tests that seem to be ‚Äúrepresentative‚Äù.  This ‚Äúrepresentative‚Äù subset will provide sufficient coverage with minimal effort. <br><br>  In theory, everything is simple, but in practice a problem will quickly arise.  In reality, these 60 scenarios are not created equally.  Some of them are borderline cases.  For example, module C runs through three code routes.  One of them is a very special case.  It can only be recreated if C receives specific input data from component B, which itself is a border case and can only be obtained with special input data from component A. So this particular scenario may require a very complex setup to select input data that will cause special condition on component C. <br><br>  On the other hand, Mary will simply recreate the border case with a simple unit test without additional complexity. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/13a/339/0e0/13a3390e06302b257fdce580943044db.png"></div><br>  So Mary will <i>only</i> write unit tests?  In the end, it will lead her to the <a href="https://habr.com/ru/post/358178/">anti-pattern 1</a> .  To avoid this, she will write both unit and integration tests.  Save all unit tests for real business logic, and then write one or two integration tests to verify that the rest of the system works properly (that is, parts that help these modules do their work). <br><br>  Integration tests should focus on the remaining components.  The business logic can be handled by unit tests.  Mary's integration tests will focus on serialization / deserialization, communication with the queue and the database system. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/437/408/d61/437408d6106e7decd4c4d542e1358947.png"></div><br>  As a result, the number of integration tests is significantly less than the number of unit tests, which corresponds to the form of a pyramid of tests from the first section of this article. <br><br><h3>  Integration tests slow </h3><br>  The second big problem with integration tests is their speed.  As a rule, an integration test is performed an order of magnitude slower than a unit test.  The unit test only needs the source code of the application and nothing else.  They are almost always limited by CPU load.  On the other hand, integration tests can perform I / O operations with external systems, so that they are much more difficult to optimize. <br><br>  To get an idea of ‚Äã‚Äãthe time difference, suppose the following numbers. <br><br><ul><li>  Each unit test takes 60 ms (on average). </li><li>  Each integration test takes 800 ms (on average). </li><li>  In the application 40 services, as shown in the previous section. </li><li>  Mary writes 10 unit tests and 2 integration tests for each service. </li><li>  Joe writes 12 integration tests for each service. </li></ul><br>  Now we will count.  Please note that Joe allegedly found the perfect subset of integration tests that give the same code coverage that Mary has (in reality it will not be like this). <br><br><table><tbody><tr><th>  lead time </th><th>  Having only integration tests (Joe) </th><th>  Having unit tests and integration tests (Mary) </th></tr><tr><td>  Only unit tests </td><td>  N / A </td><td>  24 seconds </td></tr><tr><td>  Only integration tests </td><td>  6.4 minutes </td><td>  64 seconds </td></tr><tr><td>  All tests </td><td>  6.4 minutes </td><td>  1.4 minutes </td></tr></tbody></table><br>  The difference in total work time is huge.  Waiting for one minute after each code change is significantly different from waiting for the whole six minutes.  And the 800 ms assumption for each integration test is extremely conservative.  I saw integration test sets where one test takes a few minutes. <br><br>  To summarize, an attempt to use <i>only</i> integration tests to cover business logic is a huge waste of time.  Even if you automate tests using CI, the feedback loop (from commit to getting the test result) is still very long. <br><br><h3>  Integration tests are harder to debug than unit tests </h3><br>  The last reason why it is not recommended to limit itself to integration tests only (without modular ones) is the amount of time to debug a failed test.  Since an integration test by definition tests several software components, a failure can be caused by <i>any</i> of the tested components.  Identifying the problem is the more difficult the more components are involved. <br><br>  If the integration test fails, you must understand the cause of the failure and how to fix it.  The complexity and scope of integration tests make them extremely difficult to debug.  Again, as an example, assume that only integration tests have been made for your application.  Let's say this is a typical online store. <br><br>  Your colleague (or you) sends a new commit that initiates the launch of integration tests with the following result: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/05c/aac/a5a/05caaca5a8b0a49df7d2ac518debca0a.png"></div><br>  As a developer, you look at the result and see that the integration test with the name ‚ÄúCustomer buys goods‚Äù does not pass.  In the context of an online store application, this is not very good.  There are many reasons why this test may not pass. <br><br>  It is impossible to find out the reason for the failure of the test without plunging into the logs and metrics of the test environment (assuming that they will help determine the exact problem).  In some cases (and more complex applications), the only way to genuinely debug an integration test is to extract the code, recreate the test environment on the local machine, and then run the integration tests and attempt to reproduce the failure in the local development environment. <br><br>  Now imagine that you are working with Mary on this application, so you have both integration and unit tests.  Your colleagues send commits, you run all the tests and get the following: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/400/fc3/00b/400fc300b1da49041a2248faf37796b4.png"></div><br>  Now two tests failed: <br><br><ul><li>  "Customer buys goods" does not pass as before (integration test). </li><li>  The ‚Äúspecial discount test‚Äù also fails (unit test). </li></ul><br>  Now it is very easy to understand where to look for the problem.  You can go directly to the source code of the discount functionality, find the error and correct it - and in 99% of cases the integration test will also be debugged. <br><br>  Failure of a unit test <i>before or</i> with the integration process is a much more painless process when you need to find an error. <br><br><h3>  Summary of why unit tests are needed </h3><br>  This was the longest section of this article, but I think it is very important.  To summarize: although <i>theoretically</i> you can only use integration tests, <i>in practice</i> <br><br><ol><li>  Unit tests are easier to maintain. </li><li>  Unit tests easily reproduce borderline cases and rare situations. </li><li>  Unit tests are performed much faster than integration tests. </li><li>  Failed unit tests are easier to fix than integration ones. </li></ol><br>  If you have only integration tests, then you are wasting both development time and company money.  We need both modular and integration tests at the same time.  They are not mutually exclusive.  There are several articles online that promote the use of only one type of test.  All of these articles spread misinformation.  Sad but true. <br><br><a name="3"></a><h1>  Antipattern 3. Wrong type of tests </h1><br>  Now we understand why we need both types of tests (modular <i>and</i> integration).  You need to decide <i>how many</i> tests you need in each category. <br><br>  There is no firm and clear rule.  It all depends on your application.  It is important to understand that you have to spend some time to understand which type of test is more valuable for <i>your</i> application.  The test pyramid is just an assumption about the number of tests.  It assumes that you are writing a commercial web application, but this is not always the case.  Consider a few examples: <br><br><h3>  Example: Linux Command Line Utility </h3><br>  Your application is a command line utility.  It takes files of one format (for example, CSV), performs some transformations and exports to another format (for example, JSON).  The application is autonomous, does not communicate with any other systems and does not use the network.  Transformations are complex mathematical processes that are crucial for the application to work properly (they must always be executed correctly, regardless of the speed of the work). <br><br>  What you need for this example: <br><br><ul><li>  Many unit tests for mathematical calculations. </li><li>  Some integration tests for reading CSV and writing JSON. </li><li>  No GUI tests, because the GUI is missing. </li></ul><br>  Here is the ‚Äúpyramid‚Äù of tests for such a project: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/b80/9f9/da5/b809f9da545bbc8189f1466f6cf92f72.png"></div><br>  Unit tests dominate here, and the resulting form is <b>not</b> a pyramid. <br><br><h3>  Example: Payment Management </h3><br>  You add a new application that will be embedded in a large collection of existing enterprise systems.  The application is a payment gateway that processes payment information for an external system.  This new application should keep a log of all transactions in an external database, it should communicate with external payment providers (Paypal, Stripe, WorldPay, etc.), as well as send payment data to another system that bills. <br><br>  What you need for this example: <br><br><ul><li>  Almost no unit tests, because there is no business logic. </li><li>  Many integration tests for external communications, database storage, billing system. </li><li>  No GUI tests, because the GUI is missing. </li></ul><br>  Here is the ‚Äúpyramid‚Äù of tests for such a project: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/214/a3c/775/214a3c775fc47a82731b806731d7e558.png"></div><br>  Integration tests dominate here, and the resulting form is again <b>not</b> a pyramid. <br><br><h3>  Example: Website Builder </h3><br>  You are working on a completely new startup that has developed a revolutionary way to create websites: the one-of-a-kind web application designer in the browser. <br><br>  The application is a graphic designer with a set of all possible HTML elements that can be added to a web page, and a library of ready-made templates.  There is the possibility of buying new templates on the market.  The designer is very user-friendly, allows you to drag and drop components onto the page, resize them, edit properties, change colors and appearance. <br><br>  What is needed for this contrived example: <br><br><ul><li>  Almost no unit tests, because there is no business logic. </li><li>  Several integration tests for market interaction. </li><li>  A lot of GUI tests to make sure that the GUI is working properly. </li></ul><br>  Here is the ‚Äúpyramid‚Äù of tests for such a project: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/443/655/895/44365589580fb8428873e47100cab4f0.png"></div><br>  UI tests dominate here, and the resulting shape is again <b>not</b> a pyramid. <br><br>  These extreme situations show that different applications require a different combination of tests.  I personally saw payment management applications without integration tests, as well as website designers without UI tests. <br><br>  On the Internet, you can find articles (I'm not going to refer to them), which call the specific ratio of integration tests, unit tests and UI tests.  All of these articles are based on assumptions that may <i>not fit</i> your project. <br><br><a name="4"></a><h1>  Antipattern 4. Testing the wrong functionality </h1><br>  In the previous sections, we described the types and number of tests required for your application.  The next logical step is to explain what kind of functionality you need to test. <br><br>  Theoretically, the ultimate goal is to cover 100% of the code.  In practice, this goal is difficult to achieve and it does not guarantee the absence of bugs. <br><br>  In some cases it is really possible to test <i>all the</i> functionality of the application.  If you start a project from scratch and work in a small team that works correctly and takes into account the effort required for the tests, then it is perfectly normal to cover all the added functionality with tests (because there are already tests for the existing code). <br><br>  But not all developers are so lucky.  In most cases, you inherit an existing application with a minimum number of tests (or without them at all!).  If you work in a large and well-established company, then working with legacy code is more a rule rather than an exception. <br><br>  Ideally, you will be given enough time to write tests for both new and existing legacy code.  This romantic idea is likely to be rejected by the project manager, who is more interested in adding new features than in testing / refactoring.  We'll have to prioritize and find a balance between adding new functionality (at the request of the authorities) and expanding the existing set of tests. <br><br>  So what exactly will we test?  What to focus on?  Several times I have seen how developers spend valuable time writing unit tests that have little or no value for the overall stability of the application.  The canonical example of useless testing is trivial tests that test the application's data model. <br><br>  Code coverage is analyzed in detail in a separate <a href="https://habr.com/ru/post/358178/">anti-pattern</a> .  In the same section we will talk about the ‚Äúimportance‚Äù of the code and how it relates to tests. <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> If you ask any developer to show the source of any application, then he will probably open the IDE or code repository in the browser and show the individual folders. </font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/0f5/43d/f93/0f543df93fff02f3ad1db75d392ec7d2.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">This is the physical code model. </font><font style="vertical-align: inherit;">It shows the folders in the file system containing the source code. </font><font style="vertical-align: inherit;">Although this hierarchy is great for working with the code itself, unfortunately, it does not show importance. </font><font style="vertical-align: inherit;">A flat list of folders implies that all the code components they contain have the same value. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">This is not the case, since the various components of the code have a different impact on the overall functionality of the application. </font><font style="vertical-align: inherit;">As a brief example, suppose you are writing an online store application and two errors occurred during production:</font></font><br><br><ol><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Customers can not pay for goods from the cart, which stopped all sales. </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Customers receive incorrect recommendations when viewing products. </font></font></li></ol><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Although both errors are corrected, the first one is clearly of higher priority. </font><font style="vertical-align: inherit;">Therefore, if you got an online store application without any tests at all, you should write new tests that directly check the functionality of the cart, and not the recommendation engine. </font><font style="vertical-align: inherit;">Despite the fact that the recommendation mechanism and the basket may be located in the same level folders in the file system, they are of different importance when tested. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">If we generalize, then in any medium / large application, sooner or later, the developer will have a different representation of the code - the mental model.</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/caa/e24/2b0/caae242b0182a0e36ab614260019cb38.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Three layers of code are shown here, but depending on the size of the application there may be more. </font></font> It: <br><br><ol><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Critical code - a code with frequent failures, where most of the new functions are introduced and which is important to users. </font></font></li><li>     ,         . </li><li>     ,         . </li></ol><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">This mental model should be kept in mind whenever you write a new software test. Ask yourself if the functionality for which you are writing tests refers to </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">critical</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> or </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">basic</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> code. If so, write a test. If not, then maybe it makes sense to spend time on something else (for example, on another bug). </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The concept of code importance also helps to answer the eternal question: what kind of code coverage is enough for an application? To answer, you need to either know the importance levels of the application code, or ask someone who knows. When you have this information, the answer is obvious: try writing tests that cover 100% of the </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">critical code</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . If you have already done this, then try to write tests covering 100%</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">main code</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">However, it is </font></font><a href="https://habr.com/ru/post/358178/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">not recommended</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> to try to cover with tests 100% of the total code. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">It is important to note that the critical code is always only a small subset of the total. </font><font style="vertical-align: inherit;">Thus, if the critical code is, say, 20% of the total, then covering tests with 20% of the total code is already a good first step for reducing the number of bugs in production. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In general, write unit and integration tests for code that:</font></font><br><br><ul><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> often breaks </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> often changes </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> critical for business </font></font></li></ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> If there is time for further expansion of the test suite, then make sure that you are aware of a decrease in the effect of them before spending time on tests with little or no importance. </font></font><br><br><a name="5"></a><h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Antipattern 5. Testing internal implementation </font></font></h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">More tests are always good. </font><font style="vertical-align: inherit;">Right? </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wrong! </font><font style="vertical-align: inherit;">You also need to make sure that the tests are actually well structured. </font><font style="vertical-align: inherit;">The presence of incorrectly written tests causes double damage:</font></font><br><br><ul><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> First, they spend precious developer time while writing. </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Then they spend even more time when they have to redo them (when adding a new function). </font></font></li></ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Strictly speaking, the </font></font><a href="https://habr.com/ru/post/358178/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">test code is similar to any other code</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . At some point, refactoring will be required to gradually improve it. But if you regularly change existing tests when adding new features, then </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">your tests do not test what they should</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">I have seen companies launch new projects and think that this time they will do everything right - they are starting to write a </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">lot of</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> tests to cover all the functionality. After some time, add a new function, but for it you need to change a few existing tests. Then add another function and update </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">even more</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> tests. Soon, the amount of effort to refactor / correct existing tests actually exceeds the time required to implement the function itself.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In such situations, some developers just give up. They declare that tests are a waste of time, and abandon the existing set of tests in order to fully focus on new features. In some exceptional cases, even releases are delayed due to the failure of the tests. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Of course, there is a problem in the poor quality of the tests. If they constantly need refactoring, then there is too close connection with the main code. Unfortunately, to identify such "incorrectly" written tests requires some experience. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Changing a large number of existing tests when a new function appears is only a </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">symptom</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. The real problem is that tests check the internal implementation, and this is always a disaster scenario. In several manuals on software testing, an attempt is made to explain this concept, but very few people demonstrate it with clear examples. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">At the beginning of the article I promised that I would not talk about a specific programming language, and I would keep the promise. Here the illustrations show the data structure of your favorite language. Think of them as structures / objects / classes that contain fields / values. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Suppose a Customer object in an online store application looks like this:</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/fc6/5e9/9ce/fc65e99ce172fc46d53e1cb3606624d1.png"></div><br>  The Customer type takes only two values, where <code>0</code> means ‚Äúguest‚Äù and <code>1</code> means ‚Äúregistered user‚Äù.  The developers look at the object and write ten unit tests to check the ‚Äúguests‚Äù and ten for the ‚Äúregistered users‚Äù.  And when I say ‚Äúfor verification‚Äù, I mean that tests <b>check this particular field in this particular object</b> . <br><br>  Time passes, and managers decide that the branch office needs a new type of user with a value of <code>2</code> .  Developers add ten more tests for affiliates.  Finally, another type of user called ‚Äúpremium customer" has been added - and the developers add ten more tests. <br><br>  At the moment we have 40 tests in four categories, and they all check these specific fields.  (The numbers are fictional, the example is only for demonstration. In a real project there can be ten interrelated fields in six nested objects and 200 tests). <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e95/22b/74b/e9522b74b6a0fb787113ea9320714a4e.png"><br><br>  If you are an experienced developer, you can imagine further developments.  New requirements come: <br><br><ol><li>  Registered users need to save more email. </li><li>  For users in branches, you need to save the company name. </li><li>  Premium users are now awarded bonus points. </li></ol><br>  The client object is modified as follows: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/bf8/cc4/ba0/bf8cc4ba08d7215347db90eed31c95af.png"><br><br>  Now we have four objects associated with foreign keys, and all 40 tests immediately break down, because the field they are verifying no longer exists. <br><br>  <i>Of course, in this trivial example, you can simply keep the existing field, so as not to violate the backward compatibility with tests.</i>  In a real application, this is not always possible.  Sometimes backward compatibility essentially means that you need to keep both the old and the new code (before / after the new function), which will greatly inflate it.  Also note that saving the old code just for the sake of unit tests is in itself an obvious anti-pattern. <br><br>  When this happens in a real situation, developers ask for extra time to fix the tests.  Then project managers say that unit tests are a waste of time because they interfere with the introduction of new functionality.  Then the whole team refuses the test suite, quickly disabling failed tests. <br><br>  Here the main problem is not testing, but as tests.  Instead of the internal implementation, the expected behavior should be tested.  In our simple example, instead of testing directly the internal structure of an object, you need to check the exact business requirement in each case.  Here's how to implement the same tests: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/5da/bc4/973/5dabc4973e6aa23927cfad59a5d4e56d.png"><br><br>  Here, tests do not check the internal structure of the object at all.  They check only its interaction with other objects / methods / functions.  If necessary, other objects / methods / functions should be simulated.  Please note that each type of test directly corresponds to a specific business requirement, not a technical implementation (which is always a good practice). <br><br>  When the internal implementation of an object changes, the test verification code remains the same.  Only the configuration code for each test can be changed, which should be centrally stored in one auxiliary function <code>createSampleCustomer()</code> or something similar (for more details, see <a href="https://habr.com/ru/post/358178/">antipattern 9</a> ). <br><br>  Of course, theoretically the verified objects themselves can change.  In practice, the <b>simultaneous</b> change of <code>loginAsGuest()</code> , <code>register()</code> , <code>showAffiliateSales()</code> and <code>getPremiumDiscount()</code> .  In a realistic scenario, you will need to refactor ten tests instead of forty. <br><br>  To summarize, if you constantly fix existing tests as new features are added, this means that your tests are closely related to the internal implementation. <br><br><a name="6"></a><h1>  Antipattern 6. Excessive attention to test coverage </h1><br>  Code coverage is the industry‚Äôs favorite metric.  There <a href="https://softwareengineering.stackexchange.com/questions/1380/how-much-code-coverage-is-enough">are</a> <a href="https://martinfowler.com/bliki/TestCoverage.html">endless</a> <a href="https://testing.googleblog.com/2010/07/code-coverage-goal-80-and-no-less.html">discussions</a> between developers and project managers about the necessary code coverage of tests. <br><br>  Everyone loves to talk about coverage, because it is an understandable, easily measurable indicator.  Most programming languages ‚Äã‚Äãand testing frameworks have simple tools for displaying it. <br><br>  <i>Let me give you a little secret</i> : code coverage is a completely useless metric.  There is no ‚Äúright‚Äù indicator.  This is a trap question.  You may have a project with 100% coverage of the code, which still has bugs and problems.  In reality, you need to keep track of other metrics - the well-known indicators CTM (Codepipes Testing Metrics). <br><br><a name="14"></a><h3>  CTM metrics </h3><br>  Here is the definition of CTM, if you are not familiar with them: <br><br><table><tbody><tr><th>  Metric name </th><th>  Description </th><th>  Perfect value </th><th>  Normal value </th><th>  Problem value </th></tr><tr><td>  PDWT </td><td>  Percentage of developers writing tests </td><td>  100% </td><td>  20% -70% </td><td>  Any less than 100% </td></tr><tr><td>  PBCNT </td><td>  The percentage of bugs leading to the creation of new tests </td><td>  100% </td><td>  0% -5% </td><td>  Any less than 100% </td></tr><tr><td>  PTVB </td><td>  Percentage of tests checking behavior </td><td>  100% </td><td>  ten% </td><td>  Any less than 100% </td></tr><tr><td>  PTD </td><td>  The percentage of deterministic tests </td><td>  100% </td><td>  50% -80% </td><td>  Any less than 100% </td></tr></tbody></table><br>  <b>PDWT</b> (percentage of developers writing tests) is probably the most important indicator.  It makes no sense to talk about software testing anti-patterns if you don‚Äôt have tests at all.  All developers in a team must write tests.  Any new function can be declared <i>made</i> only if it is accompanied by one or several tests. <br><br>  <b>PBCNT</b> (percentage of bugs leading to the creation of new tests).  Each production bug is a great reason to write a new test that checks the corresponding fix.  Any bug should appear in production no more than once.  If your project suffers from the appearance of repeated bugs even after their initial ‚Äúcorrection‚Äù, the team will really benefit from the use of this metric.  For more on this, see the <a href="https://habr.com/ru/post/358178/">anti-pattern 10</a> . <br><br>  <b>PTVB</b> (percentage of tests that test behavior, not implementation).  Closely related tests devour a lot of time when refactoring the underlying code.  This topic has already been discussed in the <a href="https://habr.com/ru/post/358178/">anti-pattern 5</a> . <br><br>  <b>PTD</b> (percentage of deterministic tests of the total).  Tests should fail only if something is wrong with the business code.  If tests periodically break for no apparent reason, this is a huge problem that is discussed in the <a href="https://habr.com/ru/post/358178/">anti-pattern 7</a> . <br><br>  If after reading about the metrics you still insist on setting a hard indicator to cover the code, I will give you the number <b>20%</b> .  This number should be used as a rule of thumb based on <a href="https://en.wikipedia.org/wiki/Pareto_principle">Pareto law</a> .  20% of your code causes 80% of your errors, so if you really want to start writing tests, it will be good to start first with this code.  The board also agrees well with the <a href="https://habr.com/ru/post/358178/">antipattern 4</a> , where I suggest writing tests for critical code first. <br><br>  <i>Do not</i> try to achieve 100% total coverage.  It sounds good in theory, but it is almost always a waste of time: <br><br><ul><li>  you are wasting your energy, because the transition from 80% to 100% is much more difficult than from 0% to 20%; </li><li>  an increase in code coverage leads to a decrease in recoil. </li></ul><br>  In any non-trivial application there are certain scenarios that require complex unit tests to run.  The effort required to write such tests usually outweighs the risk that these scenarios are implemented in production (if it ever happens at all). <br><br>  If you have worked with any large application, you should know that after reaching 70% or 80% of the coverage it becomes very difficult to write useful tests for the rest of the code. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/1ff/e89/de5/1ffe89de5a51a0eb9a38c1cfcd22ce36.png"><br><br>  As we have already seen in the description of the anti-pattern <a href="https://habr.com/ru/post/358178/">4</a> , some code routes in reality never fail in production, so it‚Äôs not recommended to write tests for them.  It is better to spend time implementing the actual functionality. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/bb1/f8d/6f8/bb1f8d6f84467e4c599737082bb0c34b.jpg"><br><br>  If for a project there is a condition of a certain percentage of code coverage by tests, then developers are usually forced to test trivial code or write tests that simply check the basic programming language.  This is a huge waste of time, and as a developer you are obliged to complain to management about such unreasonable demands. <br><br>  To summarize, code coverage with tests <b>cannot be</b> used as an indicator of the quality of a software project. <br><br><a name="7"></a><h1>  Antipattern 7. Unreliable or slow tests </h1><br>  Specifically, this anti-pattern <a href="https://martinfowler.com/articles/nonDeterminism.html">has already been</a> <a href="https://testing.googleblog.com/2016/05/flaky-tests-at-google-and-how-we.html">repeatedly</a> <a href="https://semaphoreci.com/community/tutorials/how-to-deal-with-and-eliminate-flaky-tests">discussed</a> <a href="https://testing.googleblog.com/2017/04/where-do-our-flaky-tests-come-from.html">in detail</a> , so I will only add. <br><br>  Since software tests are an early indicator of regressions, they must always work reliably.  Failure of the test should be a cause of concern, and those responsible for the corresponding build should start checking why the test failed. <br><br>  This approach only works with tests that fall in a deterministic way.  If the test sometimes fails and sometimes passes (without any code changes between checks), then it is unreliable and discredits all testing.  It causes double damage: <br><br><ul><li>  Developers no longer trust tests and begin to ignore them. </li><li>  Even normal test failures become difficult to detect in a sea of ‚Äã‚Äãnon-deterministic results. </li></ul><br>  A failed test should be clearly informed to all team members, since it changes the status of the entire assembly.  On the other hand, in the presence of unreliable tests it is difficult to understand whether new failures occur, or whether it is the result of old unreliable tests. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/051/985/737/0519857378670d33a80cf9f1308f9561.png"></div><br>  Even a small number of unreliable tests are enough to destroy trust in others.  For example, you have five unreliable tests, you drove a new build through tests and got three crashes.  It is not clear, everything is in order or you have three regressions. <br><br>  A similar problem with very slow tests.  Developers need fast feedback on the results of each commit (this is also discussed in the next section), so slow tests will eventually be ignored or not started at all. <br><br>  In practice, unreliable and slow tests are almost always integration and / or user interface tests.  As we climb the pyramid of tests, the likelihood of unreliable tests increases significantly.  It is known that if a test handles browser events, then it is difficult to make it deterministic.  Sources of unreliability can be many factors, but the test environment and its requirements are usually to blame. <br><br>  The main protection against unreliable and slow tests is to isolate them in a separate test suite (provided they are incorrigible).  There are many resources on the Internet on how to fix such tests in any programming language, so it makes no sense to explain it here. <br><br>  To summarize, you should have an absolutely reliable test suite, let it be just a subset of the entire test suite.  If the test from this set fails, then the problem is definitely with the code.  Any failure of such a test means that the code should not be allowed into production. <br><br><a name="8"></a><h1>  Antipattern 8. Run tests manually </h1><br>  Different organizations use different types of tests.  Unit tests, load tests, user acceptance tests (UAT) are typical categories of test sets that <i>can be</i> performed before releasing code into production. <br><br>  Ideally, all tests are performed automatically without human intervention.  If this is not possible, then at least tests that verify the correctness of the code (ie, unit and integration tests) <b>should be</b> performed automatically.  Thus, developers get feedback on the code as quickly as possible.  The function is very easy to fix when the code is fresh in your head and you have not yet switched the context to another function. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/be4/711/1aa/be47111aa5e567086b76646d5ceaa64a.png"></div><br>  Previously, the longest stage of the software life cycle was application deployment.  In the cloud, machines are created on request (in the form of VMs or containers), so that the preparation time for a new machine is reduced to a few minutes or seconds.  Such a paradigm shift was taken by surprise by many companies that were not ready for such frequent cycles.  Most existing practices focus on long release cycles.  Expecting a specific release time with a manual ‚Äúgo-ahead‚Äù is one of the outdated practices that should be abandoned if the company is committed to fast deployments. <br><br>  Rapid deployment implies trust in each deployment.  The credibility of automatic deployment requires a high degree of confidence in the code.  Although there are several ways to gain this confidence, the first line of defense is your software tests.  However, having a test suite with a quick regression search is only half the battle.  The second prerequisite is the <i>automatic</i> execution of tests (possibly, after each commit). <br><br>  Many companies <i>think</i> that they have implemented continuous delivery and / or deployment.  In fact, it is not.  Practicing true CI / CD means that <i>at any given time</i> there is a version of the code that is ready for deployment.  This means that the release candidate <i>has already been</i> tested.  Therefore, the presence of a ‚Äúready-made‚Äù package that has not yet received the go-ahead is not a real CI / CD. <br><br>  Most companies realized that human participation causes errors and delays, but there are still companies that run tests is a semi-automatic process.  By ‚Äúsemi-automatic‚Äù is meant that the test suite itself can be automated, but people perform some maintenance tasks, such as preparing the test environment or clearing the test data to complete the tests.  This is an anti-pattern, because it is not real automation.  <b>All</b> aspects of testing should be automated. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/60d/253/086/60d253086b1a9122d9424712f4514db6.png"></div><br>  Having access to virtual machines or containers, it is very easy to create various test environments on demand.  Creating a test environment on the fly for each request should become standard practice in your organization.  This means that each new function is tested separately.  The problem component (i.e., the failing test) must not block the rest. <br><br>  A simple way to understand the level of test automation in a company is to observe the routine work of QA / testing staff.  In the ideal case, testers simply create new tests that are added to the existing set.  They do not start them manually.  The test suite is executed by the build server. <br><br>  To summarize, testing should always happen behind the scenes.  Developers will recognize the test result for their particular function 5‚Äì15 minutes after the commit.  Testers create new tests and refactor existing tests, but do not run them manually. <br><br><a name="9"></a><h1>  Antipattern 9. Insufficient attention to the test code </h1><br>  An experienced developer will always first spend some time organizing the code in his mind before starting to write.  Regarding the design of the code there are several principles, and some of them are so important that even separate articles on Wikipedia are devoted to them.  Here are some examples: <br><br><ul><li>  <a href="https://en.wikipedia.org/wiki/Don%2527t_repeat_yourself">DRY</a> </li><li>  <a href="https://en.wikipedia.org/wiki/KISS_principle">Kiss</a> </li><li>  <a href="https://en.wikipedia.org/wiki/SOLID_(object-oriented_design)">SOLID</a> </li></ul><br>  Perhaps the first principle is the most important because it forces the code to establish the only source of truth that is reused in several functions.  Depending on the programming language, you can also use some other recommendations and design patterns.  There may be separate recommendations adopted specifically in your team. <br><br>  However, for some unknown reason, some developers do not apply the same principles to the software test code.  I have seen projects where the function code is perfectly designed, but the test code suffers from huge amounts of duplication, hard-coded variables, copy-paste fragments and other errors that would be considered unforgivable in the main code. <br><br>  It does not make sense to consider the test code as second-rate, because in the long term, all the code must be serviced.  In the future, tests will have to be updated and reworked.  Their variables and structure will change.  If you write tests without thinking about their design, then you create additional technical debt, which will be added to the already existing one in the main code. <br><br>  Try writing tests with the same attention you pay to the component code.  Here you need to use all the same refactoring techniques.  To start: <br><br><ul><li>  All test code must be centralized.  In the same way, all tests should produce test data. </li><li>  Complex verification segments should be extracted into a common library for this area. </li><li>  Frequently used imitations and emulations should not be copied with copy-paste. </li><li>  Test initialization code should be common to similar tests. </li></ul><br>  If you use static analysis tools, source code formatting or code quality, configure them to handle test code, too. <br><br>  To summarize, develop tests as thoroughly as the main component code. <br><br><a name="10"></a><h1>  Antipattern 10. Failure to write tests for new production bugs </h1><br>  One of the tasks of testing is to find regressions.  As we saw in the <a href="https://habr.com/ru/post/358178/">anti-pattern 4</a> , most applications have a ‚Äúcritical‚Äù part of the code where most bugs appear.  When you correct an error, you need to make sure that it does not happen again.  One of the best ways to guarantee this is to write a test for correction (either a unit test, or an integration test, or both). <br><br>  Errors that leak into production are ideal candidates for writing tests: <br><br><ul><li>  they show a lack of testing in this area, since the bug has already hit production; </li><li>  if you write a test for this error, it will protect future releases as well. </li></ul><br>  I am always amazed when development teams (even with a solid testing strategy) do not write a test for an error found <i>in production</i> .  They correct the code and immediately correct the error.  For some strange reason, many developers assume that writing tests only matters when adding a new function. <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">It is difficult to imagine something farther from the truth. I would even say that tests that derive from real errors are more valuable than tests that are added as part of a new development. In the end, you never know how often a new function will fail in production (perhaps it belongs to non-critical code that will never fail). The corresponding test is good, but its value is questionable. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">But the test that you write for a real error is very valuable. It not only checks the correctness of the correction, but also ensures that it will always work, even after refactoring in this area.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">If you join a legacy project without tests, this is also the most obvious way to start implementing useful testing. </font><font style="vertical-align: inherit;">Instead of trying to guess which code to cover with tests, just pay attention to existing bugs - and write tests for them. </font><font style="vertical-align: inherit;">After a while, tests will cover a critical part of the code, since by definition all your tests check what often fails. </font><font style="vertical-align: inherit;">One of the </font></font><a href="https://habr.com/ru/post/358178/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">metrics I proposed</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> displays these efforts. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The only case where it is permissible to refuse a test is if the error in the working environment is not related to the code and comes from the environment itself. </font><font style="vertical-align: inherit;">For example, incorrect configuration of the load balancer cannot be corrected with a unit test.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> To summarize, if you are not sure which code to test, look at the errors that go into production. </font></font><br><br><a name="11"></a><h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Antipattern 11. Attitude towards TDD as a religion </font></font></h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">TDD means </font></font><a href="https://en.wikipedia.org/wiki/Test-driven_development"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">development through testing</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">Like all previous methodologies, it is good on paper as long as the consultants do not begin to prove that this is the only right decision. </font><font style="vertical-align: inherit;">At the time of this writing, this practice has gradually ceased, but I decided to mention it for completeness (since the corporate world is particularly affected by this anti-pattern). </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Generally speaking, when it comes to software testing:</font></font><br><br><ol><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">tests can be written </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">before the</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> corresponding code;</font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">tests can be written </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">simultaneously</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> with the appropriate code;</font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">tests can be written </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">after the</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> appropriate code;</font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> you can never write tests for a specific code. </font></font></li></ol><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">One of the basic principles of TDD is to always follow option 1 (writing tests before implementation code). In general, it is a good practice, but not always the </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">best</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Writing tests before the code means that you are confident in the final API, and this is not always the case. Maybe you have a clear specification and you know the exact signatures of all the methods that should be implemented. But in other cases, you can just experiment with something or write code </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">in the direction of the</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> solution, and not immediately the final version.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">From a practical point of view, the same startup is too early to blindly follow TDD. If you are working in a startup, then your code can change so quickly that TDD will not help much. You can even drop the code and start over again until you write the ‚Äúcorrect‚Äù version. Writing tests after the implementation code is an absolutely correct strategy in this case. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The absence of tests in general (option 4) is also valid. As we saw in the </font></font><a href="https://habr.com/ru/post/358178/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">anti-pattern 4</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , some code does not need testing at all. Writing tests for a trivial code as ‚Äúset by TDD‚Äù will not give you anything. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The obsession of TDD apologists to write tests first caused enormous damage to the </font></font><a href="https://softwareengineering.stackexchange.com/questions/98485/tdd-negative-experience"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">mental health of sensible developers.</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font><font style="vertical-align: inherit;">This obsession has already been spoken about several times, so I hope I don‚Äôt need to repeat myself (searching for the keywords ‚ÄúTDD is crap / stupid / dead‚Äù). </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Here I want to confess that I myself worked several times according to the following scenario:</font></font><br><br><ol><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> First, the implementation of the main component. </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Then writing a test. </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Test run is successful. </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Commenting on critical parts of the component code. </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Test run failed. </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Delete comments, return the code to its original state. </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Running the test is success again. </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Commit </font></font></li></ol><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">To summarize, TDD is a good idea, but you don‚Äôt have to constantly follow it. </font><font style="vertical-align: inherit;">If you work for a Fortune 500 company with a bunch of business analysts and get clear specifications for what you need to implement, then TDD </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">may</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> be useful. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">On the other hand, if you are just playing at home with a new framework on a day off and trying to understand how it works, then you </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">don‚Äôt have to</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> follow TDD.</font></font><br><br><a name="12"></a><h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Antipattern 12. Writing tests without first reading the documentation </font></font></h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The professional knows his work tool well. You may have to spend extra time at the beginning of the project in order to study in detail the technologies you intend to use. New web frameworks are constantly coming out, and it is always helpful to know all the features that can be used to write efficient and concise code. Elapsed time will return a hundredfold. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">With the same respect must be treated to the tests. Since some developers see tests as secondary (see also </font></font><a href="https://habr.com/ru/post/358178/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">antipattern 9</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ), they never try to find out in detail what their testing framework is capable of. Copy-paste code from other projects and examples at first glance works, but not so should a professional behave.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Unfortunately, this picture is too common. </font><font style="vertical-align: inherit;">People write several ‚Äúauxiliary functions‚Äù and ‚Äúutilities‚Äù for tests, not realizing that in the framework this function is either built-in or connected using external modules. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Such utilities make it difficult to understand the tests (especially for juniors), since they are filled with ‚Äúinternal‚Äù knowledge that does not apply to other projects / companies. </font><font style="vertical-align: inherit;">Several times I have replaced ‚Äúsmart internal testing solutions‚Äù with standard off-the-shelf libraries that do the same in a standardized way. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">You should spend some time and learn about the capabilities of your test framework. </font><font style="vertical-align: inherit;">For example, how it works with:</font></font><br><br><ul><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> parameterized tests; </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> imitations and emulations; </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> test settings and dismantling (teardown); </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> categorization of texts; </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> conditional test execution. </font></font></li></ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> If you are working on a typical web application, then you should do minimal research and learn best practices regarding: </font></font><br><br><ul><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> test data generators; </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> HTTP client libraries; </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> servers for HTTP imitation; </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> mutational testing and fuzzing; </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> clean / rollback db; </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> load testing and so on. </font></font></li></ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">No need to reinvent the wheel. </font><font style="vertical-align: inherit;">This also applies to code testing. </font><font style="vertical-align: inherit;">Perhaps in some border situations your application is a truly unique gem and needs some special utility for the core code. </font><font style="vertical-align: inherit;">But I can bet that your modular and integration tests are completely ordinary, so writing special testing utilities is a dubious practice.</font></font><br><br><a name="13"></a><h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Antipattern 13. Poor attitude to unknowing testing </font></font></h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Although I mention this anti-pattern last, it was he who forced me to write this article. It always disappoints me when I meet people at conferences and meetings that ‚Äúproudly‚Äù declare that </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">all tests are a waste of time</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> and that their application works fine without any tests at all. More often, there are those who are against a certain type of testing (usually against modular or integration tests), as we have seen in anti-patterns </font></font><a href="https://habr.com/ru/post/358178/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">1</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> or </font></font><a href="https://habr.com/ru/post/358178/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">2</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">When I meet such people, I like to ask them and find out the true reasons behind the hatred of the tests. And it always comes down to anti-patterns. Or they worked in companies with slow tests ( </font></font><a href="https://habr.com/ru/post/358178/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">antipattern 7</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ), or tests required constant refactoring (</font></font><a href="https://habr.com/ru/post/358178/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">antipattern 5</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ). Their ‚Äúzadolbali‚Äù unreasonable demands to cover with tests 100% of the code ( </font></font><a href="https://habr.com/ru/post/358178/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">antipattern 6</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ) or TDD fanatics ( </font></font><a href="https://habr.com/ru/post/358178/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">antipattern 11</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ) who tried to impose their own distorted understanding of TDD on the whole team. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">If you are one of those people, I really feel you. I know how hard it is to work in a company with the wrong organization of the process.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bad past testing experience should not interfere with your objective assessment when it comes to testing the next project that starts from scratch. </font><font style="vertical-align: inherit;">Try to objectively look at your team, your project and see if any antipatterns apply to you. </font><font style="vertical-align: inherit;">If yes, then just testing is conducted incorrectly and no amount of tests will fix your application. </font><font style="vertical-align: inherit;">Sad but true. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">It's one thing when your team suffers from bad testing practices, and another is to make the junior think that ‚Äútesting is a waste of time.‚Äù </font><font style="vertical-align: inherit;">Please, do not do that. </font><font style="vertical-align: inherit;">There are companies that do not suffer </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">from any of the</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> anti-patterns mentioned in the article. </font><font style="vertical-align: inherit;">Try to find them!</font></font></div><p>Source: <a href="https://habr.com/ru/post/358178/">https://habr.com/ru/post/358178/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../358168/index.html">Programming for Palm in 2017</a></li>
<li><a href="../358170/index.html">How is AADHAAR - the largest biometric system in the world</a></li>
<li><a href="../358172/index.html">DC / AC inverter: principle of operation, circuitry, firmware</a></li>
<li><a href="../358174/index.html">Planar transformer: technology, calculations, cost</a></li>
<li><a href="../358176/index.html">Basics of game code optimization</a></li>
<li><a href="../358180/index.html">Magnasanti - the largest and most terrible city of SimCity</a></li>
<li><a href="../358182/index.html">Use GPG to encrypt messages and files.</a></li>
<li><a href="../358184/index.html">Using Linux Kernel Sequence Files</a></li>
<li><a href="../358186/index.html">Arduino for beginners. Part 2</a></li>
<li><a href="../358188/index.html">Telegram is trying to get the key transfer order canceled to decrypt user messages.</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>