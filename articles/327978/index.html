<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Neuroclot: Part 1. Installing the Raspberry Pi and the cameras in the chicken coop and setting them up</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Big Brother is watching you, bird! 


 Articles about neurocooler 
 Spoiler header 

1. Intro to learning about neural networks 
2. Iron, software and...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Neuroclot: Part 1. Installing the Raspberry Pi and the cameras in the chicken coop and setting them up</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/getpro/habr/post_images/f9c/daf/4cf/f9cdaf4cf7bc84804afed29e674deaf0.jpg" alt="image"><br>  <i>Big Brother is watching you, bird!</i> <br><br><br>  <b>Articles about neurocooler</b> <br><div class="spoiler">  <b class="spoiler_title">Spoiler header</b> <div class="spoiler_text"><ol><li>  <b><a href="https://habrahabr.ru/post/328138/">Intro</a> to learning about neural networks</b> </li><li>  <b><a href="https://habrahabr.ru/post/327978/">Iron, software and config</a> for monitoring chickens</b> </li><li>  <a href="https://habrahabr.ru/post/328940/"><b>A bot</b></a> that posts events from the life of chickens - without a neural network </li><li>  Dataset markup </li><li>  A working <a href="https://habrahabr.ru/post/330738/"><b>model</b></a> for the recognition of chickens in the hen house </li><li>  The result - a working bot that recognizes chickens in the hen house </li></ol><br></div></div><a name="habracut"></a><br><cut><br><br><p>  The idea came a long time ago.  Someone has the idea of ‚Äã‚Äãheating coops with cryptocurrency-minded video cards (cryptocurrency), which is great, of course, but someone has ideas in recognizing images, sounds, in neural networks and their real use. </p><br><p>  Once upon a time, they read an article about a Japanese man who <a href="https://cloud.google.com/blog/big-data/2016/08/how-a-japanese-cucumber-farmer-is-using-deep-learning-and-tensorflow">helped</a> his father with sorting cucumbers;  decided to analyze how our parents chickens rush, sending them reports to the messenger - an idea of ‚Äã‚Äãfun. </p><br><cut><br><p>  In general, a lot of plans.  The fact that there was a stir near the nest may mean that the bird has climbed into the nest or has crawled out of it.  This is easy to understand with the help of openCV, and we already know how.  Make it easy with this <a href="http://www.pyimagesearch.com/2015/06/01/home-surveillance-and-motion-detection-with-the-raspberry-pi-python-and-opencv/">blog</a> . </p><br><p>  But what if you recognize each bird and analyze which one is not rushing?  Evaluate the productivity of each individual chicken?  If the bird does not rush and has no other good reason for resting (for example, short daylight hours, shedding), then maybe it's time to cook chicken soup? </p><br><p>  Just submit a message: ‚ÄúIt seems to us that the bird ch11 is not rushing without a reason; perhaps we should consider its further fate.‚Äù  And then it turns out that the bird ch11 is our old cat Cranberry, which simply lives with chickens. </p><br><h2>  Hackathon </h2><br><p>  Thoughts that it all sounds great, did not give rest.  The first experience in the recognition of movement ( <a href="https://t.me/snakers4/742">on cars outside the window</a> ) was not bad, and now the equipment was idle.  Everything always happens suddenly, so one fine Thursday I bought tickets for Friday night to my parents and flew over the weekend to set up data collection for a neuroculture. </p><br><p>  The main difficulty was the lack of wired internet and the impossibility of carrying it in principle (wilderness, what to do).  But when you don‚Äôt know what you are signing up for, hope for the best, yes. </p><br><p>  In addition, there were no outlets in the hen house.  The parents, of course, manage switches from the house, giving the light and signaling.  Her father responded to a request to turn a rosette into a hen house, and she, in general, materialized there very quickly. </p><br><p>  The main part of the equipment is the Raspberry Pi 3 and the camera board to it, a power source and a usb fan (for processing images without a fan heats the processor right up to 80 degrees).  In addition, someone had to provide pi Internet. </p><br><p>  So, among the alternatives for hotspot is a 3g / 4g modem huavei, an old xperia on an android.  The modem is good because it does not need a separate power source, and the bad is that it works out of the box only with Windows.  There are, of course, articles about how to get it on Linux, but something did not want to. </p><br><p>  In the conditions of tightly limited time (left a day before departure) a telephone was chosen. <br>  The provider did not provide a static IP service in this region.  The IP turned out to be dynamic, which was decided to be fixed using a dynamic DNS service. </p><br><p>  And all of a sudden (whoever doubted it), it didn't work.  After all, IP is not just dynamic, it is gray dynamic.  This means that it is impossible to reach it from the outside, the ports are closed. </p><br><p>  At the same time, a Python script was captured to capture and transfer images to the server, but it was still raw. </p><br><p>  In the meantime, half the time available was already spent. </p><br><p>  A friend suggested that there is a beautiful thing, ssh back connect, which, in general, saved us from disappointment.  There was very little time left, so it was not possible to fully understand how everything works, it was necessary for it to work at least somehow. </p><br><p>  Before we left, we set up crowns with an ssh tunnel prokidyvaniem, temperature measurement and an alarm in the mail if something happens, and the entire setup went to the hen house.  With the Internet there is still bad, but it is.  It turned out that it is quite dark there and nothing is visible on the photos.  My father promised to adjust the lighting as soon as there is time.  For the time being, the camera was turned off. </p><br><p>  The main thing is that it was possible to connect to pi from wherever the Internet was. </p><br><h2>  More about setting up </h2><br><p>  Slightly moving away from the hackathon - march-throw, I undertook to tune up this matter further.  After reading the <a href="https://linuxaria.com/howto/permanent-ssh-tunnels-with-autossh">guides</a> (using the keywords permanent autossh), I tried to set up autossh instead of reverse ssh, which was unstable and was supported by the crown.  At first, nothing happened with autossh, I continued to use the first solution with crown, but the problem with the growing connections forced me to make friends with autossh. </p><br><p>  To get everything started, you only need to create an executable file (who does not know how to google create executable file linux) on a remote device with a dynamic gray IP and add the following line there: </p><br><pre><code class="bash hljs">/usr/bin/autossh -M 0 -o ServerAliveInterval=50 -o ServerAliveCountMax=2 -nNTf -R 2222:localhost:22 userB@hostB -p bbbb</code> </pre> <br><p>  In this line, 2222 can be replaced with any port you don't need, you need to replace userB with the user on your home server (that is, the one that is not in the hen house), hostB with the host on your home server, bbbb is the port of your home server, if different from the standard (22). </p><br><p>  You can read about the parameters of the team yourself if you are interested or want to change something.  Next we add to the cron (crontab -e) a line (if unfamiliar with the crown, then <a href="https://t.me/snakers4/367">1</a> <a href="https://t.me/snakers4/368">2</a> <a href="https://t.me/snakers4/369">3</a> <a href="https://t.me/snakers4/376">4</a> friends collected introductory), which will run autossh when rebooting: </p><br><pre> <code class="bash hljs">@reboot /path/to/script/autosshtunnel.sh</code> </pre><br><p>  So now, if you go to a home server from another remote machine, make sure that the session is not broken.  That is, I go to the server from a laptop, and already from the server I knock on the chicken coop, in which case I prescribe the parameters for the eternal session and when connected to the server, and when connected to the chicken coop (distributor). </p><br><p>  This is done according to this pattern: </p><br><pre> <code class="bash hljs">ssh -o TCPKeepAlive=yes -o ServerAliveInterval=50 user@box.example.com</code> </pre> <br><p>  I connect to the system in the hen house like this: </p><br><pre> <code class="bash hljs">ssh -o TCPKeepAlive=yes -o ServerAliveInterval=50 sshuser@localhost -p 2222</code> </pre> <br><p>  This all concerned the possibility of a remote connection, now let's quickly talk about temperature alarms.  To set up email alarms in debian systems like ubuntu and rasbian - just follow this <a href="https://help.ubuntu.com/community/EmailAlerts">guide</a> , you just need to install ssmtp and fix the config, that's all.  The simplest script for an alarm about overheating to a mail for a rasbian might look like this: </p><br><pre> <code class="bash hljs">TEMPERATURE=<span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$(/opt/vc/bin/vcgencmd measure_temp)</span></span></span><span class="hljs-string">"</span></span> NTEMPERATURE=<span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$(echo $TEMPERATURE | tr -dc '0-9.')</span></span></span><span class="hljs-string">"</span></span> LIMIT=<span class="hljs-string"><span class="hljs-string">"61.0"</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> [ $(<span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$NTEMPERATURE</span></span></span><span class="hljs-string"> &gt; </span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$LIMIT</span></span></span><span class="hljs-string">"</span></span> | bc) -ne 0 ]; <span class="hljs-keyword"><span class="hljs-keyword">then</span></span> <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">"The critical CPU temperature has been reached </span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$NTEMPERATURE</span></span></span><span class="hljs-string">"</span></span> | sudo /usr/bin/ssmtp -vvv somename@somehost.com <span class="hljs-keyword"><span class="hljs-keyword">fi</span></span></code> </pre> <br><p>  Then it remains to pack this script into an executable file and throw it into crowns.  While not hot, I run the script every two minutes. </p><br><p>  Now let's talk about the main script, which we collect images.  Images we consider conditionally useful if we notice movement.  We will fasten analytics and recognition to these images already.  We have already mentioned a useful <a href="http://www.pyimagesearch.com/2015/06/01/home-surveillance-and-motion-detection-with-the-raspberry-pi-python-and-opencv/">blog</a> , from which we have taken the script as a basis, having rewritten it a little. </p><br><p>  In the guide it is already written what is needed for work, but I will repeat that you need to make an <a href="http://www.pyimagesearch.com/2016/04/18/install-guide-raspberry-pi-3-raspbian-jessie-opencv-3/">OpenCV build</a> .  This can take a long time (in my case it took 5 hours).  In addition, it is necessary to put the same and other libraries, also mentioned there, for example, numpy, imutils, - there were no pitfalls. </p><br><p>  We rewrote the main script to fit our needs and made the following changes: 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    </p><ul><li>  changed Python 2 to Python 3; </li><li>  instead of dropbox, they used their server; </li><li>  the original and compressed frame is saved. </li></ul><p></p><br><p>  The ready-made version of pi_surveillance.py looks like this (well, except that you still need to take out the constants from the script to the config): </p><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># import the necessary packages import sys sys.path.append('/usr/local/lib/python2.7/site-packages') from pyimagesearch.tempimage import TempImage from picamera.array import PiRGBArray from picamera import PiCamera import argparse import warnings import datetime import imutils import json import time import cv2 import os # construct the argument parser and parse the arguments ap = argparse.ArgumentParser() ap.add_argument("-c", "--conf", required=True, help="path to the JSON configuration file") args = vars(ap.parse_args()) # filter warnings, load the configuration and check if we are going to use server warnings.filterwarnings("ignore") conf = json.load(open(args["conf"])) client = None if conf["use_server"]: #we do not use Dropbox print("[INFO] you are using server") # initialize the camera and grab a reference to the raw camera capture camera = PiCamera() camera.resolution = tuple(conf["resolution"]) camera.framerate = conf["fps"] rawCapture = PiRGBArray(camera, size=tuple(conf["resolution"])) # allow the camera to warmup, then initialize the average frame, last # uploaded timestamp, and frame motion counter print("[INFO] warming up...") time.sleep(conf["camera_warmup_time"]) avg = None lastUploaded = datetime.datetime.now() motionCounter = 0 # capture frames from the camera for f in camera.capture_continuous(rawCapture, format="bgr", use_video_port=True): # grab the raw NumPy array representing the image and initialize # the timestamp and occupied/unoccupied text frame = f.array timestamp = datetime.datetime.now() text = "Unoccupied" # resize the frame, frame = imutils.resize(frame, width=1920) frameorig = imutils.resize(frame, width=1920) # convert it to grayscale, and blur it gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) gray = cv2.GaussianBlur(gray, (21, 21), 0) # if the average frame is None, initialize it if avg is None: print("[INFO] starting background model...") avg = gray.copy().astype("float") rawCapture.truncate(0) continue # accumulate the weighted average between the current frame and # previous frames, then compute the difference between the current # frame and running average cv2.accumulateWeighted(gray, avg, 0.5) frameDelta = cv2.absdiff(gray, cv2.convertScaleAbs(avg)) # threshold the delta image, dilate the thresholded image to fill # in holes, then find contours on thresholded image thresh = cv2.threshold(frameDelta, conf["delta_thresh"], 255, cv2.THRESH_BINARY)[1] thresh = cv2.dilate(thresh, None, iterations=2) cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE) cnts = cnts[0] if imutils.is_cv2() else cnts[1] # loop over the contours # check if there is at least one contour, which is large enough # I know this isn't the best practice # I know about bool variables # I know about other things too. I just don't actually care # Yes, I am a liar, 'cause if I did not care, # I wouldn't write anything of those ^ for c in cnts: # if the contour is too small, ignore it if cv2.contourArea(c) &lt; conf["min_area"]: continue text = "Occupied" print("[INFO] room is occupied, motion counter is {mc}".format(mc=motionCounter)) # initiate timestamp ts = timestamp.strftime("%A-%d-%B-%Y-%I:%M:%S%p") ts1 = timestamp.strftime("%A-%d-%B-%Y") # let's create paths on a server pathorig = "{base_path}/{timestamp}/origs".format( base_path=conf["server_base_path"], timestamp=ts1) pathres = "{base_path}/{timestamp}/res".format( base_path=conf["server_base_path"], timestamp=ts1) os.system('ssh -p bbbb "%s" "%s %s"' % ("userB@hostB", "sudo mkdir -p", pathorig)) os.system('ssh -p bbbb "%s" "%s %s"' % ("userB@hostB", "sudo mkdir -p", pathres)) # upload images on a server if (text == "Occupied"): motionCounter += 1 if motionCounter &gt;= conf["min_motion_frames"] and (timestamp - lastUploaded).seconds &gt;= conf["min_upload_seconds"]: print("[INFO] time to upload, motion counter is {mc}".format(mc=motionCounter)) # upload original t = TempImage() cv2.imwrite(t.path, frameorig) os.system('scp -P bbbb "%s" "%s:%s"' % (t.path, "userB@hostB", pathorig)) t.cleanup() # upload resized image of 512 px framec = imutils.resize(frame, width=512) tc = TempImage() cv2.imwrite(tc.path, framec) os.system('scp -P bbbb "%s" "%s:%s"' % (tc.path, "userB@hostB", pathres)) tc.cleanup() #reset motionCounter motionCounter = 0 lastUploaded = datetime.datetime.now() # otherwise, the room is not occupied else: motionCounter = 0 # check to see if the frames should be displayed to screen if conf["show_video"]: # display the security feed cv2.imshow("Security Feed", frame) key = cv2.waitKey(1) &amp; 0xFF # if the `q` key is pressed, break from the loop if key == ord("q"): break # clear the stream in preparation for the next frame rawCapture.truncate(0)</span></span></code> </pre> <br><p>  How our config now looks like: </p><br><pre> <code class="bash hljs">{ <span class="hljs-string"><span class="hljs-string">"show_video"</span></span>: <span class="hljs-literal"><span class="hljs-literal">false</span></span>, <span class="hljs-string"><span class="hljs-string">"use_server"</span></span>: <span class="hljs-literal"><span class="hljs-literal">true</span></span>, <span class="hljs-string"><span class="hljs-string">"server_base_path"</span></span>: <span class="hljs-string"><span class="hljs-string">"/media/server/PIC_LOGS"</span></span>, <span class="hljs-string"><span class="hljs-string">"min_upload_seconds"</span></span>: 1.0, <span class="hljs-string"><span class="hljs-string">"min_motion_frames"</span></span>: 3, <span class="hljs-string"><span class="hljs-string">"camera_warmup_time"</span></span>: 2.5, <span class="hljs-string"><span class="hljs-string">"delta_thresh"</span></span>: 5, <span class="hljs-string"><span class="hljs-string">"resolution"</span></span>: [1920, 1080], <span class="hljs-string"><span class="hljs-string">"fps"</span></span>: 16, <span class="hljs-string"><span class="hljs-string">"min_area"</span></span>: 6000 }</code> </pre><br><p>  And so - tempimage.py: </p><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># import the necessary packages import uuid import os import datetime class TempImage: def __init__(self, basePath="./temps", ext=".jpg"): # construct the file path timestamp = datetime.datetime.now() ts = timestamp.strftime("-%I:%M:%S%p") self.path = "{base_path}/{rand}{tmstp}{ext}".format(base_path=basePath, rand=str(uuid.uuid4())[:8], tmstp=ts, ext=ext) def cleanup(self): # remove the file os.remove(self.path)</span></span></code> </pre><br><p>  The first image was an image of a chicken tail in a nest.  An excellent gift for May for an introvert in life, which in good weather stares at the console.  The image really pleased, despite the darkness, the lack of a bird's head in the frame and the script's inadequate nature.  This is a chicken tail ( <i>Just think, a thousand kilometers away from you, the chicken crawled into the nest, not suspecting that you are watching it.</i> ): </p><br><img src="https://habrastorage.org/getpro/habr/post_images/8a7/a61/1d9/8a7a611d9ce0eda3b97830f3f7bf82b8.jpg" alt="image"><br><p>  Then the lighting was tuned, and I received noticeably more inspirational photos. </p><br><img src="https://habrastorage.org/getpro/habr/post_images/103/4c1/9e0/1034c19e0d77ed52ae95d34034784179.jpg" alt="image"><br><img src="https://habrastorage.org/getpro/habr/post_images/22c/7f2/0af/22c7f20af42d7f0aedf952984e3a7335.jpg" alt="image"><br><br><p>  The script is launched, taking into account the fact that OpenCV is installed in the virtual working environment cv, like this (we would also have to figure out how to send this to the background): </p><br><pre> <code class="python hljs">source ~/.profile workon cv cd ~/chickencoop python3 /home/sshuser/chickencoop/pi_surveillance.py --conf conf.json</code> </pre> <br><img src="https://habrastorage.org/getpro/habr/post_images/d40/911/d37/d40911d37901963162a331d7b2269483.jpg" alt="image"><br><br>  <i>To be continued...</i> </cut></cut></div><p>Source: <a href="https://habr.com/ru/post/327978/">https://habr.com/ru/post/327978/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../327960/index.html">Design Case: MroSupply E-commerce Site</a></li>
<li><a href="../327962/index.html">Experience DataLine: the work of technical support service</a></li>
<li><a href="../327966/index.html">Technosphere Lectures: Go Programming</a></li>
<li><a href="../327970/index.html">Roskomnadzor is trying to finish off Rutracker. Locking server announcers and workarounds</a></li>
<li><a href="../327974/index.html">South Korea: what any developer who wants to localize his mobile game needs to know</a></li>
<li><a href="../327980/index.html">3 administrative scripts</a></li>
<li><a href="../327982/index.html">Reaction to user feedback in order to increase the average rating</a></li>
<li><a href="../327984/index.html">Mikrotik guarding temperature</a></li>
<li><a href="../327986/index.html">We broadcast a video stream from a web page via WebRTC to Facebook and YouTube at the same time</a></li>
<li><a href="../327988/index.html">Free from all shackles: Emercoin version 6.2 has become completely decentralized</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>