<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Comparison of open OLAP-systems Big Data: ClickHouse, Druid and Pinot</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="ClickHouse , Druid and Pinot are three open data stores that allow you to perform analytical queries on large amounts of data with interactive delays....">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">ğŸ”</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">ğŸ“œ</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">â¬†ï¸</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">â¬‡ï¸</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Comparison of open OLAP-systems Big Data: ClickHouse, Druid and Pinot</h1><div class="post__text post__text-html js-mediator-article">  <a href="https://clickhouse.yandex/">ClickHouse</a> , <a href="http://druid.io/">Druid</a> and <a href="https://github.com/linkedin/pinot">Pinot</a> are three open data stores that allow you to perform analytical queries on large amounts of data with interactive delays.  This article is a translation of the <a href="https://medium.com/%40leventov/comparison-of-the-open-source-olap-systems-for-big-data-clickhouse-druid-and-pinot-8e042a5ed1c7">detailed comparison</a> made by Roman Leventov. <br><br><h2>  Spoiler </h2><table><tbody><tr><th>  <strong>Clickhouse</strong> </th><th>  <strong>Druid or Pinot</strong> </th></tr><tr><td>  There are C ++ experts in the organization. </td><td>  There are Java experts in the organization. </td></tr><tr><td>  Small cluster </td><td>  Large cluster </td></tr><tr><td>  Some tables </td><td>  Many tables </td></tr><tr><td>  One data set </td><td>  Multiple unrelated datasets </td></tr><tr><td>  Tables and data are permanently in cluster </td><td>  Tables and datasets periodically appear in the cluster and are removed from it </td></tr><tr><td>  The size of the tables (and the intensity of queries to them) remains stable over time. </td><td>  Tables grow and shrink significantly </td></tr><tr><td>  Uniform requests (their type, size, distribution by time of day, etc.) </td><td>  Heterogeneous queries </td></tr><tr><td>  There is a dimension in the data by which they can be segmented, and there are almost no queries that affect data located in several segments. </td><td>  There is no such measurement, and queries often affect data located throughout the cluster. </td></tr><tr><td>  The cloud is not used, the cluster must be deployed on a specific physical server configuration </td><td>  Cluster deployed in the cloud </td></tr><tr><td>  No existing Hadoop or Spark clusters </td><td>  Hadoop or Spark clusters already exist and can be used </td></tr></tbody></table>  And under the cut - a detailed story about how the novel came to this. <a name="habracut"></a><br><br><h2>  Information sources </h2><br>  Details of the implementation of <strong>ClickHouse</strong> became known to me from <a href="https://github.com/ztlpn">Alexey Zatelepin</a> , one of the <strong>key developers of the project</strong> .  The documentation available in English is rather poor - the last four sections of <a href="https://clickhouse.yandex/docs/en/development/architecture.html">this page of documentation</a> are the best source of information. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      <strong>I myself participate in the development of Druid</strong> , but I do not have a personal interest in this system - to be honest, most likely in the near future I will cease to engage in its development.  Therefore, readers can count on the absence of any bias. <br><br>  Everything that I will write about <strong>Pinot</strong> further is based on the <a href="https://github.com/linkedin/pinot/wiki/Architecture">Architecture</a> page <a href="https://github.com/linkedin/pinot/wiki/Architecture">in the Pinot wiki</a> , as well as on other wiki pages in the Design Documentation section.  The last time they were updated in June 2017 - more than six months ago. <br><br>  The reviewers of the original article were Alexey Zatelepin and <a href="https://github.com/ludv1x">Vitaliy Lyudvichenko</a> (developers of ClickHouse), <a href="https://github.com/gianm">Jean Merlino</a> (most active developer of Druid), <a href="https://github.com/kishoreg">Kishore Gopalakrishna</a> (architect Pinot) and <a href="https://github.com/jfim">Jean-Francois Im</a> (developer of Pinot).  We join the thanks of the author and believe that this greatly increases the credibility of the article. <br><br>  <strong>Warning</strong> : the article is quite large, so you may want to limit yourself to reading the section â€œConclusionâ€ at the end. <br><br><h1>  Similarities between systems </h1><br><h2>  Related data and calculations </h2><br>  <strong>At the fundamental level, ClickHouse, Druid and Pinot are similar</strong> because they store data and perform query processing on the same nodes, moving away from the â€œdisconnectedâ€ BigQuery architecture.  Recently, I have already described several hereditary problems with related architecture in the case of Druid [ <a href="https://medium.com/%40leventov/the-problems-with-druid-at-large-scale-and-high-load-part-1-714d475e84c9">1</a> , <a href="https://medium.com/%40leventov/the-challenges-of-running-druid-at-large-scale-and-future-directions-part-2-ef594ce298f2">2</a> ].  There is currently no open equivalent for BigQuery (with the exception of, perhaps, <a href="http://drill.apache.org/">Drill</a> ?).  Possible approaches to building such open systems are covered in <a href="https://medium.com/%40leventov/design-of-a-cost-efficient-time-series-store-for-big-data-88c5dc41af8e">another article on my blog</a> . <br><br><h2>  Differences from Big Data SQL Systems: Indexes and Static Data Distribution </h2><br>  The systems reviewed in this article <strong>perform queries faster</strong> than Big Data systems from the SQL-on-Hadoop class family: Hive, Impala, Presto, and Spark, even when the latter gain access to data stored in a column format â€” for example, Parquet or Kudu.  This is because in ClickHouse, Druid and Pinot: <br><br><ul><li>  There is <strong>its own format for storing data with indexes</strong> , and they are tightly integrated with query processing engines.  Systems of the SQL-on-Hadoop class can usually be called agnostic about the data formats and therefore they are less â€œintrusiveâ€ in Big Data backends. </li><li>  <strong>Data is distributed relatively â€œstaticallyâ€</strong> between nodes, and this can be used for distributed query execution.  The other side of the coin is that ClickHouse, Druid and Pinot <strong>do not support queries</strong> <strong>that require moving a large amount of data</strong> between nodes â€” for example, join between two large tables. </li></ul><br><h2>  No point updates and deletes </h2><br>  Being on the other side of the database spectrum, ClickHouse, Druid and Pinot <strong>do not support point updates and deletes</strong> , as opposed to column systems like Kudu, InfluxDB and Vertica (?).  This gives ClickHouse, Druid and Pinot the ability to produce more efficient column compression and more aggressive indices, which means <strong>greater resource utilization</strong> and faster query execution. <br><br>  The developers of ClickHouse in Yandex plan to start supporting <a href="https://clickhouse.yandex/docs/en/roadmap.html">updates and deletions in the future</a> , but I'm not sure if these will be â€œrealâ€ point requests or updates / deletions of data ranges. <br><br><h2>  Big Data Absorption </h2><br>  All three systems support streaming data absorption from Kafka.  Druid and Pinot support streaming <a href="https://en.wikipedia.org/wiki/Lambda_architecture">Lambda-style</a> streaming and packet acquisition of the same data.  ClickHouse supports batch inserts directly, so it does not need a separate batch absorption system similar to that used in Druid and Pinot.  If you are interested in the details, you can find them further. <br><br><h2>  Tested on a large scale </h2><br>  All three systems are tested for performance on a large scale: <a href="https://yandex.com/blog/clickhouse/evolution-of-data-structures-in-yandex-metrica">ClickHouse cluster works</a> in <a href="https://yandex.com/blog/clickhouse/evolution-of-data-structures-in-yandex-metrica">Yandex.Metrica</a> , consisting of about ten thousand CPU cores.  Metamarkets uses <a href="https://medium.com/%40leventov/the-problems-with-druid-at-large-scale-and-high-load-part-1-714d475e84c9">a similarly sized Druid cluster</a> .  One Pinot cluster on LinkedIn includes â€œ <a href="https://github.com/linkedin/pinot/issues/3">thousands of machines</a> .â€ <br><br><h2>  Immaturity </h2><br>  All systems considered in the article are <strong>immature by the standards of Big Data open enterprise systems</strong> .  However, most likely they are immature no more than the average open Big Data system - but this is a completely different story.  ClickHouse, Druid and Pinot lack some obvious optimizations and functionality, and they are full of bugs (Iâ€™m not 100% sure about ClickHouse and Pinot, but I donâ€™t see any reasons why they would be better than Druid in this regard). <br><br>  This brings us to the next important section. <br><br><h1>  Pro performance comparison and system selection </h1><br>  I regularly see on the network how some conduct comparisons of big data systems: they take a set of their data, in some way â€œfeedâ€ it to the estimated system, and then immediately try to measure performance â€” how much memory or disk space was used and how fast requests.  Moreover, the understanding of how the systems they test the system from is absent.  Then, using only such specific performance data â€” sometimes together with the functionality they need and which the system <em>currently has</em> â€” they ultimately make their choice or, even worse, choose to write their own â€œbestâ€ system with zero <br><br>  This approach seems to me wrong, at least it does not apply to open OLAP-systems for Big Data.  The task of creating a Bid Data OLAP system that could work effectively in most use cases and would contain all the necessary functions is so great that I estimate its implementation at least <strong>100 man-years</strong> . <br><br>  Today, ClickHouse, Druid and Pinot are optimized <em>only</em> for specific use cases that are required by their developer - and for the most part contain only those functions that the developers themselves need.  I can guarantee that your case will necessarily â€œrest onâ€ those bottlenecks that the developers of the OLAP-systems under consideration have not yet encountered - or in those places that they are not interested in. <br><br>  Not to mention the fact that the above-mentioned approach â€œto drop data into a system that you donâ€™t know anything about and then measure its effectivenessâ€ is very likely to give a distorted result due to serious â€œnarrowâ€ places that could actually be corrected by <strong>simply changing the configuration</strong> , data schema, or other query construction. <br><br><h2>  CloudFlare: ClickHouse vs. Druid </h2><br>  One such example, well illustrating the problem described above, is Marek Vavrushâ€™s post about <a href="https://blog.cloudflare.com/how-cloudflare-analyzes-1m-dns-queries-per-second/">choosing between ClickHouse and Druid at Cloudflare</a> .  They needed 4 ClickHouse servers (which eventually became 9), and they estimated that they would need â€œhundreds of nodesâ€ to deploy a similar installation of Druid.  Let Marek admit that the <strong>comparison is dishonest</strong> , because Druid lacks "sorting by primary key", he may not even realize that it is possible to achieve approximately the same effect in Druid simply by <a href="http://druid.io/docs/0.11.0/ingestion/index.html">setting the correct measurement order in the " <em>ingestion spec</em> "</a> and making simple preparations Data: trim the value of the <code>__time</code> column in Druid to some kind of coarse detail (for example, one hour) and optionally add another â€œlong-typeâ€ precise_time column if some queries require a more precise timeframe.  Yes, this is a hack, but, as we just figured out, in Druid, you can sort the data by any dimension before <code>__time</code> , and it's easy enough to implement. <br><br>  However, I will not argue with their final decision to choose ClickHouse, since on a scale of about 10 nodes and for their needs ClickHouse also seems to me a better choice than Druid.  But their conclusion that ClickHouse is at least an order of magnitude more efficient (by the standards of infrastructure costs) than Druid is a serious misconception.  In fact, among the systems we are considering today, <strong>Druid offers the best opportunity for really cheap installations</strong> (see the section â€œLevels of Druid request processing nodesâ€ below). <br><br><blockquote>  When you choose the OLAP Big Data system, do not compare how well they are now suitable for your case.  Now they are all suboptimal.  Instead, compare how quickly your company can make these systems move in the direction that you need. </blockquote><br>  Due to their fundamental architectural similarities, ClickHouse, Druid and Pinot have about the same â€œlimitâ€ of efficiency and performance optimization.  There is no â€œmagic pillâ€ that would allow any of these systems to be faster than the rest.  Do not allow yourself to be confused by the fact that <em>in their current state, the</em> systems show themselves very differently in different benchmarks. <br><br>  Suppose Druid does not support â€œsorting by primary keyâ€ as well as ClickHouse does â€” and ClickHouse, in turn, does not support â€œinverted indicesâ€ as well as Druid, which gives these systems advantages with a particular load.  <strong>Missed optimization can be implemented in the selected system with the help of not so</strong> <strong>much of</strong> <strong>their efforts</strong> , if you have the intention and opportunity to decide on such a step. <br><br><ul><li>  Your organization should have engineers who can read, understand, and modify the source code of the selected system, and they should also have time for that.  Note that ClickHouse is written in C ++, and Druid and Pinot are written in Java. </li><li>  Or your organization must sign a contract with a company that supports the chosen system.  These will be <a href="https://www.altinity.com/">Altinity</a> for ClickHouse, <a href="https://imply.io/services">Imply</a> and <a href="https://hortonworks.com/open-source/druid/">Hortonworks</a> for Druid.  For Pinot, there are no such companies at the moment. </li></ul><br>  Other information about developing systems that you should take into account: <br><br><ul><li>  The authors of ClickHouse, working in Yandex, argue that they spend 50% of their time on creating the functionality that they need inside the company, and the other 50% go to the functions that most â€œcommunity votesâ€ gain.  However, for you to benefit from this fact, it is required that the <strong>functions that you need are the</strong> <strong>most needed by the</strong> ClickHouse <strong>community</strong> . </li><li>  Imply's Druid developers are motivated to work on widely used features, as this will allow them to maximize their business reach in the future. </li><li>  The development process of Druid strongly resembles <a href="https://community.apache.org/apache-way/apache-project-maturity-model.html">the Apache model</a> , when software has been developed by several companies for several years, each of which has rather peculiar and different priorities, and there is no leading company among them.  ClickHouse and Pinot are still far from this stage, since only Yandex and Linkedin, respectively, are engaged in them.  The third-party contribution to the development of Druid has a minimal chance of being rejected due to the fact that it disagrees with the vision of the main developer - after all <strong>, there is no â€œmainâ€ developer company in Druid</strong> . </li><li>  Druid supports the â€œDeveloper APIâ€, which allows you to add your own column types, aggregation mechanisms, possible options for â€œdeep storageâ€, etc., and you can keep all this in a code base separate from the Druid kernel itself.  This API is documented by the developers of Druid, and they monitor its compatibility with previous versions.  However, it is not enough â€œadultâ€, and it breaks down with almost every new release of Druid.  As far as I know, similar APIs are not supported in ClickHouse and Pinot. </li><li>  According to Github, the <strong>largest number of people working on Pinot</strong> - it seems that only last year at <a href="https://github.com/linkedin/pinot/graphs/contributors%3Ffrom%3D2017-01-24%26amp%3Bto%3D2018-01-24%26amp%3Btype%3Dc">least 10 person-years</a> were invested in Pinot.  For ClickHouse, this figure is about 6 person-years, and for Druid - 7. In theory, this should mean that Pinot is improving faster than all the other systems we are considering. </li></ul><br>  The Druid and Pinot architectures are almost identical to each other, while ClickHouse stands slightly apart.  Therefore, we first compare ClickHouse with the â€œgeneralizedâ€ Druid / Pinot architecture, and then discuss the minor differences between Druid and Pinot. <br><br><h1>  Differences between ClickHouse and Druid / Pinot </h1><br><h2>  Data Management: Druid and Pinot </h2><br>  In Druid and Pinot, all the data in each "table" (no matter how it was called in the terminology of these systems) is divided into the specified number of parts.  According to the time axis, data is usually divided at a specified interval.  These pieces of data are then â€œsealedâ€ individually into autonomous entities, called â€œsegmentsâ€.  Each segment includes table metadata, columnar compressed data and indexes. <br><br>  Segments are stored in the â€œdeep storageâ€ storage file system (for example, HDFS) and can be loaded onto query processing nodes, but the latter are not responsible for the stability of the segments, so query processing nodes can be replaced relatively freely.  <strong>Segments are not tied tightly to specific nodes</strong> and can be loaded on those or other nodes.  A dedicated dedicated server (called a â€œcoordinatorâ€ in Druid and a â€œcontrollerâ€ in Pinot, but Iâ€™ll refer to it as a â€œmasterâ€ below) is responsible for assigning segments to nodes, and moving segments between nodes, if necessary. <br><br>  This does not contradict what I noted above, all three systems have a static distribution of data between nodes, since the loading of segments and their movement into Druid - and as I understand it in Pinot - are expensive operations and therefore are not performed for each individual queue, but occur usually every few minutes / hours / days. <br><br>  Segment metadata is stored in ZooKeeper - directly in the case of Druid, and using the <a href="http://helix.apache.org/">Helix</a> framework at Pinot.  In Druid, metadata is also stored in the SQL database, more about this in the section â€œDifferences between Druid and Pinotâ€. <br><br><h2>  Data Management: ClickHouse </h2><br>  There are no â€œsegmentsâ€ in ClickHouse that contain data falling within specific time ranges.  There is no â€œdeep storageâ€ for the data, the nodes in the ClickHouse cluster are also responsible for processing requests, and the constancy / stability of the data stored on them.  So you <strong>do not need HDFS</strong> or cloud storage like Amazon S3. <br><br>  ClickHouse has partitioned tables consisting of the specified node set.  There is no â€œcentral authorityâ€ or metadata server.  All nodes between which a table is divided contain complete, identical copies of the metadata, including the addresses of all the other nodes where sections of this table are stored. <br><br>  The partitioned table metadata includes â€œweightsâ€ of nodes for distributing freshly written data â€” for example, 40% of the data should go to node A, 30% to node B, and 30% to C. Usually, the distribution should occur evenly, â€œperegosâ€, as in this For example, it is required only when a new node is added to a partitioned table and you need to quickly fill it with some data.  <strong>Updates to these "weights" must be performed manually by the</strong> administrators of the ClickHouse cluster, or by an automated system built on top of ClickHouse. <br><br><h2>  Data Management: Comparison </h2><br>  The data management approach in ClickHouse is simpler than in Druid and Pinot: no â€œdeep storageâ€ is required, just one type of node, no dedicated server is needed to manage the data.  But the ClickHouse approach leads to some difficulties when any data table grows so large that it requires splitting between a dozen or more nodes: the query gain becomes as large as the partitioning factor â€” even for queries that cover a small data interval: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ah/dq/-h/ahdq-hhbczhc52lhjj4guiuyjgm.png"></div><br>  <em>Compromise of data distribution in ClickHouse</em> <br><br>  In the example shown in the image above, these tables are distributed between the three nodes in Druid / Pinot, but a query over a small data interval usually affects only two of them (until the interval crosses the border interval of the segment).  In ClickHouse, any queries will be forced to touch three nodes - if the table is segmented between three nodes.  In this example, the difference does not look so significant, but imagine what happens if the number of nodes reaches 100 â€” while the segmentation factor can still be, for example, 10 in Druid / Pinot. <br><br>  To mitigate this problem, the largest ClickHouse cluster in Yandex, consisting of hundreds of nodes, is in fact divided into many â€œsub-clustersâ€ with several dozens of nodes each.  The ClickHouse cluster is used to work with website analytics, and each data point has a â€œwebsite IDâ€ dimension.  There is a tight binding of each site ID to a specific sub-cluster, where all the data for this site ID goes.  On top of the ClickHouse cluster, there is a business logic layer that manages this data separation during data acquisition and query execution.  Fortunately, in their usage scenarios, very few requests affect several site identifiers, and similar requests are not from service users, so they do not have a hard link to real time according to the service level agreement. <br><br>  Another disadvantage of the ClickHouse approach is that when the cluster grows very quickly, the data cannot be rebalanced automatically without the participation of a person who manually changes the "weights" of nodes in the table being split. <br><br><h2>  Druid query processing node levels </h2><br>  Data management with â€œeasier to imagineâ€ segments - this concept fits well with our cognitive abilities.  The segments themselves can be moved between nodes relatively simply.  This two reasons allowed Druid to implement the â€œ <em>leveling</em> â€ of the nodes involved in processing requests: old data is automatically transferred to servers with relatively large disks, but less memory and CPU, which can <strong>significantly reduce the cost of a large Druid work cluster</strong> by slowing down requests to more old data. <br><br>  This feature allows Metamarkets to save hundreds of thousands of dollars in Druid infrastructure costs each month - as opposed to the alternative if a â€œflatâ€ cluster were used. <br><div style="text-align:center;"><img src="https://habrastorage.org/webt/r0/l1/be/r0l1be1ndua9n7yidhs0vp__4mi.png"></div><br>  <em>Druid query processing node levels</em> <br><br>  As far as I know, ClickHouse and Pinot do not yet have similar functionality - it is assumed that all nodes in their clusters are the same. <br><br>  Due to the fact that the architecture of Pinot is very similar to the architecture of Druid, it seems to me that it will not be too difficult to add a similar function to Pinot.  It will be harder in the case of ClickHouse, since using the concept of â€œsegmentsâ€ is extremely useful for implementing this function, but it is still possible. <br><br><h2>  Data Replication: Druid and Pinot </h2><br>  The unit of replication in Druid and Pinot is a single segment.  Segments are replicated at the deep storage level (for example, in three replicas on HDFS, or using blob storage in Amazon S3), and at the request processing level: usually in Druid and Pinot, each segment is loaded into two different nodes .  A master server monitors replication levels for each segment and loads a segment to a server if the replication factor falls below a given level (for example, if any of the nodes stops responding). <br><br><h2>  Data Replication: ClickHouse </h2><br>  The replication unit in ClickHouse is a section of the table on the server (for example, all data from any table stored on the server).  Similar to sectioning, replication in ClickHouse is â€œstatic and specificâ€ rather than â€œcloud-styleâ€: several servers know that they are replicas of each other (for some particular table; in the case of another table, the replication configuration may differ).  Replication provides both persistence and availability of queries.  When a disk is damaged on one node, the data is not lost, since it is also stored on another node.  When a node is temporarily unavailable, requests can be redirected to the replica. <br><br>  In the largest ClickHouse cluster in Yandex, there are two identical sets of nodes in different data centers, and they are paired.  In each pair, the nodes are replicas of each other (the replication factor of two is used), and they are located in different data centers. <br><br>  ClickHouse relies on ZooKeeper to manage replication - so if you donâ€™t need replication, then you donâ€™t need ZooKeeper either.  This means that ZooKeeper is not required for ClickHouse deployed on a single node. <br><br><h2>  Data Acquisition: Druid and Pinot </h2><br>  In Druid and Pinot, query processing nodes specialize in loading segments and serve requests for data in segments;  they are not engaged in the accumulation of new data and the production of new segments. <br><br>  When a table can be updated with a delay of an hour or more, the segments are created using batch processing engines â€” for example, Hadoop or Spark.  Both Druid and Pinot have first-class Hadoop support out of the box.  There is a <a href="https://github.com/metamx/druid-spark-batch">third-party plugin to support indexing Druid in Spark</a> , but at the moment it is not officially supported.  As far as I know, there is no such level of Spark support in Pinot yet, that is, you should be ready to deal with Pinot interfaces and code, and then write your own code in Java / Scala yourself, even if this should not be too difficult.  (However, since the publication of the original article, Sparkâ€™s support for Pinot <a href="https://github.com/linkedin/pinot/pull/2388">has been contributed by the contributor</a> ). <br><br>  When the table has to be updated in real time, the idea of â€‹â€‹real-time nodes comes to the rescue, which do three things: it receives new data from Kafka (Druid also supports other sources), serves requests with recent data, creates segments in the background and then writes them in the deep repository. <br><br><h2>  Data Absorption: ClickHouse </h2><br>  The fact that ClickHouse does not need to prepare "segments" that contain all the data and fall into specified time intervals allows you to build a simpler data absorption architecture.  ClickHouse does not require a batch processing engine like Hadoop or real-time nodes.  The usual ClickHouse nodes â€” the same ones that handle data storage and serve requests to them â€” accept packet data records directly. <br><br>  If the table is divided into segments, the node that receives the packet entry (for example, 10k rows) distributes the data according to "weights" (see the section below).  Lines are written in one packet, which forms a small "set".  The set is immediately converted to column format.  Each ClickHouse node runs a background process that combines rowsets into even larger sets.  The ClickHouse documentation is strongly tied to the principle known as â€œMergeTreeâ€ and emphasizes the similarity of its work with the <a href="https://ru.wikipedia.org/wiki/LSM-%25D0%25B4%25D0%25B5%25D1%2580%25D0%25B5%25D0%25B2%25D0%25BE">LSM tree</a> , although I am slightly confused because the data is not organized into trees - they lie in a flat columnar format. <br><br><h2>  Data Absorption: Comparison </h2><br>  Data absorption in Druid and Pinot is â€œheavyâ€: it consists of several different services, and managing them is hard work. <br><br>  Data acquisition in ClickHouse is much simpler (which is compensated for by the complexity of managing â€œhistoricalâ€ data â€” that is, not real-time data), but here there is one thing: you should be able to collect data in packets before ClickHouse itself.  Automatic acquisition and batch data collection from <a href="https://clickhouse.yandex/docs/en/table_engines/kafka.html">Kafka is available out of the box</a> , but if you use another source of data in real time (here everything is meant, anything between the query infrastructure, an alternative to Kafka, and streaming processing engines, up to various HTTP-endpoint), then you have to create an intermediate packet collection service, or enter the code directly into ClickHouse. <br><br><h2>  Request execution </h2><br>  <strong>Druid and Pinot</strong> have a separate layer of nodes called â€œ <em>brokers</em> &amp; kaquo;â€ that accept all requests to the system.  They determine which â€œhistoricalâ€ ( <em>containing non-real-time data</em> ) query processing nodes should be sent subqueries based on the mapping of segments to nodes in which segments are loaded.  Brokers store mapping information in memory.  Broker nodes send further subqueries to query processing nodes, and when the results of these subqueries are returned, the broker combines them and returns the final combined result to the user. <br><br>  I do not venture to suggest why when designing Druid and Pinot it was decided to introduce another type of nodes. ,      , ,          ,          .    â€”          .      ,    Druid  Pinot  Â«Â»   . <br><br>  <strong>ClickHouse</strong>      Â« Â»   .  ,  <a href="https://clickhouse.yandex/docs/en/table_engines/distributed.html">Â«Â»  </a>  ClickHouse,       ,          ,    -  Druid  Pinot.        ,     ,         Â« Â»     ClickHouse.         ,               . <br><br>   (      ClickHouse,  -  Druid  Pinot)    ,       -   , ClickHouse  Pinot    :       ,       . <a href="https://medium.com/%40leventov/the-problems-with-druid-at-large-scale-and-high-load-part-1-714d475e84c9">Druid     </a> :       ,       . <br><br><h2> ClickHouse vs. Druid  Pinot:  </h2><br> Â«Â»      Druid  Pinot       ClickHouse    . ,  ,      (   )      (,              ),     . <br><br> <strong>ClickHouse</strong>    RDMBS, , PostgreSQL.  , ClickHouse      .     â€” ,    100  CPU     1 TB ,   ,  ClickHouse     Druid  Pinot           ,   Â«Â», Â«    Â», Â«Â».   , ClickHouse    InfluxDB,   Druid  Pinot. <br><br> <strong>Druid and Pinot</strong>    Big Data  HBase.       ,    ZooKeper,      ( , HDFS),        ,       ,     .    ,  ClickHouse,  Druid  Pinot    .   ,            ,  ,     ..      Â«     Â». <br><br> -,      .        ,     .   <em></em>   .         ,       :             ,           . <br><br><table><tbody><tr><th> <strong>ClickHouse</strong> </th><th> <strong>Druid  Pinot</strong> </th></tr><tr><td>      C++ </td><td>      Java </td></tr><tr><td>   </td><td>   </td></tr><tr><td>   </td><td>   </td></tr><tr><td>    </td><td>     </td></tr><tr><td>        </td><td>             </td></tr><tr><td>   (    )     </td><td>      </td></tr><tr><td>   ( , ,      ..) </td><td>   </td></tr><tr><td>    ,      ,     ,   ,     </td><td>   ,     ,     </td></tr><tr><td>   ,          </td><td>     </td></tr><tr><td>    Hadoop  Spark </td><td>  Hadoop  Spark       </td></tr></tbody></table><br> <strong>:</strong>       ,       (),   .  ,  ,     ,   ,       Druid  Pinot,  ClickHouse.  ,    Druid  Pinot    ,           ClickHouse,           . <br><br><h1>   Druid  Pinot </h1><br>        , Druid  Pinot    .     ,         ,  ,         .   , ,      ,     ,    . <br><br>  Druid  Pinot   <strong>  </strong> ,    ,        â€”  <strong>  </strong>  -. ,            ,      Â«Â»  Â«Â» â€”    ,    . <br><br><h2>    Druid </h2><br> -  Druid (      Pinot)          ,         ,    .     ZooKeeper. , Druid <em> </em>       SQL  ,      Druid.   ,       ,      : <br><br><ul><li>  ZooKeeper <strong>  </strong> .          ,   ,   ,   ZooKeeper.  ,  ,  ,    ,  .. â€”    SQL  . </li><li>      ,      (        â€”     ClickHouse,   Druid,   Pinot),            ZooKeeper,    Â« Â»      SQL.         , <strong>  Â«Â»    </strong> ,        . </li><li>       ,      <strong> Druid  ZooKeeper </strong> .  ZooKeeper     :  ,      (,       ).    <a href="https://groups.google.com/d/msg/druid-development/eIWDPfhpM_U/Em06lGjhAwAJ">  Consul</a> .      <a href="https://groups.google.com/d/msg/druid-development/tWnwPyL0Vk4/2uLwqgQiAAAJ">  HTTP-</a> ,      ,     ZooKeeper Â«Â»   SQL. </li></ul><br>          SQL,      , ,       -  SQL. Druid  MySQL  PostgreSQL,     Microsoft SQL Server.  ,  Druid   ,       RDBMS â€”  , Amazon RDS. <br><br><h2>    Pinot </h2><br>    Druid,           <a href="https://curator.apache.org/">Curator</a>    ZooKeeper, Pinot          <a href="https://helix.apache.org/"> Helix</a> . <br><br>   ,   ,     Pinot       .  Helix   ,      Druid,          , ,      . <br><br>   , Helix   Pinot  Â« Â». Helix,  , <strong>Pinot,      ZooKeeper </strong> . <br><br>         Druid  Pinot â€”   ,               ,     . <br><br><h2> Â« Â»  Pinot </h2><br>        Kafka  -  , Pinot  ,        ,        , -    ,           . <br><br>      Â« <strong>predicate pushdown</strong> Â»         . <br><br>    Druid    ,      Hadoop,     ,       . Druid     Â« Â»  . <br><br><h2> Â«Â» Druid   Pinot </h2><br>  Druid           ,             Â«Â»: <br><br><ul><li> HDFS, Cassandra, Amazon S3, Google Cloud Storage  Azure Blob Storage  ..   Â« Â»; </li><li> Kafka, r RabbitMQ, Samza,  Flink,  Spark, Storm,  .. ( <a href="https://github.com/druid-io/tranquility">Tranquility</a> )        ; </li><li>  Druid,  Graphite,  Ambari,  StatsD,  Kafka   Â«Â»    Druid (). </li></ul><br>     Pinot       LinkedIn       ,  ,   ,   .   Â« Â»   HDFS  Amazon S3,          Kafka.   -   ,  ,           Pinot.   ,       ,  <a href="https://www.slideshare.net/XIANGFU3/pinot-near-realtime-analytics-uber">Uber</a>  Slack   Pinot. <br><br><h2>          Pinot </h2><br>  ,   <a href="https://github.com/linkedin/pinot/wiki/Architecture">  Pinot</a>    Druid: <br><br><ul><li> <strong>  </strong>   ,     Druid. </li><li> <strong>  </strong>   .  Druid   ,    ,      .      Druid  Pinot, <a href="https://www.slideshare.net/XIANGFU3/pinot-near-realtime-analytics-uber/17">   Uber   </a> ,     . </li><li> <strong>   </strong>     . </li><li> <strong>    </strong> .  Druid          (     Â«CloudFlare: ClickHouse  DruidÂ»).     ,     Pinot â€”      Druid  Pinot    (  !),    Uber. </li><li> <strong> </strong> ,    ,       Pinot,   Druid. </li></ul><br> ,       Druid.    ,   Pinot   ,   Druid,       ,   .   : Pinot (  Druid)      ( Zstd)       <a href="http://www.vldb.org/pvldb/vol8/p1816-teller.pdf">Gorilla</a> . <br><br>   Uber      count (*)    Druid  Pinot    [ <a href="https://www.slideshare.net/XIANGFU3/pinot-near-realtime-analytics-uber/18">1</a> , <a href="https://www.slideshare.net/XIANGFU3/pinot-near-realtime-analytics-uber/19">2</a> ],    Druid     ,      <a href="https://github.com/druid-io/druid/issues/4065"> O(1) </a> .          Â« Â»,     . <br><br>   ,       <code>GROUP BY,</code>    Uber,         Druid,        . <br><br><h2>  Druid      ()  </h2><br>  Pinot        ,     ,    .  Druid    ;      ,   <strong></strong> <strong> </strong> <strong>   </strong> <strong></strong> ,          ,      .           Metamarkets  <strong>30â€“40%</strong> . ,     ,   -    â€”    <a href="https://metamarkets.com/2016/distributing-data-in-druid-at-petabyte-scale/">  </a> . <br><br>  ,   LinkedIn            Pinot, ,  ,       ,          . <br><br><h2> Pinot         </h2><br>       Â« Â»,  -     ,    ,  Pinot        -    . <br>  Druid     . <br><br><h2>      Druid </h2><br>    . Druid           ,     Â«Â»   Â« CPU, RAM /   Â»  ,                  . <br><br>   ,  Pinot      . <br><br><h1>  Conclusion </h1><br> <strong>ClickHouse, Druid  Pinot    </strong> ,       Big Data-    Impala, Presto, Spark,         ,    ,  InfluxDB. <br><br>    , ClickHouse, Druid  Pinot   Â« Â».     , <strong>    </strong>      .       (    )    -   . <br><br><blockquote>            â€”    ,        ,  ,       . </blockquote><br>    , ClickHouse      Druid  Pinot â€”     Druid  Pinot  ,             . <br><br> ClickHouse   Â«Â»    PostgreSQL. ClickHouse     .    ( 1 TB ,  100  CPU), ClickHouse     ,  Druid  Pinot â€”        â€”   ,  ClickHouse        .    ,          InfluxDB  Prometheus,    Druid  Pinot. <br><br> Druid  Pinot     Big Data   Hadoop.    Â«Â»       ( 500 ),     ClickHouse        SRE.  , Druid  Pinot          ,      ,  ClickHouse. <br><br>     Druid  Pinot  ,  Pinot    Helix      ZooKeeper,     Druid      ZooKeeper.   ,  Druid     - SQL- .   , Pinot  ,  Druid. <br><br><blockquote>             ,            :          (   )  . , ,      .       ( <strong> 9 </strong> )  <a href="http://ritfest.ru/">++</a>  : <a href="http://frontendconf.ru/"></a> , <a href="http://backendconf.ru/"></a> , <a href="http://rootconf.ru/"></a>  <a href="http://whalerider.ru/"></a> .        ,            â€” ,      . </blockquote></div><p>Source: <a href="https://habr.com/ru/post/351308/">https://habr.com/ru/post/351308/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../351294/index.html">FastTrack Training. "Network Basics". "The Basics of Telephony." Part 2. Eddie Martin. December 2012</a></li>
<li><a href="../351296/index.html">Blockchain on Go. Part 3: Permanent Memory and Command Line Interface</a></li>
<li><a href="../351298/index.html">Apache PHP MySQL bundle on Solaris 11.3</a></li>
<li><a href="../351300/index.html">Analysis of performance tasks with JBreak (part 2)</a></li>
<li><a href="../351304/index.html">Thymeleaf Tutorial: Chapter 7. Conditional Execution</a></li>
<li><a href="../351310/index.html">SSH in humans is not secure enough. How I struggle with paranoia</a></li>
<li><a href="../351312/index.html">3. Check Point for maximum. Content Awareness</a></li>
<li><a href="../351316/index.html">Introvert management introverts or experience managing technical teams</a></li>
<li><a href="../351318/index.html">John Carmack: Weekly vacation spent programming</a></li>
<li><a href="../351320/index.html">Profiling: measurement and analysis</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>