<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>How to solve the old problem with ML in Python and .Net</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="It happens that some tasks pursue you for many years. For me, such a task was the gluing of sentences of texts in which the transition to a new line i...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>How to solve the old problem with ML in Python and .Net</h1><div class="post__text post__text-html js-mediator-article"><p><img src="https://habrastorage.org/webt/bm/pi/vr/bmpivrmqylxi0ypvqte57qsnadw.png"></p><br><p>  It happens that some tasks pursue you for many years.  For me, such a task was the gluing of sentences of texts in which the transition to a new line is rigidly scored, and often also the transfer of words.  In practice, it is extracted from a PDF or using OCR text.  Often it was possible to find such texts on the websites of online libraries, in the archives of old documents, which were edited by DOS editors.  And such formatting greatly hinders then the correct breakdown into sentences (and with hyphenation, into tokens) for subsequent NLP processing.  Yes, and trite show such a document in the search results - it will be ugly. </p><br><p>  I solved this problem several times - on Delphi, C #.  Then it was a hard algorithm, where he wrote with his hands, for example, what could be the width of the text, so that the text was considered formatted "as before".  It did not always work perfectly, but in general, it was enough. </p><a name="habracut"></a><br><p>  At the moment, I crawl on some ML projects in Python.  At one point, it turned out that the next corpus of documents consists of texts extracted from PDF versions of scientific articles.  Of course, the text was extracted with a rigid breakdown of the paragraph paragraph characters, with hyphenation.  That is, to work normally with such texts was no longer possible.  Python attracts the fact that it has almost everything!  But a couple of hours of searching did not give anything sane (perhaps, of course, I was looking for this).  And then I decided once again to write a postprocessor for such documents.  The choice was of two options - to port your past code with C #, or write something that could be taught.  Finally, I was led to the second approach by the fact that the scientific texts were partially exported from two-column texts, and partly from single-column texts.  Also different font sizes.  This led to the fact that the old version, with its hard-wired admissible boundaries, often worked incorrectly.  Sitting by hand again select options - well, no, soon the <a href="https://ru.wikipedia.org/wiki/%25D0%25A2%25D0%25B5%25D1%2585%25D0%25BD%25D0%25BE%25D0%25BB%25D0%25BE%25D0%25B3%25D0%25B8%25D1%2587%25D0%25B5%25D1%2581%25D0%25BA%25D0%25B0%25D1%258F_%25D1%2581%25D0%25B8%25D0%25BD%25D0%25B3%25D1%2583%25D0%25BB%25D1%258F%25D1%2580%25D0%25BD%25D0%25BE%25D1%2581%25D1%2582%25D1%258C">singularity will come</a> , I do not have time for that!  So, it is decided - we are writing a library that uses machine learning. </p><br><p>  All code can be found <a href="https://github.com/serge-sotnyk/pdf-lines-gluer">in the repository</a> : </p><br><ul><li>  <a href="https://github.com/serge-sotnyk/pdf-lines-gluer/blob/master/pdf_gluer.ipynb">Laptop with steps</a> </li><li>  <a href="https://github.com/serge-sotnyk/pdf-lines-gluer/blob/master/pdf_lines_gluer.py">Auxiliary utilities (at the same time and a pattern for code generation)</a> </li><li>  <a href="https://github.com/serge-sotnyk/pdf-lines-gluer/blob/master/pdf_preprocessor.py">Generated code</a> </li><li>  <a href="https://github.com/serge-sotnyk/pdf-lines-gluer/tree/master/corpus">The body of the marked (and not only) documents</a> </li></ul><br><h1 id="razmetka">  Markup </h1><br><p>  What is the buzz and complexity of machine learning - if the algorithm fails somewhere, you often do not need to change the program itself.  It is enough to collect new data (often they need to be annotated) and restart the construction of the model.  The computer will do the rest for you.  Of course, there is a chance that new data will have to come up with new features, change the architecture, but in most cases it turns out to get by just checking that everything began to work well.  This is also a challenge - typing and marking data can be difficult.  Or very difficult.  And also - scary bored :-) </p><br><p>  So the most boring is markup.  The <a href="https://github.com/serge-sotnyk/pdf-lines-gluer/tree/master/corpus">corpus folder</a> contains documents that I just took from the body of the Krapivin2009 documents I worked with at that moment.  There are 10 documents that seemed typical to me.  I marked only 3, because already at the start of training on this base, a sufficient quality of the "glue stick" was obtained.  If in the future it turns out that everything is not so simple, then new documents with markup will appear in this folder and the learning process will repeat. </p><br><p>  In this case, it seemed to me convenient that the files remain text, so the markup format was to add a sign at the beginning of the line that this line should be glued to the previous one (the '+' character) or not (the '*' character).  Here is a fragment (file <a href="https://github.com/serge-sotnyk/pdf-lines-gluer/blob/master/corpus/1005058.txt">1005058.txt</a> ): </p><br><pre><code class="plaintext hljs">*Introduction *Customers on the web are often overwhelmed with options and flooded with promotional messages for +products or services they neither need nor want. When users cannot find what they are searching for, the +e-commerce site struggles to maintain good customer relations. *Employing a recommender system as part of a site's Customer Relationship Management (CRM) activities +can overcome the problems associated with providing users with too little information, or too much of +the wrong information. Recommender systems are able to assist customers during catalog browsing and are +an effective way to cross-sell and improve customer loyalty. *In this paper, we will compare several recommender systems being used as an essential component of +CRM tools under development at Verizon. Our solutions are purposely for the current customers and current +products - recommendations for new customers and new products are out of the scope of this paper.</code> </pre> <br><p>  A couple of hours of tedious work and 3 files with 2300 examples (one line - one sample) are ready.  This is already sufficient in many cases for simple classifiers such as logistic regression, which has been applied further. </p><br><h1 id="fichi">  Features </h1><br><p>  Classifiers do not work directly with textual data.  At the entrance they are given features - either numbers or boolean signs (which, again, are translated into the numbers 0/1) that there is some kind of feature or not.  Designing the right features from good data is the key to machine learning success.  A feature of our case is that our corpus is English texts.  And I want to get at least the minimum language independence.  At least within European languages.  Therefore, for text features, we apply a little trick. </p><br><p>  Converting text into a list of features and labels, whether to glue with the previous line, is performed by the auxiliary function <a href="https://github.com/serge-sotnyk/pdf-lines-gluer/blob/master/pdf_lines_gluer.py">_featurize_text_with_annotation</a> : </p><br><pre> <code class="python hljs">x, y = pdf_lines_gluer._featurize_text_with_annotation(raw_text)</code> </pre> <br><p>  Note - hereinafter, mostly python code snippets are going on, which you <a href="https://github.com/serge-sotnyk/pdf-lines-gluer/blob/master/pdf_gluer.ipynb">can see completely in the laptop</a> . </p><br><p>  Used features: </p><br><ul><li>  'this_len' is the length of the current string in characters. </li><li>  'mean_len' is the average length of lines in the range -5 ... + 5 lines. </li><li>  'prev_len' is the length of the previous line in characters. </li><li>  'first_chars' - here is our cunning feature.  The first 2 characters of the string are placed here.  But at the same time, all lower case letters (of any alphabet) are replaced by the English character 'a', uppercase letters - by 'A', numbers - by '0'.  This significantly reduces the number of possible signs, while generalizing them.  Examples of what happens: 'Aa', 'aa', 'AA', '0.', 'a-' ... </li><li>  'isalpha' - whether the letter is the last character of the previous line. </li><li>  'isdigit' - whether the digit is the last character of the previous line. </li><li>  'islower' - whether the last character of the previous line is a lowercase letter. </li><li>  'punct' - punctuation mark, which ends the previous line, or a space for other symbols. </li></ul><br><p>  An example of a feature set for a single line: </p><br><pre> <code class="plaintext hljs">{'this_len': 12, 'mean_len': 75.0, 'prev_len': 0, 'first_chars': 'Aa', 'isalpha': False, 'isdigit': False, 'islower': False, 'punct': ' '}</code> </pre> <br><p>  In order to work with them the classifier from the sklearn package, we use the DictVectorizer class, with which string features (we have 'first_chars'), are converted into several columns entitled (names can be obtained via <a href="https://scikit-learn.org/stable/modules/feature_extraction.html">get_feature_names ()</a> ) as' first_chars = Aa ',' first_chars = 0. '.  Boolean features turn into zeros and ones, and numeric values ‚Äã‚Äãremain numbers ‚Äî field names do not change.  Outside, the method returns a numpy.array of approximately the following form (only one line is shown): </p><br><pre> <code class="plaintext hljs">[[ 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 39.1 30. 0. 1. 36. ]]</code> </pre> <br><h1 id="trenirovka-klassifikatora">  Classifier Training </h1><br><p>  Having received a set of features in the form of an array of floating-point numbers, we can now start the learning process.  For this, we use logistic regression as a classifier.  Classes are unbalanced, so we set the option class_weight = 'balanced', check the result on the test part of the body: </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.linear_model <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> LogisticRegression <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.metrics <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> classification_report clf = LogisticRegression(random_state=<span class="hljs-number"><span class="hljs-number">1974</span></span>, solver=<span class="hljs-string"><span class="hljs-string">'liblinear'</span></span>, max_iter=<span class="hljs-number"><span class="hljs-number">2000</span></span>, class_weight=<span class="hljs-string"><span class="hljs-string">'balanced'</span></span>) clf.fit(x_train, y_train) y_pred = clf.predict(x_test) print(classification_report(y_true=y_test, y_pred=y_pred))</code> </pre> <br><p>  We get the following quality indicators: </p><br><pre> <code class="plaintext hljs"> precision recall f1-score support False 0.82 0.92 0.86 207 True 0.96 0.91 0.94 483 accuracy 0.91 690 macro avg 0.89 0.91 0.90 690 weighted avg 0.92 0.91 0.91 690</code> </pre> <br><p>  As you can see, approximately in 1/10 of the cases we have errors of various kinds.  But in practice, it's not so scary.  The fact is that even when marking with the eye it is not always clear where the end of the paragraph is, and where the end of the sentence is.  Therefore, even the markup itself may contain such errors.  But the most critical mistakes are not where they occur at the boundary of the proposal, but where the proposal remains broken.  And there are very few such errors in reality. </p><br><h1 id="vosstanavlivaem-tekst">  Restore text </h1><br><p>  It is time to recover text corrupted by extracting from PDF.  We can already determine whether we need to glue the string with the previous one, but there is one more thing - hyphenation.  Everything is pretty straightforward, so I coded this part hard (let me pseudo-code): </p><br><pre> <code class="plaintext hljs">     :         :       :      :        \n</code> </pre> <br><p>  Armed with this strategy, we restore the English text (there are errors in the type of "ff" and "fi" in the original - it is simply copied from the body of Krapivin2009): </p><br><div class="spoiler">  <b class="spoiler_title">Original English text</b> <div class="spoiler_text"><pre> <code class="python hljs">text = <span class="hljs-string"><span class="hljs-string">"""The rapid expansion of wireless services such as cellular voice, PCS (Personal Communications Services), mobile data and wireless LANs in recent years is an indication that signicant value is placed on accessibility and portability as key features of telecommunication (Salkintzis and Mathiopoulos (Guest Ed.), 2000). devices have maximum utility when they can be used any- where at anytime". One of the greatest limitations to that goal, how- ever, is nite power supplies. Since batteries provide limited power, a general constraint of wireless communication is the short continuous operation time of mobile terminals. Therefore, power management is y Corresponding Author: Dr. Krishna Sivalingam. Part of the research was supported by Air Force Oce of Scientic Research grants F-49620-97-1- 0471 and F-49620-99-1-0125; by Telcordia Technologies and by Intel. Part of the work was done while the rst author was at Washington State Univer- sity. The authors' can be reached at cej@bbn.com, krishna@eecs.wsu.edu, pagrawal@research.telcordia.com, jcchen@research.telcordia.com c 2001 Kluwer Academic Publishers. Printed in the Netherlands. Jones, Sivalingam, Agrawal and Chen one of the most challenging problems in wireless communication, and recent research has addressed this topic (Bambos, 1998). Examples include a collection of papers available in (Zorzi (Guest Ed.), 1998) and a recent conference tutorial (Srivastava, 2000), both devoted to energy ecient design of wireless networks. Studies show that the signicant consumers of power in a typical laptop are the microprocessor (CPU), liquid crystal display (LCD), hard disk, system memory (DRAM), keyboard/mouse, CDROM drive, oppy drive, I/O subsystem, and the wireless network interface card (Udani and Smith, 1996, Stemm and Katz, 1997). A typical example from a Toshiba 410 CDT mobile computer demonstrates that nearly 36% of power consumed is by the display, 21% by the CPU/memory, 18% by the wireless interface, and 18% by the hard drive. Consequently, energy conservation has been largely considered in the hardware design of the mobile terminal (Chandrakasan and Brodersen, 1995) and in components such as CPU, disks, displays, etc. Signicant additional power savings may result by incorporating low-power strategies into the design of network protocols used for data communication. This paper addresses the incorporation of energy conservation at all layers of the protocol stack for wireless networks. The remainder of this paper is organized as follows. Section 2 introduces the network architectures and wireless protocol stack considered in this paper. Low-power design within the physical layer is brie y discussed in Section 2.3. Sources of power consumption within mobile terminals and general guidelines for reducing the power consumed are presented in Section 3. Section 4 describes work dealing with energy ecient protocols within the MAC layer of wireless networks, and power conserving protocols within the LLC layer are addressed in Section 5. Section 6 discusses power aware protocols within the network layer. Opportunities for saving battery power within the transport layer are discussed in Section 7. Section 8 presents techniques at the OS/middleware and application layers for energy ecient operation. Finally, Section 9 summarizes and concludes the paper. 2. Background This section describes the wireless network architectures considered in this paper. Also, a discussion of the wireless protocol stack is included along with a brief description of each individual protocol layer. The physical layer is further discussed. """</span></span> corrected = pdf_lines_gluer._preprocess_pdf(text, clf, v) print(corrected)</code> </pre> </div></div><br><p>  After recovery we get: </p><br><div class="spoiler">  <b class="spoiler_title">Recovered English text</b> <div class="spoiler_text"><p>  In recent years, there has been an indication of the number of mobile services that have been given to mobile communication and wireless LANs. .), 2000).  It‚Äôs not a problem that it can be used at any time. It is the Corresponding Author: Dr. Krishna Sivalingam who has been a research team supported by F-49620-97-10471 and F-49620-99-1-0125; by Telcordia Technologies and by Intel. At the State University of the United States of America, the author of the article was at cej@bbn.com, krishna@eecs.wsu.edu, pagrawal@research.telcordia.com, jcchen@research.telcordia.com c <br>  2001 Kluwer Academic Publishers.  Printed in the Netherlands. <br>  Jones, Sivalingam, Agrawal and Chen have agreed to choose this topic (Bambos, 1998).  Examples include a collection of papers available in (Zorzi, (Guest Ed.), 1998) and a recent conference tutorial (Srivastava, 2000), <br>  Studies of the microprocessor (CPU), liquid crystal display (LCD), hard disk, system memory (DRAM), keyboard / mouse, CDROM drive, oppy drive, I / O subsystem, and the wireless network interface card (Udani and Smith, 1996, Stemm and Katz, 1997).  A typical example from a Toshiba 410 CDT mobile computer demonstrates that nearly 36% of the CPU power consumption, <br>  18% by the wireless interface, and 18% by the hard drive.  Consequently, it has been financed by its mobile terminal design (Chandrakasan and Brodersen, 1995) and in components such as CPU, disks, displays, etc.  Signicant additional power savings can be achieved by incorporating low-power strategies used for data communication.  Addresses for wireless networks. <br>  It is organized as follows.  Section 2 introduces the network protocol and wireless protocol stack in this paper.  Low-power design <br>  discussed in Section 2.3.  SECTION 4: SECTION 4: SECTION 4: SECTION 3 <br>  5. Section 6 discusses power aware protocols within the network layer.  There is a possibility to discuss the use of energy. <br>  Finally, Section 9 summarizes and concludes the paper. <br>  2. Background <br>  This section describes the wireless network architectures considered in this paper.  It is also possible to review the individual protocol layer.  The physical layer is further discussed. </p></div></div><br><p>  There is one controversial place, but in general, sentences have been restored and such text can already be processed as whole sentences. </p><br><p>  But we planned to make a language independent option.  And that is exactly what our feature set targets.  Let's check in the Russian text (also a fragment of the text from the PDF): </p><br><div class="spoiler">  <b class="spoiler_title">Original Russian text</b> <div class="spoiler_text"><pre> <code class="python hljs">ru_text = <span class="hljs-string"><span class="hljs-string">"""       -       (. 1.10),    ,   - .       ,      , -   .       ,       .          : 1.        ,       -  (   ,   . 1.10,    ). 2.    ( )           ,     .      ,     ."""</span></span> corrected = pdf_lines_gluer._preprocess_pdf(ru_text, clf, v) print(corrected)</code> </pre> </div></div><br><p>  Got: </p><br><div class="spoiler">  <b class="spoiler_title">Recovered Russian text</b> <div class="spoiler_text"><p>  The support vector method is designed to solve classification problems by searching for good decision boundaries (Fig. 1.10) separating two sets of points belonging to different categories.  The decisive boundary can be a line or surface dividing a sample of training data into spaces belonging to two categories.  To classify new points, you only need to check on which side of the border they are located. <br>  The search for such boundaries is the support vector machine in two stages: <br>  1. Data is displayed in a new space of higher dimension, where the border can be represented as a hyperplane (if the data were two-dimensional, as in Figure 1.10, the hyperplane degenerates into a line). <br>  2. A good decision boundary (separating the hyperplane) is calculated by maximizing the distance from the hyperplane to the nearest points of each class, this stage is called the gap maximization.  This allows us to generalize the classification of new samples that do not belong to the training data set. </p></div></div><br><p>  Everything is perfect here. </p><br><h1 id="kak-polzovatsya-kodogeneraciya">  How to use (code generation) </h1><br><p>  Initially, I had a plan to make a package that can be delivered using PIP, but then I came up with an easier way (for me).  The feature set was not very large, the logistic regression itself and the DictVectorizer have a simple structure: </p><br><ul><li>  With DictVectorizer, it‚Äôs enough to save the feature <em>names</em> and vocabulary_ </li><li>  LogisticRegression - coef <em>, classes</em> , intercept_ </li></ul><br><p>  Therefore, another version was born with code generation (in the laptop it goes in the section "Serialize as code"): </p><br><ol><li>  We read the <a href="https://github.com/serge-sotnyk/pdf-lines-gluer/blob/master/pdf_lines_gluer.py">pdf_lines_gluer.py</a> file, which contains auxiliary code for vectorization and text recovery using a trained classifier. </li><li>  In the place designated in the source code as "# inject code here #", we insert the code initializing DictVectorizer and LogisticRegression in the state that we got in the laptop after the training.  We also inject here the only public (as far as possible for Python) function preprocess_pdf: <br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">preprocess_pdf</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(text: str)</span></span></span><span class="hljs-function"> -&gt; str:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> _preprocess_pdf(text, _clf, _v)</code> </pre> </li><li>  The resulting code is written to the <a href="https://github.com/serge-sotnyk/pdf-lines-gluer/blob/master/pdf_preprocessor.py">pdf_preprocessor.py</a> file <a href="https://github.com/serge-sotnyk/pdf-lines-gluer/blob/master/pdf_preprocessor.py">.</a> </li></ol><br><p>  It is this generated pdf_preprocessor.py file that contains everything we need.  To use it - just take this one file and drop it into your project.  Using: </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> pdf_preprocessor <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> preprocess_pdf ... print(preprocess_pdf(text))</code> </pre> <br><p>  If you have any problems with some texts, this is what you need to do: </p><br><ol><li>  Put your texts in the corpus folder, annotate them. </li><li>  Start your laptop <a href="https://github.com/serge-sotnyk/pdf-lines-gluer/blob/master/pdf_gluer.ipynb">https://github.com/serge-sotnyk/pdf-lines-gluer/blob/master/pdf_gluer.ipynb</a> - it takes less than 5 seconds for me on current texts. </li><li>  Take away and test the new version of the pdf_preprocessor.py file </li></ol><br><p>  Perhaps something will go wrong and the quality will not satisfy you.  Then it will be somewhat more difficult - you will need to add new features until you find their correct combination. </p><br><h1 id="c-i-mlnet">  C # and ML.NET </h1><br><p>  In our company, most of the backend code is based on .Net.  Of course, interaction with Python adds inconvenience here.  And I would like to have a similar solution in C #.  Long time followed the development of the <a href="https://dotnet.microsoft.com/apps/machinelearning-ai/ml-dotnet">ML.NET</a> framework.  I made small attempts to do something in the past year, but they were disappointed by the insufficient coverage of various cases, a small amount of documentation, API instability.  Since spring of this year, the framework has moved to the release state and I decided to try it again.  Moreover, the most tedious work with the markings of the case has already been done. </p><br><p>  At first glance, the framework added in convenience.  More often I began to find the necessary documentation (although, it‚Äôs still far from quality and quantity in sklearn).  But most importantly - a year ago I still almost did not know sklearn.  And now I began to see that many things in ML.NET were trying to do in the image and likeness (as far as possible, given the difference in platforms).  These analogies have simplified the assimilation of ML.NET principles in practice. </p><br><p>  A working project on this platform can look at <a href="">https://github.com/serge-sotnyk/pdf-postprocess.cs</a> </p><br><p>  The general principles remain the same - in the folder corpus are anotised (and not very) documents.  Having started the ModelCreator project, next to the corpus folder, we will see the models folder, where the archive with the trained model will be placed.  This is all the same logistic regression with the same features. </p><br><p>  But here I didn‚Äôt bother with code generation.  To use the trained model, take the PdfPostprocessor project (which inside has the PdfPostprocessModel.zip model compiled as a resource inside).  After that, the model can be used as shown in the minimal example - <a href="">https://github.com/serge-sotnyk/pdf-postprocess.cs/blob/master/MinimalUsageExample/Program.cs</a> : </p><br><pre> <code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">using</span></span> PdfPostprocessor; ... <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">static</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">Main</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">string</span></span></span></span><span class="hljs-function"><span class="hljs-params">[] args</span></span></span><span class="hljs-function">)</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> postprocessor = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Postprocessor(); Console.WriteLine(); Console.WriteLine(<span class="hljs-string"><span class="hljs-string">"Restored paragraphs in the English text:"</span></span>); Console.WriteLine(postprocessor.RestoreText(EnText)); Console.WriteLine(); Console.WriteLine(<span class="hljs-string"><span class="hljs-string">"Restored paragraphs in the Russian text:"</span></span>); Console.WriteLine(postprocessor.RestoreText(RuText)); }</code> </pre> <br><p>  While the model is being copied from the models folder to the PdfPostprocessor project, it is done manually - it was more convenient for me to better control which model would fall into the final project. </p><br><p>  There is nuget-package - PdfPostprocessor.  To use the package and the model that you trained, use the overloaded version of the Postprocessor constructor. </p><br><h1 id="sravnenie-variantov-na-python-i-c35">  Comparing options in Python and C # </h1><br><p>  While the thrill of developing on two platforms is fresh, it may be worthwhile to briefly retell them.  I have not been a militant supporter of this or that platform for a long time and I understand the feelings of believers of different confessions with understanding.  You also need to understand that I still work with static-typed languages ‚Äã‚Äãfor most of my life, so they are just a little closer to me. </p><br><h3 id="chto-ne-ponravilos-pri-perehode-na-c35">  What did not like when switching to C # </h3><br><ul><li>  Verbosity.  Yet the code on Python is smaller.  This is the absence of operator brackets, and brackets after if, for.  Lack of endless new.  Active use of fields, since they are easy to turn into properties if necessary.  Even to the fact that privacy in Python, which is simply indicated by underlining an identifier at the beginning, you get used to it and in practice turned out to be very convenient, more convenient than a bunch of privacy modifiers in other languages.  And the brevity of designs speeds up development and makes it easier to read code. </li><li>  In most cases, the code on Python looks cleaner and more elegant (this is just subjective).  From this it is also easier to read and maintain. </li><li>  On Python, for almost everything, there is some kind of function or decorator in some kind of package, but in C # a lot has to be added.  This further inflates the code with various helper functions, classes.  And more time consuming. </li><li>  The degree of documentation of C # and its frameworks is significantly lower than in the Python ecosystem. </li><li>  The stricter ML.NET typing compared to the omnivorous sklearn also made it necessary to spend some time in search of the right transformations, and the previous paragraph did not help to resolve this issue. </li></ul><br><h3 id="chto-ponravilos-pri-perehode-na-c35">  What did you like when switching to C # </h3><br><ul><li>  A sense of security.  Already not very often, but quite regularly, Python omnivorousness leads me to subtle problems.  And now, when porting code to C #, there was an error that made some features useless.  After correction, accuracy rose by a couple of percent. </li><li>  Speed.  The code on Python had to abandon the features that were tied to what kind of gluing decision was made in the past sentences - if you submit the proposal classifier one by one, then the overall speed will turn out to be lower than the baseboard.  In order for data processing on Python to be fast, it is necessary to vectorize it as much as possible and sometimes it makes you refuse from potentially useful options, or it is very difficult to make them. </li><li>  Linq.  They are much more convenient than List Comprehension (LC) in Python.  Even LC with one for makes me write at the beginning what after in, then go back to the beginning and finish the for, and only then write the expression at the beginning of the LC.  Just in that order, I think - the source of records, items, what to convert.  LINQ (  "" )     .    LC (  for)   . ,       ,   . </li><li> Lambda.    ,   .   ,   C#   . </li></ul><br><p>      ‚Äî      .      ,    .Net     ,   .    -  ‚Äî   REST       C#. </p><br><p>  C#   .            ‚Äî      ,    - .   Microsoft     Kotlin ‚Äî    .Net      ,         .          Python- ‚Äî ,     <a href="https://en.wikipedia.org/wiki/Julia_(programming_language)">Julia</a> .      . </p><br><h1 id="zaklyuchenie">  Conclusion </h1><br><p>    : </p><br><ul><li>   ,     ‚Äî  ,    ,   -    . , ,   -   . </li><li>    .  ,   ML.NET     - .       . </li><li> ,    Python-     .Net.         , . </li></ul></div>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <p>Source: <a href="https://habr.com/ru/post/457072/">https://habr.com/ru/post/457072/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../457062/index.html">Cosmonaut Training Center in Star City</a></li>
<li><a href="../457064/index.html">On the issue of modules</a></li>
<li><a href="../457066/index.html">How to finalize the FEDOR robot and the flight chair for the ISS</a></li>
<li><a href="../457068/index.html">Queues - what is it, why and how to use? Look at the possibilities of AWS SQS</a></li>
<li><a href="../457070/index.html">Textolite instead of cardboard. A couple of words about the interactive badge OFFZONE 2019</a></li>
<li><a href="../457074/index.html">Evolution of developers: what games to expect in the future</a></li>
<li><a href="../457078/index.html">How to turn your avatar in Telegram into a clock</a></li>
<li><a href="../45708/index.html">Software self motivation</a></li>
<li><a href="../457082/index.html">Imperceptible issuance of administrator rights</a></li>
<li><a href="../457084/index.html">How to live with professional lighting. Videos from Badoo Techleads Meetup # 4</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>