<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Algorithm for Improved Self-Organizing Growing Neural Network (ESOINN)</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Introduction 
 In my previous article on non-teacher machine learning methods, the basic algorithm SOINN , an algorithm for constructing self-organizi...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Algorithm for Improved Self-Organizing Growing Neural Network (ESOINN)</h1><div class="post__text post__text-html js-mediator-article"><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/8b7/428/ba8/8b7428ba84069f21c6f605d112a61668.jpg"></div><br><h1>  Introduction </h1><br>  In my <a href="http://habrahabr.ru/post/192978/">previous article</a> on non-teacher machine learning methods, the basic algorithm <abbr title="Self-Organizing Incremental Neural Network">SOINN</abbr> , an algorithm for constructing self-organizing growing neural networks, was considered.  As noted, the basic model of the SOINN network has a number of drawbacks that do not allow it to be used for learning in the lifetime mode (ie, for learning during the whole lifetime of the network).  These shortcomings included a two-layer network structure that required, with minor changes in the first layer of the network, retrain the second layer completely.  The algorithm also had many customizable parameters, which made it difficult to use when working with real data. <br><br>  This article will discuss the An Enhanced Self-Organizing Incremental Neural Network algorithm, which is an extension of the basic SOINN model and partially solves the voiced problems. <br><a name="habracut"></a><br><h1>  General idea of ‚Äã‚ÄãSOINN class algorithms </h1><br>  The main idea of ‚Äã‚Äãall SOINN algorithms is to build a probabilistic data model based on the images provided to the system.  In the process of learning, SOINN class algorithms build a graph, each vertex of which lies in the region of the local maximum of the probability density, and the edges connect the vertices belonging to the same classes.  The meaning of this approach is to assume that the classes form regions of high probability density in space, and we are trying to construct a graph that most accurately describes such regions and their mutual arrangement.  In the best way this idea can be illustrated as follows: <br><br>  1) For incoming input data, a graph is constructed so that the vertices fall in the region of the local maximum of the probability density.  So we get a graph, for each vertex of which we can construct some function that describes the distribution of input data in the corresponding region of space. <br> <a href="https://habr.com/ru/post/206116/"><img src="https://habrastorage.org/getpro/habr/post_images/d7e/662/feb/d7e662feb6848edd3ebe6de3778b3628.png"></a> <br>  2) The graph as a whole is a mixture of distributions, by analyzing which, you can determine the number of classes in the source data, their spatial distribution, and other characteristics. <br> <a href="https://habr.com/ru/post/206116/"><img src="https://habrastorage.org/getpro/habr/post_images/d1d/f2e/982/d1df2e98214a0c2c1711c4c656e5d8fb.png"></a> 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h1>  <abbr title="An Enhanced Self-Organizing Incremental Neural Network">ESOINN</abbr> Algorithm </h1><br>  We now turn to the consideration of the algorithm ESOINN.  As mentioned earlier, the ESOINN algorithm is derived from the basic learning algorithm for self-organizing growing neural networks.  Like the basic SOINN algorithm, the algorithm in question is intended for online (and even lifetime) learning without a teacher and without the ultimate goal of learning.  The main difference between ESOINN and the algorithm considered earlier is that the network structure is single-layered here and, as a result, has a smaller number of tunable parameters and greater flexibility in learning during the entire operation time of the algorithm.  Also, in contrast to the basic network, where the winning nodes were always connected by an edge, a condition for creating a connection appeared in the extended algorithm, taking into account the mutual arrangement of the classes to which the winning nodes belong.  The addition of such a rule allowed the algorithm to successfully separate the close and partially overlapping classes.  Thus, the ESOINN algorithm attempts to solve the problems identified by the basic SOINN algorithm. <br><br>  Further, the algorithm for constructing the ESOINN network will be considered in detail. <br><br><h2>  Flow chart </h2><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/625/a69/963/625a699630ad6ea524aac8820fd63320.png"></div><br><br><h2>  Algorithm Description </h2><br><br><h3>  Used notation </h3><br><img src="https://habrastorage.org/getpro/habr/post_images/a23/8fa/4ac/a238fa4ace56f4f2dbc2a3890683ceec.png">  - a set of graph nodes. <br><img src="https://habrastorage.org/getpro/habr/post_images/433/cef/9cf/433cef9cf9292cc540b36c46df55b946.png">  - set of graph edges. <br><img src="https://habrastorage.org/getpro/habr/post_images/833/413/19c/83341319c76c566b6ecae23682df13b1.png">  - number of nodes in <img src="https://habrastorage.org/getpro/habr/post_images/a23/8fa/4ac/a238fa4ace56f4f2dbc2a3890683ceec.png">  . <br><img src="https://habrastorage.org/getpro/habr/post_images/8c7/e8c/28e/8c7e8c28eebd8d3aea69ed4f568254dd.gif">  - feature vector of the object submitted to the input of the algorithm. <br><img src="https://habrastorage.org/getpro/habr/post_images/76a/c81/221/76ac81221b58319e015213dd98b59589.gif">  - vector of signs of the i-th vertex of the graph. <br><img src="https://habrastorage.org/getpro/habr/post_images/735/5cd/c85/7355cdc858f0a853193ac9b47dc43807.gif">  - the number of accumulated signals of the i-th vertex of the graph. <br><img src="https://habrastorage.org/getpro/habr/post_images/6d7/471/d1c/6d7471d1ce366ce7ba124922ada455dd.gif">  - density at the i-th vertex of the graph. <br><br><h3>  Algorithm </h3><br><ol><li>  Initialize a set of nodes <img src="https://habrastorage.org/getpro/habr/post_images/a23/8fa/4ac/a238fa4ace56f4f2dbc2a3890683ceec.png">  two nodes with feature vectors taken randomly from the range of acceptable values. <br>  Initialize a set of links <img src="https://habrastorage.org/getpro/habr/post_images/68a/494/ba5/68a494ba5f4bd19de0eb607dc432ac69.png">  empty set. <br></li><li>  Submit the input feature feature vector to the input. <img src="https://habrastorage.org/getpro/habr/post_images/8c7/e8c/28e/8c7e8c28eebd8d3aea69ed4f568254dd.gif">  . <br></li><li>  Find the nearest node <img src="https://habrastorage.org/getpro/habr/post_images/bd9/a38/f71/bd9a38f7166b9f71cc50f6fa834ab145.png">  (winner) and second closest knot <img src="https://habrastorage.org/getpro/habr/post_images/4b8/c82/23e/4b8c8223ea469393325dd8dfa26c7164.png">  (second winner) like: <br><img src="https://habrastorage.org/getpro/habr/post_images/18d/6c8/16b/18d6c816ba74d1e36b6d985e851f64c5.png"><br><img src="https://habrastorage.org/getpro/habr/post_images/f1e/61c/558/f1e61c5582d8001a5303bd0f61e990f8.png"><br></li><li>  If the distance between the feature vector of the input object and <img src="https://habrastorage.org/getpro/habr/post_images/bd9/a38/f71/bd9a38f7166b9f71cc50f6fa834ab145.png">  or <img src="https://habrastorage.org/getpro/habr/post_images/4b8/c82/23e/4b8c8223ea469393325dd8dfa26c7164.png">  greater than some predetermined threshold <img src="https://habrastorage.org/getpro/habr/post_images/149/7a6/c36/1497a6c365d26abf0f7b81701cb4779d.png">  or <img src="https://habrastorage.org/getpro/habr/post_images/c39/291/4d1/c392914d187d05780c8b1206f323f426.png">  , it creates a new node (Add a new node to <img src="https://habrastorage.org/getpro/habr/post_images/a23/8fa/4ac/a238fa4ace56f4f2dbc2a3890683ceec.png">  and go to step 2). <br><img src="https://habrastorage.org/getpro/habr/post_images/149/7a6/c36/1497a6c365d26abf0f7b81701cb4779d.png">  and <img src="https://habrastorage.org/getpro/habr/post_images/c39/291/4d1/c392914d187d05780c8b1206f323f426.png">  calculated by the formulas: <br><img src="https://habrastorage.org/getpro/habr/post_images/bc6/912/f11/bc6912f110d4a90dfa15a4f0f9210c51.png">  (if the top has neighbors) <br><img src="https://habrastorage.org/getpro/habr/post_images/f82/13d/a18/f8213da18a7876f8f2d441d08015a722.png">  (if the top has no neighbors) <br></li><li>  Increase the age of all edges emanating from <img src="https://habrastorage.org/getpro/habr/post_images/bd9/a38/f71/bd9a38f7166b9f71cc50f6fa834ab145.png">  by 1. <br></li><li>  Using <b>Algorithm 2</b> , determine if a connection is needed between <img src="https://habrastorage.org/getpro/habr/post_images/bd9/a38/f71/bd9a38f7166b9f71cc50f6fa834ab145.png">  and <img src="https://habrastorage.org/getpro/habr/post_images/4b8/c82/23e/4b8c8223ea469393325dd8dfa26c7164.png">  : <br><ol><li>  If necessary: ‚Äã‚Äãif edge <img src="https://habrastorage.org/getpro/habr/post_images/0e7/6d7/5d4/0e76d75d45239ed551d279c0c8845130.png">  exists, then reset its age, otherwise create an edge <img src="https://habrastorage.org/getpro/habr/post_images/0e7/6d7/5d4/0e76d75d45239ed551d279c0c8845130.png">  and set its age to 0. <br></li><li>  If this is not necessary: ‚Äã‚Äãif the edge exists, then delete it. <br></li></ol><br></li><li>  Increase the number of signals accumulated by the winner according to the formula: <img src="https://habrastorage.org/getpro/habr/post_images/08d/863/b93/08d863b930602016a627cae7e0949267.png">  . <br></li><li>  Update the winner‚Äôs density using the formula: <img src="https://habrastorage.org/getpro/habr/post_images/7f9/0aa/6ce/7f90aa6cefe83b843a62ac0d9749f931.gif">  where <img src="https://habrastorage.org/getpro/habr/post_images/e55/d22/a80/e55d22a80537ab467275d3375d4c2aae.gif">  - the average distance between nodes within the cluster to which the winner belongs.  It is calculated by the formula: <img src="https://habrastorage.org/getpro/habr/post_images/dbe/7cb/054/dbe7cb0542e336385810b8acf502e33c.gif">  . <br></li><li>  Adapt the vector of signs of the winner and its topological neighbors with weights <img src="https://habrastorage.org/getpro/habr/post_images/89a/1dc/b33/89a1dcb33f3ef1a7b95ba20f784a1131.png">  and <img src="https://habrastorage.org/getpro/habr/post_images/edc/587/854/edc587854cc40c60ef491dfe11f6d4d1.png">  by the formulas: <br><img src="https://habrastorage.org/getpro/habr/post_images/42c/368/97a/42c36897a60127c6c5fa4486c450b231.png"><br><img src="https://habrastorage.org/getpro/habr/post_images/c8a/c9d/2f0/c8ac9d2f02e49a1ae8da079d57b09828.gif"><br>  We use the same adaptation scheme as in the basic SOINN algorithm: <br><img src="https://habrastorage.org/getpro/habr/post_images/dde/a4f/f71/ddea4ff71ea27696fa72d80619bc9642.png"><br><img src="https://habrastorage.org/getpro/habr/post_images/490/b5b/9d1/490b5b9d10bfe878fe81e08f6518b54a.png"><br></li><li>  Find and remove those edges whose age exceeds a certain threshold value. <img src="https://habrastorage.org/getpro/habr/post_images/389/140/237/38914023795ee0b31caf4b6de480847e.png">  . <br></li><li>  If the number of input signals generated so far is a multiple of some parameter <img src="https://habrastorage.org/getpro/habr/post_images/88b/7c1/be9/88b7c1be96a1f4b3f5f0bd054dd90b96.png">  , then: <br><ol><li>  Update class labels for all nodes using <b>Algorithm 1</b> . <br></li><li>  Remove the nodes that are noise, as follows: <br><ol><li>  For all nodes <img src="https://habrastorage.org/getpro/habr/post_images/25d/a00/65b/25da0065be84e92e2a654ad31e915907.png">  of <img src="https://habrastorage.org/getpro/habr/post_images/8de/917/dbe/8de917dbe909501d233158d1a64c3046.png">  : if a node has two neighbors and <img src="https://habrastorage.org/getpro/habr/post_images/a5c/2db/3e2/a5c2db3e2249b3169b0c11d3f0b010a3.gif">  , then delete this node. <br></li><li>  For all nodes <img src="https://habrastorage.org/getpro/habr/post_images/25d/a00/65b/25da0065be84e92e2a654ad31e915907.png">  of <img src="https://habrastorage.org/getpro/habr/post_images/8de/917/dbe/8de917dbe909501d233158d1a64c3046.png">  : if the node has one neighbor and <img src="https://habrastorage.org/getpro/habr/post_images/a99/21f/b6f/a9921fb6f17e7acabcfbeba11f7312f9.png">  , then delete this node. <br></li><li>  For all nodes <img src="https://habrastorage.org/getpro/habr/post_images/25d/a00/65b/25da0065be84e92e2a654ad31e915907.png">  of <img src="https://habrastorage.org/getpro/habr/post_images/8de/917/dbe/8de917dbe909501d233158d1a64c3046.png">  : if the node has no neighbors, then delete it. <br></li></ol><br></li></ol><br></li><li>  If the learning process is completed, then classify the nodes of different classes (using the algorithm for selecting <a href="http://ru.wikipedia.org/wiki/%25D0%259A%25D0%25BE%25D0%25BC%25D0%25BF%25D0%25BE%25D0%25BD%25D0%25B5%25D0%25BD%25D1%2582%25D0%25B0_%25D1%2581%25D0%25B2%25D1%258F%25D0%25B7%25D0%25BD%25D0%25BE%25D1%2581%25D1%2582%25D0%25B8_%25D0%25B3%25D1%2580%25D0%25B0%25D1%2584%25D0%25B0">related components of the</a> graph), then report the number of classes, the prototype vector for each class, and stop the learning process. <br></li><li>  Go to step 2 to continue learning without a teacher if the learning process is not finished yet. <br></li></ol><br><br><h4>  Algorithm 1: Division of the composite class into subclasses </h4><br><ol><li>  A node is called a vertex of a class if it has the maximum density in a neighborhood.  Find all such vertices in the composite class and assign them different labels. <br></li><li>  Assign the remaining vertices to the same classes as the corresponding vertices. <br></li><li>  Nodes lie in the area of ‚Äã‚Äãoverlapping classes, if they belong to different classes and have a common edge. <br></li></ol><br>  In practice, this method of class division into subclasses leads to the fact that in the presence of noise a large class can be falsely classified as several small classes.  Therefore, before you divide the classes, you need to smooth them. <br><br>  Suppose we have two unsmootted classes: <br><div style="text-align:center;"> <a href="https://habr.com/ru/post/206116/"><img src="https://habrastorage.org/getpro/habr/post_images/449/312/ca3/449312ca388e2d1998f0839eb7902535.png"></a> </div><br>  Take a subclass <img src="https://habrastorage.org/getpro/habr/post_images/4c4/a23/675/4c4a236755489100d2c99d57e6f88d4f.png">  and subclass <img src="https://habrastorage.org/getpro/habr/post_images/d58/2ac/dd3/d582acdd3bd168b3a055cdfc71be71b9.png">  .  Suppose the vertex density of a subclass <img src="https://habrastorage.org/getpro/habr/post_images/4c4/a23/675/4c4a236755489100d2c99d57e6f88d4f.png">  equals <img src="https://habrastorage.org/getpro/habr/post_images/a1c/7cf/67d/a1c7cf67d24e8d23c8239a38ee1f52ae.png">  , and have a subclass <img src="https://habrastorage.org/getpro/habr/post_images/d58/2ac/dd3/d582acdd3bd168b3a055cdfc71be71b9.png">  equals <img src="https://habrastorage.org/getpro/habr/post_images/094/187/193/0941871930b5de7cd1f2a537dff9a95f.png">  .  Combine <img src="https://habrastorage.org/getpro/habr/post_images/4c4/a23/675/4c4a236755489100d2c99d57e6f88d4f.png">  and <img src="https://habrastorage.org/getpro/habr/post_images/d58/2ac/dd3/d582acdd3bd168b3a055cdfc71be71b9.png">  in one subclass if the following conditions are met: <br><img src="https://habrastorage.org/getpro/habr/post_images/834/4b0/d21/8344b0d2126a02abbabb188e65b9845f.png"><br>  or <br><img src="https://habrastorage.org/getpro/habr/post_images/4d8/274/2ee/4d82742ee39935f58142d361b0673ac3.png"><br>  Here, the first and second winners are in the area of ‚Äã‚Äãoverlapping subclasses. <img src="https://habrastorage.org/getpro/habr/post_images/4c4/a23/675/4c4a236755489100d2c99d57e6f88d4f.png">  and <img src="https://habrastorage.org/getpro/habr/post_images/d58/2ac/dd3/d582acdd3bd168b3a055cdfc71be71b9.png">  .  Parameter <img src="https://habrastorage.org/getpro/habr/post_images/246/1b3/ea7/2461b3ea77d0bee675c8ad006f983bfb.png">  is calculated as follows: <br><img src="https://habrastorage.org/getpro/habr/post_images/6eb/7f8/0c3/6eb7f80c316a6b1df172a50b9bd77b07.png">  where <img src="https://habrastorage.org/getpro/habr/post_images/4a0/fe8/f28/4a0fe8f285a8a8992c70838237390b60.png">  - average density of nodes in a subclass <img src="https://habrastorage.org/getpro/habr/post_images/4c4/a23/675/4c4a236755489100d2c99d57e6f88d4f.png">  . <br><br>  After that, remove all edges connecting vertices of different classes.  Thus, we divide the composite class into subclasses that do not overlap. <br><br><h4>  Algorithm 2: Building a connection between vertices </h4><br>  Connect two nodes in the event that: <br><ol><li>  At least one of them is a new node (it is not yet determined to which subclass it belongs). <br></li><li>  They belong to the same class. <br></li><li>  They belong to different classes, and the conditions for the merging of these classes are fulfilled (conditions from <b>Algorithm 1</b> ). <br></li></ol><br>  Otherwise we do not connect these nodes, and if the connection between them exists, then we delete it. <br><br>  By using <b>Algorithm 1</b> when checking the need to create an edge between nodes, the ESOINN algorithm will try to find a ‚Äúbalance‚Äù between unnecessary class separation and combining different classes into one.  This property allows successful clustering of closely spaced classes. <br><br><h2>  Algorithm Discussion </h2><br>  Using the algorithm shown above, we first find a pair of vertices with the feature vectors closest to the input signal.  Then we decide whether the input signal belongs to one of the already known classes or is it a representative of a new class.  Depending on the answer to this question, we either create a new class on the network, or adjust the already known class corresponding to the input signal.  In the event that the learning process lasts quite a long time, the network adjusts its structure, separating the unlike and combining similar subclasses.  After the training is completed, we classify all the nodes into different classes. <br><br>  As you can see, in the course of its work, the network can learn new information, while not forgetting all that it has learned earlier.  This property allows to some extent solve the stability-plasticity dilemma and makes the network ESOINN suitable for lifetime education. <br><br><h1>  Experiments </h1><br>  To conduct experiments with the presented algorithm, it was implemented in C ++ using the Boost Graph Library.  The code is posted on <a href="https://github.com/BelBES/ESOINN">GitHub</a> . <br><br>  A competition for the classification of handwritten numbers based on MNIST, on the website <a href="https://www.kaggle.com/c/digit-recognizer">kaggle.com, was used</a> as a platform for experiments.  The training data contains 48000 images of handwritten numbers 28x28 pixels in size and having 256 shades of gray, presented in the form of 784-dimensional vectors. <br><br>  We received the results of the classification in a non-stationary environment (that is, the network continued to learn during the classification of the test sample). <br><br>  The network parameters were taken as follows: <br><img src="https://habrastorage.org/getpro/habr/post_images/233/c9e/ec5/233c9eec5dc2f8f8181c9c3bef6c4c6d.png">  = 200 <br><img src="https://habrastorage.org/getpro/habr/post_images/e45/320/b7b/e45320b7b3570d3233b6d1fc72f9796c.png">  = 50 <br><img src="https://habrastorage.org/getpro/habr/post_images/c86/b50/c4f/c86b50c4ff12c8075cc751d73f79be5e.png">  = 0.0001 <br><img src="https://habrastorage.org/getpro/habr/post_images/940/e46/100/940e461004b296719e3c61563c3e8052.png">  = 1.0 <br><br>  As a result of the work, the network identified 14 clusters whose centers are as follows: <br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/3ed/3ae/165/3ed3ae16599912241f2d5413ae1585f5.png"></div><br><br>  At the time of this writing, ESOINN occupied an honorable 191 place in the rating with an accuracy of 0.96786 for 25% of the test sample, which is not so bad for an algorithm that initially had no a priori information about the input data. <br><img src="https://habrastorage.org/getpro/habr/post_images/672/5d2/368/6725d23683bd83e621bfca330a495e11.png"><br><br><h1>  Conclusion </h1><br>  This article has reviewed a modified learning algorithm for growing ESOINN neural networks.  Unlike the basic SOINN algorithm, the ESOINN algorithm has only one layer and can be used for a lifetime of study.  Also, the ESOINN algorithm allows working with partially overlapping and fuzzy classes, which the basic version of the algorithm did not know how.  The number of algorithm parameters was reduced by half, which makes it easier to configure the network when working with real data.  The experiment showed the operability of the considered algorithm. <br><br><h1>  Literature </h1><br><ol><li><a name="paper1"></a>  <a href="https://github.com/BelBES/ESOINN/blob/master/e-soinn.pdf">‚ÄúAn enhanced self-organizing incremental neural network for online unsupervised learning‚Äù Shen Furaoa, Tomotaka Ogurab, Osamu Hasegawab, 2007</a> . <br></li><li><a name="paper2"></a>  <a href="http://watanabe-www.math.dis.titech.ac.jp/syllabus/atmis/Hasegawa1.pdf">Osamu Hasegawa from Tokyo Institute of Technology at IIT Bombay.</a> <br></li><li><a name="paper3"></a>  <a href="http://www.youtube.com/watch%3Fv%3DTmbVHngdUPw">Osamu Hasegawa from the Tokyo Institute of Technology at IIT Bombay (video).</a> <br></li><li><a name="paper4"></a>  Website of the <a href="http://haselab.info/">Hasegawa Lab</a> , which studies self-organizing growing neural networks. <br></li></ol></div><p>Source: <a href="https://habr.com/ru/post/206116/">https://habr.com/ru/post/206116/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../206104/index.html">Quantization Matrix Manipulation</a></li>
<li><a href="../206106/index.html">Derek Sivers: Why are my programs and ideas public?</a></li>
<li><a href="../206108/index.html">First Steam Machines arrived to owners</a></li>
<li><a href="../206110/index.html">The digest of news from the world of mobile development for the last week ‚Ññ33 (December 9-15, 2013)</a></li>
<li><a href="../206112/index.html">FrontendSimpleEdit - a simple content editor for the external part of the site on MODX Revolution</a></li>
<li><a href="../206120/index.html">Simple Unity State Machine</a></li>
<li><a href="../206122/index.html">Cheap USB PC Button</a></li>
<li><a href="../206124/index.html">FT232H and almost universal USB <-> JTAG adapter for 15 euros</a></li>
<li><a href="../206126/index.html">Foxconn nanoPC AT-7300 nettop review on Intel Core i3-3217U</a></li>
<li><a href="../206128/index.html">Electronics and seals: we collect a robot toy for a cat on STM32</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>