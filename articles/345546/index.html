<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Asynchronous loading of large datasets into Tensorflow</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Deep neural networks are now a trendy topic. 


 There are a lot of tutorials and video lectures on the web, and other materials discussing the basic ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Asynchronous loading of large datasets into Tensorflow</h1><div class="post__text post__text-html js-mediator-article"><p>  Deep neural networks are now a trendy topic. </p><br><p>  There are a lot of tutorials and video lectures on the web, and other materials discussing the basic principles of building neural networks, their architecture, learning strategies, etc.  Traditionally, neural networks are trained by displaying a neural network of image packets from a training sample and correcting the coefficients of this network <a href="https://ru.wikipedia.org/wiki/%25D0%259C%25D0%25B5%25D1%2582%25D0%25BE%25D0%25B4_%25D0%25BE%25D0%25B1%25D1%2580%25D0%25B0%25D1%2582%25D0%25BD%25D0%25BE%25D0%25B3%25D0%25BE_%25D1%2580%25D0%25B0%25D1%2581%25D0%25BF%25D1%2580%25D0%25BE%25D1%2581%25D1%2582%25D1%2580%25D0%25B0%25D0%25BD%25D0%25B5%25D0%25BD%25D0%25B8%25D1%258F_%25D0%25BE%25D1%2588%25D0%25B8%25D0%25B1%25D0%25BA%25D0%25B8">using the back propagation error method</a> .  One of the most popular tools for working with neural networks is Google's <a href="https://www.tensorflow.org/">Tensorflow</a> library. </p><br><p>  The neural network in Tensorflow is represented by a sequence of layer operations. <br>  (such as matrix multiplication, <a href="https://ru.wikipedia.org/wiki/%25D0%25A1%25D0%25B2%25D1%2591%25D1%2580%25D1%2582%25D0%25BE%25D1%2587%25D0%25BD%25D0%25B0%25D1%258F_%25D0%25BD%25D0%25B5%25D0%25B9%25D1%2580%25D0%25BE%25D0%25BD%25D0%25BD%25D0%25B0%25D1%258F_%25D1%2581%25D0%25B5%25D1%2582%25D1%258C">convolution</a> , pooling, etc.).  The layers of the neural network, together with the operations of adjusting the coefficients, form a calculation graph. </p><br><p>  The learning process of the neural network in this case consists in the "presentation" of the neural <br>  networks of object packages, comparing predicted classes with true ones, calculations <br>  errors and modifications of neural network coefficients. </p><br><p>  In this case, Tensoflow hides the technical details of the training and the implementation of the coefficient adjustment algorithm, and from the programmer's point of view, one can speak mostly only about the computation graph, which produces ‚Äúpredictions‚Äù.  Compare the computation graph that the programmer thinks about. </p><br><p><img src="https://habrastorage.org/webt/4d/ui/dt/4duidtqhdydft4ys2ahttbj9ysm.png" alt="Predicticting graph"></p><br><p>  with the graph which, among other things, performs the adjustment of coefficients </p><br><p><img src="https://habrastorage.org/webt/lj/af/3c/ljaf3cwewgd3tzbezgev4izejto.png" alt="Training graph">  . </p><br><p>  But what Tensorflow cannot do for a programmer is to convert the input dataset into a convenient for training neural network.  Although the library has quite a few "basic blocks". </p><br><p>  How to use them to build an effective conveyor for the "power" ( <em>feed</em> ) neural network input data and I want to tell in this article. </p><a name="habracut"></a><br><p>  As an example of the problem, <a href="http://www.image-net.org/">ImageNet</a> datasset will be used, which was recently published as a <a href="https://www.kaggle.com/c/imagenet-object-detection-challenge">competition for detecting objects on Kaggle.</a> We will train the network to detect one object, the one with the largest bounding box. </p><br><p>  If you have not tried to work with this library, it may be worth exploring the basic concepts, for example, in the <a href="https://habrahabr.ru/company/ods/blog/324898/">Tensorflow deep learning library</a> article, or on the <a href="https://www.tensorflow.org/">official website.</a> </p><br><h1>  Preparatory steps </h1><br><p>  The following assumes that you have </p><br><ul><li>  [Python] [python_org] is installed, the examples use Python 2.7, <br>  but there should be no difficulty in porting them to Python 3. * </li><li>  library [Tensorflow and Python interface to it] [install_tensorflow] </li><li>  downloaded and unpacked [dataset] [download_dataset] from Kaggle competition </li></ul><br><p>  Traditional library aliases: </p><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np</code> </pre> <br><h1>  Data preprocessing </h1><br><p>  To load data, we will use the mechanisms provided by the <a href="https://www.tensorflow.org/versions/master/api_guides/python/input_dataset">module for working with</a> datasets in Tensorflow. </p><br><p>  For training and validation, we need a dataset, in which both images and their descriptions are at the same time.  But in the downloaded dataset files with images and annotations are neatly laid out in different daddies. </p><br><p>  Therefore, we will make an iterator that is iterated over the corresponding pairs. </p><br><pre> <code class="python hljs">ANNOTATION_DIR = os.path.join(<span class="hljs-string"><span class="hljs-string">"Annotations"</span></span>, <span class="hljs-string"><span class="hljs-string">"DET"</span></span>) IMAGES_DIR = os.path.join(<span class="hljs-string"><span class="hljs-string">"Data"</span></span>, <span class="hljs-string"><span class="hljs-string">"DET"</span></span>) IMAGES_EXT = <span class="hljs-string"><span class="hljs-string">"JPEG"</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">image_annotation_iterator</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(dataset_path, subset=</span></span><span class="hljs-string"><span class="hljs-function"><span class="hljs-params"><span class="hljs-string">"train"</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">""" Yields tuples of image filename and corresponding annotation. :param dataset_path: Path to the root of uncompressed ImageNet dataset :param subset: one of 'train', 'val', 'test' :return: iterator """</span></span> annotations_root = os.path.join(dataset_path, ANNOTATION_DIR, subset) <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> annotations_root images_root = os.path.join(dataset_path, IMAGES_DIR, subset) <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> images_root <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> dir_path, _, file_names <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> os.walk(annotations_root): <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> annotation_file <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> file_names: path = os.path.join(dir_path, annotation_file) relpath = os.path.relpath(path, annotations_root) img_path = os.path.join( images_root, os.path.splitext(relpath)[<span class="hljs-number"><span class="hljs-number">0</span></span>] + <span class="hljs-string"><span class="hljs-string">'.'</span></span> + IMAGES_EXT ) <span class="hljs-keyword"><span class="hljs-keyword">assert</span></span> os.path.isfile(img_path), \ RuntimeError(<span class="hljs-string"><span class="hljs-string">"File {} doesn't exist"</span></span>.format(img_path)) <span class="hljs-keyword"><span class="hljs-keyword">yield</span></span> img_path, path</code> </pre> <br><p>  From this, you can already make a dataset and run "processing on the graph", <br>  for example, retrieve file names from dataset. <br>  We create: </p><br><pre> <code class="python hljs">files_dataset = tf.data.Dataset.from_generator( functools.partial(image_annotation_iterator, <span class="hljs-string"><span class="hljs-string">"./ILSVRC"</span></span>), output_types=(tf.string, tf.string), output_shapes=(tf.TensorShape([]), tf.TensorShape([])) )</code> </pre> <br><p>  To extract data from dataset, we need an iterator <br>  <code>make_one_shot_iterator</code> will create an iterator that passes through <br>  given once.  <code>Iterator.get_next()</code> creates a tensor in which to load <br>  data from the iterator. </p><br><pre> <code class="python hljs">iterator = files_dataset.make_one_shot_iterator() next_elem = iterator.get_next()</code> </pre> <br><p>  Now you can create a session and "calculate the values" of the tensor: </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">with</span></span> tf.Session() <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> sess: <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">10</span></span>): element = sess.run(next_elem) <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> i, element</code> </pre> <br><p>  But for use in neural networks, we need not file names, but images in the form of "three-layer" matrices of the same form and the category of these images in the form of <a href="https://ru.wikipedia.org/wiki/%25D0%25A3%25D0%25BD%25D0%25B8%25D1%2582%25D0%25B0%25D1%2580%25D0%25BD%25D1%258B%25D0%25B9_%25D0%25BA%25D0%25BE%25D0%25B4">"one hot" vector</a> </p><br><h3 id="kodiruem-kategorii-izobrazheniy">  We encode categories of images </h3><br><p>  Parsing annotation files is not very interesting by itself.  I used the <a href="https://pypi.python.org/pypi/beautifulsoup4">BeautifulSoup</a> package for this.  <code>Annotation</code> helper class can initialize from the file path and store a list of objects.  First we need to compile a list of categories in order to know the size of the vector for encoding <code>cat_max</code> .  And also make the display of string categories in the number of <code>[0..cat_max]</code> .  The creation of such mappings is also not very interesting, we will further assume that the <code>cat2id</code> and <code>id2cat</code> contain the forward and reverse mapping described above. </p><br><p>  The function of converting a file name into a coded category vector. </p><br><p>  You can see that another category is added for the background: in some images no objects are marked. </p><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">ann_file2one_hot</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(ann_file)</span></span></span><span class="hljs-function">:</span></span> annotation = reader.Annotation(<span class="hljs-string"><span class="hljs-string">"unused"</span></span>, ann_file) category = annotation.main_object().cls result = np.zeros(len(cat2id) + <span class="hljs-number"><span class="hljs-number">1</span></span>) result[cat2id.get(category, len(cat2id))] = <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> result</code> </pre> <br><p>  Apply the transformation to dataset: </p><br><pre> <code class="python hljs">dataset = file_dataset.map( <span class="hljs-keyword"><span class="hljs-keyword">lambda</span></span> img_file_tensor, ann_file_tensor: (img_file_tensor, tf.py_func(ann_file2one_hot, [ann_file_tensor], tf.float64)) )</code> </pre> <br><p>  The <code>map</code> method returns a new dataset, in which a function is applied to each line of the initial dataset.  The function does not actually apply until we started to iterate over the resulting dataset. </p><br><p>  You can also notice that we wrapped our function in <code>tf.py_func</code> .  as parameters, the tensors are included in the transformation function, and not the values ‚Äã‚Äãthat lie in them. </p><br><p>  And to work with strings, this wrapper is needed. </p><br><h3 id="zagruzhaem-izobrazhenie">  Upload an image </h3><br><p>  In Tensorflow there is a rich <a href="https://www.tensorflow.org/api_docs/python/tf/image">library for working with images</a> .  Use it to download them.  We need to: read the file, decode it into a matrix, bring the matrix to a standard size (for example, the average), normalize the values ‚Äã‚Äãin this matrix. </p><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">image_parser</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(file_name)</span></span></span><span class="hljs-function">:</span></span> image_data = tf.read_file(file_name) image_parsed = tf.image.decode_jpeg(image_data, channels=<span class="hljs-number"><span class="hljs-number">3</span></span>) image_parsed = tf.image.resize_image_with_crop_or_pad(image_parsed, <span class="hljs-number"><span class="hljs-number">482</span></span>, <span class="hljs-number"><span class="hljs-number">415</span></span>) image_parsed = tf.cast(image_parsed, dtype=tf.float16) image_parsed = tf.image.per_image_standardization(image_parsed) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> image_parsed</code> </pre> <br><p>  Unlike the previous function, here the <code>file_name</code> is a tensor, which means we don‚Äôt need to wrap this function, we will add it to the previous snippet: </p><br><pre> <code class="python hljs">dataset = file_dataset.map( <span class="hljs-keyword"><span class="hljs-keyword">lambda</span></span> img_file_tensor, ann_file_tensor: ( image_parser(img_file_tensor), tf.py_func(ann_file2one_hot, [ann_file_tensor], tf.float64) ) )</code> </pre> <br><p>  Let's check that our graph of graphs produces something meaningful: </p><br><pre> <code class="python hljs"> iterator = dataset.make_one_shot_iterator() next_elem = iterator.get_next() <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> type(next_elem[<span class="hljs-number"><span class="hljs-number">0</span></span>]) <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> tf.Session() <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> sess: <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">3</span></span>): element = sess.run(next_elem) <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> i, element[<span class="hljs-number"><span class="hljs-number">0</span></span>].shape, element[<span class="hljs-number"><span class="hljs-number">1</span></span>].shape</code> </pre> <br><p>  It should work: </p><br><pre> <code class="hljs lisp"><span class="hljs-number"><span class="hljs-number">0</span></span> (<span class="hljs-number"><span class="hljs-number">482</span></span>, <span class="hljs-number"><span class="hljs-number">415</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>) (<span class="hljs-number"><span class="hljs-number">201</span></span>,) <span class="hljs-number"><span class="hljs-number">1</span></span> (<span class="hljs-number"><span class="hljs-number">482</span></span>, <span class="hljs-number"><span class="hljs-number">415</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>) (<span class="hljs-number"><span class="hljs-number">201</span></span>,) <span class="hljs-number"><span class="hljs-number">2</span></span> (<span class="hljs-number"><span class="hljs-number">482</span></span>, <span class="hljs-number"><span class="hljs-number">415</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>) (<span class="hljs-number"><span class="hljs-number">201</span></span>,)</code> </pre> <br><p>  As a rule, at the very beginning it would be necessary to divide the dataset into 2 or 3 parts for training / validation / testing.  We will use the division for training and validation from the downloaded archive. </p><br><h1>  Designing a Calculation Graph </h1><br><p>  We will train a convolutional neural network (English convolutional neural netwrok, CNN) by a method similar to a <a href="https://habrahabr.ru/company/ods/blog/326418/">stochastic gradient descent</a> , but we will use its improved version of <a href="">Adam</a> .  To do this, we need to combine our instances into "packages" (eng. Batch).  In addition, to utilize multiprocessing (and, at best, the availability of a GPU for training), you can enable background data paging </p><br><pre> <code class="python hljs">BATCH_SIZE = <span class="hljs-number"><span class="hljs-number">16</span></span> dataset = dataset.batch(BATCH_SIZE) dataset = dataset.prefetch(<span class="hljs-number"><span class="hljs-number">2</span></span>)</code> </pre> <br><p>  We will combine the packages on <code>BATCH_SIZE</code> instances and pump up 2 such packages. </p><br><p>  During training, we want to periodically drive validation, on a sample that does not participate in training.  So we need to repeat all the manipulations above for another dataset. </p><br><p>  Fortunately, all of them can be combined into a function such as <code>dataset_from_file_iterator</code> and create two datasets: </p><br><pre> <code class="python hljs">train_dataset = dataset_from_file_iterator( functools.partial(image_annotation_iterator, <span class="hljs-string"><span class="hljs-string">"./ILSVRC"</span></span>, subset=<span class="hljs-string"><span class="hljs-string">"train"</span></span>), cat2id, BATCH_SIZE ) valid_dataset = ... <span class="hljs-comment"><span class="hljs-comment">#     subset="val"</span></span></code> </pre> <br><p>  But since we want to continue using the same graph of calculations for training and validation, we will create a more flexible iterator.  That which allows him to reinitialize. </p><br><pre> <code class="python hljs"> iterator = tf.data.Iterator.from_structure( train_dataset.output_types, train_dataset.output_shapes ) train_initializer_op = iterator.make_initializer(train_dataset) valid_initializer_op = iterator.make_initializer(valid_dataset)</code> </pre> <br><p>  Later, after performing this or that operation, we can switch the iterator from one dataset to <br>  other. </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">with</span></span> tf.Session(config=config, graph=graph) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> sess: sess.run(train_initialize_op) <span class="hljs-comment"><span class="hljs-comment">#  # ... sess.run(valid_initialize_op) #  # ...</span></span></code> </pre> <br><p>  For teprey we need to describe our neural network, but we will not go into this question. <br>  We assume that the <code>semi_alex_net_v1(mages_batch, num_labels)</code> function <code>semi_alex_net_v1(mages_batch, num_labels)</code> builds the desired architecture and returns a tensor with output values ‚Äã‚Äãpredicted by the neural network. </p><br><p>  Let us set the error function, and subtleties, the optimization operation: </p><br><pre> <code class="python hljs">img_batch, label_batch = iterator.get_next() logits = semi_alexnet_v1.semi_alexnet_v1(img_batch, len(cat2id)) loss = tf.losses.softmax_cross_entropy( logits=logits, onehot_labels=label_batch) labels = tf.argmax(label_batch, axis=<span class="hljs-number"><span class="hljs-number">1</span></span>) predictions = tf.argmax(logits, axis=<span class="hljs-number"><span class="hljs-number">1</span></span>) correct_predictions = tf.reduce_sum(tf.to_float(tf.equal(labels, predictions))) optimizer = tf.train.AdamOptimizer().minimize(loss)</code> </pre> <br><h1>  Training and validation cycle </h1><br><p>  Now you can start learning: </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">with</span></span> tf.Session() <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> sess: sess.run(tf.local_variables_initializer()) sess.run(tf.global_variables_initializer()) sess.run(train_initializer_op) counter = tqdm() total = <span class="hljs-number"><span class="hljs-number">0.</span></span> correct = <span class="hljs-number"><span class="hljs-number">0.</span></span> <span class="hljs-keyword"><span class="hljs-keyword">try</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> <span class="hljs-keyword"><span class="hljs-keyword">True</span></span>: opt, l, correct_batch = sess.run([optimizer, loss, correct_predictions]) total += BATCH_SIZE correct += correct_batch counter.set_postfix({ <span class="hljs-string"><span class="hljs-string">"loss"</span></span>: <span class="hljs-string"><span class="hljs-string">"{:.6}"</span></span>.format(l), <span class="hljs-string"><span class="hljs-string">"accuracy"</span></span>: correct/total }) counter.update(BATCH_SIZE) <span class="hljs-keyword"><span class="hljs-keyword">except</span></span> tf.errors.OutOfRangeError: <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> <span class="hljs-string"><span class="hljs-string">"Finished training"</span></span></code> </pre><br><p>  Above, we create a session, initialize global and local variables in the graph, initialize the iterator with training data.  [tqdm] [tgdm] does not apply to the learning process, it is simply a convenient tool for visualizing progress. </p><br><p>  In the context of the same session, we launch and validation: the validation cycle looks very similar.  The main difference: the optimization operation does not start. </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">with</span></span> tf.Session() <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> sess: <span class="hljs-comment"><span class="hljs-comment"># Train # ... # Validate counter = tqdm() sess.run(valid_initializer_op) total = 0. correct = 0. try: while True: l, correct_batch = sess.run([loss, correct_predictions]) total += BATCH_SIZE correct += correct_batch counter.set_postfix({ "loss": "{:.6}".format(l), "valid accuracy": correct/total }) counter.update(BATCH_SIZE) except tf.errors.OutOfRangeError: print "Finished validation"</span></span></code> </pre> <br><h3 id="epohi-i-chekpoynty">  Epochs and Checkpoints </h3><br><p>  One simple pass through all the images is certainly not enough for training.  And you need the code for training and validation above to perform in a loop (within one session). </p><br><p>  Perform either a fixed number of iterations, or until training helps.  A single pass through the entire data set is traditionally called an epoch (eng. Epoch). </p><br><p>  In case of unforeseen stops of training and for further use of the model, you need to save it.  To do this, when creating an execution graph, you need to create a <code>Saver</code> class object.  And in the course of training to maintain the state of the model. </p><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#   # ... saver = tf.train.Saver() #   with tf.Session() as sess: for i in range(EPOCHS): # Train # ... # Validate # ... saver.save(sess, "checkpoint/name")</span></span></code> </pre><br><h1>  What's next </h1><br><p>  We learned how to create datasets, transform them using functions of working with <br>  tensors, as well as the usual functions written in python.  We learned how to load images in the background loop without trying to load them into memory or save them in the decompressed form.  They also learned to save the trained model. </p><br><p>  By applying part of the steps described above and <a href="https://www.tensorflow.org/api_docs/python/tf/train/Saver">downloading</a> it, you can make a program that will recognize images. </p><br><p>  The article does not completely reveal the topics of neural networks as such, their architecture and methods of training.  For those who want to figure it out, I can recommend the <a href="https://www.udacity.com/course/deep-learning--ud730">Deep Learning by Google</a> course on Udacity, it is suitable for beginners as well, without a serious background.  About the use of convolutional neural networks for recognition there is an excellent course of lectures by <a href="https://www.youtube.com/playlist%3Flist%3DPL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv">Convolutional Neural Networks for Visual Recognition</a> from Stanford University.  It is also worth looking at <a href="https://www.coursera.org/specializations/deep-learning">coursera</a> ning <a href="https://www.coursera.org/specializations/deep-learning">coursera courses</a> on the Sourcesera.  There are also quite a lot of materials on Habrahabr, for example, a good overview of the <a href="https://habrahabr.ru/company/ods/blog/324898/">Tensorflow</a> library from Open Data Science. </p><br><p>  UPD: Script and helper libraries are available on <a href="https://github.com/golovasteek/ImageNet_ObjectDetection/tree/97d9194ed32048b6ca12a688536c8f26b3df1bec">Github</a> </p></div>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <p>Source: <a href="https://habr.com/ru/post/345546/">https://habr.com/ru/post/345546/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../345530/index.html">Avito X: people - people</a></li>
<li><a href="../345532/index.html">Building a RESTful web API on the InterSystems platform - 2</a></li>
<li><a href="../345534/index.html">As I wrote my own ERP system, ver. 2.0</a></li>
<li><a href="../345538/index.html">40-year-old taxi driver from Tambov became a programmer</a></li>
<li><a href="../345542/index.html">How changing two lines of code can take several days</a></li>
<li><a href="../345550/index.html">How EdTech Leaders Earn</a></li>
<li><a href="../345552/index.html">Service Workers. Instructions for use</a></li>
<li><a href="../345556/index.html">Load testing "non-HTTP". Part 1 JMeter</a></li>
<li><a href="../345560/index.html">New C ++ 17 that everyone should use</a></li>
<li><a href="../345566/index.html">My strategy for the Russian AI Cup 2017</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>