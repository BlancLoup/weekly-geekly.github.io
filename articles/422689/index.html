<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Determining the color of cars using neural networks and TensorFlow</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hello, my name is Roman Lapin, I am a 2nd year postgraduate student at the Faculty of the Higher School of General and Applied Physics at UNN. This ye...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Determining the color of cars using neural networks and TensorFlow</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/webt/ay/jz/uv/ayjzuvpfvae66prncupgndyiwpc.jpeg"><br><br>  Hello, my name is Roman Lapin, I am a 2nd year postgraduate student at the Faculty of the Higher School of General and Applied Physics at UNN.  This year I managed to qualify and participate in the work of the Intel Summer School in Nizhny Novgorod.  I was assigned the task of determining the color of a car with the help of the Tensorflow library, on which I worked together with my mentor and engineer of the ICV team Alexey Sidnev. <br>  And that's what I did. <br><a name="habracut"></a><br>  There are several aspects to this task: <br><br><ol><li>  The car can be painted in several colors, as in the KDPV.  And in one of our datasets, for example, there was a car with camouflage colors. </li><li>  Depending on the lighting and the camera that captures what is happening on the road, cars of the same color will look very different.  The ‚Äúilluminated‚Äù cars may have a very small part that corresponds to the ‚Äútrue‚Äù color of the car. </li></ol><br><h2>  <font color="#0071c5">Vehicle color detection</font> </h2><br>  The color of the car is a rather strange substance.  The manufacturer has a clear understanding of what color the car they produce, for example: phantom, glacial, black pearl, pluton, lime, krypton, angkor, carnelian, platinum, blues.  The traffic police opinion about the colors of cars is quite conservative and very limited.  Each individual person has a subjective perception of color (you can recall the popular story about the color of the dress).  Thus, we decided to perform the markup as follows. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      On each image, the coordinates of the vertices of the bordering rectangles around the cars (I will use the English version - <i>car bounding box</i> ) and the areas that best characterize the color of vehicles ( <i>color box</i> ) are marked on them.  The number of the latter is equal to the color of the car ( <i>n</i> x <i>color box</i> - n-color car). <br><br>  Hereinafter, the numbers of cars are smeared for the possibility to publish photos in open access. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/mh/p7/z5/mhp7z5aebrmyfhgw-cack-fm8zi.png" alt="image"></div><br>  <i>Dataset car layout</i> <br><br>  Later we worked with two color spaces - RGB and LAB - with 8 and 810/81 classes, respectively.  To compare the results of different approaches, we used to determine the color of 8 classes in RGB, which are obtained by dividing the BGR cube into 8 equal small cubes.  They can easily be called common names: white, black, red, green, blue, pink, yellow, cyan.  To estimate the error of any method, we have already used the color space LAB, in which the <a href="https://en.wikipedia.org/wiki/Color_difference">distance</a> between the colors is defined. <br><br>  There are two intuitive ways to determine color by <i>color box</i> : medium or median color.  But in the <i>color box</i> there are pixels of the most different colors, so I wanted to know how accurately each of these two approaches worked. <br><br>  For 8 RGB colors for each <i>color box of</i> each machine in dataset, we determined the average color of the pixels and the median, the results are shown in the figures below.  The rows are marked with ‚Äútrue‚Äù colors ‚Äî that is, colors defined as medium or median, respectively; in the columns, colors occurring in principle.  When adding one car to the table, the number of pixels of each color was normalized by their number, i.e. the sum of all values ‚Äã‚Äãadded to the row was equal to one. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ic/q-/ep/icq-ep_xxwuaiuuec8bordv3_cu.png" alt="image"></div><br>  <i>The study of the accuracy of determining the color of the machine as the average color of the color 'abox pixels.</i>  <i>Average accuracy: <b>75%</b></i> <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/at/b3/wm/atb3wmizgurxd0gemdqiltoj62w.png" alt="image"></div><br>  <i>The study of the accuracy of determining the color of the machine as the median color of the pixels of the color box.</i>  <i>Average accuracy: <b>76%</b></i> <br><br>  As you can see, there is not much difference between the methods, which indicates a good markup.  Later we used the median, since it showed the best result. <br>  The vehicle color determination will be based on the area inside the <i>car bounding box</i> . <br><br><h2>  <font color="#0071c5">Do we need networks?</font> </h2><br>  The inevitable question is: do we really need neural networks to solve an intuitively simple task?  Maybe you can take the median or average pixel color of the <i>car bounding box</i> in the same way?  The figures below show the result of this approach.  As will be shown later, it is worse than the method using neural networks. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/an/bl/o8/anblo8jtdfojv3v7b1yd_bt5zzi.png" alt="image"></div><br>  <i>The distribution of the share of cars with the value of L2 error in the space LAB between the color box color, defined as the average, and the car bounding box color of the value of this error</i> <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/l-/ir/o0/l-iro02-06n4ugotazhlmumisii.png" alt="image"></div><br>  <i>The distribution of the share of cars with the value of L2 errors in the LAB space between the color box color defined as the median and the <i>car bounding box</i> color of this error value</i> <br><br><h2>  <font color="#0071c5">Description of the approach to the task</font> </h2><br>  In our work, we used the Resnet-10 architecture to highlight features.  To solve one label and multilabel tasks, the activation functions of <a href="https://en.wikipedia.org/wiki/Softmax_function">softmax</a> and <a href="https://en.wikipedia.org/wiki/Sigmoid_function">sigmoid,</a> respectively, were chosen. <br>  An important issue was the choice of a metric by which we could compare our results.  In the case of one label task, you can select the class corresponding to the <a href="https://en.wikipedia.org/wiki/Arg_max">maximum response</a> .  However, this solution will obviously not work in the case of multilabel / multi-color machines, since argmax produces one, the most likely color.  The <a href="https://en.wikipedia.org/wiki/Lp_space">L1</a> metric depends on the number of classes, so it could not be used to compare all the results either.  Therefore, it was decided to dwell on the metric of the area under the <a href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic">ROC curve</a> (ROC AUC - area under curve) as universal and generally accepted. <br><br>  We worked in two color spaces.  The first is the standard <a href="https://en.wikipedia.org/wiki/RGB_color_model">RGB</a> , in which we chose 8 classes: we divided the RGB cube into 8 identical sub-cubic pins: white, black, red, green, blue, pink, yellow, cyan.  Such a partition is very rough, but simple. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/vq/4z/pd/vq4zpd9edgxx4m9z0cnk-8jso2i.png" alt="image"></div><br>  <i>Splitting RGB color space into 8 areas</i> <br><br>  In addition, we conducted research with the color space LAB, in which we used the division into 810 classes.  Why so much?  LAB was introduced after the American scientist <a href="https://en.wikipedia.org/wiki/David_MacAdam">David MacAdam</a> established that there are areas of colors that are not distinguishable by the human eye ( <a href="https://en.wikipedia.org/wiki/MacAdam_ellipse">Macadam ellipses</a> ).  LAB was constructed so that in it these ellipses had the form of circles (in the section of constant L - brightness). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/-1/y5/q9/-1y5q9owfaqva2sd7sxy45auef0.png" alt="image"></div><br>  <i>Macadam ellipses and color space LAB ( <a href="https://iovs.arvojournals.org/article.aspx%3Farticleid%3D2187751">image source</a> )</i> <br><br>  In total, there are 81 such circles in the cross section. We took step 10 in the L parameter (from 0 to 100), receiving 810 classes.  In addition, we conducted an experiment with a constant L and, accordingly, 81 class. <br><br><h2>  <font color="#0071c5">RGB and LAB</font> </h2><br>  For the 8-class problem and the RGB space, we get the following results: <br><table><tbody><tr><th>  Activation function </th><th>  Multilabel task </th><th>  ROC AUC </th></tr><tr><td>  softmax </td><td>  - </td><td>  0.97 </td></tr><tr><td>  sigmoid </td><td>  ‚úì </td><td>  0.88 </td></tr></tbody></table>  <i>The table of color recognition results of machines in the 8-class problem</i> <br><br>  It seems that the result for the multilabel task is already quite good.  To test this assumption, we built an error matrix, taking the threshold value for the probability of 0.55.  Those.  if this value is exceeded in probability for the corresponding color, we consider that the car is painted in this color too.  Despite the fact that the threshold is chosen low enough, when it is possible to see the characteristic errors in determining the color of the car and draw conclusions. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/5s/5q/9t/5s5q9tyt_8nbe4c0vb-mgxtoday.png" alt="image"></div><br>  <i>The table of results of recognition of color of cars in the 8th class task</i> <br><br>  Just look at the lines that match the green or pink colors to make sure that the model is far from perfect.  To the question of why, with a large value for the metric, such a strange unfortunate result is obtained, we will come back, we immediately immediately designate: if we consider only 8 classes, a huge number of colors fall into the ‚Äúwhite‚Äù and ‚Äúblack‚Äù classes, therefore this result . <br><br>  Therefore, next we move into the color space LAB and conduct research there. <br><table><tbody><tr><th>  Activation func </th><th>  Multilabel task </th><th>  ROC AUC </th></tr><tr><td>  softmax </td><td>  - </td><td>  0.915 </td></tr><tr><td>  sigmoid </td><td>  ‚úì </td><td>  0.846 </td></tr></tbody></table>  <i>The table of color recognition results of machines in the 810-class problem</i> <br><br>  The result was less, which is logical, since the number of classes increased by two orders of magnitude.  Taking the sigmoid result as a starting point, we tried to improve our model. <br><br><h2>  <font color="#0071c5">LAB: experiments with different weights</font> </h2><br>  Before that, all experiments were performed with unit weights as a function of loss ( <i>loss</i> ): <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ox/u5/af/oxu5afajo-qngyg1t6tdml1sdxo.png" alt="image"></div><br><br>  Here GT is ground truth, W is weights. <br><br>  In the color space LAB you can enter a <a href="https://en.wikipedia.org/wiki/Color_difference">distance</a> .  Let's say we have one unit in GT.  Then it corresponds to some rectangular parallelepiped in the color space LAB.  This parallelepiped (more precisely, its center) is removed at a different distance from all other parallelepipeds (again, their centers).  Depending on this distance, you can experiment with the following weights: <br><br>  a) Zero at the place of the unit in GT, and with distance from it - the increase in weights; <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/zs/in/ql/zsinql6ut3hucnr3ytrvkc0xxqi.png" alt="image"></div><br><br>  b) On the contrary, at the place of the unit in GT is the unit, when removed, the scale decreases; <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/8v/-l/oo/8v-looj6mqsgrtzvz9elevykcak.png" alt="image"></div><br><br>  c) Option a) plus a small Gaussian additive with an amplitude of ¬Ω at the site of the unit in the GT; <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/yx/qy/ac/yxqyac6ks3cvy10qh6lilp4ib0q.png" alt="image"></div><br><br>  d) Option a) plus a small Gaussian additive with amplitude 1 in place of the unit in the GT; <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ep/0s/01/ep0s01rau7n0oiak71zjkp5vhxg.png" alt="image"></div><br><br>  e) Option b) with a small addition at the maximum distance from one in GT. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ff/9q/ft/ff9qftnoidusfhdhz1p9jjoqwi0.png" alt="image"></div><br><br>  The last version of the scales with which we conducted experiments was, as we called it, triple gauss, namely, three normal distributions with centers in place of units in the GT, as well as at the greatest distance from them. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/qk/jr/kb/qkjrkbhyxschjibmya3xt3hik9y.png" alt="image"></div><br>  <i>Three normal distributions with centers in place of units in the GT and at the greatest distance from them</i> <br><br>  He will have to explain a little more.  You can select the two most distant parallelepipeds, and, therefore, the class, and compare them by distance from the source.  For the class corresponding to the far, the amplitude of the distribution is set to 0.8, and for the second, m times smaller, where m is the ratio of the distance from the source to the far distance to the distance between the source and the near. <br><br>  The results are shown in the table.  Due to the fact that in the scales of option a) there were zero weights - just units in GT, the result for them came out even worse than the starting point, since the network did not take into account successful color definitions, learning less.  The weights b) and e) practically coincided, and therefore the result for them coincided.  The largest increase in percentage points compared with the starting result was shown by the variant of weights f) - triple gauss. <br><table><tbody><tr><th>  Activation function </th><th>  Number of classes </th><th>  Weights type </th><th>  ROC AUC </th></tr><tr><td rowspan="5">  sigmoid </td><td rowspan="5">  810 </td><td>  a) </td><td>  0.844 </td></tr><tr><td>  b), e) </td><td>  0.848 </td></tr><tr><td>  c) </td><td>  0.888 </td></tr><tr><td>  d) </td><td>  0.879 </td></tr><tr><td>  f) </td><td>  0.909 </td></tr></tbody></table>  <i>The color recognition results of machines in the 810 class problem with different weights</i> <br><br><h2>  <font color="#0071c5">LAB: experimenting with new labels</font> </h2><br>  So, we conducted experiments with different weights in <i>loss</i> .  Then we decided to try to leave the weights as single ones, and change the labels that are transferred to the loss function and are used to optimize the network.  If before that labels coincided with GT, now they decided to use again Gaussian distributions with centers in place of units in GT: <br><br>  The motivation for such a decision is as follows.  The fact is that with ordinary labels all cars in datasets fall into a fixed number of classes, less than 810, so the network learns to determine the color of cars of only these classes.  With new labels, non-zero values ‚Äã‚Äãfall into all classes and we can expect an increase in the accuracy of determining the color of the car.  We experimented with two sigmas (standard deviations) for the above Gaussian distributions: 41.9 and 20.9.  Why such?  The first sigma is chosen as follows: the minimum distance between the classes (28) is taken and sigma is determined from the condition of the distribution falling twice in the class next to the GT.  And the second sigma is just less than the first two times. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/jk/z4/xq/jkz4xqdkl-nwecfnttwzuhwgyuo.png" alt="image"></div><br>  <i>Distribution of cars training dataset classes for different labels in the loss</i> <br><br>  Indeed, it was possible to further improve the result with the help of such a trick, as shown in the table.  As a result, the determination accuracy reached 0.955! <br><table><tbody><tr><th>  Activation function </th><th>  Number of classes </th><th>  Labels type </th><th>  Weights type </th><th>  ROC AUC </th></tr><tr><td rowspan="4">  sigmoid </td><td rowspan="4">  810 </td><td>  usual </td><td>  ones </td><td>  0.846 </td></tr><tr><td>  usual </td><td>  three gauss </td><td>  0.909 </td></tr><tr><td>  new, œÉ <sub>1</sub> </td><td rowspan="2">  three gauss </td><td>  0.955 </td></tr><tr><td>  new, œÉ <sub>2</sub> </td><td>  0.946 </td></tr></tbody></table>  <i>The color recognition results of machines in the 810 class problem: with ordinary labels and unit weights, with ordinary labels and weights in the form of triple gauss, with new labels and unit weights</i> <br><br><h2>  <font color="#0071c5">LAB: 81</font> </h2><br>  If we talk about unsuccessful experiments, it is necessary to mention an attempt to train the network with 81 classes and the constant parameter L. We observed in previous experiments that the brightness is determined quite accurately by the network, and we decided to practice only parameters a and b two other coordinates are called in LAB).  Unfortunately, despite the fact that the network was able to train perfectly in the plane, showing a greater value in the metric, the idea to set the L parameter at the output of the network as the average for the <i>car bounding box</i> suffered a collapse and the actual color and thus determined differed very much. <br><br><h2>  <font color="#0071c5">Comparison with problem solving without using neural networks</font> </h2><br>  And now let's go back to the very beginning and compare what we have with the recognition of the color of the car without using neural networks. <br>  The results are shown in the figures below.  It can be seen that the peak has become more than 3 times, and the number of cars with a large error between the true and certain colors has decreased significantly. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/l-/ir/o0/l-iro02-06n4ugotazhlmumisii.png" alt="image"></div><br>  <i>The distribution of the share of cars with the L2 value of the error in the LAB space between the color color bounding box, defined as the median, and the car bounding box color of this error value</i> <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/6j/wr/b5/6jwrb5imhzh2rbvnaxrgzedf0p8.png" alt="image"></div><br>  <i>The distribution of the share of cars with the value of L2 error in the LAB space between the color at the output of the neural network, and the color of the car bounding box of the magnitude of this error</i> <br><br><h2>  <font color="#0071c5">Examples</font> </h2><br>  The following are examples of color recognition cars.  The first - the black car (a typical case) is recognized as black, and the distance in the LAB space between the true color and a certain (18.16) is less than the minimum distance between the classes (28).  In the second picture, the network was able not only to determine that the car was illuminated (there is a high probability that corresponds to one of the classes of white flowers), but also its real color (silver).  However, the machine from the next figure, also illuminated, was not detected by the network as red.  The color of the car shown in the figure below could not be determined at all by the network, which follows from the fact that the probabilities for all colors are too small. <br><br>  In many ways, the task was due to the need to recognize multi-color cars.  The last figure shows a two-tone black and yellow car.  The black color is most likely recognized by the network, which is apparently due to the prevalence of machines of this and similar colors in the training dataset, and the yellow color, which is close to the true one, entered the top 3. <br><table><tbody><tr><th width="200"><img src="https://habrastorage.org/webt/ro/l7/re/rol7re300p2hf30rtsvaiyfbi20.png" align="right" alt="image"></th><th><img src="https://habrastorage.org/webt/n8/ig/cl/n8igclilt4ep3qlmipvt9rmbt5w.png" align="left" alt="image"></th></tr></tbody></table><table><tbody><tr><th width="200"><img src="https://habrastorage.org/webt/o5/pf/fj/o5pffjzvnat7mouv8yhf-kuzs3g.png" align="right" alt="image"></th><th><img src="https://habrastorage.org/webt/vn/ml/wa/vnmlwawbhys7tkvrwquwc6bttsw.png" align="left" alt="image"></th></tr></tbody></table><table><tbody><tr><th width="200"><img src="https://habrastorage.org/webt/jh/mi/hs/jhmihs9rnoqounq2ostwq8iz1q0.png" align="right" alt="image"></th><th><img src="https://habrastorage.org/webt/pv/sg/ft/pvsgftesuo5lmmy_gvuzsj-rg4o.png" align="left" alt="image"></th></tr></tbody></table><table><tbody><tr><th width="200"><img src="https://habrastorage.org/webt/f7/uj/p3/f7ujp3uavgqz6aobfa_hbk6xpos.png" align="right" alt="image"></th><th><img src="https://habrastorage.org/webt/0c/mo/l1/0cmol16qj3ghtsc49jqag2dy8yc.png" align="left" alt="image"></th></tr></tbody></table><table><tbody><tr><th width="200"><img src="https://habrastorage.org/webt/dd/hi/th/ddhithwwjdez_q6sr8xa9cwcs-i.png" align="right" alt="image"></th><th><img src="https://habrastorage.org/webt/gg/hf/px/gghfpxgurqddwvldmop4t1zszfo.png" align="left" alt="image"></th></tr></tbody></table><br><h2>  <font color="#0071c5">ROC curve: visualization and problems</font> </h2><br>  So, at the output, we got a fairly high result on the metric.  The following figure shows the ROC curves both for solving a problem with 8 classes, and for a problem with 810 classes, as well as solutions without using neural networks.  It can be seen that the result is slightly different than the one that was written out earlier.  The previous results were obtained using TensorFlow, the graphs below were obtained using the scikit-learn package. <br><table><tbody><tr><th><div style="text-align:center;"><img src="https://habrastorage.org/webt/yq/zm/ib/yqzmib4v_0jaco5torqqvu0fdmo.png" alt="image"></div></th><th><div style="text-align:center;"><img src="https://habrastorage.org/webt/k0/nb/gn/k0nbgn7ows7rcx-q3so38ugg_dw.png" alt="image"></div></th></tr></tbody></table>  <i>ROC curve for several solutions.</i>  <i>On the right is the upper left corner of the left graph.</i> <br><br>  You can take as fixed values ‚Äã‚Äãany fixed numbers (for example, Tensorflow when setting the corresponding parameter to 50 takes the same thresholds from 0 to 1 at regular intervals), you can - the values ‚Äã‚Äãat the network output, and you can limit them from below to not consider values ‚Äã‚Äãof the order of 10 <sup>-4</sup> , for example.  The result of the last approach is shown in the following figure. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/fb/2c/b2/fb2cb2dxnaxvjjtywmlbdb-xs54.png" alt="image"></div><br>  <i>ROC curve for several options for solving the problem with a threshold of 10 <sup>-4</sup></i> <br><br>  It can be seen that all the curves that correspond to the solution of the problem using neural networks are characteristically better (located above) without solving them, but between the first one it is impossible to choose one uniquely best curve.  Depending on which threshold the user chooses, different curves will respond to different optimal solutions of the problem.  Therefore, on the one hand, we have found such an approach, which allows us to determine the color of the car quite accurately and shows a high metric, on the other hand, we have shown that the limit has not yet been reached and the area metric under the ROC curve has its drawbacks. <br><br>  Ready to answer questions and listen to comments in the comments. </div><p>Source: <a href="https://habr.com/ru/post/422689/">https://habr.com/ru/post/422689/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../422679/index.html">Imaginary problems cause bad software</a></li>
<li><a href="../422681/index.html">SAP and Python integration or how to take data from SAP easier</a></li>
<li><a href="../422683/index.html">In the US, two traders set up a fake brokerage company to steal money from novice investors</a></li>
<li><a href="../422685/index.html">Smart Watch Samsung Galaxy Watch: upgrade from Android Wear OS to Tizen OS - personal experience</a></li>
<li><a href="../422687/index.html">Messengers are in danger</a></li>
<li><a href="../422691/index.html">Hybrid camera and lidar improves robotic capabilities, complementing information about the outside world</a></li>
<li><a href="../422693/index.html">Plugin Team for Customizing JavaFX Components in a Desktop Application</a></li>
<li><a href="../422697/index.html">Webpack 4 and the separation of the configuration file into modules</a></li>
<li><a href="../422699/index.html">Closed loophole confirms the unreality of the quantum world</a></li>
<li><a href="../422701/index.html">Deep Learning and OpenVINO Toolkit. Ask an Intel Expert Question</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>