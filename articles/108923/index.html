<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>NLP: spell check - an inside look (part 2)</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="( Part 1 ) Today we will talk about the levels of understanding of texts by our system, about which spelling errors are easy to catch, which are not v...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>NLP: spell check - an inside look (part 2)</h1><div class="post__text post__text-html js-mediator-article">  ( <a href="http://habrahabr.ru/blogs/artificial_intelligence/108831/">Part 1</a> ) Today we will talk about the levels of understanding of texts by our system, about which spelling errors are easy to catch, which are not very easy, and which are extremely difficult. <br><br>  To begin with, the text can be viewed from two points of view: either as a simple sequence of words, spaces, and punctuation marks, or as a network of related concepts and syntactic-semantic dependencies.  Say, in the sentence "I love big dogs" you can arrange words in any order, while the structure of the connections between words will be the same: <br><br><img src="http://habreffect.ru/files/dc2/c8537d6e3/%D0%91%D1%83%D1%84%D0%B5%D1%80_%D0%BE%D0%B1%D0%BC%D0%B5%D0%BD%D0%B001.png"><a name="habracut"></a>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Errors can also occur at different levels.  You can make a mistake in the linear structure - type the same word twice, forget the point, the parenthesis, and the like.  That is, an error occurs in the process of building words into a chain, and a person is unlikely to make it out of ignorance of any grammatical rule.  Probably, we are talking about a simple inattention.  However, at the level of the chains, some real grammatical errors can be identified.  For example, in the English text there should be no combination of ‚Äúwas‚Äù - there should be either ‚Äúwas‚Äù or ‚Äúhas been‚Äù. <br><br>  But still, real grammar begins at the level of analyzing the network of concepts.  For example, in our example about dogs, the subject ‚ÄúI‚Äù should be combined in person and number with the verb ‚ÄúI love‚Äù, regardless of the relative position of these words in the sentence.  Of course, this consideration does not negate the need to catch even simpler errors identified at the level of the linear structure. <br><br><h1>  First levels </h1>  It is reasonable to start error checking with the simplest.  If something can be caught at the level of a trivial search for substrings, why connect heavy artillery?  The simplest functionality is the AutoCorrect list, which also exists in MS Word.  We are talking about obvious typos, corrected by the system automatically, even without user confirmation: abbout -&gt; about, amde -&gt; made, compleatly -&gt; completely.  Perhaps the autocorrect seems to be such an obvious function that it seems to make no sense to talk about it, however, as an active MS Word user, the autocorrect often helps me, and I will be happy to see the autocaution in other word processors.  For this we work, in the end. <br><br>  Slightly more complicated are simple rules based on regular expressions that treat the text as one big line.  Today we catch simple situations with regular expressions associated with typographical roughnesses: space (s) between punctuation marks, extra spaces between words, non-standard combinations like "!?"  and so on.  In principle, even at the level of a simple search for substrings, you can find a number of errors skipped by the spell checker. <br><br><h1>  Offers and tokens </h1>  Now we turn to more interesting things.  In order to analyze the text precisely as text, and not as a string of characters, it is necessary to learn how to select structural elements in it.  We are still far from the structure of connections between words, so let's start with the simplest thing - recognizing the boundaries of sentences.  Why do we need it?  Well, firstly, there are mistakes that are characteristic for the beginning and the end of a sentence: you forgot to start with a capital letter, you forgot to put an end to the end (dots, question / exclamation marks).  There are less obvious cases - for example, it is stylistically unacceptable to begin a sentence with a number written in numbers.  Secondly, without the existing sentence structure, it is impossible to proceed to the next stage of the analysis ‚Äî to identify the links between the words of the sentence. <br><br>  Like everything else in our world, at a second glance the task of breaking up the text into sentences no longer seems so simple.  The obvious algorithm is to find the final punctuation mark followed by the capital letter.  At the same time, we will be mistaken when we meet the name of a person: ‚ÄúAs M. Ivanov stated ...‚Äù Similarly, there are cuts in the way at which there is a period.  In principle, you can add a list of names and abbreviations to the analyzer, but this solution will still not be without flaws.  For example, it will have to be completely rewritten for any new language with its own rules for ending sentences.  In addition, there is an obvious problem: we proceed from the fact that the input text contains errors (in their correction and the essence of our module);  so how in the conditions of an incorrect input to break the text into sentences?  In this case, we automatically lose the opportunity to see the error at the junction of sentences.  If we assume that the border lies between a point and a capital letter, then an error like ‚Äúforgot to put a capital letter‚Äù will immediately be out of reach, because the system simply does not understand that there is a sentence boundary in this place. <br><br>  Now the most popular approaches to splitting text into sentences in real conditions are to use machine-based classification algorithms. <br><br><h1>  Sentence splitter </h1> In short, the task of classification is to determine the correct class of an object C based on its attributes (A1, ..., An).  The input to the learning algorithm is given a large sample of known objects, on the basis of which it forms its own idea of ‚Äã‚Äãhow attribute values ‚Äã‚Äãaffect the belonging of an object to a particular class.  Then you can feed the algorithm a set of attributes of an unknown object and get its most likely class. <br><br>  A textbook example of the classification task is the determination of the type of iris flower based on four parameters - the length and width of the petal and the sepal.  There are three types of iris: Iris setosa, Iris virginica and Iris versicolor.  The Iris dataset lists 50 entries of the following form: <br><br><img src="http://habreffect.ru/files/8ea/49efb7857/%D0%91%D1%83%D1%84%D0%B5%D1%80_%D0%BE%D0%B1%D0%BC%D0%B5%D0%BD%D0%B002.png"><br><br>  The classification algorithm can study this data and build a model for matching the attributes of an iris to a particular type.  If an iris unknown to me grows in my garden, I can measure its parameters and ask the algorithm what kind of iris I belong to. <br><br>  The qualifier can also be used for other purposes: making decisions based on a table of reference decisions under the circumstances, as well as identifying hidden patterns - another textbook example involves studying the ‚Äúattributes‚Äù of passengers who survived the Titanic crash in order to understand what the chances of different groups of people (child / adult, male / female, passenger / team member, the owner of a 1/2/3 class ticket). <br><br>  There are a lot of different classification algorithms: decision trees, nearest neighbor, bayesian network, maximum entropy model, linear regression ... Each has its own advantages and disadvantages.  Some work better with numerical data, others are easier to program, others are faster, fourth formulate the identified classification rules in an easy-to-analyze way. <br><br>  In relation to the division of text into sentences, the classifier works as follows.  At the entrance comes the text, divided into proposals manually.  The system studies the "attributes" of each end of the sentence (in fact, it looks to be left and right of the border) and builds a classification model.  Now the algorithm can input any point of the text and ask if it is the boundary of the sentence. <br><br>  What are the subtleties here?  First, here we have a not quite standard formulation of the classification problem.  We only get the end-of-sentence contexts at the input: <br><br>  (A1, ..., An) -&gt; (end of sentence) <br><br>  In the classical formulation, the knowledge base should include all variants, ie: <br><br>  (A1, ..., An) -&gt; (end of sentence) <br>  (A1, ..., An) -&gt; (not the end of a sentence) <br><br>  In our case, cramming into the table all the examples of non-ends of the sentence is too ruinous - the base will grow incredibly.  Apparently, for this reason, the most frequently cited author of the machine learning scheme (as applied to our task) <a href="http://acl.ldc.upenn.edu/A/A97/A97-1004.pdf">A. Ratnaparkhi</a> used the principle of maximum entropy.  This model allows you to simply ask the probability that an object belongs to a given class without regard to other possible classes.  In other words, we ask the model what the likelihood of a given context to be the end of a sentence.  If the algorithm responds that the probability is higher than 1/2, you can mark the context as a sentence boundary. <br><br>  I think it makes sense to try other classification algorithms.  As far as I know, this was not done;  if my hands reach, I'll do it.  Experiments of the same Ratnaparkhi show the accuracy of its algorithm in the region of 98%, that is, from one hundred ends of sentences he guesses 98 correctly. <br><br>  Unfortunately, in the spell checker we are again confronted with the fact that the input text may contain errors.  If you train the model on correct texts divided into sentences, the computer will rightly decide that the sentence always begins with a capital letter.  If we throw away the ‚Äútitle‚Äù from the attributes taken into account, the accuracy of the model will fall.  You can manually make a few errors in the reference texts (in some places ‚Äúforget‚Äù the point, in some places replace the upper case letter).  Further, in the Ratnaparkhi system, we must first find the potential boundary of sentences, and then ask the system about its opinion on this place.  He does this simply: we look for a point, an exclamation point or a question mark - and ask what it is.  With us, the user can forget about the point - and what to do? <br><br>  Today, in addition to the punctuation marks, I also check newline characters (from personal experience - if I forget to put a full stop, it‚Äôs at the end of the paragraph).  You can try to learn all the spaces between words, but I'm afraid that the accuracy may fall.  In general, there is something to think about :) <br><br>  Okay, enough for today, we will continue next time. </div><p>Source: <a href="https://habr.com/ru/post/108923/">https://habr.com/ru/post/108923/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../108914/index.html">Authorities seized Torrent-Finder.com domain (changed DNS)</a></li>
<li><a href="../108915/index.html">Understanding prototype, __proto__, constructor and their chains in pictures</a></li>
<li><a href="../108917/index.html">Hacking a Vogue magazine or video player for 119 rubles</a></li>
<li><a href="../108920/index.html">Introduction to OCaml: Data Types and Mapping [3]</a></li>
<li><a href="../108921/index.html">The "mystery" of Vogue magazine</a></li>
<li><a href="../108926/index.html">Practical advice for those who want to build a web community</a></li>
<li><a href="../108927/index.html">Kinect - advanced sensor for robots</a></li>
<li><a href="../108931/index.html">NAT on Cisco. Part 1</a></li>
<li><a href="../108932/index.html">Microsoft continues to support Creative Commons!</a></li>
<li><a href="../108934/index.html">Not another social network or how we decided to create our own social network (Part 2 - organizing the information space on news portals)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>