<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Load Average in Linux: Solving the Mystery</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Load averages are industry-critical metrics. Many companies spend millions of dollars automatically scaling cloud instances based on this and several ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Load Average in Linux: Solving the Mystery</h1><div class="post__text post__text-html js-mediator-article"><p><img src="https://habrastorage.org/web/c56/554/a4d/c56554a4dbc34f98a4c6b2981c0c802c.jpg"></p><br><p>  Load averages are industry-critical metrics.  Many companies spend millions of dollars automatically scaling cloud instances based on this and several other metrics.  But on Linux, it is shrouded in mystery.  Tracking the average load on Linux is a task that works in an uninterrupted sleep state (uninterruptible sleep state).  Why?  I have never met an explanation.  In this article I want to solve this mystery, and create a reference for the average load values ‚Äã‚Äãfor all who try to interpret them. </p><a name="habracut"></a><br><p>  Linux load averages are ‚Äúsystem load averages‚Äù that indicate the need for executable threads (tasks) in the form of an average number of executable and pending threads.  This is a measure of the load that may exceed the system currently being processed.  Most tools show three average values: for 1, 5 and 15 minutes: </p><br><pre><code class="hljs pgsql">$ uptime <span class="hljs-number"><span class="hljs-number">16</span></span>:<span class="hljs-number"><span class="hljs-number">48</span></span>:<span class="hljs-number"><span class="hljs-number">24</span></span> up <span class="hljs-number"><span class="hljs-number">4</span></span>:<span class="hljs-number"><span class="hljs-number">11</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">user</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">load</span></span> average: <span class="hljs-number"><span class="hljs-number">25.25</span></span>, <span class="hljs-number"><span class="hljs-number">23.40</span></span>, <span class="hljs-number"><span class="hljs-number">23.46</span></span> top - <span class="hljs-number"><span class="hljs-number">16</span></span>:<span class="hljs-number"><span class="hljs-number">48</span></span>:<span class="hljs-number"><span class="hljs-number">42</span></span> up <span class="hljs-number"><span class="hljs-number">4</span></span>:<span class="hljs-number"><span class="hljs-number">12</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">user</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">load</span></span> average: <span class="hljs-number"><span class="hljs-number">25.25</span></span>, <span class="hljs-number"><span class="hljs-number">23.14</span></span>, <span class="hljs-number"><span class="hljs-number">23.37</span></span> $ cat /proc/loadavg <span class="hljs-number"><span class="hljs-number">25.72</span></span> <span class="hljs-number"><span class="hljs-number">23.19</span></span> <span class="hljs-number"><span class="hljs-number">23.35</span></span> <span class="hljs-number"><span class="hljs-number">42</span></span>/<span class="hljs-number"><span class="hljs-number">3411</span></span> <span class="hljs-number"><span class="hljs-number">43603</span></span></code> </pre> <br><p>  Some interpretations are: </p><br><ul><li>  If the values ‚Äã‚Äãare 0.0, then the system is idle. </li><li>  If the average value for 1 minute is higher than for 5 or 15, then the load increases. </li><li>  If the average value for 1 minute is lower than for 5 or 15, then the load decreases. </li><li>  If the load values ‚Äã‚Äãare higher than the number of processors, then you may have performance problems (depending on the situation). </li></ul><br><p>  For this set of three values, you can estimate the load dynamics, which is certainly useful.  Also, these metrics are useful when you need a single assessment of resource requirements, for example, to automatically scale cloud services.  But in order to deal with them in more detail, it is necessary to turn to other metrics.  In itself, a value in the range 23-25 ‚Äã‚Äãdoes not mean anything, but it makes sense if the number of processors is known, and if we are talking about the load related to the processor. </p><br><p>  Instead of debugging average load values, I usually switch to other metrics.  We will talk about this closer to the end of the article, in the chapter ‚ÄúMore suitable metrics‚Äù. </p><br><h2 id="istoriya">  Story </h2><br><p>  Initially, the average load values ‚Äã‚Äãshow only the need for processor resources: the number of running and pending processes.  <a href="https://tools.ietf.org/html/rfc546">RFC 546</a> has a good description called "TENEX Load Averages", August 1973: </p><br><blockquote>  [1] TENEX average load is a measure of CPU resource requirements.  This is the average number of executable processes over a period of time.  For example, if the hourly average load is 10, then this means (for a uniprocessor system) that at any time during this hour 1 process is running and 9 are ready for execution (that is, not blocked for I / O) and waiting for the processor is free. </blockquote><p>  A version on <a href="https://tools.ietf.org/html/rfc546">ietf.org</a> leads to a PDF scan of a hand-drawn graphic in July 1973, demonstrating that this metric has been used for decades: </p><br><p><img src="https://habrastorage.org/web/e13/242/633/e13242633e664bf0a9051b76b8d27ead.jpg" alt="image"><br>  <em>source:</em> <em><a href="https://tools.ietf.org/html/rfc546"></a></em>  <em><a href="https://tools.ietf.org/html/rfc546">https://tools.ietf.org/html/rfc546</a></em> </p><br><p>  Today you can find the source code of old operating systems on the web.  Here is a snippet from <a href="https://github.com/PDP-10/tenex">TENEX</a> (early 1970's) SCHED.MAC, on the DEC macro assembler: </p><br><pre> <code class="hljs sql">NRJAVS==3 ;NUMBER OF <span class="hljs-keyword"><span class="hljs-keyword">LOAD</span></span> AVERAGES WE MAINTAIN GS RJAV,NRJAVS ;EXPONENTIAL AVERAGES OF NUMBER OF ACTIVE PROCESSES [...] ;<span class="hljs-keyword"><span class="hljs-keyword">UPDATE</span></span> RUNNABLE JOB AVERAGES DORJAV: MOVEI <span class="hljs-number"><span class="hljs-number">2</span></span>,^D5000 MOVEM <span class="hljs-number"><span class="hljs-number">2</span></span>,RJATIM ;<span class="hljs-keyword"><span class="hljs-keyword">SET</span></span> <span class="hljs-built_in"><span class="hljs-built_in">TIME</span></span> <span class="hljs-keyword"><span class="hljs-keyword">OF</span></span> <span class="hljs-keyword"><span class="hljs-keyword">NEXT</span></span> <span class="hljs-keyword"><span class="hljs-keyword">UPDATE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">MOVE</span></span> <span class="hljs-number"><span class="hljs-number">4</span></span>,RJTSUM ;CURRENT INTEGRAL OF NBPROC+NGPROC SUBM 4,RJAVS1 ;DIFFERENCE FROM LAST <span class="hljs-keyword"><span class="hljs-keyword">UPDATE</span></span> EXCH <span class="hljs-number"><span class="hljs-number">4</span></span>,RJAVS1 FSC <span class="hljs-number"><span class="hljs-number">4</span></span>,<span class="hljs-number"><span class="hljs-number">233</span></span> ;FLOAT IT FDVR 4,[5000.0] ;AVERAGE OVER LAST 5000 MS [...] ;TABLE OF EXP(-T/C) FOR T = 5 SEC. EXPFF: EXP 0.920043902 ;C = 1 MIN EXP 0.983471344 ;C = 5 MIN EXP 0.994459811 ;C = 15 MIN</code> </pre> <br><p>  And here is a fragment from modern <a href="">Linux</a> (include / linux / sched / loadavg.h): </p><br><pre> <code class="hljs cpp"><span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">define</span></span></span><span class="hljs-meta"> EXP_1 1884 </span><span class="hljs-comment"><span class="hljs-meta"><span class="hljs-comment">/* 1/exp(5sec/1min) as fixed-point */</span></span></span><span class="hljs-meta"> #</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">define</span></span></span><span class="hljs-meta"> EXP_5 2014 </span><span class="hljs-comment"><span class="hljs-meta"><span class="hljs-comment">/* 1/exp(5sec/5min) */</span></span></span><span class="hljs-meta"> #</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">define</span></span></span><span class="hljs-meta"> EXP_15 2037 </span><span class="hljs-comment"><span class="hljs-meta"><span class="hljs-comment">/* 1/exp(5sec/15min) */</span></span></span></span></code> </pre> <br><p>  The constants for 1, 5 and 15 minutes are also hard-coded in Linux. </p><br><p>  Similar metrics were also found in older systems, including <a href="http://web.mit.edu/Saltzer/www/publications/instrumentation.html">Multics</a> , which contained an exponential average value of a queue of planned tasks (exponential scheduling queue average). </p><br><h2 id="tri-chisla">  Three numbers </h2><br><p>  Three numbers are average load values ‚Äã‚Äãfor 1, 5 and 15 minutes.  But they are not really average, and not for 1, 5 and 15 minutes.  As can be seen from the above code, 1, 5, and 15 are the constants used in the equation, which calculates the exponentially decaying sliding sums of a five-second average (exponentially-damped moving average).  So average loads for 1, 5 and 15 minutes do not reflect the load at all for the specified time intervals. </p><br><p>  If you take an idle system and then feed it with a single-threaded load tied to the processor (one thread per cycle), what will be the one-minute average load value after 60 seconds?  If it were just an average, we would get 1.0.  Here is the experiment schedule: </p><br><p><img src="https://habrastorage.org/web/0b9/cbb/3f5/0b9cbb3f515948c3a1d20dd3ffb4047d.png" alt="image"><br>  <em>Visualization of the experiment on the exponential attenuation of the average load value.</em> </p><br><p>  The so-called "one-minute average" reaches about 0.62 at one minute.  Dr. Neil G√ºnther described this and other experiments in more detail in the <a href="http://www.teamquest.com/import/pdfs/whitepaper/ldavg1.pdf">How It Works</a> article, there are also quite a few Linux-related comments on <a href="">loadavg.c</a> . </p><br><h2 id="nepreryvaemye-zadachi-linux">  Linux Uninterrupted Tasks </h2><br><p>  When average load values ‚Äã‚Äãfirst appeared in Linux, they reflected only the need for processor resources, as in other OSs.  But later they underwent changes, they included not only the tasks performed, but also those that are in an uninterrupted state (TASK_UNINTERRUPTIBLE or nr_uninterruptible).  This state is used by code branches that want to avoid signal interruptions, including tasks blocked by disk I / O, and some locks.  You may have already encountered this state: it is displayed as the "D" state in the output of <code>ps</code> and <code>top</code> .  On the ps (1) page, it is called ‚Äúuninterruptible sleep (usually IO)‚Äù. </p><br><p>  The introduction of an uninterrupted state means that in Linux, the average load values ‚Äã‚Äãmay increase due to disk (or NFS) I / O load, and not just processor resources.  Anyone who is familiar with other operating systems and their average processor loads is initially confused by the inclusion of this state. </p><br><p>  <strong>What for?</strong>  Why was this done in Linux? </p><br><p>  There are a myriad of articles on average loads, many of which mention nr_uninterruptible in Linux.  But I did not see a single explanation, or at least a serious assumption, why they began to take this state into account.  Personally, I would suggest that it should reflect more general resource requirements, and not just for a processor. </p><br><h2 id="v-poiskah-drevnego-patcha-dlya-linux">  In search of an ancient patch for Linux </h2><br><p>  It's easy to see why something changes in Linux: you look at the history of git commits for the desired file and read the descriptions of the changes.  I looked at the history on <a href="">loadavg.c</a> , but the change that adds the unchanged state is dated earlier than the file containing the code from the earlier file.  I checked another file, but it gave nothing: the code ‚Äúskipped‚Äù through different files.  Hoping for good luck, I pushed <code>git log -p</code> around the entire Linux Github repository containing 4 GB of text, and started reading from the end, looking for the place where this code first appeared.  That didn't help me either.  The oldest change in the repository dates back to 2005, when Linus imported Linux 2.6.12-rc2, and the change was made earlier. </p><br><p>  There are old Linux repositories ( <a href="">1</a> and <a href="https://kernel.googlesource.com/pub/scm/linux/kernel/git/nico/archive/">2</a> ), but there is no description of this change in them either.  Trying to find at least the date of its introduction, I studied the archive on <a href="https://www.kernel.org/pub/linux/kernel/Historic/v0.99/">kernel.org</a> and found that it was at 0.99.15, and at 0.99.13 it was not there yet.  However, version 0.99.14 was missing.  I managed to find it and confirm that the desired change appeared in Linux 0.99.14, in November 1993. I hoped that the description of this release would help me, but <a href="http://www.linuxmisc.com/30-linux-announce/4543def681c7f27b.htm">here</a> I didn‚Äôt find an explanation: </p><br><blockquote>  ‚ÄúChanges in the last official release (p13) are too numerous to list (or even recall) ...‚Äù - Linus </blockquote><p>  He mentioned only the main changes, not related to the average value of the load. </p><br><p>  By date, I managed to find <a href="http://lkml.iu.edu/hypermail/linux/kernel/index.html">the mailing list</a> kernel <a href="http://lkml.iu.edu/hypermail/linux/kernel/index.html">archives</a> and a specific patch, but the older letter was dated as early as June 1995: </p><br><blockquote>  "While working on a system that allows for more efficient scaling of mail archives, I accidentally destroyed the current archives (ay oh)." </blockquote><p>  I began to feel damned.  Fortunately, I was able to locate the old linux-devel mailing list archives, pulled from the server backup, often stored as digest archives.  I scanned over 6,000 digests containing over 98,000 letters, of which 30,000 were from 1993.  But found nothing.  It seemed that the original description of the patch was lost forever, and we would not get the answer to the question ‚Äúwhy‚Äù. </p><br><h2 id="proishozhdenie-nepreryvaemosti">  The origin of the continuity </h2><br><p>  But suddenly on the site <a href="http://oldlinux.org/Linux.old/mail-archive/">oldlinux.org</a> in an archived mailbox file for 1993, I found this: </p><br><pre> <code class="hljs perl">From: Matthias Urlichs &lt;urlichs@smurf.sub.org&gt; Subject: Load average broken ? Date: Fri, <span class="hljs-number"><span class="hljs-number">29</span></span> Oct <span class="hljs-number"><span class="hljs-number">1993</span></span> <span class="hljs-number"><span class="hljs-number">11</span></span>:<span class="hljs-number"><span class="hljs-number">37</span></span>:<span class="hljs-number"><span class="hljs-number">23</span></span> +<span class="hljs-number"><span class="hljs-number">0200</span></span>    <span class="hljs-string"><span class="hljs-string">""</span></span>      .    .   ,  ,      <span class="hljs-string"><span class="hljs-string">""</span></span>,   , /,   .  ,    ,            ‚Ä¶   ,           .    ,      ,     . ;-) --- kernel/sched.c.orig Fri Oct <span class="hljs-number"><span class="hljs-number">29</span></span> <span class="hljs-number"><span class="hljs-number">10</span></span>:<span class="hljs-number"><span class="hljs-number">31</span></span>:<span class="hljs-number"><span class="hljs-number">11</span></span> <span class="hljs-number"><span class="hljs-number">1993</span></span> +++ kernel/sched.c Fri Oct <span class="hljs-number"><span class="hljs-number">29</span></span> <span class="hljs-number"><span class="hljs-number">10</span></span>:<span class="hljs-number"><span class="hljs-number">32</span></span>:<span class="hljs-number"><span class="hljs-number">51</span></span> <span class="hljs-number"><span class="hljs-number">1993</span></span> @@ -<span class="hljs-number"><span class="hljs-number">414</span></span>,<span class="hljs-number"><span class="hljs-number">7</span></span> +<span class="hljs-number"><span class="hljs-number">414</span></span>,<span class="hljs-number"><span class="hljs-number">9</span></span> @@ unsigned long nr = <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span>(p = &amp;LAST_TASK; p &gt; &amp;FIRST_TASK; --p) - <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (*p &amp;&amp; (*p)-&gt;<span class="hljs-keyword"><span class="hljs-keyword">state</span></span> == TASK_RUNNING) + <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (*p &amp;&amp; ((*p)-&gt;<span class="hljs-keyword"><span class="hljs-keyword">state</span></span> == TASK_RUNNING) || + (*p)-&gt;<span class="hljs-keyword"><span class="hljs-keyword">state</span></span> == TASK_UNINTERRUPTIBLE) || + (*p)-&gt;<span class="hljs-keyword"><span class="hljs-keyword">state</span></span> == TASK_SWAPPING)) nr += FIXED_1; <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> nr; } -- Matthias Urlichs \ XLink-POP N|rnberg | EMail: urlichs@smurf.sub.org Schleiermacherstra_e <span class="hljs-number"><span class="hljs-number">12</span></span> \ Unix+Linux+Mac | Phone: ...please <span class="hljs-keyword"><span class="hljs-keyword">use</span></span> email. <span class="hljs-number"><span class="hljs-number">90491</span></span> N|rnberg (Germany) \ Consulting+Networking+Programming+etc<span class="hljs-string"><span class="hljs-string">'ing 42</span></span></code> </pre> <br><p>  It was just incredible to read about the reflections of 24 years ago, which caused this change.  The letter confirmed that the change in the metric should have taken into account the needs of other system resources, and not just the processor.  Linux has moved from ‚Äúaverage processor load‚Äù to something like ‚Äúaverage system load‚Äù. </p><br><p>  The above example with a disk with a slower swap is not without meaning: reducing the system performance, the need for resources (processes that are executed and waiting for the queue) should increase.  However, the average load values ‚Äã‚Äãdecreased because they took into account only the CPU running states, but not the swapping states.  Mattias rightly considered this illogical, and therefore corrected. </p><br><h2 id="nepreryvaemost-segodnya">  Continuity today </h2><br><p>  But do the average load values ‚Äã‚Äãin Linux sometimes not rise too high, which can no longer be explained by disk I / O?  Yes, this is true, although I assume that this is a consequence of a new branch of code that uses TASK_UNINTERRUPTIBLE, which did not exist in 1993.  In Linux 0.99.14, there were 13 code branches that directly used TASK_UNINTERRUPTIBLE or TASK_SWAPPING (the paging state was later removed from Linux).  Today in Linux 4.12 there are almost 400 branches using TASK_UNINTERRUPTIBLE, including some blocking primitives.  It is likely that one of these branches should not be taken into account in the average load value.  I will check if this is so when I see again that the value is too high, and see if this can be corrected. </p><br><p>  I wrote to Mattias and asked him 24 years later about his change in the average load.  He answered in an hour: </p><br><blockquote>  ‚ÄúThe essence of the‚Äú average load ‚Äùis to provide a numerical estimate of the employment of the system from the point of view of a person.  TASK_UNINTERRUPTIBLE means (means?) That the process is waiting for something like a disk read, which affects the system load.  A system that strongly depends on a disk can be very inhibited, but the average TASK_RUNNING value will be around 0.1, which is completely useless. ‚Äù </blockquote><p>  So Matthias is still confident in the correctness of this step, at least as to what TASK_UNINTERRUPTIBLE was intended for. </p><br><p>  But today TASK_UNINTERRUPTIBLE corresponds to more things.  Do we need to change the average load values ‚Äã‚Äãso that they reflect only the CPU and disk resource requirements?  Peter Zijstra has already sent me a good idea: consider <code>task_struct-&gt;in_iowait</code> instead of TASK_UNINTERRUPTIBLE in the average load, because it more closely corresponds to disk I / O.  However, this raises another question: what do we really want?  Do we want to measure system resource requirements as threads of execution, or do we need physical resources?  If the first, then you need to take into account uninterrupted blocking, because these threads consume system resources.  They are not idle.  So the average load in Linux is probably already working as it should. </p><br><p>  To better understand the uninterrupted code branches, I would like to measure them in action.  Then you can evaluate different examples, measure the time spent and understand whether this makes sense. </p><br><h2 id="izmerenie-nepreryvaemyh-zadach">  Measurement of uninterrupted tasks </h2><br><p>  Here is an off-processor (off-CPU) <a href="http://www.brendangregg.com/blog/2016-01-20/ebpf-offcpu-flame-graph.html">flame graph</a> from a production-server covering 60 seconds and showing only kernel stacks, on which I left only the TASK_UNINTERRUPTIBLE ( <a href="">SVG</a> ) state. </p><br><p>  The graph reflects many examples of uninterrupted code branches: </p><br><p><img src="https://habrastorage.org/web/038/823/b5d/038823b5dae641539b2504edc496a87d.png" alt="image"></p><br><p>  If you are not familiar with flame graphs: you can <a href="">click</a> on the blocks, examine the whole stacks, which are displayed as columns of blocks.  The size of the X axis is proportional to the time spent blocking out of the processor, and the sort order (from left to right) does not matter.  For non-processor stacks, the color blue is selected (for the internal processor stacks I use warm colors), and variations in saturation indicate different frames. </p><br><p>  I generated the graph using my <a href="https://github.com/iovisor/bcc">bcc</a> offcputime tool (for working, it needs the eBPF capabilities of Linux 4.8+), as well as applications for creating <a href="https://github.com/brendangregg/FlameGraph">flame graphs</a> : </p><br><pre> <code class="hljs kotlin"># ./bcc/tools/offcputime.py -K --state <span class="hljs-number"><span class="hljs-number">2</span></span> -f <span class="hljs-number"><span class="hljs-number">60</span></span> &gt; <span class="hljs-keyword"><span class="hljs-keyword">out</span></span>.stacks # awk <span class="hljs-string"><span class="hljs-string">'{ print $1, $2 / 1000 }'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">out</span></span>.stacks | ./FlameGraph/flamegraph.pl --color=io --countname=ms &gt; <span class="hljs-keyword"><span class="hljs-keyword">out</span></span>.offcpu.svgb&gt;</code> </pre> <br><p>  I use awk to change the output from microsecond to millisecond.  Offcputime "--state 2" corresponds to TASK_UNINTERRUPTIBLE (see sched.h), this is an option I added for the sake of this article.  For the first time, Joseph Bachik did this with his <a href="https://github.com/josefbacik/kernelscope">kernelscope</a> tool, which also uses bcc and flame graphics.  In my examples, I only show kernel stacks, but offcputime.py also supports custom stacks. </p><br><p>  As for the above graph: it displays only 926 ms out of 60 seconds spent in a state of uninterrupted sleep.  This adds a total of 0.015 to our average load values.  This is the time spent by some cgroup branches, but this server does not perform many disk I / O operations. </p><br><p>  But a more interesting graph covering only 10 seconds ( <a href="">SVG</a> ): </p><br><p><img src="https://habrastorage.org/web/921/044/e94/921044e948ae46abac41e9499eb4f48b.png" alt="image"></p><br><p>  The wider tower on the right refers to the <code>systemd-journal  proc_pid_cmdline_read()</code> being blocked <code>systemd-journal  proc_pid_cmdline_read()</code> (reading / proc / PID / cmdline), which adds 0.07 to the average load.  On the left, a wider page fault tower, also ending in <code>rwsem_down_read_failed()</code> (adds 0.23 to the average load).  I painted these functions in purple using the search feature in my tool.  Here is the code snippet from <code>rwsem_down_read_failed()</code> : </p><br><pre> <code class="hljs kotlin"> <span class="hljs-comment"><span class="hljs-comment">/* wait to be given the lock */</span></span> <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> (<span class="hljs-literal"><span class="hljs-literal">true</span></span>) { set_task_state(tsk, TASK_UNINTERRUPTIBLE); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (!waiter.task) <span class="hljs-keyword"><span class="hljs-keyword">break</span></span>; schedule(); }</code> </pre> <br><p>  This is a lock acquisition code using TASK_UNINTERRUPTIBLE.  Linux has interrupted and uninterrupted versions of mutex acquire functions (for example, <code>mutex_lock()</code> and <code>mutex_lock_interruptible()</code> , <code>down()</code> and <code>down_interruptible()</code> for semaphores).  Interruptible versions allow you to interrupt tasks by a signal, and then wake up to continue processing before a lock is acquired.  The time spent sleeping in uninterrupted blocking usually adds little to the average load, and in this case the gain reaches 0.3.  If there were much more, it would be worthwhile to find out whether it is possible to reduce blocking conflicts (for example, I start digging into <code>systemd-journal</code> and <code>proc_pid_cmdline_read()</code> !) In order to improve performance and reduce the average load value. </p><br><p>  Does it make sense to consider these branches of the code in the average load?  I would say yes.  These threads are stopped in the middle of execution and blocked.  They are not idle.  They need resources, even if they are software, not hardware. </p><br><h2 id="analiziruem-srednie-znacheniya-nagruzki-v-linux">  Analyzing average load values ‚Äã‚Äãin Linux </h2><br><p>  Is it possible to fully decompose into components the average load?  Here is an example: on an idle 8-processor system, I launched tar to archive several uncached files.  The application took a few minutes, for the most part it was blocked by disk read operations.  Here are the statistics from three different terminal windows: </p><br><pre> <code class="hljs perl">terma$ pidstat -p <span class="hljs-string"><span class="hljs-string">`pgrep -x tar`</span></span> <span class="hljs-number"><span class="hljs-number">60</span></span> Linux <span class="hljs-number"><span class="hljs-number">4.9</span></span>.<span class="hljs-number"><span class="hljs-number">0</span></span>-rc5-virtual (bgregg-xenial-bpf-i-0b7296777a2585be1) 08/<span class="hljs-number"><span class="hljs-number">01</span></span>/<span class="hljs-number"><span class="hljs-number">2017</span></span> _x86_64<span class="hljs-number"><span class="hljs-number">_</span></span> (<span class="hljs-number"><span class="hljs-number">8</span></span> CPU) <span class="hljs-number"><span class="hljs-number">10</span></span>:<span class="hljs-number"><span class="hljs-number">15</span></span>:<span class="hljs-number"><span class="hljs-number">51</span></span> PM UID PID %usr %system %guest %CPU CPU Command <span class="hljs-number"><span class="hljs-number">10</span></span>:<span class="hljs-number"><span class="hljs-number">16</span></span>:<span class="hljs-number"><span class="hljs-number">51</span></span> PM <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">18468</span></span> <span class="hljs-number"><span class="hljs-number">2.85</span></span> <span class="hljs-number"><span class="hljs-number">29.77</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">00</span></span> <span class="hljs-number"><span class="hljs-number">32.62</span></span> <span class="hljs-number"><span class="hljs-number">3</span></span> tar termb$ iostat -<span class="hljs-keyword"><span class="hljs-keyword">x</span></span> <span class="hljs-number"><span class="hljs-number">60</span></span> [...] avg-cpu: %user %nice %system %iowait %steal %idle <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">54</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">00</span></span> <span class="hljs-number"><span class="hljs-number">4.03</span></span> <span class="hljs-number"><span class="hljs-number">8.24</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.09 <span class="hljs-number"><span class="hljs-number">87.10</span></span> Device: rrqm/<span class="hljs-keyword"><span class="hljs-keyword">s</span></span> wrqm/sr/sw/<span class="hljs-keyword"><span class="hljs-keyword">s</span></span> rkB/<span class="hljs-keyword"><span class="hljs-keyword">s</span></span> wkB/<span class="hljs-keyword"><span class="hljs-keyword">s</span></span> avgrq-sz avgqu-sz await r_await w_await svctm %util xvdap1 <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">00</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">05</span></span> <span class="hljs-number"><span class="hljs-number">30.83</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">18</span></span> <span class="hljs-number"><span class="hljs-number">638.33</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">93</span></span> <span class="hljs-number"><span class="hljs-number">41.22</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">06</span></span> <span class="hljs-number"><span class="hljs-number">1.84</span></span> <span class="hljs-number"><span class="hljs-number">1.83</span></span> <span class="hljs-number"><span class="hljs-number">3.64</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">39</span></span> <span class="hljs-number"><span class="hljs-number">1.21</span></span> xvdb <span class="hljs-number"><span class="hljs-number">958.18</span></span> <span class="hljs-number"><span class="hljs-number">1333.83</span></span> <span class="hljs-number"><span class="hljs-number">2045.30</span></span> <span class="hljs-number"><span class="hljs-number">499.38</span></span> <span class="hljs-number"><span class="hljs-number">60965.27</span></span> <span class="hljs-number"><span class="hljs-number">63721.67</span></span> <span class="hljs-number"><span class="hljs-number">98.00</span></span> <span class="hljs-number"><span class="hljs-number">3.97</span></span> <span class="hljs-number"><span class="hljs-number">1.56</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">31</span></span> <span class="hljs-number"><span class="hljs-number">6.67</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">24</span></span> <span class="hljs-number"><span class="hljs-number">60.47</span></span> xvdc <span class="hljs-number"><span class="hljs-number">957.63</span></span> <span class="hljs-number"><span class="hljs-number">1333.78</span></span> <span class="hljs-number"><span class="hljs-number">2054.55</span></span> <span class="hljs-number"><span class="hljs-number">499.38</span></span> <span class="hljs-number"><span class="hljs-number">61018.87</span></span> <span class="hljs-number"><span class="hljs-number">63722.13</span></span> <span class="hljs-number"><span class="hljs-number">97.69</span></span> <span class="hljs-number"><span class="hljs-number">4.21</span></span> <span class="hljs-number"><span class="hljs-number">1.65</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">33</span></span> <span class="hljs-number"><span class="hljs-number">7.08</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">24</span></span> <span class="hljs-number"><span class="hljs-number">61.65</span></span> md<span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">00</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">00</span></span> <span class="hljs-number"><span class="hljs-number">4383.73</span></span> <span class="hljs-number"><span class="hljs-number">1991.63</span></span> <span class="hljs-number"><span class="hljs-number">121984.13</span></span> <span class="hljs-number"><span class="hljs-number">127443.80</span></span> <span class="hljs-number"><span class="hljs-number">78.25</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">00</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">00</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">00</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">00</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">00</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">00</span></span> termc$ uptime <span class="hljs-number"><span class="hljs-number">22</span></span>:<span class="hljs-number"><span class="hljs-number">15</span></span>:<span class="hljs-number"><span class="hljs-number">50</span></span> up <span class="hljs-number"><span class="hljs-number">154</span></span> days, <span class="hljs-number"><span class="hljs-number">23</span></span>:<span class="hljs-number"><span class="hljs-number">20</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span> users, load average: <span class="hljs-number"><span class="hljs-number">1.25</span></span>, <span class="hljs-number"><span class="hljs-number">1.19</span></span>, <span class="hljs-number"><span class="hljs-number">1.05</span></span> [...] termc$ uptime <span class="hljs-number"><span class="hljs-number">22</span></span>:<span class="hljs-number"><span class="hljs-number">17</span></span>:<span class="hljs-number"><span class="hljs-number">14</span></span> up <span class="hljs-number"><span class="hljs-number">154</span></span> days, <span class="hljs-number"><span class="hljs-number">23</span></span>:<span class="hljs-number"><span class="hljs-number">21</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span> users, load average: <span class="hljs-number"><span class="hljs-number">1.19</span></span>, <span class="hljs-number"><span class="hljs-number">1.17</span></span>, <span class="hljs-number"><span class="hljs-number">1.06</span></span></code> </pre> <br><p>  I also built a non-CPU flame graph exclusively for uninterrupted state ( <a href="">SVG</a> ): </p><br><p><img src="https://habrastorage.org/web/fb8/f01/156/fb8f011561534332bc974507019ccb39.png" alt="image"></p><br><p>  Average last minute load was 1.19.  Let's decompose into components: </p><br><ul><li>  0.33 - processor time tar (pidstat) </li><li>  0.67 - uninterrupted reads from the disk, presumably (on the graph 0.69, I believe that for him the data collection began a little later and covers a slightly different time range) </li><li>  0.04 - other processor consumers (user mpstat + system, minus processor consumption by tar from pidstat) </li><li>  0.11 - uninterrupted disk input / output of the core workers, dumps to disk (on the chart there are two towers on the left) </li></ul><br><p>  The total is 1.15.  Not enough yet 0.04.  In part, this may include rounding and measurement errors of the interval shifts, but mainly this may be due to the fact that the average load is an exponentially decaying sliding sum, while the other metrics used (pidstat, iostat) are normal averages.  Up to 1.19, the one-minute average load was 1.25, which means that one of the above still pulls the metric up.  How much?  According to my earlier schedules, at one minute mark, 62% of the metric accounted for the current minute, and the rest - for the previous one.  So 0.62 x 1.15 + 0.38 x 1.25 = 1.18.  Close enough to get 1.19. </p><br><p>  In this system, one thread (tar) performs the work, plus a little more time is spent on threads of the kernel workers, so the Linux average load report at 1.19 looks reasonable.  If I measured the ‚Äúaverage processor load,‚Äù I would be shown only 0.37 (calculated value from mpstat), which is correct only for processor resources, but does not take into account the fact that more than one thread needs to be processed. </p><br><p>  I hope this example showed you that these numbers are not taken from the ceiling (processor + uninterrupted), and you can decompose them yourself into components. </p><br><h2 id="smysl-srednih-znacheniy-nagruzki-v-linux">  The meaning of load average Linux </h2><br><p>  I grew up on operating systems in which the average load values ‚Äã‚Äãapplied only to the processor, so the Linux version always strained me.  Perhaps the real problem is that the term ‚Äúaverage load‚Äù is as ambiguous as ‚Äúinput-output‚Äù.  What kind of input / output?  Drive?  File system?  Networks? .. Similarly, average loads of what?  CPU?  Systems?     : </p><br><ul><li>  Linux   ‚Äî  (  ) <strong>¬´    ¬ª</strong> ,   .          (, ,  ).  ,     ,    . :     . </li><li>      ‚Äî  <strong>¬´    ¬ª</strong> .    ,       . :      (  ). </li></ul><br><p>      : <strong>¬´     ¬ª</strong> ,        (  ). </p><br><p> , -     Linux   ,    ,    :    ,  ,     .     . </p><br><h2 id="chto-takoe-horoshie-ili-plohie-srednie-nagruzki">   ¬´¬ª  ¬´¬ª  ? </h2><br><p><img src="https://habrastorage.org/web/27d/7b9/ae8/27d7b9ae8aba4416936c3a499e1f7f71.png" alt="image"></p><br><p>           :  ,      ,        .      . </p><br><p>       -         ,     1,0,      .   ,     (  )      .     1,5   ,            ,       . </p><br><p>      ,             11  16 (  5,5  8).   ,   .    :      /   2. </p><br><p>       Linux:    ,     ,         .    <em></em> :   ,        20,   40,       ,  ,  . </p><br><h2 id="bolee-podhodyaschie-metriki">    </h2><br><p>     Linux      (, ,  ),    ,  .     ,    . ,  : </p><br><ul><li> <strong>   (per-CPU utilization):</strong> ,  <code>mpstat -P ALL 1</code> . </li><li> <strong>     (per-process CPU utilization):</strong> , <code>top, pidstat 1</code>   . </li><li> <strong>   ()    (per-thread run queue (scheduler) latency):</strong> ,  /proc/PID/schedstats, delaystats, perf sched </li><li>     (CPU run queue latency): ,  <code>/proc/schedstat</code> , <code>perf sched</code> ,   <a href="http://www.brendangregg.com/blog/2016-10-08/linux-bcc-runqlat.html">runqlat</a> <a href="https://github.com/iovisor/bcc">bcc</a> . </li><li> <strong>    (CPU run queue length):</strong> ,  vmstat 1   'r',    <code>runqlen bcc</code> . </li></ul><br><p>   ‚Äî  ,   ‚Äî   (saturation metrics).       ,    ‚Äî     .      ‚Äî     ( ):  ,  /     ,     .       . ,        .         ,     . </p><br><p>  Linux 4.6  <code>schedstats</code> ( <code>sysctl kernel.sched_schedstats</code> )   ,    .   (delay accounting)        <a href="https://github.com/uber-common/cpustat">cpustat</a> ,        <a href="https://github.com/hishamhm/htop/issues/665">htop</a> ,      . , ,  ,     ( )     /proc/sched_debug: </p><br><pre> <code class="hljs swift">$ awk '<span class="hljs-type"><span class="hljs-type">NF</span></span> &gt; <span class="hljs-number"><span class="hljs-number">7</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> ($<span class="hljs-number"><span class="hljs-number">1</span></span> == <span class="hljs-string"><span class="hljs-string">"task"</span></span>) { <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (h == <span class="hljs-number"><span class="hljs-number">0</span></span>) { <span class="hljs-built_in"><span class="hljs-built_in">print</span></span>; h=<span class="hljs-number"><span class="hljs-number">1</span></span> } } <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> { <span class="hljs-built_in"><span class="hljs-built_in">print</span></span> } }' /proc/sched_debug task <span class="hljs-type"><span class="hljs-type">PID</span></span> tree-key switches prio wait-time sum-exec sum-sleep systemd <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-number"><span class="hljs-number">5028.684564</span></span> <span class="hljs-number"><span class="hljs-number">306666</span></span> <span class="hljs-number"><span class="hljs-number">120</span></span> <span class="hljs-number"><span class="hljs-number">43.133899</span></span> <span class="hljs-number"><span class="hljs-number">48840.448980</span></span> <span class="hljs-number"><span class="hljs-number">2106893.162610</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> /<span class="hljs-keyword"><span class="hljs-keyword">init</span></span>.scope ksoftirqd/<span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">3</span></span> <span class="hljs-number"><span class="hljs-number">99071232057.573051</span></span> <span class="hljs-number"><span class="hljs-number">1109494</span></span> <span class="hljs-number"><span class="hljs-number">120</span></span> <span class="hljs-number"><span class="hljs-number">5.682347</span></span> <span class="hljs-number"><span class="hljs-number">21846.967164</span></span> <span class="hljs-number"><span class="hljs-number">2096704.183312</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> / kworker/<span class="hljs-number"><span class="hljs-number">0</span></span>:0H <span class="hljs-number"><span class="hljs-number">5</span></span> <span class="hljs-number"><span class="hljs-number">99062732253.878471</span></span> <span class="hljs-number"><span class="hljs-number">9</span></span> <span class="hljs-number"><span class="hljs-number">100</span></span> <span class="hljs-number"><span class="hljs-number">0.014976</span></span> <span class="hljs-number"><span class="hljs-number">0.037737</span></span> <span class="hljs-number"><span class="hljs-number">0.000000</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> / migration/<span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">9</span></span> <span class="hljs-number"><span class="hljs-number">0.000000</span></span> <span class="hljs-number"><span class="hljs-number">1995690</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">0.000000</span></span> <span class="hljs-number"><span class="hljs-number">25020.580993</span></span> <span class="hljs-number"><span class="hljs-number">0.000000</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> / lru-add-drain <span class="hljs-number"><span class="hljs-number">10</span></span> <span class="hljs-number"><span class="hljs-number">28.548203</span></span> <span class="hljs-number"><span class="hljs-number">2</span></span> <span class="hljs-number"><span class="hljs-number">100</span></span> <span class="hljs-number"><span class="hljs-number">0.000000</span></span> <span class="hljs-number"><span class="hljs-number">0.002620</span></span> <span class="hljs-number"><span class="hljs-number">0.000000</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> / watchdog/<span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">11</span></span> <span class="hljs-number"><span class="hljs-number">0.000000</span></span> <span class="hljs-number"><span class="hljs-number">3368570</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">0.000000</span></span> <span class="hljs-number"><span class="hljs-number">23989.957382</span></span> <span class="hljs-number"><span class="hljs-number">0.000000</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> / cpuhp/<span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">12</span></span> <span class="hljs-number"><span class="hljs-number">1216.569504</span></span> <span class="hljs-number"><span class="hljs-number">6</span></span> <span class="hljs-number"><span class="hljs-number">120</span></span> <span class="hljs-number"><span class="hljs-number">0.000000</span></span> <span class="hljs-number"><span class="hljs-number">0.010958</span></span> <span class="hljs-number"><span class="hljs-number">0.000000</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> / xenbus <span class="hljs-number"><span class="hljs-number">58</span></span> <span class="hljs-number"><span class="hljs-number">72026342.961752</span></span> <span class="hljs-number"><span class="hljs-number">343</span></span> <span class="hljs-number"><span class="hljs-number">120</span></span> <span class="hljs-number"><span class="hljs-number">0.000000</span></span> <span class="hljs-number"><span class="hljs-number">1.471102</span></span> <span class="hljs-number"><span class="hljs-number">0.000000</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> / khungtaskd <span class="hljs-number"><span class="hljs-number">59</span></span> <span class="hljs-number"><span class="hljs-number">99071124375.968195</span></span> <span class="hljs-number"><span class="hljs-number">111514</span></span> <span class="hljs-number"><span class="hljs-number">120</span></span> <span class="hljs-number"><span class="hljs-number">0.048912</span></span> <span class="hljs-number"><span class="hljs-number">5708.875023</span></span> <span class="hljs-number"><span class="hljs-number">2054143.190593</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> / [...] dockerd <span class="hljs-number"><span class="hljs-number">16014</span></span> <span class="hljs-number"><span class="hljs-number">247832.821522</span></span> <span class="hljs-number"><span class="hljs-number">2020884</span></span> <span class="hljs-number"><span class="hljs-number">120</span></span> <span class="hljs-number"><span class="hljs-number">95.016057</span></span> <span class="hljs-number"><span class="hljs-number">131987.990617</span></span> <span class="hljs-number"><span class="hljs-number">2298828.078531</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> /system.slice/docker.service dockerd <span class="hljs-number"><span class="hljs-number">16015</span></span> <span class="hljs-number"><span class="hljs-number">106611.777737</span></span> <span class="hljs-number"><span class="hljs-number">2961407</span></span> <span class="hljs-number"><span class="hljs-number">120</span></span> <span class="hljs-number"><span class="hljs-number">0.000000</span></span> <span class="hljs-number"><span class="hljs-number">160704.014444</span></span> <span class="hljs-number"><span class="hljs-number">0.000000</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> /system.slice/docker.service dockerd <span class="hljs-number"><span class="hljs-number">16024</span></span> <span class="hljs-number"><span class="hljs-number">101.600644</span></span> <span class="hljs-number"><span class="hljs-number">16</span></span> <span class="hljs-number"><span class="hljs-number">120</span></span> <span class="hljs-number"><span class="hljs-number">0.000000</span></span> <span class="hljs-number"><span class="hljs-number">0.915798</span></span> <span class="hljs-number"><span class="hljs-number">0.000000</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> /system.slice/ [...]</code> </pre> <br><p>   ,         .     <a href="http://www.brendangregg.com/usemethod.html"> USE</a> ,    <a href="http://www.brendangregg.com/USEmethod/use-linux.html">Linux-</a> . </p><br><p>     ,   ,     .            .         ,    .        ( ),     ( ),      .    ,        . </p><br><p>   ,       , ‚Äî    .        ,    ,        ,     ,        .          ,     . </p><br><h2 id="zaklyuchenie">  Conclusion </h2><br><p>  1993  Linux-      ,          ¬´    ¬ª  ¬´   ¬ª.        ,          ,     .          (  ,     ).         ,       1, 5  15 .       ,             . </p><br><p>      Linux     ,         .                (   ,    ),      ,   . </p><br><p>   ,        Linux  1993- ‚Äî      , ‚Äî     .    bcc/eBPF     Linux-        ,      -.        ,    ,        .        ,     . </p><br><p>       <a href="">kernel/sched/loadavg.c</a>   Linux: </p><br><blockquote>     ,       . <strong>  ,     .</strong>    ,         tickless-. </blockquote><br><h2 id="ssylki">  Links </h2><br><ul><li> Saltzer, J., and J. Gintell. ‚Äú <a href="http://web.mit.edu/Saltzer/www/publications/instrumentation.html">The Instrumentation of Multics</a> ,‚Äù CACM, August 1970 (  ). </li><li>    <a href="">system_performance_graph</a>  Multics (  ). </li><li>   <a href="https://github.com/PDP-10/tenex">TENEX</a> (    SCHED.MAC). </li><li> <a href="https://tools.ietf.org/html/rfc546">RFC 546</a> "TENEX Load Averages for July 1973" (     ). </li><li> Bobrow, D., et al. ‚ÄúTENEX: A Paged Time Sharing System for the PDP-10,‚Äù Communications of the ACM, March 1972 (    ). </li><li> Gunther, N. "UNIX Load Average Part 1: How It Works" <a href="http://www.teamquest.com/import/pdfs/whitepaper/ldavg1.pdf">PDF</a> (  ). </li><li>     <a href="http://www.linuxmisc.com/30-linux-announce/4543def681c7f27b.htm">Linux 0.99 patchlevel 14</a> . </li><li>         <a href="http://oldlinux.org/Linux.old/mail-archive/">oldlinux.org</a> ( alan-old-funet-lists/kernel.1993.gz,    linux-,    ). </li><li>   Linux kernel/sched.c     : <a href="http://kernelhistory.sourcentral.org/linux-0.99.13/%3Ff%3D/linux-0.99.13/S/449.html%2523L332">0.99.13</a> , <a href="http://kernelhistory.sourcentral.org/linux-0.99.14/%3Ff%3D/linux-0.99.14/S/323.html%2523L412">0.99.14</a> . </li><li>   Linux 0.99  <a href="https://www.kernel.org/pub/linux/kernel/Historic/v0.99/">kernel.org</a> . </li><li>       Linux: <a href="">loadavg.c</a> , <a href="">loadavg.h</a> </li><li>   <a href="https://github.com/iovisor/bcc">bcc</a> ,   <a href="http://www.brendangregg.com/blog/2016-01-20/ebpf-offcpu-flame-graph.html">offcputime</a> ,    TASK_UNINTERRUPTIBLE. </li><li> <a href="http://www.brendangregg.com/flamegraphs.html">-</a> ,     . </li></ul></div>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <p>Source: <a href="https://habr.com/ru/post/335326/">https://habr.com/ru/post/335326/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../335304/index.html">Combining actors and the SEDA approach: why and how?</a></li>
<li><a href="../335306/index.html">A few words about testing complex hardware systems</a></li>
<li><a href="../335314/index.html">Startup of the day (July 2017)</a></li>
<li><a href="../335318/index.html">Angular 4 Material. Part 1 - Creating and Configuring a Project</a></li>
<li><a href="../335324/index.html">Vivaldi 1.11 - the desire for comfort</a></li>
<li><a href="../335328/index.html">IOS UI tests: why you need to believe in QA friendship and development, but don't flatter yourself</a></li>
<li><a href="../335330/index.html">How to start young mobile game developers from Russia in the current reality [Part 2]</a></li>
<li><a href="../335332/index.html">Learning to program for Android</a></li>
<li><a href="../335336/index.html">CRM-system: full implementation algorithm</a></li>
<li><a href="../335338/index.html">Expand Emercoin testnet and get a lot of free coins</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>