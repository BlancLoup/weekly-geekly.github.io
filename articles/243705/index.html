<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Analyze text with Azure Machine Learning</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="In this post, I‚Äôll tell you how you can use Microsoft Azure Machine Learning to analyze text tonality, as well as what problems you may encounter when...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Analyze text with Azure Machine Learning</h1><div class="post__text post__text-html js-mediator-article">  In this post, I‚Äôll tell you how you can use <a href="http://azure.microsoft.com/en-us/services/machine-learning/">Microsoft Azure Machine Learning</a> to analyze text tonality, as well as what problems you may encounter when using Azure ML and how to get around them. <br><br>  What is the analysis of tonality is well described in the article <a href="http://habrahabr.ru/post/149605/">‚ÄúTeach the computer to the senses (sentiment analysis in Russian)‚Äù</a> . <br>  Our goal will be to build a web service that accepts some text as input and returns 1 if the text is positive, and -1 if it is negative.  Microsoft Azure Machine Learning is ideally (almost) suitable for this task, as there is a built-in ability to publish the results of calculations as a web service and support for the R language - this eliminates the need to write your crutches and configure your virtual machine / web server.  In general, all the benefits of cloud technology.  In addition, it was recently <a href="http://habrahabr.ru/company/microsoft/blog/242561/">announced</a> that everyone can try Azure ML even without an Azure account and a credit card - only a Microsoft Account is needed. <br><a name="habracut"></a><br>  The whole process will be reduced to two points: <br><ul><li>  Creating and training models </li><li>  Using the resulting model </li></ul><br><br><h4>  Model training </h4><br>  To recognize tonality we will use a naive Bayes classifier.  For training, we need a tagged sample containing a set of some texts and corresponding estimates.  Next, for this set, a document-term matrix is ‚Äã‚Äãbuilt, where the rows correspond to the documents, and the columns represent the terms that are found in them.  Each cell contains the number of repetitions of this term in the corresponding document.  Thus, for the two documents " <i>Today is a good weather</i> " and " <i>I do not feel very well, the weather is to blame,</i> " the document-term matrix will look like this: <br><table><tbody><tr><td></td><td>  Today </td><td>  the good </td><td>  weather </td><td>  I </td><td>  not </td><td>  highly </td><td>  OK </td><td>  myself </td><td>  feel </td><td>  is to blame </td></tr><tr><td>  doc1 </td><td>  one </td><td>  one </td><td>  one </td><td>  0 </td><td>  0 </td><td>  0 </td><td>  0 </td><td>  0 </td><td>  0 </td><td>  0 </td></tr><tr><td>  doc2 </td><td>  0 </td><td>  0 </td><td>  one </td><td>  one </td><td>  one </td><td>  one </td><td>  one </td><td>  one </td><td>  one </td><td>  one </td></tr></tbody></table>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Please note that in the table there are two forms of the same word - ‚Äúgood‚Äù and ‚Äúgood‚Äù.  This can be avoided by using stemming (those cutting the endings according to certain rules), but then the results may worsen.  Read more about this, as well as the weighting of terms and N-grams, see the article at the link at the beginning of the post. <br><br>  After constructing this matrix, it can be directly used to train the Bayes classifier.  But let's move on from theory to practice. <br><br><h5>  Practice </h5><br>  We will evaluate the tone of posts on the walls in the VC.  Accordingly, for the training of the classifier, a sample of posts with a tonality is needed.  It can be <a href="">downloaded from this link</a> (attention, this sample was marked during our (I, <a href="http://habrahabr.ru/users/astapp/" class="user_link">ASTAPP</a> and <a href="http://habrahabr.ru/users/mkulikow/" class="user_link">MKulikow</a> ) participation in the <a href="http://habrahabr.ru/company/microsoft/blog/241660/">Big Data hackathon</a> , and, accordingly, it does not pretend to high accuracy and may contain errors, since the markup was made in large in a hurry).  In this sample, there are about 3500 random posts from random VKontakte walls, of which 341 are positive and 115 are negative.  Evaluation of posts was carried out on a scale from -10 to 10. <br><br>  So let's create an experiment in Azure ML to train a classifier.  Go to the <a href="https://studio.azureml.net/Home/">ML home page</a> and click New -&gt; Experiment -&gt; Blank Experiment.  Before you open the pure field of the new experiment.  From above, you can immediately change the name to a more decent one - habr_article_sentiment, for example. <br><br>  Now you need to upload our dataset to Azure.  In theory, to do this, click New -&gt; Dataset -&gt; From Local File, and then select Generic CSV File with a header from the list ‚ÄúSelect a type for new dataset:‚Äù.  However, there is a problem - if the line contains a newline character (\ n), even if it is escaped with quotation marks, then the import will be incorrect.  And in the posts on the walls of the VK this symbol is necessarily present.  This bug can be circumvented by uploading a CSV file to the database, and then using the Reader block from the Data Input and Output section to load data.  Drag this block onto the experiment field, configure the database connection and set the SQL query for the data selection (do not forget to tick the ‚ÄúAccept any server certificate (insecure)‚Äù box. ‚ÄùThe SQL query will look like this: <br><br><pre><code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> score <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> grade, <span class="hljs-built_in"><span class="hljs-built_in">text</span></span> <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> tmp.big_data_hack</code> </pre> <br><br>  Now you can run the experiment and check what will be at the output of the Reader block - to do this, click on the Run button at the bottom of the page, and after completion of execution, click on the output node of the right mouse button and select "Visualize".  You should get something like this: <br><br><img src="https://habrastorage.org/files/b9d/7b0/a42/b9d7b0a4213d42ccb2d35de7afe035d4.png" alt="image"><br><br>  In the block on the right, you can see some statistics - it is clear that the maximum value is 70, this is an obvious typo in the marking process, and there are unmarked lines (lines with a neutral tone). <br><br>  Now let's remove the empty lines, and also give estimates from the scale from -10 to 10 to the categorical assessment: -1, 0 and 1. To do this, use the blocks Missing Value Scrubber and Clip Values.  Using the search in the panel with blocks, find and drag the Missing Value Scrubber block on the experiment field and connect its input with the output of the Reader block: <br><br><img src="https://habrastorage.org/files/1ca/919/afd/1ca919afd09043dcad27d8bbef87456c.png" alt="image"><br><br>  Set the settings of this block as in the picture above - here, I think, everything is clear. <br><br>  Now drag the Clip Values ‚Äã‚Äãblock - this block is used to detect and replace outliers and is perfect for our purposes - just set the min.  and max.  value as -1 and 1 respectively. <br><br><img src="https://habrastorage.org/files/83a/247/a60/83a247a604474c9cbea0764fdf095370.png" alt="image"><br><br>  Please note that this block has a Columns Selector - you should choose which columns it will process.  The default is all digital.  Let's select our grade column ‚Äî click Launch Column Selector and set the following settings: <br><br><img src="https://habrastorage.org/files/a40/79b/cfe/a4079bcfef054a2ab3f637957613265f.png" alt="image"><br><br>  Let's try to run the experiment and see what happens - click Run and visualize the output of the Clip Values ‚Äã‚Äãblock: <br><br><img src="https://habrastorage.org/files/057/70b/07d/05770b07d2c64de6962fa27d6e496bb8.png" alt="image"><br><br>  Wonderful!  Just what is needed - now we can go directly to the training of the classifier.  Since Azure ML supports the execution of arbitrary R-scripts, we will use the naive Bayes classifier from the e1071 package for R. Drag the Execute R Script block onto the experiment field and connect the Clip Values ‚Äã‚Äãoutput to the Dataset1 input point: <br><br><img src="https://habrastorage.org/files/5ae/ac7/abf/5aeac7abfad046839b2570035eb92a01.png" alt="image"><br><br>  It should immediately be said: ideally, the process of teaching the model and its subsequent use is as follows: we create an experiment, choose the model we want to use, teach it and carry out an accuracy check.  Then, we simply right-click on the output of the model and select ‚ÄúSave as Trained Model‚Äù.  After that, the trained model is saved in the block section, and we can always use it - those in order to publish a web service, we simply create a new experiment, drag our trained model there and set the weekend output points.  Everything is very easy and understandable.  However, at the moment there is no possibility to save the trained model from the block of type ‚ÄúExecute R Script‚Äù.  I very much hope that this will be fixed soon (vote, please, for this <a href="http://feedback.azure.com/forums/257792-machine-learning/suggestions/6528448-save-r-script-as-trained-model">here</a> ).  However, the ability to save and use the model from the R-script is still there: you can serialize an object into a set of bytes, and then submit it to the output of the block (after converting this set to a single-column DataFrame, since only DataFram 'can be fed to the output s).  After the experiment is completed, you can right-click on the exit point and select Save as Dataset.  In future experiments, it will be possible to select this dataset and connect it to the input of the R-script block, and then load it and deserialize it.  The way is crooked, but it works :) You can do a little easier if you have a locally installed R - we train the model, save it in .RData, package it in zip, and load this zip into the dataset section and connect it to the third input of the R-script block - ‚Äú Script Bundle (Zip) ".  In general, you can directly upload a file of type .RData to the dataset section, but I did not find a single block to which it is then connected - it does not even connect to the R-script block, which would be quite logical: ( <br><br>  In view of the above, the code on R looks like this: <br><pre> <code class="hljs pgsql">library("RTextTools") library("stringr") library("tm") library("e1071") #      (   <span class="hljs-number"><span class="hljs-number">1</span></span>) data &lt;- maml.mapInputPort(<span class="hljs-number"><span class="hljs-number">1</span></span>) #             ,         / data &lt;- data[data$grade != <span class="hljs-number"><span class="hljs-number">0</span></span>,] #   -         dtm &lt;- create_matrix(data$<span class="hljs-type"><span class="hljs-type">text</span></span> , <span class="hljs-keyword"><span class="hljs-keyword">language</span></span>="russian" , minWordLength = <span class="hljs-number"><span class="hljs-number">2</span></span> , maxWordLength = <span class="hljs-number"><span class="hljs-number">10</span></span>, , stemWords = <span class="hljs-keyword"><span class="hljs-keyword">FALSE</span></span> , removeNumbers = <span class="hljs-keyword"><span class="hljs-keyword">TRUE</span></span> , removeSparseTerms = <span class="hljs-number"><span class="hljs-number">0</span></span> ) mat = <span class="hljs-keyword"><span class="hljs-keyword">as</span></span>.matrix(dtm) #    DocumentTermMatrix    #   classifier = naiveBayes(mat, <span class="hljs-keyword"><span class="hljs-keyword">as</span></span>.factor(data$grade)) #   serClsf &lt;- serialize(classifier, <span class="hljs-keyword"><span class="hljs-keyword">connection</span></span> = <span class="hljs-keyword"><span class="hljs-keyword">NULL</span></span>) #  DataFrame       output &lt;- data.frame(clsfr = <span class="hljs-keyword"><span class="hljs-keyword">as</span></span>.integer(serClsf)) maml.mapOutputPort("output");</code> </pre><br><br>  Now, finally, you can run the experiment!  It took me about a minute to complete it.  After completion, if everything passed without errors, you can right-click on the output port and save the classifier as a new datasset: <br><br><img src="http://habrastorage.org/files/6cc/707/507/6cc7075075314b498d945c6cd78741ed.png" alt="image"><br><br>  This completes the training of the model and you can proceed to the next part - using the resulting model, creating and publishing a web service. <br><br><h4>  Using the model </h4><br>  Create a new experiment and name it, for example, habr_article_sentiment_use.  Drag the Execute R Script block onto the field and connect the previously saved classifier to its second port: <br><br><img src="http://habrastorage.org/files/785/806/11c/78580611cb454e3393f095c25945f85b.png" alt="image"><br><br>  And we will connect to the first port just a text file with a single column containing 1 line - a test proposal for checking the model.  This is necessary for two reasons - firstly, we will see that the classifier really works, but, most importantly, it will give Azure Machine Learning information about the structure of the input data of the web service, which we will publish - in this case, it accepts only 1 string as input parameter.  This text file might look like this, for example: <br><br><pre> <code class="hljs objectivec"><span class="hljs-string"><span class="hljs-string">"text"</span></span> <span class="hljs-string"><span class="hljs-string">"     .    ,   ,      ,   .      ."</span></span></code> </pre> <br><br>  The result is this: <br><br><img src="http://habrastorage.org/files/318/88d/885/31888d885c7844c399843d69019e6a5d.png" alt="image"><br><br>  Make sure by clicking Visualize on the output of this dataset that it has only one column named ‚Äútext‚Äù. <br><br>  Now let's write an R-script to use the classifier: <br><pre> <code class="hljs pgsql">library("RTextTools") library("stringr") library("tm") library("e1071") #       ,    -   data &lt;- maml.mapInputPort(<span class="hljs-number"><span class="hljs-number">1</span></span>) serializedObj &lt;- maml.mapInputPort(<span class="hljs-number"><span class="hljs-number">2</span></span>) #    classifier &lt;- unserialize(<span class="hljs-keyword"><span class="hljs-keyword">as</span></span>.raw(serializedObj$clsfr)) # C  -    doc &lt;- data$<span class="hljs-type"><span class="hljs-type">text</span></span> dtm &lt;- create_matrix(doc , <span class="hljs-keyword"><span class="hljs-keyword">language</span></span>="russian" , minWordLength = <span class="hljs-number"><span class="hljs-number">4</span></span> , maxWordLength = <span class="hljs-number"><span class="hljs-number">10</span></span>, , stemWords = <span class="hljs-keyword"><span class="hljs-keyword">FALSE</span></span> , removeNumbers = <span class="hljs-keyword"><span class="hljs-keyword">TRUE</span></span> , removeSparseTerms = <span class="hljs-number"><span class="hljs-number">0</span></span> ) mat = <span class="hljs-keyword"><span class="hljs-keyword">as</span></span>.matrix(dtm) #   predicted &lt;- predict(classifier, mat) #    DataFrame result &lt;- <span class="hljs-keyword"><span class="hljs-keyword">as</span></span>.data.frame(predicted) #     maml.mapOutputPort("result");</code> </pre><br><br>  Let's run the experiment and visualize the result - I got -1, although the text is generally positive.  This indicates a low sample quality and the need to use more complex approaches.  Our hackathon had an accuracy of about 72%. <br><br>  Next you need to set the input point of the web service - click on the first input of the R-script block and select Set as Publish Input.  Similarly, set the output: click on the output point ‚ÄúResult Dataset‚Äù and select Set as Publish Output.  Now you can finally publish the web service - click on the Publish Web Service on the panel below (if this button is unavailable, just start the experiment, after its execution it is activated).  After confirmation, you will be transferred to the newly published web service page: <br><br><img src="http://habrastorage.org/files/c0a/cc4/5e6/c0acc45e64854c429a18cdef9e48c4d9.png" alt="image"><br><br>  From here you can go to the generated web service help page - to do this, click on the API Help Page in the REQUEST / RESPONSE line.  This page contains comprehensive information on how to use the web service, even code samples in different languages.  Let's try to make the first request - using your favorite REST client, send the following JSON service: <br><br><pre> <code class="javascript hljs">{ <span class="hljs-string"><span class="hljs-string">"Id"</span></span>: <span class="hljs-string"><span class="hljs-string">"score00001"</span></span>, <span class="hljs-string"><span class="hljs-string">"Instance"</span></span>: { <span class="hljs-string"><span class="hljs-string">"FeatureVector"</span></span>: { <span class="hljs-string"><span class="hljs-string">"text"</span></span>: <span class="hljs-string"><span class="hljs-string">"     ,     ...   ,   ,  ...    "</span></span> }, <span class="hljs-string"><span class="hljs-string">"GlobalParameters"</span></span>: {} } }</code> </pre><br><br>  In response, we will come: <br><pre> <code class="hljs json">[<span class="hljs-string"><span class="hljs-string">"-1"</span></span>]</code> </pre><br><br><h4>  Conclusion </h4><br>  That's all!  As you can see, using Azure Machine Learning is very simple, although at the moment there are some problems.  But, like Azure as a whole, Azure ML is developing very fast, and I hope that soon there will be no need for all these workarounds and the bugs will disappear. <br><br>  In conclusion, here are two helpful links: <br><ol><li>  Fast start to Azure Machine Learning: <a href="http://habrahabr.ru/company/microsoft/blog/236823/">http://habrahabr.ru/company/microsoft/blog/236823/</a> </li><li>  The Machine Learning Center on the Azure website: <a href="http://azure.microsoft.com/en-us/documentation/services/machine-learning/">http://azure.microsoft.com/en-us/documentation/services/machine-learning/</a> </li></ol></div><p>Source: <a href="https://habr.com/ru/post/243705/">https://habr.com/ru/post/243705/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../243691/index.html">White Cube on guard of air purity, part 2</a></li>
<li><a href="../243693/index.html">HP Apollo 8000 Water Cool Supercomputer</a></li>
<li><a href="../243697/index.html">4G Security: Capturing a USB Modem and SIM Card via SMS</a></li>
<li><a href="../243699/index.html">How we do command and situational centers for large companies.</a></li>
<li><a href="../243703/index.html">What does the crowd of startups have to do with the Overgrounds Zerg</a></li>
<li><a href="../243707/index.html">What I learned from C # /. Net developers at the Go conference #</a></li>
<li><a href="../243711/index.html">"English Lessons": Habrahabr vs Geektimes</a></li>
<li><a href="../243713/index.html">Flow - static type analysis in JS from Facebook</a></li>
<li><a href="../243715/index.html">Tomorrow at 10:00 (MSK), watch the Russian App Day conference broadcast</a></li>
<li><a href="../243719/index.html">Step-by-step modification of the preset Bacula setting</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>