<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Why and how we hide the license plates of cars in Avito ads</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hey. At the end of last year, we began to automatically hide the numbers of cars in the photos in the announcement cards on Avito. About why we did it...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Why and how we hide the license plates of cars in Avito ads</h1><div class="post__text post__text-html js-mediator-article">  Hey.  At the end of last year, we began to automatically hide the numbers of cars in the photos in the announcement cards on Avito.  About why we did it, and what are the ways to solve such problems, read the article. <br><br><img src="https://habrastorage.org/webt/fr/0p/vx/fr0pvxzrkfbjqpvdeeu3-hfp4z8.png" alt="Hide my plate!"><br><a name="habracut"></a><br><h4>  Task </h4><br>  In 2018, Avito sold 2.5 million cars.  It is almost 7,000 per day.  All ads for sale need an illustration - a photo of the car.  But according to the state number on it you can find a lot of additional information about the car.  And some of our users try to close the state number on their own. <br><table><tbody><tr><td><img src="https://habrastorage.org/webt/ti/u9/yl/tiu9ylusazwgoyouuhvbd3iephi.png" alt="image"></td><td><img src="https://habrastorage.org/webt/tf/8x/6l/tf8x6lq0j4cnyytbzn4pbwalky8.png" alt="image"></td></tr><tr><td><img src="https://habrastorage.org/webt/t-/mz/ig/t-mzigkjjc00g-w_b2vx4sz0vy8.png" alt="image"></td><td><img src="https://habrastorage.org/webt/rq/gu/31/rqgu31h8n1j4n08z2wu6oqfzwlo.png" alt="image"></td></tr><tr><td colspan="2"><img src="https://habrastorage.org/webt/55/9b/rb/559brbhsq8xldsnln_umbwjqldw.png" alt="prototype for illustration at the beginning of the article"></td></tr></tbody></table><br>  The reasons why users want to hide the license plate may be different.  For our part, we want to help them protect their data.  And we try to improve the processes of sale and purchase for users.  For example, we have an anonymous number service for a long time: when you sell a car, a temporary mobile number is created for you.  Well, to protect the data on state numbers, we depersonalize the photos. <br><br><img src="https://habrastorage.org/webt/ol/-o/ii/ol-oiivyox1f2cogwd2pzf1jz9y.png" alt="image">
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h4>  Review of solutions </h4><br>  To automate the process of protecting user photos, you can use convolutional neural networks to detect a polygon with a license plate. <br>  Now for the detection of objects, architectures of two groups are used: two-stage networks, for example, Faster RCNN and Mask RCNN;  single-stage (singleshot) - SSD, YOLO, RetinaNet.  Object detection is the output of the four coordinates of the rectangle in which the object of interest is inscribed. <br><br><img src="https://habrastorage.org/webt/-g/bz/p4/-gbzp4vk0cj2uwknc1qeavh8roy.png" alt="image"><br><br>  The networks mentioned above are able to find in the pictures a lot of objects of different classes, which is already redundant to solve the problem of finding a license plate, because the car in our pictures is usually only one (there are exceptions when people take pictures of their sold car and its random neighbor , but this happens quite rarely, so this could be neglected). <br><br>  Another feature of these networks is that by default they provide a bounding box with sides parallel to the axes of coordinates.  This is because the detection uses a set of pre-defined kinds of rectangular frames called anchor boxes.  More specifically, first, using a convolutional network (for example, resnet34), a matrix of features is obtained from the image.  Then, for each subset of features obtained using a sliding window, a classification occurs: whether or not there is an object for the k anchor box and a regression is performed in the four coordinates of the frame, which correct its position. <br>  Read more about this <a href="https://habr.com/ru/post/421299/">here</a> . <br><br><img src="https://habrastorage.org/webt/ew/er/dq/ewerdqloqogwqhsp8kauzmwzwtq.png" alt="image"><br><br>  After that there are two more heads: <br><br><img src="https://habrastorage.org/webt/be/9j/ib/be9jibquo3xic6fi-3dof-ivyq4.png" alt="not the most original picture of architecture"><br><br>  one to classify an object (dog / cat / plant, etc), <br>  the second (bbox regressor) is used to regress the coordinates of the frame obtained in the previous step in order to increase the ratio of the object area to the area of ‚Äã‚Äãthe frame. <br><br>  In order to predict the rotated frame of the box, you need to change the bbox regressor so that you also get the angle of rotation of the frame.  If you do not do this, then it will turn out somehow. <br><br><img src="https://habrastorage.org/webt/c0/4p/5d/c04p5dcpnl02xrgbvapzycdtboe.png" alt="image"><br><br>  In addition to the two-stage Faster R-CNN, there are one-stage detectors, such as RetinaNet.  It differs from the previous architecture in that it immediately predicts the class and the frame, without the preliminary stage of the proposal of sections of the picture, which may contain objects.  In order to predict rotated masks, you also need to change the box subnet head. <br><br><img src="https://habrastorage.org/webt/uu/_w/qx/uu_wqxel27ctxz39s_trbw4be88.png" alt="image"><br><br>  One example of existing architectures for predicting rotated bounding boxes is DRBOX.  This network does not use the preliminary stage of the region proposal, as in Faster RCNN, therefore it is a modification of one-step methods.  For training this network, K rotated at certain corners of the bounding box (rbox) is used.  The network predicts the probabilities for each of K rbox to contain the target object, coordinates, bbox size and rotation angle. <br><br><img src="https://habrastorage.org/webt/oq/a4/yo/oqa4yonbchbbmkcu9mjsj7nmmfm.png" alt="image"><br><br>  To modify the architecture and re-train one of the considered networks on data with rotated bounding boxes is a realizable task.  But our goal can be achieved more easily, because the area of ‚Äã‚Äãapplication of the network is much narrower here - only to hide license plates. <br>  Therefore, we decided to start with a simple network to predict the four points of the number; later it will be possible to complicate the architecture. <br><br><h4>  Data </h4><br>  The assembly of the dataset is divided into two steps: to collect pictures of cars and to mark on them an area with a license plate.  The first task has already been solved in our infrastructure: we keep all ads that have ever been placed on Avito.  To solve the second problem, we use Toloka.  On <a href="https://toloka.yandex.ru/requester/">toloka.yandex.ru/requester we</a> create the task: <br><blockquote>  In the task given photo of the car.  It is necessary to highlight the license plate of the car, using a quadrilateral.  In this case, the state number should be allocated as accurately as possible. </blockquote><img src="https://habrastorage.org/webt/mk/vl/j4/mkvlj4d7k8bsg_xkke1gkcsrxuy.png" alt="image"><br><br>  With the help of Toloki, you can create data marking tasks.  For example, assess the quality of search results, mark up different classes of objects (texts and pictures), mark up videos, etc.  They will be performed by Toloki users, for a fee that you assign.  For example, in our case, the pushers should highlight the landfill with the car's license number in the photo.  In general, it is very convenient for marking a large dataset, but getting high quality is quite difficult.  On a fair lot of bots, whose task is to get money from you, instructing answers randomly or using some strategy.  To counteract these bots there is a system of rules and checks.  The main test is to add test questions: you manually mark up part of the tasks using the Toloki interface, and then add them to the main task.  If the tagging is often mistaken on the control questions, you block it and the markup does not take into account. <br><br>  For the classification task it is very easy to determine whether the marking is wrong or not, and for the task of selecting an area it is not so easy.  The classic way is to count IoU. <br><br><img src="https://habrastorage.org/webt/fw/r2/ye/fwr2yeqbrlk1-skjy2udjx04y2e.png" alt="image"><br><br>  If this ratio is less than a certain threshold for several tasks, then that user is blocked.  However, for two arbitrary quadrilaterals, it is not so easy to calculate IoU, especially since Toloka has to implement this in JavaScript.  We made a small hack, and we believe that the user was not mistaken if for each point of the source polygon in a small neighborhood there is a point marked by a razmechchik.  There is also a rule of quick answers, so that responding users, captcha, disagreement with the majority opinion, etc., are blocked too quickly.  Having set up these rules, you can expect pretty good markup, but if you really need high quality and complex markup, you need to hire freelancers-markers specifically.  As a result, our dataset was 4k of marked-up pictures, and it all cost $ 28 on Toloka. <br><br><h4>  Model </h4><br>  Now we will make a network for predicting four points of the area.  We will get the signs using resnet18 (11.7M parameters versus 21.8M parameters for resnet34), then we make a head for the regression of four points (eight coordinates) and a head for classifying whether there is a license plate in the picture or not.  The second head is needed, because in ads for the sale of cars, not all photos with cars.  The photo may be a detail of the car. <br><br><img src="https://habrastorage.org/webt/wz/qc/5s/wzqc5spmzueaqptlw6hiknobayo.png" alt="image"><br><br>  Similar to us, of course, it is not necessary to detect. <br><br>  We are training two goals at the same time by adding a photo without a license plate with a bounding box target (0.0,0,0,0,0,0,0,0) and a value for the ‚Äúlicense plate / without picture‚Äù classifier - (0, one). <br><br>  Then you can create a single loss function for both heads as the sum of the next losses.  For regression to the coordinates of the polygon license plate using a smooth L1 loss. <br><br><img src="https://habrastorage.org/webt/6s/v7/yu/6sv7yus_w9o4d1xmqfhbnsenotc.png" alt="image"><br><br>  It can be interpreted as a combination of L1 and L2, which behaves like L1 when the absolute value of the argument is large and like L2 when the value of the argument is close to zero.  For classification use softmax and crossentropy loss.  The tracer extractor is resnet18, we use weights that were pre-trained on ImageNet, then we continue to train the extractor and heads on our dataset.  In this task, we used the mxnet framework, since it is the main one for computer vision in Avito.  In general, the microservice architecture allows you not to become attached to a specific framework, but when you have a large code base, it is better to use it and not to write the same code again. <br><br>  Having received acceptable quality on our dataset, we turned to the designers to make us a license plate with the Avito logo.  At first, of course, we tried to do it ourselves, but it didn‚Äôt look very beautiful.  Next you need to change the brightness of the Avito license plate to the brightness of the original area with the license plate and you can impose a logo on the image. <br><br><img src="https://habrastorage.org/webt/3j/gr/bz/3jgrbzhv3y9sldjmbm5hlfmhlo8.png" alt="image"><br><br><h4>  Run in the prod </h4><br>  The problem of reproducibility of results, support and development of projects, solved with some error in the world of backend- and frontend-development, still stands open where it is necessary to use machine learning models.  You probably had to understand the Legacy code models.  Well, if the readme has links to articles or open source repositories on which the solution was based.  The script to start retraining may fall with errors, for example, the version of cudnn has changed, and that version of tensorflow no longer works with this version of cudnn, and cudnn does not work with this version of nvidia drivers.  Maybe one data iterator was used for training, and another was used for testing and production.  So you can continue for quite some time.  In general, reproducibility problems exist. <br><br>  We try to remove them using the nvidia-docker environment for training models, it has all the necessary dependencies for the suda, and we also install dependencies for the python there.  A version of the library with an iterator for data, augmentations, model inflection is common for the training / experimentation stage and for production.  Thus, in order to train a model on new data, you need to download the repository to the server, run a shell script that will collect the docker-environment, inside which jupyter notebook will rise.  Inside you will have all the notebooks for training and testing, which will not fall with an error due to the environment.  It‚Äôs better, of course, to have one train.py file, but practice shows that you always need to look at what modelka gives and change something in the learning process, so in the end you still run jupyter. <br><br>  Model weights are stored in git lfs - this is a special technology for storing large files in the gita. Before that, we used the artifactory, but through git lfs it is more convenient because by downloading the repository with the service, you immediately get the current version of the scales, as in production.  For the inference of models, autotests are written, so it‚Äôs not possible to roll out the service with weights that do not pass them.  The service itself is launched at the docker inside the microservice infrastructure on the kubernetes cluster.  For performance monitoring, we use grafana.  After rolling, we gradually increase the load on the service instances with the new model.  When rolling out a new feature, we create a / b tests and make a verdict on the further fate of the feature, based on statistical tests. <br><br>  As a result: we launched a smearing of numbers on ads in the category of cars for private traders, 95 percentile of the processing time of one image to hide the number is 250 ms. </div><p>Source: <a href="https://habr.com/ru/post/447286/">https://habr.com/ru/post/447286/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../447276/index.html">What is ITIL library and why does your company need it</a></li>
<li><a href="../447278/index.html">Estonia is trying to use AI in justice</a></li>
<li><a href="../447280/index.html">Pumping game accounts in China: a serious business and a headache for developers</a></li>
<li><a href="../447282/index.html">Errors of system and application programmers caught in the frontend (article deleted)</a></li>
<li><a href="../447284/index.html">Updating Web and Azure Tools in Visual Studio 2019</a></li>
<li><a href="../447288/index.html">Top 5 Stablecoins. All you need to know</a></li>
<li><a href="../447290/index.html">Doctor rides, rides</a></li>
<li><a href="../447292/index.html">14 new products in Visual Studio 2019</a></li>
<li><a href="../447298/index.html">Knowledge management through competency models</a></li>
<li><a href="../447302/index.html">Weekend OS</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>