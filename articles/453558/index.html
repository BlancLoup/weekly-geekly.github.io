<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Introduction to machine learning</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Full course in Russian can be found at this link . 
 The original English course is available here . 



 The release of new lectures is scheduled eve...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Introduction to machine learning</h1><div class="post__text post__text-html js-mediator-article">  Full course in Russian can be found at <a href="https://www.youtube.com/playlist%3Flist%3DPLfdVzZl6HHg9y9l6U5xUjqKS13rWoQPF4">this link</a> . <br>  The original English course is available <a href="https://www.udacity.com/course/intro-to-tensorflow-for-deep-learning--ud187">here</a> . <br><br><img src="https://habrastorage.org/webt/f-/6y/ml/f-6ymlhmfceofcmhbv2qsfv2hfu.jpeg"><br><a name="habracut"></a><br>  <i>The release of new lectures is scheduled every 2-3 days.</i> <br><br><h2>  Interview with Sebastian Trun, CEO Udacity </h2><br>  ‚ÄúHello again, I‚Äôm with you, Paige and today‚Äôs guest is Sebastian.‚Äù <br>  - Hi, I'm Sebastian! <br>  - ... a man who has an incredible career, who managed to do a lot of amazing things!  You are the co-founder of Udacity, you founded Google X, you are a professor at Stanford.  You have been doing incredible research and deep learning throughout your career.  What brought you the most satisfaction and in which of the areas did you get the most reward for the work you did? <br>  - To be honest, I really love being in Silicon Valley!  I like being close to people who are significantly smarter than me, and I have always viewed technology as a tool that changes the rules of the game in various ways - from education to logistics, healthcare, etc.  All this is changing so quickly, and there is an incredible desire to be a participant in these changes, to watch them.  You look at your surroundings and you realize that most of what you see around does not work as it should - you can always invent something new! <br>  - Well, this is a very optimistic view of technology!  What was your biggest ‚ÄúEureka‚Äù throughout your career? <br>  - Lord, there were so many!  I remember one of the days when Larry Page called me and offered to create autopilot cars that could drive through all the streets of California.  At that time I was considered an expert, I was considered to be one of those, and I was the same person who said ‚Äúno, this cannot be done‚Äù.  After that, Larry convinced me that, in principle, it is possible to do it, one has only to start and make an attempt.  And we did it!  It was a moment when I realized that even the experts are wrong and saying ‚Äúno‚Äù we are 100% pessimistic.  I think we should be more open to new things. <br>  - Or, for example, if Larry Page calls you and says, - ‚ÄúHey, do a cool thing like Google X‚Äù and it turns out something pretty cool! <br>  - Yes, that's for sure, no need to complain!  I mean, all this is a process that goes through a lot of discussions on the way to implementation.  I was really lucky to work and I am proud of it, in Google X and on other projects. <br>  - Amazing!  So, this course is all about working with TensorFlow.  Do you have experience using TensorFlow or maybe you know (heard) it? <br>  - Yes!  I literally love TensorFlow, of course!  In my own laboratory, we use it often and a lot; one of the most significant works based on TensorFlow was released about two years ago.  We have learned that the iPhone and Android can be more effective in determining skin cancer than the best dermatologists in the world.  We published our research in Nature and it produced a sort of stir in medicine. <br>  - Sounds amazing!  So you know and love TensorFlow, which in itself is great!  Have you already worked with TensorFlow 2.0? <br>  - No, unfortunately I haven't had time yet. <br>  - He will be just amazing!  All students of this course will work with this version. <br>  - I envy them!  Be sure to try! <br>  - Perfectly!  There are a lot of students in our course who have never in their life been engaged in machine learning, from the word ‚Äúabsolutely‚Äù.  For them, the field may be new, perhaps for someone the programming itself will be a new thing.  What is your advice for them? <br>  - I would like them to remain open - to new ideas, methods, solutions, positions.  Machine learning is actually simpler than programming.  In the process of programming, you need to take into account each case in the source data, adapt the program logic and rules for it.  At this very time, using TensorFlow and machine learning, you essentially train the computer using examples, letting the computer find the rules yourself. <br>  - This is incredibly interesting!  I can't wait to tell students of this course a little more about machine learning!  Sebastian, thank you for taking the time and came to us today! <br>  - Thank you!  Stay in touch! 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h2>  What is machine learning? </h2><br>  So let's start with the following task - input and output values ‚Äã‚Äãare given. <br><br><img src="https://habrastorage.org/webt/a2/ec/84/a2ec84ej7mnna9degt489lkhgxs.jpeg"><br><br>  When you have a value of 0 as an input value, then you have 32 as an output value. When you have 8 as an input value, 46.4 as an output value.  When you have 15 as an input value, then 59 as an output value, and so on. <br><br>  Take a closer look at these values ‚Äã‚Äãand let me ask you a question.  Can you determine what the output value will be if we get 38 at the input? <br><br><img src="https://habrastorage.org/webt/p6/dj/5o/p6dj5o7yrrekj2vxzexnq6hqpi0.jpeg"><br><br>  If you answered 100.4, then you were right! <br><br><img src="https://habrastorage.org/webt/bv/z9/-k/bvz9-kkmmvjurwja9ltuupq-lje.jpeg"><br><br>  So how could we solve this problem?  If you take a closer look at the values, you can see that they are related by the expression: <br><br><img src="https://habrastorage.org/webt/bm/ql/pq/bmqlpqb79ptaf8q_gsikh9wg3pg.jpeg"><br><br>  Where C - degrees Celsius (input values), F - Fahrenheit (output values). <br><br>  What your brain has now done ‚Äî juxtaposed input values ‚Äã‚Äãand output values ‚Äã‚Äãand found a common model (link, dependency) between them ‚Äî this is exactly what machine learning does. <br><br>  For input and output values, machine learning algorithms will find a suitable algorithm for converting input values ‚Äã‚Äãinto output values.  This can be represented as follows: <br><br><img src="https://habrastorage.org/webt/_m/c8/zq/_mc8zq1ochmxaq78aqd39ktngqm.jpeg"><br><br>  Let's take an example.  Imagine that we want to develop a program that will convert degrees Celsius to degrees Fahrenheit using the formula <code>F = C * 1.8 + 32</code> . <br><br><img src="https://habrastorage.org/webt/me/0w/t6/me0wt6lyjkzoqbgdwb3-tvtv2s0.jpeg"><br><br>  The solution, when approaching from the point of view of traditional software development, can be implemented in any programming language using the function: <br><br><img src="https://habrastorage.org/webt/e3/oi/zk/e3oizkl4oob_fnd2yq-i1fxifwk.jpeg"><br><br>  So what do we have?  The function takes the input value C, then calculates the output value F using an explicitly specified algorithm, and then returns the calculated value. <br><br><img src="https://habrastorage.org/webt/d7/vn/yh/d7vnyhgewv7pknnv0bmepxybtg8.jpeg"><br><br>  On the other hand, in the machine learning approach, we only have input and output values, but not the algorithm itself: <br><br><img src="https://habrastorage.org/webt/m1/3s/wy/m13swy6p2a4z_wuboqdawda7m-8.jpeg"><br><br>  The machine learning approach is based on using neural networks to find the relationship between input and output values. <br><br><img src="https://habrastorage.org/webt/sd/_u/cb/sd_ucbyegwsntvcufqhgzqgqefs.jpeg"><br><br>  You can think of neural networks as a stack of layers, each of which consists of previously known mathematics (formulas) and internal variables.  The input value enters the neural network and passes through a stack of neuron layers.  During passage through the layers, the input value is converted according to the mathematics (given formulas) and the values ‚Äã‚Äãof the internal variable layers, producing the output value. <br><br>  In order for the neural network to be able to learn and determine the correct relationship between the input and output values, we need to train it ‚Äî train it. <br><br>  We train the neural network through repeated attempts to match the input values ‚Äã‚Äãof the output. <br><br><img src="https://habrastorage.org/webt/a7/8r/k5/a78rk54x-g6lpgjm67cvmuas43c.jpeg"><br><br>  In the process of training, there is a ‚Äúfit‚Äù (selection) of the values ‚Äã‚Äãof internal variables in the layers of the neural network until the network learns to generate the corresponding output values ‚Äã‚Äãto the corresponding input values. <br><br>  As we will see later, in order to train a neural network and allow it to choose the most appropriate values ‚Äã‚Äãof internal variables, thousands or tens of thousands of iterations (trainings) are performed. <br><br><img src="https://habrastorage.org/webt/kv/h5/xa/kvh5xahns3dammp0e1-guhsjwmg.jpeg"><br><br>  As a simplified version of understanding machine learning, you can imagine machine learning algorithms as functions that match the values ‚Äã‚Äãof internal variables so that the correct input values ‚Äã‚Äãcorrespond to the input values. <br><br>  There are many types of neural network architectures.  However, regardless of which architecture you choose, the mathematics inside (which calculations are performed and in which order) will remain unchanged during the workout.  Instead of changing mathematics, internal variables (weights and displacements) change during training. <br><br>  For example, in the task of converting from degrees Celsius to Fahrenheit, the model starts by multiplying the input value by a certain number (weight) and adding another value (offset).  The training of the model consists in finding the appropriate values ‚Äã‚Äãfor these variables, without changing the performed multiplication and addition operations. <br><br>  But one cool thing that is worth thinking about!  If you have solved the task of converting degrees Celsius to Fahrenheit, which is indicated in the video and in the text below, you probably decided it because you had some previous experience or knowledge of how to perform this kind of conversion from degrees Celsius to Fahrenheit.  For example, you might just know that 0 degrees Celsius corresponds to 32 degrees Fahrenheit.  On the other hand, systems based on machine learning do not have previous auxiliary knowledge to solve the problem.  They learn to solve problems of this kind not based on previous knowledge and in their absence. <br><br>  Enough talk - go to the practical part of the lecture! <br><br><h2>  CoLab: convert degrees Celsius to degrees Fahrenheit </h2><br>  <a href="https://colab.research.google.com/drive/1Bw-WlZeTV-D9JPraPk1-QjERqC_c-C9l">The Russian version of the CoLab source code</a> and the <a href="https://colab.research.google.com/github/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l02c01_celsius_to_fahrenheit.ipynb">English version of the CoLab source code</a> . <br><br><h2>  Basics: learning the first model </h2><br>  Welcome to CoLab, where we will train our first machine learning model! <br><br>  We will try to preserve the simplicity of the presented material and introduce only the basic concepts necessary for work.  Subsequent CoLabs will contain more advanced techniques. <br><br>  The task that we will be solving is the conversion of degrees Celsius to degrees Fahrenheit.  The conversion formula is as follows: <br><br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-1-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mi>f</mi><mo>=</mo><mi>c</mi><mtext>&amp;#xA0;</mtext><mi>t</mi><mi>i</mi><mi>m</mi><mi>e</mi><mi>s</mi><mn>1.8</mn><mo>+</mo><mn>32</mn></math>" role="presentation" style="font-size: 100%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="19.958ex" height="2.419ex" viewBox="0 -780.1 8593 1041.5" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/453558/&amp;xid=17259,15700023,15700186,15700190,15700256,15700259&amp;usg=ALkJrhjtm8QL7xoYWbFDnWNCQIAj8PrxDQ#MJMATHI-66" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/453558/&amp;xid=17259,15700023,15700186,15700190,15700256,15700259&amp;usg=ALkJrhjtm8QL7xoYWbFDnWNCQIAj8PrxDQ#MJMAIN-3D" x="828" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/453558/&amp;xid=17259,15700023,15700186,15700190,15700256,15700259&amp;usg=ALkJrhjtm8QL7xoYWbFDnWNCQIAj8PrxDQ#MJMATHI-63" x="1884" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/453558/&amp;xid=17259,15700023,15700186,15700190,15700256,15700259&amp;usg=ALkJrhjtm8QL7xoYWbFDnWNCQIAj8PrxDQ#MJMATHI-74" x="2568" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/453558/&amp;xid=17259,15700023,15700186,15700190,15700256,15700259&amp;usg=ALkJrhjtm8QL7xoYWbFDnWNCQIAj8PrxDQ#MJMATHI-69" x="2929" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/453558/&amp;xid=17259,15700023,15700186,15700190,15700256,15700259&amp;usg=ALkJrhjtm8QL7xoYWbFDnWNCQIAj8PrxDQ#MJMATHI-6D" x="3275" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/453558/&amp;xid=17259,15700023,15700186,15700190,15700256,15700259&amp;usg=ALkJrhjtm8QL7xoYWbFDnWNCQIAj8PrxDQ#MJMATHI-65" x="4153" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/453558/&amp;xid=17259,15700023,15700186,15700190,15700256,15700259&amp;usg=ALkJrhjtm8QL7xoYWbFDnWNCQIAj8PrxDQ#MJMATHI-73" x="4620" y="0"></use><g transform="translate(5089,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/453558/&amp;xid=17259,15700023,15700186,15700190,15700256,15700259&amp;usg=ALkJrhjtm8QL7xoYWbFDnWNCQIAj8PrxDQ#MJMAIN-31"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/453558/&amp;xid=17259,15700023,15700186,15700190,15700256,15700259&amp;usg=ALkJrhjtm8QL7xoYWbFDnWNCQIAj8PrxDQ#MJMAIN-2E" x="500" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/453558/&amp;xid=17259,15700023,15700186,15700190,15700256,15700259&amp;usg=ALkJrhjtm8QL7xoYWbFDnWNCQIAj8PrxDQ#MJMAIN-38" x="779" y="0"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/453558/&amp;xid=17259,15700023,15700186,15700190,15700256,15700259&amp;usg=ALkJrhjtm8QL7xoYWbFDnWNCQIAj8PrxDQ#MJMAIN-2B" x="6591" y="0"></use><g transform="translate(7592,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/453558/&amp;xid=17259,15700023,15700186,15700190,15700256,15700259&amp;usg=ALkJrhjtm8QL7xoYWbFDnWNCQIAj8PrxDQ#MJMAIN-33"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/post/453558/&amp;xid=17259,15700023,15700186,15700190,15700256,15700259&amp;usg=ALkJrhjtm8QL7xoYWbFDnWNCQIAj8PrxDQ#MJMAIN-32" x="500" y="0"></use></g></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mi>f</mi><mo>=</mo><mi>c</mi><mtext>&nbsp;</mtext><mi>t</mi><mi>i</mi><mi>m</mi><mi>e</mi><mi>s</mi><mn>1.8</mn><mo>+</mo><mn>32</mn></math></span></span></div><script type="math/tex;mode=display" id="MathJax-Element-1"> f = c \ times 1.8 + 32 </script></p><br><br>  Of course, it would be easier to just write a conversion function in Python or any other programming language that would perform direct calculations, but in this case it would not be machine learning :) <br><br>  Instead, we will feed the input values ‚Äã‚Äãof degrees Celsius (0, 8, 15, 22, 38) and their corresponding degrees Fahrenheit (32, 46, 59, 72, 100) to the TensorFlow input.  Then we will train the model so that it approximately corresponds to the above formula. <br><br><h3>  Import Dependencies </h3><br>  First of all we import <code>TensorFlow</code> .  Here and in the following, we abbreviate it as <code>tf</code> .  We also configure the logging level - only errors. <br><br>  Next, import <code>NumPy</code> as <code>np</code> .  <code>Numpy</code> helps us present our data in the form of high-performance lists. <br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> __future__ <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> absolute_import, division, print_function, unicode_literals <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf tf.logging.set_verbosity(tf.logging.ERROR) <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np</code> </pre><br><h3>  Preparation of data for training </h3><br>  As we have seen earlier, the method of machine learning with a teacher is based on the search for an algorithm for transforming input data into a weekend.  Since the task of this CoLab is to create a model that can produce the result of converting degrees Celsius to degrees Fahrenheit, we will create two lists, <code>celsius_q</code> and <code>fahrenheit_a</code> , which we use when training our model. <br><br><pre> <code class="python hljs">celsius_q = np.array([<span class="hljs-number"><span class="hljs-number">-40</span></span>, <span class="hljs-number"><span class="hljs-number">-10</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">8</span></span>, <span class="hljs-number"><span class="hljs-number">15</span></span>, <span class="hljs-number"><span class="hljs-number">22</span></span>, <span class="hljs-number"><span class="hljs-number">38</span></span>], dtype=float) fahrenheit_a = np.array([<span class="hljs-number"><span class="hljs-number">-40</span></span>, <span class="hljs-number"><span class="hljs-number">14</span></span>, <span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-number"><span class="hljs-number">46</span></span>, <span class="hljs-number"><span class="hljs-number">59</span></span>, <span class="hljs-number"><span class="hljs-number">72</span></span>, <span class="hljs-number"><span class="hljs-number">100</span></span>], dtype=float) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i,c <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> enumerate(celsius_q): print(<span class="hljs-string"><span class="hljs-string">"{}   = {}  "</span></span>.format(c, fahrenheit_a[i]))</code> </pre><br> <code>-40.0   = -40.0   <br> -10.0   = 14.0   <br> 0.0   = 32.0   <br> 8.0   = 46.0   <br> 15.0   = 59.0   <br> 22.0   = 72.0   <br> 38.0   = 100.0   <br></code> <br>  Some machine learning terminology: <br><br><ul><li>  <b>Property</b> - input (s) value of our model.  In this case, the unit value is degrees Celsius. </li><li>  <b>Labels</b> are output values ‚Äã‚Äãthat our model predicts.  In this case, the unit value is degrees Fahrenheit. </li><li>  <b>An example</b> is a pair of input-output values ‚Äã‚Äãused for training.  In this case, it is a pair of values ‚Äã‚Äãfrom <code>celsius_q</code> and <code>fahrenheit_a</code> under a certain index, for example, (22.72). </li></ul><br><h2>  Create a model </h2><br>  Next, we create a model.  We will use the most simplified model - the model of a full mesh network ( <code>Dense</code> network).  Since the task is rather trivial, the network will consist of a single layer with a single neuron. <br><br><h4>  We build a network </h4><br>  We will name the layer <code>l0</code> ( <b>l</b> ayer and zero) and create it by initializing <code>tf.keras.layers.Dense</code> with the following parameters: <br><br><ul><li>  <code>input_shape=[1]</code> - this parameter determines the dimension of the input parameter - a single value.  1 √ó 1 matrix with a single value.  Since this is the first (and only) layer, then the dimension of the input data corresponds to the dimension of the entire model.  The only value is a floating point value representing degrees Celsius. </li><li>  <code>units=1</code> - this parameter determines the number of neurons in a layer.  The number of neurons determines how many of the internal variables of the layer will be used for training in finding solutions to the problem.  Since this is the last layer, its dimension is equal to the dimension of the result ‚Äî the output value of the model ‚Äî the only floating-point number representing Fahrenheit degrees.  (In a multilayer network, the size and shape of the <code>input_shape</code> layer must match the size and shape of the next layer). </li></ul><br><pre> <code class="python hljs">l0 = tf.keras.layers.Dense(units=<span class="hljs-number"><span class="hljs-number">1</span></span>, input_shape=[<span class="hljs-number"><span class="hljs-number">1</span></span>])</code> </pre><br><h4>  Transform layers into a model </h4><br>  Once the layers are defined they need to be converted to a model.  <code>Sequential</code> model takes as an argument the list of layers in the order in which they should be applied - from the input value to the output value. <br><br>  Our model has only one layer - <code>l0</code> . <br><br><pre> <code class="python hljs">model = tf.keras.Sequential([l0])</code> </pre><br>  <b>Note</b> <br>  Quite often, you will encounter the definition of layers directly in the function of the model, rather than with their preliminary description and subsequent use: <br><pre> <code class="python hljs">model = tf.keras.Sequential([ tf.keras.layers.Dense(units=<span class="hljs-number"><span class="hljs-number">1</span></span>, input_shape=[<span class="hljs-number"><span class="hljs-number">1</span></span>]) ])</code> </pre><br><h3>  Compile model with loss and optimization function </h3><br>  Before training, the model must be compiled (assembled).  When compiling for training are needed: <br><br><ul><li>  <b>the loss function</b> is a way of measuring how far the predicted value is from the desired output value (the measurable difference is called ‚Äúloss‚Äù). </li><li>  <b>optimization function</b> - a way to adjust the internal variables to reduce losses. </li></ul><br><br><pre> <code class="python hljs">model.compile(loss=<span class="hljs-string"><span class="hljs-string">'mean_squared_error'</span></span>, optimizer=tf.keras.optimizers.Adam(<span class="hljs-number"><span class="hljs-number">0.1</span></span>))</code> </pre><br>  The loss function and the optimization function are used during the training model ( <code>model.fit(...)</code> mentioned below) to perform the primary calculations at each point and then optimize the values. <br><br>  The effect of calculating current losses and the subsequent improvement of these values ‚Äã‚Äãin the model is exactly what training is (one iteration). <br><br>  During training, the optimization function is used to calculate the corrections of the values ‚Äã‚Äãof internal variables.  The goal is to adjust the values ‚Äã‚Äãof internal variables in such a way in the model (and this is, in fact, a mathematical function) so that they reflect the approximate expression that exists as a Celsius to Fahrenheit degree conversion. <br><br>  TensorFlow uses numerical analysis to perform this kind of optimization operations and all this complexity is hidden from our eyes, so we will not go into details in this course. <br><br>  What is useful to know about these parameters: <br><br>  The loss function (standard error) and the optimization function (Adam) used in this example are standard for such simple models, but many others are available.  At this stage, we do not care how these functions work. <br><br>  What you should pay attention to is the optimization function and the parameter ‚Äî the <code>learning rate</code> ( <code>learning rate</code> ), which in our example is <code>0.1</code> .  This is the used step size when adjusting the internal values ‚Äã‚Äãof variables.  If the value is too small, then too many training iterations will be needed to train the model.  Too large - accuracy drops.  Finding a good learning speed factor requires some trial and error; it is usually in the range from <code>0.01</code> (default) to <code>0.1</code> . <br><br><h4>  We train model </h4><br>  The model is trained by the <code>fit</code> method. <br><br>  During training, the model receives the input values ‚Äã‚Äãof degrees Celsius, performs transformations using the values ‚Äã‚Äãof internal variables (called "weights") and returns values ‚Äã‚Äãthat must correspond to degrees Fahrenheit.  Since the initial values ‚Äã‚Äãof the weights are arbitrary, the resulting values ‚Äã‚Äãwill be far from the correct values.  The difference between the required result and the actual is calculated using the loss function, and the optimization function determines how the weights should be corrected. <br><br>  This cycle of calculations, comparisons and adjustments is controlled inside the <code>fit</code> method.  The first argument is the input values, the second argument is the desired output values.  The <code>epochs</code> argument determines how many times this training cycle should be executed.  The <code>verbose</code> argument controls the level of logging. <br><br><pre> <code class="python hljs">history = model.fit(celsius_q, fahrenheit_a, epochs=<span class="hljs-number"><span class="hljs-number">500</span></span>, verbose=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) print(<span class="hljs-string"><span class="hljs-string">"  "</span></span>)</code> </pre><br>  In the following videos, we will dive into the details of how this all works and exactly how fully connected layers ( <code>Dense</code> layers) work ‚Äúunder the hood‚Äù. <br><br><h4>  Display training statistics </h4><br>  The <code>fit</code> method returns an object that contains information about the change in losses with each subsequent iteration.  We can use this object to build an appropriate loss schedule.  High loss means that the value of the Fahrenheit degrees that the model predicted is far from the true values ‚Äã‚Äãin the <code>fahrenheit_a</code> array. <br><br>  For visualization we will use <code>Matplotlib</code> .  As you can see, our model improves very quickly at the very beginning, and then comes to a stable and slow improvement until the results become ‚Äúabout‚Äù - ideal at the very end of the training. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.pyplot <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> plt plt.xlabel(<span class="hljs-string"><span class="hljs-string">'Epoch'</span></span>) plt.ylabel(<span class="hljs-string"><span class="hljs-string">'Loss'</span></span>) plt.plot(history.history[<span class="hljs-string"><span class="hljs-string">'loss'</span></span>])</code> </pre><br><img src="https://habrastorage.org/webt/5t/qg/ds/5tqgdsya8uiphpuehc5c2xxdrak.png"><br><br><h4>  Use the model for predictions. </h4><br>  We now have a model that was trained on the input values <code>celsius_q</code> and output values <code>fahrenheit_a</code> to determine the relationship between them.  We can use the prediction method to calculate those Fahrenheit degrees for which we previously did not know the corresponding degrees Celsius. <br><br>  For example, how much is 100.0 degrees Celsius Fahrenheit?  Try to guess before running the code below. <br><br><pre> <code class="python hljs">print(model.predict([<span class="hljs-number"><span class="hljs-number">100.0</span></span>]))</code> </pre><br>  Conclusion: <br><br> <code>[[211.29639]] <br></code> <br><br>  The correct answer is 100 √ó 1.8 + 32 = 212, so our model did quite well! <br><br>  <b>Review</b> <br><br><ul><li>  We created a model using the <code>Dense</code> layer </li><li>  We trained it in 3500 examples (7 pairs of values, 500 training iterations) </li></ul><br>  Our model adjusted the values ‚Äã‚Äãof internal variables (weights) in the <code>Dense</code> layer in such a way as to return the correct values ‚Äã‚Äãof Fahrenheit degrees to an arbitrary input value of degrees Celsius. <br><br><h3>  We look at the weight </h3><br>  Let's display the values ‚Äã‚Äãof the internal variables of the <code>Dense</code> layer. <br><br><pre> <code class="python hljs">print(<span class="hljs-string"><span class="hljs-string">"   : {}"</span></span>.format(l0.get_weights()))</code> </pre><br>  Conclusion: <br><br><pre> <code class="plaintext hljs">   : [array([[1.8261501]], dtype=float32), array([28.681389], dtype=float32)]</code> </pre><br>  The value of the first variable is close to ~ 1.8, and the second to ~ 32.  These values ‚Äã‚Äã(1.8 and 32) are immediate values ‚Äã‚Äãin the formula for converting degrees Celsius to Fahrenheit. <br><br>  This is really very close to the actual values ‚Äã‚Äãin the formula!  We will look at this point in more detail in the following videos, where we will show how the <code>Dense</code> layer works, but for now it‚Äôs worth knowing only that one neuron with a single input and output contains simple mathematics - <code>y = mx + b</code> (as an equation direct), which is nothing but our formula for converting degrees Celsius to Fahrenheit, <code>f = 1.8c + 32</code> . <br><br>  Since the representations are the same, the values ‚Äã‚Äãof the internal variables of the model should have converged to those presented in the actual formula, which happened as a result. <br><br>  With additional neurons, additional input values ‚Äã‚Äãand output values, the formula becomes a bit more complicated, but the essence remains the same. <br><br><h4>  Some experiments </h4><br>  For fun!  What happens if we create more <code>Dense</code> layers with a large number of neurons, which, in turn, will contain more internal variables? <br><br><pre> <code class="python hljs">l0 = tf.keras.layers.Dense(units=<span class="hljs-number"><span class="hljs-number">4</span></span>, input_shape=[<span class="hljs-number"><span class="hljs-number">1</span></span>]) l1 = tf.keras.layers.Dense(units=<span class="hljs-number"><span class="hljs-number">4</span></span>) l2 = tf.keras.layers.Dense(units=<span class="hljs-number"><span class="hljs-number">1</span></span>) model = tf.keras.Sequential([l0, l1, l2]) model.compile(loss=<span class="hljs-string"><span class="hljs-string">'mean_squared_error'</span></span>, optimizer=tf.keras.optimizers.Adam(<span class="hljs-number"><span class="hljs-number">0.1</span></span>)) model.fit(celsius_q, fahrenheit_a, epochs=<span class="hljs-number"><span class="hljs-number">500</span></span>, verbose=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) print(<span class="hljs-string"><span class="hljs-string">"  "</span></span>) print(model.predict([<span class="hljs-number"><span class="hljs-number">100.0</span></span>])) print(<span class="hljs-string"><span class="hljs-string">" ,  100    {}  "</span></span>.format(model.predict([<span class="hljs-number"><span class="hljs-number">100.0</span></span>]))) print(<span class="hljs-string"><span class="hljs-string">"    l0: {}"</span></span>.format(l0.get_weights())) print(<span class="hljs-string"><span class="hljs-string">"    l1: {}"</span></span>.format(l1.get_weights())) print(<span class="hljs-string"><span class="hljs-string">"    l2: {}"</span></span>.format(l2.get_weights()))</code> </pre><br>  Conclusion: <br><br><pre> <code class="plaintext hljs">   [[211.74748]]  ,  100    [[211.74748]]       l0: [array([[-0.5972079 , -0.05531882, -0.00833384, -0.10636603]], dtype=float32), array([-3.0981746, -1.8776944, 2.4708805, -2.9092448], dtype=float32)]     l1: [array([[ 0.09127654, 1.1659832 , -0.61909443, 0.3422218 ], [-0.7377194 , 0.20082018, -0.47870865, 0.30302727], [-0.1370897 , -0.0667181 , -0.39285263, -1.1399261 ], [-0.1576551 , 1.1161333 , -0.15552482, 0.39256814]], dtype=float32), array([-0.94946504, -2.9903848 , 2.9848468 , -2.9061244 ], dtype=float32)]     l2: [array([[-0.13567649], [-1.4634581 ], [ 0.68370366], [-1.2069695 ]], dtype=float32), array([2.9170544], dtype=float32)]</code> </pre><br>  As you may have noticed, the current model is also capable of predicting the corresponding values ‚Äã‚Äãof Fahrenheit degrees quite well.  However, if you look at the values ‚Äã‚Äãof internal variables (weights) of neurons by layers, then we will not see any values ‚Äã‚Äãsimilar to 1.8 and 32.  The added complexity of the model hides the ‚Äúsimple‚Äù form of converting degrees Celsius to degrees Fahrenheit. <br><br>  Stay in touch and in the next part we will look at how the Dense layers work ‚Äúunder the hood‚Äù. <br><br><h3>  Brief summary </h3><br>  Congratulations!  You just trained your first model.  In practice, we saw how the model learned from the input and output values ‚Äã‚Äãto multiply the input value by 1.8 and add 32 to it to get the correct result. <br><br><img src="https://habrastorage.org/webt/g7/c9/ho/g7c9horz6n3sokt6htkcie4ydsq.jpeg"><br><br>  It was really impressive considering how many lines of code we needed to write: <br><br><pre> <code class="python hljs">l0 = tf.keras.layers.Dense(units=<span class="hljs-number"><span class="hljs-number">1</span></span>, input_shape=[<span class="hljs-number"><span class="hljs-number">1</span></span>]) model = tf.keras.Sequential([l0]) model.compile(loss=<span class="hljs-string"><span class="hljs-string">'mean_squared_error'</span></span>, optimizer=tf.keras.optimizers.Adam(<span class="hljs-number"><span class="hljs-number">0.1</span></span>)) history = model.fit(celsius_q, fahrenheit_a, epochs=<span class="hljs-number"><span class="hljs-number">500</span></span>, verbose=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) model.predict([<span class="hljs-number"><span class="hljs-number">100.0</span></span>])</code> </pre><br>  The above example is a general plan for all machine learning programs.  You will use similar constructions to create and train neural networks and to solve subsequent problems. <br><br><h3>  Training process </h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The training process (occurring in the method </font></font><code>model.fit(...)</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">) consists of a very simple sequence of actions, the result of which should be the values ‚Äã‚Äãof the internal variables that give the results as close as possible to the original. </font><font style="vertical-align: inherit;">The optimization process by which such results are achieved, called </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">gradient descent</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , uses numerical analysis to find the most appropriate values ‚Äã‚Äãfor the internal variables of the model.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In order to engage in machine learning for you, in principle, there is no need to understand these details. But for those who are still interested in learning more: gradient descent, by iterations, changes the values ‚Äã‚Äãof parameters a little bit, ‚Äúpulling‚Äù them in the right direction until the best results are obtained. In this case, the ‚Äúbest results‚Äù (best values) mean that any subsequent change in the parameter will only worsen the model's result. The function that measures how good or bad the model at each iteration is called the ‚Äúloss function‚Äù and the goal of each ‚Äúpullout‚Äù (correction of internal values) is to reduce the value of the loss function.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The training process begins with the ‚Äúdirect distribution‚Äù block, in which the input parameters are input to the neural network, follow to the hidden neurons and then go to the weekend. The model then applies internal transformations over the input values ‚Äã‚Äãand internal variables to predict the response. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In our example, the input value is the temperature in degrees Celsius and the model predicted the corresponding value in degrees Fahrenheit. </font></font><br><br><img src="https://habrastorage.org/webt/vo/vs/sx/vovssxwlsojtbl89vts6llkqfgk.jpeg"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">As soon as the value is predicted, the difference between the predicted value and the correct value is calculated. The difference is called ‚Äúloss‚Äù and is a form of measuring how well the model worked. The loss value is calculated by the loss function, which we defined as one of the arguments when calling the method </font></font><code>model.compile(...)</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">After calculating the loss value, the internal variables (weights and displacements) of all layers of the neural network are adjusted to minimize the loss value in order to bring the output value closer to the correct original reference value. </font></font><br><br><img src="https://habrastorage.org/webt/wd/sf/qb/wdsfqbnpgcoudq5h7xtoik7omxa.jpeg"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">This optimization process is called </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">gradient descent</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . A specific optimization algorithm is used to calculate the new value for each internal variable when the method is called </font></font><code>model.compile(...)</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. In the example above, we used an optimization algorithm </font></font><code>Adam</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">For this course it is not necessary to understand the principles of the workout process, however, if you are curious enough, you can find more information in </font></font><a href="https://developers.google.com/machine-learning/crash-course/reducing-loss/video-lecture"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Google Crash Course</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">(translation and practical part of the whole course are laid by the author in the plans for publication). </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">By this point you should already be familiar with the following terms:</font></font><br><br><ul><li> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Property</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : input value of our model;</font></font></li><li> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Examples</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : pairs of input + output values;</font></font></li><li> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tags</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : model output values;</font></font></li><li> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Layers</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : a collection of nodes combined together within a neural network;</font></font></li><li> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Model</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : representing your neural network;</font></font></li><li> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dense and fully connected</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : each node in one layer is associated with each node from the previous layer.</font></font></li><li> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Weights and offsets</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : internal model variables;</font></font></li><li> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Losses</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : the difference between the desired output value and the actual output value of the model;</font></font></li><li> <b>MSE</b> :  ,   ,        ,    . </li><li> <b> </b> : ,     -         ; </li><li> <b></b> :     ; </li><li> <b>  </b> :  ¬´¬ª       ; </li><li> <b></b> :      ; </li><li> <b></b> :       ; </li><li> <b> </b> :      ; </li><li> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Back propagation</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : calculating the values ‚Äã‚Äãof internal variables according to an optimization algorithm, starting from the output layer and towards the input layer through all intermediate layers.</font></font></li></ul><br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Dense layers </font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In the previous section, we created a model that converts Celsius degrees to Fahrenheit degrees, using a simple neural network to find the relationship between Celsius degrees and Fahrenheit degrees. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Our network consists of a single fully connected layer. </font><font style="vertical-align: inherit;">But what is a full connected layer? </font><font style="vertical-align: inherit;">To understand this, let's create a more complex neural network with 3 input parameters, one hidden layer with two neurons and one output layer with a single neuron.</font></font><br><br><img src="https://habrastorage.org/webt/qo/_p/rk/qo_prk3p2aclbp8xdyzgk8trkme.jpeg"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Recall that a neural network can be thought of as a set of layers, each of which consists of nodes called neurons. Neurons at each level can be connected to the neurons of each subsequent layer. The type of layers in which each neuron of one layer is connected with each other neuron of the next layer is called a fully connected (fully connected) or dense layer (the </font></font><code>Dense</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">-layer). </font></font><br><br><img src="https://habrastorage.org/webt/yk/dl/wb/ykdlwbtzt8rbjusmtndstttg_em.jpeg"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Thus, when we use fully connected layers in </font></font><code>keras</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, we kind of inform that the neurons of this layer must be connected with all the neurons of the previous layer. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">To create the above neural network, the following expressions are enough for us:</font></font><br><br><pre> <code class="python hljs">hidden = tf.keras.layers.Dense(units=<span class="hljs-number"><span class="hljs-number">2</span></span>, input_shape=[<span class="hljs-number"><span class="hljs-number">3</span></span>]) output = tf.keras.layers.Dense(units=<span class="hljs-number"><span class="hljs-number">1</span></span>) model = tf.keras.Sequential([hidden, output])</code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">So, we figured out what are neurons and how they are interconnected. But how do fully connected layers actually work? </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">To understand what is actually happening there and what they are doing, we need to look under the hood and analyze the internal mathematics of neurons. </font></font><br><br><img src="https://habrastorage.org/webt/io/xa/yf/ioxayfceecf7saxdaxnzw3hjyw4.jpeg"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Imagine that our model takes as its input three parameters - </font></font><code>1, 2, 3</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, and </font></font><code>1, 2  3</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">- the neurons of our network. Remember we said that the neuron has internal variables? So, </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">w *</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> and </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">b *</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> are the same internal variables of the neuron, also known as </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">weights</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> and </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">displacements</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. It is the values ‚Äã‚Äãof these variables that are adjusted in the learning process in order to obtain the most accurate results of the comparison of the input values ‚Äã‚Äãof the output. </font></font><br><br><img src="https://habrastorage.org/webt/gz/ff/pf/gzffpftu7hqtdvesq6g9jmcjj10.jpeg"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">What you should definitely keep in mind - the </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">internal mathematics of the neuron remains unchanged</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . In other words, in the process of training </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">only the</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> weights and displacements </font><font style="vertical-align: inherit;">change </font><font style="vertical-align: inherit;">. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">When you start learning machine learning it may seem strange - the fact that it really works, but that‚Äôs how machine learning works! </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Let us now return to our example of converting degrees Celsius to degrees Fahrenheit. </font></font><br><br><img src="https://habrastorage.org/webt/qv/vf/hz/qvvfhzkmdgzktu-yi8i64_cqo4q.jpeg"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">With a single neuron, we only have one weight and one offset.</font></font> You know what?<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">This is exactly what the formula for converting degrees Celsius to degrees Fahrenheit looks like. If we substitute a </font></font><code>w11</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">value </font></font><code>1.8</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, and instead of </font></font><code>b1</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">- </font></font><code>32</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, we get the final transformation model! </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">If we return to the results of our model from the practical part, we note that the weight and displacement indicators were ‚Äúcalibrated‚Äù in such a way that they approximately correspond to the values ‚Äã‚Äãfrom the formula.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">We purposefully created just such a practical example to visually show the exact comparison between weights and displacements. By applying machine learning in practice, we can never compare the values ‚Äã‚Äãof variables with the target algorithm in the same way, as in the example above. How can we do this? No, because we do not even know the target algorithm! </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Solving machine learning problems we test various architectures of neural networks with different numbers of neurons in them - by trial and error we find the most accurate architectures and models and we hope that they will solve the task set in the learning process. In the following practical part we will be able to study concrete examples of such an approach. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Stay in touch, because now the fun begins!</font></font><br><br><h3>  Results </h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In this lesson, we learned basic approaches to machine learning and learned how fully connected layers (- </font></font><code>Dense</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">layers) work. </font><font style="vertical-align: inherit;">You trained your first model to convert degrees Celsius to degrees Fahrenheit. </font><font style="vertical-align: inherit;">You also learned the basic terms used in machine learning, such as properties, examples, tags. </font><font style="vertical-align: inherit;">You, among other things, wrote the main lines of Python code that are the backbone of any machine learning algorithm. </font><font style="vertical-align: inherit;">You saw that in a few lines of code you can create, train and request a prediction from a neural network using </font></font><code>TensorFlow</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">and </font></font><code>Keras</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">... and standard call-to-action - subscribe, put a plus and share :)</font></font><br><br><div class="spoiler"> <b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Video version of the article</font></font></b> <div class="spoiler_text"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> The video comes out the day after publication. </font></font><br></div></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">YouTube: </font></font><a href="https://www.youtube.com/channel/UCF06rqj-U4Q0SitG8NX11EQ%3Fsub_confirmation%3D1"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">https://youtube.com/channel/ashmig</font></font></a> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Telegram: </font></font><a href="https://t.me/ashmig"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">https://t.me/ashmig</font></font></a> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> VK: </font></font><a href="https://vk.com/ashmig"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">https://vk.com/ashmig</font></font></a> </div><p>Source: <a href="https://habr.com/ru/post/453558/">https://habr.com/ru/post/453558/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../453544/index.html">Seven-segment decoder using both direct and inverse outputs of a BCD counter</a></li>
<li><a href="../453546/index.html">Need a small keyboard - make it yourself</a></li>
<li><a href="../453548/index.html">We revive braking Samsung Galaxy TAB 2 WiFi</a></li>
<li><a href="../453552/index.html">Sort: determine the best algorithm</a></li>
<li><a href="../453554/index.html">How has Starlink changed from SpaceX</a></li>
<li><a href="../453562/index.html">Digital events in Moscow from May 27 to June 2</a></li>
<li><a href="../453564/index.html">Make it True - Developing a logical game on Unity</a></li>
<li><a href="../453578/index.html">From critics to algorithms: labels, corporations and musical culture of the 20th century</a></li>
<li><a href="../45358/index.html">Blog for crisis</a></li>
<li><a href="../453580/index.html">The digest of fresh materials from the world of the frontend for the last week ‚Ññ 366 (May 20 - 26, 2019)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>