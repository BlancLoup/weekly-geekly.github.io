<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Hybrid PHP / Go Application Development Using RoadRunner</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="The classic PHP application is single-threaded, heavy loading (unless of course you write on microframes) and the inevitable death of the process afte...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Hybrid PHP / Go Application Development Using RoadRunner</h1><div class="post__text post__text-html js-mediator-article">  The classic PHP application is single-threaded, heavy loading (unless of course you write on microframes) and the inevitable death of the process after each request ... Such an application is heavy and slow, but we can give it a second life by hybridization.  To speed up - we demonize and optimize memory leaks to achieve better performance - we will introduce our own Golang RoadRunner PHP application server to add flexibility - we simplify the PHP code, expand the stack and share responsibility between the server and the application.  In essence, we will make our application work as if we were writing it in Java or another language. <br><br>  Thanks to hybridization, a previously slow application stopped suffering from 502 errors under load, the average response time to requests decreased, productivity increased, and deployment and assembly became easier due to unification of the application and getting rid of unnecessary bindings in the form of nginx + php-fpm. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/RUm94xCaXMo" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  <strong>Anton Titov</strong> ( <a href="https://habr.com/ru/users/lachezis/" class="user_link">Lachezis</a> ) is CTO and co-founder of SpiralScout LLC with 12 years of active commercial development experience in PHP.  Over the past few years, he has been actively implementing Golang on the company's development stack.  Anton spoke about one example at <a href="https://phprussia.ru/2019">PHP Russia 2019</a> . <br><a name="habracut"></a><br><h2>  PHP Application Life Cycle </h2><br>  Schematically, the device of an abstract application with a certain framework looks like this. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/webt/mm/va/0d/mmva0djqxjc5l733ikzi738ydry.jpeg"><br><br>  When we send a request to a process, it happens: <br><br><ul><li>  project initialization; </li><li>  loading shared libraries, frameworks, and ORMs; </li><li>  loading libraries required for a specific project; </li><li>  routing; </li><li>  request routing to a specific controller; </li><li>  response generation. </li></ul><br>  This is the principle of operation of a classic <strong>single-threaded application</strong> with a single entry point, which after each execution is completely destroyed or clears its state.  All code is unloaded from memory, the worker is cleared, or simply resets its state. <br><br><h3>  Lazy-loading </h3><br>  The standard and simple way to speed up is the implementation of the <strong>Lazy-loading system</strong> or On-demand-loading libraries. <br><br><img src="https://habrastorage.org/webt/vj/eb/gp/vjebgpv7_a4fuvu64x4g8eqmbke.jpeg"><br><br><blockquote>  With Lazy-loading we request only the necessary code. </blockquote><br>  When accessing a specific controller, only the necessary libraries will be loaded into memory, processed, and then unloaded.  This allows you to <strong>reduce the average response time of the project</strong> and greatly facilitate the process of working on the server.  In all the frameworks we are currently using, the principle of lazy loading is implemented. <br><br><h3>  Cache frequent calculations </h3><br>  The method is more complicated and actively used, for example, in the Symfony framework, template engines, ORM schemes, and routing.  This is not caching like memcached or Redis for user data.  This system <strong>warms up parts of the code in advance</strong> .  At the first request, the system generates code or a cache file, and at subsequent requests, these calculations, necessary, for example, to compile a template, will no longer be performed. <br><br><img src="https://habrastorage.org/webt/nb/44/f6/nb44f6isfvs6vouultxridabeps.jpeg"><br><br>  Caching significantly <strong>speeds up the application</strong> , but at the same time <strong>complicates it</strong> .  For example, there are problems with invalidating the cache and updating the application.  Do not confuse the user cache with the application cache - in one, the data changes over time, in the other only when the code is updated. <br><br><h3>  Processing request </h3><br>  When a request is received from an external PHP-FPM server, the request entry point and initialization will match. <br><br><blockquote>  It turns out that the client‚Äôs request is the state of our process. </blockquote><br>  The only way to change this state is to completely destroy the worker and start over with a new request. <br><br><img src="https://habrastorage.org/webt/jc/cr/rb/jccrrb-szkhb6_nfn2zthotuctk.jpeg"><br><br>  This is a single-threaded classic model with its advantages. <br><br><ul><li>  All workers at the end of the request die. </li><li>  Memory leaks, race condition, deadlocks are not inherent in PHP.  You can not worry about it. </li><li>  The code is simple: we write, process the request, die and move on. </li></ul><br>  On the other hand, for each request, we completely load the framework, all the libraries, perform some calculations, recompile the templates.  With each request in a circle we produce a lot of manipulation and unnecessary work. <br><br><h3>  How it works on the server </h3><br>  Most likely, a bunch of nginx and PHP will work.  Nginx will work as a reverse proxy: give users part of the statics, and delegate part of the requests to the PHP process manager PHP-FPM below.  Already the manager raises a separate worker for the request and processes it.  After that, the worker is destroyed or cleared.  Next, a new worker is created for the next request. <br><br><img src="https://habrastorage.org/webt/8f/lc/fp/8flcfpz6zxemgxlas6avx5aguqa.jpeg"><br><br>  Such a model works stably - the application is almost impossible to kill.  But under heavy loads, the amount of work for initializing and destroying workers affects the system performance, because even for a simple GET request, we often have to pull a bunch of dependencies and re-raise the database connection. <br><br><h2>  Speeding up the application </h2><br>  How to speed up the classic application after introducing cache and Lazy-loading?  What other options are there? <br><br>  <strong>Turn to the language itself</strong> . <br><br><ul><li>  <strong>Use OPCache.</strong>  I think no one is running PHP on production without OPCache enabled? </li><li>  Wait for <strong>RFC: Preloading</strong> .  It allows you to preload a set of files into a virtual machine. </li><li>  <strong>JIT</strong> - seriously accelerates the application on CPU-bound tasks.  Unfortunately, with tasks related to databases, it will not help much. </li></ul><br>  <strong>Use alternatives</strong> .  For example, the HHVM virtual machine from Facebook.  It executes code in a more streamlined environment.  Unfortunately, HHVM is not fully compatible with PHP syntax.  As an alternative, kPHP compilers from VK or PeachPie, which completely converts code to .NET C #, are an alternative. <br><br>  <strong>Fully rewrite to another language.</strong>  This is a radical option - completely get rid of code loading between requests. <br><br>  You can completely <b>store the state of the application in memory</b> , actively use this memory for work, and forget about the concept of a dying worker and completely clear the application between requests. <br><br>  To achieve this, we remove the entry point, which used to be together with the initialization point, deep into the application. <br><br><h3>  Transferring entry point - demonization </h3><br>  This is creating an infinite loop in the application: an incoming request - run it through the framework - we generate a response to the user.  This is a serious saving - all bootstrapping, all framework initialization is performed only once, and then several requests are processed by the application. <br><br><img src="https://habrastorage.org/webt/ce/7k/3l/ce7k3lov0kzcyxc3zyjq008taiy.jpeg"><br><br><h3>  We adapt the application </h3><br>  Interestingly, we can focus on optimizing only that part of the application that will run <strong>in runtime</strong> : controllers, business logic.  In this case, you can abandon the Lazy-loading model.  We will take part of the bootstrapping of the project to the beginning - at the time of initialization.  Preliminary calculations: routing, templates, settings, ORM schemes will inflate initialization, but in the future they will save processing time for one specific request. <br><br><img src="https://habrastorage.org/webt/fz/kj/ft/fzkjftdkc41niwqyrmml-ijjkwy.jpeg"><br><br>  I do not recommend compiling templates when downloading a worker, but downloading, for example, all configurations is useful. <br><br><h3>  Compare Models </h3><br>  Compare the demonized (left) and classic models. <br><br><img src="https://habrastorage.org/webt/zo/en/6r/zoen6rl8zyj6tpn7bghp_ozv61m.jpeg"><br><br>  The demonized model from the moment the process was created until the moment the response is returned to the user takes longer.  The classic application is optimized for quick creation, processing and destruction. <br><br>  However, all subsequent requests after warming up the code are much faster.  The framework, application, container is already in memory and ready to accept requests and respond quickly. <br><br><h3>  Problems of the long-lived model </h3><br>  Despite the advantages, the model has a set of limitations. <br><br>  <strong>Memory leaks.</strong>  The application lies in memory for a very long time, and if you use the "curves" of the library, the wrong dependencies or global states - the memory will begin to leak.  At some point, a fatal error will appear that will break the user's request. <br><br>  The problem is solved in two ways. <br><br><ul><li>  Write accurate code, use proven libraries. </li><li> Actively monitor workers.  If you suspect that memory is leaking inside the process, proactively change it to an analog with a lower limit, that is, simply to a new copy that has not yet managed to accumulate uncleaned memory. </li></ul><br>  <strong>Data leaks</strong> .  For example, if during an incoming request we save the current user of the system in some global variable and forget to reset this variable after the request, then there is a chance that the next user of the system will accidentally gain access to data that he should not see. <br><br>  The problem is solved at the application architecture level. <br><br><ul><li>  Do not store an active user in a global context.  All data that is specific to the request context is discarded and cleared before the next request. </li><li>  Handle session data carefully.  Sessions in PHP - with the classical approach, this is a global object.  Wrap it correctly so that it is reset on a subsequent request. </li></ul><br>  <strong>Resource management</strong> . <br><br><ul><li>  Monitor connections to the database.  If the application hangs in the memory for a month or two, then the open connection will most likely close in this time: the database will be re-installed, rebooted or the firewall will reset the connection.  At the code level, consider reconnect or, after each request, reset the connection and re-raise it at the next request. </li><li>  Avoid long-lived file lock.  If your worker writes some information to a file, there is no problem.  But if this file is open and has a lock on it, then no other process in your system will have access to it until the lock is released. </li></ul><br><br><h2>  Explore the long-lived model </h2><br>  Consider the long-lived worker model ‚Äî demonizing an application ‚Äî and explore ways to implement it. <br><br><h3>  Non-blocking approach </h3><br>  We use asynchronous PHP - we load the application once into memory and process incoming HTTP requests inside the application.  Now the <strong>application and the server are one process</strong> .  When the request arrives, we create a separate coroutine or in the event loop we give a promise, process it and give it to the user. <br><br><img src="https://habrastorage.org/webt/v6/js/od/v6jsodvtlxjfy1udzwvl0wa2njk.jpeg"><br><br>  The undeniable advantage of the approach is maximum performance.  It is also possible to use interesting tools, for example, <strong>configure WebSocket directly on your application</strong> . <br><br>  However, the approach significantly <strong>increases the complexity of the development</strong> .  You need to install ELDO, remember that not all database drivers will be supported, and the PDO library is excluded. <br><br>  To solve problems in the case of demonization with a non-blocking approach, you can use well-known tools: <strong>ReactPHP</strong> , <strong>amphp</strong> and <strong>Swoole</strong> - an interesting development in the form of a C-extension.  These tools work quickly, they have a good community and good documentation. <br><br><h3>  Blocking approach </h3><br>  We do not raise coroutines inside the application, but do it from the outside. <br><br><img src="https://habrastorage.org/webt/ad/ul/eq/adulequ1msa3sb6ae6saah3bu-c.jpeg"><br><br>  We just <strong>pick up a few application processes</strong> , as PHP-FPM would do.  Instead of transmitting these requests in the form of a process state, we deliver them from the outside in the form of a protocol or messaging. <br><br>  We write the same <strong>single-threaded code</strong> that we know, we use all the same libraries and the same PDO.  All the hard work of working with sockets, HTTP, and other tools is done <strong>outside of a PHP application</strong> . <br><br>  Of the minuses: we must <strong>monitor the memory</strong> and remember that <strong>communication between two different processes is not free</strong> , but we need to transfer data.  This will create a slight overhead. <br><br>  To solve the problem, there is already a <strong>PHP-RM tool</strong> that is written in PHP.  On the ReactPHP library, it has <strong>integration with several frameworks</strong> .  However, PHP-PM is very <strong>slow, it leaks memory at the server level</strong> and under load it does not show as much growth as PHP-FRM. <br><br><h2>  We write our application server </h2><br>  We wrote <a href="https://roadrunner.dev/">our application server</a> , which is similar to PHP-RM, but there is more functionality.  What did we want from the server? <br><br>  <strong>Combine with existing frameworks.</strong>  We would like to have flexible integration with almost all frameworks on the market.  I don‚Äôt feel like writing a tool that works only in a particular particular case. <br><br>  <strong>Different processes for server and application</strong> .  Possibility of a hot reboot, so that during local development, press F5 and see the new updated code, as well as be able to expand them individually. <br><br>  <strong>High speed and stability</strong> .  Still, we are writing an HTTP server. <br><br>  <strong>Easy extensibility</strong> .  We want to use the server not only as an HTTP-Server, but also for individual scenarios like a queue server or a gRPC server. <br><br>  <strong>Work out of the box</strong> wherever possible: Windows, Linux, ARM CPU. <br><br>  Ability to write very <strong>fast multi-threaded extensions</strong> specific to our application. <br><br>  As you already understood, we will write in Golang. <br><br><h2>  RoadRunner Server </h2><br>  To create a PHP server, you need to solve 4 main problems: <br><br><ul><li>  Establish communication between Golang and PHP processes. </li><li>  Process management: the creation, destruction, monitoring of workers. </li><li>  Balancing tasks - efficient distribution of tasks to workers.  Since we are implementing a system that blocks an individual worker for a particular specific incoming task, it is important to create a system that would quickly say that the process has finished work and is ready to accept the next task. </li><li>  HTTP stack - sending HTTP request data to the worker.  It is a simple task to write an incoming point to which the user sends a request, which is passed to PHP and returned. </li></ul><br><h3>  Variants of interaction between processes </h3><br>  First, let's solve the communication problem between Golang and PHP processes.  We have several ways. <br><br>  <strong>Embedding: embedding a PHP interpreter directly in Golang.</strong>  This is possible, but requires a custom PHP assembly, complex setup, and a common process for the server and PHP.  Like in <a href="https://github.com/deuill/go-php">go-php</a> , for example, where the PHP interpreter is integrated into Golang. <br><br>  <strong>Shared Memory - The use of shared memory space,</strong> <strong>where processes share this space</strong> .  It takes painstaking work.  When exchanging data, you will have to synchronize the state manually and the amount of errors that may occur is quite large.  Shared Memory also depends on the OS. <br><br><h3>  Writing your transport protocol - Goridge </h3><br>  We went along a simple path that is used in almost all solutions on Linux systems - we used the transport protocol.  It is <strong>written on top of the standard PIPES and UNIX / TCP SOCKETS</strong> . <br><br>  It has the ability to transfer data in both directions, detect errors, and also tag requests and put headers on them.  An important nuance for us is the ability to implement the protocol without dependencies both on the side of PHP and Golang - without C-extensions in a pure language. <br><br>  As with any protocol, the foundation is a data packet.  In our case, the packet has a fixed header of 17 bytes. <br><br><img src="https://habrastorage.org/webt/wb/_h/g_/wb_hg_qtkmoxe74sthy12rhtzms.jpeg"><br><br>  The first byte is allocated to determine the type of packet.  This can be a stream or a flag that indicates the type of data serialization.  Then two times we pack the data size into Little Endian and Big Endian.  We use this legacy to detect transmission errors.  If we see that the size of the packed data in two different orders does not match, most likely a data transfer error has occurred.  Then the data is transmitted. <br><br><img src="https://habrastorage.org/webt/bt/rb/dr/btrbdre8cwionih8m6e7yze2crw.jpeg"><br><br>  In the third version of the package, we will get rid of such a legacy, introduce a more classical approach with a checksum, and also add the ability to use this protocol with asynchronous PHP processes. <br><br>  To implement the protocol in Golang and PHP, we used standard tools. <br><br>  <strong>On Golang:</strong> encoding / binary libraries and io and net libraries for working with standard pipes and UNIX / TCP sockets. <br><br>  <strong>In PHP:</strong> the familiar function for working with binary data pack / unpack and the extensions streams and sockets for pipes and sockets. <br><br>  An interesting <strong>side effect</strong> arose during implementation.  We integrated it with the standard Golang net / rpc library, which allows us to call service code from Golang directly in the application. <br><br>  We write a service: <br><br><pre><code class="go hljs"><span class="hljs-comment"><span class="hljs-comment">//  sample type  struct{} // Hi returns greeting message. func (a *App) Hi(name string, r *string) error { *r = fmt.Sprintf("ll, %s!", name) return nil }</span></span></code> </pre> <br>  We call it a small amount of code from the application: <br><br><pre> <code class="go hljs">&lt;?php use Spiral\Goridge; require <span class="hljs-string"><span class="hljs-string">"vendor/autoload.php"</span></span>; $rpc = <span class="hljs-built_in"><span class="hljs-built_in">new</span></span> Goridge\RPC( <span class="hljs-built_in"><span class="hljs-built_in">new</span></span> Goridge\SocketRelay(<span class="hljs-string"><span class="hljs-string">"127.0.0.1"</span></span>, <span class="hljs-number"><span class="hljs-number">6001</span></span>) ); echo $rpc-&gt;call(<span class="hljs-string"><span class="hljs-string">"App.Hi"</span></span>, <span class="hljs-string"><span class="hljs-string">"Antony"</span></span>);</code> </pre> <br><h3>  PHP Process Manager </h3><br>  The next part of the server is the management of PHP workers. <br><img src="https://habrastorage.org/webt/vt/jy/tk/vtjytk9effas7jkgjgadvbek_zw.jpeg"><br><br>  Worker is a PHP process that we constantly monitor from Golang.  We collect the log of its errors in the STDERR file, communicate with the worker via the Goridge transport protocol, and collect statistics on memory consumption, task execution, and blocking. <br><br>  The implementation is simple - this is the standard functionality of os / exec, runtime, sync, atomic.  To create workers we use <strong>Worker Factory</strong> . <br><img src="https://habrastorage.org/webt/wq/kr/tt/wqkrtt0n0xxvhdnxuvx_4f2deiy.jpeg"><br><br>  Why Worker Factory?  Because we want to communicate both on standard pipes and on sockets.  In this case, the initialization process is slightly different.  When creating a worker who communicates by pipe, we can create it immediately and send data directly.  In the case of sockets, you need to create a worker, wait until it reaches the system, make a PID handshake, and only then continue working. <br><br><h3>  Task balancer </h3><br>  The third part of the server is the most important for performance. <br><br>  For implementation, we use the standard Golang functionality - a <strong>buffered channel</strong> .  In particular, we create several workers and put them in this channel as a LIFO stack. <br><img src="https://habrastorage.org/webt/bm/po/f4/bmpof4s5-owl810px69ectqiw_i.jpeg"><br>  Upon receiving tasks from the user, we send a request to the LIFO stack and ask for the first free worker to be issued.  If the worker cannot be allocated for a certain amount of time, then the user receives an error of the type ‚ÄúTimeout Error‚Äù.  If the worker is allocated - it gets out of the stack, is blocked, after which it receives the task from the user. <br><img src="https://habrastorage.org/webt/cm/2o/cq/cm2ocqak94ubao7tk8vxnglfyyo.jpeg"><br>  After the task is processed, the response is returned to the user, and the worker stands at the end of the stack.  He is ready to carry out the next task again. <br><img src="https://habrastorage.org/webt/oj/f_/l4/ojf_l4ipil8fcslpyherhsg02la.jpeg"><br>  If an error occurs, then the user will receive an error, as the worker will be destroyed.  We ask Worker Pool and Worker Factory to create an identical process and replace it on the stack.  This allows the system to work even in the event of fatal errors by simply re-creating workers by analogy with PHP-FPM. <br><img src="https://habrastorage.org/webt/qs/li/dq/qslidqche8glb-q5pucwfwnpogw.jpeg"><br><br>  As a result, it turned out to implement a small system that works very quickly - <strong>200 ns for the allocation of the worker</strong> .  It is able to work even in case of fatal errors.  Each worker at one point in time processes only one task, which allows us to use the <strong>classic blocking approach</strong> . <br><br><h3>  Proactive monitoring </h3><br>  A separate part of both the process manager and the task balancer is the proactive monitoring system. <br><img src="https://habrastorage.org/webt/83/zq/ep/83zqepdmerd6ozakntcmv33hnus.jpeg"><br><br>  This is a system that once a second polls workers and monitors indicators: it looks at how much memory they consume, how much they are in, whether they are IDLE.  In addition to tracking, the system monitors memory leaks.  If the worker exceeds a certain limit, we will see it and carefully remove it from the system before a fatal leak occurs. <br><br><h3>  HTTP stack </h3><br>  The last and simple part. <br><img src="https://habrastorage.org/webt/hl/cc/7e/hlcc7ehfob5vhc_zjse_em8e0eg.jpeg"><br>  <strong>How is it implemented:</strong> <br><br><ul><li>  raises an HTTP point on the Golang side; </li><li>  we receive a request; </li><li>  convert to PSR-7 format; </li><li>  send the request to the first free worker; </li><li>  Unpack the request into a PSR-7 object; </li><li>  we process; </li><li>  we generate the answer. </li></ul><br>  For implementation, we used the standard <strong>Golang NET / HTTP library</strong> .  This is a well-known library with many extensions.  Able to work both over HTTPS and over the HTTP / 2 protocol. <br><br>  On the PHP side, we used the PSR-7 standard <strong>.</strong>  It is an <strong>independent framework</strong> with many extensions and Middlewares.  The PSR-7 is <strong>immutable in design</strong> , which fits well with the concept of long-lived applications and avoids global query errors. <br><br>  Both structures in both Golang and PSR-7 are similar, which significantly saved time for mapping a request from one language to another. <br><br>  To start the server requires a <strong>minimum binding</strong> : <br><br><pre> <code class="go hljs">http: address: <span class="hljs-number"><span class="hljs-number">0.0</span></span><span class="hljs-number"><span class="hljs-number">.0</span></span><span class="hljs-number"><span class="hljs-number">.0</span></span>:<span class="hljs-number"><span class="hljs-number">8080</span></span> workers: command: <span class="hljs-string"><span class="hljs-string">"php psr-worker.php"</span></span> pool: numWorkers: <span class="hljs-number"><span class="hljs-number">4</span></span></code> </pre> <br>  Moreover, from version 1.3.0 the last part of the config can be omitted. <br><br>  Download the server binary file, put it in the Docker container or in the project folder.  Alternatively, globally we write a small configuration file that describes which pod we are going to listen to, which worker is the entry point, and how many are required. <br><br>  On the PHP side, we write a primary loop that receives a PSR-7 request, processes it, and returns a response or an error back to the server. <br><br><pre> <code class="go hljs">while ($req = $psr7-&gt;acceptRequest()) { try { $resp = <span class="hljs-built_in"><span class="hljs-built_in">new</span></span> \Zend\Diactoros\Response(); $resp-&gt;getBody()-&gt;write(<span class="hljs-string"><span class="hljs-string">"hello world"</span></span>); $psr7-&gt;respond($resp); } catch (\Throwable $e) { $psr7-&gt;getWorker()-&gt;error((<span class="hljs-keyword"><span class="hljs-keyword">string</span></span>)$e); } }</code> </pre> <br>  <strong>Assembly</strong>  To implement the server, we chose an architecture with a component approach.  This makes it possible to assemble the server for the needs of the project, adding or removing individual pieces depending on the requirements of the application. <br><br><pre> <code class="go hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">func</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">main</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span></span> { rr.Container.Register(env.ID, &amp;env.Service{}) rr.Container.Register(rpc.ID, &amp;rpc.Service{}) rr.Container.Register(http.ID, &amp;http.Service{}) rr.Container.Register(static.ID, &amp;static.Service{}) rr.Container.Register(limit.ID, &amp;limit.Service{} <span class="hljs-comment"><span class="hljs-comment">// you can register additional commands using cmd.CLI rr.Execute() }</span></span></code> </pre> <br><h2>  Use cases </h2><br>  Consider the options for using the server and modifying the structure.  To begin, consider the classic pipeline - the server‚Äôs work with requests. <br><br><h3>  Modularity </h3><br>  The server receives the request to an HTTP point and passes it through a set of Middleware, which are written in Golang.  An incoming request is converted to a task that the worker understands.  The server gives the task to the worker and returns it back. <br><br><img src="https://habrastorage.org/webt/zz/v5/ak/zzv5akvapzklanxdlzunxdq-xpu.jpeg"><br><br>  At the same time, the worker, using the Goridge protocol, communicates with the server, monitors its status and transfers data to it. <br><br><h3>  Middleware on Golang: authorization </h3><br>  This is the first thing to do.  In our application, we wrote Middleware to <strong>authorize a user by JWT token</strong> .  Middleware is written similarly for any other type of authorization.  A very banal and simple implementation is to write Rate-Limiter or Circuit-Breaker. <br><br><img src="https://habrastorage.org/webt/on/zg/ro/onzgroqwxc7umuy-y2xfv9s7dqe.jpeg"><br><br>  <strong>Authorization is quick</strong> .  If the request is not valid - just do not send it to the PHP application and do not spend resources on processing useless tasks. <br><br><h3>  Monitoring </h3><br>  The second use case.  We can integrate the monitoring system directly into Golang Middleware.  For example, Prometheus, to collect statistics on the speed of response points, the number of errors. <br><br><img src="https://habrastorage.org/webt/rz/_o/hz/rz_ohzkiz6bwjoebzqu2qt4e6dc.jpeg"><br><br>  You can also <strong>combine monitoring with application-specific metrics</strong> (available as standard with 1.4.5).  For example, we can send the number of requests to the database or the number of processed specific requests to the Golang server, and then to Prometheus. <br><br><h3>  Distributed Tracing and Logging </h3><br>  We write Middleware with a process manager.  In particular, we can connect to the realtime system for monitoring logs and <strong>collect all the logs in one central database</strong> , which is useful when writing distributed applications. <br><br><img src="https://habrastorage.org/webt/lf/ir/cd/lfircdprhx6nqetmadblqftvbu4.jpeg"><br><br>  We can also <strong>tag requests</strong> , give them a specific ID and pass this ID to all downstream services or communication systems between them.  As a result, we can build a <strong>distributed trace</strong> and see how the application logs go. <br><br><h3>  Record your query history </h3><br>  This is a small module that records all incoming requests and stores them in an external database.  The module allows you to make replay requests in the project and implement an automatic testing system, a load testing system, or just checking the operation of the API. <br><br><img src="https://habrastorage.org/webt/ex/q3/kg/exq3kgpym1uf6tjcfwysjk1so00.jpeg"><br><br>  How did we implement the module? <br><br>  <strong>We process part of the requests for Golang</strong> .  We write Middleware in Golang and we can send part of the requests to Handler, which is also written in Golang.  If any point in the application is worrying in terms of performance, we rewrite it to Golang and drag the stack from one language to another. <br><br><img src="https://habrastorage.org/webt/q0/zf/qn/q0zfqnzddo_mn7h-d779cg9ganm.jpeg"><br><br>  <strong>We are writing a WebSocket server</strong> .  Implementing a WebSocket server or push notification server is becoming a trivial task. <br><br><ul><li>  Golang service at the server level. </li><li>  For communication we use Goridge. </li><li>  Thin service layer in PHP. </li><li>  We implement the notification server. </li></ul><br>  We receive a request and raise a WebSocket connection.  If the application needs to send some kind of notification to the user, it launches this message via the RPC protocol to the WebSocket server. <br><br><img src="https://habrastorage.org/webt/go/ta/fv/gotafvsepr8u8_r_lvfdjpff2rg.jpeg"><br><br>  <strong>Manage your PHP environment.</strong>  When creating a Worker Pool, RoadRunner has full control over the state of environment variables and allows you to change them as you like.  If we are writing a large distributed application, we can use a single source of configuration data and connect it as a system to configure the environment.  If we raise a set of services, all these services will knock on one single system, configure and then work.  This can greatly simplify the deployment, as well as get rid of .env files. <br><br><img src="https://habrastorage.org/webt/iv/m5/03/ivm503pht02yug6do6-od3pyt6i.jpeg"><br><br>  Interestingly, the env variables that are available inside the worker are not global within the system.  This slightly improves container safety. <br><br><h3>  Golang library integration in PHP </h3><br>  We used this option on the official website of <a href="https://roadrunner.dev/">RoadRunner</a> .  This is an integration of a practically full-fledged database <strong>with full-text search BleveSearch</strong> inside the server. <br><br><img src="https://habrastorage.org/webt/5a/ba/uc/5abaucml3dmvxqpns_h7bug_ldi.jpeg"><br><br>  We indexed the documentation pages: we placed them in Bolt DB, after which we performed a full-text search without a real database like MySQL, and without a search cluster like Elasticsearch.  The result was a small project where some of the functionality is in PHP, but the search is in Golang. <br><br><h3>  Implementing Lambda Functions </h3><br>  You can go further and <strong>completely get rid of the HTTP layer.</strong>  In this case, implementing, for example, Lambda functions is a simple task. <br><br><img src="https://habrastorage.org/webt/ty/ie/dy/tyiedyrsetx2l5wljnllkbju0xg.jpeg"><br><br>  For implementation, we use the standard <a href="https://roadrunner.dev/docs/library-aws-lambda">AWS runtime</a> for the Lambda function.  We write a small binding, completely cut out the HTTP servers and send the data in binary format to the workers.  We also have access to the environment settings, which allows us to write functions that are configured directly from the Amazon admin panel. <br><br>  Workers are in memory for the entire life of the process, and the Lambda function after the initial request remains in memory for 15 minutes.  At this time, the code does not load and responds quickly.  In synthetic tests, we received up to <strong>0.5 ms per one incoming request</strong> . <br><br><h3>  gRPC for PHP </h3><br>  The more difficult option is to replace the HTTP layer with the gRPC layer.  This <a href="https://github.com/spiral/php-grpc">package is available on GitHub</a> . <br><img src="https://habrastorage.org/webt/jh/u5/cg/jhu5cgv7-cdj6wf4ifukhqxnd0u.jpeg"><br><br>  We can completely proxy all incoming Protobuf requests to a subordinate PHP application, there they can be unpacked, processed and answered back.  We can write code in both PHP and Golang, combining and transferring functionality from one stack to another.  The service supports Middleware.  The standalone application can work as well as in conjunction with HTTP. <br><br><h3>  Queue server </h3><br>  The last and most interesting option is the implementation of <a href="https://github.com/spiral/jobs">the queue server</a> . <br><img src="https://habrastorage.org/webt/rn/ch/1i/rnch1i0ieekunszmsv_ppegtwbu.jpeg"><br><br>  On the PHP side, all we do is get a binary payload, unpack it, do the work, and tell the server about the success.  On the Golang side, we are fully engaged in managing connections with brokers.  It could be RabbitMQ, Amazon SQS or Beanstalk. <br><br>  On the Golang side, we implement the ‚Äú <strong>Graceful shutdown‚Äù of</strong> workers.  We can beautifully wait for the implementation of the ‚Äúdurable connection‚Äù - if the connection with the broker is lost, the server waits for a while using the ‚Äúback-off strategy‚Äù, it lifts the connection and the application does not even notice it. <br><br>  We can process these requests in both PHP and Golang, and queue them on both sides: <br><br><ul><li>  from the PHP side through the Goridge protocol Goridge RPC; </li><li>  from Golang - communicating with the SDK library. </li></ul><br>  If payload falls, then not the entire Consumer falls, but only one separate process.  The system immediately raises it, the task is sent to the next worker.  This allows you to perform non-stop tasks. <br><br>  We implemented one of the brokers directly in the server memory and used the Golang functionality.  This allows us to write an application using queues before choosing the final stack.  We lift the application locally, run it, and we have queues that work in memory and behave the same way they would behave on RabbitMQ, Amazon SQS or Beanstalk. <br><br>  When using two languages ‚Äã‚Äãin such a hybrid combination, it is worth remembering how to separate them. <br><br><h3>  Separate domain domains </h3><br><blockquote>  Golang is a multi-threaded and fast language that is suitable for writing infrastructure logic and user monitoring and authorization logic. </blockquote><br>  It is also useful for <strong>implementing custom drivers</strong> for accessing data sources - these are queues, for example, Kafka, Cassandra. <br><br><blockquote>  PHP is a great language for writing business logic. </blockquote><br>  This is a good system for HTML rendering, ORM and working with the database. <br><br><h2>  Tool comparison </h2><br>  Several months ago <a href="https://habr.com/ru/post/431818/">on Habr√© compared</a> PHP-FPM, PHP-PM, React-PHP, Roadrunner and other tools.  The benchmark was held on a project with real Symfony 4. <br><br>  RoadRunner under load shows good results and is ahead of all servers.  Compared with PHP-FPM, the performance is 6-8 times more. <br><img src="https://habrastorage.org/webt/ny/tx/yl/nytxylmddyrmglxjoe8hos7tnka.jpeg"><br><br>  In the same benchmark, RoadRunner did not lose a single request, everything was worked out 100%.  Unfortunately, React-PHP lost 8-9 requests under loads - this is unacceptable.  We would like the server not to crash and to work stably. <br><img src="https://habrastorage.org/webt/7b/fl/gq/7bflgqhrq1f-y0jixnud_k1ckdg.jpeg"><br><br>  Since the publication of RoadRunner in the public domain on GitHub, we have received more than 30,000 installations.  The community has helped us write a specific set of extensions, improvements and believe that the solution has the right to life. <br><br>  RoadRunner is good if you want to <strong>significantly speed up the application, but are not yet ready to jump into asynchronous PHP</strong> .  This is a compromise that will require a certain amount of effort, but not as significant as a complete rewrite of the code base. <br><br>  <a href="https://github.com/spiral/roadrunner">Take RoadRunner</a> if you want <strong>more control over the PHP life cycle</strong> , <strong>if there aren‚Äôt enough PHP capabilities,</strong> for example, for the queue system or Kafka, and when your popular Golang library solves your problem, which doesn't exist in PHP, and writing takes time, which you don‚Äôt have either. <br><br><h2>  Summary </h2><br>  What we got by writing this server and using it in our production infrastructure. <br><br><ul><li>  <strong>They increased the reaction speed of application points by 4 times</strong> compared to PHP-FPM. </li><li>  <strong>Completely got rid of 502 errors under loads</strong> .  At peak loads, the server just waits a little longer and responds as if there were no loads. </li><li>  After optimizing memory leaks, workers <strong>hang in memory for up to 2 months</strong> .  This helps when writing distributed applications, since all requests between services are already cached at the socket level. </li><li>  <strong>We use Keep-Alive.</strong>  This significantly speeds up communication between a distributed system. </li><li>  Inside the real infrastructure, <strong>we put everything in the Alpine Docker in Kubernetes</strong> .  The deployment system and project builds are now easier.  All that is required is to build a custom RoadRunner build for the project, put it in the Docker project, fill in the Docker image, and then calmly upload our pod to Kubernetes. </li><li>  According to the actual timing of one of the projects to individual points that do not have access to the database, the <strong>average response time is 0.33 ms</strong> . </li></ul><br><blockquote>  The next professional conference for PHP developers <a href="https://phprussia.ru/">PHP Russia</a> only next year.  For now, we offer the following: <br><br><ul><li>  <a href="https://golangconf.ru/2019">Pay</a> attention to <a href="https://golangconf.ru/2019">GolangConf</a> if you are interested in the Go part and want to know more details or hear arguments in favor of switching to this language.  If you yourself are ready to share your experience - most likely <a href="https://conf.ontico.ru/lectures/propose%3Fconference%3Dgc2019">send abstracts</a> . </li><li>  Take part in <a href="https://www.highload.ru/moscow/2019">HighLoad ++</a> in Moscow, if everything is important for you that is associated with high performance, submit a report by September 7, or book a ticket. </li><li>  Subscribe to the <a href="http://eepurl.com/VYVaf">newsletter</a> and the <a href="https://t.me/PHPRussiaConfChannel">telegram channel</a> in order to receive an invitation to PHP Russia 2020 earlier than others. </li></ul></blockquote></div><p>Source: <a href="https://habr.com/ru/post/461827/">https://habr.com/ru/post/461827/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../461807/index.html">How pod priorities at Kubernetes caused downtime at Grafana Labs</a></li>
<li><a href="../461815/index.html">A revolution in the design of computer power supplies half a century ago</a></li>
<li><a href="../461817/index.html">CMake and C ++ - brothers forever</a></li>
<li><a href="../461819/index.html">Why simple website design is better scientifically</a></li>
<li><a href="../461823/index.html">Enhanced Four Rules for Software Design</a></li>
<li><a href="../46183/index.html">Domain .tel: Internet Phone Directory</a></li>
<li><a href="../461831/index.html">StealthWatch: Deployment and Customization. Part 2</a></li>
<li><a href="../461833/index.html">Do not get lost in three pines: an egocentric representation of the environment</a></li>
<li><a href="../461837/index.html">Deploying your MTProxy Telegram with statistics</a></li>
<li><a href="../461845/index.html">Investments on the stock exchange as a way to preserve finances: 3 working methods</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>