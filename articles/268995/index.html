<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>FlexPod DataCenter: Direct-Attached Storage</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="In a previous article, I talked about a ‚Äúnon-FlexPod DC‚Äù architecture that can be supported from a single source by using the Cisco Solution Support f...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>FlexPod DataCenter: Direct-Attached Storage</h1><div class="post__text post__text-html js-mediator-article">  In a previous article, I talked about a <a href="http://habrahabr.ru/post/244623/">‚Äúnon-FlexPod DC‚Äù architecture</a> that can be supported from a single source by using the Cisco Solution Support for Critical Infrastructure (SSCI) program.  Its main feature is that it does not have Nexus series switches, and if you add them there, such an architecture can become a full-fledged FlexPod DataCenter. <br><br>  Here we will talk about the new network design for FlexPod DataCenter, with the direct inclusion of NetApp <abbr title="Storage System">storage</abbr> systems in the <abbr title="Unified Computing System">UCS</abbr> domain.  The difference from the <a href="http://habrahabr.ru/company/netapp/blog/181744/">standard FlexPod DataCenter architecture</a> is that the Nexus switches are not located between <abbr title="Unified Computing System">UCS</abbr> and NetApp, but ‚Äúon top of‚Äù UCS. <br><a name="habracut"></a><br><br>  Despite the fact that before NetApp <abbr title="Fabric attached storage">FAS</abbr> series <abbr title="Storage System">storage</abbr> systems could be connected directly to Fabric Interconnect (FI), the FlexPod DataCenter architecture did not officially presuppose such a design.  Now the direct-on design is supported and sorted, like the FlexPod DataCenter architecture. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/files/44a/00f/0a3/44a00f0a39404bee989a5c4ab4fa7f05.png"><br><br>  The overall design of the network <abbr title="Fiber channel">FC</abbr> and <abbr title="Fiber channel over ethernet">FCoE</abbr> with direct inclusion. <br><div class="spoiler">  <b class="spoiler_title">Description of the switching circuit in the image above</b> <div class="spoiler_text">  Simultaneous connection via <abbr title="Fiber channel">FC</abbr> and <abbr title="Fiber channel over ethernet">FCoE is</abbr> depicted for two reasons: <br><ol><li>  So really you can do it and it will work. </li><li>  To show that you can <abbr title="Fiber channel">FC</abbr> and / or <abbr title="Fiber channel over ethernet">FCoE</abbr> . </li></ol><br>  The Ethernet connection between two NetApp <abbr title="Fabric attached storage">FAS</abbr> controllers is depicted for two reasons: <br><ol><li>  To show that these are two nodes of the same ON system (if the node is larger, the picture would necessarily have cluster switches). </li><li>  External cluster link is a required accessory of the Clustered DataONTAP operating system. </li></ol><br>  <abbr title="Fiber channel">FC</abbr> link from <abbr title="Fabric interconnect">FI</abbr> to Nexus switch is depicted for two reasons: <br><ol><li>  For the future.  When we need to switch NetApp to Nexus switches and <abbr title="Fabric interconnect">FI</abbr> get access to their LUNs.  After that, the scheme will become more scalable, you can add more <abbr title="Unified Computing System">UCS</abbr> domains. </li><li>  In order to take resources from storage from other servers that are not included in the <abbr title="Unified Computing System">UCS</abbr> domain.  For example, <abbr title="Unified Computing System">UCS</abbr> Rack servers ( <abbr title="Unified Computing System">UCS</abbr> C series) not connected to <abbr title="Fabric interconnect">FI</abbr> or servers from other manufacturers. </li></ol><br></div></div><br><br>  For Ethernet traffic in conjunction with both direct inclusion and <abbr title="iSCSI">iSCSI</abbr> protocol, as well as direct inclusion and <abbr title="Fiber channel protocol">FCP</abbr> protocol - with the help of multipassing built into these protocols, there is no problem in configuring fault tolerance and link balancing. <br>  But for <a href="https://community.brocade.com/dtscp75322/attachments/dtscp75322/fibre/21648/2/UCS%2520Connectivity%2520Best%2520Practice.pdf">NAS with direct-on protocols</a> ( <abbr title="Network file system">NFS</abbr> v2 / <abbr title="Network file system">NFS</abbr> v3 and <abbr title="Common Internet File System">CIFS</abbr> v1 / <abbr title="Common Internet File System">CIFS</abbr> v2), due to the lack of load balancing and multi-paging within these protocols, some other underlying protocols such as <abbr title="Link Aggregation Control Protocol">LACP</abbr> and <abbr title="Cisco virtual Port Channel">vPC</abbr> ( <abbr title="Fabric interconnect">FI</abbr> does not support <abbr title="Cisco virtual Port Channel">vPC</abbr> ), so the fault tolerance for an Ethernet network will have to be built somehow differently.  For example, fault tolerance for Ethernet can be done at the level of a virtual switch (which may have performance problems with such a switch) or by using <i>active-passive</i> switching of an aggregated network link, without <abbr title="Link Aggregation Control Protocol">LACP</abbr> (which will not allow balancing traffic across all available links), for this purpose an aggregated link <i>ifgrp</i> , from the <abbr title="Storage System">storage</abbr> side, must be configured in <i>single-mode</i> . <br>  The issue of direct-on for <abbr title="Network-attached storage">NAS</abbr> protocols is not so hot for <abbr title="Network file system">NFS</abbr> v4 and <abbr title="Common Internet File System">CIFS</abbr> v3.0, but requires support for these protocols on the client side and <abbr title="Storage System">storage</abbr> (all <abbr title="Fabric attached storage">FAS</abbr> systems with <abbr title="Clustered Data ONTAP">cDOT</abbr> support <abbr title="Network file system">NFS</abbr> v4 and <abbr title="Common Internet File System">CIFS</abbr> v3.0), since both protocols Finally, some kind of multipassing has been achieved. <br><div class="spoiler">  <b class="spoiler_title">configure FCoE and CIFS / NFS traffic over a single link</b> <div class="spoiler_text"><ul><li>  First, you need the Cisco <abbr title="Unified Computing System">UCS</abbr> firmware version 2.1 or higher. </li><li>  Secondly, you need storage with 10GB <abbr title="Converged Network Adapter">CNA</abbr> / <abbr title="Unified Target Adapter">UTA</abbr> ports </li></ul><br>  Next, go to the settings: <br>  From the NetApp storage side, you need to switch the ports to the <abbr title="Converged Network Adapter">CNA</abbr> state (you need to have <abbr title="Converged Network Adapter">CNA</abbr> ports, regular Ethernet 1 / 10Gbs ports do not support this), using the <i>ucadmin command</i> on the <abbr title="Storage System">storage system</abbr> (you will need to restart the <abbr title="Storage System">storage system</abbr> ).  The system will display independently ‚Äúvirtual‚Äù Ethernet ports and ‚Äúvirtual‚Äù <abbr title="Fiber channel">FC</abbr> ports, separately (although the physical port will be used for one such ‚Äúvirtual‚Äù Ethernet and one ‚Äúvirtual‚Äù <abbr title="Fiber channel">FC</abbr> ).  These ports are configured separately, like normal physical ports. <br><br>  On <abbr title="Fabric interconnect">FI,</abbr> you need to enable the <abbr title="Fiber channel">FC</abbr> mode in the ‚ÄúSwitching mode‚Äù state, in the Fabric A / B settings on the ‚ÄúEquipment‚Äù tab.  This setting will require a restart of <abbr title="Fabric interconnect">FI</abbr> . <br><br>  If you want to transfer some ports to FC mode, in the Fabric A / B settings on the Equipment tab, select ‚ÄúConfigure Unified Ports‚Äù and select the required number of FC ports in the wizard (they are selected on the right).  FI reboot again. <br><br>  After rebooting the <abbr title="Fabric interconnect">FI</abbr> on the ‚ÄúEquipment‚Äù tab, convergent or FC ports will need to be transferred to the ‚ÄúAppliance port‚Äù mode, after a few seconds the port will go online.  Then reconfigure the port in the ‚ÄúFCoE Storage Port‚Äù mode or in the ‚ÄúFC Storage Port‚Äù mode, in the right pane you will see the port type ‚Äú <a href="http://www.cisco.com/c/en/us/td/docs/unified_computing/ucs/sw/gui/config/guide/2-1/b_UCSM_GUI_Configuration_Guide_2_1/b_UCSM_GUI_Configuration_Guide_2_1_chapter_0110.html">Unified Storage</a> ‚Äù.  Now it will be possible to choose <abbr title="Cisco Virtual Storage Area Networks">VSAN</abbr> and <abbr title="Virtual Local Area Networks">VLAN</abbr> for such a port.  And an important point, created earlier by <abbr title="Cisco Virtual Storage Area Networks">VSAN</abbr> , must have included ‚ÄúFC zoning‚Äù on <abbr title="Fabric interconnect">FI in</abbr> order to perform zoning. <br><br>  Setting zoning for FI: <br>  SAN-&gt; Storage Cloud-&gt; Fabric X-&gt; VSANs-&gt; Create "NetApp-VSAN-600" -&gt; <br>  VSAN ID: 600 <br>  FCoE VLAN ID: 3402 <br>  FC Zonning Settings: FC Zonning -&gt; Enabled <br><br>  SAN-&gt; Policies-&gt; vHBA Templates-&gt; Create "vHBA-T1" -&gt; VSAN "NetApp-VSAN-600" <br><br>  SAN-&gt; Policies-&gt; Storage Connection Policies-&gt; Create ‚ÄúMy-NetApp-Conn‚Äù -&gt; Zoning Type-&gt; Sist (or Simt if needed) -&gt; Create-&gt; <br>  FC Target Endpoint: "NetApp LIF's WWPN" (starts at 20 :) <br><br>  SAN-&gt; Policies-&gt; SAN Connectivity Policies-&gt; Create "NetApp-Conn-Pol1" -&gt; vHBA Initiator Group-&gt; <br>  Create "iGroup1" -&gt; Select vHBA Initiators "vHBA-T1" <br>  Select Storage Connectivity Policy: "My-NetApp-Conn" <br><br>  When creating a Server Profile, use the created policies and vHBA template. <br></div></div><br><br><h4>  Why was there no live feed in FlexPod DataCenter before? </h4><br>  The fact is that NetApp in its new solutions often adheres to the ideology ‚Äúit is better to outbid than undercook‚Äù.  So, when I went to the world of Clustered ONTAP for <abbr title="Fabric attached storage">FAS</abbr> <abbr title="Storage System">storage systems</abbr> , it was imperative for the cluster interconnect to <a href="http://blog.aboutnetapp.ru/archives/1118">have dedicated Nexus 5k switches (for $ 1)</a> exclusively for this task.  Over time, this configuration was revised, tested and added the ability to <i>switch-less</i> configurations.  Likewise, it took time to test and debug direct storage, first added new Cisco <abbr title="Unified Computing System">UCS</abbr> Manager based FC zoning topologies with direct connect (direct connect topologies) <abbr title="Storage System">storage</abbr> in the <abbr title="Unified Computing System">UCS</abbr> domain, it became available with firmware version <a href="http://www.cisco.com/c/en/us/td/docs/unified_computing/ucs/release/notes/UCS_28313.html">Release 2.1</a> (1a), and then This appeared in the FlexPod architecture. <br><br><h4>  Why do you need Nexus switches? </h4><a name="why_do_we_need_nexuses"></a><br>  The configuration with the direct inclusion of <abbr title="Storage System">storage</abbr> in <abbr title="Fabric interconnect">FI</abbr> , in terms of architectural differences, in the case of using block protocols for <abbr title="Fiber channel">FC</abbr> / <abbr title="Fiber channel over ethernet">FCoE</abbr> / <abbr title="iSCSI">iSCSI</abbr> access, is the least different from the original design of the FlexPod, where Nexus switches played the role of a link between the storage and the <abbr title="Unified Computing System">UCS</abbr> domain.  However, in the new design, the <i>Nexus</i> series <i>switches are still a mandatory</i> component of the architecture: <br><ul><li>  firstly, because FlexPod must somehow be integrated into the existing infrastructure and provide access to clients </li><li>  secondly, live streaming will keep architecture scalability in the future </li><li>  thirdly, in contrast to the direct connection with the <abbr title="Storage Area Network">SAN</abbr> ( <abbr title="Fiber channel">FC</abbr> / <abbr title="Fiber channel over ethernet">FCoE</abbr> / <abbr title="iSCSI">iSCSI</abbr> ), the Ethernet network design for the <abbr title="Network-attached storage">NAS</abbr> requires an intermediate link between the <abbr title="Storage System">storage system</abbr> and the <abbr title="Unified Computing System">UCS</abbr> domain to perform load balancing on the network links, and mainly fault tolerance functions. </li><li>  Fourthly, external client access via Ethernet to the FlexPod must be fault tolerant. </li></ul><br><br><h4>  <a href="https://habr.com/ru/post/268995/">Availability of switches for NAS</a> </h4><a name="Nexus_for_NAS"></a><br>  The difference between <abbr title="Storage Area Network">SAN</abbr> and <abbr title="Network-attached storage">NAS</abbr> designs is that in the case of block protocols, the mechanisms of multipassing and balancing are performed at the <abbr title="Fiber channel">FC</abbr> / <abbr title="Fiber channel over ethernet">FCoE</abbr> / <abbr title="iSCSI">iSCSI</abbr> protocol level, and in the case of using <abbr title="Network file system">NFS</abbr> / <abbr title="Common Internet File System">CIFS</abbr> ( <abbr title="Server message block">SMB</abbr> ) protocols, these mechanisms are absent.  Multipassing and balancing functions must be performed at the Ethernet level using <abbr title="Cisco virtual Port Channel">vPC</abbr> and <abbr title="Link Aggregation Control Protocol">LACP</abbr> , i.e.  by means of the switch, which I determine as the determining factor of its presence in such designs. <br><br><h4>  <a href="https://habr.com/ru/post/268995/">How to reduce costs in the first stage</a> </h4><a name="lower_price"></a><br>  Despite the fact that Nexus switches are an essential component of the FlexPod DataCenter architecture, a direct connection reduces the cost of such a solution at the first stage of commissioning the complex, i.e.  will not buy Nexus switches at the beginning.  In other words, you can first <a href="http://habrahabr.ru/post/244623/">assemble non-FlexPod DC</a> .  And then buy the switches after a while, spreading budget expenses into a thinner layer and getting a more scalable FlexPod DataCenter architecture, when this is necessary. <br><br>  Subsequently, the network design can be transformed into a more scalable one, and due to the duplication of components this can be done without stopping the complex. <br><br><img src="https://habrastorage.org/files/855/368/b47/855368b4751d43dc8621d0cea38462a1.png"><br><br>  The limitation of the network design presented in Fig.2 is <i>2 links from one storage controller to the switches, when <abbr title="Fiber channel over ethernet">FCoE</abbr> and Ethernet traffic go through them <u>simultaneously</u></i> .  If you need to increase the number of links from the storage system, you will have to separate the <abbr title="Fiber channel protocol">FCP</abbr> and Ethernet traffic by separate, dedicated ports and links. <br><br>  <a href="http://habrahabr.ru/post/272511/">Benefits of FlexPod</a> configurations. <br><br><h4>  <a href="https://habr.com/ru/post/268995/">New configurations and designs</a> </h4><a name="Novelty"></a><br>  New documents on the implementation of the <abbr title="Data processing center">data center</abbr> architecture were released: FlexPod Express, Select and DataCenter with Clustered Data ONTAP (cDOT): <br><ul><li>  Nexus 6000/9000: <a href="http://www.cisco.com/en/US/docs/unified_computing/ucs/UCS_CVDs/flexpod_esxi51_nk6_design.pdf">FlexPod Datacenter with VMware vSphere 5.1U1 and Cisco Nexus 6000 Series Switch Design Guide</a> , <a href="http://www.cisco.com/c/dam/en/us/td/docs/unified_computing/ucs/UCS_CVDs/flexpod_esxi55u1_n9k_design.pdf">FlexPod Datacenter with VMware vSphere 5.5 and Cisco Nexus 9000 Series Switches</a> </li><li>  MetroCluster on <abbr title="Clustered Data ONTAP">cDOT</abbr> (MCC): <a href="http://www.netapp.com/us/media/tr-4396.pdf">MetroCluster in Clustered Data ONTAP 8.3 Verification Tests Using Oracle Workloads</a> </li><li>  All-Flash FAS (AFF): <a href="http://www.netapp.com/us/system/pdf-reader.aspx%3Fcc%3Dus%26m%3DNVA-1110-FP-DESIGN.pdf%26pdfUri%3Dtcm:10-129510">FlexPod Datacenter with NetApp All-Flash FAS and VMware Horizon (with View)</a> , <a href="http://www.netapp.com/us/system/pdf-reader.aspx%3Fcc%3Dus%26m%3DNVA-0011-DESIGN.pdf%26pdfUri%3Dtcm:10-127129">FlexPod Datacenter with VMware vSphere 5.5 Update and All-Flash FAS</a> . </li><li>  FlexPod Express: <a href="http://www.netapp.com/us/media/tr-4331.pdf">FlexPod Express with VMware vSphere 5.5: Large Configuration</a> , <a href="http://www.netapp.com/us/media/tr-4328.pdf">FlexPod Express with VMware vSphere 5.5 Update 1: Small and Medium configs Implementation Guide</a> . </li><li>  Cisco Security: <a href="http://www.cisco.com/c/dam/en/us/td/docs/unified_computing/ucs/UCS_CVDs/flexpod_sea.pdf">FlexPod Datacenter with Cisco Secure Enclaves</a> </li><li>  Cisco <abbr title="Application Centric Infrastructure">ACI</abbr> : <a href="http://www.cisco.com/c/dam/en/us/td/docs/unified_computing/ucs/UCS_CVDs/sharepoint2013_aci_flexpod_vmware.pdf">FlexPod Data Center with Microsoft SharePoint 2013 and Cisco Application Centric Infrastructure (ACI) Design Guide</a> , <a href="http://www.cisco.com/c/dam/en/us/td/docs/unified_computing/ucs/UCS_CVDs/flexpod_esxi51u1_n9k_aci_design.pdf">FlexPod Datacenter with VMware vSphere 5.1 U1 and Cisco ACI Design Guide</a> , <a href="http://www.netapp.com/ru/communities/tech-ontap/1411-tot-flexpod.aspx%3FREF_SOURCE%3DEMMtot-1411%26h">FlexPod and Cisco ACI - the perfect combination</a> </li><li>  FlexPod Select: <a href="http://www.netapp.com/us/system/pdf-reader.aspx%3Fcc%3Dus%26m%3Dnva-0012-design.pdf%26pdfUri%3Dtcm:10-129761">Oracle RAC NVA Design FlexPod Select for High-Performance</a> </li><li>  <a href="http://www.veeam.com/wp-flexpod-install-operations-guide.html">FlexPod + Veeam Install Guide: How the Veeam Provides for Cisco and NetApp Converged Infrastructures</a> </li></ul><br><br>  <b>I ask to send messages on errors in the text to the <abbr title="Private message">LAN</abbr> .</b> <br>  <b>Notes and additions on the contrary I ask in the comments.</b> </div><p>Source: <a href="https://habr.com/ru/post/268995/">https://habr.com/ru/post/268995/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../268983/index.html">How to calculate everything in the world by a single SQL query. PostgreSQL window functions</a></li>
<li><a href="../268987/index.html">Accelerate Android code</a></li>
<li><a href="../268989/index.html">Objects of zero size</a></li>
<li><a href="../268991/index.html">Pagination of lists in Android with RxJava. Part I</a></li>
<li><a href="../268993/index.html">Remote execution of system commands on request via sockets in Python 3 or how I downloaded the sites</a></li>
<li><a href="../268997/index.html">Frida-node or a little bit strange code</a></li>
<li><a href="../268999/index.html">How did Cisco Security Ninja teach 20,000 employees to secure programming?</a></li>
<li><a href="../269001/index.html">The digest of interesting materials for the mobile # 125 developer (October 12-18)</a></li>
<li><a href="../269003/index.html">Script shipping management online store</a></li>
<li><a href="../269007/index.html">Virtual quadrocopter on Unity + OpenCV (Part 2)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>