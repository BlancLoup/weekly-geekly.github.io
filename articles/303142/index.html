<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>OpenGL ES 2.0. One million particles</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="In this article we will look at one of the options for implementing the particle system on OpenGL ES 2.0. Let's talk in detail about the limitations, ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>OpenGL ES 2.0. One million particles</h1><div class="post__text post__text-html js-mediator-article">  In this article we will look at one of the options for implementing the particle system on OpenGL ES 2.0.  Let's talk in detail about the limitations, we will describe the principles and analyze a small example. <br><br><img src="https://habrastorage.org/files/9a6/2ba/b61/9a62bab61366428782e83834b9f22106.jpg" alt="image"><br><a name="habracut"></a><br><h2>  Restrictions </h2><br><br>  In general, we will require two additional properties from OpenGL ES 2.0 (the specification does not require their presence): <br><ul><li>  <strong>Vertex Texture Fetch</strong> .  Allows us to access texture maps via texture units from the <em>vertex</em> shader.  You can request the maximum number of units supported by the graphics processor using the <a href="http://docs.gl/es2/glGet">glGetIntegerv</a> function with the parameter name GL_MAX_VERTEX_TEXTURE_IMAGE_UNITS.  The table below presents data on the currently popular processors. </li><li>  <strong>Fragment high floating-point precision</strong> .  Allows us to perform calculations with high accuracy in a <em>fragment</em> shader.  You can request the accuracy and range of values ‚Äã‚Äãusing the <a href="http://docs.gl/es2/glGetShaderPrecisionFormat">glGetShaderPrecisionFormat</a> function with the GL_FRAGMENT_SHADER and GL_HIGH_FLOAT parameter names for the shader type and data type, respectively.  For all the processors listed in the table, the accuracy is 23 bits with a range of values ‚Äã‚Äãfrom -2 ^ 127 to 2 ^ 127, with the exception of <em>Snapdragon Andreno 2xx</em> , for this series the range is from -2 ^ 62 to 2 ^ 62. </li></ul>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Processor Information: <br><table><thead><tr><th>  CPU </th><th>  Vertex TIU </th><th>  Accuracy </th><th>  Range </th></tr></thead><tbody><tr><td>  Snapdragon Adreno 2xx </td><td>  four </td><td>  23 </td><td>  [-2 ^ 62, 2 ^ 62] </td></tr><tr><td>  Snapdragon Adreno 3xx </td><td>  sixteen </td><td>  23 </td><td>  [-2 ^ 127, 2 ^ 127] </td></tr><tr><td>  Snapdragon Adreno 4xx </td><td>  sixteen </td><td>  23 </td><td>  [-2 ^ 127, 2 ^ 127] </td></tr><tr><td>  Snapdragon Adreno 5xx </td><td>  sixteen </td><td>  23 </td><td>  [-2 ^ 127, 2 ^ 127] </td></tr><tr><td>  Intel HD Graphics </td><td>  sixteen </td><td>  23 </td><td>  [-2 ^ 127, 2 ^ 127] </td></tr><tr><td>  ARM Mali-T6xx </td><td>  sixteen </td><td>  23 </td><td>  [-2 ^ 127, 2 ^ 127] </td></tr><tr><td>  ARM Mali-T7xx </td><td>  sixteen </td><td>  23 </td><td>  [-2 ^ 127, 2 ^ 127] </td></tr><tr><td>  ARM Mali-T8xx </td><td>  sixteen </td><td>  23 </td><td>  [-2 ^ 127, 2 ^ 127] </td></tr><tr><td>  NVIDIA Tegra 2/3/4 </td><td>  0 </td><td>  0 </td><td>  0 </td></tr><tr><td>  NVIDIA Tegra K1 / X1 </td><td>  32 </td><td>  23 </td><td>  [-2 ^ 127, 2 ^ 127] </td></tr><tr><td>  PowerVR SGX (Series5) </td><td>  eight </td><td>  23 </td><td>  [-2 ^ 127, 2 ^ 127] </td></tr><tr><td>  PowerVR SGX (Series5XT) </td><td>  eight </td><td>  23 </td><td>  [-2 ^ 127, 2 ^ 127] </td></tr><tr><td>  PowerVR Rogue (Series6) </td><td>  sixteen </td><td>  23 </td><td>  [-2 ^ 127, 2 ^ 127] </td></tr><tr><td>  PowerVR Rogue (Series6XT) </td><td>  sixteen </td><td>  23 </td><td>  [-2 ^ 127, 2 ^ 127] </td></tr><tr><td>  VideoCore IV </td><td>  eight </td><td>  23 </td><td>  [-2 ^ 127, 2 ^ 127] </td></tr><tr><td>  Vivante GC1000 </td><td>  four </td><td>  23 </td><td>  [-2 ^ 127, 2 ^ 127] </td></tr><tr><td>  Vivante GC4000 </td><td>  sixteen </td><td>  23 </td><td>  [-2 ^ 127, 2 ^ 127] </td></tr></tbody></table><br><br>  There is a problem with <em>NVIDIA Tegra 2/3/4</em> , a number of popular devices such as the <em>Nexus 7, HTC One X, ASUS Transformer</em> work on this series. <br><h2>  Particle system </h2><br><br>  Considering the systems of particles generated on the CPU, in the context of increasing the amount of data being processed (the number of particles), the main performance problem is copying (uploading) data from the RAM to the video memory on each frame.  Therefore, our main task is to avoid this copying, transferring the calculations to the non-operational mode on the graphics processor. <br><blockquote>  Recall that in OpenGL ES 2.0 there are no built-in mechanisms such as <a href="https://www.opengl.org/wiki/Transform_Feedback">Transform Feedback</a> (available in OpenGL ES 3.0) or <a href="https://www.opengl.org/wiki/Compute_Shader">Compute Shader</a> (available in OpenGL ES 3.1), allowing you to perform calculations on the GPU. </blockquote><br><br>  The essence of the method is to use as a buffer data for storage, characterizing a particle, values ‚Äã‚Äã(coordinates, accelerations, etc.) - <em>textures</em> and process them with vertex and fragment shaders.  Also, as we store and load the normals, talking about the <a href="https://en.wikipedia.org/wiki/Normal_mapping">Normal mapping</a> .  The size of the buffer, in our case, is proportional to the number of particles to be processed.  Each texel stores a separate value (quantities, if there are several) for an individual particle.  Accordingly, the number of processed quantities is inversely related to the number of particles.  For example, in order to process positions and accelerations for 1048576 particles, we need two textures of 1024x1024 (if there is no need to preserve the aspect ratio) <br><br>  There are additional restrictions that we need to take into account.  To be able to record any information, the format of the pixel texture data must be supported by the implementation as a <em>color-renderable format</em> .  This means that we can use the texture as a color buffer in the frame <a href="https://www.opengl.org/wiki/Framebuffer_Object">-by-</a> frame <a href="https://www.opengl.org/wiki/Framebuffer_Object">rendering</a> .  The specification describes only three such formats: <em>GL_RGBA4, GL_RGB5_A1, GL_RGB565</em> .  Considering the subject area, we need at least 32 bits per pixel to process values ‚Äã‚Äãsuch as coordinates or accelerations (for the two-dimensional case).  Therefore, the formats mentioned above are not enough for us. <br><br>  To ensure the necessary minimum, we consider two additional types of textures: <em>GL_RGBA8</em> and <em>GL_RGBA16F</em> .  Such textures are often called <em>LDR (SDR)</em> and <em>HDR textures,</em> respectively. <br><ul><li>  <em>GL_RGBA8 is</em> supported by the specification, we can load and read textures with this format.  For recording, we need to require the extension <a href="https://www.khronos.org/registry/gles/extensions/OES/OES_rgb8_rgba8.txt">OES_rgb8_rgba8</a> . <br></li><li>  <em>GL_RGBA16F is</em> not supported by the specification, in order to load and read textures with this format, we need the extension <a href="https://www.khronos.org/registry/gles/extensions/OES/OES_texture_float.txt">GL_OES_texture_half_float</a> .  Moreover, in order to obtain an acceptable quality result, we need the support of linear filters for minification and magnification of such textures.  The extension <a href="https://www.khronos.org/registry/gles/extensions/OES/OES_texture_float_linear.txt">GL_OES_texture_half_float_linear</a> is responsible for <a href="https://www.khronos.org/registry/gles/extensions/OES/OES_texture_float_linear.txt">this</a> .  For recording, we need the extension <a href="https://www.khronos.org/registry/gles/extensions/EXT/EXT_color_buffer_half_float.txt">GL_EXT_color_buffer_half_float</a> . </li></ul><br><br>  According to <a href="http://opengles.gpuinfo.org/gles_extensions.php">GPUINFO</a> for 2013 - 2015, support for extensions is as follows: <br><table><thead><tr><th>  Expansion </th><th>  Devices (%) </th></tr></thead><tbody><tr><td>  OES_rgb8_rgba8 </td><td>  98.69% </td></tr><tr><td>  GL_OES_texture_half_float </td><td>  61.5% </td></tr><tr><td>  GL_OES_texture_half_float_linear </td><td>  43.86% </td></tr><tr><td>  GL_EXT_color_buffer_half_float </td><td>  32.78% </td></tr></tbody></table><br><br>  Generally speaking, HDR textures are more suitable for our purposes.  First, they allow us to process more information without compromising performance, for example, to manipulate particles in three-dimensional space without increasing the number of buffers.  Secondly, there is no need for intermediate mechanisms for unpacking and packing data when reading and writing, respectively.  But, due to poor support for HDR textures, we will choose LDR. <br><br>  So, going back to the point, the general scheme of what we are going to do looks like this: <br><br><img src="https://habrastorage.org/files/7c5/6bb/aea/7c56bbaea8b84abea9251fac2aa89458.png" alt="image"><br><br>  The first thing we need is to split the calculations into passes.  The splitting depends on the number and type of characterizing values ‚Äã‚Äãthat we are going to work on.  Based on the fact that we have a texture as a data buffer and taking into account the limitations on the format of pixel data described above, each pass can process no more than 32 bits of information on each particle.  For example, on the first pass, we calculated the accelerations (32 bits, 16 bits per component), on the second, the positions were updated (32 bits, 16 bits per component). <br><br>  Each pass processes data in double buffering mode.  This provides access to the system state of the previous frame. <br><br>  The core of the aisle is the usual <a href="https://en.wikipedia.org/wiki/Texture_mapping">texture mapping</a> into two triangles, where our data buffers act as texture maps.  The general view of shaders is as follows: <br><pre><code class="hljs pgsql">//   <span class="hljs-keyword"><span class="hljs-keyword">attribute</span></span> vec2 a_vertex_xy; <span class="hljs-keyword"><span class="hljs-keyword">attribute</span></span> vec2 a_vertex_uv; <span class="hljs-type"><span class="hljs-type">varying</span></span> vec2 v_uv; <span class="hljs-type"><span class="hljs-type">void</span></span> main() { gl_Position = vec4(a_vertex_xy, <span class="hljs-number"><span class="hljs-number">0.0</span></span>, <span class="hljs-number"><span class="hljs-number">1.0</span></span>); v_uv = a_vertex_uv; }</code> </pre> <br><pre> <code class="hljs ruby">/<span class="hljs-regexp"><span class="hljs-regexp">/   precision highp float; varying vec2 v_uv; /</span></span><span class="hljs-regexp"><span class="hljs-regexp">/    /</span></span><span class="hljs-regexp"><span class="hljs-regexp">/ ( ) uniform sampler2D u_prev_state; /</span></span><span class="hljs-regexp"><span class="hljs-regexp">/     /</span></span><span class="hljs-regexp"><span class="hljs-regexp">/ ( ) uniform sampler2D u_pass_0; ... uniform sampler2D u_pass_n; /</span></span><span class="hljs-regexp"><span class="hljs-regexp">/   &lt;type&gt; unpack(vec4 raw); &lt;type_0&gt; unpack_0(vec4 raw); ... &lt;type_n&gt; unpack_1(vec4 raw) /</span></span><span class="hljs-regexp"><span class="hljs-regexp">/   vec4 pack(&lt;type&gt; data); void main() { /</span></span><span class="hljs-regexp"><span class="hljs-regexp">/      /</span></span><span class="hljs-regexp"><span class="hljs-regexp">/     v_uv &lt;type&gt; data = unpack(texture2D(u_prev_state, v_uv)); &lt;type_0&gt; data_pass_0 = unpack_0(texture2D(u_pass_0, v_uv)); ... &lt;type_n&gt; data_pass_n = unpack_n(texture2D(u_pass_n, v_uv)); /</span></span><span class="hljs-regexp"><span class="hljs-regexp">/   &lt;type&gt; result = ... /</span></span><span class="hljs-regexp"><span class="hljs-regexp">/     gl_FragColor = pack(result); }</span></span></code> </pre> <br><br>  The implementation of the unpacking / packing functions depends on the quantities that we process.  At this stage, we rely on the requirement, described at the beginning, of high precision calculations. <br>  For example, for two-dimensional coordinates (components [x, y] of 16 bits), the functions might look like this: <br><pre> <code class="hljs cs"><span class="hljs-function"><span class="hljs-function">vec4 </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">pack</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">vec2 </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">value</span></span></span></span></span><span class="hljs-function">)</span></span> { vec2 shift = vec2(<span class="hljs-number"><span class="hljs-number">255.0</span></span>, <span class="hljs-number"><span class="hljs-number">1.0</span></span>); vec2 mask = vec2(<span class="hljs-number"><span class="hljs-number">0.0</span></span>, <span class="hljs-number"><span class="hljs-number">1.0</span></span> / <span class="hljs-number"><span class="hljs-number">255.0</span></span>); vec4 result = fract(<span class="hljs-keyword"><span class="hljs-keyword">value</span></span>.xxyy * shift.xyxy); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> result - result.xxzz * mask.xyxy; } <span class="hljs-function"><span class="hljs-function">vec2 </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">unpack</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">vec4 </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">value</span></span></span></span></span><span class="hljs-function">)</span></span> { vec2 shift = vec2(<span class="hljs-number"><span class="hljs-number">1.0</span></span> / <span class="hljs-number"><span class="hljs-number">255.0</span></span>, <span class="hljs-number"><span class="hljs-number">1.0</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> vec2(dot(<span class="hljs-keyword"><span class="hljs-keyword">value</span></span>.xy, shift), dot(<span class="hljs-keyword"><span class="hljs-keyword">value</span></span>.zw, shift)); }</code> </pre> <br><h2>  Drawing </h2><br><br>  After the computation stage, the rendering phase follows.  To access the particles at this stage, we need, for sorting, some external index.  The vertex buffer ( <a href="https://en.wikipedia.org/wiki/Vertex_Buffer_Object">Vertex Buffer Object</a> ) with the texture coordinates of the data buffer will act as such an index.  The index is created and initialized (unloaded into the memory of the video device) once and does not change in the process. <br><br>  In this step, the requirement for access to texture maps takes effect.  The vertex shader is similar to the fragment shader from the calculation stage: <br><pre> <code class="hljs ruby">/<span class="hljs-regexp"><span class="hljs-regexp">/   /</span></span><span class="hljs-regexp"><span class="hljs-regexp">/   attribute vec2 a_data_uv; /</span></span><span class="hljs-regexp"><span class="hljs-regexp">/  ,   uniform sampler2D u_positions; /</span></span><span class="hljs-regexp"><span class="hljs-regexp">/   ( ) uniform sampler2D u_data_0; ... uniform sampler2D u_data_n; /</span></span><span class="hljs-regexp"><span class="hljs-regexp">/    vec2 unpack(vec4 data); /</span></span><span class="hljs-regexp"><span class="hljs-regexp">/     &lt;type_0&gt; unpack_0(vec4 data); ... &lt;type_n&gt; unpack_n(vec4 data); void main() { /</span></span><span class="hljs-regexp"><span class="hljs-regexp">/      vec2 position = unpack(texture2D(u_positions, a_data_uv)); gl_Position = vec4(position * 2.0 - 1.0, 0.0, 1.0); /</span></span><span class="hljs-regexp"><span class="hljs-regexp">/      &lt;type_0&gt; data_0 = unpack(texture2D(u_data_0, a_data_uv)); ... &lt;type_n&gt; data_n = unpack(texture2D(u_data_n, a_data_uv)); }</span></span></code> </pre> <br><h2>  Example </h2><br><br>  As a small example, we will try to generate a dynamic system of 1048576 particles, known as <a href="https://en.wikipedia.org/wiki/Attractor">Strange Attractor</a> . <br><br> <a href="https://www.youtube.com/watch%3Fv%3Dlx3xy8CakE0"><img src="https://raw.githubusercontent.com/PkXwmpgN/elements/master/screenshots/strange.jpeg" alt="Strange attractors"></a> <br><br>  Frame processing consists of several stages: <br><br><img src="https://habrastorage.org/files/3f5/a82/576/3f5a8257687e4cfaa3a8812662cdfdbf.png" alt="image"><br><h3>  Compute stack </h3><br><br>  At the computation stage, we will have only one independent pass, which is responsible for the positioning of the particles.  It is based on a simple formula: <br><pre> <code class="hljs lisp"> Xn+1 = sin(<span class="hljs-name"><span class="hljs-name">a</span></span> * Yn) - cos(b * Xn) Yn+1 = sin(<span class="hljs-name"><span class="hljs-name">c</span></span> * Xn) - cos(d * Yn)</code> </pre> <br><br>  Such a system is also called <a href="http://paulbourke.net/fractals/peterdejong/">Peter de Jong Attractors</a> .  Over time, we will change only the coefficients. <br><pre> <code class="hljs pgsql">//   <span class="hljs-keyword"><span class="hljs-keyword">attribute</span></span> vec2 a_vertex_xy; <span class="hljs-type"><span class="hljs-type">varying</span></span> vec2 v_uv; <span class="hljs-type"><span class="hljs-type">void</span></span> main() { gl_Position = vec4(a_vertex_xy, <span class="hljs-number"><span class="hljs-number">0.0</span></span>, <span class="hljs-number"><span class="hljs-number">1.0</span></span>); v_uv = a_vertex_xy * <span class="hljs-number"><span class="hljs-number">0.5</span></span> + <span class="hljs-number"><span class="hljs-number">0.5</span></span>; }</code> </pre> <br><pre> <code class="hljs pgsql">//   <span class="hljs-type"><span class="hljs-type">precision</span></span> highp <span class="hljs-type"><span class="hljs-type">float</span></span>; <span class="hljs-type"><span class="hljs-type">varying</span></span> vec2 v_uv; uniform lowp <span class="hljs-type"><span class="hljs-type">float</span></span> u_attractor_a; uniform lowp <span class="hljs-type"><span class="hljs-type">float</span></span> u_attractor_b; uniform lowp <span class="hljs-type"><span class="hljs-type">float</span></span> u_attractor_c; uniform lowp <span class="hljs-type"><span class="hljs-type">float</span></span> u_attractor_d; vec4 pack(vec2 <span class="hljs-keyword"><span class="hljs-keyword">value</span></span>) { vec2 shift = vec2(<span class="hljs-number"><span class="hljs-number">255.0</span></span>, <span class="hljs-number"><span class="hljs-number">1.0</span></span>); vec2 mask = vec2(<span class="hljs-number"><span class="hljs-number">0.0</span></span>, <span class="hljs-number"><span class="hljs-number">1.0</span></span> / <span class="hljs-number"><span class="hljs-number">255.0</span></span>); vec4 result = fract(<span class="hljs-keyword"><span class="hljs-keyword">value</span></span>.xxyy * shift.xyxy); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> result - result.xxzz * mask.xyxy; } <span class="hljs-type"><span class="hljs-type">void</span></span> main() { vec2 pos = v_uv * <span class="hljs-number"><span class="hljs-number">4.0</span></span> - <span class="hljs-number"><span class="hljs-number">2.0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span>(<span class="hljs-type"><span class="hljs-type">int</span></span> i = <span class="hljs-number"><span class="hljs-number">0</span></span>; i &lt; <span class="hljs-number"><span class="hljs-number">3</span></span>; ++i) { pos = vec2(sin(u_attractor_a * pos.y) - cos(u_attractor_b * pos.x), sin(u_attractor_c * pos.x) - cos(u_attractor_d * pos.y)); } pos = clamp(pos, vec2(<span class="hljs-number"><span class="hljs-number">-2.0</span></span>), vec2(<span class="hljs-number"><span class="hljs-number">2.0</span></span>)); gl_FragColor = pack(pos * <span class="hljs-number"><span class="hljs-number">0.25</span></span> + <span class="hljs-number"><span class="hljs-number">0.5</span></span>); }</code> </pre> <br><h3>  Renderer Stage </h3><br><br>  At the stage rendering stage, we will render our particles with ordinary sprites. <br><pre> <code class="hljs pgsql">//   //  <span class="hljs-keyword"><span class="hljs-keyword">attribute</span></span> vec2 a_positions_uv; //  (,    ) uniform sampler2D u_positions; <span class="hljs-type"><span class="hljs-type">varying</span></span> vec4 v_color; vec2 unpack(vec4 <span class="hljs-keyword"><span class="hljs-keyword">value</span></span>) { vec2 shift = vec2(<span class="hljs-number"><span class="hljs-number">0.00392156863</span></span>, <span class="hljs-number"><span class="hljs-number">1.0</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> vec2(dot(<span class="hljs-keyword"><span class="hljs-keyword">value</span></span>.xy, shift), dot(<span class="hljs-keyword"><span class="hljs-keyword">value</span></span>.zw, shift)); } <span class="hljs-type"><span class="hljs-type">void</span></span> main() { vec2 position = unpack(texture2D(u_positions, a_positions_uv)); gl_Position = vec4(position * <span class="hljs-number"><span class="hljs-number">2.0</span></span> - <span class="hljs-number"><span class="hljs-number">1.0</span></span>, <span class="hljs-number"><span class="hljs-number">0.0</span></span>, <span class="hljs-number"><span class="hljs-number">1.0</span></span>); v_color = vec4(<span class="hljs-number"><span class="hljs-number">0.8</span></span>); }</code> </pre> <br><pre> <code class="hljs pgsql">//   <span class="hljs-type"><span class="hljs-type">precision</span></span> lowp <span class="hljs-type"><span class="hljs-type">float</span></span>; <span class="hljs-type"><span class="hljs-type">varying</span></span> vec4 v_color; <span class="hljs-type"><span class="hljs-type">void</span></span> main() { gl_FragColor = v_color; }</code> </pre> <br><div class="spoiler">  <b class="spoiler_title">Result</b> <div class="spoiler_text"><img src="https://habrastorage.org/files/89d/20b/2b8/89d20b2b82014dfa8b03ddfb378ba2ac.jpeg" alt="image"><br></div></div><br><h3>  Postprocessing </h3><br><br>  Finally, at the <a href="https://en.wikibooks.org/wiki/OpenGL_Programming/Post-Processing">post-processing</a> stage, we will apply several effects. <br><br>  <strong>Gradient mapping</strong> .  Adds color content based on the brightness of the original image. <br><div class="spoiler">  <b class="spoiler_title">Result</b> <div class="spoiler_text"><img src="https://habrastorage.org/files/91e/3f8/dbe/91e3f8dbe0744991bc45f99be4a5917e.jpeg" alt="image"><br></div></div><br><br>  <strong>Bloom</strong> .  Adds a slight glow. <br><div class="spoiler">  <b class="spoiler_title">Result</b> <div class="spoiler_text"><img src="https://habrastorage.org/files/b0a/410/3a1/b0a4103a1f6149c1bb823bf1e2d94aa9.jpeg" alt="image"><br></div></div><br><h2>  Code </h2><br><br>  Project repository on <a href="https://github.com/PkXwmpgN/elements">GitHub</a> . <br>  Currently available: <br><ul><li>  Main code base (C ++ 11 / C ++ 14) along with shaders; </li><li>  Examples and demo versions of applications; <br><ul><li>  Liquid  Fluid simulation; </li><li>  Light Scattered.  Adaptation of the effect of scattered light; </li><li>  Strange Attractors.  The example described in the article; </li><li>  Wind field.  Implementing <a href="http://www.intpowertechcorp.com/GDC03.pdf">Navier-Stokes</a> with a large number of particles (2 ^ 20); </li><li>  Flame Simulation.  Flame simulation. </li></ul></li><li>  Client for Android. </li></ul><br><h2>  Continuation </h2><br><br>  In this example, we see that the computation stage, the stage rendering stage and the post-processing stage consist of several dependent passages. <br>  In the next part, we will try to consider the implementation of multi-pass rendering, taking into account the requirements imposed by each stage. <br><br>  I would be happy for comments and suggestions (you can mail yegorov.alex@gmail.com) <br>  Thank! <br></div><p>Source: <a href="https://habr.com/ru/post/303142/">https://habr.com/ru/post/303142/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../303130/index.html">PHP Digest number 87 - interesting news, materials and tools (May 29 - June 12, 2016)</a></li>
<li><a href="../303134/index.html">The value of multi-font design</a></li>
<li><a href="../303136/index.html">The digest of fresh materials from the world of the frontend for the last week No. 215 (June 6 - 12, 2016)</a></li>
<li><a href="../303138/index.html">What makes us go to work every morning?</a></li>
<li><a href="../303140/index.html">Matrix procrastination (postponing cases "for later")</a></li>
<li><a href="../303144/index.html">CD Changer Control Protocol</a></li>
<li><a href="../303146/index.html">NetApp SDS: ONTAP Select</a></li>
<li><a href="../303150/index.html">We automate the purchase of railway tickets Ukrzal—ñznits—ñ</a></li>
<li><a href="../303156/index.html">Delayed Durability or a story about how to speed up the execution of autotests from 11 to 2.5 minutes</a></li>
<li><a href="../303158/index.html">The digest of interesting materials for the mobile # 157 developer (June 6-13)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>