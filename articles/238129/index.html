<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Analysis of existing approaches to face recognition</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="With enviable regularity on Habr√© appear articles telling about those or other methods of facial recognition. We decided not just to support this wond...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Analysis of existing approaches to face recognition</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/files/3b8/b2f/69a/3b8b2f69aa234ca699d53318e580adb7.jpg" align="left">  With enviable regularity on Habr√© appear articles telling about those or other methods of facial recognition.  We decided not just to support this wonderful topic, but to lay out our internal document, which covers, if not all, but many approaches to face recognition, their strengths and weaknesses.  It was compiled by Andrei Gusak, our engineer, for young employees of the machine vision department, for educational, so to speak, purposes.  Today we offer it to everyone.  At the end of the article there is an impressive list of references for the most inquisitive. <a name="habracut"></a><br><br>  So, let's begin. <br>  Despite the large variety of algorithms presented, one can identify the general structure of the facial recognition process: <br><img src="https://habrastorage.org/files/987/110/5f4/9871105f432c457091a3b883512379a2.png"><br><br>  <i>The overall processing of facial image recognition</i> 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      At the first stage, the face is detected and localized in the image.  At the stage of recognition, the image of the face is aligned (geometric and brightness), the calculation of the signs and the recognition itself is the comparison of the calculated signs with the benchmarks embedded in the database.  The main difference of all the algorithms presented will be the calculation of signs and the comparison of their aggregates among themselves. <br><br><h5>  1. The method of flexible comparison on graphs (Elastic graph matching) [13]. </h5><br><br>  The essence of the method is reduced to the elastic juxtaposition of graphs describing images of faces.  Persons are represented as graphs with weighted vertices and edges.  At the recognition stage, one of the graphs - the reference one - remains unchanged, while the other is deformed in order to best fit the first one.  In such recognition systems, graphs can be either a rectangular grid or a structure formed by characteristic (anthropometric) points of a face. <br><br>  but) <img src="https://habrastorage.org/files/afe/bd2/804/afebd280435d4f7ba308d3b37dbb2623.png"><br><br>  b) <img src="https://habrastorage.org/files/bc4/c72/440/bc4c724406d34056994b26d78926e1eb.jpg"><br><br>  <i>An example of the structure of a graph for face recognition: a) a regular lattice b) a graph based on anthropometric points of the face.</i> <br><br>  At the vertices of the graph, the values ‚Äã‚Äãof attributes are calculated; most often, the complex values ‚Äã‚Äãof Gabor filters or their ordered sets ‚Äî Gabor wavelets (Gabor lines) are used, which are computed locally in some local vertex region of the graph by convolving the brightness values ‚Äã‚Äãof pixels with Gabor filters. <br><br><img src="https://habrastorage.org/files/4fd/5d1/826/4fd5d18265de4e2298c3847ef24724e8.png"><br>  <i>Set (bank, jet) filters Gabor</i> <br><br><img src="https://habrastorage.org/files/557/0ac/b02/5570acb0233d4310a44ce3e8c6263040.png"><br>  <i>An example of a convolution image of the face with two Gabor filters</i> <br><br>  The edges of the graph are weighted by the distances between adjacent vertices.  The difference (distance, discriminatory characteristic) between two graphs is calculated with the help of some price deformation function, which takes into account both the difference between the values ‚Äã‚Äãof features calculated at the vertices and the degree of deformation of the edges of the graph. <br>  A graph is deformed by displacing each of its vertices by a certain distance in certain directions relative to its original location and selecting its position such that the difference between the values ‚Äã‚Äãof attributes (responses of Gabor filters) at the top of the deformed graph and the corresponding top of the reference graph is minimal.  This operation is performed alternately for all the vertices of the graph until the smallest total difference between the signs of the deformable and reference graphs is reached.  The value of the price function of deformation in such a position of the deformable graph will be a measure of the difference between the input face image and the reference graph.  This ‚Äúrelaxation‚Äù deformation procedure should be carried out for all reference persons included in the database of the system.  The result of the system recognition is the standard with the best value of the price function of deformation. <br><br><img src="https://habrastorage.org/files/306/381/7e7/3063817e70834273add4ee5c99d93d8b.png"><br>  <i>Example of deformation of a graph in the form of a regular lattice</i> <br><br>  In individual publications, 95-97% recognition efficiency is indicated, even in the presence of various emotional expressions and a change in the angle of the face to 15 degrees.  However, the developers of elastic comparison systems on graphs refer to the high computational cost of this approach.  For example, to compare the input face image with the 87 reference ones, it took approximately 25 seconds when working on a parallel computer with 23 transputers [15] (Note: the publication is dated 1993).  In other publications on this topic, the time is either not indicated, or it is said that it is great. <br><br>  <b>Disadvantages:</b> high computational complexity of the recognition procedure.  Low manufacturability in memorizing new standards.  Linear dependence of work time on the size of the database of persons. <br><br><h5>  2. Neural networks </h5><br><br>  Currently, there are about a dozen varieties of neural networks (NA).  One of the most widely used options is a network built on a multi-layer perceptron, which allows you to classify the image / signal fed to the input according to the network pre-tuning / training. <br>  Neural networks are trained on a set of training examples.  The essence of learning is reduced to adjusting the weights of interneuronal connections in the process of solving an optimization problem using the gradient descent method.  In the process of learning NA, the key features are automatically extracted, their importance is determined, and the relationships between them are built.  It is assumed that a trained NA will be able to apply the experience gained in the learning process to unknown images at the expense of generalizing abilities. <br>  The best results in the field of face recognition (based on the analysis of publications) were shown by the Convolutional Neural Network or the convolutional neural network (hereinafter referred to as SNS) [29-31], which is a logical development of the ideas of NA architectures like the cognitron and the neocognitron.  Success is due to the possibility of taking into account the two-dimensional topology of the image, in contrast to the multilayer perceptron. <br>  Distinctive features of the SNA are local receptor fields (provide local two-dimensional connectivity of neurons), total weights (provide detection of some features anywhere in the image) and a hierarchical organization with spatial subsampling.  Thanks to these innovations, the SNA provides partial stability to scale changes, shifts, turns, angle changes and other distortions. <br><br><img src="https://habrastorage.org/files/822/993/03b/82299303b7904b84902483bc01da32f1.png"><br>  <i>Schematic representation of the convolutional neural network architecture</i> <br><br>  Testing of the SNA on an ORL database containing images of individuals with small changes in lighting, scale, spatial turns, position, and various emotions showed 96% recognition accuracy. <br>  The development of the SNA received in the development of DeepFace [47], which acquired <br>  Facebook to recognize the faces of users of their social networks.  All features of the architecture are closed. <br><br><img src="https://habrastorage.org/files/c3d/e98/bc9/c3de98bc9bc542e3bc1837fb420bf022.png"><br>  <i>DeepFace working principle</i> <br><br>  <b>Disadvantages of neural networks:</b> adding a new reference person to the database requires a complete retraining of the network throughout the entire set (quite a long procedure, depending on the sample size from 1 hour to several days).  Mathematical problems associated with learning: hitting the local optimum, choosing the optimal optimization step, retraining, etc. It is difficult to formalize the choice of network architecture (the number of neurons, layers, the nature of connections).  Summarizing all the above, we can conclude that NA is a ‚Äúblack box‚Äù with difficult to interpret work results. <br><br><h5>  3. Hidden Markov models (SMM, HMM) </h5><br><br>  One of the statistical methods for face recognition are hidden Markov models (SMM) with discrete time [32‚Äì34].  The SMMs use the statistical properties of the signals and take into account their spatial characteristics directly.  The elements of the model are: the set of hidden states, the set of observable states, the matrix of transition probabilities, the initial probability of states.  Each has its own Markov model.  When an object is recognized, Markov models generated for a given object base are checked and the maximum observed probability is searched for that the sequence of observations for a given object is generated by the corresponding model. <br>  To date, it has not been possible to find examples of the commercial use of SMM for face recognition. <br><br>  <b>Disadvantages:</b> <br>  - it is necessary to select the model parameters for each database; <br>  - The SMM does not have a distinctive ability, that is, the learning algorithm only maximizes the response of each image to its model, but does not minimize the response to other models. <br><br><h5>  4. Principal component method or principal component analysis (PCA) [11] </h5><br><br>  One of the most well-known and developed is the principal component analysis (PCA) method, based on the Karhunen-Loyev transform. <br>  Initially, the principal component method began to be used in statistics to reduce the feature space without significant loss of information.  In the problem of face recognition, it is used mainly to represent a face image with a vector of small dimension (main components), which is then compared with the reference vectors embedded in the database. <br>  The main goal of the principal component method is to significantly reduce the dimension of the feature space in such a way that it describes as best as possible the ‚Äútypical‚Äù images belonging to many individuals.  Using this method, it is possible to identify various variability in a training sample of face images and describe this variability in the basis of several orthogonal vectors, which are called eigenface. <br><br>  The set of eigenvectors obtained once on a training sample of face images is used to encode all other face images, which are represented by a weighted combination of these eigenvectors.  Using a limited number of eigenvectors, it is possible to obtain a compressed approximation to the input face image, which can then be stored in a database as a coefficient vector that simultaneously serves as a search key in the database of persons. <br><br>  The essence of the main component method is as follows.  First, the entire training set of faces is transformed into one common data matrix, where each row represents one copy of the image of a person laid out in a row.  All persons in the training set must be reduced to the same size and with normalized histograms. <br><br><img src="https://habrastorage.org/files/7d1/e3b/a0a/7d1e3ba0a881465495c6bb6b7440d8ee.png"><br>  <i>Transformations of a training set of persons into one common matrix X</i> <br><br>  Then the data is normalized and the rows are brought to the 0th mean and 1st variance, the covariance matrix is ‚Äã‚Äãcalculated.  For the resulting covariance matrix, the problem of determining the eigenvalues ‚Äã‚Äãand the corresponding eigenvectors (proper faces) is solved.  Next, the eigenvectors are sorted in decreasing order of eigenvalues ‚Äã‚Äãand only the first k vectors are left by the rule: <br><br><img src="https://habrastorage.org/files/077/2e6/884/0772e6884e704d4db05c2d35297669d5.png"><br><img src="https://habrastorage.org/files/743/1f8/2cc/7431f82cc0cc4ed49586cc981ab6aa23.png"><br>  <i>PCA algorithm</i> <br><br><img src="https://habrastorage.org/files/caf/036/afb/caf036afb0ef4cc6826c377362700b79.png"><br>  <i>An example of the first ten eigenvectors (own faces) obtained on the learner set of faces</i> <br><br><img src="https://habrastorage.org/files/fda/32a/a1d/fda32aa1d4294ddbb0da73ad46e659ed.png">  = 0.956 * <img src="https://habrastorage.org/files/6bd/2c4/e83/6bd2c4e83a9d4da29d9d6a576140f105.png">  -1.842 * <img src="https://habrastorage.org/files/449/29c/1db/44929c1db13d45678a87fa5daf45a958.png">  +0.046 <img src="https://habrastorage.org/files/621/3a2/adf/6213a2adf25949fcb7dddd195ec60f9e.png">  ... <br><br>  <i>An example of building (synthesis) of a human face using a combination of its own faces and main components</i> <br><br><img src="https://habrastorage.org/files/dab/8c9/693/dab8c969387143ed8c691d14bbb1217a.png"><br>  <i>The principle of choosing the basis of the first best eigenvectors</i> <br><br><img src="https://habrastorage.org/files/446/f5a/ce1/446f5ace119c423ea22893876454050e.png"><br>  <i>An example of mapping a face into a three-dimensional metric space, obtained from three own faces and further recognition</i> <br><br><img src="https://habrastorage.org/files/674/ae4/971/674ae49714b9495c8d6b8df84ee22b14.png"><br><br>  The method of principal components has proven itself in practical applications.  However, in cases where there are significant changes in the light or facial expression on the face, the effectiveness of the method drops significantly.  The thing is, the PCA chooses a subspace so as to maximally approximate the input data set, rather than discriminate between classes of individuals. <br><br>  In [22], a solution to this problem was proposed using the Fisher linear discriminant (the name ‚ÄúEigen-Fisher‚Äù, ‚ÄúFisherface‚Äù, LDA) is found in the literature.  LDA selects a linear subspace that maximizes the relationship: <br><br><img src="https://habrastorage.org/files/925/7f8/083/9257f808328d40b08f168e3de1f27b66.png"><br><br>  Where <img src="https://habrastorage.org/files/ae1/a74/d70/ae1a74d7025b4f3ea35c5d0f8aed274f.png"><br><br>  interclass scatter matrix, and <br><img src="https://habrastorage.org/files/741/c40/e07/741c40e07d4346f5afac59c2d8e32786.png"><br><br>  Matrix of intraclass scatter;  m is the number of classes in the database. <br><br>  LDA is looking for a projection of data in which classes are as linearly separable as possible (see figure below).  For comparison, the PCA is looking for a data projection in which the spread across the entire database of individuals will be maximized (excluding classes).  According to the results of experiments [22], under conditions of strong tank and lower shading of face images, Fisherface showed 95% efficiency compared to 53% of the Eigenface. <br><br><img src="https://habrastorage.org/files/c7a/3ee/740/c7a3ee7409aa41489452b7418eef5805.jpg"><br>  <i>The fundamental difference in the formation of PCA and LDA projections</i> <br><br>  PCA versus LDA <br><br><img src="https://habrastorage.org/files/c8d/e97/694/c8de976940c5480a89469d4ab0f3b278.png"><br><br><br><h5>  5. Active Appearance Models (AAM) and Active Shape Models (ASM) ( <a href="http://habrahabr.ru/post/155759/%26post%3D5385365_18497/">Habra Source</a> ) </h5><br>  <b>Active Appearance Models (AAM)</b> <br>  Active Models of Appearance (Active Appearance Models, AAM) are statistical models of images that can be adapted to a real image by various kinds of deformations.  This type of model in a two-dimensional version was proposed by Tim Kuts and Chris Taylor in 1998 [17,18].  Initially, active appearance models were used to evaluate the parameters of facial images. <br>  The active appearance model contains two types of parameters: parameters associated with the form (shape parameters) and parameters associated with the statistical model of image pixels or texture (appearance parameters).  Before using the model must be trained on a set of pre-marked images.  Image marking is done manually.  Each label has its own number and determines the characteristic point that the model will have to find when adapting to a new image. <br><br><img src="https://habrastorage.org/files/e47/5b9/be7/e475b9be784547a699e9770fa3f0ba8a.png"><br>  <i>An example of a markup of a face image of 68 points forming the AAM shape.</i> <br><br>  The AAM learning procedure begins with the normalization of the shapes on the tagged images in order to compensate for differences in scale, tilt and offset.  For this, the so-called generalized Procrustes analysis is used. <br><br><img src="https://habrastorage.org/files/274/e79/97d/274e7997db0047c8935d1f11cec9d237.png"><br>  <i>Coordinates of face shape points before and after normalization</i> <br><br>  Of the total set of normalized points, the main components are then selected using the PCA method. <br><br><img src="https://habrastorage.org/files/7cf/179/53b/7cf17953bc614aa1bba0acd92953905a.png"><br>  <i>The model of the AAM form consists of a triangulation lattice s0 and a linear combination of displacements si with respect to s0</i> <br><br>  Further, a matrix is ‚Äã‚Äãformed from pixels inside the triangles formed by points of the shape, such that each column contains the pixel values ‚Äã‚Äãof the corresponding texture.  It is worth noting that the textures used for learning can be either single-channel (grayscale) or multi-channel (for example, RGB color space or another).  In the case of multichannel textures, the vectors of pixels are formed separately for each of the channels, and then they are concatenated.  After finding the main components of the texture matrix, the AAM model is considered trained. <br><br><img src="https://habrastorage.org/files/cfd/2e7/035/cfd2e70350264d45b38d68dcb0ad5808.png"><br><br>  The AAM appearance model consists of a base view A0, defined by pixels inside the base lattice s0 and a linear combination of offsets Ai relative to A0 <br><br><img src="https://habrastorage.org/files/06a/e2e/f8b/06ae2ef8bca64099be73a8c73c2f59d3.png"><br><br>  An example of instantiation of AAM.  Form Parameters Vector <br>  p = (p_1, p_2, „Äñ..., p _m) ^ T = (- 54.10, -9.1, ...) ^ T is used to synthesize the model of the form s, and the vector of parameters Œª = (Œª_1, Œª_2, „Äñ..., Œª„Äó _m) ^ T = (3559,351, -256, ...) ^ T for the synthesis of the appearance of the model.  The resulting face model „ÄñM (W (x; p))„Äó ^ is obtained as a combination of two models ‚Äî shape and appearance. <br><br>  The model is fitted to a specific face image in the process of solving an optimization problem, the essence of which is to minimize the functionality <br><br><img src="https://habrastorage.org/files/ac4/33b/41e/ac433b41e1bd4ad3af3700fd967e662f.png"><br><br>  gradient descent method.  The found model parameters will reflect the position of the model on a particular image. <br><br><img src="https://habrastorage.org/files/158/986/40d/15898640d18e4ed2aa84e29feed60e22.png"><br><img src="https://habrastorage.org/files/037/36f/ce7/03736fce7e7949578cbf1e0eeff3eda2.png"><br>  <i>An example of fitting a model to a specific image in 20 iterations of the gradient descent procedure.</i> <br><br>  With the help of AAM, you can simulate images of objects subject to both rigid and non-rigid deformation.  AAM consists of a set of parameters, some of which represent the shape of a face, the rest define its texture.  The deformation is usually understood as a geometric transformation in the form of a composition of translation, rotation and scaling.  When solving the problem of localizing a face in an image, a search is made for the parameters (location, shape, texture) of AAM, which represent the synthesized image that is closest to the observed one.  According to the proximity of AAM to the customized image, a decision is made whether there is a face or not. <br><br>  <i><b>Active Shape Models (ASM)</b></i> <br><br>  The essence of the ASM method [16,19,20] is to take into account the statistical relationships between the location of anthropometric points.  On the available sample of images of persons taken in full face.  On the image, the expert marks the location of the anthropometric points.  On each image the points are numbered in the same order. <br><br><img src="https://habrastorage.org/files/48f/21f/4f8/48f21f4f8e4d476c9c9fffa9d0de224a.gif"><br><img src="https://habrastorage.org/files/29c/3da/483/29c3da483a874d4b9176828a3642fafa.gif"><br>  <i>Example of a face shape using 68 points</i> <br><br>  In order to bring the coordinates on all images to a single system, so-called  generalized scrolling analysis, as a result of which all points are reduced to the same scale and centered.  Further, for the whole set of images, the average form and the covariance matrix are calculated.  On the basis of the covariance matrix, eigenvectors are calculated, which are then sorted in descending order of the corresponding eigenvalues.  The ASM model is determined by the matrix Œ¶ and the vector of the average form s ÃÖ. <br>  Then any form can be described using the model and parameters: <br><br><img src="https://habrastorage.org/files/8a1/b92/6a1/8a1b926a18a842378dbd46ef8fd3d04c.png"><br><br>  Localization of the ASM model on a new, non-training image is carried out in the process of solving an optimization problem. <br><br><img src="https://habrastorage.org/files/d39/99f/f70/d3999ff702714b259b0c9760c883f514.png"><br>  a B C D) <br> <i>    ASM   : )   )  5  )  10  )  </i> <br><br>      AAM  ASM    ,            . <br><br>      ,  ,  ,                (,      )    .               ‚Äì        .       .              10   [1]. <br><br>  AAM  ASM               . <br><br><h5> 6.  ,       </h5><br><br>   <br><br><img src="https://habrastorage.org/files/a69/e06/f78/a69e06f7819642e0821afadbb769d819.png"><br><br>    ( ‚Äì ,  , 3D ). <br><br><img src="https://habrastorage.org/files/af7/908/d15/af7908d15bf9443ab27a24efde7cd6dd.png"><br><br>          DARPA        FERET (face recognition technology). <br><br>     FERET   ,             (PCA).      .             (    ).   ,       ,   ,  ,  95%.  ,       , ,  ,   80%.  ,     ,     50%.    ,   50  ‚Äî         . <br><br>  FERET          [55]      .            ,       .       NeoFace   NEC. <br><br><h5>   (   ) </h5><br> 1. Image-based Face Recognition ‚Äî Issues and Methods <br> 2. Face Detection A Survey.pdf <br> 3. Face Recognition A Literature Survey <br> 4. A survey of face recognition techniques <br> 5. A survey of face detection, extraction and recognition <br> 6.         <br> 7.       <br> 8.      <br> 9. Face Recognition Techniques <br> 10.       . <br> 11.          <br> 12.    2-     <br> 13. Face Recognition by Elastic Bunch Graph Matching <br> 14.        - . . <br> 15. Distortion Invariant Object Recognition in the Dynamic Link Architecture <br> 16. Facial Recognition Using Active Shape Models, Local Patches and Support Vector Machines <br> 17. Face Recognition Using Active Appearance Models <br> 18. Active Appearance Models for Face Recognition <br> 19. Face Alignment Using Active Shape Model And Support Vector Machine <br> 20. Active Shape Models ‚Äî Their Training and Application <br> 21. Fisher Vector Faces in the Wild <br> 22. Eigenfaces vs. Fisherfaces Recognition Using Class Specific Linear Projection <br> 23. Eigenfaces and fisherfaces <br> 24. Dimensionality Reduction <br> 25. ICCV 2011 Tutorial on Parts Based Deformable Registration <br> 26. Constrained Local Model for Face Alignment, a Tutorial <br> 27. Who are you ‚Äì Learning person specific classifiers from video <br> 28.        <br> 29. Face Recognition A Convolutional Neural Network Approach <br> 30. Face Recognition using Convolutional Neural Network and Simple Logistic Classifier <br> 31. Face Image Analysis With Convolutional Neural Networks <br> 32.        . - <br> 33.        <br> 34. Face Detection and Recognition Using Hidden Markovs Models <br> 35. Face Recognition with GNU Octave-MATLAB <br> 36. Face Recognition with Python <br> 37. Anthropometric 3D Face Recognition <br> 38. 3D Face Recognition <br> 39. Face Recognition Based on Fitting a 3D Morphable Model <br> 40. Face Recognition <br> 41. Robust Face Recognition via Sparse Representation <br> 42. The FERET Evaluation Methodology For Face-Recognition Algorithms <br> 43.        <br> 44. Design, Implementation and Evaluation of Hardware Vision Systems dedicated to Real-Time Face Recognition <br> 45. An Introduction to the Good, the Bad, &amp; the Ugly Face Recognition Challenge Prob-lem <br> 46.         - .  Diploma <br> 47. DeepFace Closing the Gap to Human-Level Performance in Face Verification <br> 48. Taking the bite out of automated naming of characters in TV video <br> 49. Towards a Practical Face Recognition System Robust Alignment and Illumination by Sparse Representation <br> 50.             <br> 51.       <br> 52.   - <br> 53.              <br> 54. Overview of the Face Recognition Grand Challenge <br> 55. Face Recognition Vendor Test (FRVT) <br> 56.     SURF     </div><p>Source: <a href="https://habr.com/ru/post/238129/">https://habr.com/ru/post/238129/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../238119/index.html">As it turned out, everyone knows, but not everyone understands. Transactions in mysql and SELECT FOR UPDATE</a></li>
<li><a href="../238121/index.html">Windows Identity Foundation - for ASP.NET MVC projects</a></li>
<li><a href="../238123/index.html">Do it yourself! Kite Aerial Kite Aerial Photography</a></li>
<li><a href="../238125/index.html">The Martian orbital satellites MAVEN and Mangalyaan transmitted the first photos of Mars</a></li>
<li><a href="../238127/index.html">Controlled Internet: is the devil so scary how it is painted?</a></li>
<li><a href="../238131/index.html">folly :: fbvector - improved std :: vector from Facebook</a></li>
<li><a href="../238133/index.html">Is it possible to improve contextual search in the browser?</a></li>
<li><a href="../238135/index.html">Exclusively under your ears: print headphones on a 3D printer</a></li>
<li><a href="../238137/index.html">Meet the Intel RealSense SDK Beta, participate in the competition and get a 3D camera</a></li>
<li><a href="../238139/index.html">Web development with comfort: Parallels Desktop 10 + Vagrant</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>