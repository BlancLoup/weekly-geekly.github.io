<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>We solve the â€œFirst Open Contestâ€ from Mail.ru on Data Science using Azure ML (introduction to Azure ML)</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Now there is an ML Boot Camp competition in which it is necessary to predict the time for which 2 matrices of sizes mï½˜k and kï½˜n will be multiplied on ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">ğŸ”</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">ğŸ“œ</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">â¬†ï¸</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">â¬‡ï¸</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>We solve the â€œFirst Open Contestâ€ from Mail.ru on Data Science using Azure ML (introduction to Azure ML)</h1><div class="post__text post__text-html js-mediator-article">  Now there is an <a href="http://mlbootcamp.ru/main/">ML Boot Camp</a> competition in which it is necessary to predict the time for which 2 matrices of sizes mï½˜k and kï½˜n will be multiplied on this computing system, if it is known how much this problem was solved on other computing systems with different matrix sizes ( <a href="http://mlbootcamp.ru/championship/7/">exact rules</a> ).  Let's try to solve this regression problem not using standard tools and libraries (R, Python and panda), but using a cloud product from Microsoft: <a href="https://studio.azureml.net/">Azure ML</a> .  For our purposes, free access is suitable, for which even a trial Azure account is sufficient.  Anyone who wants to get a quick guide to setting up and using Azure ML in general, and ML Studio in particular, using the example of solving real live tasks, are invited under cat. <br><a name="habracut"></a><br><h2>  Creating data sources </h2><br>  Open ML Studio: <br><br><img src="https://habrastorage.org/files/535/bb2/377/535bb2377a14407a955ab3a2c2238c2a.png"><br><br>  We will create one new experiment (in terms of Azure ML is a complete solution of the problem - from reading the input data to receiving the answer, then it can be converted to Web Service) and two new data sources (dataset) to represent the input data (one for signs, another for values).  Download the training sample csv files from the ML Boot Camp website (x_train.csv and y_train.csv).  To add a data source, select â€œDatasetâ€ in the menu on the left and click â€œNewâ€ in the lower left corner, this window will appear: 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/files/284/bb2/fd7/284bb2fd76e94570920495f10aa59a8a.png"><br><br>  Specify the path to the file x_train.csv, give this data source the name x_train.  Also create the y_train data source.  Now both of these data sources are shown on the â€œDatasetsâ€ tab: <br><br><img src="https://habrastorage.org/files/eb6/46f/49d/eb646f49d5d54854867fb2c1d3ecd23b.png"><br><br><h2>  Creating an experiment, the choice of characteristics </h2><br>  It's time to create an experiment, for this, in the menu on the left, select the item â€œExperimentsâ€, click â€œNewâ€ in the lower left and select â€œBlank Experimentâ€.  In the line above, you can give it a suitable name, in the end we get the following scope for our Data Science operations: <br><br><img src="https://habrastorage.org/files/acd/a10/853/acda108535204a0db4105c729487647b.png"><br><br>  As you can see, on the left is a menu that lists all possible operations that can be added to the experiment, such as: data entry and output, selection of columns, various regression methods, classifications, etc.  All of them will be added to our experiment by simply dragging the mouse and connecting different operations together. <br>  Now we need to show what we want to use as input to the task.  In the menu on the left, select the topmost item â€œSaved Datasetsâ€, then â€œMy Datasetsâ€, select the x_train and y_train data sources created by us and drag them to the experimental area, resulting in: <br><br><img src="https://habrastorage.org/files/fe1/0d9/ed6/fe10d9ed67054f97a37ed8055ca1575b.png"><br><br>  Now we need to combine the columns of these two data sources, because all the Azure ML methods work with a single table (data frame) in which to specify the column, which is the learning value.  To do this, we use the module "Add Columns".  Hint: searching by modules will help you find a module by keywords or make sure that such a module does not exist yet.  Drag the â€œAdd Columnsâ€ operation to the workspace and connect its two upper data entry points with our x_train and y_train data sources, respectively.  This operation has no parameters, so you donâ€™t need to configure anything else.  We get: <br><br><img src="https://habrastorage.org/files/d03/d7c/1dc/d03d7c1dc18f4980bef996f2fee7e1b6.png"><br><br>  To see how our data now looks.  Run the experiment by clicking the â€œRunâ€ button on the bottom line.  After the experiment is successfully completed, you can click on the output of the operation â€œAdd Columnsâ€ and select the action â€œVisualizeâ€: <br><br><img src="https://habrastorage.org/files/9d8/770/473/9d8770473cc44c9abce0f25693dcafc4.png"><br><img src="https://habrastorage.org/files/231/713/73e/23171373e1bb4723b027e9eb53c0e47d.png"><br><br>  The properties window allows you to see the columns, the first lines, for each attribute: average, median, histogram, etc.  We see that in our table there are 952 columns (signs), and from them it is necessary to choose meaningful ones, which will help us in solving our problem.  The selection of features is one of the most complex and non-deterministic operations in Data Science, so for now, for simplicity, weâ€™ll select a few features that at first glance are significant.  The module that helps us do this is called â€œSelect Columns in Datasetâ€.  Add it to the workspace, connect with the operation "Add Columns".  Now, in the parameters "Select Columns in Dataset" we indicate which signs we want to leave.  To do this, select the module "Select Columns in Dataset", in the properties on the right pane, click "Launch column selector": <br><br><img src="https://habrastorage.org/files/043/b4b/ecb/043b4becba354fd0933a3b24d0287dbe.png"><br><br>  Now we add the names of the columns that we want to leave (this is not the optimal choice of columns at all), do not forget to add the â€œtimeâ€ column: <br><br><img src="https://habrastorage.org/files/f34/545/ba7/f34545ba76d848969f18e7cd4598a10c.png"><br><br>  Let's run the experiment again, make sure that only the columns that are selected are left in the resulting table.  Now the last step in data preparation: we divide the data into a training and test sample in the proportion of 70:30.  To do this, we will find and place in the working area the module â€œSplit Dataâ€, in its settings we will set â€œFraction of rows in the first output datasetâ€ equal to 0.7.  We get: <br><br><img src="https://habrastorage.org/files/7bc/590/3b0/7bc5903b063e4b528062a29ea13983d6.png"><br><br><h2>  Use of algorithms </h2><br>  Now we are finally ready to use some kind of regression method.  Methods are listed in the left menu: â€œMachine Learningâ€, â€œInitialize Modelâ€, â€œRegressionâ€: <br><br><img src="https://habrastorage.org/files/a8e/5ce/e41/a8e5cee41071477ca9005e27d1708577.png"><br><br>  First, let's try the forest decision tree method: â€œDecision Forest Regressionâ€.  Add it to the workspace, as well as the â€œTrain modelâ€ module.  This module has two inputs: one connects with the algorithm (in our case with â€œDecision Forest Regressionâ€), the other connects with the training sample data (left output of the â€œSplit Dataâ€ module).  The experiment now looks like this: <br><br><img src="https://habrastorage.org/files/1eb/5a9/7c6/1eb5a97c6f8641559d9d8e201c6b61f1.png"><br><br>  The red circle in the Train model module tells us that it has required parameters that we did not tune up: it needs to indicate which sign we are trying to predict (in our case, this time).  Click "Launch column selector", add a single time column.  Note that the method itself has default settings that allow it to run without manual configuration.  Of course, to get good results, try different combinations of parameters that will be specific to each method.  Now the experiment can be started, the forest of trees will be built, they can even be viewed by calling the already familiar â€œVisualizeâ€ window.  After training the model, it would be good to test it on a test (validation) sample, which represents 30% of the initial data.  To do this, we use the Score Model module, connecting its first input with the output of the Train model module (trained model), and the second with the second output of the Split Data module.  Now the sequence of operations looks like this: <br><br><img src="https://habrastorage.org/files/a7a/326/2fe/a7a3262fead74ed0a0f5f3b356f863db.png"><br><br>  You can run the experiment again and see the output of the â€œScore modelâ€: <br><br><img src="https://habrastorage.org/files/321/003/fb8/321003fb8bfe4f05ae259b0852384146.png"><br><br>  Two new columns were added: â€œScored Label Meanâ€ (average of the predicted value) and â€œScored Label Standard Deviationâ€ (standard deviation of the predicted value from the actual).  You can also build a scatter plot (scatter plot, scatter plot) for the predicted and actual values â€‹â€‹(visible in the figure).  Now we learn its accuracy with the help of the module â€œEvaluate Modelâ€, which we will connect with the module â€œScore Modelâ€. <br><br><img src="https://habrastorage.org/files/fb9/8cb/394/fb98cb3946b74f58870ec3b45e623ed3.png"><br><br>  The output of the â€œEvaluate Modelâ€ module contains information on the accuracy of the method on our verification data, including absolute and relative errors: <br><br><img src="https://habrastorage.org/files/f1d/7ea/afe/f1d7eaafe078438e85040aa909daea8b.png"><br><br>  Of course, the method is not perfect, but we didnâ€™t do it at all. <br><br><h2>  Adding a new method and comparing methods </h2><br>  Let's try another method based on decision trees: â€œBoosted Decision Tree Regressionâ€.  In the same way as for the first method, add the â€œTrain Modelâ€ and â€œScore Modelâ€ modules, run the experiment, see the output of the â€œScore Modelâ€ module for the new method.  Note that only one column was added, representing the predicted value: â€œScored Labelsâ€, for it you can also build a scatter chart: <br><br><img src="https://habrastorage.org/files/f6e/76b/4be/f6e76b4bec11489f90af07079e16350b.png"><br><br>  Now we will compare the accuracy of these two methods, using the already added module â€œEvaluate Modelâ€, for this we will connect its right input with the conclusion â€œScore Modelâ€ of the second method.  As a result, we obtain the following sequence of operations: <br><br><img src="https://habrastorage.org/files/b6d/cb4/1fd/b6dcb41fdc1749239e3b3b8e5ca4885d.png"><br><br>  Let's look at the output of the â€œEvaluate Modelâ€ module: <br><br><img src="https://habrastorage.org/files/103/375/0db/1033750dbfb049f59ce3f520b92114ac.png"><br><br>  Now we can compare the methods among themselves and choose the one, the accuracy of which (in the sense necessary for our task) is higher. <br><br><h2>  We solve the problem with real data </h2><br>  We have trained methods, we know their accuracy - it's time to test them in battle.  Let's download the file x_test.csv, which contains the data for which we must predict the time of matrix multiplication.  To use the trained method, we need: <br><ol><li>  Add a new data source with the name x_test and data from the x_test.csv file. </li><li>  Drag the new x_test data source to the experiment workspace. </li><li>  Now we need to leave only those columns that took part in the training, copy the Select Columns in Dataset module, and remove the time column from the list of columns (since it is not in our test data). </li><li>  Now we can run our trained method on the prepared data, for this we add the operation â€œScore Modelâ€, connect its first input with the output of the Train Model module of the Boosted Decision Tree Regression method, the second input with the output of the newly added Select Columns in Dataset. </li><li>  Now it remains to bring the data to a format that can be downloaded as a solution to the ML Boot Camp website.  To do this, we will add another module â€œSelect Columns in Datasetâ€, in which we will select just one column - our predicted values â€‹â€‹of â€œScored Labelsâ€, and add the module â€œConvert to CSVâ€ to its output. </li></ol><br>  As a result, we obtain the following experiment: <br><br><img src="https://habrastorage.org/files/547/319/d9b/547319d9b0cf4b4f9ea1c2a7f227fc67.png"><br><br>  You can download the received csv file by clicking on the output of the â€œConvert to CSVâ€ module and selecting the â€œDownloadâ€ item.  Now we will delete the first line (with the name) from the received csv, upload it to the ML Boot Camp website.  Works!  But accuracy leaves much to be desired. <br><br><h2>  Further optimization </h2><br>  Consider several modules that will help improve the accuracy of the regression. <br><ol><li>  Try different methods that can be found in the menu on the left. </li><li>  The Filter Based Feature Selection module, which tries to select the features with the most predictive ability (several different methods, which are specified in its properties), will help select the signs.  This module is added instead of the â€œSelect Columns in Datasetâ€ module. </li><li>  The â€œPermutation Feature Importanceâ€ module, which accepts a trained model and a set of test data as input parameters, will help assess which features are more useful in an already trained model. </li><li>  The â€œTune Model Hyperparametersâ€ module will help you to choose the parameters of the method, which will conduct the specified number of method launches with different parameter sets and show the accuracy of each run. </li><li>  As a heavy artillery, you can use any R and Python scripts using the modules "Execute R Script" and "Execute Python Script", respectively. </li></ol><br><br><h2>  Conclusion </h2><br>  I like Azure ML, it allows you to quickly prototype a solution to a problem, and then delve into tuning and optimizing its solution. <br><br>  The experiment is posted to the gallery and is open to everyone at: <a href="https://gallery.cortanaintelligence.com/Experiment/ML-Boot-Camp-from-Mail-ru-1">gallery.cortanaintelligence.com/Experiment/ML-Boot-Camp-from-Mail-ru-1</a> <br><br>  Take part in the contest!  Anyone who can get a MAPE error less than 0.1, write, the author will be pleased. </div><p>Source: <a href="https://habr.com/ru/post/304186/">https://habr.com/ru/post/304186/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../304174/index.html">Simple automation example letsencrypt</a></li>
<li><a href="../304178/index.html">Mindfields contracts: respectable partnership of developers and enterprises</a></li>
<li><a href="../304180/index.html">PyCon Russia 2016: latest news and final program</a></li>
<li><a href="../304182/index.html">Why graphQL future</a></li>
<li><a href="../304184/index.html">5 consequences of using high technology that can lead to depression</a></li>
<li><a href="../304188/index.html">Data leakage is becoming more expensive: the average size of company losses due to hacking rose to $ 4 million</a></li>
<li><a href="../304190/index.html">Acronis People 2: Start a career in Acronis. How, instead of a cozy internship, I got into the development hell</a></li>
<li><a href="../304192/index.html">Progressive simplification</a></li>
<li><a href="../304196/index.html">Confrontation: new format and new reality</a></li>
<li><a href="../304200/index.html">How to increase conversion to ecommerce using exit polls</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>