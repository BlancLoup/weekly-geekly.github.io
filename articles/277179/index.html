<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Combining video clips from multiple cameras and synchronizing them over time</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="In the remote surveillance system (VOS), which was reviewed in the previous article , Kurento media server is used to manage media streams, which allo...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Combining video clips from multiple cameras and synchronizing them over time</h1><div class="post__text post__text-html js-mediator-article">  In the remote surveillance system (VOS), which was reviewed in the <a href="https://habrahabr.ru/post/277147/">previous article</a> , Kurento media server is used to manage media streams, which allows recording streams, where each stream is a separate file.  The problem is that when viewing the exam protocol, you need to play three streams simultaneously with time synchronization (test webcam with sound, proctor webcam with sound, and test desktop), and throughout the exam each stream can be broken. into several fragments.  This article is about how to solve this problem, as well as organize the preservation of video on WebDAV server just one bash-script. <br><br><img src="https://habrastorage.org/files/5e0/204/eaa/5e0204eaaf0f4a3caa0a6e57795b403b.png" alt="Reproduction of the VOS video archive"><br><a name="habracut"></a><br>  The Kurento media <a href="http://www.kurento.org/">server</a> saves the media streams in their original form, as they are transmitted from the client, in fact, the stream is dumped to a webm file, the vp8 and vorbis codecs are used (there is also support for mp4).  This leads to the fact that the saved files have a variable video resolution and a variable bit rate, since  WebRTC dynamically changes the encoding parameters of video and audio streams depending on the quality of communication channels.  During each proctoring session, clients can establish a connection several times and interrupt the connection, which leads to the appearance of multiple files for each camera and screen, and also out-of-sync appears in time, if then all these fragments are glued together. <br><br>  To correctly play such videos, you must perform the following steps: 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <ul><li>  recode all video streams, indicating the static resolution for each camera (each camera has its own resolution, all fragments of one camera have one resolution); </li><li>  add missing video fragments to compensate for out of sync with the subsequent merging of fragments; </li><li>  glue together all the fragments of each camera to make three video files; </li><li>  merge three video files into one integrated screen. </li></ul><br>  As a result, the recording can be played only after transcoding, but in this task it is an acceptable option, since  view the record in the same second after the recording, no one will.  In addition, delayed transcoding reduces server load during proctoring sessions, since  The recoding process can be scheduled for the night when the load is minimal. <br><br>  Each proctoring session in VOS has its own unique identifier, which is transmitted by Kurento when a connection is established between the subject and the proctor.  Within this session, three streams are created that can be interrupted and resumed for technical reasons or at the initiative of the proctor.  For naming video files that are saved by Kurento, the format was ‚Äútimestamp_camera-session.webm‚Äù (mask in the form of a regular expression ^ [0-9] + _ [a-z0-9] + - [0-9a-f] {24 } .webm $), where timestamp is the timestamp for creating the file in milliseconds;  camera - camera identifier to distinguish the streams from the test camera's webcam (camera1), the proctor's webcam (camera2) and the stream with the desktop image (screen);  session - proctoring session identifier.  After each proctoring session, a lot of video fragments are saved; possible variants of video fragmentation are shown in the figure below. <br><br><img src="https://habrastorage.org/files/901/e7b/693/901e7b6934de45b094b72ff2e925d25c.png" alt="Possible options for video fragmentation"><br><br>  The numbers 1-12 are some timestamps;  the bold line is video clips of various lengths;  dashed line - missing parts to add;  empty gaps - time intervals in which there are no video clips should be excluded from the final video. <br><br>  The output video file is a block of three parts, two cameras with a resolution of 320x240 (4: 3) and one screen with a resolution of 768x480 (16:10).  The original image should be scaled to the specified size.  If the aspect ratio does not match this format, then fit the entire image in the center of the specified rectangle, paint the empty areas in black.  As a result, the location of the cameras should look like in the picture below (blue and green - webcams, red - desktop). <br><br><img src="https://habrastorage.org/files/f11/22e/d8e/f1122ed8ec5340c98540e7c8c306c3a6.png" alt="The location of the cameras on the complex screen"><br><br>  As a result, each proctoring session, instead of multiple passages, has only one video file with a recording of the entire session.  In addition, the output file takes up less space, because  video frame rate is reduced to the minimum acceptable number of 1-5 frames / s.  The resulting file is uploaded to the WebDAV server, where VOS applies for this file through the appropriate interface, taking into account the necessary access rights.  The WebDAV protocol is quite common, because the repository can be anything, you can even use <a href="">Yandex.Disk</a> for this purpose. <br><br>  The implementation of all these functions was able to fit into a small bash-script, for which additional tools ffmpeg and curl will be needed.  First you need to recode video files with dynamic resolution and bit rate, setting the necessary parameters for each camera.  The transcoding function of the original video file with the specified resolution and the number of frames per second looks like this: <br><br><pre><code class="bash hljs"><span class="hljs-function"><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">scale_video_file</span></span></span></span>() { <span class="hljs-built_in"><span class="hljs-built_in">local</span></span> in_file=<span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$1</span></span></span><span class="hljs-string">"</span></span> <span class="hljs-built_in"><span class="hljs-built_in">local</span></span> out_file=<span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$2</span></span></span><span class="hljs-string">"</span></span> <span class="hljs-built_in"><span class="hljs-built_in">local</span></span> width=<span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$3</span></span></span><span class="hljs-string">"</span></span> <span class="hljs-built_in"><span class="hljs-built_in">local</span></span> height=<span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$4</span></span></span><span class="hljs-string">"</span></span> ffmpeg -i <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$in_file</span></span></span><span class="hljs-string">"</span></span> -c:v vp8 -r:v <span class="hljs-variable"><span class="hljs-variable">${FRAME_RATE}</span></span> -filter:v scale=<span class="hljs-string"><span class="hljs-string">"'if(gte(a,4/3),</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${width}</span></span></span><span class="hljs-string">,-1)':'if(gt(a,4/3),-1,</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${height}</span></span></span><span class="hljs-string">)'"</span></span>,pad=<span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${width}</span></span></span><span class="hljs-string">:</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${height}</span></span></span><span class="hljs-string">:(</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${width}</span></span></span><span class="hljs-string">-iw)/2:(</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${height}</span></span></span><span class="hljs-string">-ih)/2"</span></span> -c:a libvorbis -q:a 0 <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${out_file}</span></span></span><span class="hljs-string">"</span></span> }</code> </pre> <br>  Particular attention should be paid to the ffmpeg scale filter, it allows you to adjust the image to a given resolution, even if the aspect ratio is different by filling the resulting empty space with black color.  FRAME_RATE is a global variable in which the frame rate is set. <br><br>  Next, you need a function that will create a stub file to fill in the gaps between the video files: <br><br><pre> <code class="bash hljs"><span class="hljs-function"><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">write_blank_file</span></span></span></span>() { <span class="hljs-built_in"><span class="hljs-built_in">local</span></span> out_file=<span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$1</span></span></span><span class="hljs-string">"</span></span> [ -e <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${out_file}</span></span></span><span class="hljs-string">"</span></span> ] &amp;&amp; <span class="hljs-built_in"><span class="hljs-built_in">return</span></span>; <span class="hljs-built_in"><span class="hljs-built_in">local</span></span> duration=$(<span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-variable"><span class="hljs-variable">$2</span></span> | LC_NUMERIC=<span class="hljs-string"><span class="hljs-string">"C"</span></span> awk <span class="hljs-string"><span class="hljs-string">'{printf("%.3f", $1 / 1000)}'</span></span>) <span class="hljs-built_in"><span class="hljs-built_in">local</span></span> width=<span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$3</span></span></span><span class="hljs-string">"</span></span> <span class="hljs-built_in"><span class="hljs-built_in">local</span></span> height=<span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$4</span></span></span><span class="hljs-string">"</span></span> ffmpeg -f lavfi -i <span class="hljs-string"><span class="hljs-string">"color=c=black:s=</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${width}</span></span></span><span class="hljs-string">x</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${height}</span></span></span><span class="hljs-string">:d=</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${duration}</span></span></span><span class="hljs-string">"</span></span> -c:v vp8 -r:v <span class="hljs-variable"><span class="hljs-variable">${FRAME_RATE}</span></span> -f lavfi -i <span class="hljs-string"><span class="hljs-string">"aevalsrc=0|0:d=</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${duration}</span></span></span><span class="hljs-string">:s=48k"</span></span> -c:a libvorbis -q:a 0 <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${out_file}</span></span></span><span class="hljs-string">"</span></span> }</code> </pre> <br>  Here you can create a video track of a given resolution, duration (in milliseconds) and frame rate, as well as a sound track with silence.  All this is encoded with the same codecs as the main video clips. <br><br>  The resulting video clips of each camera need to be combined, for this the following function is used (OUTPUT_DIR is a global variable containing the path to the directory with video clips): <br><br><pre> <code class="bash hljs"><span class="hljs-function"><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">concat_video_group</span></span></span></span>() { <span class="hljs-built_in"><span class="hljs-built_in">local</span></span> video_group=<span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$1</span></span></span><span class="hljs-string">"</span></span> ffmpeg -f concat -i &lt;(ls <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${OUTPUT_DIR}</span></span></span><span class="hljs-string">"</span></span> | grep -oe <span class="hljs-string"><span class="hljs-string">"^[0-9]\+_</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${video_group}</span></span></span><span class="hljs-string">$"</span></span> | xargs -I FILE <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">"file </span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${OUTPUT_DIR%/}</span></span></span><span class="hljs-string">/FILE"</span></span>) -c copy <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${OUTPUT_DIR}</span></span></span><span class="hljs-string">/</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${video_group}</span></span></span><span class="hljs-string">"</span></span> ls <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${OUTPUT_DIR}</span></span></span><span class="hljs-string">"</span></span> | grep -oe <span class="hljs-string"><span class="hljs-string">"^[0-9]\+_</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${video_group}</span></span></span><span class="hljs-string">$"</span></span> | xargs -I FILE rm <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${OUTPUT_DIR%/}</span></span></span><span class="hljs-string">/FILE"</span></span> }</code> </pre> <br>  You will also need a function to determine the duration of the video file in milliseconds, here we use the ffprobe utility from the ffmpeg package: <br><br><pre> <code class="bash hljs"><span class="hljs-function"><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">get_video_duration</span></span></span></span>() { <span class="hljs-built_in"><span class="hljs-built_in">local</span></span> in_file=<span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$1</span></span></span><span class="hljs-string">"</span></span> ffprobe -v error -show_entries format=duration -of default=noprint_wrappers=1:nokey=1 <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${in_file}</span></span></span><span class="hljs-string">"</span></span> | LC_NUMERIC=<span class="hljs-string"><span class="hljs-string">"C"</span></span> awk <span class="hljs-string"><span class="hljs-string">'{printf("%.0f", $1 * 1000)}'</span></span> }</code> </pre> <br>  Now, when there is a transcoding function, the function of creating missing fragments of a given length, as well as the function of gluing all these fragments, we need the function of synchronizing video clips from different cameras, which will decide which fragments and how long it is necessary to recreate.  The algorithm is as follows: <br><br><ol><li>  Retrieve a list of files with video clips, sorted according to their timestamp, which is the first part of the file name. </li><li>  View the list from top to bottom, simultaneously creating another list of the form ‚Äútime_label: flag: file_name‚Äù.  The essence of this list is to mark all the points of beginning and end of each video file (see the picture with the video fragmentation illustration).  For our example, this will be the following list: <br><pre> <code class="hljs ruby"><span class="hljs-number"><span class="hljs-number">1</span></span><span class="hljs-symbol"><span class="hljs-symbol">:</span></span><span class="hljs-number"><span class="hljs-number">1</span></span><span class="hljs-symbol"><span class="hljs-symbol">:camera1-session</span></span>.webm <span class="hljs-number"><span class="hljs-number">3</span></span><span class="hljs-symbol"><span class="hljs-symbol">:-</span></span><span class="hljs-number"><span class="hljs-number">1</span></span><span class="hljs-symbol"><span class="hljs-symbol">:camera1-session</span></span>.webm <span class="hljs-number"><span class="hljs-number">7</span></span><span class="hljs-symbol"><span class="hljs-symbol">:</span></span><span class="hljs-number"><span class="hljs-number">1</span></span><span class="hljs-symbol"><span class="hljs-symbol">:camera1-session</span></span>.webm <span class="hljs-number"><span class="hljs-number">10</span></span><span class="hljs-symbol"><span class="hljs-symbol">:-</span></span><span class="hljs-number"><span class="hljs-number">1</span></span><span class="hljs-symbol"><span class="hljs-symbol">:camera1-session</span></span>.webm <span class="hljs-number"><span class="hljs-number">2</span></span><span class="hljs-symbol"><span class="hljs-symbol">:</span></span><span class="hljs-number"><span class="hljs-number">1</span></span><span class="hljs-symbol"><span class="hljs-symbol">:camera2-session</span></span>.webm <span class="hljs-number"><span class="hljs-number">5</span></span><span class="hljs-symbol"><span class="hljs-symbol">:-</span></span><span class="hljs-number"><span class="hljs-number">1</span></span><span class="hljs-symbol"><span class="hljs-symbol">:camera2-session</span></span>.webm <span class="hljs-number"><span class="hljs-number">8</span></span><span class="hljs-symbol"><span class="hljs-symbol">:</span></span><span class="hljs-number"><span class="hljs-number">1</span></span><span class="hljs-symbol"><span class="hljs-symbol">:camera2-session</span></span>.webm <span class="hljs-number"><span class="hljs-number">10</span></span><span class="hljs-symbol"><span class="hljs-symbol">:-</span></span><span class="hljs-number"><span class="hljs-number">1</span></span><span class="hljs-symbol"><span class="hljs-symbol">:camera2-session</span></span>.webm <span class="hljs-number"><span class="hljs-number">3</span></span><span class="hljs-symbol"><span class="hljs-symbol">:</span></span><span class="hljs-number"><span class="hljs-number">1</span></span><span class="hljs-symbol"><span class="hljs-symbol">:screen-session</span></span>.webm <span class="hljs-number"><span class="hljs-number">6</span></span><span class="hljs-symbol"><span class="hljs-symbol">:-</span></span><span class="hljs-number"><span class="hljs-number">1</span></span><span class="hljs-symbol"><span class="hljs-symbol">:screen-session</span></span>.webm <span class="hljs-number"><span class="hljs-number">8</span></span><span class="hljs-symbol"><span class="hljs-symbol">:</span></span><span class="hljs-number"><span class="hljs-number">1</span></span><span class="hljs-symbol"><span class="hljs-symbol">:screen-session</span></span>.webm <span class="hljs-number"><span class="hljs-number">12</span></span><span class="hljs-symbol"><span class="hljs-symbol">:-</span></span><span class="hljs-number"><span class="hljs-number">1</span></span><span class="hljs-symbol"><span class="hljs-symbol">:screen-session</span></span>.webm</code> </pre> </li><li>  Add the resulting list with entries with zero duration (identical time stamps) for the first and last file of the original list of video clips.  This is needed at the stage of calculating the missing intermediate video clips. </li><li>  Supplement the list with entries that correspond to the beginning and end of the fragments, when there is no video from any of the cameras.  In our example, these will be the entries ‚Äú6: 1: ...‚Äù and ‚Äú7: -1: ...‚Äù. </li><li>  The resulting list is divided into three parts, we get for each camera its own list.  Go through each list and invert it, i.e.  instead of a list of existing fragments should get a list of missing fragments. </li><li>  Convert the resulting list to the format ‚Äútimestamp: duration: filename‚Äù so that you can create the missing video clips based on it. </li></ol><br>  This algorithm is implemented by the following set of functions: <br><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#   # input: timestamp:flag:filename # output: timestamp:duration:filename find_spaces() { local state=0 prev=0 sort -n | while read item do arr=(${item//:/ }) timestamp=${arr[0]} flag=${arr[1]} let state=state+flag if [ ${state} -eq 0 ] then let prev=timestamp elif [ ${prev} -gt 0 ] then let duration=timestamp-prev if [ ${duration} -gt 0 ] then echo ${prev}:${duration}:${arr[2]} fi prev=0 fi done } #         zero_marks() { sort -n | sed '1!{$!d}' | while read item do arr=(${item//:/ }) timestamp=${arr[0]} for video_group in ${VIDEO_GROUPS} do echo ${timestamp}:1:${video_group} echo ${timestamp}:-1:${video_group} done done } #  ,         blank_marks() { find_spaces | while read item do arr=(${item//:/ }) first_time=${arr[0]} duration=${arr[1]} let last_time=first_time+duration for video_group in ${VIDEO_GROUPS} do echo ${first_time}:1:${video_group} echo ${last_time}:-1:${video_group} done done } #    : timestamp:duration:filename generate_marks() { ls "${OUTPUT_DIR}" | grep "^[0-9]\+_" | sort -n | while read video_file do filename=${video_file#*_} timestamp=${video_file%%_*} duration=$(get_video_duration "${OUTPUT_DIR%/}/${video_file}") echo ${timestamp}:1:${filename} echo $((timestamp+duration)):-1:${filename} done | tee &gt;(zero_marks) &gt;(blank_marks) } #     ,     fragments_by_groups() { local cmd="tee" for video_group in ${VIDEO_GROUPS} do cmd="${cmd} &gt;(grep :${video_group}$ | find_spaces)" done eval "${cmd} &gt;/dev/null" } #    write_fragments() { while read item do arr=(${item//:/ }) timestamp=${arr[0]} duration=${arr[1]} video_file=${arr[2]} write_blank_file "${OUTPUT_DIR%/}/${timestamp}_${video_file}" "${duration}" $(get_video_resolution "${video_file}") done } #    generate_marks | fragments_by_groups | write_fragments</span></span></code> </pre> <br>  After the missing video clips are recreated, you can begin to combine them.  To do this, we need the following function, which combines all the video files of one group (that is, with one camera ID): <br><br><pre> <code class="bash hljs"><span class="hljs-function"><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">concat_video_group</span></span></span></span>() { <span class="hljs-built_in"><span class="hljs-built_in">local</span></span> video_group=<span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$1</span></span></span><span class="hljs-string">"</span></span> ffmpeg -f concat -i &lt;(ls <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${OUTPUT_DIR}</span></span></span><span class="hljs-string">"</span></span> | grep -oe <span class="hljs-string"><span class="hljs-string">"^[0-9]\+_</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${video_group}</span></span></span><span class="hljs-string">$"</span></span> | sort -n | xargs -I FILE <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">"file </span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${OUTPUT_DIR%/}</span></span></span><span class="hljs-string">/FILE"</span></span>) -c copy <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${OUTPUT_DIR}</span></span></span><span class="hljs-string">/</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${video_group}</span></span></span><span class="hljs-string">"</span></span> }</code> </pre> <br>  Now, when there are all three video files synchronized in time, they need to be combined into one integrated screen, placing these files in the necessary parts of the integrated screen: <br><br><pre> <code class="bash hljs"><span class="hljs-function"><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">encode_video_complex</span></span></span></span>() { <span class="hljs-built_in"><span class="hljs-built_in">local</span></span> video_file=<span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$1</span></span></span><span class="hljs-string">"</span></span> <span class="hljs-built_in"><span class="hljs-built_in">local</span></span> camera1=<span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$2</span></span></span><span class="hljs-string">"</span></span> <span class="hljs-built_in"><span class="hljs-built_in">local</span></span> camera2=<span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$3</span></span></span><span class="hljs-string">"</span></span> <span class="hljs-built_in"><span class="hljs-built_in">local</span></span> camera3=<span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$4</span></span></span><span class="hljs-string">"</span></span> ffmpeg \ -i <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${OUTPUT_DIR%/}</span></span></span><span class="hljs-string">/</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${camera1}</span></span></span><span class="hljs-string">"</span></span> \ -i <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${OUTPUT_DIR%/}</span></span></span><span class="hljs-string">/</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${camera2}</span></span></span><span class="hljs-string">"</span></span> \ -i <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${OUTPUT_DIR%/}</span></span></span><span class="hljs-string">/</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${camera3}</span></span></span><span class="hljs-string">"</span></span> \ -threads <span class="hljs-variable"><span class="hljs-variable">${NCPU}</span></span> -c:v vp8 -r:v <span class="hljs-variable"><span class="hljs-variable">${FRAME_RATE}</span></span> -c:a libvorbis -q:a 0 \ -filter_complex <span class="hljs-string"><span class="hljs-string">" pad=1088:480 [base]; [0:v] setpts=PTS-STARTPTS, scale=320:240 [camera1]; [1:v] setpts=PTS-STARTPTS, scale=320:240 [camera2]; [2:v] setpts=PTS-STARTPTS, scale=768:480 [camera3]; [base][camera1] overlay=x=0:y=0 [tmp1]; [tmp1][camera2] overlay=x=0:y=240 [tmp2]; [tmp2][camera3] overlay=x=320:y=0; [0:a][1:a] amix"</span></span> <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${OUTPUT_DIR%/}</span></span></span><span class="hljs-string">/</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${video_file}</span></span></span><span class="hljs-string">"</span></span> }</code> </pre> <br>  Here, using the ffmpeg filter, an empty black area (pad) is created, then placed on it in the specified camera order.  The sound from the first two cameras is mixed. <br><br>  After processing the video and receiving the output file, upload it to the server (global variables STORAGE_URL, STORAGE_USER and STORAGE_PASS contain the WebDAV server address, username and password to it, respectively): <br><br><pre> <code class="bash hljs"><span class="hljs-function"><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">upload</span></span></span></span>() { <span class="hljs-built_in"><span class="hljs-built_in">local</span></span> video_file=<span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$1</span></span></span><span class="hljs-string">"</span></span> [ -n <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${video_file}</span></span></span><span class="hljs-string">"</span></span> ] || <span class="hljs-built_in"><span class="hljs-built_in">return</span></span> 1 [ -z <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${STORAGE_URL}</span></span></span><span class="hljs-string">"</span></span> ] &amp;&amp; <span class="hljs-built_in"><span class="hljs-built_in">return</span></span> 0 <span class="hljs-built_in"><span class="hljs-built_in">local</span></span> http_code=$(curl -o /dev/null -w <span class="hljs-string"><span class="hljs-string">"%{http_code}"</span></span> --digest --user <span class="hljs-variable"><span class="hljs-variable">${STORAGE_USER}</span></span>:<span class="hljs-variable"><span class="hljs-variable">${STORAGE_PASS}</span></span> -T <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${OUTPUT_DIR%/}</span></span></span><span class="hljs-string">/</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${video_file}</span></span></span><span class="hljs-string">"</span></span> <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${STORAGE_URL%/}</span></span></span><span class="hljs-string">/</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${video_file}</span></span></span><span class="hljs-string">"</span></span>) <span class="hljs-comment"><span class="hljs-comment">#   ,    201,   - 204 test "${http_code}" = "201" -o "${http_code}" = "204" }</span></span></code> </pre> <br>  The full code of the script reviewed <a href="">is posted on GitHub</a> . <br>  To test the operation of the algorithm, you can use the following generator, which creates video clips from the considered example: <br><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#!/bin/bash STORAGE_DIR="./storage" write_blank_video() { local width="$1" local height="$2" local color="$3" local duration="$4" local frequency="$5" local out_file="$6-56a8a7e3f9adc29c4dd74295.webm" ffmpeg -y -f lavfi -i "color=c=${color}:s=${width}x${height}:d=${duration}" -f lavfi -i "sine=frequency=${frequency}:duration=${duration}:sample_rate=48000,pan=stereo|c0=c0|c1=c0" -c:a libvorbis -vf "drawtext=fontfile=/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf: timecode='00\:00\:00\:00': r=30: x=10: y=10: fontsize=24: fontcolor=black: box=1: boxcolor=white@0.7" -c:v vp8 -r:v 30 "${STORAGE_DIR%/}/${out_file}" &lt;/dev/null &gt;/dev/null } # camera1 write_blank_video 320 200 blue 2 1000 1000_camera1 write_blank_video 320 200 blue 3 1000 7000_camera1 # camera2 write_blank_video 320 240 green 3 2000 2000_camera2 write_blank_video 320 240 green 2 2000 8000_camera2 # screen write_blank_video 800 480 red 3 3000 3000_screen write_blank_video 800 480 red 4 3000 8000_screen</span></span></code> </pre> <br><iframe width="560" height="315" src="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://www.youtube.com/embed/SAGxNNTTHNI%3Ffeature%3Doembed&amp;xid=17259,15700002,15700021,15700186,15700190,15700248,15700253&amp;usg=ALkJrhhHmXEQ5QAVp6iZD69TiRjsx2-2Tg" frameborder="0" allowfullscreen=""></iframe><br>  As a result, the problem is solved, the resulting script can be placed on the Kurento server and run it on a schedule.  After successfully uploading the created video files to the WebDAV server, you can delete the original files, thus archiving the video for later viewing in a readable form. <br></div><p>Source: <a href="https://habr.com/ru/post/277179/">https://habr.com/ru/post/277179/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../277167/index.html">Remote debugging javascript with VS2015. Part 3 (F12 Chooser)</a></li>
<li><a href="../277169/index.html">Will React Native fulfill the programmer‚Äôs dream: single code for web, android and ios?</a></li>
<li><a href="../277171/index.html">Router for Matreshka.js 2</a></li>
<li><a href="../277173/index.html">Critical Vulnerability in Cisco ASA</a></li>
<li><a href="../277177/index.html">Measuring performance using BenchmarkDotNet</a></li>
<li><a href="../277183/index.html">Example module for Magento 2 in a different way</a></li>
<li><a href="../277185/index.html">The digest of interesting materials for the mobile developer # 140 (on February 8-14)</a></li>
<li><a href="../277189/index.html">Putting XGBoost under OS X</a></li>
<li><a href="../277191/index.html">Ballad about SharePoint</a></li>
<li><a href="../277193/index.html">The digest of interesting materials from the world of web development and IT for the last week ‚Ññ198 (February 7 - 14, 2016)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>