<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Analysis of implicit user preferences. Scientific and Technical Workshop in Yandex</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="The analysis of implicit user preferences expressed in links and the duration of page views is the most important factor in ranking documents in searc...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Analysis of implicit user preferences. Scientific and Technical Workshop in Yandex</h1><div class="post__text post__text-html js-mediator-article">  The analysis of implicit user preferences expressed in links and the duration of page views is the most important factor in ranking documents in search results or, for example, showing advertisements and recommending news.  Click analysis algorithms are well studied.  But is it possible to find out something else about the individual preferences of a person, using more information about his behavior on the site?  It turns out that the trajectory of the mouse movement allows you to find out which parts of the document you are viewing are interested in the user. <br><br>  This issue was devoted to a study conducted by me, <a href="http://tech.yandex.ru/people/144042/">Mikhail Ageev</a> , together with Dmitry Lagun and Evgeny Agishtein at <a href="http://ir.mathcs.emory.edu/">Emory Intelligent Information Access Lab of the</a> University of Emory. <br><br><iframe src="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://video.yandex.ru/iframe/ya-events/m-42221-1503f41408f-f3e9c72d5c19289/&amp;xid=17259,15700002,15700021,15700186,15700190,15700253&amp;usg=ALkJrhhijdHCasqyMeSHwcHayMLOsZ7mew" width="450" height="146" frameborder="0" scrolling="no" allowfullscreen="1"></iframe>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <div class="slideshow"><iframe src="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=http://www.slideshare.net/slideshow/embed_code/27694001&amp;xid=17259,15700002,15700021,15700186,15700190,15700253&amp;usg=ALkJrhgopboLUS-OoOMObNfE65PW-Hn3Sw" width="425" height="355" frameborder="0" marginwidth="0" marginheight="0" scrolling="no"></iframe></div><br>  We studied data collection methods and algorithms for analyzing user behavior by mouse movements, as well as the possibilities of using these methods in practice.  They allow you to significantly improve the formation of snippets (annotations) of documents in search results.  The work with the description of these algorithms was awarded the Best Paper Shortlisted Nominee diploma at the 2013 ACM SIGIR international conference.  Later I presented a report on the results of the work done in the framework of scientific and technical seminars in Yandex.  His summary you will find under the cut. <br><a name="habracut"></a><br>  Snippets are the most important part of any search engine.  They help users search for information, and the usability of a search engine depends on their quality.  A good snippet should be readable, should show the parts of the document that match the user's request.  Ideally, the snippet should contain a direct answer to the user's question or an indication that the answer is in the document. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/3bd/ce7/769/3bdce77697784b83893cfc37d432eb3a.png" width="640"><br><br>  The general principle is that the query text is matched with the text of the document, which highlights the most relevant sentences containing the query words or query extensions.  The formula for calculating the most relevant fragments takes into account matches with the query.  The density of the text, the location of the text, the structure of the document is taken into account.  However, for highly relevant documents that pop up at the top of the search results, textual factors are often not enough.  The text may repeatedly contain words from the query, and it is impossible to determine which parts of the text answer the user's question based on textual information only.  Therefore, additional factors are required. <br><br>  When viewing the page, the user's attention is distributed unevenly.  The focus is on those fragments that contain the desired information. <br><br>  We conducted experiments using equipment that monitors the movement of the eye pupil with an accuracy of several dozen pixels.  Here is an example of the distribution of the thermal map of the user's pupil's trajectory, which looked for the answer to the question of how many dead pixels should be on the iPad 3 so that it can be replaced under warranty.  He enters a query [how many dead pixels ipad 3 replace], which leads him to the Apple Community Forums page with a similar question.  On the page, the words from the request are encountered many times, however, the user focuses on the fragment that actually contains the answer, as can be seen on the heat map. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/9c5/e51/06a/9c5e5106a88920666f5d8590c183e5b4.png" width="640"><br><br>  If we could track and analyze the movements of the pupils of a larger number of users, we could only select ideal snippets for various requests based on this data.  The problem is that the users do not have the means for light tracking, so you need to look for other ways to obtain the necessary information. <br><br>  When browsing web documents, users usually make mouse movements that scroll pages.  In their article of 2010, K. Guo and E. Agishtein note that along the trajectory, it is possible to predict the movement of the eye pupil with an accuracy of 150 pixels and a fullness of 70%. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/383/eb4/bc2/383eb4bc2eb3d1bfd15e1590e76bc382.png" width="640"><br><br>  Below is a thermal map of mouse movements when viewing a document found on the query [worst drought in US].  It can be seen that the greatest activity can be traced precisely on a fragment containing information about the strongest droughts in the United States; it is from this that the perfect snippet can be formed. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/011/c02/792/011c027923a9e75c19a21146dfe063aa.png" width="640"><br><br>  The idea of ‚Äã‚Äãour study is that data on mouse movements can be collected using the JavaScript API that works in most browsers.  By user behavior, we can predict which fragments contain relevant information for the request, and then use this data to improve the quality of the snippets.  In order to implement and test this idea, you need to solve several problems.  First, you need to understand how to collect realistic and fairly large-scale data on user behavior behind the search results page.  Secondly, you need to learn from the mouse movements to determine the fragments most interesting to the user.  Users have different habits: some like to select a readable text or just hover the mouse on it, others open the document and read it from top to bottom, occasionally flipping it down.  In this case, users may have different browsers and input devices.  In addition, the amount of data on mouse movements is two orders of magnitude higher than the amount of data on clicks.  There is also the task of combining behavioral factors with traditional textual ones. <br><br><h4>  How to collect data </h4><br>  To collect data, we used the infrastructure developed by us in 2011. The main idea is to create a game like Yandex search cup.  The player is set a goal for a limited time using the search engine to find the answer to the question on the Internet.  The player finds the answer and sends it to us along with the URL of the page where it was found.  Selection of participants takes place through Amazon Mechanical Turk.  Each game consists of 12 questions.  For participation in a game of about forty minutes, a guaranteed payment of $ 1 is assumed.  Another one dollar get 25% of the best players.  This is a fairly cheap way to collect data, which at the same time provides a wide variety of users from all over the world.  Questions were taken on sites Wiki.answers.com, Yahoo!  Answers and the like.  The main condition was the lack of ready-made answers on these sites themselves.  At the same time, the questions should not be too simple, but have a clear short answer that can be found on the Internet.  To cut off robots and unscrupulous participants, it was necessary to implement several stages of testing the quality of the results.  First, there is a captcha at the entrance to the system, secondly, the user needs to answer 1-2 trivial questions, and third, the user must perform the task using our proxy server, thanks to which we can verify that he really asked questions to the search engine and visited the page with the answer. <br><br>  Using standard modules for the Apache HTTP server mod_proxy_html and mod_sed, we implemented proxying of all calls to search services.  The user came to our page, saw the familiar search engine interface, but all the links there were replaced with ours.  By clicking on such a link, the user got to the desired page, but our JavaScript code that tracks behavior has already been embedded in it. <br><br>  When logging there is a small problem: the position of the mouse is represented by coordinates in the browser window, and the coordinates of the text in it depend on the screen resolution, version and settings.  We need an exact binding precisely to the text.  Accordingly, we need to calculate the coordinates of each word on the client and store this information on the server. <br><br>  The results of the experiments were the following data: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/316/95c/374/31695c374057240de058432ac687d69c.png" width="640"><br><br>  From a statistical point of view, the data is as follows: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/6d7/3cd/a5a/6d73cda5a442bd09e0f524dfd49be382.png" width="640"><br><br>  The code and collected data are freely available at this <a href="http://ir-ub.mathcs.emory.edu/BeBS/">link</a> . <br><br><h4>  Prediction of fragments that interested users </h4><br>  To select snippets, the text is divided into fragments of five words.  For each fragment, six behavioral factors are identified: <br><br><ul><li>  The duration of the cursor over the fragment; </li><li>  The duration of the cursor next to the fragment (¬± 100px); </li><li>  The average speed of the mouse over the fragment; </li><li>  The average speed of the mouse next to the fragment; </li><li>  Show time of the fragment in the visible part of the viewing window (scrollabar); </li><li>  The time the fragment is displayed in the middle of the viewport. </li></ul><br>  With the help of machine learning, all these six factors are rolled into one number ‚Äî the probability of a fragment's interestingness.  But first we need to create a training set.  At the same time, we do not know for certain what really interested the reader, what he read, and where he found the answer.  But we can take as positive examples fragments that overlap with the user's response, and all other fragments as negative examples.  This training set is inaccurate and incomplete, but it is quite enough for learning the algorithm and improving the quality of snippets. <br><br>  The first experiment is to test the adequacy of our model.  We have trained an algorithm for predicting the interestingness of a fragment on one set of pages and apply it to another set.  The graph on the x-axis shows the predicted probability of the fragment interestingness, and on the y-axis the average value of the fragment intersection measure with the user‚Äôs response: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/ca6/dd6/c9e/ca6dd6c9e6d60a5d9899327b51a0f6eb.png" width="640"><br><br>  We see that if the algorithm is to a large extent certain that the fragment is good, then this fragment has a large intersection with the user's response. <br><br>  When building a machine learning method, the most important factors were DispMiddleTime (the time during which a fragment of text was visible on the screen) and MouseOverTime (the time during which the mouse cursor was over a fragment of text). <br><br>
<h4>  Improving snippets based on behavioral analysis </h4><br>  So, we can determine which fragments interested the user.  How can we use this to improve snippets?  As a starting point, we implemented a modern algorithm for generating snippets, published by researchers from Yahoo!  in 2008.  For each sentence, a set of textual factors is computed and a machine learning method is constructed to predict the quality of the fragment in terms of snippet extraction using assessment assessments on a scale {0,1}.  Then several machine learning methods are compared: <a href="http://en.wikipedia.org/wiki/Support_vector_machine">SVM</a> , <a href="http://en.wikipedia.org/wiki/Ranking_SVM">ranking SVM</a> and <a href="http://en.wikipedia.org/wiki/Gradient_boosting">GBDT</a> .  We added more factors and expanded the rating scale to {0,1,2,3,4,5}.  For the formation of a snippet, one to four sentences are selected from the best set.  Fragments are selected using a greedy algorithm that collects fragments with total best weight. <br><br>  We use the following set of textual factors: <br><br><ul><li>  Exact match; </li><li>  Number of query words and synonyms found (3 factors); </li><li>  <a href="http://ru.wikipedia.org/wiki/Okapi_BM25">BM25-</a> like (4 factors); </li><li>  The distance between the query words (3 factors); </li><li>  The length of the sentence; </li><li>  Position in the document; </li><li>  Readability: the number of punctuation marks, headwords, various words (9 factors). </li></ul><br>  Now that we have a fragment weight in terms of textual relevance, we need to combine it with the fragment interestingness factor calculated from the user's behavior.  We use a simple linear combination of factors, and the weight Œª in the formula for calculating the quality of a fragment is the weight of behavior. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/060/2c7/a33/0602c7a3302b03024911de7414d73135.png" width="640"><br><br>  We need to choose the right weight Œª.  There are two extremes: if the value of Œª is too small, then the behavior is not taken into account and the snippets are different from the baseline, if the value of Œª is too large, there is a risk that we will lose as snippets.  To select Œª, we conduct an experiment with the choice of five values ‚Äã‚Äãfrom zero to one {0.1.0.3.0.5.0.7.0.9}.  To compare the experiments, we scored assessors who compared snippets in pairs according to three criteria: <br><br><ul><li>  <b>Representativeness:</b> which snippet better reflects the document compliance with the query?  You must read the document before answering the question. </li><li>  <b>Readability:</b> which <b>snippet is</b> better written, easier to read? </li><li>  <b>Judjeability:</b> which of the snippets best helps to find the relevant answer and decide whether to click on the link? </li></ul><br>  The graphs below show the proportions of pairs of snippets in which the behavioral algorithm showed an improvement in quality for three criteria and five values ‚Äã‚Äãof Œª.  For each of the values ‚Äã‚Äãof Œª, assessors gave a different number of assessments, and different numbers of snippets differ in quality.  Therefore, the confidence intervals for each of Œª are somewhat different.  We see that for Œª = 0.7 we get a statistically significant improvement in the quality of the snippet for each of the criteria.  Coverage for these snippets is also quite large: 40% of snippets with regard to behavior differ from the baseline. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/52a/8da/8fd/52a8da8fda1e94b4239b3e5e383a1f48.png" width="640"><br><br><h4>  Basic assumptions and limitations of the considered approach </h4><br>  Firstly, experiments were conducted on informational questions, when the user searches for the text of the answer in documents.  However, there are other types of user intent: for example, commercial, navigation.  For such requests, behavioral factors may cause interference, or require another way of accounting.  Secondly, according to the experiment, we assume that page views are grouped by information need.  In our experiments, all users for each pair of document request were looking for the same thing.  Therefore, we aggregate data for all users, calculating the average value of the fragment weight for all users.  In the real world, users can ask the same query and view the same document for different purposes.  And for each request we need to group users by intent in order to be able to apply these methods and aggregate these behaviors.  And thirdly, to introduce this technology into a real system, you need to find a way to collect data on user behavior.  There are already browser plugins, ad networks and visitor counters that collect data on user clicks.  Their functionality can be expanded by adding the ability to collect data on mouse movements. <br><br>  Among other uses of the method are the following: <br><br><ul><li>  Improved Click Model by predicting P (Examine | Click = 0).  If we only track clicks, then we can‚Äôt say with certainty why the user didn‚Äôt click on the link in the search results.  He could read the snippet, and decide that the document is irrelevant, or he simply did not see the document.  With the use of mouse tracking, this problem disappears, and we can significantly improve the prediction of the relevance of the document. </li><li>  Behavior of users on mobile devices. </li><li>  Classification of mouse movements by intent.  If you complicate the model, you can learn to distinguish random mouse movements from intentional ones, when the user really helps himself to read with the cursor.  In addition, you can take into account moments of inactivity as one of the additional signs of interest of the fragment. </li></ul><br><br>  After the report, a session of questions and answers took place, which can be viewed on <a href="http://tech.yandex.ru/events/science-seminars/Ageev-17Oct/talks/1369/">video</a> . </div><p>Source: <a href="https://habr.com/ru/post/223121/">https://habr.com/ru/post/223121/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../223109/index.html">Moving from MongoDB Full Text to ElasticSearch</a></li>
<li><a href="../223111/index.html">Vraschete - social and economic network</a></li>
<li><a href="../223115/index.html">In defense of javascript: void (0);</a></li>
<li><a href="../223117/index.html">Skylock - wireless bicycle lock on solar batteries</a></li>
<li><a href="../223119/index.html">What to read on the weekend. Digest news of the gaming industry</a></li>
<li><a href="../223123/index.html">How to assemble a 3D printer in Russia and why I went to do it in China</a></li>
<li><a href="../223125/index.html">Automate toilet flush on Arduino + Z-Wave</a></li>
<li><a href="../223131/index.html">JetBrains EdTech Hackathon results</a></li>
<li><a href="../223133/index.html">MSI S12 Netbook Review</a></li>
<li><a href="../223135/index.html">The script that handles system events with DBus</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>