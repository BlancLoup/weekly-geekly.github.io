<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Machine vision. What is it and how to use it? Optical source image processing</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Machine vision is a scientific direction in the field of artificial intelligence, in particular robotics, and related technologies for obtaining image...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Machine vision. What is it and how to use it? Optical source image processing</h1><div class="post__text post__text-html js-mediator-article">  <b>Machine vision</b> is a scientific direction in the field of artificial intelligence, in particular robotics, and related technologies for obtaining images of real-world objects, processing them, and using the obtained data to solve various kinds of applied tasks without the participation of (full or partial) man. <br><br><img src="https://habrastorage.org/webt/lq/sl/7e/lqsl7e1hfx8sztyzvnecq3egetg.jpeg"><a name="habracut"></a><br><br><h2>  Historical breakthroughs in machine vision </h2><br><blockquote><ul><li>  1955 - Oliver Selfridge.  The article "Eyes and ears of a computer." </li><li>  1958 - Frank Rosenblatt.  Computer implementation of the perceptron. </li><li>  The 1960s are the first image processing systems. </li><li>  1970s - Lawrence Roberts.  The concept of machine construction of three-dimensional images of objects. </li><li>  1979 - Hans-Helmut Nagel.  Theory of the analysis of dynamic scenes. </li><li>  1990s - The first unmanned vehicle control systems. </li><li>  2003 - Corporate face recognition systems. </li></ul></blockquote><br><h2>  Machine Vision Components </h2><br><blockquote><ul><li>  One or more digital or analog cameras (black and white or color) with suitable optics for imaging </li><li>  Software for making images for processing.  For analog cameras, this is the image digitizer. </li><li>  Processor (modern PC with multi-core processor or embedded processor, for example, DSP) </li><li>  Machine vision software that provides tools for the development of individual software applications. </li><li>  I / O equipment or communication channels for the results report </li><li>  Smart camera: one device that includes all the above items. </li><li>  Very specialized light sources (LEDs, fluorescent and halogen lamps, etc.) </li><li>  Specific software applications for image processing and detection of relevant properties. </li><li>  A sensor to synchronize detection parts (often an optical or magnetic sensor) for capturing and processing images. </li><li>  Drives of a certain form used to sort or discard defective parts. </li></ul></blockquote>  Machine vision focuses on the use of, mainly industrial, for example, autonomous robots and visual inspection and measurement systems.  This means that the technology of image sensors and control theory is associated with the processing of video data to control the robot and the processing of the received data in real time is carried out by software or hardware. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Image processing and image analysis are mainly focused on working with 2D images, i.e.  how to convert one image to another.  For example, pixel-by-pixel operations to increase contrast, operations to highlight edges, eliminate noise, or geometric transformations, such as rotating an image.  These operations assume that image processing / analysis acts independently of the content of the images themselves. <br><br>  Computer vision focuses on processing three-dimensional scenes designed for one or more images.  For example, by restoring a structure or other information about a 3D scene from one or more images.  Computer vision often depends on more or less complex assumptions about what is represented in the images. <br><br>  There is also an area called visualization, which was originally associated with the process of creating images, but sometimes dealt with processing and analysis.  For example, radiography works with the analysis of video data for medical use. <br><br>  Finally, pattern recognition is an area that uses various methods to obtain information from video data, mainly based on a statistical approach.  Much of this area is devoted to the practical application of these methods. <br><br>  Thus, we can conclude that the concept of ‚Äúmachine vision‚Äù today includes: computer vision, recognition of visual images, analysis and image processing, etc. <br><br><h2>  Tasks of machine vision </h2><br><blockquote><ul><li>  Recognition </li><li>  Identification </li><li>  Detection </li><li>  Text recognising </li><li>  Restoration of 3D forms from 2D images </li><li>  Motion estimation </li><li>  Scene restoration </li><li>  Image Recovery </li><li>  Selection on images of structures of a certain type, image segmentation </li><li>  Optical flow analysis </li></ul></blockquote><br><h2>  Recognition </h2><br><img src="https://habrastorage.org/getpro/habr/post_images/787/f02/70f/787f0270fa4b4d889f6d3bc69bd9a668.jpg"><br><br>  The classical problem in computer vision, image processing and computer vision is the definition of whether the video data contains some characteristic object, feature or activity. <br><br>  This task can be reliably and easily solved by man, but it has not been solved satisfactorily in computer vision in the general case so far: random objects in random situations. <br><br>  One or more predefined or studied objects or classes of objects can be recognized (usually together with their two-dimensional position in the image or three-dimensional position in the scene). <br><br><h2>  Identification </h2><br><img src="https://habrastorage.org/getpro/habr/post_images/07f/b45/917/07fb45917761ff7bdd522c2d5f3965c6.jpg"><br><br>  An individual instance of an object belonging to a class is recognized. <br>  Examples: the identification of a specific human face or fingerprint or car. <br><br><h2>  Detection </h2><br><img src="https://habrastorage.org/getpro/habr/post_images/6e3/c34/8f3/6e3c348f313300fc46ec47f61b524b5f.jpg"><br><br>  Video data are checked for a specific condition. <br><br>  Detection based on relatively simple and fast calculations is sometimes used to find small areas in the analyzed image, which are then analyzed using techniques that are more demanding of resources to get the correct interpretation. <br><br><h2>  Text recognising </h2><br><img src="https://habrastorage.org/getpro/habr/post_images/33b/457/434/33b45743479021b83d48ab0fabb90249.jpg"><br><br>  Search for images by content: finding all the images in a large set of images that have content defined in various ways. <br><br>  Position evaluation: determining the position or orientation of a particular object relative to the camera. <br><br>  Optical character recognition: character recognition on images of typed or handwritten text (usually for translation into the text format most suitable for editing or indexing. For example, ASCII). <br><br><img src="https://habrastorage.org/getpro/habr/post_images/55a/56b/a5b/55a56ba5b6f45644815390e1f6dca962.png"><br><br>  Restoration of 3D shape from 2D images is performed using stereo-construction of the depth map, reconstruction of the normal field and depth map from the halftone image, reconstruction of the depth map from the texture and shape determination from the movement <br><br>  An example of the restoration of 3D shapes in 2D image <br><br><img src="https://habrastorage.org/webt/db/l5/nq/dbl5nqgrwtkijjtikipvuiroenu.jpeg"><br><br><h2>  Motion estimation </h2><br>  Several tasks related to motion estimation, in which a sequence of images (video data) are processed to find an estimate of the speed of each point of the image or 3D scene.  Examples of such tasks are: determining the three-dimensional movement of the camera, tracking, that is, following the movement of an object (for example, cars or people) <br><br><h2>  Scene restoration </h2><br>  Given two or more images of the scene, or video.  Scene restoration has the task to recreate the three-dimensional model of the scene.  In the simplest case, the model may be a set of points of three-dimensional space.  More complex methods reproduce the full three-dimensional model. <br><br><h2>  Image Recovery </h2><br><img src="https://habrastorage.org/webt/7o/bp/_i/7obp_i6jhrhjxznssmo3ocrqbsc.jpeg"><br><br>  The task of image restoration is noise removal (sensor noise, motion blur, etc.). <br><br>  The simplest approach to solving this problem are various types of filters, such as low or medium frequency filters. <br><br>  A higher level of noise removal is achieved during the initial analysis of video data for the presence of various structures, such as lines or borders, and then controlling the filtering process based on this data. <br><br><h2>  Image Recovery </h2><br>  Optical flow analysis (finding the movement of pixels between two images). <br>  Several tasks related to motion estimation, in which a sequence of images (video data) are processed to find an estimate of the speed of each point of the image or 3D scene. <br><br>  Examples of such tasks are: definition of three-dimensional camera movement, tracking, i.e.  following the movement of an object (for example, cars or people). <br><br><h2>  Image processing methods </h2><br><blockquote><ul><li>  Pixel count </li><li>  Binarization </li><li>  Segmentation </li><li>  Barcode reading </li><li>  Optical character recognition </li><li>  Measurement </li><li>  Edge detection </li><li>  Pattern matching </li></ul></blockquote><br><h2>  Pixel count </h2><br>  Counts the number of light or dark pixels. <br>  Using the pixel counter, the user can select a rectangular area on the screen in a place of interest, for example, where he expects to see the faces of people passing by.  The camera will immediately respond with information about the number of pixels represented by the sides of the rectangle. <br><br>  The pixel counter allows you to quickly check whether the mounted camera complies with regulatory requirements or customer requirements regarding pixel resolution, for example, for the faces of people entering the doors controlled by the camera, or for license plate recognition. <br><br><h2>  Binarization </h2><br><img src="https://habrastorage.org/webt/zd/93/6i/zd936ibtxom9c4jwxll0ae8zzg0.png"><br><br>  Converts an image in grayscale to binary (white and black pixels). <br>  The values ‚Äã‚Äãof each pixel are conventionally encoded as ‚Äú0‚Äù and ‚Äú1‚Äù.  The value "0" is conventionally called the background or background and "1" - the foreground. <br><br>  Often, when storing digital binary images, a bitmap is used, where one bit of information is used to represent one pixel. <br><br>  Also, especially in the early stages of the development of technology, the two possible colors were black and white, which is not mandatory. <br><br><h2>  Segmentation </h2><br>  Used for searching and / or counting parts. <br><br>  The goal of segmentation is to simplify and / or change the representation of the image so that it is easier and easier to analyze. <br><br>  Image segmentation is usually used to highlight objects and borders (lines, curves, etc.) in images.  More precisely, image segmentation is the process of assigning such labels to each pixel of an image that pixels with the same labels have common visual characteristics. <br><br>  The result of image segmentation is a set of segments that together cover the entire image, or a set of contours, separated from the image.  All pixels in a segment are similar in some characteristic or computed property, for example, in color, brightness, or texture.  Neighboring segments differ significantly in this characteristic. <br><br><h2>  Barcode reading </h2><br><img src="https://habrastorage.org/webt/t6/am/4k/t6am4kiimi3vy3bfafcnxf7iksy.jpeg"><br><br>  Barcode - graphic information applied to the surface, marking or packaging of products, representing the possibility of reading it with technical means - a sequence of black and white stripes or other geometric shapes. <br>  In machine vision, bar codes are used to decode 1D and 2D codes designed to be read or scanned by machines. <br><br><h2>  Optical character recognition </h2><br>  Optical character recognition: automated text reading, such as serial numbers. <br><br>  Recognition is used to convert books and documents into electronic form, to automate business accounting systems, or to publish text on a web page. <br><br>  OCR allows you to edit text, search for words or phrases, store it in a more compact form, display or print material without losing quality, analyze information, and also apply electronic translation, formatting, or conversion to speech to text. <br><br><h2>  My program, written in LabView on working with images </h2><br>  Used computer vision for non-destructive quality control of superconducting materials. <br><br>  <b>Introduction</b>  Solving the tasks of ensuring integrated security (both the antiterrorist and mechanical security of facilities and the technological security of engineering systems) currently requires the system organization of control, the current state of facilities.  One of the most promising ways to control the current state of objects is optical and optical-electronic methods based on video image processing technologies of an optical source.  These include: programs for working with images;  newest image processing;  equipment for image acquisition, analysis and processing, i.e.  a complex of tools and methods relating to the field of computer and computer vision.  Computer vision is a common set of methods that allow computers to see and recognize three- or two-dimensional objects, both engineering and non-engineering.  To work with computer vision, digital or analog I / O devices are required, as well as computer networks and IP location analyzers designed to monitor the production process and prepare information for making operational decisions in the shortest possible time. <br><br>  <b>Formulation of the problem.</b>  Today, the main task for the designed machine vision complexes remains the detection, recognition, identification and qualification of potential risk objects located in a random place in the operational area of ‚Äã‚Äãthe complex.  Currently existing software products aimed at solving the listed problems have a number of significant drawbacks, namely: significant complexity associated with the high detail of optical images;  high power consumption and a fairly narrow range of possibilities.  Extending the tasks of detecting objects of potential risk to the area of ‚Äã‚Äãsearching for random objects in random situations that are in a random place is not possible with available software products, even with the use of a supercomputer. <br><br>  <b>Purpose.</b>  Development of a universal program for processing images of an optical source, with the possibility of streaming data analysis, that is, the program must be easy and fast so that it can be recorded on a small-sized computer device. <br><br>  <b>Tasks:</b> <br><blockquote><ul><li>  development of a mathematical model of the program; </li><li>  writing a program; </li><li>  testing of the program in a laboratory experiment, with full preparation and conduct of the experiment; </li><li>  study of the possibility of applying the program in related areas of activity. </li></ul></blockquote><br>  <b>The relevance of the program is determined by:</b> <br><blockquote><ul><li>  the absence of image processing software on the software market with a detailed analysis of the engineering components of the objects; </li><li>  the ever-growing demands for quality and speed of obtaining visual information that dramatically increase the demand for image processing programs; </li><li>  the existing need for high-performance programs that are reliable and simple from the user's point of view; </li><li>  the high cost of professional visual processing software. </li></ul></blockquote><br>  <b>Analysis of the relevance of the program.</b> <br><blockquote><ul><li>  the absence of image processing software on the software market with a detailed analysis of the engineering components of the objects; </li><li>  the ever-growing demands for quality and speed of obtaining visual information that dramatically increase the demand for image processing programs; </li><li>  the existing need for high-performance programs that are reliable and simple from the user's point of view; </li><li>  there is a need for high performance programs and simple control, which is extremely difficult to achieve in our time.  For example, I took Adobe Photoshop.  This graphic editor has a harmonious combination of functionality and ease of use for an ordinary user, but in this program it is impossible to work with complex tools for image processing (for example, image analysis by building a mathematical dependence (function) or integral image processing); </li><li>  the high cost of professional visual processing software.  If the software is of high quality, then the price for it is extremely high, down to the individual functions of one or another set of programs.  The graph below shows the price / quality relationship of simple program analogues. </li></ul></blockquote><br>  To simplify the solution of problems of this type, I developed a mathematical model and wrote a program for a computer device for image analysis using the simplest transformations of the original images. <br><br>  The program works with conversions such as binarization, brightness, image contrast, etc.  The principle of the program is demonstrated by the example of the analysis of superconducting materials. <br><br>  When creating composite superconductors based on Nb3Sn, the volume ratio of bronze and niobium varies, the size and number of fibers in it, the uniformity of their distribution over the cross section of the bronze matrix, the presence of diffusion barriers and stabilizing materials.  For a given volume fraction of niobium in the conductor, an increase in the number of fibers leads, respectively, to a decrease in their diameter.  This leads to a noticeable increase in the Nb / Cu ‚Äì Sn interaction surface, which greatly accelerates the growth process of the superconducting phase.  Such an increase in the number of the superconducting phase with an increase in the number of fibers in the conductor provides an increase in the critical characteristics of the superconductor.  In this regard, it is necessary to have a tool to control the volume fraction of the superconducting phase in the final product (composite superconductor). <br><br>  When creating the program, the importance of conducting research on the materials from which superconducting cables are created was taken into account, since if the ratio of niobium to bronze is incorrect, an explosion of wires is possible, and, consequently, human sacrifice, monetary costs and loss of time.  This program allows you to determine the quality of the wires on the basis of chemical physical analysis of the object. <br><br>  <b>Program block diagram</b> <br><img src="https://habrastorage.org/webt/lr/yy/sm/lryysmja_cko9pa5stvtk4ekp_g.png"><br>  <b>Description of the stages of the study.</b> <br><br>  <b>Stage 1.</b>  Sample preparation: cutting of a composite superconductor on an EDM machine;  pressing the sample into the plastic matrix;  polishing the sample to a mirror state;  etching a sample to isolate niobium fibers on a bronze matrix.  Samples of pressed composite superconducting samples were obtained; <br><br>  <b>Stage 2</b>  Image acquisition: metallographic imaging on a scanning electron microscope. <br><br>  <b>Stage 3</b>  Image processing: creating a tool for determining the volume fraction of the superconducting phase in a metallographic image;  a set of statistically significant data on a specific type of sample.  Created mathematical models of various tools for image processing;  a software development was created to estimate the volume fraction of the superconducting phase;  the program was facilitated by combining several mathematical functions into one;  An average value of the volume fraction of niobium fibers in a bronze matrix of 24.7 ¬± 0.1% was obtained.  A low deviation rate indicates a high repeatability of the composite wire structure. <br><br>  <b>Electron microscopic images of composite superconductors</b> <br><br><img src="https://habrastorage.org/webt/p4/cp/wk/p4cpwkjrysuyzh2umaaaw5ltsvy.jpeg"><br><br>  <b>Methods of image processing in the program.</b> <br><blockquote><ul><li>  <b>Identification</b> - an individual instance of an object belonging to a class is recognized. </li><li>  <b>Binarization</b> is the process of converting a color (or in grayscale) image into a two-color black and white. </li><li>  <b>Segmentation</b> is the process of dividing a digital image into several segments (multiple pixels, also called superpixels). </li><li>  <b>Erosion</b> is a complex process in which the structural element passes through all the pixels of the image.  If at some position each unit pixel of the structural element coincides with the unit pixel of the binary image, then the logical addition of the central pixel of the structural element with the corresponding pixel of the output image is performed. </li><li>  <b>Dilatation</b> is a convolution of an image or a selected area of ‚Äã‚Äãan image with some kernel.  The kernel can have any shape and size.  In this case, the only leading position in the kernel is allocated, which is combined with the current pixel in the calculation of convolution. </li></ul></blockquote><br>  <b>Formulas of the program</b> <br><br>  <b>Binarization formula (Otsu method):</b> <br><br><img src="https://habrastorage.org/webt/hn/sv/ou/hnsvoutc_djopovzahy9codbd6e.jpeg"><br><br>  <b>Formula of erosion:</b> <img src="https://habrastorage.org/webt/2u/zm/a_/2uzma_mga0r_beooo6fs-a_gatk.jpeg"><br><br>  <b>Dilatation formula:</b> <img src="https://habrastorage.org/webt/lw/dy/gr/lwdygrk_-awvq4ul8-ydyj3bzjo.jpeg"><br><br>  <b>Dilation and erosion pattern</b> <br><img src="https://habrastorage.org/webt/ye/d8/we/yed8wehnjkuedkpi_ic1ug6ipb4.jpeg"><br><br>  <b>Segmentation formulas by color thresholds:</b> <br><br>  Determining the magnitude of the gradient of brightness for each pixel of the image: <img src="https://habrastorage.org/webt/u2/ko/zm/u2kozmr7gqudtga55mdyt2pseey.jpeg"><br><br>  Threshold Calculation: <img src="https://habrastorage.org/webt/rv/n2/su/rvn2suivmwcb9yl-caebfllb8sg.jpeg"><br><br>  <b>Used equipment</b> <br><blockquote><ul><li>  CHMER GX-320L CNC - machine for EDM cutting samples </li><li>  SimpliMet 1000 - hot pressing machine </li><li>  AutoMet 250 Buehler - grinding and polishing machine </li><li>  Axio Scope A1 Carl Zeiss - optical microscope for quality control of thin sections </li><li>  Hitachi TM-1000 - scanning electron microscope for metallographic images </li></ul></blockquote><br>  <b>Program interface</b> <br><img src="https://habrastorage.org/webt/wf/pu/km/wfpukmqrgw2w1jiceow5mjeslc4.png"></div><p>Source: <a href="https://habr.com/ru/post/350918/">https://habr.com/ru/post/350918/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../350908/index.html">Programming for network engineers: the first case</a></li>
<li><a href="../350910/index.html">Create your cryptocics (Part 2)</a></li>
<li><a href="../350912/index.html">Why GitHub won't help hiring a developer</a></li>
<li><a href="../350914/index.html">MDM system without primary normalization. Actual approach to solving old problems</a></li>
<li><a href="../350916/index.html">What are programmers afraid of?</a></li>
<li><a href="../350920/index.html">FastTrack Training. "Network Basics". "Basics of data centers." Part 2. Eddie Martin. December 2012</a></li>
<li><a href="../350922/index.html">The digest of fresh materials from the world of the frontend for the last week ‚Ññ305 (March 5 - 11, 2018)</a></li>
<li><a href="../350924/index.html">Reducing the complexity of calculations in operations with vectors and matrices</a></li>
<li><a href="../350926/index.html">Algorithms in the industry: the theory of formal languages ‚Äã‚Äãand chat bots</a></li>
<li><a href="../350928/index.html">CNCF Open Source Solutions Guide (and more) for cloud native</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>