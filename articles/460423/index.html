<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>PostgreSQL WAL: 3. Checkpoint</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="We already got acquainted with the device of the buffer cache - one of the main objects in shared memory - and realized that in order to recover from ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>PostgreSQL WAL: 3. Checkpoint</h1><div class="post__text post__text-html js-mediator-article">  We already got acquainted with the device of the <a href="https://habr.com/ru/company/postgrespro/blog/458186/">buffer cache</a> - one of the main objects in shared memory - and realized that in order to recover from a crash, when the contents of the RAM disappear, we need to keep a <a href="https://habr.com/ru/company/postgrespro/blog/459250/">prerecord log</a> . <br><br>  The unresolved problem, on which we stopped last time, is that it is unknown from what point you can start playing log records during recovery.  Starting from the beginning, as advised by the King from <em>Alice</em> , will not work: it is impossible to keep all the journal entries from the start of the server - this is potentially a huge amount, and the same huge recovery time.  We need such a gradually advancing point from which we can begin the restoration (and, accordingly, we can safely delete all previous log entries).  This is the <em>reference point</em> , which will be discussed today. <br><br><h1>  Check Point </h1><br>  What property should a control point have?  We must be sure that all journal entries starting at the checkpoint will be applied to pages written to disk.  If this were not the case, during the recovery we could read from the disk too old version of the page and apply a journal entry to it, and thereby irrevocably damage the data. <br><a name="habracut"></a><br>  How to get a control point?  The easiest option is to periodically suspend the system and dump all dirty buffer pages and other caches to disk.  (Note that the pages are only recorded, but not crowded out of the cache.) Such points will satisfy the condition, but, of course, no one wants to work with the system, constantly freezing for an indefinite, but very significant time. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Therefore, in practice, everything is somewhat more complicated: the control point from a point turns into a segment.  First we <em>start the</em> control point.  After that, without interrupting the work and, if possible, without creating peak loads, we slowly dump dirty buffers onto the disk. <br><br><img src="https://habrastorage.org/webt/n0/ch/6f/n0ch6fdrfxkylmuqjdar7idfxsw.png"><br><br>  When all buffers that were dirty <em>at the start of the</em> control point were recorded, the control point is considered <em>complete</em> .  Now (but not before) we can use the <em>start</em> point as the point from which to start the recovery.  And the journal entries up to this point we no longer need. <br><br><img src="https://habrastorage.org/webt/q4/th/83/q4th83seql63dkrgfmg7esu3zh8.png"><br><br>  The checkpoint is performed by a checkpoint special background process. <br><br>  The duration of writing dirty buffers is determined by the value of the <em>checkpoint_completion_target</em> parameter.  It shows how much time between two adjacent control points will be recorded.  The default value is 0.5 (as in the figures above), that is, the record takes half the time between the control points.  Usually the value is increased up to 1.0 for greater uniformity. <br><br>  Let us take a closer look at what happens when a checkpoint is executed. <br><br>  First, the checkpoint process flushes transactional status (XACT) buffers to disk.  Since there are few of them (only 128), they are recorded immediately. <br><br>  Then the main work begins - writing dirty pages from the buffer cache.  As we have said, it is impossible to reset all pages at once, since the size of the buffer cache can be significant.  Therefore, first all currently dirty pages are marked in the buffer cache in the headers with a special flag. <br><br><img src="https://habrastorage.org/webt/_4/ym/eq/_4ymeqozl8o23kwq6su9ntvjujk.png"><br><br>  And then the checkpoint process gradually goes through all buffers and discards those marked on the disk.  Recall that the pages are not pushed out of the cache, but only written to disk, so no attention should be paid to the number of calls to the buffer, or to its fixation. <br><br>  Marked buffers can also be recorded by server processes - depending on who gets to the buffer first.  In any case, the previously set flag is cleared when writing, so (for control point purposes) the buffer will be recorded only once. <br><br>  Naturally, during the execution of the checkpoint, the pages continue to change in the buffer cache.  But new dirty buffers are not flagged and the checkpoint process should not record them. <br><br><img src="https://habrastorage.org/webt/fg/uo/vm/fguovmm8yzy0jb4jwisgg10nmm8.png"><br><br>  At the end of its work, the process creates a log entry about the end of the checkpoint.  This record contains the LSN of the starting point of the control point.  Since a checkpoint does not write anything to the log at the beginning of its work, any log entry can be found on this LSN. <br><br>  In addition, in the $ PGDATA / global / pg_control file, the indication of the last <em>passed</em> checkpoint is updated.  Before the checkpoint finishes, pg_control points to the previous checkpoint. <br><br><img src="https://habrastorage.org/webt/w0/cy/gi/w0cygixp3k4k3qscwfa2nlapqna.png"><br><br>  To look at the work of the control point, create some kind of table - its pages will fall into the buffer cache and will be dirty: <br><br><pre><code class="pgsql hljs">=&gt; <span class="hljs-keyword"><span class="hljs-keyword">CREATE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">TABLE</span></span> chkpt <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> * <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> generate_series(<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">10000</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> g(n); =&gt; <span class="hljs-keyword"><span class="hljs-keyword">CREATE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">EXTENSION</span></span> pg_buffercache; =&gt; <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> count(*) <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> pg_buffercache <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> isdirty;</code> </pre> <pre> <code class="plaintext hljs"> count ------- 78 (1 row)</code> </pre><br>  Remember the current position in the log: <br><br><pre> <code class="pgsql hljs">=&gt; <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> pg_current_wal_insert_lsn();</code> </pre><pre> <code class="plaintext hljs"> pg_current_wal_insert_lsn --------------------------- 0/3514A048 (1 row)</code> </pre><br>  Now we‚Äôll manually perform the checkpoint and make sure that there are no dirty pages left in the cache (as we said, new dirty pages may appear, but in our case no changes occurred during the checkpoint execution): <br><br><pre> <code class="pgsql hljs">=&gt; <span class="hljs-keyword"><span class="hljs-keyword">CHECKPOINT</span></span>; =&gt; <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> count(*) <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> pg_buffercache <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> isdirty;</code> </pre><pre> <code class="plaintext hljs"> count ------- 0 (1 row)</code> </pre><br>  Let's see how the reference point is reflected in the log: <br><br><pre> <code class="pgsql hljs">=&gt; <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> pg_current_wal_insert_lsn();</code> </pre><pre> <code class="plaintext hljs"> pg_current_wal_insert_lsn --------------------------- 0/3514A0E4 (1 row)</code> </pre><br><pre> <code class="plaintext hljs">postgres$ /usr/lib/postgresql/11/bin/pg_waldump -p /var/lib/postgresql/11/main/pg_wal -s 0/3514A048 -e 0/3514A0E4</code> </pre><pre> <code class="plaintext hljs">rmgr: Standby len (rec/tot): 50/ 50, tx: 0, lsn: 0/3514A048, prev 0/35149CEC, desc: RUNNING_XACTS nextXid 101105 latestCompletedXid 101104 oldestRunningXid 101105</code> </pre><pre> <code class="plaintext hljs">rmgr: XLOG len (rec/tot): 102/ 102, tx: 0, lsn: 0/3514A07C, prev 0/3514A048, desc: CHECKPOINT_ONLINE redo 0/3514A048; tli 1; prev tli 1; fpw true; xid 0:101105; oid 74081; multi 1; offset 0; oldest xid 561 in DB 1; oldest multi 1 in DB 1; oldest/newest commit timestamp xid: 0/0; oldest running xid 101105; online</code> </pre><br>  Here we see two entries.  The last of these is a checkpoint record (CHECKPOINT_ONLINE).  The LSN of the start of the checkpoint is indicated after the word redo, and this position corresponds to the log entry, which was the last one at the start of the checkpoint. <br><br>  We find the same information in the control file: <br><br><pre> <code class="plaintext hljs">postgres$ /usr/lib/postgresql/11/bin/pg_controldata -D /var/lib/postgresql/11/main | egrep 'Latest.*location'</code> </pre><pre> <code class="plaintext hljs">Latest checkpoint location: 0/3514A07C Latest checkpoint's REDO location: 0/3514A048</code> </pre><br><h1>  Recovery </h1><br>  Now we are ready to clarify the recovery algorithm outlined in the last article. <br><br>  If the server crashes, then the next time the startup process detects it, it will look in the pg_control file and see a status other than ‚Äúshut down‚Äù.  In this case, automatic recovery is performed. <br><br>  First, the recovery process reads from the same pg_control the position of the start of the checkpoint.  (For completeness, we note that if the backup_label file is present, then the checkpoint record is read from it ‚Äî this is necessary for restoring from backups, but this is a topic for a separate cycle.) <br><br>  Then he will read the magazine, starting from the position he has found, consistently applying journal entries to the pages (if there is a need for this, as we already discussed <a href="https://habr.com/ru/company/postgrespro/blog/459250/">last time</a> ). <br><br>  Finally, all non-journaling tables are overwritten with images in init files. <br><br>  At this point, the startup process terminates, and the checkpointer process immediately executes a checkpoint in order to fix the restored state on the disk. <br><br>  You can simulate a crash by forcibly stopping the server in immediate mode. <br><br><pre> <code class="plaintext hljs">student$ sudo pg_ctlcluster 11 main stop -m immediate --skip-systemctl-redirect</code> </pre><br>  (The <code>--skip-systemctl-redirect</code> key is needed here because PostgreSQL installed in Ubuntu is used from the package. It is controlled by the pg_ctlcluster command, which actually calls the systemctl, and it already calls pg_ctl. With all these wrappers, the mode name is lost along the way. And the <code>--skip-systemctl-redirect</code> key allows you to do without systemctl and save important information.) <br><br>  Check the status of the cluster: <br><br><pre> <code class="plaintext hljs">postgres$ /usr/lib/postgresql/11/bin/pg_controldata -D /var/lib/postgresql/11/main | grep state</code> </pre><pre> <code class="plaintext hljs">Database cluster state: in production</code> </pre><br>  When launched, PostgreSQL understands that a failure has occurred and a repair is required. <br><br><pre> <code class="plaintext hljs">student$ sudo pg_ctlcluster 11 main start</code> </pre><br><pre> <code class="plaintext hljs">postgres$ tail -n 7 /var/log/postgresql/postgresql-11-main.log</code> </pre><pre> <code class="plaintext hljs">2019-07-17 15:27:49.441 MSK [8865] LOG: database system was interrupted; last known up at 2019-07-17 15:27:48 MSK 2019-07-17 15:27:49.801 MSK [8865] LOG: database system was not properly shut down; automatic recovery in progress 2019-07-17 15:27:49.804 MSK [8865] LOG: redo starts at 0/3514A048 2019-07-17 15:27:49.804 MSK [8865] LOG: invalid record length at 0/3514A0E4: wanted 24, got 0 2019-07-17 15:27:49.804 MSK [8865] LOG: redo done at 0/3514A07C 2019-07-17 15:27:49.824 MSK [8864] LOG: database system is ready to accept connections 2019-07-17 15:27:50.409 MSK [8872] [unknown]@[unknown] LOG: incomplete startup packet</code> </pre><br>  The need for recovery is noted in the message log: <em>database system was not properly shut down;</em>  <em>automatic recovery in progress</em> .  Then, the replay of the journal entries starts from the position noted in ‚Äúredo starts at‚Äù and continues until the following journal entries are obtained.  This completes the restoration in the ‚Äúredo done at‚Äù position and the DBMS starts working with clients ( <em>database system is ready to accept connections</em> ). <br><br>  And what happens when the server stops normally?  To dump dirty pages to disk, PostgreSQL disables all clients and then executes the final checkpoint. <br><br>  Remember the current position in the log: <br><br><pre> <code class="pgsql hljs">=&gt; <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> pg_current_wal_insert_lsn();</code> </pre><pre> <code class="plaintext hljs"> pg_current_wal_insert_lsn --------------------------- 0/3514A14C (1 row)</code> </pre><br>  Now gently stop the server: <br><br><pre> <code class="plaintext hljs">student$ sudo pg_ctlcluster 11 main stop</code> </pre><br>  Check the status of the cluster: <br><br><pre> <code class="plaintext hljs">postgres$ /usr/lib/postgresql/11/bin/pg_controldata -D /var/lib/postgresql/11/main | grep state</code> </pre><pre> <code class="plaintext hljs">Database cluster state: shut down</code> </pre><br>  And in the journal we will find the only entry on the final control point (CHECKPOINT_SHUTDOWN): <br><br><pre> <code class="plaintext hljs">postgres$ /usr/lib/postgresql/11/bin/pg_waldump -p /var/lib/postgresql/11/main/pg_wal -s 0/3514A14C</code> </pre><pre> <code class="plaintext hljs">rmgr: XLOG len (rec/tot): 102/ 102, tx: 0, lsn: 0/3514A14C, prev 0/3514A0E4, desc: CHECKPOINT_SHUTDOWN redo 0/3514A14C; tli 1; prev tli 1; fpw true; xid 0:101105; oid 74081; multi 1; offset 0; oldest xid 561 in DB 1; oldest multi 1 in DB 1; oldest/newest commit timestamp xid: 0/0; oldest running xid 0; shutdown</code> </pre><pre> <code class="plaintext hljs">pg_waldump: FATAL: error in WAL record at 0/3514A14C: invalid record length at 0/3514A1B4: wanted 24, got 0</code> </pre><br>  (The terrible fatal message pg_waldump just wants to say about what he read to the end of the magazine.) <br><br>  Run the instance again. <br><br><pre> <code class="plaintext hljs">student$ sudo pg_ctlcluster 11 main start</code> </pre><br><h1>  Background record </h1><br>  As we found out, the control point is one of the processes that writes dirty pages from the buffer cache to disk.  But not the only one. <br><br>  If the backend needs to push the page out of the buffer, and the page is dirty, it will have to write it to disk on its own.  This is not a good situation, leading to expectations - much better when recording occurs asynchronously, in the background. <br><br>  Therefore, in addition to the checkpoint process (checkpointer), there is also <em>a background writing process</em> (background writer, bgwriter, or simply writer).  This process uses the same buffer search algorithm as the crowding mechanism.  By and large there are two differences. <br><br><ol><li>  Not a pointer to the ‚Äúnext victim‚Äù is used, but your own.  He may be ahead of the pointer to the "victim", but never lags behind him. </li><li>  Bypassing the buffers, the hit counter does not decrease. </li></ol><br>  Buffers are recorded, which simultaneously: <br><br><ul><li>  contain modified data (dirty) </li><li>  not fixed (pin count = 0) </li><li>  have zero number of calls (usage count = 0). </li></ul><br>  Thus, the background writing process runs ahead of the crowding out and finds those buffers that are likely to be crowded out soon.  Ideally, due to this, the servicing processes should find that the buffers selected by them can be used without stopping to write. <br><br><h1>  Customization </h1><br>  <em>The checkpoint process is</em> usually configured for the following reasons. <br><br>  First, we need to decide how much log files we can afford to save (and how much recovery time suits us).  The more, the better, but for obvious reasons this value will be limited. <br><br>  Further, we can calculate how much time this volume will be generated under normal load.  How to do this, we have already considered (you need to remember the position in the journal and subtract one from the other). <br><br>  This time will be our usual interval between control points.  We write it to the <em>checkpoint_timeout</em> parameter.  The default value - 5 minutes - is clearly too short, usually the time is increased, say, up to half an hour.  I repeat: the less often you can afford control points, the better - it reduces overhead. <br><br>  However, it is possible (and even likely) that the load will sometimes be higher than normal, and in the time specified in the parameter too much log entries will be generated.  In this case, I would like to perform the checkpoint more often.  For this, in the <em>max_wal_size</em> parameter <em>,</em> we specify the volume that is valid within one control point.  If the actual volume is received more, the server initiates an unscheduled checkpoint. <br><br>  Thus, most of the control points occur on a schedule: once in <em>checkpoint_timeout</em> time units.  But with increased load, the control point is called more often when the volume <em>reaches max_wal_size</em> . <br><br>  It is important to understand that the <em>max_wal_size</em> parameter does not define at all the maximum amount that the log files on the disk can occupy. <br><br><ul><li>  To recover from a failure, you need to store files from the time of the last passed checkpoint, plus the files that have accumulated during the running of the current checkpoint.  Therefore, the total amount can be roughly estimated as <br>  (1 + <em>checkpoint_completion_target</em> ) √ó <em>max_wal_size</em> . </li><li>  Up to version 11, PostgreSQL additionally stored files and for the time before last the checkpoint, so that up to version 10 in the above formula, instead of 1, it is necessary to put 2. </li><li>  The <em>max_wal_size</em> parameter is just a wish, but not a hard limit.  Maybe more. </li><li>  The server does not have the right to erase log files that have not yet been transferred through replication slots, and which have not yet been recorded in the archive with continuous archiving.  If this functionality is used, constant monitoring is necessary, because you can easily overwhelm the server memory. </li></ul><br>  For completeness, you can set not only the maximum volume, but also the minimum: the <em>min_wal_size</em> parameter.  The meaning of this setting is that the server does not delete files, as long as they fit into the volume <em>min_wal_size</em> , but simply renames them and uses them again.  This allows you to save a little on the constant creation and deletion of files. <br><br>  <em>The process of background recording</em> makes sense to set up after setting the control point.  Together, these processes must have time to write dirty buffers before they are required by the serving processes. <br><br>  The background writing process runs in cycles for a maximum of <em>bgwriter_lru_maxpages</em> pages, falling asleep between cycles on <em>bgwriter_delay</em> . <br><br>  The number of pages that will be recorded in one cycle of work is determined by the average number of buffers that have been requested by service processes since the last run (this uses a moving average to smooth out the unevenness between runs, but does not depend on a long history).  The calculated number of buffers is multiplied by the coefficient <em>bgwriter_lru_multiplier</em> (but in any case it will not exceed <em>bgwriter_lru_maxpages</em> ). <br><br>  Default values: <em>bgwriter_delay</em> = 200ms (most likely too much, in 1/5 of a second a lot of water will <em>leak</em> ), <em>bgwriter_lru_maxpages</em> = 100, <em>bgwriter_lru_multiplier</em> = 2.0 (trying to respond to demand ahead). <br><br>  If the process has not detected any dirty buffers at all (that is, nothing happens in the system), it ‚Äúhibernates‚Äù, from which it is deduced from the server process by the buffer.  After that, the process wakes up and again works in the usual way. <br><br><h1>  Monitoring </h1><br>  The setting of the checkpoint and the background recording can and should be adjusted by receiving feedback from the monitoring. <br><br>  The <em>checkpoint_warning</em> parameter displays a warning if checkpoints caused by log size overflow are performed too often.  Its default value is 30 seconds, and it must be aligned with the <em>checkpoint_timeout</em> value. <br><br>  The <em>log_checkpoints</em> parameter (disabled by default) allows you to receive information on running checkpoints in the server message log.  Turn it on. <br><br><pre> <code class="pgsql hljs">=&gt; <span class="hljs-keyword"><span class="hljs-keyword">ALTER</span></span> <span class="hljs-keyword"><span class="hljs-keyword">SYSTEM</span></span> <span class="hljs-keyword"><span class="hljs-keyword">SET</span></span> log_checkpoints = <span class="hljs-keyword"><span class="hljs-keyword">on</span></span>; =&gt; <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> pg_reload_conf();</code> </pre><br>  Now we change something in the data and execute the control point. <br><br><pre> <code class="pgsql hljs">=&gt; <span class="hljs-keyword"><span class="hljs-keyword">UPDATE</span></span> chkpt <span class="hljs-keyword"><span class="hljs-keyword">SET</span></span> n = n + <span class="hljs-number"><span class="hljs-number">1</span></span>; =&gt; <span class="hljs-keyword"><span class="hljs-keyword">CHECKPOINT</span></span>;</code> </pre><br>  In the message log we will see something like this: <br><br><pre> <code class="plaintext hljs">postgres$ tail -n 2 /var/log/postgresql/postgresql-11-main.log</code> </pre><pre> <code class="plaintext hljs">2019-07-17 15:27:55.248 MSK [8962] LOG: checkpoint starting: immediate force wait 2019-07-17 15:27:55.274 MSK [8962] LOG: checkpoint complete: wrote 79 buffers (0.5%); 0 WAL file(s) added, 0 removed, 0 recycled; write=0.001 s, sync=0.013 s, total=0.025 s; sync files=2, longest=0.011 s, average=0.006 s; distance=1645 kB, estimate=1645 kB</code> </pre><br>  Here you can see how many buffers were recorded, how the composition of the log files changed after the checkpoint, how long the checkpoint took and the distance (in bytes) between adjacent checkpoints. <br><br>  But probably the most useful information is the statistics of the work of the checkpoint process and the background record in the pg_stat_bgwriter view.  Presentation of one for two, because once both tasks were performed by one process;  then their functions were divided, and the presentation remained. <br><br><pre> <code class="pgsql hljs">=&gt; <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> * <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> pg_stat_bgwriter \gx</code> </pre><pre> <code class="plaintext hljs">-[ RECORD 1 ]---------+------------------------------ checkpoints_timed | 0 checkpoints_req | 1 checkpoint_write_time | 1 checkpoint_sync_time | 13 buffers_checkpoint | 79 buffers_clean | 0 maxwritten_clean | 0 buffers_backend | 42 buffers_backend_fsync | 0 buffers_alloc | 363 stats_reset | 2019-07-17 15:27:49.826414+03</code> </pre><br>  Here, among other things, we see the number of control points performed: <br><br><ul><li>  checkpoints_timed - on schedule (on reaching checkpoint_timeout), </li><li>  checkpoints_req - on request (including upon reaching max_wal_size). </li></ul><br>  The large value of checkpoint_req (compared to checkpoints_timed) indicates that checkpoints occur more often than expected. <br><br>  Important information about the number of pages recorded: <br><br><ul><li>  buffers_checkpoint - checkpoint process, </li><li>  buffers_backend - serving processes, </li><li>  buffers_clean - background write process. </li></ul><br>  In a well-tuned system, the buffers_backend value should be substantially less than the sum of buffers_checkpoint and buffers_clean. <br><br>  Even maxwritten_clean is useful for setting up a background recording - this number shows how many times the background recording process stopped working due to exceeding <em>bgwriter_lru_maxpages</em> . <br><br>  You can reset the accumulated statistics using the following call: <br><br><pre> <code class="pgsql hljs">=&gt; <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> pg_stat_reset_shared(<span class="hljs-string"><span class="hljs-string">'bgwriter'</span></span>);</code> </pre><br>  To be continued. </div><p>Source: <a href="https://habr.com/ru/post/460423/">https://habr.com/ru/post/460423/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../46041/index.html">Electronic First Aid Guide</a></li>
<li><a href="../460411/index.html">Insane GIF Converter in Animated Telegram Stickers</a></li>
<li><a href="../460413/index.html">7 useful sites and applications for learning English</a></li>
<li><a href="../460415/index.html">Apple Watch 4 (44 mm, 2019) vs Pebble Steel Classic (2014)</a></li>
<li><a href="../46042/index.html">And in parrots, I am much longer ...</a></li>
<li><a href="../46043/index.html">Baseball cap with opener</a></li>
<li><a href="../460431/index.html">Building an automated testing pipeline on Azure DevOps</a></li>
<li><a href="../460433/index.html">Risks and threats in the Internet of things</a></li>
<li><a href="../460437/index.html">How we put out a tech bike</a></li>
<li><a href="../460439/index.html">P4 programming language</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>