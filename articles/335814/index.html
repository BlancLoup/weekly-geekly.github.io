<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Kubernetes success stories in production. Part 3: GitHub</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="We continue to talk about successful examples of using Kubernetes in production. New case - quite fresh. Details about him appeared only yesterday. An...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Kubernetes success stories in production. Part 3: GitHub</h1><div class="post__text post__text-html js-mediator-article">  We continue to talk about successful examples of using Kubernetes in production.  New case - quite fresh.  Details about him appeared only yesterday.  And what is even more significant, it will be about a major online service, which every reader of the Habra will probably work in one way or another - GitHub. <br><br><img src="https://habrastorage.org/web/97b/6d2/13b/97b6d213b0454108b1eb76d1eae06fe3.png"><a name="habracut"></a><br><br><h2>  First information </h2><br>  The fact that GitHub is engaged in the implementation of Kubernetes in its production, was first <a href="https://www.nixp.ru/news/14136.html">publicly known a</a> month ago from the <a href="https://twitter.com/AaronBBrown777/status/884920896422633474">Twitter account of the</a> SRE-engineer of the Aaron Brown company.  Then he briefly reported: 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <div class="oembed"><twitter-widget class="twitter-tweet twitter-tweet-rendered" id="twitter-widget-0" style="position: static; visibility: visible; display: block; transform: rotate(0deg); width: 500px; margin: 10px auto; max-width: 100%; min-width: 220px;" data-tweet-id="884920896422633474"></twitter-widget><blockquote class="twitter-tweet" align="center" data-twitter-extracted-i1552551218304386936="true"><p lang="en" dir="ltr">  Hey <a href="https://twitter.com/kelseyhightower">@kelseyhightower</a> , if you‚Äôre surfing GitHub today, you might like it. </p>  - Aaron Brown (@ AaronBBrown777) <a href="https://twitter.com/AaronBBrown777/status/884920896422633474">July 11, 2017</a> </blockquote><script async="" src="//platform.twitter.com/widgets.js" charset="utf-8"></script></div><br>  That is: ‚Äúif you go through the pages of GitHub today, then you may be interested in the fact that from this day all web content is delivered using Kubernetes‚Äù.  The following answers clarified that the traffic to the Docker containers managed by Kubernetes was switched for the web frontend and the Gist service, and the API applications were in the process of migration.  Containerization in GitHub has affected only stateless applications, because the situation with stateful products is more complicated and ‚Äú[for maintenance] MySQL, Redis and Git have already been extensively automated [in GitHub]‚Äù.  The choice for Kubernetes was called optimal for GitHub employees with a note that "Mesos / Nomad is neither worse nor better - they are just different." <br><br>  There was little information, but GitHub engineers promised to talk about the details soon.  And yesterday Jesse Newland, SRE senior in the company, published the long-awaited article ‚Äú <a href="https://githubengineering.com/kubernetes-at-github/">Kubernetes at GitHub</a> ‚Äù, and just 8 hours before this publication on Habr√©, the already mentioned Aaron Brown spoke at the belatedly celebration of Kubernetes 2 anniversary in Apprenda with the corresponding report: <br><br><img src="https://habrastorage.org/web/f24/100/a01/f24100a01b0045afa598416c81961638.jpg"><br>  <i>Quote from the report of Aaron: "" I dream to spend more time setting up hosts ", - no engineer, never"</i> <br><br><h2>  Why bother Kubernetes in GitHub at all? </h2><br>  Until recent events, the main GitHub application, written in Ruby on Rails, has changed little over the past 8 years since its creation: <br><br><ul><li>  On Ubuntu servers configured using Puppet, God‚Äôs process manager ran Unicorn web server. </li><li>  For deployment, Capistrano was used, which was connected via SSH to each front-end server, updated the code and restarted the processes. </li><li>  When the peak load exceeded the available capacity, SRE engineers added new frontend servers using gPanel, IPMI, iPXE, Puppet Facter and Ubuntu PXE image in their workflow <i>(read more about this <a href="https://githubengineering.com/githubs-metal-cloud/">here</a> )</i> . </li></ul><br>  As GitHub grew (employees, the number of features and services, user requests), there were difficulties, and in particular: <br><br><ul><li>  some teams needed to ‚Äúextract‚Äù a small part of their functionality from large services for a separate launch / deployment; </li><li>  the increase in the number of services led to the need to support a variety of similar configurations for dozens of applications (more time was spent on server support and provisioning); </li><li>  Deploy new services (depending on their complexity) took days, weeks or even months. </li></ul><br><blockquote>  Over time, it became clear that this approach does not provide our engineers with the flexibility that was necessary to create a world-class service.  Our engineers needed a self-service platform that they could use for experimenting with new services, their deployment and scaling.  In addition, it was necessary that the same platform satisfy the requirements of the main application on Ruby on Rails, so that engineers and / or robots could respond to changes in load by allocating additional computing resources in seconds, rather than hours, days, or longer. </blockquote><br>  Engineers and developers started a joint project to solve these problems, which led to the study and comparison of existing container orchestration platforms.  Evaluating Kubernetes, they identified several advantages: <br><br><ol><li>  active open source community supporting the project; </li><li>  positive experience of the first launch (the first deployment of the application in a small cluster took only a few hours); </li><li>  extensive information about the experience of the authors Kubernetes, which led them to the existing architecture. </li></ol><br><h2>  Kubernetes Deplo </h2><br>  To organize the deployment of the main Ruby GitHub application using the Kubernetes infrastructure, a so-called ‚ÄúAssessment Lab‚Äù was created.  It consisted of the following projects: <br><br><ol><li>  A Kubernetes cluster running in the AWS VPC cloud and managed with Terraform and kops. </li><li>  A set of integration tests for Bash that perform checks on temporary Kubernetes clusters that were actively used at the beginning of the project. </li><li>  <code>Dockerfile</code> for the application. </li><li>  Improvements to the internal platform for continuous integration (CI) to support the assembly of containers and their publication in the registry. </li><li>  YAML submissions 50+ resources used in Kubernetes. </li><li>  Improvements in the internal deployment application for ‚Äúforwarding‚Äù Kubernetes resources from the repository to the Kubernetes namespace and creating Kubernetes secrets (from the internal repository). </li><li>  Service based on HAProxy and consul-template for redirecting traffic from pods from Unicorn to existing services. </li><li>  Service that sends emergency events from Kubernetes to the internal error reporting system. </li><li>  The kube-me service, which is compatible with chatops-rpc and provides chat users with limited access to kubectl commands. </li></ol><br>  The bottom line is a chat-based interface for deploying a GitHub application at any pull request: <br><br><img src="https://habrastorage.org/web/a3a/d3f/279/a3ad3f279de94ca7868dcb24eb22d64b.png"><br><br>  The implementation of the laboratory proved to be excellent, and by the beginning of June, the entire GitHub deployed to the new scheme. <br><br><h2>  Kubernetes for infrastructure </h2><br>  The next stage in the implementation of Kubernetes was the construction of a very demanding infrastructure performance and reliability for the company's main service in production - github.com. <br><br>  The basic infrastructure of GitHub is the so-called <a href="https://githubengineering.com/githubs-metal-cloud/">metal cloud</a> (a cloud running on physical servers in its own data centers).  Of course, Kubernetes was required to run, given the existing specifics.  To this end, the company's engineers again implemented a number of auxiliary projects: <br><br><ol><li>  Calico was chosen as the network provider, which ‚Äúout of the box provided the necessary functionality for the rapid deployment of the cluster in <code>ipip</code> mode‚Äù. </li><li>  Repeated (‚Äúat least a dozen times‚Äù) reading <a href="https://github.com/kelseyhightower/kubernetes-the-hard-way">Kubernetes the hard way</a> helped assemble several manually serviced servers into a temporary cluster Kubernetes, which successfully passed the integration tests used for existing AWS-based clusters. </li><li>  Create a small utility that generates the CA and configuration for each cluster in a format recognized by the used Puppet and secrets storage systems. </li><li>  Puppet'izatsiya configuration of two roles (Kubernetes node and Kubernetes apiserver). </li><li>  Creation of a service (in the Go language) that collects the logs of the containers, adds metadata to each line in the key-value format and sends them to the syslog for the host. </li><li>  Add support for Kubernetes NodePort Services in a load balancing service ( <a href="https://www.nixp.ru/news/13786.html">GLB</a> ). </li></ol><br>  The bottom line is the Kubernetes cluster on the iron servers, which passed internal tests and in less than a week began to be used for migrating from AWS.  After creating additional such clusters, GitHub engineers launched a copy of the combat github.com on Kubernetes and (using GLB) offered their employees a button to switch between the original installation of the application and the version in Kubernetes.  The services architecture looked like this: <br><br><img src="https://habrastorage.org/web/622/8a3/632/6228a363227b4be8b84aaf0f426c75aa.png"><br><br>  After fixing the problems found by employees, a gradual switching of user traffic to new clusters began: first, 100 requests per second, and then 10% of all requests to github.com and api.github.com. <br><br>  Go from 10% to 100% of the traffic did not hurry.  Part-load tests showed unexpected results: the failure of one Kubernetes apiserver node had a negative impact on the availability of available resources in general ‚Äî the reason ‚Äúapparently‚Äù was associated with interaction between different clients connecting to apiserver (calico-agent, kubelet, kube -proxy, kube-controller-manager), and the behavior of the internal load balancer when the apiserver node falls.  Therefore, GitHub decided to run the main application on several clusters in different places and redirect requests from problematic clusters to workers. <br><br>  By mid-July of this year, 100% of GitHub production traffic was redirected to Kubernetes-based infrastructure. <br><br>  One of the remaining problems, according to the company's engineer, is that sometimes during heavy loads, on some Kubernetes nodes, a kernel panic occurs, after which they reboot.  Although outwardly for users it is not noticeable at all, the SRE-team has a high priority on finding out the reasons for this behavior and eliminating them, and the tests that test fault tolerance have specifically added the call to kernel panic (via <code>echo c &gt; /proc/sysrq-trigger</code> ) .  Despite this, the authors are generally satisfied with their experience and are going to migrate more to such an architecture, as well as to begin experiments with the launch of stateful services in Kubernetes. <br><br><h2>  Other articles from the cycle </h2><br><ul><li>  ‚Äú <a href="https://habrahabr.ru/company/flant/blog/334140/">Kubernetes success stories in production.</a>  <a href="https://habrahabr.ru/company/flant/blog/334140/">Part 1: <b>4,200 pods and TessMaster on eBay</b></a> . ‚Äù </li><li>  ‚Äú <a href="https://habrahabr.ru/company/flant/blog/334770/">Kubernetes success stories in production.</a>  <a href="https://habrahabr.ru/company/flant/blog/334770/">Part 2: <b>Concur and SAP</b></a> . ‚Äù </li><li>  ‚Äú <a href="https://habrahabr.ru/company/flant/blog/339724/">Kubernetes success stories in production.</a>  <a href="https://habrahabr.ru/company/flant/blog/339724/">Part 4: <b>SoundCloud (by Prometheus)</b></a> . ‚Äù </li><li>  ‚Äú <a href="https://habrahabr.ru/company/flant/blog/342412/">Kubernetes success stories in production.</a>  <a href="https://habrahabr.ru/company/flant/blog/342412/">Part 5: <b>Monzo Digital Bank</b></a> . </li><li>  ‚Äú <a href="https://habrahabr.ru/company/flant/blog/345780/">Kubernetes success stories in production.</a>  <a href="https://habrahabr.ru/company/flant/blog/345780/">Part 6: <b>BlaBlaCar</b></a> . </li><li>  ‚Äú <a href="https://habrahabr.ru/company/flant/blog/347098/">Kubernetes success stories in production.</a>  <a href="https://habrahabr.ru/company/flant/blog/347098/">Part 7: <b>BlackRock</b></a> . </li><li>  ‚Äú <a href="https://habrahabr.ru/company/flant/blog/349940/">Kubernetes success stories in production.</a>  <a href="https://habrahabr.ru/company/flant/blog/349940/">Part 8: <b>Huawei</b></a> . </li><li>  ‚Äú <a href="https://habr.com/company/flant/blog/349940/">Kubernetes success stories in production.</a>  <a href="https://habr.com/company/flant/blog/349940/">Part 9: <b>CERN and 210 K8s clusters.</b></a> ‚Äù </li><li>  ‚Äú <a href="https://habr.com/ru/company/flant/blog/441754/">Kubernetes success stories in production.</a>  <a href="https://habr.com/ru/company/flant/blog/441754/">Part 10: <b>Reddit</b></a> . </li></ul></div><p>Source: <a href="https://habr.com/ru/post/335814/">https://habr.com/ru/post/335814/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../335804/index.html">Random forest vs neural network: who will better cope with the task of recognizing gender in speech (part 2)</a></li>
<li><a href="../335806/index.html">Guide to localizing applications for the Chinese market. Part 1</a></li>
<li><a href="../335808/index.html">BIM: how we build builders in construction</a></li>
<li><a href="../335810/index.html">We break and restore the Chinese IP camera</a></li>
<li><a href="../335812/index.html">Simple Java code breaking the Scala type inference system</a></li>
<li><a href="../335816/index.html">Computer networks for dummies</a></li>
<li><a href="../335818/index.html">Yamichat - customizable chat bot and online consultant in one platform</a></li>
<li><a href="../335820/index.html">Modern methods of web application security research</a></li>
<li><a href="../335824/index.html">The second edition of the book "Learning Python. Game programming, data visualization, web applications</a></li>
<li><a href="../335826/index.html">How hackers prepare attacks on banks</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>