<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Universal Memcomputing Machines as an alternative to Turing Machine</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="This article can be considered a free translation (although rather an attempt to understand) of this article . And yes, it is written more for mathema...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Universal Memcomputing Machines as an alternative to Turing Machine</h1><div class="post__text post__text-html js-mediator-article">  <i>This article can be considered a free translation (although rather an attempt to understand) of <a href="">this article</a> .</i>  <i>And yes, it is written more for mathematicians than for a wide audience.</i> <br><br>  <i>A small spoiler: in the beginning it seemed to me some kind of magic, but then I understood the catch ...</i> <br><br>  Nowadays, the Turing machine (hereinafter MT) is the universal definition of the concept of an algorithm, and hence the universal definition of a ‚Äúproblem solver‚Äù.  There are many other models of the algorithm - lambda calculus, Markov algorithms, etc., but all of them are mathematically equivalent to MT, so even though they are interesting, they do not significantly change anything in the theoretical world. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Generally speaking, there are other models - Nondeterministic Turing Machine, Quantum Turing Machines.  However, they are (for the time being) only abstract models that cannot be implemented in practice. <br><br>  Six months ago, an interesting <a href="http://advances.sciencemag.org/content/1/6/e1500031">article</a> was published in Science Advances with a computational model that differs significantly from MT and which it is quite possible to put into practice (the article itself was about how they counted the SSP task on real hardware). <br><br>  And yes.  The most interesting thing about this model is that, according to the authors, it is possible to solve (some) tasks from the NP class of complete problems in the time and memory polynomial. <br><a name="habracut"></a><br>  Probably you should immediately stipulate that this result does not mean a solution to the problem. <img src="http://tex.s2cms.ru/svg/P%20%3D%20NP" alt="P = NP">  .  After all, the statement of this problem does not ‚Äúsolve the <img src="http://tex.s2cms.ru/svg/q%20%5Cin%20NPcomplete" alt="q \ in NPcomplete">  behind <img src="http://tex.s2cms.ru/svg/n%5E%7Bconst%7D" alt="n ^ {const}">  time ‚Äù, and is it possible to simulate a non-deterministic Turing machine on a regular Turing machine in the time polynomial.  Since there is a completely different model of calculations, it is impossible to speak about classical classes of complexity. <br><br>  <em>I myself am skeptical at the moment about the possibility of building this machine in the gland (why I will tell below), but the model itself seemed to me quite interesting for analysis and, quite possibly, it will find application in other areas of science.</em> <br><br><h1>  Small introduction </h1><br>  What is a computer (more precisely, the most popular implementation of MT - Arch. Von Neumann) today?  Some kind of I / O interface, memory and CPU, which is physically separated from them.  In the CPU, there are both the module that controls the progress of the calculations and the blocks that perform these calculations. <br><img src="https://habrastorage.org/files/3f6/d16/4d8/3f6d164d88b845c2b66efbf9efe734c5.png"><br>  The physical separation of the CPU means that we have to spend a lot of time transferring data.  Actually for this purpose various levels of cash memory were invented.  However, cache memory, of course, makes life easier, but does not solve all data transfer problems. <br><br>  The proposed data model was inspired by the work of the brain (the phrase is rather trite, but it is quite suitable here).  Its essence is that the calculations take place not in a separate device, where you need to transfer data, but directly in memory.  The order of calculations is controlled by an external device (Control Unit). <br><img src="https://habrastorage.org/files/86c/762/24f/86c76224f3b34fa8aa7006b7473d7c9a.png"><br>  This model of computing, called Universal Memcomputing Machines (I did not begin to translate this term. Then I will use the abbreviation UMM). <br><br>  In this article, we first recall how MT is formally defined, then we will look at the definition of UMM, look at an example of how to set an algorithm for solving a problem on a UMM, consider several properties, including the most important information overhead. <br><br><h1>  Formal description of the model. </h1><br><h2>  Universal Turing Machine (UTM) </h2><br>  I think you all remember what a Turing machine is (otherwise there is no point in reading this article).  Tape, carriage, all things.  Let's just remember how it is defined formally. <br><br>  Turing machine is a tuple <br><br><div style="text-align:center;"><img src="http://tex.s2cms.ru/svg/%0AUTM%20%3D%20(Q%2C%20%5CGamma%2C%20b%2C%20%5CSigma%2C%20%5Cdelta%2C%20q_0%2C%20F)%2C%0A" alt="UTM = (Q, \ Gamma, b, \ Sigma, \ delta, q_0, F),"></div><br>  Where <img src="http://tex.s2cms.ru/svg/Q" alt="Q">  - many possible states, <br><img src="http://tex.s2cms.ru/svg/%5CGamma" alt="\ Gamma">  - many possible ribbon symbols <br><img src="http://tex.s2cms.ru/svg/b%20%5Cin%20%5CGamma" alt="b \ in \ Gamma">  - empty character <br><img src="http://tex.s2cms.ru/svg/%5CSigma" alt="\ Sigma">  - many incoming characters <br><img src="http://tex.s2cms.ru/svg/q_0" alt="q_0">  - initial state <br><img src="http://tex.s2cms.ru/svg/F%20%5Csubseteq%20Q" alt="F \ subseteq Q">  - a set of final states <br><br><img src="http://tex.s2cms.ru/svg/%5Cdelta%20%3A%20Q%20%5Csmallsetminus%20F%20%5Ctimes%20%5CGamma%20%5Crightarrow%20Q%20%5Ctimes%20%5CGamma%20%5Ctimes%20%5C%7BL%2C%20N%2C%20R%5C%7D" alt="\ delta: Q \ smallsetminus F \ times \ Gamma \ rightarrow Q \ times \ Gamma \ times \ {L, N, R \}">  where <img src="http://tex.s2cms.ru/svg/L%2C%20N%2C%20R" alt="L, N, R">  accordingly, the shift to the left, without offset, offset to the right.  I.e <img src="http://tex.s2cms.ru/svg/%5Cdelta" alt="\ delta">  - our transition table. <br><br><h2>  Memprocessor </h2><br>  To begin with, let's define our UMM memory cell - memeprocessor. <br><br>  The memprocessor is defined as a 4-tuple. <img src="http://tex.s2cms.ru/svg/(x%2C%20y%2C%20z%2C%20%5Csigma)" alt="(x, y, z, \ sigma)">  where <img src="http://tex.s2cms.ru/svg/x" alt="x">  - the state of the memory processor, <img src="http://tex.s2cms.ru/svg/y" alt="y">  - vector of internal variables. <img src="http://tex.s2cms.ru/svg/z" alt="z">  - vector of "external" variables, that is, variables, connecting different meprocessors.  In other words, if <img src="http://tex.s2cms.ru/svg/z_1" alt="z_1">  and <img src="http://tex.s2cms.ru/svg/z_2" alt="z_2">  - vectors of external variables of two memprocessors, then two memprocessors are connected <img src="http://tex.s2cms.ru/svg/%5CLeftrightarrow" alt="\ Leftrightarrow"><img src="http://tex.s2cms.ru/svg/z_1%20%5Ccap%20z_2%20%5Cneq%20%5CO" alt="z_1 \ cap z_2 \ neq \ O">  .  Also, if the memprocessor is not connected to anyone, then <img src="http://tex.s2cms.ru/svg/z%20%3D%20z(x%2Cy)" alt="z = z (x, y)">  , that is, determined only by the internal state. <br><br>  And finally <img src="http://tex.s2cms.ru/svg/%5Csigma%5Bx%2Cy%2Cz%5D%20%3D%20(x'%2C%20y')" alt="\ sigma [x, y, z] = (x ', y')">  , i.e <img src="http://tex.s2cms.ru/svg/%5Csigma" alt="\ sigma">  - the operator of the new state. <br><br>  I want to remind you that the memory processor is not the processor that we usually imagine in our head.  It is rather a memory cell that has the function of obtaining a new state (programmable). <br><br><h2>  Universal Memcomputing Machine (UMM) </h2><br>  Now we introduce the formal definition of UMM.  UMM is a model of a computer formed of interconnected meprocessors (which, generally speaking, can be both digital and analog). <br><br><div style="text-align:center;"><img src="http://tex.s2cms.ru/svg/%0AUMM%20%3D%20(M%2C%20%5CDelta%2C%20%5Cmathcal%7BP%7D%2C%20S%2C%20%5CSigma%2C%20p_0%2C%20s_0%2C%20F)%2C%0A" alt="UMM = (M, \ Delta, \ mathcal {P}, S, \ Sigma, p_0, s_0, F),"></div><br>  Where <img src="http://tex.s2cms.ru/svg/M" alt="M">  - many possible states of the meprocessor <br><img src="http://tex.s2cms.ru/svg/%5Cmathcal%7BP%7D" alt="\ mathcal {P}">  - A set of pointers to the memprocessor (used in <img src="http://tex.s2cms.ru/svg/%5Cdelta" alt="\ delta">  to select the desired memory processors) <br><img src="http://tex.s2cms.ru/svg/S" alt="S">  - many indexes <img src="http://tex.s2cms.ru/svg/%5Calpha" alt="\ alpha">  (number of function used <img src="http://tex.s2cms.ru/svg/%5Cdelta" alt="\ delta">  ) <br><img src="http://tex.s2cms.ru/svg/%5CSigma" alt="\ Sigma">  - the initial state of the memprocessor <br><img src="http://tex.s2cms.ru/svg/p_0" alt="p_0">  - initial set of pointers <br><img src="http://tex.s2cms.ru/svg/s_0" alt="s_0">  - initial operator index ($ \ alpha $) <br><img src="http://tex.s2cms.ru/svg/F%20%5Csubseteq%20M" alt="F \ subseteq M">  - a set of final states <br><br><img src="http://tex.s2cms.ru/svg/%5CDelta%20%3D%20%5C%7B%20%5Cdelta_%7B%5Calpha%7D%20%5C%20%20%7C%20%20%5C%20%5Cdelta_%7B%5Calpha%7D%3A%20M%5E%7Bm_%7B%5Calpha%7D%7D%20%5Csmallsetminus%20F%20%5Ctimes%20%5Cmathcal%7BP%7D%20%20%0A%20%20%20%20%5Crightarrow%20M%5E%7B%7Bm'%7D_%7B%5Calpha%7D%7D%20%5Ctimes%20%5Cmathcal%7BP%7D%5E2%20%5Ctimes%20S%20%5C%7D%2C" alt="\ Delta = \ {\ delta _ {\ alpha} \ | \ \ delta _ {\ alpha}: M ^ {m _ {\ alpha}} \ smallsetminus F \ times \ mathcal {P} \ rightarrow M ^ {{m '} _ {\ alpha}} \ times \ mathcal {P} ^ 2 \ times S \},"><br>  Where <img src="http://tex.s2cms.ru/svg/m_%7B%5Calpha%7D%20%3C%20%5Cinfty" alt="m _ {\ alpha} &amp; lt; \ infty">  - the number of memprocessors used as input by the function <img src="http://tex.s2cms.ru/svg/%5Cdelta_%7B%5Calpha%7D" alt="\ delta _ {\ alpha}">  , <img src="http://tex.s2cms.ru/svg/%7Bm'%7D_%7B%5Calpha%7D%20%3C%20%5Cinfty" alt="{m '} _ {\ alpha} &amp; lt; \ infty">  - the number of memory processors used as an exit function <img src="http://tex.s2cms.ru/svg/%5Cdelta_%7B%5Calpha%7D" alt="\ delta _ {\ alpha}">  . <br><br>  By analogy with the Turing machine, as you might have guessed, <img src="http://tex.s2cms.ru/svg/%5Cdelta_%7B%5Calpha%7D" alt="\ delta _ {\ alpha}">  - transition functions, an analogue of the state table.  If you look at an example, then let <img src="http://tex.s2cms.ru/svg/p_%7B%5Calpha%7D%2C%20%7Bp'%7D_%7B%5Calpha%7D%2C%20p_%7B%5Cbeta%7D%20%5Cin%20%5Cmathcal%7BP%7D" alt="p _ {\ alpha}, {p '} _ {\ alpha}, p _ {\ beta} \ in \ mathcal {P}">  - pointers to memprocessors, <img src="http://tex.s2cms.ru/svg/p_%7B%5Calpha%7D%20%3D%20%5C%7B%20i_1%2C%20%5Cdots%2C%20i_%7Bm_%7B%5Calpha%7D%7D%20%5C%7D" alt="p _ {\ alpha} = \ {i_1, \ dots, i_ {m _ {\ alpha}} \}">  , <img src="http://tex.s2cms.ru/svg/x(p)" alt="x (p)">  - the state vector of these memprocessors, and <img src="http://tex.s2cms.ru/svg/%5Cbeta%20%5Cin%20S" alt="\ beta \ in S">  - the index of the next command, then <br><br><div style="text-align:center;"><img src="http://tex.s2cms.ru/svg/%20%5Cdelta_%7B%5Calpha%7D%20%5Bx(p_%7B%5Calpha%7D)%5D%20%3D%20(x'(%7Bp'%7D_%7B%5Calpha%7D)%2C%20%5Cbeta%2C%20p_%7B%5Cbeta%7D)%20" alt="\ delta _ {\ alpha} [x (p _ {\ alpha})] = (x '({p'} _ {\ alpha}), \ beta, p _ {\ beta})"></div><br>  Generally speaking, discarding formalism, the main difference between UMM and MT is that in UMM, affecting a single memory cell (that is, a memory processor), you automatically influence its environment, without additional calls from the Control Unit. <br><br>  Note 2 properties of the UMM, directly arising from its definition. <br><ul><li>  <strong>Property 1. Intrinsic parallelism</strong> (I have not decided how to properly translate this term, so I left it as it is).  Any function <img src="http://tex.s2cms.ru/svg/%5Cdelta_%7B%5Calpha%7D" alt="\ delta _ {\ alpha}">  can run on any set of processors at the same time.  In the Turing machine for this you need to enter additional tapes and heads. <br></li><li>  <strong>Property 2. Functional polymorphism</strong> .  It lies in the fact that, unlike the Turing machine, the UMM can have many different operators <img src="http://tex.s2cms.ru/svg/%5Cdelta_%7B%5Calpha%7D" alt="\ delta _ {\ alpha}">  . <br></li></ul><br><img src="https://habrastorage.org/files/0f1/730/8e6/0f17308e61ff479ab4dceec3da0511f8.png"><br>  Generally speaking, it is not so difficult to modify the Turing machine so that it also has these properties, but the authors insist. <br><br>  And a few more comments on the definition.  The UMM, unlike the Turing machine, can have an infinite state space with a finite number of meprocessors (due to the fact that they can be analog). <br><br>  By the way, UMM can be considered as a generalization of neural networks. <br><br><h2>  We prove one theorem. </h2><br><blockquote>  UMM is a <a href="https://ru.wikipedia.org/wiki/%25D0%25A3%25D0%25BD%25D0%25B8%25D0%25B2%25D0%25B5%25D1%2580%25D1%2581%25D0%25B0%25D0%25BB%25D1%258C%25D0%25BD%25D0%25B0%25D1%258F_%25D0%25BC%25D0%25B0%25D1%2588%25D0%25B8%25D0%25BD%25D0%25B0_%25D0%25A2%25D1%258C%25D1%258E%25D1%2580%25D0%25B8%25D0%25BD%25D0%25B3%25D0%25B0">universal</a> machine (that is, a machine that can simulate the operation of any MT). <br></blockquote><br>  <strong>Evidence.</strong> <br><br>  In other words, we need to show that the Turing machine is a special case of the UMM.  (whether the opposite is true is not proven, and if the authors of the article are right, then this will be equivalent to proving <img src="http://tex.s2cms.ru/svg/P%20%3D%20NP" alt="P = NP">  ) <br><br>  Let in the definition of UMM, <img src="http://tex.s2cms.ru/svg/M%20%3D%20Q%20%5Ccup%20%5CGamma" alt="M = Q \ cup \ Gamma">  .  We will designate one of the memory processors as <img src="http://tex.s2cms.ru/svg/j_s" alt="j_s">  , the rest (possibly infinite qty) as <img src="http://tex.s2cms.ru/svg/j" alt="j">  .  Next we define the pointer <img src="http://tex.s2cms.ru/svg/p%20%3D%20%5C%7Bj_s%2C%20j%5C%7D" alt="p = \ {j_s, j \}">  . <img src="http://tex.s2cms.ru/svg/j_s" alt="j_s">  we will use as a designation of the state <img src="http://tex.s2cms.ru/svg/q%20%5Cin%20Q" alt="q \ in Q">  , <img src="http://tex.s2cms.ru/svg/j" alt="j">  as a ribbon symbol ( <img src="http://tex.s2cms.ru/svg/%5CGamma" alt="\ Gamma">  ). <br><br><img src="http://tex.s2cms.ru/svg/%5CDelta" alt="\ Delta">  we will consist of a single function <img src="http://tex.s2cms.ru/svg/%5Cdelta%20%5B%20x(p)%20%5D%20%3D%20(x'(p)%2C%20p')" alt="\ delta [x (p)] = (x '(p), p')">  (omit <img src="http://tex.s2cms.ru/svg/%5Cbeta" alt="\ beta">  , since there is only one function).  New condition <img src="http://tex.s2cms.ru/svg/x'" alt="x '">  determined by the transition table MT, <img src="http://tex.s2cms.ru/svg/x'(j_s)" alt="x '(j_s)">  - there will be a new state, <img src="http://tex.s2cms.ru/svg/x'(j)" alt="x '(j)">  - new ribbon symbol.  New pointer <img src="http://tex.s2cms.ru/svg/p'%20%3D%20%5C%7Bj_s%2C%20j'%5C%7D" alt="p '= \ {j_s, j' \}">  , <img src="http://tex.s2cms.ru/svg/j'%20%3D%20j" alt="j '= j">  if there is no carriage transition, <img src="http://tex.s2cms.ru/svg/j'%20%3D%20j%20%2B%201" alt="j '= j + 1">  if we move the carriage to the right, <img src="http://tex.s2cms.ru/svg/j'%20%3D%20j%20-%201" alt="j '= j - 1">  if left.  As a result, when writing to <img src="http://tex.s2cms.ru/svg/x" alt="x">  initial state <img src="http://tex.s2cms.ru/svg/q_0" alt="q_0">  and the starting character from <img src="http://tex.s2cms.ru/svg/%5CSigma" alt="\ Sigma">  , with <img src="http://tex.s2cms.ru/svg/%5CDelta%20%3D%20%5Cdelta" alt="\ Delta = \ delta">  UTM simulates a universal Turing machine. <br><br>  <strong>The theorem is proved.</strong> <br><br><h1>  Algorithms </h1><br>  Let's look at an example of how to solve problems on the UMM (for now just to get acquainted with the model).  Take the subset sum problem ( <a href="https://en.wikipedia.org/wiki/Subset_sum_problem">SSP</a> ) problem. <br><br>  Let there be many <img src="http://tex.s2cms.ru/svg/G%20%5Cin%20%5Cmathds%7BZ%7D" alt="G \ in \ mathds {Z}">  and given a number <img src="http://tex.s2cms.ru/svg/s" alt="s">  .  Is there a subset <img src="http://tex.s2cms.ru/svg/K%20%5Csubseteq%20G" alt="K \ subseteq G">  whose sum of elements is equal <img src="http://tex.s2cms.ru/svg/s" alt="s">  . <br><br><h2>  Exponential algorithm </h2><br>  Let the memprocessors in our UMM be arranged in a matrix form (see the figure).  We define three operations. <br><img height="550" src="https://habrastorage.org/files/55a/b5f/377/55ab5f3771eb401f91b4e7ff7f2d2d4f.png"><br><ol><li><img src="http://tex.s2cms.ru/svg/%5Cchi" alt="\ chi">  - this is directly a calculation.  Using activation lines, we can select rows and bounding columns in which calculations are made.  The essence of the calculation is in adding the value of the leftmost cell to the entire row. <br></li><li><img src="http://tex.s2cms.ru/svg/%5Cmu" alt="\ mu">  - this is a data movement operation.  The control node selects two columns and the values ‚Äã‚Äãfrom the first are copied to the second.  The control node does not necessarily perform the copy operation itself; it simply activates the columns with the necessary lines. <br></li><li><img src="http://tex.s2cms.ru/svg/p" alt="p">  - operation similar to <img src="http://tex.s2cms.ru/svg/%5Cmu" alt="\ mu">  , only it takes 1 value and writes it to the column. <br></li></ol><br>  By combining these three operations, we can get the transition function <img src="http://tex.s2cms.ru/svg/%5Cdelta%20%3D%20%5Cmu%20%5Ccirc%20%5Cchi%20%5Ccirc%20p" alt="\ delta = \ mu \ circ \ chi \ circ p">  . <br><img height="600" src="https://habrastorage.org/files/c16/b96/908/c16b9690823949aa977c391d9e095d93.png"><br>  In the first step of the algorithm, we get the sum of all subsets of length <img src="http://tex.s2cms.ru/svg/n-1" alt="n-1">  on the second step of the subsets <img src="http://tex.s2cms.ru/svg/n-2" alt="n-2">  and so on.  As soon as we found the desired number (it will be in the left column), we found the answer.  Each step is performed in one function call. <img src="http://tex.s2cms.ru/svg/%5Cdelta" alt="\ delta">  therefore the algorithm works <img src="http://tex.s2cms.ru/svg/n-1" alt="n-1">  steps. <br><br>  Now let's calculate how many processors we need to perform these operations.  At iteration k we need <img src="http://tex.s2cms.ru/svg/%5Cbinom%7Bn-1%7D%7Bk-1%7D%20(n%2B2-k)" alt="\ binom {n-1} {k-1} (n + 2-k)">  meprotsessorov.  Estimation for this expression using Stirling formula - <img src="http://tex.s2cms.ru/svg/(n%2F2%20%5Cpi)%5E%7B1%2F2%7D%202%5E%7Bn-1%7D" alt="(n / 2 \ pi) ^ {1/2} 2 ^ {n-1}">  .  The number of nodes grows exponentially. <br><br>  I think now it has become more or less clear what kind of object it is.  We now turn to the most delicious that the UMM offers us, namely to the third property - the <strong>information overhead</strong> . <br><br><h2>  Exponential Information Overhead </h2><br>  Suppose we have n memprocessors, let us designate the state of the selected memprocessors as <img src="http://tex.s2cms.ru/svg/x(p)%20%3D%20(x(j_1)%2C%20%5Cdots%2C%20x(j_n))" alt="x (p) = (x (j_1), \ dots, x (j_n))">  .  The status of a separate memprocessor <img src="http://tex.s2cms.ru/svg/x(j)%20%3D%20u_j" alt="x (j) = u_j">  contained in internal variables <img src="http://tex.s2cms.ru/svg/u_j%20%5Cin%20M_a" alt="u_j \ in M_a">  . <img src="http://tex.s2cms.ru/svg/u_j" alt="u_j">  - vector.  Also for each memprocessor, we divide external variables into 2 groups - ‚Äúin‚Äù and ‚Äúout‚Äù (out of one memprocessor is connected to in another).  In the picture the empty circle is a component <img src="http://tex.s2cms.ru/svg/(u_j)_h%20%3D%200" alt="(u_j) _h = 0">  .  Suppose also that we have a device that, when connected to the desired meprocessor, can be considered at once <img src="http://tex.s2cms.ru/svg/u_j" alt="u_j">  . <br><img height="300" src="https://habrastorage.org/files/515/0aa/ea4/5150aaea4b6f45c3a3291728bbd4ab53.png"><br>  This device, connected to several memprocessors, can consider the state of both, and therefore their global state, defined as <img src="http://tex.s2cms.ru/svg/u_%7Bj_1%2C%20j_2%7D%20%3D%20u_%7Bj_1%7D%20%5Cdiamond%20u_%7Bj_2%7D" alt="u_ {j_1, j_2} = u_ {j_1} \ diamond u_ {j_2}">  where <img src="http://tex.s2cms.ru/svg/%5Cdiamond%20%3A%20R%5Ed%20%5Ctimes%20R%5Ed%20%5Crightarrow%20R%5Ed" alt="\ diamond: R ^ d \ times R ^ d \ rightarrow R ^ d">  - commutative, associative operation, <img src="http://tex.s2cms.ru/svg/d%20%3D%20%5Cdim(u_j)" alt="d = \ dim (u_j)">  .  This operation is defined as <br><br><div style="text-align:center;"><img src="http://tex.s2cms.ru/svg/%0A(u_%7Bj_1%7D%20%5Cdiamond%20u_%7Bj_2%7D)_%7Bh%20%5Cstar%20k%7D%20%3D%20(u_%7Bj_1%7D)_h%20%20%5Cast%20(u_%7Bj_2%7D)_k%2C%0A" alt="(u_ {j_1} \ diamond u_ {j_2}) _ {h \ star k} = (u_ {j_1}) _ h \ ast (u_ {j_2}) _ k,"></div><br>  Where <img src="http://tex.s2cms.ru/svg/%5Cstar%3A%20%5Cmathds%7BZ%7D%20%5Ctimes%20%5Cmathds%7BZ%7D%20%5Crightarrow%20%5Cmathds%7BZ%7D" alt="\ star: \ mathds {Z} \ times \ mathds {Z} \ rightarrow \ mathds {Z}">  and <img src="http://tex.s2cms.ru/svg/%5Cast%3A%20R%20%5Ctimes%20R%20%5Crightarrow%20R" alt="\ ast: R \ times R \ rightarrow R">  - commutative and associative operations with <img src="http://tex.s2cms.ru/svg/h%20%5Cstar%200%20%3D%20h" alt="h \ star 0 = h">  and <img src="http://tex.s2cms.ru/svg/x%20%5Cast%200%20%3D%200" alt="x \ ast 0 = 0">  .  Moreover, if for <img src="http://tex.s2cms.ru/svg/h%2C%20k%2C%20h'%2C%20k'" alt="h, k, h ', k'">  performed <img src="http://tex.s2cms.ru/svg/h%20%5Cstar%20k%20%3D%20h'%20%5Cstar%20k'" alt="h \ star k = h '\ star k'">  then <br><br><div style="text-align:center;"><img src="http://tex.s2cms.ru/svg/%0A(u_%7Bj_1%7D%20%5Cdiamond%20u_%7Bj_2%7D)_%7Bh%20%5Cstar%20k%7D%20%3D%20(u_%7Bj_1%7D%20%5Cdiamond%20u_%7Bj_2%7D)_%7Bh%20%5Cstar%20k%7D%20%5Coplus%20(u_%7Bj_1%7D%20%5Cdiamond%20u_%7Bj_2%7D)_%7Bh'%20%5Cstar%20k'%7D%2C%0A" alt="(u_ {j_1} \ diamond u_ {j_2}) _ {h \ star k} = (u_ {j_1} \ diamond u_ {j_2}) _ {h \ star k} \ oplus (u_ {j_1} \ diamond u_ { j_2}) _ {h '\ star k'},"></div><br>  Where <img src="http://tex.s2cms.ru/svg/%5Coplus%3A%20R%20%5Ctimes%20R%20%5Crightarrow%20R" alt="\ oplus: R \ times R \ rightarrow R">  - commutative, associative operation, for which <img src="http://tex.s2cms.ru/svg/x%20%5Coplus%200%20%3D%20x" alt="x \ oplus 0 = x">  . <br><br>  Now having a lot <img src="http://tex.s2cms.ru/svg/G%20%3D%20%5C%7Ba_1%2C%20%5Cdots%2C%20a_n%5C%7D" alt="G = \ {a_1, \ dots, a_n \}">  integers, we define the message <img src="http://tex.s2cms.ru/svg/m%20%3D%20(a_%7B%5Csigma_1%7D%20%5Cstar%20%5Cdots%20%5Cstar%20a_%7B%5Csigma_k%7D)%20%5Ccup%20(a_%7B%5Csigma_1%7D%20%2C%20%5Cdots%20%2C%20a_%7B%5Csigma_k%7D)" alt="m = (a _ {\ sigma_1} \ star \ dots \ star a _ {\ sigma_k}) \ cup (a _ {\ sigma_1}, \ dots, a _ {\ sigma_k})">  where <img src="http://tex.s2cms.ru/svg/(%5Csigma_1%2C%20%5Cdots%2C%20%5Csigma_k)" alt="(\ sigma_1, \ dots, \ sigma_k)">  - indexes taken from various subsets <img src="http://tex.s2cms.ru/svg/%5C%7B1%2C%20%5Cdots%2C%20n%5C%7D" alt="\ {1, \ dots, n \}">  .  Thus many messages <img src="http://tex.s2cms.ru/svg/M" alt="M">  consists of <img src="http://tex.s2cms.ru/svg/%5Csum_%7Bj%3D0%7D%5Em%20%5Cbinom%7Bn%7D%7Bj%7D%20%3D%202%5En" alt="\ sum_ {j = 0} ^ m \ binom {n} {j} = 2 ^ n">  equally likely messages <img src="http://tex.s2cms.ru/svg/m" alt="m">  The amount of information on Shannon is equal to <img src="http://tex.s2cms.ru/svg/I(m)%20%3D%20-%5Clog_2(2%5E%7B-n%7D)%20%3D%20n" alt="I (m) = - \ log_2 (2 ^ {- n}) = n"><br><img height="200" src="https://habrastorage.org/files/9be/0fc/4f1/9be0fc4f1adc44a89cb83a37eda759d2.png"><br>  Now, taking n memprocessors, we expose nonzero components <img src="http://tex.s2cms.ru/svg/u_%7Bj_0%7D%2C%20u_%7Bj_h%7D" alt="u_ {j_0}, u_ {j_h}">  where <img src="http://tex.s2cms.ru/svg/h%20%5Cin%20%5C%7B1%2C%20%5Cdots%2C%20n%5C%7D" alt="h \ in \ {1, \ dots, n \}">  .  So we coded all the elements. <img src="http://tex.s2cms.ru/svg/G" alt="G">  on the memory processors.  On the other hand, by connecting to the necessary meprocessors and reading their global state (according to the formulas, the sum of the elements is obtained there), we can consider any possible state m.  In other words, n memprocessors can encode (compress information if you wish) about <img src="http://tex.s2cms.ru/svg/2%5En" alt="2 ^ n">  messages at the same time. <br><br><h2>  SSP solution algorithm using Exponential Information Overhead </h2><br>  Here I have to say that I could not understand the details of this algorithm (it turned out that I am not so good at electrical engineering and signal processing, and the authors apparently decided not to paint everything for such ignoramuses), but the general idea is . <br><br>  For starters, they offer a look at the function <br><br><div style="text-align:center;"><img src="http://tex.s2cms.ru/svg/%0Ag(x)%20%3D%20-1%20%2B%20%5Cprod_%7Bj%3D1%7D%5En%20(1%20%2B%20e%5E%7Bi%202%20%5Cpi%20a_j%20x%7D)%0A" alt="g (x) = -1 + \ prod_ {j = 1} ^ n (1 + e ^ {i 2 \ pi a_j x})"></div><br>  If we open the brackets, then we will have works on various sets of indices <img src="http://tex.s2cms.ru/svg/j" alt="j">  (denote such a set as <img src="http://tex.s2cms.ru/svg/P" alt="P">  ), and they are equal <br><br><div style="text-align:center;"><img src="http://tex.s2cms.ru/svg/%0A%5Cprod_%7Bj%20%5Cin%20P%7D%20%20e%5E%7Bi%202%20%5Cpi%20a_j%20x%7D%20%3D%20%5Cexp%20%5Cleft(i%202%20%5Cpi%20x%20%5Csum_%7Bj%20%5Cin%20P%7D%20a_j%20%5Cright)%0A" alt="\ prod_ {j \ in P} e ^ {i 2 \ pi a_j x} = \ exp \ left (i 2 \ pi x \ sum_ {j \ in P} a_j \ right)"></div><br>  In other words, our function <img src="http://tex.s2cms.ru/svg/g" alt="g">  contains information about the sums of all subsets <img src="http://tex.s2cms.ru/svg/G" alt="G">  .  Now, if we consider the function g as a signal source, then each exponent contributes to the resulting signal, with the contribution with frequency <img src="http://tex.s2cms.ru/svg/%5Csum_%7Bj%20%5Cin%20P%7D%20a_j" alt="\ sum_ {j \ in P} a_j">  . <br><br>  Now, all we need is to apply a Fourier transform to this signal and see what frequencies we have in the signal.  If we have a component with a frequency <img src="http://tex.s2cms.ru/svg/s" alt="s">  then the subset <img src="http://tex.s2cms.ru/svg/G" alt="G">  with sum <img src="http://tex.s2cms.ru/svg/s" alt="s">  exists. <br><br>  If we solve this problem on a regular computer, now we could apply a fast Fourier transform.  Let us estimate the asymptotics. <br><br>  To do this, we estimate the number of points that need to be taken from the signal.  By the Kotelnikov theorem, these points need <img src="http://tex.s2cms.ru/svg/N%20%3D%202%20f_%7Bmax%7D%20%2B%201" alt="N = 2 f_ {max} + 1">  where <img src="http://tex.s2cms.ru/svg/f_%7Bmax%7D%20%3C%20n%20%5Cmax%5C%7B%7Ca_j%7C%5C%7D" alt="f_ {max} &amp; lt; n \ max \ {| a_j | \}">  - Evaluation of the maximum possible value of frequency.  In the article, the authors introduced an additional variable. <img src="http://tex.s2cms.ru/svg/p" alt="p">  which is proportional <img src="http://tex.s2cms.ru/svg/N" alt="N">  and considered the asymptotics through it. <br><br>  Thus, using <abbr title="Fast Fourier Transform">FFT</abbr> we can solve the problem for <img src="http://tex.s2cms.ru/svg/O(p%20%5Clog(p))" alt="O (p \ log (p))">  .  Here it should be noted that, as in the backpack problem (and SSP is a special case of the backpack problem), $ p $ grows exponentially.  For our problem, you can also use the G√∂rtsel algorithm, which will give us <img src="http://tex.s2cms.ru/svg/O(n%20p)" alt="O (n p)">  .  The proposed method allows the authors to get rid of <img src="http://tex.s2cms.ru/svg/p" alt="p">  asymptotic, which will give us linear time. <br><br>  Now, in your own words (for more detailed consideration, refer to the original articles), how they achieved this. <br><br>  Take <img src="http://tex.s2cms.ru/svg/n" alt="n">  analog memory processors, the internal value of which will be the value of a certain number of <img src="http://tex.s2cms.ru/svg/G" alt="G">  .  As operators <img src="http://tex.s2cms.ru/svg/%5Cstar" alt="\ star">  and <img src="http://tex.s2cms.ru/svg/%5Cast" alt="\ ast">  taken, respectively, addition and multiplication. <br><br>  But it is in our model.  In iron, it turns out that each memprocessor is a signal generator with its own frequency (corresponding to the number of <img src="http://tex.s2cms.ru/svg/G" alt="G">  ), the general state of the memory processors is simply the addition of a signal.  It turns out that these memory processors simulate the function <img src="http://tex.s2cms.ru/svg/g" alt="g">  . <br><img src="https://habrastorage.org/files/22e/c7c/774/22ec7c774cd947a484450ec8fe382ff1.png"><br>  Well, now, in order to read the result, you need to check if there is a given frequency in the signal.  Instead of implementing FFT, they made a piece of hardware that only skips a given frequency (I didn‚Äôt quite understand how, but my knowledge in electronics is to blame), which is already working for a constant time. <br><br>  Total time asymptotics in general amounted to <img src="http://tex.s2cms.ru/svg/O(1)" alt="O (1)">  , asymptotics for the memprocessor was <img src="http://tex.s2cms.ru/svg/O(n)" alt="O (n)">  .  Let us fireworks?  Do not hurry. <br><br><h1>  Some problems of the model </h1><br>  In fact, the authors slyly shifted the ‚Äúcomplicated‚Äù part of the task, which gives us the exhibitor, from the program part to the technical part.  In an earlier article about this in general, not a word, in July they admit it, but only a few lines. <br><br>  It's all about signal coding (I found a clear explanation <a href="http://www.scottaaronson.com/blog/%3Fp%3D2212">here</a> ).  Due to the fact that we encode analog signals, and use discrete signal generators, we now need exponential accuracy in determining the signal level (in the piece of hardware that isolates the desired frequency), which may require the time exponent. <br><br>  The authors argue that this trouble can be circumvented, if instead of discrete signal generators use analog.  But I have big doubts that you can use analog circuits for any <img src="http://tex.s2cms.ru/svg/n" alt="n">  and at the same time not to drown in the noise (because of them at the time they abandoned analog computers and began to use digital). <br><br><h2>  Total </h2><br>  Wonderful magic did not happen.  NP full problems are still difficult to calculate.  So why did I write all this?  Mainly because at least the physical implementation is complex, the model itself seems very interesting to me, and their study is necessary.  Soon (if not now), such models will be of great importance in many areas of science. <br><br>  For example, as I mentioned, neural networks are a special case of UMM.  It is possible that we will learn a little more about neural networks if we look at them from the other side using a slightly different mate.  apparatus. </div><p>Source: <a href="https://habr.com/ru/post/274593/">https://habr.com/ru/post/274593/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../274577/index.html">Some modern approaches to natural language processing</a></li>
<li><a href="../274581/index.html">Docker compose and merge projects using mixer-a</a></li>
<li><a href="../274585/index.html">Eddystone and Physical Web: Beacon Evolution</a></li>
<li><a href="../274587/index.html">Java web platform in 30 minutes</a></li>
<li><a href="../274591/index.html">Experience Angular + Typescript + Offline SPA project in a year</a></li>
<li><a href="../274595/index.html">Next week, Microsoft stops supporting all versions of IE, except 11</a></li>
<li><a href="../274597/index.html">Overview of the example application of reinforcement learning using TensorFlow</a></li>
<li><a href="../274601/index.html">Tips for novice microcontroller programmers</a></li>
<li><a href="../274603/index.html">PROLOG for programmers</a></li>
<li><a href="../274605/index.html">Low-level optimization of parallel algorithms or SIMD in .NET</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>