<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Chatbot on neural networks</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Recently came across such an article . As it turned out, a certain company with the speaker‚Äôs name ‚Äúnanosemantics‚Äù announced a Russian chatbot contest...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Chatbot on neural networks</h1><div class="post__text post__text-html js-mediator-article"> Recently came across <a href="http://megamozg.ru/post/14664/">such an article</a> .  As it turned out, a certain company with the speaker‚Äôs name ‚Äúnanosemantics‚Äù announced a Russian chatbot contest, pompously calling it ‚ÄúTuring Test‚Äù. ‚Äù  Personally, I take a negative attitude to such undertakings ‚Äî chatbot is a program to imitate a conversation ‚Äî the creation is usually not clever, based on pre-made templates, and the competition does not move their science, but the show and the attention of the public is assured.  Creates the ground for various speculations about intelligent computers and great breakthroughs in artificial intelligence, which is very far from the truth.  Especially in this case, when only bots written on the template matching engine are accepted, moreover, Nanosemantics itself. <br><br>  However, it is always easy to scold others, but it is not so easy to do something working.  I was curious whether it was possible to make a chatbot not by manually filling out response templates, but by learning the neural network on sample dialogs.  A quick search on the Internet did not provide useful information, so I decided to quickly do a couple of experiments and see what happens. <br><a name="habracut"></a><br>  Normal chatbot is limited to superficial responses that are defined by predefined patterns.  A trained chatbot (there are such) searches for answers to similar questions in its database of dialogs, and sometimes even creates new templates.  But still, his ‚Äúmind‚Äù is usually strictly limited from above by a given algorithm.  But a bot with a neural network operating on the principle of a question at the entrance ‚Äî the answer at the exit ‚Äî is theoretically unlimited.  There are works in which it is shown that neural networks can learn the rules of logical inference by getting input into sentences in natural language, as well as answer questions relating to various texts.  But we will not be so ambitious in the ways and we will just try to get something resembling the answers of a typical chatbot. <br><br>  As a source of data, only a dialogue transcript in English (consisting of 3,860 replicas) was quickly found.  Well, it will come down to experience, since with our approach the language has no fundamental difference.  To begin with, to compare with something, I quickly collected a simple chatbot that selects ready-made answers from the transcript, based on the word matches in the interlocutor's phrases (cosine of the angle between the question and answer vectors, which are "bags of words").  The whole program fit lines on 30: 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Here's what happened: <br><br><img src="https://habrastorage.org/files/b25/3c7/f3d/b253c7f3dbf34b05a572b98ce1b7bd63.png"><br><br>  Translation (approximate) (W: - person, W: - program): <br>  <i><b>H:</b> hello</i> <i><br></i>  <i><b>P</b> : I see visitors here, that's good.</i> <i><br></i>  <i><b>D:</b> How are you <b>?</b></i> <i><br></i>  <i><b>P:</b> smiles</i> <i><br></i>  <i><b>Q:</b> what is your name?</i> <i><br></i>  <i><b>P:</b> shrugs</i> <i><br></i>  <i><b>W:</b> Who are you?</i> <i><br></i>  <i><b>P:</b> I'm fine</i> <i><br></i>  <i><b>W:</b> do you understand me?</i> <i><br></i>  <i><b>P:</b> Absolutely everything, hmm ...</i> <i><br></i>  <i><b>D:</b> I have to go</i> <i><br></i>  <i><b>N:</b> ^^</i> <i><br></i>  <i><b>H:</b> see you later</i> <i><br></i>  <i><b>P:</b> I'm not sure</i> <br><br>  With a shallow survey, it answers quite well for such a simple program, it doesn‚Äôt know what its name is or who it is ... but nevertheless, a certain sense of presence is taking shape - a good illustration of the fact that we tend to over-animate really simple algorithms (or maybe just 90% of all communication - superficial?). <br><br>  We now turn to more complex algorithms.  I‚Äôll say right away that it‚Äôs harder to do it right away, because template chatbots are created to ‚Äúdeceive‚Äù the user, and use different tricks to create the illusion of communication, and our task is to do without deception. <br><br>  How to generate text using a neural network?  Now the classic way to do this is the neural language model.  The bottom line is that the neural network is given the task to predict the next word based on n-previous ones.  The words at the output are encoded on the principle of one output neuron - one word (see figure).  Input words can be encoded in the same way, or use a distributed representation of words in a vector space, where words of similar meaning are at a smaller distance than words with different meanings. <br><br><img src="https://habrastorage.org/files/e8a/7a0/1fc/e8a7a01fc2bc4e339cc502235ce5382e.png"><br><br>  A trained neural network can give rise to a text and obtain a prediction of its ending (by adding the last predicted word to the end and applying the neural network to a new, elongated text).  Thus, it is possible to create a model of answers.  One problem - the answers have nothing to do with the phrases of the interlocutor. <br><br>  The obvious solution to the problem is to input the presentation of the previous phrase of the dialogue.  How to do it?  Two of the many possible ways we discussed in the <a href="http://habrahabr.ru/company/meanotek/blog/256593/">previous article</a> about the classification of proposals.  The simplest version of NBoW is to use the sum of all the word vectors of the previous phrase. <br><br><img src="https://habrastorage.org/files/e61/18c/261/e6118c26118a4b558c80ef2ec4631c34.png"><br><br>  The architecture shown in the picture is far from the only one possible, but perhaps one of the simplest.  The recurrent layer receives as input the data relative to the current word, the vector representing the previous phrase, and also its own states at the previous step (therefore, it is called recurrent).  Due to this, a neural network (theoretically) can remember information about previous words for an unlimited phrase length (as opposed to an implementation where only words from a fixed-size window are counted).  In practice, of course, such a layer presents certain difficulties in learning. <br><br>  After learning the network got the following: <br><img src="https://habrastorage.org/files/be1/8d7/a11/be18d7a11f5c4befa1ea0cfdccea290e.png"><br><br>  Mda ... more or less meaningless set of words.  There are no connections between words and there is a logic in the construction of sentences, but there is no general sense, and there is no connection with questions either (at least I don‚Äôt see).  In addition, the bot is overly talkative - words are formed into large long chains.  There are many reasons for this - this is a small (about 15,000 words) training sample size, and difficulties in training a recurrent network, which actually sees the context in two or three words, and therefore easily loses the thread of the narration, and the lack of expressiveness of the previous phrase.  Actually, this was expected, and I brought this option to show that the problem is not solved in the forehead.  Although, in fact, correct selection of the training algorithm and network parameters can achieve more interesting options, but they will suffer such problems as repeated repetition of phrases, difficulties with choosing the end of a sentence, copying long fragments from the original training set, etc. In addition, such a network is difficult to analyze - it is unclear what exactly is learned and how it works.  Therefore, we will not waste time analyzing the capabilities of this architecture and try a more interesting option. <br><br>  In the second variant, I connected the convolution network described in the previous article with the recurrent language model: <br><br><img src="https://habrastorage.org/files/a72/b17/830/a72b17830a9242858a5d91fa20bf96f2.png"><br><br>  Like the network from the previous article, the convolutional layer contains 16 filters.  From general considerations, it can be expected that this four-layer model will be harder and the result will be worse.  In addition, 16 filters seem to be insufficient to create a model of the replica of the interlocutor.  Indeed, her training takes much longer, but the result ... well, judge for yourself: <br><br><img src="https://habrastorage.org/files/f10/a04/7e8/f10a047e878c4820aebf8b9e54e0eb88.png"><br><br>  Translation (approximate) of the dialogue (R: - person, P: - program) <br>  <i><b>H:</b> hello</i> <i><br></i>  <i><b>P:</b> oh, hello</i> <i><br></i>  <i><b>H:</b> how are you?</i> <i><br></i>  <i><b>P:</b> I can't see</i> <i><br></i>  <i><b>H:</b> oops ... well, sorry</i> <i><br></i>  <i><b>P:</b> it seems to me a good dream.</i> <i><br></i>  <i><b>W:</b> can you feel?</i> <i><br></i>  <i><b>P:</b> I suppose</i> <i><br></i>  <i><b>Q:</b> Could you see before?</i> <i><br></i>  <i><b>P:</b> Yes</i> <i><br></i>  <i><b>W:</b> Who are you?</i> <i><br></i>  <i><b>P:</b> I</i> <i><br></i>  <i><b>D:</b> I have to go</i> <i><br></i>  <i><b>P:</b> I'm not sure I can accept it.</i> <i><br></i>  <i><b>H:</b> see you later</i> <i><br></i>  <i><b>P:</b> Yes</i> <i><br></i> <br>  In my opinion quite effectively.  It resembles fragments from science fiction novels, where artificial intelligence comes to life in a computer, especially the statements of the program that it cannot see, but could see before.  It is time to declare the creation of AI and the great achievement ... <br><br>  In fact, of course, this neural network does not have any intelligence, which does not make it, though less interesting.  The fact is that we can analyze what has actually been learned by tracing the dependence of activation of the convolutional neurons on the input phrases.  Through such an analysis, a neuron that responds to the words of greeting (‚Äúhello‚Äù, ‚Äúhi‚Äù, ‚Äúhe‚Äù y, etc.), as well as a neuron that recognizes question phrases like ‚Äúhave you ...?‚Äù, Was found. the question is not obligatory (they usually learn to answer ‚Äúyes‚Äù to the neural network), besides, if the word ‚Äúyou‚Äù appears in the question, the likelihood that the answer will begin with the word ‚ÄúI‚Äù (‚Äúme‚Äù ). <br><br>  Thus, the neural network has learned some typical conversation patterns and language tricks, which are often used when programming chatbots "manually", having well disposed of the 16 available filters.  It is possible that replacing a simple convolutional network with a multilayer one, adding filters and increasing the size of the training sample, you can get chatbots, which will seem more ‚Äúsmart‚Äù than their counterparts, based on manual selection of patterns.  But this question is already outside of our article. </div><p>Source: <a href="https://habr.com/ru/post/256987/">https://habr.com/ru/post/256987/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../256975/index.html">Audit of one ‚Äúslow‚Äù application in one large concern</a></li>
<li><a href="../256977/index.html">Step-by-Step: Preparing Mac OS Installation Packages. Part one</a></li>
<li><a href="../256979/index.html">Create an isomorphic application on React and Flummox</a></li>
<li><a href="../256981/index.html">The use of STM32 in industrial machines on the example of the blow molding machine CHODOS (Czech Republic)</a></li>
<li><a href="../256985/index.html">Step-by-Step: Preparing Mac OS Installation Packages. Part two. Package Creation in Package Maker</a></li>
<li><a href="../256989/index.html">Hacker implanted an NFC chip in his hand to bypass security scanners and control android phones</a></li>
<li><a href="../256993/index.html">Looking for the perfect review system for an online store</a></li>
<li><a href="../256995/index.html">Vivaldi Technologies - Straight Talk</a></li>
<li><a href="../256997/index.html">The history of the development of iOS-application. Basically about the rake</a></li>
<li><a href="../256999/index.html">Detailed analysis of Habrahabr using the Wolfram Language (Mathematica)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>