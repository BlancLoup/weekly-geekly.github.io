<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>We study the internal kitchen of the Linux kernel using / proc for quick diagnosis and problem solving</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="This article is about modern Linux. For example, RHEL6 with 2.6.3x kernels will do, but RHEL5 with 2.6.18 kernels (by the way, the most popular in pro...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>We study the internal kitchen of the Linux kernel using / proc for quick diagnosis and problem solving</h1><div class="post__text post__text-html js-mediator-article">  This article is about modern Linux.  For example, RHEL6 with 2.6.3x kernels will do, but RHEL5 with 2.6.18 kernels (by the way, the most popular in production) - alas, no.  And still - here there will be no description of nuclear debuggers or SytemTap scripts;  only good old simple commands like "cat / proc / PID / xyz" for some useful nodes of the / proc file system. <br><br><h4>  Diagnostics of the "braking" process </h4><br>  Here is a good example of a common problem that I reproduced on my laptop: the user complains that the <code>find</code> works "much slower" without returning any results.  Knowing what was the matter, we solved the problem.  However, I was asked to state a systematic approach to solving such problems. <br><br>  Fortunately, the system is running OEL6, i.e.  on a fairly fresh core (namely, 2.6.39 UEK2) 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      So, let's proceed to the diagnosis. <br><a name="habracut"></a><br>  First check to see if the find process is still alive: <br><br><blockquote>  [root @ oel6 ~] # ps -ef |  grep find <br>  root <font color="red"><b>27288</b></font> 27245 4 11:57 pts / 0 00:00:01 <b>find.</b>  <b>-type f</b> <br>  root 27334 27315 0 11:57 pts / 1 00:00:00 grep find <br></blockquote><br>  Yes, it is in place - PID 27288 (I will use this pid later in the diagnostic example) <br><br>  Let's start with the basics and take a look at what is the bottleneck for this process.  If it is not blocked by anything (for example, it reads everything it needs from the cache), it should use 100% CPU.  If it is blocked due to IO or problems with the network, then the processor load must be lower or absent altogether. <br><br><blockquote>  [root @ oel6 ~] # top -cbp <b>27288</b> <br>  top - 11:58:15 up 7 days, 3:38, 2 users, load average: 1.21, 0.65, 0.47 <br>  Tasks: 1 total, 0 running, 1 sleeping, 0 stopped, 0 zombie <br>  Cpu (s): 0.1% us, 0.1% sy, 0.0% ni, 99.8% id, 0.0% wa, 0.0% hi, 0.0% si, 0.0% st <br>  Mem: 2026460k total, 1935780k used, 90680k free, 64416k buffers <br>  Swap: 4128764k total, 251004k used, 3877760k free, 662280k cached <br><br>  PID USER PR NI VIRT RES SHR S% CPU% MEM TIME + COMMAND <br>  27288 root 20 0 109m 1160 844 D <font color="red"><b>0.0</b></font> 0.1 0: 01.11 find.  -type f <br></blockquote><br>  The output of the 'top' command states that this process does not load the CPU at all (or the load is so small that it can be considered zero).  However, there is a very important difference between a process that is completely frozen, not having a chance at all to get a processor quantum, and a process that constantly wakes up from the waiting state and then immediately falls asleep again (for example, some kind of poll operation, which is constantly timed out, and then the process during execution causes it to fall asleep again).  In order to recognize these two states, the 'top' command, unfortunately, is not enough.  But at least we have already found out that this process does not devour the CPU time. <br><br>  Let's try other tools.  Usually, if a process seems to hang like this (0% CPU usually means that the process is in some kind of blocking system call - which causes the kernel to put the process to sleep), I run <code>strace</code> on this process to track which system call he is currently stuck.  If the process is in fact not completely frozen, but periodically returns from the system call and wakes up, then this will also be seen in the strace output (the system call will be periodically completed and then called again): <br><br><blockquote>  [root @ oel6 ~] # strace -cp 27288 <br>  Process 27288 attached - interrupt to quit <br><br>  <font color="red"><strong>^ C</strong></font> <font color="red"><strong><br></strong></font>  <font color="red"><strong>^ Z</strong></font> <br>  [1] + Stopped strace -cp 27288 <br><br>  [root @ oel6 ~] # kill -9 %% <br>  [1] + Stopped strace -cp 27288 <br>  [root @ oel6 ~] # <br>  [1] + Killed strace -cp 27288 <br></blockquote><br>  Oops ... Looks like the strace team itself is also stuck!  For quite a long time she did not display anything on the screen, and did not even respond to pressing CTRL + C, so I had to first send it to the background mode by pressing CTRL + Z, and then completely kill it.  Not a very easy diagnosis! <br><br>  Let's try pstack (on Linux, pstack is just a script wrapper for the GDB debugger).  Pstack will not tell us anything about the kernel's internal kitchen, but at least indicates what kind of system call it is (usually it looks like calling the libc library function on top of the user stack): <br><br><blockquote>  [root @ oel6 ~] # pstack 27288 <br><br>  ^ C <br>  ^ Z <br>  [1] + Stopped pstack 27288 <br><br>  [root @ oel6 ~] # kill %% <br>  [1] + Stopped pstack 27288 <br>  [root @ oel6 ~] # <br>  [1] + Terminated pstack 27288 <br></blockquote><br>  Pstack is also frozen without any explanation! <br><br>  So, we still do not know whether our process is 100% free (alas), or just 99.99% (it wakes up and immediately falls asleep) - and also we don‚Äôt know where exactly this happened. <br><br>  Where else can you look?  There is one more frequently available space - the status and WCHAN fields, the contents of which can be explored using the good old ps command (hmm ... maybe it was worth running it right away to make sure that we are not dealing with zombies): <br><br><blockquote>  [root @ oel6 ~] # ps -flp 27288 <br>  FS UID PID PPID C PRI NI ADDR SZ <b>WCHAN</b> STIME TTY TIME CMD <br>  0 D root 27288 27245 0 80 0 - 28070 <font color="red"><b>rpc_wa</b></font> 11:57 pts / 0 00:00:01 find.  -type f <br></blockquote><br>  To make sure that the process continues to be in the same state, ps must be run several times in a row (you do not want to come to a false conclusion on the basis of a single attempt made at the wrong moment?).  However, here I bravely show only one launch. <br><br>  The process is in state D (‚Äúdeep sleep‚Äù), which is usually associated with disk I / O (which is what the ps man page also says).  In addition, the WCHAN field (the name of the function that led the process to hibernation / standby) is slightly truncated.  I can add an option to the ps call to make the output of this field a little wider, however, since its contents come from the / proc system anyway, let's look at the source (again, it would be nice to do it several times to make sure it hung whether the process is complete, or just very often and often sleeps): <br><br><blockquote>  [root @ oel6 ~] # cat / proc / 27288 / <strong>wchan</strong> <br>  <strong>rpc_wait_bit_killable</strong> <strong><br></strong> <br></blockquote><br>  Hmm ... Looks like the process is waiting for some kind of RPC call.  This usually means that the process communicates with other processes (either on a local machine, or even on a remote server).  But we still do not know why. <br><br><h4>  Is there any movement, or is the process completely frozen? </h4><br>  Before moving on to the very ‚Äúmeat‚Äù of the article, let's determine whether the process is completely frozen or not.  On modern kernels, you can learn about this by studying / proc / PID / status.  For clarity, I have highlighted interesting values ‚Äã‚Äãfor us: <br><br><blockquote>  [root @ oel6 ~] # cat / proc / 27288 / <strong>status</strong> <br>  Name: find <br>  <strong>State: D (disk sleep)</strong> <strong><br></strong>  Tgid: 27288 <br>  Pid: 27288 <br>  PPid: 27245 <br>  TracerPid: 0 <br>  Uid: 0 0 0 0 <br>  Gid: 0 0 0 0 <br>  FDSize: 256 <br>  Groups: 0 1 2 3 4 6 10 <br>  VmPeak: 112628 kB <br>  VmSize: 112280 kB <br>  VmLck: 0 kB <br>  VMHWM: 1508 kB <br>  VmRSS: 1160 kB <br>  VmData: 260 kB <br>  VmStk: 136 kB <br>  VmExe: 224 kB <br>  VmLib: 2468 kB <br>  VmPTE: 88 kB <br>  VmSwap: 0 kB <br>  Threads: 1 <br>  SigQ: 4/15831 <br>  SigPnd: 0000000000040000 <br>  ShdPnd: 0000000000000000 <br>  SigBlk: 0000000000000000 <br>  SigIgn: 0000000000000000 <br>  SigCgt: 0000000180000000 <br>  CapInh: 00000000000000 <br>  CapPrm: ffffffffffffffffff <br>  CapEff: ffffffffffffffff <br>  CapBnd: ffffffffffffffff <br>  Cpus_allowed: ffffffff, ffffffff <br>  Cpus_allowed_list: 0-63 <br>  Mems_allowed: 00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000, 00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000001 <br>  Mems_allowed_list: 0 <br>  <strong>voluntary_ctxt_switches: 9950</strong> <strong><br></strong>  <strong>nonvoluntary_ctxt_switches: 17104</strong> <strong><br></strong> <br></blockquote><br>  The process is in a state of D - disk sleep ("deep sleep").  Also, pay attention to the values <code>voluntary_ctxt_switches</code> and <code>nonvoluntary_ctxt_switches</code> - they will tell us how many times the processor received CPU quanta (or gave back).  Then, after a few seconds, run the command again and check if the values ‚Äã‚Äãhave increased.  In my case, the numbers did not increase, and therefore I would assume that the process hung tight (well, or at least never woke up during those few seconds between the teams).  So, now I can be more sure that the process is completely frozen (and not just flying below the radar, constantly consuming 0.04% of the CPU time). <br><br>  By the way, there are two more places where you can see the number of context switches (and the second one, in addition, is available on the ancient cores): <br><br><blockquote>  [root @ oel6 ~] # cat / proc / 27288 / <strong>sched</strong> <br>  find (27288, #threads: 1) <br>  - se.exec_start: 617547410.689282 <br>  se.vruntime: 2471987.542895 <br>  se.sum_exec_runtime: 1119.480311 <br>  se.statistics.wait_start: 0.000000 <br>  se.statistics.sleep_start: 0.000000 <br>  se.statistics.block_start: 617547410.689282 <br>  se.statistics.sleep_max: 0.089192 <br>  se.statistics.block_max: 60082.951331 <br>  se.statistics.exec_max: 1.110465 <br>  se.statistics.slice_max: 0.334211 <br>  se.statistics.wait_max: 0.812834 <br>  se.statistics.wait_sum: 724.745506 <br>  se.statistics.wait_count: 27211 <br>  se.statistics.iowait_sum: 0.000000 <br>  se.statistics.iowait_count: 0 <br>  se.nr_migrations: 312 <br>  se.statistics.nr_migrations_cold: 0 <br>  se.statistics.nr_failed_migrations_affine: 0 <br>  se.statistics.nr_failed_migrations_running: 96 <br>  se.statistics.nr_failed_migrations_hot: 1794 <br>  se.statistics.nr_forced_migrations: 150 <br>  <strong>se.statistics.nr_wakeups: 18507</strong> <strong><br></strong>  se.statistics.nr_wakeups_sync: 1 <br>  se.statistics.nr_wakeups_migrate: 155 <br>  se.statistics.nr_wakeups_local: 18504 <br>  se.statistics.nr_wakeups_remote: 3 <br>  se.statistics.nr_wakeups_affine: 155 <br>  se.statistics.nr_wakeups_affine_attempts: 158 <br>  se.statistics.nr_wakeups_passive: 0 <br>  se.statistics.nr_wakeups_idle: 0 <br>  avg_atom: 0.041379 <br>  avg_per_cpu: 3.588077 <br>  <strong>nr_switches: 27054</strong> <strong><br></strong>  <strong>nr_voluntary_switches: 9950</strong> <strong><br></strong>  <strong>nr_involuntary_switches: 17104</strong> <strong><br></strong>  se.load.weight: 1024 <br>  policy: 0 <br>  prio: 120 <br>  clock-delta: 72 <br></blockquote><br>  Here you need to look at the number <code>nr_switches</code> (which is equal to <code>nr_voluntary_switches</code> + <code>nr_involuntary_switches</code> ). <br><br>  The total number of nr_switches is 27054 in the above slice, and is also located in the third field in the / proc / PID / schedstat output: <br><br><blockquote>  [root @ oel6 ~] # cat / proc / 27288 / <strong>schedstat</strong> <br>  1119480311 724745506 <strong>27054</strong> <strong><br></strong> <br></blockquote><br>  And it does not increase ... <br><br><h4>  Examine the kernel's internal kitchen using the / proc file system. </h4><br>  It seems that our process is very tightly frozen :).  Strace and pstack are useless.  They use the ptrace () system call to connect to the process and inject it into its memory, but since the process is hopelessly hung, most likely in some kind of system call, I assume that the ptrace () call also hangs on its own (by the way, I I somehow tried to run strace on strace itself at the moment when it connects to the target process. And this led to a crash of the process. I warned! :) <br><br>  How do we know in which system call we hang, having neither strace nor pstack?  Fortunately, we are working on a modern core!  Poprivetsvuemu / proc / PID / syscall! <br><br><blockquote>  [root @ oel6 ~] # cat / proc / 27288 / <strong>syscall</strong> <br>  <font color="red"><strong>262</strong></font> 0xffffffffffffffff9c 0x20cf6c8 0x7fff97c52710 0x100 0x100 0x676e776f645f616d 0x7fff97c52658 0x390e2da8ea <br></blockquote><br>  Hurt yourself!  And what should I do about it ??? <br>  Well, usually these numbers are needed for something.  If we see something like ‚Äú0xAVeryBigNumber‚Äù, then this is usually an address in memory (and they can be used with utilities like pmap), and if the number is small, most likely it is an index to some kind of array.  For example, an array of open file descriptors (which you can see in / proc / PID / fd), or, in this case, since we are dealing with system calls ‚Äî this is the number of the system call that the process is in!  So, we now know that the process is frozen in the system call # 262! <br><br>  Note that system call numbers may vary between different operating systems, operating system versions and platforms, and therefore you will need the correct header file from your operating system.  It‚Äôs nice to start by searching for ‚Äúsyscall *‚Äù in the / usr / include folder.  On my version and the Linux platform (64bit), the system calls are defined in the <code>/usr/include/asm/unistd_64.h</code> file: <br><br><blockquote>  [root @ oel6 ~] # grep 262 <strong>/usr/include/asm/unistd_64.h</strong> <br>  #define __NR_ <font color="red"><strong>newfstatat</strong></font> <strong>262</strong> <strong><br></strong> <br></blockquote><br>  We are almost there!  System call 262 is something called <code>newfstatat</code> .  It remains to run the man and find out what it is.  Give a little hint about the names of the system calls: if the man page does not find the desired name, try searching without any possible suffixes and prefixes (for example, ‚Äúman pread‚Äù instead of ‚Äúman pread64 ‚Ä≥) - and in this case, run man without the prefix‚Äú new ‚Äù- <code>man fstatat</code> .  Well, or just google. <br><br>  However, this system call, ‚Äúnew-fstat-at‚Äù, gives you the ability to read file properties in a very similar way to how a regular stat system call does.  And we are stuck just in a file metadata read operation.  So, we have moved one step further.  However, we still do not know why the hangup happened! <br><br>  Well, it's time to greet <a href="https://www.youtube.com/watch%3Fv%3Da_z4IuxAqpE">my little friend</a> <b>/ proc / PID / stack</b> , which will allow you to view the chain of the nuclear stack of the process just by printing the contents of the proc file !!! <br><br><blockquote>  [root @ oel6 ~] # cat / proc / 27288 / <strong>stack</strong> <br>  [] <strong>rpc_wait_bit_killable</strong> + 0x24 / 0x40 [sunrpc] <br>  [] __rpc_execute + 0xf5 / 0x1d0 [sunrpc] <br>  [] rpc_execute + 0x43 / 0x50 [sunrpc] <br>  [] rpc_run_task + 0x75 / 0x90 [sunrpc] <br>  [] rpc_call_sync + 0x42 / 0x70 [sunrpc] <br>  <strong>[] nfs3_rpc_wrapper.clone.0 + 0x35 / 0x80 [nfs]</strong> <strong><br></strong>  <strong>[] nfs3_proc_getattr + 0x47 / 0x90 [nfs]</strong> <strong><br></strong>  <strong>[] __nfs_revalidate_inode + 0xcc / 0x1f0 [nfs]</strong> <strong><br></strong>  <strong>[] nfs_revalidate_inode + 0x36 / 0x60 [nfs]</strong> <strong><br></strong>  <strong>[] <font color="red">nfs</font> _getattr + 0x5f / 0x110 [nfs]</strong> <br>  [] vfs_getattr + 0x4e / 0x80 <br>  [] vfs_fstatat + 0x70 / 0x90 <br>  [] sys_ <strong>newfstatat</strong> + 0x24 / 0x50 <br>  [] system_call_fastpath + 0x16 / 0x1b <br>  [] 0xffffffffffffffff <br></blockquote><br>  The top function is the place in the kernel code where we hang.  This is exactly what the WCHAN field already told us (but notice that there are actually some other functions above, such as the nuclear function <code>schedule()</code> , which puts the processes to sleep or wakes up as needed. However, these functions are not shown here perhaps because they are already the result of the wait state itself, and not its cause). <br><br>  Having a full kernel stack for this task, we can study it from bottom to top and try to figure out how the <code>rpc_wait_bit_killable</code> function <code>rpc_wait_bit_killable</code> led the scheduler to call and put us to sleep. <br><br>  The <code>system_call_fastpath</code> call is the standard kernel system call handler that caused the code that implements the newfstatat ( <code>sys_newfstatat</code> ) system call that we are dealing with.  Moving further into the "daughter" functions, we see several pieces related to NFS.  This is already 100% irrefutable proof that we are somewhere around the NFS processing code!  I do not say ‚Äúin NFS code‚Äù, as long as we can see how the extreme of these NFS functions, in turn, calls some kind of RPC function (rpc_call_sync) to communicate with another process.  In this case, it is probably <code>[kworker/N:N]</code> , <code>[nfsiod]</code> , <code>[lockd]</code> or <code>[rpciod]</code> IO kernel threads.  And for some reason, one of these streams does not respond at all (usually you should suspect a broken network connection, packet loss, or just some network problems). <br><br>  To figure out whether any of these helper threads are dependent on the network-related code, you also need to consider their stacks, although, for example, kworkers perform much more functions than just an RPC for NFS connection.  During a separate experiment (just copying a large file via NFS), I caught one of the kworkers waiting in the code to communicate with the network: <br><br><blockquote>  [root @ oel6 proc] # for i in `pgrep worker`;  do ps -fp $ i;  cat / proc / $ i / stack;  done <br>  UID PID PPID C STIME TTY TIME CMD <br>  root 53 2 0 Feb14?  00:04:34 [ <strong>kworker</strong> / 1: 1] <br><br>  [] __cond_resched + 0x2a / 0x40 <br>  [] lock_sock_nested + 0x35 / 0x70 <br>  <strong>[] tcp_sendmsg + 0x29 / 0xbe0</strong> <br>  [] inet_sendmsg + 0x48 / 0xb0 <br>  [] sock_sendmsg + 0xef / 0x120 <br>  [] kernel_sendmsg + 0x41 / 0x60 <br>  [] xs_send_kvec + 0x8e / 0xa0 [sunrpc] <br>  [] xs_sendpages + 0x173 / 0x220 [sunrpc] <br>  [] xs_tcp_send_request + 0x5d / 0x160 [sunrpc] <br>  [] xprt_transmit + 0x83 / 0x2e0 [sunrpc] <br>  [] call_transmit + 0xa8 / 0x130 [sunrpc] <br>  [] __rpc_execute + 0x66 / 0x1d0 [sunrpc] <br>  <strong>[] rpc_async_schedule + 0x15 / 0x20 [sunrpc]</strong> <strong><br></strong>  [] process_one_work + 0x13e / 0x460 <br>  [] worker_thread + 0x17c / 0x3b0 <br>  [] kthread + 0x96 / 0xa0 <br>  [] kernel_thread_helper + 0x4 / 0x10 <br></blockquote><br>  It is probably not difficult to turn on kernel tracing and find out exactly which kernel threads communicate with each other, but in this article I don‚Äôt want to do this.  Let it be a practical (and simple) diagnostic exercise! <br><br><h4>  We understand and "repair" </h4><br>  In any case, thanks to the ability to very easily get a printout of the kernel stack in modern Linux (I can not say exactly which version of the kernel it appeared), we were able to consistently conclude exactly where our find command hung - namely, in the NFS code in the kernel Linux  And when you are dealing with a hangup associated with NFS, you should most likely suspect a problem with the network.  If you are curious about how I reproduced this problem, then everything is very simple: I mounted the NFS volume from the virtual machine, ran the find command, and then suspended the machine.  This led to the same symptoms as if there was a network (configuration, firewall) problem, where the connection silently terminates without notifying the TCP end nodes, or where the packets simply do not pass for some reason. <br><br>  Since the top of the stack contains one of the ‚Äúkill‚Äù functions (which can be safely interrupted, <code>rpc_wait_bit_killable</code> ), we can kill it with the command <code>kill -9</code> : <br><br><blockquote>  [root @ oel6 ~] # ps -fp 27288 <br>  UID PID PPID C STIME TTY TIME CMD <br>  root 27288 27245 0 11:57 pts / 0 00:00:01 <strong>find.</strong>  <strong>-type f</strong> <br>  [root @ oel6 ~] # <font color="red"><strong>kill -9</strong></font> 27288 <br><br>  [root @ oel6 ~] # ls -l / proc / 27288 / stack <br>  ls: cannot access / proc / 27288 / stack: No such file or directory <br><br>  [root @ oel6 ~] # ps -fp 27288 <br>  UID PID PPID C STIME TTY TIME CMD <br>  [root @ oel6 ~] # <br></blockquote><br>  the process is complete. <br><br><h4>  Profiling kernel threads "on the knee" </h4><br>  Notice that the / proc / PID / stack file looks like a regular text file.  So you can easily get a kernel thread profile!  Here's how you can ‚Äúon the knee‚Äù find out the current system call, as well as the promotion of the kernel stack (if you are in the system call), and then combine all this into a semi-hierarchical profile: <br><br><blockquote>  [root @ oel6 ~] # <strong>export LC_ALL = C</strong> ;  for i in {1..100};  do cat / proc / 29797 / <strong>syscall</strong> |  awk '{print $ 1}';  cat / proc / 29797 / stack |  / home / oracle / os_explain -k;  usleep 100,000;  done |  sort -r |  uniq -c <br><br><pre>  69 running
       1 ffffff81534c83
       2 ffffff81534820
       6,247
      25 180 </pre><br><pre>     100 0xffffffffffffffff 
       1 thread_group_cputime 
      27 sysenter_dispatch 
       3 ia32_sysret 
       1 task_sched_runtime 
      27 sys32_pread 
       1 compat_sys_io_submit 
       2 compat_sys_io_getevents 
      27 sys_pread64 
       2 sys_io_getevents 
       1 do_io_submit 
      27 vfs_read 
       2 read_events 
       1 io_submit_one 
      27 do_sync_read 
       1 aio_run_iocb 
      27 generic_file_aio_read 
       1 aio_rw_vect_retry 
      27 generic_file_read_iter 
       1 generic_file_aio_read 
      27 mapping_direct_IO 
       1 generic_file_read_iter 
      27 blkdev_direct_IO 
      27 __blockdev_direct_IO 
      27 do_blockdev_direct_IO 
      27 dio_post_submission 
      27 dio_await_completion 
       6 blk_flush_plug_list
</pre><br></blockquote><br>  This will allow a very rough estimate of where in the core the process spends its time (if it spends it at all).  System call numbers are highlighted separately at the top.  ‚ÄúRunning‚Äù means that during the diagnostics process worked in user space (and not in system calls).  So, 69% of the time the process was in user code;  25% in the system call # 180 (nfsservctl on my system), and 6% in the system call # 247 (waitid). <br><br>  <i>Above, the author uses a call to a certain script <a href="http://blog.tanelpoder.com/files/scripts/tools/unix/os_explain">/ home / oracle / os_explain</a> .</i>  <i>You can get it on the link - approx.</i>  <i>trans.</i> <br><br>  The output shows two more "functions", for some reason they are not displayed by name.  However, their addresses are known, so we can check them manually: <br><br><blockquote>  [root @ oel6 ~] # cat / proc / <strong>kallsyms</strong> |  grep -i <strong>ffffff81534c83</strong> <br>  ffffffff81534c83 t ia32_sysret <br></blockquote><br>  It seems that this is a return from the system call for the 32-bit subsystem, however, since this function is not a system call itself (this is just an internal auxiliary function), it seems that the / proc / stack handler did not display its name.  It is also possible that these addresses are shown, because the / proc state is not consistent for the reader: while one thread modifies these memory structures and elements, the reading threads sometimes see outdated data. <br><br>  Check the second address at the same time: <br><br><blockquote>  [root @ oel6 ~] # cat / proc / kallsyms |  grep -i ffffff81534820 <br>  [root @ oel6 ~] # <br></blockquote><br>  Found nothing?  Well, however, the debugging is not over!  Let's look for something interesting around this address.  For example, delete the last couple of digits at the end of the address: <br><br><blockquote>  [root @ oel6 ~] # cat / proc / kallsyms |  grep -i ffffff815348 <br>  ffffffff8153480d t sysenter_do_call <br>  <strong>ffffffff81534819 t sysenter_dispatch</strong> <strong><br></strong>  ffffffff81534847 t sysexit_from_sys_call <br>  ffffffff8153487a t sysenter_auditsys <br>  ffffffff815348b9 t sysexit_audit <br></blockquote><br>  It looks like the sysenter_dispatch function starts with just one byte before the original address displayed in / proc / PID / stack.  Therefore, we most likely almost completed one byte (perhaps the NOP command located there for dynamic debugging).  However, it seems that these pieces of the stack are in the <code>sysenter_dispatch</code> function, which is not itself a system call, but an auxiliary function.  ( <i>If you dig a little bit - there is still a difference not in 1, but in 7 bytes. The numbers are hexadecimal! - approx. Transl.</i> ) <br><br><h4>  More about stack profiling </h4><br>  Notice that the existing various stack promotion utilities - Perf on Linux, the Oprofile and <code>profile</code> utilities from DTrace on Solaris fix the instruction pointer registers (EIP on 32-bit Intel, or RIP on x64), and also the stack pointer (ESP on 32bit and RSP on x64) for the current thread on the processor, and then follow the stack pointers back.  Thus, these utilities are able to show only those threads that are running on the CPU at the time of testing!<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">This is certainly great when we are looking for problems with a high CPU load, but it is completely useless for diagnosing tightly hung or waiting for a while / hibernating processes. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Utilities like pstack on Linux, Solaris, HP-UX, procstack (on AIX), ORADEBUG SHORT_STACK, and just reading the / proc / PID / stack pseudo file are a good addition (but not a replacement) for CPU profiling utilities - as long as they give access to the process memory independently from his state in the scheduler and read the stack right from there. If the process is asleep and does not concern the CPU, then the top of the process stack can be read from the saved context - which is stored in the kernel memory by the OS scheduler during context switching.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Of course, CPU event profiling utilities can often provide much more than just pstack, OProfile, Perf, and even the CPC provider in DTrace (on Solaris11). </font><font style="vertical-align: inherit;">For example, install and read internal processor counters to evaluate things like the number of missed CPU cycles while waiting for memory access; </font><font style="vertical-align: inherit;">the number of L1 / L2 cache misses, etc. </font><font style="vertical-align: inherit;">But better read what Kevin Closson writes about this: ( </font></font><a href="http://kevinclosson.wordpress.com/2013/02/18/using-linux-perf1-to-analyze-database-processes-part-i/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Perf</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , </font></font><a href="http://kevinclosson.wordpress.com/2006/12/14/using-oprofile-to-monitor-kernel-overhead-on-linux-running-oracle/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Oprofile</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ) </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Good luck :-)</font></font><br><br><h4>  Related Topics </h4><br><ul><li> <a href="http://blog.tanelpoder.com/2011/02/28/finding-oracle-homes-with/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Finding Oracle Homes which Oracle instances are using on ...</font></font></a> </li><li> <a href="http://blog.tanelpoder.com/2013/05/27/debugger-dangers-part-2/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Debugger Dangers - Part 2</font></font></a> </li><li> <a href="http://blog.tanelpoder.com/2011/07/06/what-is-the-purpose-of-segment-level-checkpoint-before-droptruncate-of-a-table/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Checkpoint before segment</font></font></a> </li><li> <a href="http://blog.tanelpoder.com/2011/11/13/evil-things-are-happening-in-oracle/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Evil things are happening in Oracle</font></font></a> </li><li> <a href="http://blog.tanelpoder.com/2011/03/13/oracle-exadata-performance-series-part-1-should-i-use-hugepages-on-linux-database-nodes/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Oracle Exadata Performance series - Part 1: Should I ...</font></font></a> </li></ul></div><p>Source: <a href="https://habr.com/ru/post/209446/">https://habr.com/ru/post/209446/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../209434/index.html">Japanese space agency JAXA is going to hunt space junk with a network in February</a></li>
<li><a href="../209436/index.html">About logging in Node.js</a></li>
<li><a href="../209438/index.html">Attack with your time server: NTP amplification attack (CVE-2013-5211)</a></li>
<li><a href="../209442/index.html">Components. Make & watch</a></li>
<li><a href="../209444/index.html">Transferring data between servers using LVM and iSCSI</a></li>
<li><a href="../209450/index.html">The future of IT within companies: less, better, cheaper</a></li>
<li><a href="../209452/index.html">US authorities seized another 29655 bitcoins ($ 28 million) from Silk Road servers</a></li>
<li><a href="../209454/index.html">Laboratories for penetration testing "Test.lab"</a></li>
<li><a href="../209458/index.html">Google showed the dynamics of the popularity of music trends over the past 64 years</a></li>
<li><a href="../209460/index.html">Creating reliable iSCSI storage on Linux, part 1</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>