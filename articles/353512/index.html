<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>HMD + Kinect = Augmented Virtuality</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="In this post I want to talk about the idea and Proof-Of-Concept of adding real-world objects to Virtual Reality. 

 In my opinion, the idea described ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>HMD + Kinect = Augmented Virtuality</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/webt/kt/vw/t3/ktvwt3fszmbdmwgb2_vnlovp5iy.png"><br>  In this post I want to talk about the idea and Proof-Of-Concept of adding real-world objects to Virtual Reality. <br><br>  In my opinion, the idea described in the near future will be implemented by all players of the VR market.  IMHO, the only reason why this has not yet been done - the desire to roll out the perfect solution, but it is not so easy. <br><a name="habracut"></a><br>  For many years, I have been thinking over the design of the hydraulic cabin for the MechWarrow simulator. <br><br><div class="spoiler">  <b class="spoiler_title">Of course, I will never do it.</b> <div class="spoiler_text">  Since  It requires quite significant investments, while it is quite clear that interest in it will be lost immediately after the end of the project.  I have no place to store the received bandura, but I don‚Äôt have a commercial vein to sell / rent to someone. <br></div></div><br>  But it does not interfere to periodically think about all sorts of designs. <br>  Previously, I planned to place many displays inside the cab, some of which will work as intended, and the second part will emulate ‚Äúwindows‚Äù / loopholes. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      However, in the modern world, another solution comes to mind - the VR-helmet (Head-Mounted Display).  To achieve high-quality immersion is much easier when working with a helmet, because  no need to thoroughly lick the interior of a real cabin.  Yes, and rework design at times easier, but there is BUT. <br><br>  A normal fur control panel is a complex and interesting thing.  The simplest authentic controller looks like this: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a58/494/fef/a58494fef35f54501a77baddbf6b07d4.png" alt="image"><br><br>  To do something in a serious simulator (for example, control from a gamepad) is not an option. <br>  Suppose that modeling the control panel and placing it in the VR world is not a problem. <br>  However, managing such a number of small toggle switches by touch is a very bad idea. <br>  But how to be, because the user does not see his hands in the VR world. <br><br>  Of course have <br><br><div class="spoiler">  <b class="spoiler_title">special gloves</b> <div class="spoiler_text"><img src="https://habrastorage.org/getpro/habr/post_images/d19/f27/32a/d19f2732a5d6c831c53aebca0e4d5c7c.jpg" alt="image"><br></div></div><br>  but today is not about them ... <br><br>  At the moment, depth cameras are actively developing.  The first they were declared by Microsoft with their Kinect.  Unfortunately, the MC decided that Kinekt was not economically justified and closed the project.  However, the matter did not die, as one might think.  Apple has implemented a depth camera in the last iPhone, it is this camera that is responsible for recognizing the owner's face. <br>  MS also did not abandon the technology, VR-helmets on the Windows Mixed Reality platform use inside-out tracking technology based on depth cameras. <br><br>  The obvious solution is to screw the depth camera onto the VR helmet and apply the resulting geometry on the VR world.  But for some reason nobody does it. <br><br>  ZED Mini seems to be able to build a 3D world and are mounted on a helmet, but I did not see them live, and all promo videos use world information only to apply 3D models to it, but not vice versa.  I suppose the problem is the low quality of the resulting model, which will be immediately visible when you try to render. <br><br>  Unfortunately, I have no opportunity to fasten Kinekt on the helmet.  The kinekt is huge and heavy, without invasive intervention in the design of the helmet a normal mount is not done.  A helmet borrowed and I can not spoil it. <br><br>  Therefore, for this mini-project, I placed the kinekt vertically above the table. <br>  This option suits me completely, because  if the kinekt was placed inside the virtual fur cabin, it would also be placed above the control panel to detect only the player‚Äôs hands and cut off all other objects. <br><br>  Let's move on to the project (there will be no code parsing, only theory and some pictures) <br><br>  Using libfreenect2 and OpenNI, we get a height map. <br>  How to visualize this elevation map? <br>  The obvious options in the Unreal Engine are three. <br><br>  <b>Mesh with height map defining Z vertex offset.</b> <br><br>  The obvious and fastest option.  The mesh is completely static, only the textures change (which is very fast). <br><br>  Unfortunately, this method has a serious drawback: the lack of ability to fasten physics.  From the point of view of physics, such a mesh is absolutely flat and integral.  Simple rectangle.  The fact that we have part of the vertices is transparent and cut off by the alpha test - physics does not see.  The fact that our vertices are modified by the Z coordinate - physics does not see. <br><br>  <b>Manually build the mesh at a low level.</b> <br><br>  To do this, we need to block the UPrimitiveComponent and implement a new component using SceneProxy.  This is a low-level approach that gives better speed. <br>  The main disadvantage is rather high implementation complexity. <br>  If you do fully - it is this option and should be elected. <br>  But since  I had a task to make quickly and simply, I used the third option. <br><br>  <b>Implementation based on UProceduralMeshComponent</b> <br><br>  This is a component built into the UE that allows you to easily create a mesh and even immediately read the object for calculating collisions. <br><br>  Why use the second option, and not this one? <br><br>  Because this component is not designed to work with dynamic geometry.  He is sharpened so that we once (or at least not very often and preferably not in real-time) transfer geometry to him, it is slowly considered, and then we quickly work with it.  This is not the case ... <br><br>  But for the test come down.  Moreover, the scene is empty and the computer has nothing more to count, so there are resources with a margin. <br><br>  To visualize objects with their image from the camera is not an option.  Real photos stand out against the background of the virtual world. <br><br>  Therefore, I decided to visualize it by analogy with the SteamVR lines.  Overlayed the texture of the blue grid without filling.  Plus, the contour made a stroke.  It turned out quite acceptable.  True, with full transparency, the hands were perceived a little worse, so filling the squares made slightly noticeable bluish. <br><br><img src="https://habrastorage.org/webt/iv/3q/la/iv3qlag9lh7jcw3n_kxaa1eya1i.png"><br><br>  The screenshot shows the effect of "runoff" geometry.  This is due to the inability of the depth cameras to normally process faces with an angle close to 90 degrees to the camera.  Explicitly degenerate pixels kinekt marks the value 0, but, unfortunately, not all, and some of them "noise" without degenerating.  I made a set of simple manipulations to remove the main noise, but I couldn‚Äôt completely get rid of the ‚Äúrunoff‚Äù. <br><br>  It is worth noting that this effect is very noticeable when viewed from the side (sitting in front of the table, and kinekt from above).  If the depth camera is directed parallel to the gaze and comes from a point close to the user's real organs of vision, this effect will be directed forward and much less noticeable. <br><br>  As you can see in the video, real hands work quite well inside the VR world.  The only serious drawback is the displacement resolution. <br><br>  The mesh does not morph smoothly into the new state, but is removed and re-created.  Because of the sudden movement of physical objects fail through it, so we move slowly and carefully: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/wYUDvqK1zps" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  <i>I apologize for the dark video - I was working on the project in the evenings after work, on the preview video seemed normal when all the equipment was already taken and transferred the video to the computer - it turned out that it was very dark.</i> <br><br><div class="spoiler">  <b class="spoiler_title">How to feel yourself</b> <div class="spoiler_text">  Something tells me that people who will simultaneously have HMD (optional), Kinect, the ability to work with the UE and the desire to try this project is quite small (not at all?).  Therefore, I don‚Äôt see any reason to upload the source code to the githab. <br><br>  I spread the <a href="https://drive.google.com/open%3Fid%3D1dQrMLWzx72xB8CSa3W3kTNmBs4SDzmL1">source code of the plugin</a> in the form of an archive. <br><br>  Add as a regular plugin to any UE project. <br>  I did not understand how to connect the lib file using a relative path, so in OpenNI2CameraAndMesh.Build.cs we set the full path to OpenNI2.lib <br>  Next we place ADepthMeshDirect in the right place for us. <br>  When starting the level, call the startOpenNICamera method from UTools. <br>  Do not forget that libfreenect2 is used to work with the kinekt, which means that the driver for the kinekt should be redefined to libusbK in accordance with the instructions on the libfreenect2 page <br></div></div><br>  UPD: <br>  At the beginning of the article, I said that such a system would soon be in all VR helmets.  But in the process of writing, I somehow missed this moment and did not reveal it. <br><br>  Therefore, I will quote my comment, which I wrote below to disclose this topic: <br><blockquote> If to say - why such a system is needed in all VR systems without exception - this is security. <br><br>  Now the boundaries of the playing area are marked with a conditional cube. <br><br>  But rarely one of us can afford to allocate an absolutely empty space for VR.  As a result, objects remain in the room, sometimes <a href="https://geektimes.ru/post/296713/">dangerous</a> . <br>  The main thing that I am sure will be done is a virtual display of the entire room in front of the player in the form of a barely perceptible ghost, which on the one hand does not interfere with the perception of the game, and on the other - allows you not to stumble and not die. </blockquote><br>  PS: <br>  I want to express my deep gratitude to the company ‚Äúwhich cannot be called outside of the corporate blog‚Äù, whose management has allocated me the technical basis for working on this project. </div><p>Source: <a href="https://habr.com/ru/post/353512/">https://habr.com/ru/post/353512/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../353502/index.html">Associative rules, or beer with diapers</a></li>
<li><a href="../353504/index.html">Root access through TeamCity</a></li>
<li><a href="../353506/index.html">Drupalgeddon2: SA-CORE-2018-002 operation began</a></li>
<li><a href="../353508/index.html">Imagine Cup 2018: live broadcast</a></li>
<li><a href="../353510/index.html">How can you develop two parts of the game for six months and not go crazy</a></li>
<li><a href="../353514/index.html">W3C and WHATWG standoff: Apple, Google, Microsoft, Mozilla object to DOM 4.1</a></li>
<li><a href="../353516/index.html">The history of information security in China: starting to deal with laws and regulations</a></li>
<li><a href="../353518/index.html">IPO and $ 250 million: HeadHunter will be released on Nasdaq</a></li>
<li><a href="../353520/index.html">The EU enters into force the new regulations on the protection of PD</a></li>
<li><a href="../353522/index.html">New proof of the polynomial theorem</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>