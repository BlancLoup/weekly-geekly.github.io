<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>System.IO.Pipelines: High Performance IO in .NET</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="System.IO.Pipelines is a new library that simplifies code organization in .NET. It is difficult to ensure high performance and accuracy if you have to...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>System.IO.Pipelines: High Performance IO in .NET</h1><div class="post__text post__text-html js-mediator-article">  <a href="https://www.nuget.org/packages/System.IO.Pipelines/">System.IO.Pipelines</a> is a new library that simplifies code organization in .NET.  It is difficult to ensure high performance and accuracy if you have to deal with complex code.  The task of System.IO.Pipelines is to simplify the code.  More under the cut! <br><br><img src="https://habrastorage.org/webt/nq/me/p-/nqmep-tqvyyv5nlkpcxjnmlw8z4.jpeg"><a name="habracut"></a><br><br>  The library came as a result of the efforts of the .NET Core development team, which sought to make Kestrel one of <a href="https://www.techempower.com/benchmarks/">the fastest web servers in the industry</a> .  It was originally conceived as part of the Kestrel implementation, but evolved into a reusable API, available in version 2.1 as the first class BCL API (System.IO.Pipelines). 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h2>  What problems does she solve? </h2><br>  To properly analyze data from a stream or socket, you need to write a large amount of standard code.  At the same time, there are many pitfalls that complicate both the code itself and its support. <br><br><h2>  What difficulties arise today? </h2><br>  Let's start with a simple task.  We need to write a TCP server that receives line-delimited messages from the client (\ n). <br><br><h2>  TCP Server with NetworkStream </h2><br>  REMOVAL: As with any task that requires high performance, each case should be considered based on the characteristics of your application.  It is possible that spending resources on the use of various approaches, which will be discussed further, does not make sense if the scale of the network application is not very large. <br><br>  Normal .NET code before using pipelines looks like this: <br><br><pre><code class="cs hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">async</span></span></span><span class="hljs-function"> Task </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">ProcessLinesAsync</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">NetworkStream stream</span></span></span><span class="hljs-function">)</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> buffer = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-keyword"><span class="hljs-keyword">byte</span></span>[<span class="hljs-number"><span class="hljs-number">1024</span></span>]; <span class="hljs-keyword"><span class="hljs-keyword">await</span></span> stream.ReadAsync(buffer, <span class="hljs-number"><span class="hljs-number">0</span></span>, buffer.Length); <span class="hljs-comment"><span class="hljs-comment">// Process a single line from the buffer ProcessLine(buffer); }</span></span></code> </pre> <br>  see <a href="https://gist.github.com/terrajobst/ee86ab15d1d7a1d5869d1c1f2443f3b3">sample1.cs</a> on <a href="https://gist.github.com/terrajobst/ee86ab15d1d7a1d5869d1c1f2443f3b3">github</a> <br><br>  Probably, this code will work with local testing, but it has some errors: <br><br><ul><li>  Perhaps after a single call to ReadAsync, the entire message will not be received (until the end of the line). </li><li>  It ignores the result of the work of the stream.ReadAsync () method - the amount of data actually transferred to the buffer. </li><li>  The code does not handle receiving multiple lines in a single ReadAsync call. </li></ul><br>  These are the most common errors in reading streaming data.  To avoid them, you need to make a number of changes: <br><br><ul><li>  You need to buffer incoming data until a new string is found. </li><li>  It is necessary to analyze all the rows returned to the buffer. </li></ul><br><pre> <code class="cs hljs"> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">async</span></span></span><span class="hljs-function"> Task </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">ProcessLinesAsync</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">NetworkStream stream</span></span></span><span class="hljs-function">)</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> buffer = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-keyword"><span class="hljs-keyword">byte</span></span>[<span class="hljs-number"><span class="hljs-number">1024</span></span>]; <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> bytesBuffered = <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> bytesConsumed = <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> (<span class="hljs-literal"><span class="hljs-literal">true</span></span>) { <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> bytesRead = <span class="hljs-keyword"><span class="hljs-keyword">await</span></span> stream.ReadAsync(buffer, bytesBuffered, buffer.Length - bytesBuffered); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (bytesRead == <span class="hljs-number"><span class="hljs-number">0</span></span>) { <span class="hljs-comment"><span class="hljs-comment">// EOF break; } // Keep track of the amount of buffered bytes bytesBuffered += bytesRead; var linePosition = -1; do { // Look for a EOL in the buffered data linePosition = Array.IndexOf(buffer, (byte)'\n', bytesConsumed, bytesBuffered - bytesConsumed); if (linePosition &gt;= 0) { // Calculate the length of the line based on the offset var lineLength = linePosition - bytesConsumed; // Process the line ProcessLine(buffer, bytesConsumed, lineLength); // Move the bytesConsumed to skip past the line we consumed (including \n) bytesConsumed += lineLength + 1; } } while (linePosition &gt;= 0); } }</span></span></code> </pre> <br>  see <a href="https://gist.github.com/terrajobst/8e077db206883ca156dfdb7643969c76">sample2.cs</a> on <a href="https://gist.github.com/terrajobst/8e077db206883ca156dfdb7643969c76">github</a> <br><br>  I repeat: this could work with local testing, but sometimes there are lines longer than 1 KB (1024 bytes).  It is necessary to increase the size of the input buffer until a new line is found. <br><br>  In addition, we collect buffers into an array when processing long strings.  We can improve this process using ArrayPool, which will avoid re-allocation of buffers during the analysis of long rows coming from the client. <br><br><pre> <code class="cs hljs"> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">async</span></span></span><span class="hljs-function"> Task </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">ProcessLinesAsync</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">NetworkStream stream</span></span></span><span class="hljs-function">)</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">byte</span></span>[] buffer = ArrayPool&lt;<span class="hljs-keyword"><span class="hljs-keyword">byte</span></span>&gt;.Shared.Rent(<span class="hljs-number"><span class="hljs-number">1024</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> bytesBuffered = <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> bytesConsumed = <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> (<span class="hljs-literal"><span class="hljs-literal">true</span></span>) { <span class="hljs-comment"><span class="hljs-comment">// Calculate the amount of bytes remaining in the buffer var bytesRemaining = buffer.Length - bytesBuffered; if (bytesRemaining == 0) { // Double the buffer size and copy the previously buffered data into the new buffer var newBuffer = ArrayPool&lt;byte&gt;.Shared.Rent(buffer.Length * 2); Buffer.BlockCopy(buffer, 0, newBuffer, 0, buffer.Length); // Return the old buffer to the pool ArrayPool&lt;byte&gt;.Shared.Return(buffer); buffer = newBuffer; bytesRemaining = buffer.Length - bytesBuffered; } var bytesRead = await stream.ReadAsync(buffer, bytesBuffered, bytesRemaining); if (bytesRead == 0) { // EOF break; } // Keep track of the amount of buffered bytes bytesBuffered += bytesRead; do { // Look for a EOL in the buffered data linePosition = Array.IndexOf(buffer, (byte)'\n', bytesConsumed, bytesBuffered - bytesConsumed); if (linePosition &gt;= 0) { // Calculate the length of the line based on the offset var lineLength = linePosition - bytesConsumed; // Process the line ProcessLine(buffer, bytesConsumed, lineLength); // Move the bytesConsumed to skip past the line we consumed (including \n) bytesConsumed += lineLength + 1; } } while (linePosition &gt;= 0); } }</span></span></code> </pre> <br>  <i>see <a href="https://gist.github.com/terrajobst/568dad7aa8e831cf4fcb48ca370ca251">sample3.cs</a> on <a href="https://gist.github.com/terrajobst/568dad7aa8e831cf4fcb48ca370ca251">github</a></i> <br><br>  The code works, but now the buffer size has changed, as a result, many copies of it appear.  More memory is also used, since the logic does not reduce the buffer after processing the lines.  To avoid this, you can save a list of buffers, and not to change the buffer size each time when lines are received longer than 1 KB. <br><br>  In addition, we do not increase the buffer size of 1 KB, until it is completely empty.  This means that we will send smaller and smaller buffers to ReadAsync, resulting in an increase in the number of calls to the operating system. <br><br>  We will try to eliminate this and allocate a new buffer as soon as the size of the existing one is less than 512 bytes: <br><br><pre> <code class="cs hljs"> <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-keyword"><span class="hljs-keyword">class</span></span> <span class="hljs-title"><span class="hljs-title">BufferSegment</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-keyword"><span class="hljs-keyword">byte</span></span>[] Buffer { <span class="hljs-keyword"><span class="hljs-keyword">get</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">set</span></span>; } <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> Count { <span class="hljs-keyword"><span class="hljs-keyword">get</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">set</span></span>; } <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> Remaining =&gt; Buffer.Length - Count; } <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">async</span></span></span><span class="hljs-function"> Task </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">ProcessLinesAsync</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">NetworkStream stream</span></span></span><span class="hljs-function">)</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> minimumBufferSize = <span class="hljs-number"><span class="hljs-number">512</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> segments = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> List&lt;BufferSegment&gt;(); <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> bytesConsumed = <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> bytesConsumedBufferIndex = <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> segment = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> BufferSegment { Buffer = ArrayPool&lt;<span class="hljs-keyword"><span class="hljs-keyword">byte</span></span>&gt;.Shared.Rent(<span class="hljs-number"><span class="hljs-number">1024</span></span>) }; segments.Add(segment); <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> (<span class="hljs-literal"><span class="hljs-literal">true</span></span>) { <span class="hljs-comment"><span class="hljs-comment">// Calculate the amount of bytes remaining in the buffer if (segment.Remaining &lt; minimumBufferSize) { // Allocate a new segment segment = new BufferSegment { Buffer = ArrayPool&lt;byte&gt;.Shared.Rent(1024) }; segments.Add(segment); } var bytesRead = await stream.ReadAsync(segment.Buffer, segment.Count, segment.Remaining); if (bytesRead == 0) { break; } // Keep track of the amount of buffered bytes segment.Count += bytesRead; while (true) { // Look for a EOL in the list of segments var (segmentIndex, segmentOffset) = IndexOf(segments, (byte)'\n', bytesConsumedBufferIndex, bytesConsumed); if (segmentIndex &gt;= 0) { // Process the line ProcessLine(segments, segmentIndex, segmentOffset); bytesConsumedBufferIndex = segmentOffset; bytesConsumed = segmentOffset + 1; } else { break; } } // Drop fully consumed segments from the list so we don't look at them again for (var i = bytesConsumedBufferIndex; i &gt;= 0; --i) { var consumedSegment = segments[i]; // Return all segments unless this is the current segment if (consumedSegment != segment) { ArrayPool&lt;byte&gt;.Shared.Return(consumedSegment.Buffer); segments.RemoveAt(i); } } } } (int segmentIndex, int segmentOffest) IndexOf(List&lt;BufferSegment&gt; segments, byte value, int startBufferIndex, int startSegmentOffset) { var first = true; for (var i = startBufferIndex; i &lt; segments.Count; ++i) { var segment = segments[i]; // Start from the correct offset var offset = first ? startSegmentOffset : 0; var index = Array.IndexOf(segment.Buffer, value, offset, segment.Count - offset); if (index &gt;= 0) { // Return the buffer index and the index within that segment where EOL was found return (i, index); } first = false; } return (-1, -1); }</span></span></code> </pre> <br>  <i>see <a href="https://gist.github.com/terrajobst/aed8731297b8e8268ae6a37ebfc33146">sample4.cs</a> on <a href="https://gist.github.com/terrajobst/aed8731297b8e8268ae6a37ebfc33146">github</a></i> <br><br>  As a result, the code is significantly complicated.  During the search for a delimiter, we track the filled buffers.  To do this, use the List, which displays the buffered data when searching for a new row delimiter.  As a result, ProcessLine and IndexOf will take a List instead of byte [], offset and count.  The parsing logic will start processing one or more segments of the buffer. <br><br>  And now the server will process partial messages and use the combined memory to reduce the total memory consumption.  However, a number of changes need to be made: <br><br><ol><li>  From ArrayPoolbyte, we use only Byte [] - the standard managed arrays.  In other words, when executing the ReadAsync or WriteAsync function, the validity period of the buffers is tied to the time the asynchronous operation is performed (to interact with the operating system's own I / O API).  Since pinned memory cannot move, this affects the performance of the garbage collector and can cause array fragmentation.  It may be necessary to change the pool implementation, depending on how long the asynchronous operation waits for execution. </li><li>  Throughput can be improved by breaking the link between the logic of reading and processing.  We get the effect of batch processing, and now the parsing logic will be able to read large amounts of data, processing large blocks of buffers, rather than analyzing individual lines.  As a result, the code becomes even more complicated: <br><br><ul><li>  It is necessary to create two cycles, working independently of each other.  The first will read data from the socket, and the second will analyze the buffers. </li><li>  We need a way to tell the parsing logic that the data is available. </li><li>  You also need to determine what happens if the loop reads data from the socket too quickly.  We need a way to regulate the read cycle if the syntax analysis logic does not keep up with it.  This is commonly referred to as "flow control" or "flow resistance." </li><li>  We need to make sure that the data is transferred safely.  Now the set of buffers is used both by the read cycle and the syntax analysis cycle, they work independently from each other on different threads. </li><li>  The memory management logic is also involved in two different code fragments: borrowing data from the buffer pool, which reads data from the socket, and returning from the buffer pool, which is the logic of the syntax analysis. </li><li>  You need to be extremely careful with returning buffers after executing the parsing logic.  Otherwise, there is a possibility that we will return the buffer to which the socket reading logic is still being written. </li></ul></li></ol><br>  The difficulty begins to roll off (and this is not all cases!).  To create a high-performance network, you need to write very complex code. <br><br>  The goal of System.IO.Pipelines is to simplify this procedure. <br><br><h4>  TCP Server and System.IO.Pipelines </h4><br>  Let's see how System.IO.Pipelines works: <br><br><pre> <code class="cs hljs"> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">async</span></span></span><span class="hljs-function"> Task </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">ProcessLinesAsync</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">Socket socket</span></span></span><span class="hljs-function">)</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> pipe = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Pipe(); Task writing = FillPipeAsync(socket, pipe.Writer); Task reading = ReadPipeAsync(pipe.Reader); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> Task.WhenAll(reading, writing); } <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">async</span></span></span><span class="hljs-function"> Task </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">FillPipeAsync</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">Socket socket, PipeWriter writer</span></span></span><span class="hljs-function">)</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> minimumBufferSize = <span class="hljs-number"><span class="hljs-number">512</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> (<span class="hljs-literal"><span class="hljs-literal">true</span></span>) { <span class="hljs-comment"><span class="hljs-comment">// Allocate at least 512 bytes from the PipeWriter Memory&lt;byte&gt; memory = writer.GetMemory(minimumBufferSize); try { int bytesRead = await socket.ReceiveAsync(memory, SocketFlags.None); if (bytesRead == 0) { break; } // Tell the PipeWriter how much was read from the Socket writer.Advance(bytesRead); } catch (Exception ex) { LogError(ex); break; } // Make the data available to the PipeReader FlushResult result = await writer.FlushAsync(); if (result.IsCompleted) { break; } } // Tell the PipeReader that there's no more data coming writer.Complete(); } async Task ReadPipeAsync(PipeReader reader) { while (true) { ReadResult result = await reader.ReadAsync(); ReadOnlySequence&lt;byte&gt; buffer = result.Buffer; SequencePosition? position = null; do { // Look for a EOL in the buffer position = buffer.PositionOf((byte)'\n'); if (position != null) { // Process the line ProcessLine(buffer.Slice(0, position.Value)); // Skip the line + the \n character (basically position) buffer = buffer.Slice(buffer.GetPosition(1, position.Value)); } } while (position != null); // Tell the PipeReader how much of the buffer we have consumed reader.AdvanceTo(buffer.Start, buffer.End); // Stop reading if there's no more data coming if (result.IsCompleted) { break; } } // Mark the PipeReader as complete reader.Complete(); }</span></span></code> </pre> <br>  <i>see <a href="https://gist.github.com/terrajobst/7e04b424ab279e711eece8f6b1c233d8">sample5.cs</a> on <a href="https://gist.github.com/terrajobst/7e04b424ab279e711eece8f6b1c233d8">github</a></i> <br><br>  In the pipeline version of our row reader there are two cycles: <br><br><ul><li>  FillPipeAsync reads from the socket and writes to PipeWriter. </li><li>  ReadPipeAsync reads from PipeReader and analyzes incoming lines. </li></ul><br>  Unlike the first examples, there are no specially assigned buffers.  This is one of the main features of System.IO.Pipelines.  All buffer management tasks are passed to PipeReader / PipeWriter implementations. <br><br>  The procedure is simplified: we use code only for business logic, instead of implementing complex buffer management. <br><br>  In the first loop, PipeWriter.GetMemory (int) is first called to get a certain amount of memory from the main recorder.  It then calls PipeWriter.Advance (int), which tells PipeWriter how much data is actually written to the buffer.  This is followed by a call to PipeWriter.FlushAsync () so that PipeReader can access the data. <br><br>  The second loop consumes buffers that were recorded by PipeWriter, but initially came from a socket.  When a request is returned to PipeReader.ReadAsync (), we get a ReadResult containing two important messages: the data read in the form ReadOnlySequence, and the logical data type IsCompleted, which tells the reader whether the recorder has completed the job (EOF).  When the end-of-line (EOL) separator is found and the string is analyzed, we divide the buffer into parts to skip the already processed fragment.  After that, PipeReader.AdvanceTo is called, and it tells PipeReader how much data has been consumed. <br><br>  At the end of each cycle, both the reader and the recorder are completed.  As a result, the main channel frees all allocated memory. <br><br><h2>  System.IO.Pipelines </h2><br><h4>  Partial reading </h4><br>  In addition to memory management, System.IO.Pipelines performs another important function: it looks at the data in the channel, but does not consume it. <br><br>  PipeReader has two main APIs: ReadAsync and AdvanceTo.  ReadAsync receives data from the channel, AdvanceTo informs PipeReader that these buffers are no longer required by the reader, so you can get rid of them (for example, return to the main buffer pool). <br><br>  Below is an example of an HTTP analyzer that reads data from channel partial data buffers until it receives a suitable starting line. <br><br><img src="https://habrastorage.org/webt/9c/lp/d8/9clpd8h1r6b1m1jrwultkuggw6i.png"><br><br><h2>  ReadOnlySequenceT </h2><br>  The channel implementation stores a list of associated buffers transferred between PipeWriter and PipeReader.  PipeReader.ReadAsync reveals ReadOnlySequence, which is a new BCL type and consists of one or more ReadOnlyMemory &lt;T&gt; segments.  It is similar to Span or Memory, which gives us the opportunity to look at arrays and strings. <br><br><img src="https://habrastorage.org/webt/79/y0/kw/79y0kwylohggq941soblji6qd2o.png"><br><br>  Inside the channel there are pointers that show where the reader and the recorder are located in the general set of selected data, and also update them as they are written and read the data.  SequencePosition is a single point in the linked list of buffers and is used to efficiently separate ReadOnlySequence &lt;T&gt;. <br><br>  Since ReadOnlySequence &lt;T&gt; supports one segment and more, the standard operation of high-performance logic is the separation of fast and slow paths based on the number of segments. <br><br>  As an example, we present a function that converts ASCII ReadOnlySequence to a string: <br><br><pre> <code class="cs hljs"> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">string</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">GetAsciiString</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">ReadOnlySequence&lt;</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">byte</span></span></span></span><span class="hljs-function"><span class="hljs-params">&gt; buffer</span></span></span><span class="hljs-function">)</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (buffer.IsSingleSegment) { <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> Encoding.ASCII.GetString(buffer.First.Span); } <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-keyword"><span class="hljs-keyword">string</span></span>.Create((<span class="hljs-keyword"><span class="hljs-keyword">int</span></span>)buffer.Length, buffer, (span, sequence) =&gt; { <span class="hljs-keyword"><span class="hljs-keyword">foreach</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">var</span></span> segment <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> sequence) { Encoding.ASCII.GetChars(segment.Span, span); span = span.Slice(segment.Length); } }); }</code> </pre> <br>  see <a href="https://gist.github.com/terrajobst/6e1bea5bec4591edd7c5fe5416ce7f56">sample6.cs</a> on <a href="https://gist.github.com/terrajobst/6e1bea5bec4591edd7c5fe5416ce7f56">github</a> <br><br><h4>  Flow Resistance and Flow Control </h4><br>  Ideally, reading and analysis work together: the reading stream consumes data from the network and puts it into buffers, while the analysis stream creates the appropriate data structures.  Analysis usually takes longer than just copying data blocks from the network.  As a result, the reading stream can easily overload the analysis stream.  Therefore, the reading stream will have to either slow down or consume more memory in order to save data for the analysis stream.  To ensure optimal performance, a balance is needed between the pause frequency and the allocation of large amounts of memory. <br><br>  To solve this problem, the pipeline has two flow control functions: PauseWriterThreshold and ResumeWriterThreshold.  PauseWriterThreshold determines how much data needs to be buffered before pausing PipeWriter.FlushAsync.  ResumeWriterThreshold determines how much memory the reader may consume before resuming the operation of the recorder. <br><br><img src="https://habrastorage.org/webt/qf/yj/5u/qfyj5u6aahkadlp8nk1gtc9bqr4.png"><br><br>  PipeWriter.FlushAsync is ‚Äúblocked‚Äù when the amount of data in the pipeline stream exceeds the limit set in PauseWriterThreshold and is ‚Äúunlocked‚Äù when it falls below the limit set in ResumeWriterThreshold.  To prevent the consumption limit being exceeded, only two values ‚Äã‚Äãare used. <br><br><h4>  I / O scheduling </h4><br>  When using async / await, subsequent operations are usually invoked either in pool threads or in the current SynchronizationContext. <br><br>  When implementing I / O, it is very important to carefully control where it is executed in order to use the processor cache more efficiently.  This is critical for high performance applications such as web servers.  System.IO.Pipelines uses PipeScheduler to determine where to place asynchronous callbacks.  This allows you to very precisely control which threads to use for I / O. <br><br>  A practical example is the Kestrel Libuv transport, in which I / O callbacks are executed through dedicated channels of the event loop. <br><br><h2>  There are other benefits of the PipeReader pattern. </h2><br><ul><li>  Some base systems support ‚Äústandby without buffering‚Äù: the buffer does not need to be allocated until the available data appears in the base system.  So, in Linux with epoll, you can not provide a buffer for reading until the data is prepared.  This avoids a situation where there are many threads waiting for data, and you need to immediately reserve a huge amount of memory. </li><li>  The default pipeline simplifies the recording of network code unit tests: the parsing logic is separate from the network code, and the unit tests run this logic only in buffers in memory, and do not consume it directly from the network.  It also makes it easy to test complex patterns with partial data sent.  ASP.NET Core uses it to test various aspects of the Kestrel http parser. </li><li>  Systems that allow custom code to use the main OS buffers (for example, the registered Windows I / O API) are initially suitable for using pipelines, because the PipeReader implementation always provides buffers. </li></ul><br><h4>  Other related types </h4><br>  We also added a number of new simple BCL types to System.IO.Pipelines: <br><br><ul><li>  <a href="https://docs.microsoft.com/en-us/dotnet/api/system.buffers.memorypool-1%3Fview%3Dnetcore-2.1">MemoryPoolT</a> , <a href="https://docs.microsoft.com/en-us/dotnet/api/system.buffers.imemoryowner-1%3Fview%3Dnetcore-2.1">IMemoryOwnerT</a> , <a href="https://docs.microsoft.com/en-us/dotnet/api/system.buffers.memorymanager-1%3Fview%3Dnetcore-2.1">MemoryManagerT</a> .  <a href="https://docs.microsoft.com/en-us/dotnet/api/system.buffers.arraypool-1%3Fview%3Dnetcore-2.1">ArrayPoolT has</a> been added to .NET Core 1.0, and .NET Core 2.1 now has a more general abstract representation for the pool that works with any MemoryTs.  We get an extensibility point that allows for more advanced distribution strategies, as well as control of buffer management (for example, using predefined buffers instead of exclusively managed arrays). </li><li>  <a href="https://docs.microsoft.com/en-us/dotnet/api/system.buffers.ibufferwriter-1%3Fview%3Dnetcore-2.1">The iBufferWriterT</a> is a receiver for recording synchronous buffered data (implemented by PipeWriter). </li><li>  <a href="https://docs.microsoft.com/en-us/dotnet/api/system.threading.tasks.sources.ivaluetasksource-1%3Fview%3Dnetcore-2.1">IValueTaskSource</a> - <a href="https://docs.microsoft.com/en-us/dotnet/api/system.threading.tasks.valuetask-1%3Fview%3Dnetcore-2.1">ValueTaskT has</a> existed since the release of .NET Core 1.1, but in .NET Core 2.1 it has acquired extremely efficient tools that provide uninterrupted asynchronous operations without distribution.  For more information, see <a href="https://github.com/dotnet/corefx/issues/27445">here</a> . </li></ul><br><h2>  How to use conveyors? </h2><br>  The APIs are in the <a href="https://www.nuget.org/packages/System.IO.Pipelines/">System.IO.Pipelines</a> nuget package. <br><br>  An example of a .NET Server 2.1 server application that uses pipelines to handle inline messages (from the example above) see <a href="https://github.com/davidfowl/TcpEcho">here</a> .  It can be run using the dotnet run (or Visual Studio).  In the example, data transfer from the socket on port 8087 is expected, then the received messages are written to the console.  To connect to port 8087, you can use a client, such as netcat or putty.  Send a text message and see how it works. <br><br>  At the moment, the pipeline is working in Kestrel and SignalR, and we hope that it will find more widespread use in many network libraries and components of the .NET community in the future. </div><p>Source: <a href="https://habr.com/ru/post/423105/">https://habr.com/ru/post/423105/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../423095/index.html">What's new showed on Apple presentation</a></li>
<li><a href="../423097/index.html">Tasks and solutions for the PostgreSQL fighter</a></li>
<li><a href="../423099/index.html">Steam has allowed erotica, porn and violence in games</a></li>
<li><a href="../423101/index.html">Expanding LINSTOR for Proxmox</a></li>
<li><a href="../423103/index.html">Python podcasts: that's all we found</a></li>
<li><a href="../423107/index.html">Welcome to the ‚ÄúGo in production‚Äù mitap</a></li>
<li><a href="../423109/index.html">What did Apple introduce and what did iOS developers think about it</a></li>
<li><a href="../423115/index.html">Improved effects with background layer blending in CSS</a></li>
<li><a href="../423117/index.html">Live longer or slower to grow old: a technological approach to old age</a></li>
<li><a href="../423119/index.html">DIY TTL arcade machine ... in 2018</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>