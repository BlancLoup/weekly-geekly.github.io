<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>RBKmoney Payments under the hood - the infrastructure of the payment platform</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hi, Habr! The description of the operation of the insides of a large payment platform will logically continue with a description of how exactly these ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>RBKmoney Payments under the hood - the infrastructure of the payment platform</h1><div class="post__text post__text-html js-mediator-article"><p><img src="https://habrastorage.org/webt/4q/i3/tx/4qi3txdbqxbtwlhqrqmhbutpyxs.jpeg"></p><br><p>  Hi, Habr!  The description of the operation of the <a href="https://habr.com/ru/company/rbkmoney/blog/447440/">insides of a</a> large payment platform will logically continue with a description of how exactly these components work in the real world on the physical hardware.  In this post, I‚Äôll talk about how and where platform applications are placed, how traffic from the outside world reaches them, and also describe the layout of a standard rack for us with equipment located in any of our data centers. </p><a name="habracut"></a><br><h2 id="podhody-i-ogranicheniya">  Approaches and limitations </h2><br><p><img src="https://habrastorage.org/webt/s4/oi/m1/s4oim1l0d58ti3s50leca-58-mm.jpeg"></p><br><p>  One of the first requirements that we formulated before the development of the platform sounds like "the ability to close to linear scaling of computing resources to ensure the processing of any number of transactions." </p><br><p>  The classic approaches of paid systems used by market participants imply a ceiling, albeit rather high according to statements.  It usually sounds like this: "our processing can take 1000 transactions per second." </p><br><p>  This approach does not fit into our business objectives and architecture.  We do not want to have any limit.  In fact, it would be strange to hear from Yandex or Google a statement "we can process 1 million search queries per second."  The platform should process as many requests as the business needs at the moment due to the architecture, which allows, to put it simply, send it to DC of ITshnik with a cart of servers that it installs in racks, connects to the switchboard and leaves.  And the platform orchestrator will roll out copies of business applications to new capacities, as a result of which we will get the necessary increase in RPS. </p><br><p>  The second important requirement is to ensure high availability of the services provided.  It would be fun, but not very useful, to create a payment platform that can accept an infinite number of payments in / dev / null. </p><br><p>  Perhaps the most effective way to achieve high availability is to duplicate entities that serve a service so that the failure of any reasonable number of applications, equipment or data centers does not affect the overall availability of the platform. </p><br><p>  Repeated duplication of applications requires a large number of physical servers and related network equipment.  This iron costs money, the amount of which from us of course, we cannot afford to buy a lot of expensive iron.  So the platform is designed so that it is easy to place and feel good on a large number of inexpensive and not too powerful hardware, or in the public cloud in general. </p><br><p>  Using servers that are not the strongest in terms of computing power has its advantages - their failure does not have a critical impact on the overall state of the system as a whole.  Imagine what is better - if an expensive, large and super-reliable branded server is running that uses a master-slave DBMS (and according to Murphy‚Äôs law, it will necessarily burn, and on December 31 in the evening) or a couple of servers in a cluster of 30 nodes running masterless - schematic? </p><br><p>  Based on this logic, we decided not to create one more massive point of failure in the form of a centralized disk array.  Common block devices are provided by a Ceph cluster deployed hyperconvergently on the same servers, but with a separate network infrastructure. </p><br><p>  Thus, we logically came to the general scheme of a universal rack with computing resources in the form of inexpensive and not very powerful servers in the data center.  If we need more resources, we either finish off any free rack with servers, or put another one, preferably closer. </p><br><p><img src="https://habrastorage.org/webt/rn/ce/ho/rncehoigde-wwzp3etasz6ewwkw.jpeg"></p><br><p>  Well, in the end, it's just beautiful.  When a clear amount of the same iron is installed in the racks, this allows us to solve problems with high-quality wire-laying equipment, allows us to get rid of swallow nests and the danger of getting entangled in wires by dropping processing.  A good from an engineering point of view, the system should be beautiful everywhere - and from the inside in the form of code, and outside in the form of servers and network hardware.  A beautiful system works better and more reliably; I have had enough examples to see this from personal experience. </p><br><p>  <em>Please do not think that we are grain droppers or a business pins on financing.</em>  <em>Developing and maintaining a distributed platform is actually very expensive.</em>  <em>In fact, it is even more expensive than owning a classical system built, conditionally, on a powerful brand hardware with Oracle / MSSQL, application servers and other binding.</em> </p><br><p>  <em>Our approach pays off with high reliability, very flexible horizontal scaling capabilities, the lack of a ceiling for the number of payments per second, and strange as it may sound, a large number of fans for the IT team.</em>  <em>For me, the level of enjoyment of developers and devops from the system they create is no less important than the predictable development timeframe, the quantity and quality of the features being rolled out.</em> </p><br><h2 id="servernaya-infrastruktura">  Server infrastructure </h2><br><p><img src="https://habrastorage.org/webt/ug/je/s5/ugjes5aw-7xwah9ykzbjrms8o9a.jpeg"></p><br><p>  Logically, our server capacities can be divided into two main classes: servers for hypervisors, for which the density of CPU cores and RAM per unit is important, and the storage server, where the main emphasis is placed on the amount of disk space per unit, and CPU and RAM are already selected number of disks. </p><br><p>  Currently our classic server for computing power looks like this: </p><br><ul><li>  2xXeon E5-2630 CPU; </li><li>  128G RAM; </li><li>  3xSATA SSD (Ceph SSD pool); </li><li>  1xNVMe SSD (dm-cache). </li></ul><br><p>  Server for storing states: </p><br><ul><li>  1xXeon E5-2630 CPU; </li><li>  12-16 HDD; </li><li>  2 SSD for block.db; </li><li>  32G RAM. </li></ul><br><h2 id="setevaya-infrastruktura">  Network infrastructure </h2><br><p>  In the choice of network hardware, our approach is somewhat different.  For switching and routing between vlan-s, we still use branded switches, now it is Cisco SG500X-48 and Cisco Nexus C5020 in SAN. </p><br><p>  Physically, each server is connected to the network by 4 physical ports: </p><br><ul><li>  2x1GbE - network management and RPC between applications; </li><li>  2x10GbE - network for storage. </li></ul><br><p>  The interfaces inside the machines are bonded together, then the tagged traffic diverges according to the necessary vlans. </p><br><p>  Perhaps this is the only place in our infrastructure where you can see the label of a famous vendor.  Because for routing, network filtering and traffic inspection, we use linux hosts.  We do not buy specialized routers.  All that we need we configure on servers running Gentoo (iptables for filtering, BIRD for dynamic routing, Suricata as IDS / IPS, Wallarm as WAF). </p><br><h2 id="tipichnaya-stoyka-v-dc">  Typical rack in DC </h2><br><p>  When schematically scaled, the racks in DC are practically the same, except for routers to uplinks, which are installed in one of them. </p><br><p>  The exact proportions of servers of different classes can vary, but in general the logic is preserved - there are more servers for calculations than servers for data storage. </p><br><p><img src="https://habrastorage.org/webt/yi/me/o0/yimeo0j7lk-s-rtyhabbeuayvyq.png"></p><br><h2 id="blochnye-ustroystva-i-razdelenie-resursov">  Block devices and resource sharing </h2><br><p>  Let's try to put everything together.  Imagine that we need to place several of our microservices in the infrastructure, for greater clarity, these will be microservices that need to communicate with each other via RPC and one of them is Machinegun, which stores the state in the Riak cluster, as well as some ancillary services such like ES and Consul. </p><br><p>  A typical layout will look like this: </p><br><p><img src="https://habrastorage.org/webt/za/1m/7p/za1m7pqa6mdn0cvc6lot6tdwxis.png"></p><br><p>  VMs with applications that require the maximum speed of a block device, like Riak and Elasticsearch hot nodes, use partitions on local NVMe disks.  Such VMs are tightly bound to their hypervisor, and applications themselves are responsible for the availability and integrity of their data. </p><br><p>  For common block devices, we use Ceph RBD, usually with write-through dm-cache on a local NVMe disk.  The OSD for the device can be either full-flash or HDD with an SSD log, depending on the desired response time. </p><br><h2 id="dostavka-trafika-do-prilozheniy">  Delivery of traffic to applications </h2><br><p><img src="https://habrastorage.org/webt/e9/fm/pi/e9fmpipuhko3jcmbeix8lgtfv2a.png"></p><br><p>  To balance requests coming from outside, we use the standard OSPFv3 ECMP scheme.  Small virtual machines with nginx, bird, consul announce in the OSPF cloud shared anycast addresses from the lo interface.  On routers for these addresses, bird creates multi-hop routes that provide per-flow balancing, where flow is "src-ip src-port dst-ip dst-port".  To quickly disable the missing balancer, the BFD protocol is used. </p><br><p>  When any of the balancers are added or failed, the upstream routers appear or delete the corresponding route, and the network traffic is delivered to them according to the Equal-cost multi-path approaches.  And if we do not specifically intervene, then all network traffic is evenly distributed to all available balancers on the IP stream to each. </p><br><p>  <em>By the way, the ECMP-balanced approach has unobvious <a href="https://blog.cloudflare.com/path-mtu-discovery-in-practice/">pitfalls</a> that can lead to completely unobvious losses of some traffic, especially if there are other routers or strangely configured firewalls on the route between the systems.</em> </p><br><p>  <em>To solve the problem, we use the <a href="https://github.com/cloudflare/pmtud">PMTUD daemon</a> in this part of the infrastructure.</em> </p><br><p>  Then the traffic goes inside the platform to specific microservices according to the configuration of nginx on balancers. </p><br><p>  And if everything is more or less simple and clear with balancing external traffic, then it would be difficult to extend such a scheme further inwards - we need something more than just checking the availability of a container with microservice at the network level. </p><br><p>  In order for microservice to start receiving and processing requests, it must register with Service Discovery (we use <a href="https://www.consul.io/">Consul</a> ), undergo every second health check and have a reasonable RTT. </p><br><p> If microservice feels and behaves well, Consul begins to resolve the address of its container when accessing its DNS by the name of the service.  We use the internal zone <code>service.consul</code> , and, for example, the Common API microservice version 2 will be named <code>capi-v2.service.consul</code> . </p><br><p>  The nginx config file regarding balancing in the end is ours: </p><br><pre> <code class="plaintext hljs">location = /v2/ { set $service_hostname "${staging_pass}capi-v2.service.consul"; proxy_pass http://$service_hostname:8022; }</code> </pre> <br><p>  Thus, if we again do not interfere specifically, the traffic from the balancers is evenly distributed among all the microservices registered in Service Discovery, the addition or deletion of new instances of the required microservices is fully automated. </p><br><p>  If the request from the balancer went upstream, and he died on the way, we return 502 to the outside - the balancer at its level cannot determine whether the request was idempotent or not, therefore, we give the processing of such errors to a higher level of logic. </p><br><h2 id="idempotentnost-i-dedlayny">  Idempotency and deadlines </h2><br><p>  In general, we are not afraid and do not hesitate to give 5xx errors to the API, this is a normal part of the system, if we make the correct handling of such errors at the RPC business logic level.  The principles of this processing are described in the form of a small manual called the Errors Retry Policy, we distribute it to our merchant clients and implement it within our services. </p><br><p>  To simplify this processing, we have implemented several approaches. </p><br><p>  First, for any status-changing requests to our API, you can specify a unique idempotency key within the account that lives forever and allows you to be sure that a repeated call with the same data set will return the same answer. </p><br><p>  Secondly, we implemented an additional mechanism in the form of a unique identifier for a payment session, which guarantees the idempotency of withdrawal requests, providing protection against erroneous repeated debits, even if you do not generate and transmit a separate idempotency key. </p><br><p>  Thirdly, we decided to give a predictable and controllable outside response time to any external call to our API in the form of a time cutoff parameter that determines the maximum wait time for the operation to complete on request.  It is enough to send, for example, the HTTP header <code>X-Request-Deadline: 10s</code> , to be sure that your request will be executed within 10 seconds or will be killed by the platform somewhere inside, after which we can be contacted again, guided request forwarding policy. </p><br><h2 id="upravlenie-i-vladenie-platformoy">  Platform Management and Ownership </h2><br><p>  We use SaltStack as a tool for managing both configurations and infrastructure in general.  Separate tools for automated control of the computing power of the platform have not yet taken off, although now we understand that we will go in this direction.  With our love for <a href="https://www.hashicorp.com/">Hashicorp</a> products <a href="https://www.hashicorp.com/">,</a> this is likely to be Nomad. </p><br><p>  The main infrastructure monitoring tools are checks in Nagios, but for business entities, we basically set up alerts in Grafana.  It is a very convenient tool for setting conditions, and the event-based platform model allows you to write everything into Elasticsearch and customize the selection conditions. </p><br><p><img src="https://habrastorage.org/webt/_p/yh/wh/_pyhwho6dvp3vful4zg46fg8_so.png"></p><br><p>  The data centers are located in Moscow, in them we rent spacer-stands, independently install and manage all the equipment.  We don‚Äôt use dark optics anywhere, we only have Internet from local providers. </p><br><p>  Otherwise, our approaches to monitoring, management and related services are rather standard for the industry, not sure that the next description of the integration of these services is worth mentioning in the post. </p><br><p>  On this article, I, perhaps, will finish a cycle of survey posts about how our payment platform is arranged. </p><br><p>  I think that the cycle turned out to be quite frank, I met few articles that would reveal the internal kitchen of large payment systems in such detail. </p><br><p>  <em>In general, in my opinion, a high level of openness and frankness is a very important thing for a payment system.</em>  <em>This approach not only increases the level of trust of partners and payers, but also disciplines the team, creators and service operators.</em> </p><br><p>  <em>So, guided by this principle, we recently made public the status of the platform and the uptime history of our services.</em>  <em>The entire subsequent history of our uptime, updates and downs is now public and available at <a href="https://status.rbk.money/">https://status.rbk.money/</a> .</em> </p><br><p>  I hope you were interested, and perhaps someone our approaches and the described errors will be useful.  If you are interested in any of the directions described in the posts, and you would like me to reveal them in more detail, please do not hesitate to write in the comments or in a personal. </p><br><p>  Thank you for being with us! </p><br><p><img src="https://habrastorage.org/webt/05/zb/ia/05zbiakiuub6ghwchckesii7an0.jpeg"></p><br><p>  PS For your convenience, a pointer to the previous articles of the cycle: </p><br><ul><li>  <a href="https://habr.com/ru/company/rbkmoney/blog/416897/">introduction and description of how it all began</a> ; </li><li>  <a href="https://habr.com/ru/company/rbkmoney/blog/443518/">microservices and platform business configuration</a> ; </li><li>  <a href="https://habr.com/ru/company/rbkmoney/blog/447440/">implementation of processing business logic platform</a> . </li></ul></div>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <p>Source: <a href="https://habr.com/ru/post/451814/">https://habr.com/ru/post/451814/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../451800/index.html">We make a simple sonar modem</a></li>
<li><a href="../451802/index.html">.Net Community Raiffeisenbank invites you to meet UPD Broadcast</a></li>
<li><a href="../451806/index.html">iOS Digest 5 (April 27 - May 16)</a></li>
<li><a href="../45181/index.html">Free alternative</a></li>
<li><a href="../451812/index.html">Now, good developers are measured by views and subscribers - and this is bad</a></li>
<li><a href="../451818/index.html">Rook or not Rook - that is the question</a></li>
<li><a href="../451820/index.html">Thematic Habramitap # 1: Backend Development</a></li>
<li><a href="../451826/index.html">Marketing sales boosting absurd: proven cases</a></li>
<li><a href="../451828/index.html">The main secret of Google I / O 2019, which is not to learn from the Internet</a></li>
<li><a href="../451830/index.html">Briefly with the implementation of the AES 128 ECB</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>