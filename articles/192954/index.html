<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Simple but effective Voice Activity Detection real-time algorithm</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Below is a translation of the article. 
 A SIMPLE BUT EFFICIENT REAL-TIME VOICE ACTIVITY DETECTION ALGORITHM 
 M.H. Moattar and MM Homayonpour 
 Labor...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Simple but effective Voice Activity Detection real-time algorithm</h1><div class="post__text post__text-html js-mediator-article">  Below is a translation of the article. <br>  A SIMPLE BUT EFFICIENT REAL-TIME VOICE ACTIVITY DETECTION ALGORITHM <br>  M.H.  Moattar and MM Homayonpour <br>  Laboratory for Intelligent Sound and Speech Processing (LISSP), Computer Engineering and Information Technology Dept., Amirkabir University of Technology, Tehran, Iran <br>  Original <a href="http://citeseerx.ist.psu.edu/viewdoc/download%3Fdoi%3D10.1.1.176.6740%26rep%3Drep1%26type%3Dpdf">link</a> <br><br><h5>  SUMMARY </h5><br>  The Voice Activity Detection Algorithm (hereinafter referred to as VAD) is a very important method in speech and audio processing applications.  The effectiveness of most, if not all, speech / audio processing methods depends strongly on the effectiveness of the VAD algorithm used.  An ideal voice activity detector should be independent of the application's area of ‚Äã‚Äãapplication, noise level and be least dependent on the maximum parameters of the application in which it is used.  This article proposes a close to ideal VAD algorithm, which is both easy to implement and resistant to noise.  The proposed method uses such short-term characteristics as Spectral Flatness (SF) (spectral flatness, evenness) and Short-term Energy, which makes the method suitable for use in real time.  This method was tested on several records with different noise levels and was compared with recently proposed methods.  Experiments have shown satisfactory results at different levels of noise. <br><a name="habracut"></a><br><br><h5>  1. INTRODUCTION </h5><br>  Voice Activity Detection (VAD) ‚Äîthat is, the detection of silence in a speech or audio signal is a very important task for many applications that work with audio or speech, including encoding, recognizing, enhancing speech intelligibility, and audio indexing.  For example, in the GSM 729 standard [1], two VAD modules are used for coding with a different number of bits in the sample.  VAD noise tolerance is also very important for speech recognition (Automatic Speech Recognition ASR).  A good detector will improve the accuracy and speed of any ASR in noisy environments. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      According to [2], the necessary characteristics for an ideal voice activity detector are: reliability, stability, accuracy, adaptability, simplicity, possibility of application in real time, without information about the present noise.  To achieve noise resistance is the hardest.  Under conditions of high SNR (Signal-to-noise ratio), the simplest VAD algorithms work satisfactorily, but under conditions of low SNR, all VAD algorithms degrade to a certain extent.  At the same time, the VAD algorithm must remain simple to meet the requirement of real-time applicability.  Therefore, simplicity and noise resistance are two essential characteristics of a practical speech activity detector. <br><br>  Many VAD algorithms have been proposed, the main difference of which is in the characteristics used.  Among all the characteristics, Short-term Energy and zero-crossing rate were used more often because of their simplicity.  However, they strongly degrade in the presence of noise.  In order to correct this disadvantage, different stable acoustic characteristics were proposed based on the autocorrelation function [3, 4], spectrum (spectrum based) [5], and power in a narrow band (power in the band-limited region) [1, 6 , 7], MFCC (Mel-frequency Cepstral Coefficients [4] - Cepstral coefficients of tonal frequency. You can read in the book spbu), delt spectral frequencies (delta line spectral frequencies) [6] and higher-order statistics [8].  Experiments have shown that the use of these characteristics leads to an increase in noise resistance of VAD.  Some papers suggest using different characteristics in combination with some modeling algorithms like CART (Classification and Regression Tree) [9] and ANN (Artificial Neural-Network) [10], however, these algorithms are comparable in complexity to VAD itself. <br><br>  On the other hand, some methods use noise models [11], or use an improved speech spectrum obtained after statistical filtering of noise by a Wiener filter [7, 12].  Most of the characteristics suggest the presence of stationary noise for a certain period, so they are sensitive to changes in the SNR of the signal being processed.  Some papers offer noise computation and adaptation to improve VAD resiliency [13], but these methods have greater computational complexity. <br><br>  Also, there are VADs standards that are used to create new detection methods.  Among them, GSM 729 [1], ETSI AMR [14] and AFE [15].  For example, the GSM 729 standard uses a linear spectrum of a pair of frequencies, full-band energy and low-band energy, zero-crossing rate, and applies a classifier using fixed boundaries in a limited space [1]. <br><br>  In this paper, a VAD algorithm is proposed that is both easy to implement and can be used for real-time speech / audio processing and also provides satisfactory noise immunity.  Section 3 examines in detail the algorithm proposed by VAD. <br><br><h5>  2. SHORT-TERM FEATURE (short term performance) </h5><br>  In the proposed method, we use three different characteristics for each frame.  The first characteristic is short-term energy (E).  Energy is the most frequently used characteristic in the definition of speech / silence.  However, it becomes ineffective under noise conditions, especially at low SNRs.  Therefore, we use two more characteristics, which are calculated from the frequencies. <br><br>  The second characteristic is a spectral flatness measure (SFM - Spectral Flatness Measure).  The spectrum noise measurement shows itself well in voice / non-voice detection and silence detection. <br>  It is considered SFM according to the following formula: <br>  <i>SMF <sub>db</sub> = 10log <sub>10</sub> (G <sub>m</sub> / A <sub>m</sub> )</i> <br>  Where A <sub>m</sub> and G <sub>m</sub> are respectively the arithmetic mean and the geometric mean of speech spectrum. <br><br>  In addition to these two characteristics, it was found that the speech component with the most dominant frequency component can be very useful for distinguishing frames with speech and silence.  In this work, this characteristic is denoted by F. It is easily calculated by finding the frequency that corresponds to the maximum value of the spectrum |  S (k) |. <br><br>  In the proposed method for detecting voice activity, all three characteristics are calculated simultaneously for each frame. <br><div style="text-align:center;"><img src="https://habrastorage.org/storage3/cee/4a5/c9e/cee4a5c9e9d46a0a401ad01e077de948.png"></div><br>  Image 1. Characteristic values ‚Äã‚Äãon a clear speech signal <br><br><div style="text-align:center;"><img src="https://habrastorage.org/storage3/6a1/1c3/b1c/6a11c3b1cf5a452cdcbf1c4a293a472d.png"></div><br>  Figure 2. Characteristic value on a signal damaged by white noise. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/storage3/ddd/a84/b0e/ddda84b0eae858445b41101bcbdbe720.png"></div><br>  Figure 3. Characteristic value on a signal damaged by babble noise <br><br>  Images 1-3 represent the effectiveness of these three characteristics on a clean and noise-damaged signal. <br><br><h5>  3. PROPOSED VAD ALGORITHM </h5><br>  The proposed algorithm begins with splitting the audio signal into frames.  In our implementation, the window function is not used.  The first N frames are used to initialize the threshold value.  Three characteristics are calculated for each incoming frame.  An audio frame is considered speech if the value of more than one characteristic exceeds the threshold value.  The full procedure of the proposed method is presented below: <br><pre><code class="hljs pgsql"><span class="hljs-number"><span class="hljs-number">1</span></span> -  Frame_Size = <span class="hljs-number"><span class="hljs-number">10</span></span>ms   - ( Num_of_frames ) //    <span class="hljs-number"><span class="hljs-number">2</span></span> -        . //     *    (Energy_PrimTreshhold) *   F (F_PrimTreshhold) *   SFM (SF_PrimTreshhold) <span class="hljs-number"><span class="hljs-number">3</span></span> - <span class="hljs-keyword"><span class="hljs-keyword">For</span></span> i  <span class="hljs-number"><span class="hljs-number">1</span></span>  Num_of_frames <span class="hljs-number"><span class="hljs-number">3.1</span></span> -    (E(i)) <span class="hljs-number"><span class="hljs-number">3.2</span></span> -  FFT    <span class="hljs-number"><span class="hljs-number">3.2</span></span><span class="hljs-number"><span class="hljs-number">.1</span></span> -  F(i) = arg max (S(k)) -     <span class="hljs-number"><span class="hljs-number">3.2</span></span><span class="hljs-number"><span class="hljs-number">.2</span></span> -      Measure(SFM(i)) <span class="hljs-number"><span class="hljs-number">3.3</span></span> -     <span class="hljs-number"><span class="hljs-number">30</span></span>   -  ,      (Min_E), F (Min_F), SMF (Min_SF) <span class="hljs-number"><span class="hljs-number">3.4</span></span> -      E, F, SFM * Tresh_E = Energy_PrimTresh * log(Min_E) * Tresh_F = F_PrimTresh * Tresh_SF = SF_PrimTresh <span class="hljs-number"><span class="hljs-number">3.5</span></span> -  Counter = <span class="hljs-number"><span class="hljs-number">0</span></span> *  ((E(i) - Min_E) &gt;= Tresh_E)  Counter++ *  ((F(i) - Min_F) &gt;= Tresh_F)  Counter++ *  ((SFM(i) - Min_SF) &gt;= Tresh_SF)  Counter++ <span class="hljs-number"><span class="hljs-number">3.6</span></span> -  Counter &gt; <span class="hljs-number"><span class="hljs-number">1</span></span>      ,    <span class="hljs-number"><span class="hljs-number">3.7</span></span> -      ,    tythubb Min_E = ((Silence_Count * Min_E) + E(i)) / (Silence_Count + <span class="hljs-number"><span class="hljs-number">1</span></span>) <span class="hljs-number"><span class="hljs-number">3.8</span></span> Tresh_E = Energy_PrimTresh * log(Min_E) <span class="hljs-number"><span class="hljs-number">4</span></span> -      <span class="hljs-number"><span class="hljs-number">10</span></span>  <span class="hljs-number"><span class="hljs-number">5</span></span> -      <span class="hljs-number"><span class="hljs-number">5</span></span> .</code> </pre> <br><br>  The algorithm has three parameters that must be set first.  These parameters were found automatically on the final set of clear speech signals.  Below are the optimal values ‚Äã‚Äãobtained as a result of experiments. <br>  Energy_PrimThresh = 40 <br>  F_PrimThresh (Hz) = 185 <br>  SF_PrimThresh = 5 <br><hr><br>  The original article provides the results of experiments conducted in conditions of different noise.  I would like to know the opinion of the community about this topic and about the translation itself.  Does it make sense to continue to upload translations on this topic?  On all the inaccuracies of the translation, write errors in private messages. <br>  I did not find how to indicate that this is a translation, except to assign a post to the Translations hub. <br><br><div class="spoiler">  <b class="spoiler_title">Links</b> <div class="spoiler_text"><h5>  REFERENCES: </h5><br>  [1] A. Benyassine, E. Shlomot, HY Su, D. Massaloux, C. Lamblin and JP Petit, ‚ÄúITU-T Recommendation G.729 Annex B: optimized for V. 70 digital simultaneous voice and data applications, "IEEE Communications Magazine 35, pp.  64-73, 1997. <br>  [2] MH Savoji, "Speech Communication, pp."  45-60, 1989. <br>  [3] B. Kingsbury, G. Saon, L. Mangu, M. Padmanabhan and R. Sarikaya, ‚ÄúThe 2001 IBM SPINE evaluation system,‚Äù Proc.  ICASSP, 1, pp.  53-56, 2002. <br>  [4] T. Kristjansson, S. Deligne and P. Olsen, ‚ÄúVoicing features for robust speech detection,‚Äù Proc.  Interspeech, pp.  369-372, 2005. <br>  [5] RE Yantorno, KL Krishnamachari and JM Lovekin, ‚ÄúThe Spectral Autocorrelation Peak Valley Ratio (SAPVR) - A Prod.  IEEE Int.  Workshop Intell.  Signal Process.  2001. <br>  [6] M. Marzinzik and B. Kollmeier, ‚ÄúIEEE Trans.  Speech Audio Process, 10, pp.  109-118, 2002. <br>  [7] ETSI standard document, ETSI ES 202 050 V 1.1.3., 2003. <br>  [8] K. Li, NS Swamy and MO Ahmad, ‚ÄúAn improved voice activity,‚Äù IEEE Trans.  Speech Audio Process., 13, pp.  965-974, 2005. <br>  [9] WH Shin, "Speech / non-speech classification using robust endpoint detection," ICASSP, 2000. <br>  [10] GD Wuand and CT Lin, ‚ÄúWord boundary detection system with noisy environment,‚Äù IEEE Trans.  Speechand Audio Processing, 2000. <br>  [11] A. Lee, K. Nakamura, R. Nisimura, H. Saruwatari and K. Shikano, ‚ÄúNoise robust world world spoken dialogue using GMM based rejection,‚Äù Interspeech, pp.  173-176, 2004. <br>  [12] J. Sohn, NS Kim and W. Sung, ‚ÄúA statistical modelbased voice activity detection,‚Äù IEEE Signal Process.  Lett., Pp.  1-3, 1999. <br>  [13] B. Lee and M. Hasegawa-Johnson, ‚ÄúMinimum Mean Squared Error Around,‚Äù in Proc.  Biennial on DSP for In-Vehicle and Mobile Systems, Istanbul, Turkey, June 2007. <br>  [14] ETSI EN 301 708 recommendations, ‚ÄúVoice activity detector for adaptive multi-rate (AMR) speech traffic channels,‚Äù 1999. <br></div></div></div><p>Source: <a href="https://habr.com/ru/post/192954/">https://habr.com/ru/post/192954/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../192940/index.html">ZEUS: All-in-one 3D copy machine (3D printer + 3D scanner + 3D copier + fax)</a></li>
<li><a href="../192944/index.html">Get the list of graphic classes registered in TPicture.RegisterFileFormat</a></li>
<li><a href="../192948/index.html">A free High-Performance Computing School started at the University Innopolis</a></li>
<li><a href="../192950/index.html">Review of fresh materials, July-August 2013</a></li>
<li><a href="../192952/index.html">The French company produces a prototype of a smartphone that can be charged from solar and artificial light.</a></li>
<li><a href="../192960/index.html">Core Data for iOS. Chapter number 3. Theoretical part</a></li>
<li><a href="../192964/index.html">Stiga rocket launch</a></li>
<li><a href="../192966/index.html">The digest of news from the world of mobile development for the last week ‚Ññ23 (September 2 - 8, 2013)</a></li>
<li><a href="../192972/index.html">BEM on Rails</a></li>
<li><a href="../192976/index.html">The digest of interesting news and materials from the world of PHP for the last two weeks, No. 25 (08.25.2013 - 09.09.2013)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>