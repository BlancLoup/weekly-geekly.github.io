<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Fantastic-Elasticsearch. How we "tamed" smart search through documents</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Full-text search allows you to search for documents by text content. Such a need may arise when the system contains many text entities, and users are ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Fantastic-Elasticsearch. How we "tamed" smart search through documents</h1><div class="post__text post__text-html js-mediator-article"><p>  Full-text search allows you to search for documents by text content.  Such a need may arise when the system contains many text entities, and users are required to take this data into account during the search.  We are faced with a similar situation when developing a solution for workflow *.  System data is stored in MS SQL Server or PostgreSQL, and a flexible attribute search allows you to find documents on various meta-information.  However, over time, this was not enough.  We were faced with a task: to learn how to search for documents by text properties and attached files. </p><br><p><img src="https://habrastorage.org/webt/kq/pd/au/kqpdauyhet3lltv1l5vr2mxbfja.jpeg"></p><a name="habracut"></a><br><p>  The problem is that full-text search is supported by SQL server only for a fee and does not provide the flexibility we need.  At this moment the search engines come on the scene.  There are different full-text search systems, for example: Sphinx, Solr or Elasticsearch;  but our choice was the last one.  In general, we have a large dynamic database of documents, Elasticsearch and the desire of customers to have a web-interface for full-text search.  As well as auto-completion, hints, facets and other features that are close to the functionality of an online store.  An article about how we solved this problem. </p><br><p>  * <em><a href="http://www.tadviser.ru/index.php/%25D0%259F%25D1%2580%25D0%25BE%25D0%25B4%25D1%2583%25D0%25BA%25D1%2582:Digital_Design:_%25D0%259F%25D1%2580%25D0%25B8%25D0%25BE%25D1%2580%25D0%25B8%25D1%2582%25D0%25B5%25D1%2582_%25D0%25A1%25D0%25B8%25D1%2581%25D1%2582%25D0%25B5%25D0%25BC%25D0%25B0_%25D0%25B4%25D0%25BE%25D0%25BA%25D1%2583%25D0%25BC%25D0%25B5%25D0%25BD%25D1%2582%25D0%25B0%25D1%2586%25D0%25B8%25D0%25BE%25D0%25BD%25D0%25BD%25D0%25BE%25D0%25B3%25D0%25BE_%25D1%2583%25D0%25BF%25D1%2580%25D0%25B0%25D0%25B2%25D0%25BB%25D0%25B5%25D0%25BD%25D0%25B8%25D1%258F">The system of documentation management "Priority" on the platform Docsvision</a></em> </p><br><h2 id="arhitektura">  Architecture </h2><br><p>  In the Elasticsearch database, the tables are called indexes, and the document loading process is called indexing.  To index data from the main repository, a special service was written in Elasticsearch.  It is a Windows service, in addition to which the admin utility is running.  The utility sets the necessary settings, creates indexes and starts loading documents into the database. </p><br><p>  However, at the stage of data indexing, we encountered a problem.  The system is dynamic, and thousands of changes occur every minute in the documents.  The indexing service must maintain Elasticsearch data in a state as close as possible to the current state of affairs.  Therefore, a new entity appears in the SQL database - a queue of documents for indexing.  Every N minutes, the special job finds all documents that have been changed since the previous execution and adds their identifiers to the queue.  As a result, the service will update in the indices only the documents that require it. </p><br><p><img src="https://habrastorage.org/webt/on/nw/v1/onnwv14hy-xvgcafn4zjef2p_h8.png"></p><br><h3 id="tehnologicheskiy-stek">  Technology stack </h3><br><p>  <strong>Search engine.</strong>  Elasticsearch 5.5 <br>  <strong>Plugins</strong>  analysis morphology and ingest-attachment <br>  <strong>Service.</strong>  Written in C #.  Libraries for interaction with the engine: NEST and ElasticsearchNET. <br>  <strong>Frontend.</strong>  Angular 4 </p><br><h2 id="zagruzka-nastroek">  Loading settings </h2><br><p>  Administrator's utility is a part of the service, with the help of which the types of documents and fields to be indexed are selected.  After that, data schemes are loaded into Elasticsearch (in the ES ecosystem they are called mappings).  This is necessary in order to set their own settings for different fields, which will be taken into account when indexing documents.  In addition, the utility saves the selection results to the database. </p><br><h3 id="formirovanie-mappingov">  Mapping Formation </h3><br><p>  Mappings are generated dynamically using the NEST library.  Each type of system data is assigned an Elasticsearch data type.  The database also maintains a hierarchical structure of documents.  This corresponds to the <em>object</em> and <em>nested</em> data types (for arrays). </p><br><pre><code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">var</span></span> sectionProperty = section.SectionType == SectionType.Struct ? <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> ObjectProperty { Name = section.Name } : <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> NestedProperty { Name = section.Name };</code> </pre> <br><h2 id="analiz-tekstovyh-poley">  Text field analysis </h2><br><p>  Elasticsearch provides great opportunities for full-text search.  It can take into account word forms, skip stop words, use the morphology of the language.  To do this, at the stage of mapping formation, you need to specify the correct analyzer for text fields that require it.  These settings are also specified in the admin utility. </p><br><p>  The analyzer includes three stages: the transformation of individual characters, the division of characters into tokens and the processing of these tokens.  In our case, character filtering is not required.  We use a standard tokenizer, which works out of the box for most cases.  The key link in the Russian language analyzer is the official <em>analysis-morphology</em> plugin.  It provides a token filter that allows you to search for word forms.  We also reduce all words to lower case and use our own set of stop words. </p><br><pre> <code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">var</span></span> stopFilter = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> StopTokenFilter { StopWords = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> StopWords(StopWordsArray) }; <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> filters = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> TokenFilters { { <span class="hljs-string"><span class="hljs-string">"my_stopwords"</span></span>, stopFilter } }; <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> rusAnalyzer = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> CustomAnalyzer { Tokenizer = <span class="hljs-string"><span class="hljs-string">"standard"</span></span>, Filter = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span>[] { <span class="hljs-string"><span class="hljs-string">"lowercase"</span></span>, <span class="hljs-string"><span class="hljs-string">"russian_morphology"</span></span>, <span class="hljs-string"><span class="hljs-string">"my_stopwords"</span></span> } }; <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> analazyers = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Analyzers { { <span class="hljs-string"><span class="hljs-string">"rus_analyzer"</span></span>, rusAnalyzer } }; <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> analyzis = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Analysis { Analyzers = analazyers, TokenFilters = filters };</code> </pre> <br><h3 id="nastroyki-dlya-faylov">  Settings for files </h3><br><p>  In Elasticsearch version 5.0, a new entity has appeared - the <em>Ingest</em> node.  Such nodes are used to process documents before they are indexed.  To do this, create a pipeline ( <em>pipeline</em> ) and add processors ( <em>processor</em> ).  Any of your nodes can be used as ingest.  Or you can select a separate node for primary processing. </p><br><p>  Many documents of our system contain text files.  Full-text search should be able to work on their content.  To implement this, we used the <em>Ingest Attachment</em> plugin, which uses the recently introduced pipeline technology.  Let us define a processor, which for each document file uses a processor that is accessible thanks to the plugin.  The essence of this processor is to extract text from a Base64 line into a separate field.  All that remains is for us: during indexing, get the Base64 line on the file and get into the mapping.  In the processor, we indicate which field contains the file ( <em>Field</em> ) and where to place the text ( <em>TargetFiled</em> ).  Setting <em>IndexedCharacters</em> limits the length of the file being processed (-1 removes restrictions). </p><br><pre> <code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">new</span></span> PutPipelineRequest(pipelineName) { Processors = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> List&lt;ProcessorBase&gt; { <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> ForeachProcessor { Field = <span class="hljs-string"><span class="hljs-string">"Files"</span></span>, Processor = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> AttachmentProcessor { TargetField = <span class="hljs-string"><span class="hljs-string">"_ingest._value.attachment"</span></span>, Field = <span class="hljs-string"><span class="hljs-string">"_ingest._value.RawContent"</span></span>, IndexedCharacters = <span class="hljs-number"><span class="hljs-number">-1</span></span> } } } };</code> </pre> <br><h2 id="indeksirovanie">  Indexing </h2><br><p>  The task of the service is to continuously retrieve new objects from the queue and index the relevant documents.  In this process, we are not using the NEST object model, but the low-level ElasticsearchNet library.  It provides a database interaction interface via JSON.  Objects are formed dynamically by traversing the depth of the hierarchical structure of the document.  To do this, use the well-known library NewtonsoftJson. </p><br><pre> <code class="cs hljs">client.LowLevel.IndexPut&lt;<span class="hljs-keyword"><span class="hljs-keyword">string</span></span>&gt;(indexName, typeName, documentId, json);</code> </pre> <br><p>  Indexing is implemented multithreadedly with parallel processing of each document.  The formation of JSON takes an order of magnitude longer than its indexing.  Therefore, the API is used to index individual documents, not the Bulk API, in which an array of documents is loaded into ES in one call.  In this case, the indexing would occur at the rate of formation of JSON for the largest document. </p><br><h3 id="indeksirovanie-faylov">  File indexing </h3><br><p>  Files are indexed along with the rest of the data as part of a JSON object.  All you need to do is convert the byte stream to a Base64 string.  This is done using standard library tools.  In addition, it is necessary that the files fall under the definition of the processor.  Otherwise, the magic will not happen, and they will remain the usual Base64 line.  To use a pipeline when indexing, change the method call. </p><br><pre> <code class="cs hljs">client.LowLevel.IndexPut&lt;<span class="hljs-keyword"><span class="hljs-keyword">string</span></span>&gt;(indexName, typeName, documentId, json, parameters =&gt; parameters.Pipeline(pipelineName));</code> </pre> <br><h2 id="avtodopolnenie">  Autocompletion </h2><br><p>  Autocomplete prompts you to continue the line as you type. </p><br><p><img src="https://habrastorage.org/webt/3k/j9/fj/3kj9fjcxvh535z63ddutpgv-fd8.png"></p><br><p>  In our case, the autocompet should work on those text fields that have been marked with the appropriate flag in the admin utility.  At the stage of loading mappings, a separate index is created for all complementary rows.  This is due to the fact that the search should work on multiple indexes.  Mapping is formed with a special type field <em>completion</em> . </p><br><pre> <code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">var</span></span> completionProperty = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> CompletionProperty { Name = <span class="hljs-string"><span class="hljs-string">"autocomplete"</span></span>, Analyzer = <span class="hljs-string"><span class="hljs-string">"simple"</span></span>, SearchAnalyzer = <span class="hljs-string"><span class="hljs-string">"simple"</span></span> };</code> </pre> <br><p>  When indexing documents, the text that is needed for autocompletion is broken down into sets of terms and loaded into the index.  Terms should satisfy regular expression - it is important for us to select words that are not too short and consist only of letters.  Sets are sequentially shifted by one term, so for each word there will be a line in the index that starts with it.  The length of the set is bounded above; we use a <em>completeSize of</em> four. </p><br><pre> <code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">var</span></span> regex = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Regex(pattern, RegexOptions.Compiled); <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> words = regex.Matches(text); <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">var</span></span> i = <span class="hljs-number"><span class="hljs-number">0</span></span>; i &lt; words.Count; i++) { <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> inputWords = words.OfType&lt;Match&gt;().Skip(i).Take(completeSize).ToArray(); <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> wordValues = inputWords.Select(x =&gt; x.Value).ToArray(); <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> output = <span class="hljs-keyword"><span class="hljs-keyword">string</span></span>.Join(<span class="hljs-string"><span class="hljs-string">" "</span></span>, wordValues); <span class="hljs-comment"><span class="hljs-comment">//   JSON }</span></span></code> </pre> <br><p>  During the search for autocompletion, a separate query works.  With each character entered, the database is accessed with the corresponding substring.  Requests to Elasticsearch are json objects.  To get autocomplete, we only need the block <em>suggest</em> .  It includes the <em>Completion Suggester</em> , which allows you to quickly search for a prefix.  It works only for <em>completion</em> fields.  We will meet with other sadzhester when we discuss typos. </p><br><pre> <code class="hljs json">{ <span class="hljs-attr"><span class="hljs-attr">"suggest"</span></span>: { <span class="hljs-attr"><span class="hljs-attr">"completion_suggest"</span></span>: { <span class="hljs-attr"><span class="hljs-attr">"text"</span></span>: <span class="hljs-string"><span class="hljs-string">"  "</span></span>, <span class="hljs-attr"><span class="hljs-attr">"completion"</span></span>: { <span class="hljs-attr"><span class="hljs-attr">"field"</span></span>: <span class="hljs-string"><span class="hljs-string">"autocomplete"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"size"</span></span>: <span class="hljs-number"><span class="hljs-number">10</span></span> } } } }</code> </pre> <br><h2 id="poisk">  Search </h2><br><p>  The basic part of the interface is the search line.  When a user enters characters, two queries are processed: for auto-completion and for search.  According to the results of the first of them there are hints for the continuation of printing, and on the second - issuing documents.  The search query consists of several blocks, each of which is responsible for different properties. </p><br><h3 id="polnotekstovyy-poisk">  Full text search </h3><br><p>  The <em>query</em> block corresponds to the search part of the query.  Thanks to him, selected documents that will fall into the issue.  Other important query blocks are applied to these results.  query can have subqueries that are connected using boolean operations.  To do this, we define a <em>bool</em> block.  It can include four types of conditions: <em>must</em> , <em>filter</em> , <em>must_not</em> , <em>should</em> .  In our query, the condition is <em>should</em> , which corresponds to a logical OR.  It combines several full-text subqueries.  We‚Äôll go back to the <em>filter</em> block a bit later, but for the time being we think that we are looking for all the documents. </p><br><pre> <code class="hljs json">{ <span class="hljs-attr"><span class="hljs-attr">"query"</span></span>: { <span class="hljs-attr"><span class="hljs-attr">"bool"</span></span>: { <span class="hljs-attr"><span class="hljs-attr">"filter"</span></span>: [], <span class="hljs-attr"><span class="hljs-attr">"should"</span></span>: [ //   ] } } //   }</code> </pre> <br><p>  For full-text search, the <em>multi_match</em> block is <em>used</em> .  The text from the <em>query</em> parameter is searched for in several fields at once, which are specified in the <em>fields</em> parameter.  In response to the request, a list of documents is returned, each of which has a certain <em>score</em> .  The better the document matches the request, the higher this number.  The <em>multi_match</em> query <em>does</em> not consider the text as a single phrase, but searches for individual terms.  Add a similar block, but with the <em>phrase</em> parameter, which implements the necessary functionality.  To ensure that documents with a match for the phrase are valued higher, we indicate the parameter <em>boost</em> .  It multiplies the score of the document by the specified number. </p><br><pre> <code class="hljs objectivec">{ <span class="hljs-string"><span class="hljs-string">"multi_match"</span></span>: { <span class="hljs-string"><span class="hljs-string">"query"</span></span>: <span class="hljs-string"><span class="hljs-string">" "</span></span>, <span class="hljs-string"><span class="hljs-string">"fields"</span></span>: [ <span class="hljs-string"><span class="hljs-string">"FieldName"</span></span> ] } }, { <span class="hljs-string"><span class="hljs-string">"multi_match"</span></span>: { <span class="hljs-string"><span class="hljs-string">"query"</span></span>: <span class="hljs-string"><span class="hljs-string">" "</span></span>, <span class="hljs-string"><span class="hljs-string">"fields"</span></span>: [ <span class="hljs-string"><span class="hljs-string">"FieldName"</span></span> ], <span class="hljs-string"><span class="hljs-string">"type"</span></span>: <span class="hljs-string"><span class="hljs-string">"phrase"</span></span>, <span class="hljs-string"><span class="hljs-string">"boost"</span></span>: <span class="hljs-number"><span class="hljs-number">10</span></span> } }</code> </pre> <br><p>  Among the pitfalls can be noted search among the objects in the array.  When creating a mapping, we marked some fields as <em>nested</em> .  This means that they are arrays of objects.  To search for any fields of these objects, you need a separate subquery, which is called <em>nested</em> .  It is necessary to specify the path to the array ( <em>path</em> ) and the request itself.  If you are looking for a single index, then this will be enough.  However, in our case, the search works simultaneously on several indices, and if there is no such path in any of them, ES will return an error.  Therefore, a nested query must be enclosed in an <em>indeces</em> block and indicate in which index to search.  To clearly show that no search is needed for the rest of the indexes, write " <em>no_match_query</em> ": " <em>none</em> ". </p><br><pre> <code class="hljs json">{ <span class="hljs-attr"><span class="hljs-attr">"indices"</span></span>: { <span class="hljs-attr"><span class="hljs-attr">"index"</span></span>: <span class="hljs-string"><span class="hljs-string">"indexName"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"query"</span></span>: { <span class="hljs-attr"><span class="hljs-attr">"nested"</span></span>: { <span class="hljs-attr"><span class="hljs-attr">"path"</span></span>: <span class="hljs-string"><span class="hljs-string">"PathToArray"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"query"</span></span>: { <span class="hljs-attr"><span class="hljs-attr">"multi_match"</span></span>: { <span class="hljs-attr"><span class="hljs-attr">"query"</span></span>: <span class="hljs-string"><span class="hljs-string">" "</span></span>, <span class="hljs-attr"><span class="hljs-attr">"fields"</span></span>: [ <span class="hljs-string"><span class="hljs-string">"PathToArray.FieldName"</span></span> ] } } } }, <span class="hljs-attr"><span class="hljs-attr">"no_match_query"</span></span>: <span class="hljs-string"><span class="hljs-string">"none"</span></span> } }</code> </pre> <br><h3 id="haylayty">  Highlights </h3><br><p>  Elasticsearch provides a nice way to highlight text found in a document upon request. </p><br><p><img src="https://habrastorage.org/webt/we/bi/yy/webiyy7dr7olhpnvle2l-qeprx0.png"></p><br><p>  To do this, add a new block request: <em>highlight</em> .  In <em>fields we</em> list the fields for which the highlight should be returned.  <em>Specify in the pre_tags</em> and <em>post_tags</em> parameters which characters to select words with.  If the search works on a large text field (for example, a file), Elasticsearch returns the highlights not together with the entire field, but inside a small passage.  As a result, the engine did all the work for us: and highlighted the coincidences in bold, and highlighted the context. </p><br><pre> <code class="hljs json">{ <span class="hljs-attr"><span class="hljs-attr">"highlight"</span></span>: { <span class="hljs-attr"><span class="hljs-attr">"pre_tags"</span></span>: [ <span class="hljs-string"><span class="hljs-string">"&lt;b&gt;"</span></span> ], <span class="hljs-attr"><span class="hljs-attr">"post_tags"</span></span>: [ <span class="hljs-string"><span class="hljs-string">"&lt;/b&gt;"</span></span> ], <span class="hljs-attr"><span class="hljs-attr">"fields"</span></span>: { <span class="hljs-attr"><span class="hljs-attr">"FieldName"</span></span>: {} } } }</code> </pre> <br><p>  Despite all the convenience of this feature, we are faced with a serious problem when working with it.  If the highlight has worked on the object in the array, then the response to the request cannot be determined to which object it belongs.  Files are stored in an array, and file highlighting is one of the key requirements of the customer.  The logical solution to this problem is to create a set of fields of the form <em>File_i</em> , where <em>i</em> will cover a reasonable number of attached files.  Then, by the highlight, it will become clear which index has the file, and from the search results you can take the file name from this index. </p><br><p>  However, it turned out that not everything is so simple.  The base64-to-text conversion processor can only work on an array with like fields.  Thanks to the help on the <a href="https://discuss.elastic.co/">discuss.elastic.co</a> forum, a <a href="https://discuss.elastic.co/">solution</a> was found: add another processor, which, after being converted into text, renames the fields to the desired form.  Processor Code: </p><br><pre> <code class="hljs python"><span class="hljs-string"><span class="hljs-string">"script"</span></span>: { <span class="hljs-string"><span class="hljs-string">"lang"</span></span>: <span class="hljs-string"><span class="hljs-string">"painless"</span></span>, <span class="hljs-string"><span class="hljs-string">"inline"</span></span>: <span class="hljs-string"><span class="hljs-string">"""for (def i = 0; i &lt; ctx.Files.length; i++) { def f = 'File' + (i+1); ctx.Files[i][f] = ctx.Files[i].attachment; ctx.Files[i][f].Name = ctx.Files[i].Name; for (def rf : ['attachment', 'Name']) { ctx.Files[i].remove(rf); } }"""</span></span> }</code> </pre> <br><h3 id="sadzhesty">  Sajesta </h3><br><p>  Sometimes the user makes typos when entering a request.  In this case, the search results will be empty.  However, Elasticsearch may suggest a possible error. </p><br><p><img src="https://habrastorage.org/webt/xe/nj/q7/xenjq7ejatwhlliqfgtkev5owcw.png"></p><br><p>  This functionality is implemented at the expense of the block <em>suggest</em> .  We already met with him when we discussed auto-completion, but another type of sadgetster is used to handle typos.  It is called a <em>phrase</em> and looks for mistakes, considering the entire phrase, not individual words.  We indicate the number of prompts in the results ( <em>size</em> ), the search fields ( <em>field</em> ) and the number of possible typos in the phrase ( <em>max_errors</em> ).  To cut off undesirable results, add a <em>subquery</em> ( <em>collate</em> ), which checks that the received sadest is contained in at least one index field.  Also hints support the built-in highlight, which highlights the word with an error. </p><br><pre> <code class="hljs json">{ <span class="hljs-attr"><span class="hljs-attr">"suggest"</span></span>: { <span class="hljs-attr"><span class="hljs-attr">"my_suggest"</span></span>: { <span class="hljs-attr"><span class="hljs-attr">"text"</span></span>: <span class="hljs-string"><span class="hljs-string">" "</span></span>, <span class="hljs-attr"><span class="hljs-attr">"phrase"</span></span>: { <span class="hljs-attr"><span class="hljs-attr">"size"</span></span>: <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-attr"><span class="hljs-attr">"field"</span></span>: <span class="hljs-string"><span class="hljs-string">"_all"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"max_errors"</span></span>: <span class="hljs-number"><span class="hljs-number">4</span></span>, <span class="hljs-attr"><span class="hljs-attr">"collate"</span></span>: { <span class="hljs-attr"><span class="hljs-attr">"query"</span></span>: { <span class="hljs-attr"><span class="hljs-attr">"inline"</span></span>: { <span class="hljs-attr"><span class="hljs-attr">"match"</span></span>: { <span class="hljs-attr"><span class="hljs-attr">"{{field_name}}"</span></span>: { <span class="hljs-attr"><span class="hljs-attr">"query"</span></span>: <span class="hljs-string"><span class="hljs-string">"{{suggestion}}"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"operator"</span></span>: <span class="hljs-string"><span class="hljs-string">"and"</span></span> } } } }, <span class="hljs-attr"><span class="hljs-attr">"params"</span></span>: { <span class="hljs-attr"><span class="hljs-attr">"field_name"</span></span>: <span class="hljs-string"><span class="hljs-string">"_all"</span></span> } }, <span class="hljs-attr"><span class="hljs-attr">"highlight"</span></span>: { <span class="hljs-attr"><span class="hljs-attr">"pre_tag"</span></span>: <span class="hljs-string"><span class="hljs-string">"&lt;b&gt;"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"post_tag"</span></span>: <span class="hljs-string"><span class="hljs-string">"&lt;/b&gt;"</span></span> } } } } }</code> </pre> <br><h3 id="fasety">  Facets </h3><br><img src="https://habrastorage.org/webt/aa/5o/oy/aa5ooywetwl6jseyyno34tihrkg.png" align="right"><br><p>  Another interesting feature that can be implemented using Elasticsearch.  Facets are called aggregation blocks, which can often be seen in online stores.  Add the <em>aggs</em> block to the <em>request</em> .  The most common type of aggregation that can be added to this block is called <em>terms</em> .  The results will contain all the unique values ‚Äã‚Äãof the corresponding field and the number of documents in which they are found.  It is important that aggregations do not apply to the entire set of documents, but only to those that satisfy the search query.  Therefore, when entering text, the contents of the facets will dynamically change. </p><br><pre> <code class="hljs json">{ <span class="hljs-attr"><span class="hljs-attr">"aggs"</span></span>: { <span class="hljs-attr"><span class="hljs-attr">"types"</span></span>: { <span class="hljs-attr"><span class="hljs-attr">"terms"</span></span>: { <span class="hljs-attr"><span class="hljs-attr">"field"</span></span>: <span class="hljs-string"><span class="hljs-string">"TypeField"</span></span> } }, <span class="hljs-attr"><span class="hljs-attr">"min_date"</span></span>: { <span class="hljs-attr"><span class="hljs-attr">"min"</span></span>: { <span class="hljs-attr"><span class="hljs-attr">"field"</span></span>: <span class="hljs-string"><span class="hljs-string">"DateField"</span></span> } } } }</code> </pre> <br><p>  For the complete implementation of the facets, it remains to add a filtering block to the search query.  By this we limit the search to only those parameters of the documents that were selected in the facets.  In the <em>filter</em> block, add a subquery for each filter block. </p><br><pre> <code class="hljs objectivec">{ <span class="hljs-string"><span class="hljs-string">"terms"</span></span> : { <span class="hljs-string"><span class="hljs-string">"TypeField"</span></span> : [ <span class="hljs-comment"><span class="hljs-comment">/*   */</span></span>] } }, { <span class="hljs-string"><span class="hljs-string">"range"</span></span> : { <span class="hljs-string"><span class="hljs-string">"DateField"</span></span> : { <span class="hljs-string"><span class="hljs-string">"gte"</span></span> : <span class="hljs-comment"><span class="hljs-comment">/*   */</span></span> } } }</code> </pre> <br><h2 id="itog">  Total </h2><br><p>  This is what the whole picture looks like. </p><br><p><img src="https://habrastorage.org/webt/f6/om/rx/f6omrxvvmsw9n_eojreljhm_zji.png"></p><br><h3 id="statistika-indeksirovaniya">  Indexing statistics </h3><br><p>  Currently the pilot version uses the configuration: <br>  2 servers: <br>  <u>CPU</u> : intel Xeon Platinum 8160 (10 cores) <br>  <u>RAM</u> : 40 GB </p><br><p>  <u>The volume of indices</u> : 260 GB <br>  <u>Number of documents in indices</u> : 600 thousand <br>  <u>Indexing speed</u> : 5000 doc / h </p></div>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <p>Source: <a href="https://habr.com/ru/post/351002/">https://habr.com/ru/post/351002/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../350990/index.html">‚ÄúWe'll have to write by ourselves. They sat down and wrote ": the life of the developers of the laboratory cluster of super-arrays in Sbertech</a></li>
<li><a href="../350992/index.html">Organization of information systems production processes. Part 2. Formation of the design solution</a></li>
<li><a href="../350994/index.html">31 business cybersecurity tips</a></li>
<li><a href="../350996/index.html">Java and Project Reactor</a></li>
<li><a href="../351000/index.html">Find him if you can. How to select letters in the general stream</a></li>
<li><a href="../351004/index.html">Organization of information systems production processes. Part 3. Implementation of the project solution</a></li>
<li><a href="../351006/index.html">How to notice DDOS in time: a monitoring service usage scenario for early detection</a></li>
<li><a href="../351008/index.html">Custom aggregate and window functions in PostgreSQL and Oracle</a></li>
<li><a href="../351012/index.html">Development of high-loaded WebSocket-service</a></li>
<li><a href="../351014/index.html">Batch image processing in Windows with ImageMagick. Part I</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>