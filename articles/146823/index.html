<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>First steps with OpenCL or a tale about how to run the same code on the GPU and CPU</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="So, almost a year has passed since my first post about programming video cards and horror stories about how complicated it is. Now it's time to show t...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>First steps with OpenCL or a tale about how to run the same code on the GPU and CPU</h1><div class="post__text post__text-html js-mediator-article">  So, almost a year has passed since my first post about programming video cards and horror stories about how complicated it is.  Now it's time to show that everything is not so bad and how to use this strange thing called OpenCL, and even use its main advantage, that is, the ability to run the same code on different devices.  And I will show how you can get an order of magnitude greater productivity of a conventional processor almost free. <br><a name="habracut"></a><br><h1>  Introduction </h1><br>  I think that retelling <a href="http://ru.wikipedia.org/wiki/OpenCL">Wikipedia about OpenCL</a> makes no special sense, but in a nutshell, OpenCL is a language (framework and platform) that allows you to run the same code on different devices with different architectures, and in particular on highly parallel processors. , like video cards and modern central processors.  The standard is based on C99 and is maintained by The Khronos Group, we will consider it complete on this educational program. <br><br>  I will begin by showing a small piece of code and explaining what is happening there, at the same time talking about how OpenCL works. <br><br>  First I will describe a fairly trivial code and those who are not eager to see OpenCL <s>magic</s> can skip the first part (just read the last paragraph where I describe the MathCalculations function, this is important. And if you know about OpenCL and you want to see the test results, go straight to the fifth section, but still look at MathCalculations). <br><div class="spoiler">  <b class="spoiler_title">int main (int argc, char * argv [])</b> <div class="spoiler_text"><pre><code class="hljs pgsql"><span class="hljs-type"><span class="hljs-type">int</span></span> main(<span class="hljs-type"><span class="hljs-type">int</span></span> argc, <span class="hljs-type"><span class="hljs-type">char</span></span>* argv[]) { GenerateTestData(); PerformCalculationsOnHost(); //<span class="hljs-keyword"><span class="hljs-keyword">Get</span></span> <span class="hljs-keyword"><span class="hljs-keyword">all</span></span> available platforms vector&lt;cl::Platform&gt; platforms; cl::Platform::<span class="hljs-keyword"><span class="hljs-keyword">get</span></span>(&amp;platforms); <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-type"><span class="hljs-type">int</span></span> iPlatform=<span class="hljs-number"><span class="hljs-number">0</span></span>; iPlatform&lt;platforms.size(); iPlatform++) { //<span class="hljs-keyword"><span class="hljs-keyword">Get</span></span> <span class="hljs-keyword"><span class="hljs-keyword">all</span></span> available devices <span class="hljs-keyword"><span class="hljs-keyword">on</span></span> selected platform std::vector&lt;cl::Device&gt; devices; platforms[iPlatform].getDevices(CL_DEVICE_TYPE_ALL, &amp;devices); //<span class="hljs-keyword"><span class="hljs-keyword">Perform</span></span> test <span class="hljs-keyword"><span class="hljs-keyword">on</span></span> <span class="hljs-keyword"><span class="hljs-keyword">each</span></span> device <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-type"><span class="hljs-type">int</span></span> iDevice=<span class="hljs-number"><span class="hljs-number">0</span></span>; iDevice&lt;devices.size(); iDevice++) { try { PerformTestOnDevice(devices[iDevice]); } catch(cl::Error error) { std::cout &lt;&lt; error.what() &lt;&lt; "(" &lt;&lt; error.err() &lt;&lt; ")" &lt;&lt; std::endl; } CheckResults(); } } //Clean <span class="hljs-keyword"><span class="hljs-keyword">buffers</span></span> <span class="hljs-keyword"><span class="hljs-keyword">delete</span></span>[](pInputVector1); <span class="hljs-keyword"><span class="hljs-keyword">delete</span></span>[](pInputVector2); <span class="hljs-keyword"><span class="hljs-keyword">delete</span></span>[](pOutputVector); <span class="hljs-keyword"><span class="hljs-keyword">delete</span></span>[](pOutputVectorHost); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>; }</code> </pre> <br></div></div><br>  This is what the main program of my small program for testing OpenCL looks like, and more specifically, to calculate some abstract mathematical expression that we will get to later.  So, let's figure out line by line what's going on here. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h1>  Part One - Initialization of source data and the traditional method of computing </h1><br>  GenerateTestData ();  does nothing extraordinary, but simply allocates memory for input and output arrays, and also fills the input arrays with random data. <br><div class="spoiler">  <b class="spoiler_title">void GenerateTestData ()</b> <div class="spoiler_text"><pre> <code class="hljs pgsql"><span class="hljs-type"><span class="hljs-type">void</span></span> GenerateTestData() { pInputVector1 = <span class="hljs-built_in"><span class="hljs-built_in">new</span></span> <span class="hljs-type"><span class="hljs-type">float</span></span>[DATA_SIZE]; pInputVector2 = <span class="hljs-built_in"><span class="hljs-built_in">new</span></span> <span class="hljs-type"><span class="hljs-type">float</span></span>[DATA_SIZE]; pOutputVector = <span class="hljs-built_in"><span class="hljs-built_in">new</span></span> <span class="hljs-type"><span class="hljs-type">float</span></span>[DATA_SIZE]; pOutputVectorHost = <span class="hljs-built_in"><span class="hljs-built_in">new</span></span> <span class="hljs-type"><span class="hljs-type">float</span></span>[DATA_SIZE]; srand (<span class="hljs-type"><span class="hljs-type">time</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">NULL</span></span>)); <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-type"><span class="hljs-type">int</span></span> i=<span class="hljs-number"><span class="hljs-number">0</span></span>; i&lt;DATA_SIZE; i++) { pInputVector1[i] = rand() * <span class="hljs-number"><span class="hljs-number">1000.0</span></span> / RAND_MAX; pInputVector2[i] = rand() * <span class="hljs-number"><span class="hljs-number">1000.0</span></span> / RAND_MAX; } }</code> </pre><br></div></div><br>  Next is a slightly more interesting feature: <br><div class="spoiler">  <b class="spoiler_title">void PerformCalculationsOnHost ()</b> <div class="spoiler_text"><pre> <code class="hljs pgsql"><span class="hljs-type"><span class="hljs-type">void</span></span> PerformCalculationsOnHost() { cout &lt;&lt; "Device: Host" &lt;&lt; endl &lt;&lt; endl; //<span class="hljs-keyword"><span class="hljs-keyword">Some</span></span> performance measurement timeValues.clear(); __int64 start_count; __int64 end_count; __int64 freq; QueryPerformanceFrequency((LARGE_INTEGER*)&amp;freq); <span class="hljs-keyword"><span class="hljs-keyword">for</span></span>(<span class="hljs-type"><span class="hljs-type">int</span></span> iTest=<span class="hljs-number"><span class="hljs-number">0</span></span>; iTest&lt;(TESTS_NUMBER/<span class="hljs-number"><span class="hljs-number">10</span></span>); iTest++) { QueryPerformanceCounter((LARGE_INTEGER*)&amp;start_count); <span class="hljs-keyword"><span class="hljs-keyword">for</span></span>(<span class="hljs-type"><span class="hljs-type">int</span></span> iJob=<span class="hljs-number"><span class="hljs-number">0</span></span>; iJob&lt;DATA_SIZE; iJob++) { //<span class="hljs-keyword"><span class="hljs-keyword">Check</span></span> boundary conditions <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (iJob &gt;= DATA_SIZE) break; //<span class="hljs-keyword"><span class="hljs-keyword">Perform</span></span> calculations pOutputVectorHost[iJob] = MathCalculations(pInputVector1[iJob], pInputVector2[iJob]); } QueryPerformanceCounter((LARGE_INTEGER*)&amp;end_count); <span class="hljs-type"><span class="hljs-type">double</span></span> <span class="hljs-type"><span class="hljs-type">time</span></span> = <span class="hljs-number"><span class="hljs-number">1000</span></span> * (<span class="hljs-type"><span class="hljs-type">double</span></span>)(end_count - start_count) / (<span class="hljs-type"><span class="hljs-type">double</span></span>)freq; timeValues.push_back(<span class="hljs-type"><span class="hljs-type">time</span></span>); } hostPerformanceTimeMS = std::accumulate(timeValues.<span class="hljs-keyword"><span class="hljs-keyword">begin</span></span>(), timeValues.<span class="hljs-keyword"><span class="hljs-keyword">end</span></span>(), <span class="hljs-number"><span class="hljs-number">0</span></span>)/timeValues.size(); PrintTimeStatistic(); }</code> </pre><br></div></div><br>  In her first cycle <br><pre> <code class="hljs objectivec"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> iTest=<span class="hljs-number"><span class="hljs-number">0</span></span>; iTest&lt;(TESTS_NUMBER/<span class="hljs-number"><span class="hljs-number">10</span></span>); iTest++)</code> </pre><br>  it is necessary in order to carry out the test several times in order to obtain a more accurate execution time.  The calculation time of each test is stored in the timeValues ‚Äã‚Äãarray from which the average value is then calculated and stored in hostPerformanceTimeMS. <br><br>  Second cycle <br><pre> <code class="hljs objectivec"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> iJob=<span class="hljs-number"><span class="hljs-number">0</span></span>; iJob&lt;DATA_SIZE; iJob++)</code> </pre><br>  consistently performs some mathematical calculations on the elements of the input arrays and stores them in the output array. <br><br>  As we can see, there is nothing unusual in this code, it is compiled by a regular CBC compiler and executed sequentially on a central processor, like most of the code we all write every day.  And we need it in order to subsequently verify with it the results obtained by OpenCL, as well as understand what performance gains we get. <br><br>  Immediately you should look at MathCalculations and see that everything is completely boring: <br><div class="spoiler">  <b class="spoiler_title">float MathCalculations (float a, float b)</b> <div class="spoiler_text"><pre> <code class="hljs go">float MathCalculations(float a, float b) { float res = <span class="hljs-number"><span class="hljs-number">0</span></span>; res += a*a*<span class="hljs-number"><span class="hljs-number">0.315f</span></span> + b*<span class="hljs-number"><span class="hljs-number">0.512f</span></span> + <span class="hljs-number"><span class="hljs-number">0.789f</span></span>; res += a*a*<span class="hljs-number"><span class="hljs-number">0.15f</span></span> + b*<span class="hljs-number"><span class="hljs-number">0.12f</span></span> + <span class="hljs-number"><span class="hljs-number">0.789f</span></span>; res += a*a*<span class="hljs-number"><span class="hljs-number">0.35f</span></span> + b*<span class="hljs-number"><span class="hljs-number">0.51f</span></span> + <span class="hljs-number"><span class="hljs-number">0.89f</span></span>; res += a*a*<span class="hljs-number"><span class="hljs-number">0.31f</span></span> + b*<span class="hljs-number"><span class="hljs-number">0.52f</span></span> + <span class="hljs-number"><span class="hljs-number">0.7f</span></span>; res += a*a*<span class="hljs-number"><span class="hljs-number">0.4315f</span></span> + b*<span class="hljs-number"><span class="hljs-number">0.512f</span></span> + <span class="hljs-number"><span class="hljs-number">0.4789f</span></span>; res += a*a*<span class="hljs-number"><span class="hljs-number">0.515f</span></span> + b*<span class="hljs-number"><span class="hljs-number">0.132f</span></span> + <span class="hljs-number"><span class="hljs-number">0.7859f</span></span>; res += a*a*<span class="hljs-number"><span class="hljs-number">0.635f</span></span> + b*<span class="hljs-number"><span class="hljs-number">0.521f</span></span> + <span class="hljs-number"><span class="hljs-number">0.89f</span></span>; res += a*a*<span class="hljs-number"><span class="hljs-number">0.731f</span></span> + b*<span class="hljs-number"><span class="hljs-number">0.152f</span></span> + <span class="hljs-number"><span class="hljs-number">0.7f</span></span>; res += a*a*<span class="hljs-number"><span class="hljs-number">0.1315f</span></span> + b*<span class="hljs-number"><span class="hljs-number">0.512f</span></span> + <span class="hljs-number"><span class="hljs-number">0.789f</span></span>; res += a*a*<span class="hljs-number"><span class="hljs-number">0.115f</span></span> + b*<span class="hljs-number"><span class="hljs-number">0.12f</span></span> + <span class="hljs-number"><span class="hljs-number">0.789f</span></span>; res += a*a*<span class="hljs-number"><span class="hljs-number">0.135f</span></span> + b*<span class="hljs-number"><span class="hljs-number">0.51f</span></span> + <span class="hljs-number"><span class="hljs-number">0.89f</span></span>; res += a*a*<span class="hljs-number"><span class="hljs-number">0.131f</span></span> + b*<span class="hljs-number"><span class="hljs-number">0.52f</span></span> + <span class="hljs-number"><span class="hljs-number">0.7f</span></span>; res += a*a*<span class="hljs-number"><span class="hljs-number">0.14315f</span></span> + b*<span class="hljs-number"><span class="hljs-number">0.512f</span></span> + <span class="hljs-number"><span class="hljs-number">0.4789f</span></span>; res += a*a*<span class="hljs-number"><span class="hljs-number">0.1515f</span></span> + b*<span class="hljs-number"><span class="hljs-number">0.132f</span></span> + <span class="hljs-number"><span class="hljs-number">0.7859f</span></span>; res += a*a*<span class="hljs-number"><span class="hljs-number">0.1635f</span></span> + b*<span class="hljs-number"><span class="hljs-number">0.521f</span></span> + <span class="hljs-number"><span class="hljs-number">0.89f</span></span>; res += a*a*<span class="hljs-number"><span class="hljs-number">0.1731f</span></span> + b*<span class="hljs-number"><span class="hljs-number">0.152f</span></span> + <span class="hljs-number"><span class="hljs-number">0.7f</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> res; }</code> </pre><br></div></div><br>  Actually, it has no special meaning (and it is obvious that it can be greatly simplified), but serves as a simple demonstration of pure mathematical operations.  The important thing about it is that it is in a separate .cpp file and that a lot of arithmetic operations are performed in it, but more on that later. <br><br><h1>  Part Two - Initializing OpenCL </h1><br>  So, the patient read up to this part and were delighted that the interesting begins, but those who are impatient cannot experience this feeling, they missed the last paragraph :) <br><br>  First, I will say that the OpenCL Runtime API is exactly the API for C, not for C ++.  In general, there is nothing wrong with this except that for error checking, it is necessary to check the code returned by each function and this is not very convenient.  And you also need to manually monitor the release of allocated resources. <br>  But there is also an official C ++ wrapper (it can be found on the Khronos website), which is a set of classes corresponding to OpenCL objects and supporting reference counting and throwing exceptions in case of errors (exceptions must be included with #define __CL_ENABLE_EXCEPTIONS ).  I will use this very wrapper in our test. <br><br>  So first we get a list of available platforms: <br><pre> <code class="hljs cpp"><span class="hljs-built_in"><span class="hljs-built_in">vector</span></span>&lt;cl::Platform&gt; platforms; cl::Platform::get(&amp;platforms);</code> </pre><br>  The platform in OpenCL corresponds to the vendor, i.e.  NVidia will have one platform with its devices, Intel will have another, etc. and so on.  In my case, two NVidia and Intel platforms are available to me. <br><br>  Immediately another little trick, the C ++ wrapper can use its own vectors (if you tell it about it) or vectors from STD, so if somewhere in the examples you get something like cl :: vector, don't be alarmed, he knows both formats . <br><br>  After we have received the list of platforms, for each platform we get a list of available devices: <br><pre> <code class="hljs css"><span class="hljs-selector-tag"><span class="hljs-selector-tag">std</span></span><span class="hljs-selector-pseudo"><span class="hljs-selector-pseudo">::vector</span></span>&lt;<span class="hljs-selector-tag"><span class="hljs-selector-tag">cl</span></span><span class="hljs-selector-pseudo"><span class="hljs-selector-pseudo">::Device</span></span>&gt; <span class="hljs-selector-tag"><span class="hljs-selector-tag">devices</span></span>; <span class="hljs-selector-tag"><span class="hljs-selector-tag">platforms</span></span><span class="hljs-selector-attr"><span class="hljs-selector-attr">[iPlatform]</span></span><span class="hljs-selector-class"><span class="hljs-selector-class">.getDevices</span></span>(<span class="hljs-selector-tag"><span class="hljs-selector-tag">CL_DEVICE_TYPE_ALL</span></span>, &amp;<span class="hljs-selector-tag"><span class="hljs-selector-tag">devices</span></span>);</code> </pre><br>  Actually the devices are what will perform our calculations.  It can be a GPU, a CPU, and some special accelerator that is connected to the host, i.e.  the system on which OpenCL runs.  Instead of CL_DEVICE_TYPE_ALL, you can send CL_DEVICE_TYPE_GPU, then it will issue only video cards or CL_DEVICE_TYPE_CPU for CPUs. <br><br>  For each device I find, I run a test, which I‚Äôll talk about below, and try to catch exceptions that OpenCL throws in case of problems, and if everything went well, CheckResults compares the results with those we counted in the first part of the host and calculates statistics mistakes. <br><br><h1>  Part Three - Creating and Running the Kernel </h1><br>  Here we come to the most interesting part - calculations. <br><div class="spoiler">  <b class="spoiler_title">void PerformTestOnDevice (cl :: Device device)</b> <div class="spoiler_text"><pre> <code class="hljs pgsql"><span class="hljs-type"><span class="hljs-type">void</span></span> PerformTestOnDevice(cl::Device device) { cout &lt;&lt; endl &lt;&lt; "-------------------------------------------------" &lt;&lt; endl; cout &lt;&lt; "Device: " &lt;&lt; device.getInfo&lt;CL_DEVICE_NAME&gt;() &lt;&lt; endl &lt;&lt; endl; //<span class="hljs-keyword"><span class="hljs-keyword">For</span></span> the selected device <span class="hljs-keyword"><span class="hljs-keyword">create</span></span> a context vector&lt;cl::Device&gt; contextDevices; contextDevices.push_back(device); cl::Context context(contextDevices); //<span class="hljs-keyword"><span class="hljs-keyword">For</span></span> the selected device <span class="hljs-keyword"><span class="hljs-keyword">create</span></span> a context <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> command queue cl::CommandQueue queue(context, device); //Clean output <span class="hljs-keyword"><span class="hljs-keyword">buffers</span></span> fill_n(pOutputVector, DATA_SIZE, <span class="hljs-number"><span class="hljs-number">0</span></span>); //<span class="hljs-keyword"><span class="hljs-keyword">Create</span></span> memory <span class="hljs-keyword"><span class="hljs-keyword">buffers</span></span> cl::Buffer clmInputVector1 = cl::Buffer(context, CL_MEM_READ_ONLY|CL_MEM_COPY_HOST_PTR, DATA_SIZE * sizeof(<span class="hljs-type"><span class="hljs-type">float</span></span>), pInputVector1); cl::Buffer clmInputVector2 = cl::Buffer(context, CL_MEM_READ_ONLY|CL_MEM_COPY_HOST_PTR, DATA_SIZE * sizeof(<span class="hljs-type"><span class="hljs-type">float</span></span>), pInputVector2); cl::Buffer clmOutputVector = cl::Buffer(context, CL_MEM_READ_WRITE|CL_MEM_COPY_HOST_PTR, DATA_SIZE * sizeof(<span class="hljs-type"><span class="hljs-type">float</span></span>), pOutputVector); //<span class="hljs-keyword"><span class="hljs-keyword">Load</span></span> OpenCL source code std::ifstream sourceFile("OpenCLFile1.cl"); std::string sourceCode(std::istreambuf_iterator&lt;<span class="hljs-type"><span class="hljs-type">char</span></span>&gt;(sourceFile),(std::istreambuf_iterator&lt;<span class="hljs-type"><span class="hljs-type">char</span></span>&gt;())); //Build OpenCL program <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> make the kernel cl::Program::Sources source(<span class="hljs-number"><span class="hljs-number">1</span></span>, std::make_pair(sourceCode.c_str(), sourceCode.length()+<span class="hljs-number"><span class="hljs-number">1</span></span>)); cl::Program program = cl::Program(context, source); program.build(contextDevices); cl::Kernel kernel(program, "TestKernel"); //<span class="hljs-keyword"><span class="hljs-keyword">Set</span></span> arguments <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> kernel <span class="hljs-type"><span class="hljs-type">int</span></span> iArg = <span class="hljs-number"><span class="hljs-number">0</span></span>; kernel.setArg(iArg++, clmInputVector1); kernel.setArg(iArg++, clmInputVector2); kernel.setArg(iArg++, clmOutputVector); kernel.setArg(iArg++, DATA_SIZE); //<span class="hljs-keyword"><span class="hljs-keyword">Some</span></span> performance measurement timeValues.clear(); __int64 start_count; __int64 end_count; __int64 freq; QueryPerformanceFrequency((LARGE_INTEGER*)&amp;freq); //Run the kernel <span class="hljs-keyword"><span class="hljs-keyword">on</span></span> specific ND range <span class="hljs-keyword"><span class="hljs-keyword">for</span></span>(<span class="hljs-type"><span class="hljs-type">int</span></span> iTest=<span class="hljs-number"><span class="hljs-number">0</span></span>; iTest&lt;TESTS_NUMBER; iTest++) { QueryPerformanceCounter((LARGE_INTEGER*)&amp;start_count); queue.enqueueNDRangeKernel(kernel, cl::NullRange, cl::NDRange(DATA_SIZE), cl::NDRange(<span class="hljs-number"><span class="hljs-number">128</span></span>)); queue.finish(); QueryPerformanceCounter((LARGE_INTEGER*)&amp;end_count); <span class="hljs-type"><span class="hljs-type">double</span></span> <span class="hljs-type"><span class="hljs-type">time</span></span> = <span class="hljs-number"><span class="hljs-number">1000</span></span> * (<span class="hljs-type"><span class="hljs-type">double</span></span>)(end_count - start_count) / (<span class="hljs-type"><span class="hljs-type">double</span></span>)freq; timeValues.push_back(<span class="hljs-type"><span class="hljs-type">time</span></span>); } PrintTimeStatistic(); // <span class="hljs-keyword"><span class="hljs-keyword">Read</span></span> buffer C <span class="hljs-keyword"><span class="hljs-keyword">into</span></span> a <span class="hljs-keyword"><span class="hljs-keyword">local</span></span> list queue.enqueueReadBuffer(clmOutputVector, CL_TRUE, <span class="hljs-number"><span class="hljs-number">0</span></span>, DATA_SIZE * sizeof(<span class="hljs-type"><span class="hljs-type">float</span></span>), pOutputVector); }</code> </pre><br></div></div><br>  First we output the device name obtained in this way: <br><pre> <code class="hljs objectivec">device.getInfo&lt;<span class="hljs-built_in"><span class="hljs-built_in">CL_DEVICE_NAME</span></span>&gt;()</code> </pre><br>  In the same way you can get information about the number of cores, frequency, version, etc. etc. <br><br>  Then we create the context: <br><pre> <code class="hljs cpp"><span class="hljs-built_in"><span class="hljs-built_in">vector</span></span>&lt;cl::Device&gt; contextDevices; contextDevices.push_back(device); cl::<span class="hljs-function"><span class="hljs-function">Context </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">context</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(contextDevices)</span></span></span></span>;</code> </pre><br>  With contexts, everything is not so simple ... When creating a context, we pass a list of devices that we want to include in it, but there is a restriction: only devices on one platform can be in one context, i.e.  make context with the GPU and CPU (in the case of Intel / NVidia) fail.  In the case of multiple devices in the same context, all buffers will be synchronized automatically on different devices.  On the one hand, this simplifies support for multi-GPU, and on the other hand, no one knows how, when and when the driver will synchronize, and data transfer efficiency is critical for obtaining high performance for which everything is started.  Therefore, I usually create a separate context for each device and manually distribute the data.  Thus, it is always known what, where, when occurs. <br><br>  The next step is to create a command queue for the device: <br><pre> <code class="hljs cpp">cl::<span class="hljs-function"><span class="hljs-function">CommandQueue </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">queue</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(context, device)</span></span></span></span>;</code> </pre><br>  This queue is tied to a specific device and, in theory, it may be Out of Order, but in fact, I did not notice this behavior.  There can be several queues for one device, and you can synchronize commands from different queues, but within the same context. <br><br>  Next we create buffers for the input and output vectors: <br><pre> <code class="hljs vhdl">//Create memory buffers cl::<span class="hljs-keyword"><span class="hljs-keyword">Buffer</span></span> clmInputVector1 = cl::<span class="hljs-keyword"><span class="hljs-keyword">Buffer</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">context</span></span>, CL_MEM_READ_ONLY|CL_MEM_COPY_HOST_PTR, DATA_SIZE * sizeof(float), pInputVector1); cl::<span class="hljs-keyword"><span class="hljs-keyword">Buffer</span></span> clmInputVector2 = cl::<span class="hljs-keyword"><span class="hljs-keyword">Buffer</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">context</span></span>, CL_MEM_READ_ONLY|CL_MEM_COPY_HOST_PTR, DATA_SIZE * sizeof(float), pInputVector2); cl::<span class="hljs-keyword"><span class="hljs-keyword">Buffer</span></span> clmOutputVector = cl::<span class="hljs-keyword"><span class="hljs-keyword">Buffer</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">context</span></span>, CL_MEM_READ_WRITE|CL_MEM_COPY_HOST_PTR, DATA_SIZE * sizeof(float), pOutputVector);</code> </pre><br>  When creating a buffer, the context (and not the specific device), its volume and, if desired, and using the CL_MEM_COPY_HOST_PTR flag, a pointer to the data that will be copied into it during creation are indicated.  As I said earlier, the C ++ wrapper uses reference counting, so you do not need to delete the buffer manually, unlike the pure C API. <br><br>  Next, we need to create a kernel whose code is stored in the file ‚ÄúOpenCLFile1.cl‚Äù.  To do this, we read the text from the file, create an OpenCL program, compile it, and get a kernel from it with the name "TestKernel", which you will see in the next section. <br><pre> <code class="hljs cpp">cl::Program::<span class="hljs-function"><span class="hljs-function">Sources </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">source</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">1</span></span></span></span><span class="hljs-function"><span class="hljs-params">, </span></span><span class="hljs-built_in"><span class="hljs-function"><span class="hljs-params"><span class="hljs-built_in">std</span></span></span></span><span class="hljs-function"><span class="hljs-params">::make_pair(sourceCode.c_str(), sourceCode.length()+</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">1</span></span></span></span><span class="hljs-function"><span class="hljs-params">))</span></span></span></span>; cl::Program program = cl::Program(context, source); program.build(contextDevices); cl::<span class="hljs-function"><span class="hljs-function">Kernel </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">kernel</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(program, </span></span><span class="hljs-string"><span class="hljs-function"><span class="hljs-params"><span class="hljs-string">"TestKernel"</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span></span>;</code> </pre><br>  When compiling, you need to specify on which devices we plan to launch it, in our case it is one selected device for the test, although you can specify everything at once.  You can also pass compilation flags, but in this example we don‚Äôt. <br><br>  Next, we need to set the arguments that will be passed to the kernel.  Unlike CUDA, you need to call special functions (in the case of the C ++ wrapper, methods) for each argument and, if necessary, specify the size of the argument. <br><pre> <code class="hljs objectivec"><span class="hljs-keyword"><span class="hljs-keyword">int</span></span> iArg = <span class="hljs-number"><span class="hljs-number">0</span></span>; kernel.setArg(iArg++, clmInputVector1); kernel.setArg(iArg++, clmInputVector2); kernel.setArg(iArg++, clmOutputVector); kernel.setArg(iArg++, DATA_SIZE);</code> </pre><br>  Now we come to the most important thing - starting the kernel: <br><pre> <code class="hljs css"><span class="hljs-selector-tag"><span class="hljs-selector-tag">queue</span></span><span class="hljs-selector-class"><span class="hljs-selector-class">.enqueueNDRangeKernel</span></span>(<span class="hljs-selector-tag"><span class="hljs-selector-tag">kernel</span></span>, <span class="hljs-selector-tag"><span class="hljs-selector-tag">cl</span></span><span class="hljs-selector-pseudo"><span class="hljs-selector-pseudo">::NullRange</span></span>, <span class="hljs-selector-tag"><span class="hljs-selector-tag">cl</span></span><span class="hljs-selector-pseudo"><span class="hljs-selector-pseudo">::NDRange(DATA_SIZE)</span></span>, <span class="hljs-selector-tag"><span class="hljs-selector-tag">cl</span></span><span class="hljs-selector-pseudo"><span class="hljs-selector-pseudo">::NDRange(128))</span></span>;</code> </pre><br>  The queue.enqueueNDRangeKernel itself adds the kernel start command to the command queue and sets the number of elements to be processed, as well as the size of the group.  I will tell about groups separately (in another article), but now I will only mention the fact that all elements are always divided into groups and the performance can strongly depend on the size of the group.  In our case, the number of elements is DATA_SIZE, and the group size is 128. During kernel execution, it will be run DATA_SIZE once (in an unknown sequence and possibly simultaneously) and every time it is launched, information will be transmitted on which element is being processed. <br>  enqueueNDRangeKernel is not blocking, so after starting the kernel, we have to wait for it to complete, which is what it is for: <br><pre> <code class="hljs css"><span class="hljs-selector-tag"><span class="hljs-selector-tag">queue</span></span><span class="hljs-selector-class"><span class="hljs-selector-class">.finish</span></span>();</code> </pre><br>  In fact, finish performs two tasks: <br>  1) Sends all commands to the device (execution of enqueueNDRangeKernel ensures that the driver received the command and put it in the queue, but does not guarantee its launch on the device, and quite often it can take quite a long time before the actual launch of the kernel). <br>  2) Waiting for completion of all teams in the queue. <br>  If only the first part needs to be executed, there is a push command (clFlush), which is not blocking, but causes the driver to start executing commands from the queue. <br><br>  After performing the calculations, we calculate the elapsed time and load the calculation results back to the host with the command: <br><pre> <code class="hljs objectivec">queue.enqueueReadBuffer(clmOutputVector, <span class="hljs-built_in"><span class="hljs-built_in">CL_TRUE</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, DATA_SIZE * <span class="hljs-keyword"><span class="hljs-keyword">sizeof</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">float</span></span>), pOutputVector);</code> </pre><br>  Depending on the second argument, the enqueueReadBuffer may be blocking or non-blocking.  In our case, it is blocking, so there is no need to call finish separately.  The syntax is simple: the first argument is where to read, the fourth argument is how much to read, and the last argument is where to read.  There is also a parameter that specifies the offset from the beginning of the input buffer, which should be used if we need to read the data not first, since we cannot use address arithmetic for OpenCL buffers on the host. <br><br><h1>  Part Four - OpenCL kernel code </h1><br>  And here we got to the place where we need to start writing code (although it is difficult to call it code, so ... self-indulgence :)) on OpenCL.  This is what OpenCLFile1.cl looks like: <br><pre> <code class="hljs mel">#include <span class="hljs-string"><span class="hljs-string">"MathCode.cpp"</span></span> __kernel void TestKernel( __global const <span class="hljs-keyword"><span class="hljs-keyword">float</span></span>* pInputVector1, __global const <span class="hljs-keyword"><span class="hljs-keyword">float</span></span>* pInputVector2, __global <span class="hljs-keyword"><span class="hljs-keyword">float</span></span>* pOutputVectorHost, <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> elementsNumber) { <span class="hljs-comment"><span class="hljs-comment">//Get index into global data array int iJob = get_global_id(0); //Check boundary conditions if (iJob &gt;= elementsNumber) return; //Perform calculations pOutputVectorHost[iJob] = MathCalculations(pInputVector1[iJob], pInputVector2[iJob]); }</span></span></code> </pre><br>  So in order: <br>  First of all, we include in our code the MathCode.cpp file, which contains a mathematical function, the same one I asked to pay attention to earlier and the same one that is used for traditional calculations on the host.  As you can see, we do not even copy the code, we use the same file with the mathematical code. <br>  Next we create a kernel, which we mark with the __kernel keyword.  Some kernel arguments are also labeled with the __global keyword, which indicates that this is a buffer in the device‚Äôs global memory created by us in the host code. <br>  In the kernel code we get the number of the element that needs to be processed: <br><pre> <code class="hljs objectivec"><span class="hljs-keyword"><span class="hljs-keyword">int</span></span> iJob = get_global_id(<span class="hljs-number"><span class="hljs-number">0</span></span>);</code> </pre><br>  The get_global_id parameter indicates the dimension, since the elements being processed can be a 1, 2, or 3-dimensional array. <br>  Then we check the boundary conditions: <br><pre> <code class="hljs kotlin"><span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (iJob &gt;= elementsNumber) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span>;</code> </pre><br>  This must be done for the reason that the number of elements to be processed must always be a multiple of the size of the group, and thus it may exceed the number to be processed. <br>  And after verification we do the main part: calculations, and in exactly the same way as on the host: <br><pre> <code class="hljs">pOutputVectorHost[iJob] = MathCalculations(pInputVector1[iJob], pInputVector2[iJob]);</code> </pre><br><br><h1>  Part Five - Testing and Performance Measurements </h1><br>  So it's time to start the application, evaluate the performance and draw some conclusions. <br><br>  I ran the test on two machines and got interesting results: <br>  Laptop (CPU: <a href="http://ark.intel.com/products/43124/Intel-Core-i7-820QM-Processor-(8M-Cache-1_73-GHz)">Intel¬Æ Core ‚Ñ¢ i7-820QM</a> , GPU: <a href="http://www.nvidia.ru/object/product_quadro_fx_2800_m_ru.html">NVidia Quadro FX 2800M</a> ): <br><pre> <code class="hljs css"><span class="hljs-selector-tag"><span class="hljs-selector-tag">Host</span></span>: 959<span class="hljs-selector-class"><span class="hljs-selector-class">.256</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">ms</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">CPU</span></span>: 82<span class="hljs-selector-class"><span class="hljs-selector-class">.4163</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">ms</span></span> (13<span class="hljs-selector-class"><span class="hljs-selector-class">.106X</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">faster</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">than</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">host</span></span>) <span class="hljs-selector-tag"><span class="hljs-selector-tag">GPU</span></span>: 9<span class="hljs-selector-class"><span class="hljs-selector-class">.90836</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">ms</span></span> (109<span class="hljs-selector-class"><span class="hljs-selector-class">.014X</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">faster</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">than</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">host</span></span>)</code> </pre><br>  Desktop (CPU: <a href="http://ark.intel.com/products/52213">Intel¬Æ Core ‚Ñ¢ i7-2600</a> , GPU: <a href="http://www.nvidia.ru/object/product-geforce-gtx-580-ru.html">NVidia GeForce GTX 580</a> ): <br><pre> <code class="hljs css"><span class="hljs-selector-tag"><span class="hljs-selector-tag">Host</span></span>: 699<span class="hljs-selector-class"><span class="hljs-selector-class">.031</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">ms</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">CPU</span></span>: 27<span class="hljs-selector-class"><span class="hljs-selector-class">.7833</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">ms</span></span> (25<span class="hljs-selector-class"><span class="hljs-selector-class">.159X</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">faster</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">than</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">host</span></span>) <span class="hljs-selector-tag"><span class="hljs-selector-tag">GPU</span></span>: 2<span class="hljs-selector-class"><span class="hljs-selector-class">.06257</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">ms</span></span> (338<span class="hljs-selector-class"><span class="hljs-selector-class">.897X</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">faster</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">than</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">host</span></span>)</code> </pre><br><div class="spoiler">  <b class="spoiler_title">Full results</b> <div class="spoiler_text"><pre> <code class="hljs perl">Device: Host Calculation <span class="hljs-keyword"><span class="hljs-keyword">time</span></span> statistic: (<span class="hljs-number"><span class="hljs-number">20</span></span> runs) Med: <span class="hljs-number"><span class="hljs-number">959.256</span></span> ms (<span class="hljs-number"><span class="hljs-number">1.12602</span></span>X faster than host) Avg: <span class="hljs-number"><span class="hljs-number">1080.15</span></span> ms Min: <span class="hljs-number"><span class="hljs-number">933.554</span></span> ms Max: <span class="hljs-number"><span class="hljs-number">1319.19</span></span> ms ------------------------------------------------- Device: Quadro FX <span class="hljs-number"><span class="hljs-number">2800</span></span>M Calculation <span class="hljs-keyword"><span class="hljs-keyword">time</span></span> statistic: (<span class="hljs-number"><span class="hljs-number">200</span></span> runs) Med: <span class="hljs-number"><span class="hljs-number">9.90836</span></span> ms (<span class="hljs-number"><span class="hljs-number">109.014</span></span>X faster than host) Avg: <span class="hljs-number"><span class="hljs-number">10.7231</span></span> ms Min: <span class="hljs-number"><span class="hljs-number">9.82841</span></span> ms Max: <span class="hljs-number"><span class="hljs-number">135.924</span></span> ms Errors: avgRelAbsDiff = <span class="hljs-number"><span class="hljs-number">5.25777</span></span>e-<span class="hljs-number"><span class="hljs-number">00</span></span>8 maxRelAbsDiff = <span class="hljs-number"><span class="hljs-number">5.83678</span></span>e-<span class="hljs-number"><span class="hljs-number">007</span></span> ------------------------------------------------- Device: Intel(R) Core(TM) i7 CPU Q <span class="hljs-number"><span class="hljs-number">820</span></span> @ <span class="hljs-number"><span class="hljs-number">1.73</span></span>GHz Calculation <span class="hljs-keyword"><span class="hljs-keyword">time</span></span> statistic: (<span class="hljs-number"><span class="hljs-number">200</span></span> runs) Med: <span class="hljs-number"><span class="hljs-number">82.4163</span></span> ms (<span class="hljs-number"><span class="hljs-number">13.106</span></span>X faster than host) Avg: <span class="hljs-number"><span class="hljs-number">85.2226</span></span> ms Min: <span class="hljs-number"><span class="hljs-number">79.4138</span></span> ms Max: <span class="hljs-number"><span class="hljs-number">113.03</span></span> ms Errors: avgRelAbsDiff = <span class="hljs-number"><span class="hljs-number">3.64332</span></span>e-<span class="hljs-number"><span class="hljs-number">00</span></span>8 maxRelAbsDiff = <span class="hljs-number"><span class="hljs-number">4.84797</span></span>e-<span class="hljs-number"><span class="hljs-number">007</span></span></code> </pre><br><pre> <code class="hljs perl">Device: Host Calculation <span class="hljs-keyword"><span class="hljs-keyword">time</span></span> statistic: (<span class="hljs-number"><span class="hljs-number">20</span></span> runs) Med: <span class="hljs-number"><span class="hljs-number">699.031</span></span> ms (<span class="hljs-number"><span class="hljs-number">0</span></span>.<span class="hljs-number"><span class="hljs-number">999956</span></span>X faster than host) Avg: <span class="hljs-number"><span class="hljs-number">699.1</span></span> ms Min: <span class="hljs-number"><span class="hljs-number">691.544</span></span> ms Max: <span class="hljs-number"><span class="hljs-number">715.233</span></span> ms ------------------------------------------------- Device: GeForce GTX <span class="hljs-number"><span class="hljs-number">580</span></span> Calculation <span class="hljs-keyword"><span class="hljs-keyword">time</span></span> statistic: (<span class="hljs-number"><span class="hljs-number">200</span></span> runs) Med: <span class="hljs-number"><span class="hljs-number">2.06257</span></span> ms (<span class="hljs-number"><span class="hljs-number">338.897</span></span>X faster than host) Avg: <span class="hljs-number"><span class="hljs-number">2.4</span></span> ms Min: <span class="hljs-number"><span class="hljs-number">2.03873</span></span> ms Max: <span class="hljs-number"><span class="hljs-number">82.0514</span></span> ms Errors: avgRelAbsDiff = <span class="hljs-number"><span class="hljs-number">3.50006</span></span>e-<span class="hljs-number"><span class="hljs-number">00</span></span>8 maxRelAbsDiff = <span class="hljs-number"><span class="hljs-number">4.92271</span></span>e-<span class="hljs-number"><span class="hljs-number">007</span></span> ------------------------------------------------- Device: Intel(R) Core(TM) i7-<span class="hljs-number"><span class="hljs-number">2600</span></span> CPU @ <span class="hljs-number"><span class="hljs-number">3.40</span></span>GHz Calculation <span class="hljs-keyword"><span class="hljs-keyword">time</span></span> statistic: (<span class="hljs-number"><span class="hljs-number">200</span></span> runs) Med: <span class="hljs-number"><span class="hljs-number">27.7833</span></span> ms (<span class="hljs-number"><span class="hljs-number">25.159</span></span>X faster than host) Avg: <span class="hljs-number"><span class="hljs-number">27.49</span></span> ms Min: <span class="hljs-number"><span class="hljs-number">27.0154</span></span> ms Max: <span class="hljs-number"><span class="hljs-number">35.8386</span></span> ms Errors: avgRelAbsDiff = <span class="hljs-number"><span class="hljs-number">3.64377</span></span>e-<span class="hljs-number"><span class="hljs-number">00</span></span>8 maxRelAbsDiff = <span class="hljs-number"><span class="hljs-number">4.89584</span></span>e-<span class="hljs-number"><span class="hljs-number">007</span></span></code> </pre><br></div></div><br><br>  So, let's proceed to the analysis of the results, and the results, I must say, are very impressive.  A GPU on a laptop at ~ 110X is faster than a host, and on a desktop at ~ 340X faster, an impressive result, however.  Before they start throwing sneakers at me and say that such a comparison is not correct, I will say that there are indeed some deceptions in it, but nothing more. <br><br>  First, we here do not take into account the time of copying data to the device and back.  On the one hand, this is wrong, since taking into account the copy, everything may not look so happy.  On the other hand, copying can be performed simultaneously with the calculations, or it may not be necessary to do it at all if the data are already on the device.  In general, everything is not so simple and depends on the specific task. <br><br>  Secondly, remember what the mathematical code looked like?  For those who did not look at it, I will say that it is a lot of mathematical operations on the same data, and it turned out to be simple copy-paste and replacing the numbers in the coefficients, but initially it was simpler and took only one line, only when I started testing, the results were not so joyful, the GPU was only 4-5 times faster.  What do you think, why?  (rhetorical question, you can not think :)).  And everything is simple, we have rested against memory performance.  I hope that later my hands will reach and I will write an article on the relationship between memory and processor performance, but this is another story, in this article we are only interested in the fact that we have obtained a pure test of processor arithmetic performance with this core. <br><br>  Given these two points, we can say that the GPU is indeed hundreds of times faster than non-parallel code on the CPU for pure arithmetic, which in general corresponds to the difference in theoretical performance.  (Another hope is that hands will measure the real numbers and their conformity of the theory for another article). <br><br>  But the fact that the GPU quickly thinks we know, and as a result of our test, it turned out that the CPU executes the OpenCL code rather quickly, to be exact, then 13X and 25X times faster than normal compiled MSVC10 code with default settings.  Let's understand how it turns out and where these figures come from. <br><br>  Both processors contain 4 real and 8 virtual cores, and OpenCL is made to use all cores, but the improvement is much greater than 4X.  And here I must say thanks to Intel, which in its implementation of OpenCL, added support for automatic vectorization, i.e.  without any changes in the code, OpenCL uses SSE or AVX, depending on what is available.  Considering that SSE is 128bit and AVX works with 256bit, it turns out that the performance should go up to 16X and 32X, respectively.  This is closer to the truth, but still not quite an exact match.  And then we need to remember such a joyful thing as TurboBoost.  These processors operate at 1.73GHz / 3.06GHz (laptop) and 3.4GHz / 3.8GHz (desktop) frequencies, but in fact I can say that the frequency of the laptop processor jumps from 1.73 to 2.8 continuously, and it heats up quite strongly (here you should throw a big camet at Dell behind the curve cooling system), so we really won't see any significant time during the 3.06GHz frequency test.  Plus, we should not forget that the practical result is always less than the theoretically possible (the desktop should work faster), but as we can see, 25X performance improvements can be obtained almost free of charge on the same hardware. <br><br><h1>  Conclusion </h1><br>            OpenCL,     ,       ( <a href="http://habrahabr.ru/post/125398/"></a>   ,     )         ,        ,              .  ,     ,     . <br><br> PS:  ,           ,  (   )   <a href="https://github.com/Akson/OpenCL_Test1"></a> .     OpenCL SDK    . <br><br> PS2:   -  Ivy Bridge,        .   ,     OpenCL SDK, Intel    IGP,      ,       .     AMD  . </div><p>Source: <a href="https://habr.com/ru/post/146823/">https://habr.com/ru/post/146823/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../146816/index.html">A small study on the mechanics of self-organization of online communities</a></li>
<li><a href="../146818/index.html">Apple bans US Galaxy Nexus sales</a></li>
<li><a href="../146819/index.html">Plugin that converts Photoshop styles to css code</a></li>
<li><a href="../146820/index.html">ksoap2-android and arrays in the query</a></li>
<li><a href="../146821/index.html">Publish module on cpan</a></li>
<li><a href="../146824/index.html">Bicycle: an alternative to iframe on jQuery.ajax as a tool for developing mash-up applications. Is there any reason?</a></li>
<li><a href="../146826/index.html">Gmail seems to have become the largest email service.</a></li>
<li><a href="../146828/index.html">AWS US-EAST-1 de-energized due to thunderstorms, victims need to run chkdsk</a></li>
<li><a href="../146829/index.html">Yeoman.io</a></li>
<li><a href="../146830/index.html">From July 1, a 10-digit forced dialing is introduced in Moscow</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>