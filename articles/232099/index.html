<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Clean and dirty test environments</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Good time of day, Habr! In this post I would like to talk about test environments, what is a clean and dirty environment, what tests are performed in ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Clean and dirty test environments</h1><div class="post__text post__text-html js-mediator-article"><div style="text-align:center;"><img src="https://habrastorage.org/files/6ec/89a/05b/6ec89a05bf704225956e4d350302695d.jpg"></div><br>  Good time of day, Habr!  In this post I would like to talk about test environments, what is a clean and dirty environment, what tests are performed in them and what tasks are achieved.  If you are not indifferent to these issues, welcome under cat. <br><a name="habracut"></a><br>  Each software developer, ever tested his offspring, sometimes without even knowing it.  Whether it is an application for windows, and maybe a mobile application for Android or iOS ... As a rule, novice developers are limited to test runs in the environment in which development takes place.  With the professional growth of a developer, the complexity of his creations grows.  Simple test runs can not do.  Then manual testing of the functional is used.  With a further increase in the complexity and age of the product, the number of functions that need to be covered with testing increases, at the same time it is necessary to remember the old functions, the performance of which should be checked.  The latter are not efficient to process manually and automatic testing takes place on the scene. <br><br>  Of course, it is not efficient to perform automated testing only in the development environment, since it is limited to one platform, one operating system, one set of installed software and traces of the presence of a product left over from past test runs.  The problem of testing the functionality of the platform, the operating system is solved by increasing the number of test environments: for example, increasing virtual or physical machines with different operating systems on which automatic tests will be run.  The more operating systems covered, the better the product will be.  All operating systems must be up to date. <br><br>  With physical machines, everything is simple: just enable auto-update.  With virtual machines deployed from images, the situation is more complicated.  To keep them up to date, you need to update the image.  The frequency depends on the moment of the release of the service packs or product-critical updates of the operating system.  In addition, in itself, it is useful to update the image.  Our small test automation group Acronis TrueImage made an willful decision: this period equated to three months. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      As in any business, you shouldn‚Äôt go to extremes, all variations of operating system versions are very difficult and inefficient to take into account.  It is highly likely that the user will have the current version of the Operating System (OS).  And it is worth being guided by it. <br><br><h4>  What is a clean test environment? </h4><br>  Problems of traces of the presence of previous versions of the product and interaction with third-party programs are solved by adding environments to the test plan that are as close as possible to the user's real environment (the so-called <i>dirty environment</i> ) and minimalistic environment (the so-called <i>pure environment</i> ).  Both species have the right to life and their purpose in the testing process. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/a61/a11/c0b/a61a11c0bfc84b92a2389eeef5e32c56.jpg"></div><br><br>  A clean environment - ideally, this is a newly installed operating system, followed by installing a product on it.  The number of external factors affecting the performance of the product is minimal.  Test "cooked in its own juice."  There are no traces of past product launches, any interaction with third-party programs, for example, antivirus or firewall, is excluded.  Thus, in the case of violations in the functional, we can confidently say that the problem is in the product.  Even if the problem is in the OS, the developer must ensure that it is working, since the OS is at a lower level.  To the flaws of the OS must adapt or reconcile.  OS rules the ball.  As a result, a clean environment facilitates the localization of bugs, reduces the time for setting up and deploying the test environment. <br><br>  As a pure test environment in which TrueImage is brewed, there is a small flock of physical machines with a population of 5-10 individuals.  They are usually at the disposal of manual testing engineers. <br><br><img src="https://habrastorage.org/files/abe/128/936/abe12893663d49779059f97e2eb794a0.jpg"><br>  <i>Shot from the movie where the valiant testers engineers localize bugs</i> <br><br>  In our arsenal, there is still a horde of virtual machines, most of which live on blade servers.  Virtual machines are considered conditionally clean environments, as they are defiled by our python scripts, which are copied to the experimental virtual machine in order to verify the functionality of the product.  The lifetime of virtual machines is short and equals the lifetime of the test script.  After running the virtual machine, if there are no bugs with honors in the form of a ‚Äúgreen‚Äù log, it is deleted from the server.  But if there is a hint of a defect in the application being tested, the virtual machine, after folding the logs into a secluded storage, is frozen for further clarification of the circumstances. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/acd/da0/0ba/acdda00ba15e4a1ab02a7415a0a4461c.png"></div><br><br>  And then our magic wand comes in, which saves a lot of time - a program for analyzing logs for known bugs.  The principle of its operation is not complicated, since logies are written by a computer, and not by an unpredictable person, it is enough to find the corresponding phrases or sets of phrases characteristic of the bug.  By analogy with the antivirus, a database of characteristic phrases and manifestations of defects is maintained.  Unfortunately, we have not yet written our antibagus with blackjack and heuristic analysis, so that if an unknown defect is encountered, we have to personally go into the logs. <br><br><h4>  ... and with which this clean environment is eaten </h4><br>  We have decided to divide the tests at several levels depending on the coverage of the functional and the execution time.  The first level is the BVT level (P1) - tests covering the main critical functionality, without which you shouldn‚Äôt even run the product: system backup, subsequent restor, etc.  The next level is called Common (P2-P3).  It includes functional checks, without which you can use the product somehow: backup disks of different file systems, restore to disks, with a size different from that stored, a scheduler.  BVT and Common it is advisable to perform, first of all, in clean environments.  Since these test suites are performed at the stage of active product development, it is important to run them regularly and, if bugs are found, they can be easily localized. <br><br><h4>  And what is the dirty test environment ... </h4><br>  With clean environments where only the OS is present and the product is sorted out.  But the software world is not only a clean operating system.  And in the world, in addition to the product being tested, there are other programs, even other versions of the product itself.  And how they affect the functionality of the test subject would also be good to check.  This is where the so-called dirty environment comes into play. <br><br><img src="https://habrastorage.org/files/7d1/3df/153/7d13df1536cd4d849728ac5f711efcbc.jpg"><br>  <i>Dirty is not always bad ...</i> <br><br>  <i>Dirty environment</i> - an environment in varying degrees close to the real environment in which the product will be used: the composition of the installed drivers, additional software, hardware components.  It may also be influenced by the presence of traces from previous launches of previous versions of the product, the use of accounts (for example, in cloud services) containing secondary data (backups in the cloud). <br><br>  Since different environments have different roles, respectively, the test suites for them are also different. <br><br><h4>  Why do we need to muddy? </h4><br>  Now it is the turn to tell what checks are performed in a dirty environment. <br><br>  What product function should you check?  Operation restaura?  Wasn‚Äôt it all being done for her?  Is it not after this operation that the stone falls from the shoulders?  Not.  The user can live in peace and well, knowing that he has a backup under the pillow.  So, backup should definitely pay attention.  But there is another operation, without which there will be no backup or restaurant.  This is a product installation operation. <br><br>  Acronis pays a lot of attention to this operation.  There is a type of test covering the entire life cycle of a product - LifeCycle.  These tests consist of steps such as: install, uninstall, reinstall, update, upgrade, etc.  Plus, the chains take into account the rich history of our products: 10 major versions - upgrades (but only the last 5 versions participate in testing, including new versions of the product: TrueImage 2013, TrueImage 2014) each of which has from 2 to 5 minor versions - grocery updates.  And this whole zoo is required to check.  Will TrueImage 2014 update2 be installed if the computer has already installed TrueImage 2013 update1 version?  And upgrade TrueImage 2013 RTM to TrueImage 2014 update1?  These questions will be answered by the above LifeCycle tests.  But this was not enough.  It is not enough just to put the product.  It would be nice to make sure that it works.  Therefore, between installations, upgrades, updates and reinstallations, the basic functionality of BVT is checked. <br><br><img src="https://habrastorage.org/files/56a/7aa/05d/56a7aa05d9904ab6a712f0ff8902d752.jpg"><br>  <i>Talisman TrueImage.</i>  <i>To magnify homy.</i>  <i>In honor of the former name TrueImage Home</i> <br><br>  Another type of tests performed in a dirty environment, the so-called Longhaul or Stability tests.  They are performed to assess the stability of the product over time.  Their essence is in performing the basic operations of the BVT, concluded in an automatic cycle for a long period of time.  We have this segment is 7-14 days, then the build is updated and the cycle of tests is repeated.  Thus, the previous cycle of tests affects the next one.  The backup and restore of large amounts of information sometimes take a single day, especially from the cloud, and especially with a slow channel.  Also, such tests reveal bugs associated with long work, for example, a memory leak, filling the hard disk, etc. <br><br><h4>  Peace, friendship, chewing gum </h4><br>  But that's not all.  But what about the influence of third-party programs on the product?  Here, unfortunately, automatic testing is not effective.  The computer can not fully assess the correctness of the interactions of the product and third-party programs. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/abc/c2a/e38/abcc2ae386b0437d96c742c35555e313.png"></div><br><br>  The most serious problems arise with programs that control access: antivirus and firewalls.  Here come to the aid of manual testing.  For example, will the standard Windows firewall allow a previously prepared backup to reside in the cloud? <br><br><h4>  Tests are different, tests are important. </h4><br>  Splitting tests into different levels makes it possible to choose trade-off solutions: the time needed to complete tests is inversely dependent on coverage.  For example, BVT tests are performed in the shortest period of time and allow you to quickly identify critical and blocking bugs.  Common already takes much more time, but it also covers more functionality.  Such tests, run regularly and frequently, allowing ‚Äúto keep abreast‚Äù, as a rule, are launched in <i>clean environments</i> . <br>  LifeCycle and tests on the impact of third-party software makes sense to run at least not earlier than the beta testing stage, when the product is stable.  Of particular importance is stability tests.  They are performed on individual machines 24 hours a day.  In this case, we already need a <i>dirty environment</i> . <br><br>  The presence of different levels of tests and different test environments provides greater opportunities for the localization of bugs.  The lower the test level, the less time it takes and the more often it is performed.  Suppose a bug was detected when performing a test for interaction with third-party software (high level).  This bug also manifested itself when performing Common tests, but at the same time was not seen at the lowest BVT level, it can be concluded that third-party software had nothing to do with it, since the bug was found in the pure Common Test environment, but not in BVT tests.  So it is in the functionality covered by Common tests. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/6e8/021/c23/6e8021c2319543ac895833592d4e0373.jpg"></div><br>  A clean environment helps to quickly identify and localize bugs at low cost.  The dirty environment on the contrary helps to find the most sophisticated defects in the product.  Automation justifies the funds spent on its implementation, but it will not completely save you from manual testing, at the same time some things, such as the product life cycle, cannot be tested without automation. </div><p>Source: <a href="https://habr.com/ru/post/232099/">https://habr.com/ru/post/232099/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../232089/index.html">Simple MVC model implementation with template hierarchy support</a></li>
<li><a href="../232091/index.html">Intel Pro 2500 - new SSD series with hardware encryption</a></li>
<li><a href="../232093/index.html">NASA confirms the performance of the "impossible" wave engine that does not use reactive mass - EmDrive</a></li>
<li><a href="../232095/index.html">ERPXE like a magic pill</a></li>
<li><a href="../232097/index.html">Writing a simple interpreter in C ++ using TDD, part 3</a></li>
<li><a href="../232103/index.html">Node.js + HTML5 + js = online action game. Play on Node.js</a></li>
<li><a href="../232107/index.html">Motivation in a person‚Äôs life, or my little experience (introduction)</a></li>
<li><a href="../232109/index.html">The Rosetta interplanetary station measured the surface temperature of the comet Churyumov-Gerasimenko</a></li>
<li><a href="../232111/index.html">XBMC Media Player Renamed to Kodi</a></li>
<li><a href="../232113/index.html">Switching layouts with CapsLock on Ubuntu 14.04</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>