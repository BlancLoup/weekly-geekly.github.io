<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>The amazing performance of parallel C ++ 17 algorithms. Myth or Reality?</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Good evening! 

 From our course ‚ÄúDeveloper C ++‚Äù we offer you a small and interesting study about parallel algorithms. 

 Go. 

 With the advent of p...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>The amazing performance of parallel C ++ 17 algorithms. Myth or Reality?</h1><div class="post__text post__text-html js-mediator-article">  Good evening! <br><br>  From our course <a href="https://otus.pw/NmIA/">‚ÄúDeveloper C ++‚Äù we</a> offer you a small and interesting study about parallel algorithms. <br><br>  Go. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      With the advent of parallel algorithms in C ++ 17, you can easily update your ‚Äúcomputational‚Äù code and benefit from parallel execution.  In this article, I want to consider the STL algorithm, which naturally reveals the idea of ‚Äã‚Äãindependent computing.  Is it possible to expect 10-fold acceleration with a 10-core processor?  Maybe more?  Or less?  Let's talk about it. <br><br>  <b>Introduction to parallel algorithms</b> <br><br><img src="https://habrastorage.org/webt/9g/6q/pm/9g6qpm5cnalmrub2fcrgwsuxw0y.png"><a name="habracut"></a><br><br>  C ++ 17 offers an execution policy option for most algorithms: <br><br><ul><li> sequenced_policy is a type of execution policy, is used as a unique type to eliminate the overload of the parallel algorithm and the requirement that parallelization of the execution of a parallel algorithm is impossible: the corresponding global object is <code>std::execution::seq</code> ; </li><li>  parallel_policy is a type of execution policy used as a unique type to eliminate the overload of the parallel algorithm and to indicate that parallelization of the execution of the parallel algorithm is possible: the corresponding global object is <code>std::execution::par</code> ; </li><li>  parallel_unsequenced_policy is a type of execution policy used as a unique type for eliminating the overload of the parallel algorithm and indicating that parallelization and vectorization of the parallel algorithm execution are possible: the corresponding global object is <code>std::execution::par_unseq</code> ; </li></ul><br>  Briefly: <br><br><ul><li>  use <code>std::execution::seq</code> to execute the algorithm sequentially; </li><li>  use <code>std::execution::par</code> to execute the algorithm in parallel (usually with the help of some implementation of the Thread Pool implementation); </li><li>  use <code>std::execution::par_unseq</code> for parallel execution of the algorithm with the possibility of using vector commands (for example, SSE, AVX). </li></ul><br>  As a quick example, we call <code>std::sort</code> in parallel: <br><br><pre> <code class="cpp hljs"><span class="hljs-built_in"><span class="hljs-built_in">std</span></span>::sort(<span class="hljs-built_in"><span class="hljs-built_in">std</span></span>::execution::par, myVec.begin(), myVec.end()); <span class="hljs-comment"><span class="hljs-comment">// ^^^^^^^^^^^^^^^^^^^ //  </span></span></code> </pre> <br>  Note how easy it is to add a parallel execution parameter to the algorithm!  But will it be possible to achieve significant performance improvements?  Will it increase the speed?  Or are there cases of slowdown? <br><br>  <b>Parallel <code>std::transform</code></b> <br><br>  In this article, I want to draw attention to the <code>std::transform</code> algorithm, which can potentially be the basis for other parallel methods (along with <code>std::transform_reduce</code> , <code>for_each</code> , <code>scan</code> , <code>sort</code> ...). <br><br>  Our test code will be based on the following pattern: <br><br><pre> <code class="cpp hljs"><span class="hljs-built_in"><span class="hljs-built_in">std</span></span>::transform(execution_policy, <span class="hljs-comment"><span class="hljs-comment">// par, seq, par_unseq inVec.begin(), inVec.end(), outVec.begin(), ElementOperation);</span></span></code> </pre> <br>  Suppose that the <code>ElementOperation</code> function <code>ElementOperation</code> not have any synchronization methods, in which case the code has the potential for parallel execution or even vectorization.  Each element calculation is independent, the order does not matter, so the implementation can generate several threads (possibly in a thread pool) for independent processing of elements. <br><br>  I would like to experiment with the following things: <br><br><ul><li>  the size of the vector field is large or small; </li><li>  a simple conversion that spends most of the time accessing memory; </li><li>  more arithmetic (ALU) operations; </li><li>  ALU in a more realistic scenario. </li></ul><br>  As you can see, I want to not only test the number of elements that are ‚Äúgood‚Äù for using the parallel algorithm, but also the ALU operations that the processor occupies. <br>  Other algorithms, such as sorting, accumulation (in the form of std :: reduce) also offer parallel execution, but also require more work to calculate the results.  Therefore, we will consider them candidates for another article. <br><br>  Benchmark Note <br><br>  For my tests, I use Visual Studio 2017, 15.8 - since this is the only implementation in the popular / STL compiler implementation at the current time (November, 2018) (GCC on the way!).  Moreover, I focused only on <code>execution::par</code> , since <code>execution::par_unseq</code> not available in MSVC (it works like <code>execution::par</code> ). <br><br>  There are two computers: <br><br><ul><li>  i7 8700 - PC, Windows 10, i7 8700 - clock speed 3.2 GHz, 6 cores / 12 threads (Hyperthreading); </li><li>  i7 4720 - Laptop, Windows 10, i7 4720, 2.6GHz clock speed, 4 cores / 8 threads (Hyperthreading). </li></ul><br>  The code is compiled into x64, Release more, auto-vectorization is enabled by default, I also included the extended command set (SSE2) and OpenMP (2.0). <br><br>  The code is in my github: <a href="">github / fenbf / ParSTLTests / TransformTests / TransformTests.cpp</a> <br><br>  For OpenMP (2.0), I use parallelism only for loops: <br><br><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">pragma</span></span></span><span class="hljs-meta"> omp parallel for for (int i = 0; ...)</span></span></code> </pre> <br>  I run the code 5 times and look at the minimum results. <br><br>  <i><b>Warning</b> : The results reflect only rough observations, check on your system / configuration before using in production.</i>  <i>Your requirements and environment may differ from mine.</i> <br><br>  More details about MSVC implementation can be found in <a href="https://blogs.msdn.microsoft.com/vcblog/2018/09/11/using-c17-parallel-algorithms-for-better-performance/">this post</a> .  But the latest <a href="https://www.youtube.com/watch%3Fv%3DnOpwhTbulmk">report of</a> Bill O'Neal with CppCon 2018 (Bill implemented Parallel STL in MSVC). <br><br>  Well, let's start with simple examples! <br><br>  <b>Simple conversion</b> <br><br>  Consider the case when you apply a very simple operation to the input vector.  This may be copying or multiplying elements. <br><br>  For example: <br><br><pre> <code class="cpp hljs"><span class="hljs-built_in"><span class="hljs-built_in">std</span></span>::transform(<span class="hljs-built_in"><span class="hljs-built_in">std</span></span>::execution::par, vec.begin(), vec.end(), out.begin(), [](<span class="hljs-keyword"><span class="hljs-keyword">double</span></span> v) { <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> v * <span class="hljs-number"><span class="hljs-number">2.0</span></span>; } );</code> </pre><br>  My computer has 6 or 4 cores ... can I expect a 4..6-fold acceleration of sequential execution?  Here are my results (time in milliseconds): <br><br><table><tbody><tr><th>  Operation </th><th>  Vector size </th><th>  i7 4720 (4 cores) </th><th>  i7 8700 (6 cores) </th></tr><tr><td>  execution :: seq </td><td>  10k </td><td>  0.002763 </td><td>  0.001924 </td></tr><tr><td>  execution :: par </td><td>  10k </td><td>  0.009869 </td><td>  0.008983 </td></tr><tr><td>  openmp parallel for </td><td>  10k </td><td>  0.003158 </td><td>  0.002246 </td></tr><tr><td>  execution :: seq </td><td>  100k </td><td>  0.051318 </td><td>  0.028872 </td></tr><tr><td>  execution :: par </td><td>  100k </td><td>  0.043028 </td><td>  0.025664 </td></tr><tr><td>  openmp parallel for </td><td>  100k </td><td>  0.022501 </td><td>  0.009624 </td></tr><tr><td>  execution :: seq </td><td>  1000k </td><td>  1.69508 </td><td>  0.52419 </td></tr><tr><td>  execution :: par </td><td>  1000k </td><td>  1.65561 </td><td>  0.359619 </td></tr><tr><td>  openmp parallel for </td><td>  1000k </td><td>  1.50678 </td><td>  0.344863 </td></tr></tbody></table><br>  On a faster machine, we can see that it will take about 1 million items to notice an improvement in performance.  On the other hand, on my laptop all parallel implementations were slower. <br><br>  Thus, it is difficult to notice any significant performance improvement with such transformations, even with an increase in the number of elements. <br><br>  Why so? <br><br>  Since the operations are elementary, the processor cores can call it almost instantly, using only a few cycles.  However, the processor cores spend more time waiting for the main memory.  So, in this case, for the most part they will wait, rather than perform calculations. <br><br>  <i>Reading and writing a variable in memory takes about 2-3 clocks if it is cached, and a few hundred clocks if not cached.</i> <br>  <a href="https://www.agner.org/optimize/optimizing_cpp.pdf">https://www.agner.org/optimize/optimizing_cpp.pdf</a> <br><br>  You can roughly say that if your algorithm depends on memory, then you should not expect an improvement in performance with parallel computation. <br><br>  <b>More calculations</b> <br><br>  Because memory bandwidth is extremely important and can affect the speed of things ... let's increase the number of calculations affecting each element. <br><br>  The idea is that it is better to use processor cycles, and not to waste time waiting for memory. <br><br>  To begin with, I use trigonometric functions, for example, <code>sqrt(sin*cos)</code> (these are conditional calculations in a non-optimal form, just to occupy the processor). <br><br>  We use <code>sqrt</code> , <code>sin</code> and <code>cos</code> , which can take ~ 20 per <code>sqrt</code> and ~ 100 per trigonometric function.  This amount of computation can cover the memory access delay. <br><br>  For more information about the delays of the teams, see the excellent <a href="https://www.agner.org/optimize/instruction_tables.pdf">Perf Guide</a> article <a href="https://www.agner.org/optimize/instruction_tables.pdf">from Agner Fogh</a> . <br><br>  Here is the benchmark code: <br><br><pre> <code class="cpp hljs"><span class="hljs-built_in"><span class="hljs-built_in">std</span></span>::transform(<span class="hljs-built_in"><span class="hljs-built_in">std</span></span>::execution::par, vec.begin(), vec.end(), out.begin(), [](<span class="hljs-keyword"><span class="hljs-keyword">double</span></span> v) { <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-built_in"><span class="hljs-built_in">std</span></span>::<span class="hljs-built_in"><span class="hljs-built_in">sqrt</span></span>(<span class="hljs-built_in"><span class="hljs-built_in">std</span></span>::<span class="hljs-built_in"><span class="hljs-built_in">sin</span></span>(v)*<span class="hljs-built_in"><span class="hljs-built_in">std</span></span>::<span class="hljs-built_in"><span class="hljs-built_in">cos</span></span>(v)); } );</code> </pre> <br>  And now what?  Can we expect to improve performance compared to the previous attempt? <br><br>  Here are some results (time in milliseconds): <br><br><table><tbody><tr><th>  Operation </th><th>  Vector size </th><th>  i7 4720 (4 cores) </th><th>  i7 8700 (6 cores) </th></tr><tr><td>  execution :: seq </td><td>  10k </td><td>  0.105005 </td><td>  0.070577 </td></tr><tr><td>  execution :: par </td><td>  10k </td><td>  0.055661 </td><td>  0.03176 </td></tr><tr><td>  openmp parallel for </td><td>  10k </td><td>  0.096321 </td><td>  0.024702 </td></tr><tr><td>  execution :: seq </td><td>  100k </td><td>  1.08755 </td><td>  0.707048 </td></tr><tr><td>  execution :: par </td><td>  100k </td><td>  0.259354 </td><td>  0.17195 </td></tr><tr><td>  openmp parallel for </td><td>  100k </td><td>  0.898465 </td><td>  0.189915 </td></tr><tr><td>  execution :: seq </td><td>  1000k </td><td>  10.5159 </td><td>  7.16254 </td></tr><tr><td>  execution :: par </td><td>  1000k </td><td>  2.44472 </td><td>  1.10099 </td></tr><tr><td>  openmp parallel for </td><td>  1000k </td><td>  4.78681 </td><td>  1.89017 </td></tr></tbody></table><br>  Finally, we see quite good numbers :) <br><br>  For 1000 elements (not shown here), the time for parallel and sequential calculations was similar, so for more than 1000 elements we see an improvement in the parallel version. <br><br>  For 100 thousand items, the result on a faster computer is almost 9 times better than the sequential version (similarly for the OpenMP version). <br><br>  In the largest variant of a million elements - the result is faster by 5 or 8 times. <br>  For such calculations, I achieved ‚Äúlinear‚Äù acceleration, depending on the number of processor cores.  What was expected. <br><br>  <b>Fresnel and 3D Vectors</b> <br><br>  In the section above, I used ‚Äúmade-up‚Äù calculations, but what about the real code? <br>  Let's solve the Fresnel equations that describe the reflection and curvature of light from a smooth, flat surface.  This is a popular method for generating realistic lighting in 3D games. <br><br><img src="https://habrastorage.org/webt/on/wm/7u/onwm7uw4puyphebsmkehma2jxfa.png"><br><br><img src="https://habrastorage.org/webt/7z/kq/2j/7zkq2jp8qisjnpc6y_gmgvhpupk.jpeg"><br>  <i>Photo from <a href="">Wikimedia</a></i> <br><br>  As a good sample, I found <a href="https://www.scratchapixel.com/lessons/3d-basic-rendering/introduction-to-shading/reflection-refraction-fresnel">this description and implementation</a> . <br><br>  <b>About using the GLM library</b> <br><br>  Instead of creating my own implementation, I used <a href="https://glm.g-truc.net/0.9.9/index.html">the glm library</a> .  I often use it in my OpenGl projects. <br><br>  The library is easy to access through the <a href="https://conan.io/">Conan Package Manager</a> , so I will use it too.  <a href="https://bintray.com/bincrafters/public-conan/glm%253Ag-truc">Link</a> to package. <br><br>  Conan file: <br><br><pre> <code class="bash hljs">[requires] glm/0.9.9.1@g-truc/stable [generators] visual_studio</code> </pre><br>  and the command line to install the library (it generates props files that I can use in the Visual Studio project): <br><br><pre> <code class="bash hljs">conan install . -s build_type=Release -<span class="hljs-keyword"><span class="hljs-keyword">if</span></span> build_release_x64 -s arch=x86_64</code> </pre> <br>  The library consists of a header, so you can simply download it manually if you want. <br><br>  <b>Actual code and benchmark</b> <br><br>  I adapted the glm code from <a href="https://www.scratchapixel.com/">scratchapixel.com</a> : <br><br><pre> <code class="cpp hljs"><span class="hljs-comment"><span class="hljs-comment">//    https://www.scratchapixel.com float fresnel(const glm::vec4 &amp;I, const glm::vec4 &amp;N, const float ior) { float cosi = std::clamp(glm::dot(I, N), -1.0f, 1.0f); float etai = 1, etat = ior; if (cosi &gt; 0) { std::swap(etai, etat); } //  sini     float sint = etai / etat * sqrtf(std::max(0.f, 1 - cosi * cosi)); //    if (sint &gt;= 1) return 1.0f; float cost = sqrtf(std::max(0.f, 1 - sint * sint)); cosi = fabsf(cosi); float Rs = ((etat * cosi) - (etai * cost)) / ((etat * cosi) + (etai * cost)); float Rp = ((etai * cosi) - (etat * cost)) / ((etai * cosi) + (etat * cost)); return (Rs * Rs + Rp * Rp) / 2.0f; }</span></span></code> </pre> <br>  The code uses several mathematical instructions, scalar product, multiplication, division, so the processor has something to do.  Instead of the double vector, we use a vector of 4 elements to increase the amount of used memory. <br><br>  Benchmark: <br><br><pre> <code class="cpp hljs"><span class="hljs-built_in"><span class="hljs-built_in">std</span></span>::transform(<span class="hljs-built_in"><span class="hljs-built_in">std</span></span>::execution::par, vec.begin(), vec.end(), vecNormals.begin(), <span class="hljs-comment"><span class="hljs-comment">//   vecFresnelTerms.begin(), //  [](const glm::vec4&amp; v, const glm::vec4&amp; n) { return fresnel(v, n, 1.0f); } );</span></span></code> </pre> <br>  And here are the results (time in milliseconds): <br><br><table><tbody><tr><th>  Operation </th><th>  Vector size </th><th>  i7 4720 (4 cores) </th><th>  i7 8700 (6 cores) </th></tr><tr><td>  execution :: seq </td><td>  1k </td><td>  0.032764 </td><td>  0.016361 </td></tr><tr><td>  execution :: par </td><td>  1k </td><td>  0.031186 </td><td>  0.028551 </td></tr><tr><td>  openmp parallel for </td><td>  1k </td><td>  0.005526 </td><td>  0.007699 </td></tr><tr><td>  execution :: seq </td><td>  10k </td><td>  0.246722 </td><td>  0.169383 </td></tr><tr><td>  execution :: par </td><td>  10k </td><td>  0.090794 </td><td>  0.067048 </td></tr><tr><td>  openmp parallel for </td><td>  10k </td><td>  0.049739 </td><td>  0.029835 </td></tr><tr><td>  execution :: seq </td><td>  100k </td><td>  2.49722 </td><td>  1.69768 </td></tr><tr><td>  execution :: par </td><td>  100k </td><td>  0.530157 </td><td>  0.283268 </td></tr><tr><td>  openmp parallel for </td><td>  100k </td><td>  0.495024 </td><td>  0.291609 </td></tr><tr><td>  execution :: seq </td><td>  1000k </td><td>  25.0828 </td><td>  16.9457 </td></tr><tr><td>  execution :: par </td><td>  1000k </td><td>  5.15235 </td><td>  2.33768 </td></tr><tr><td>  openmp parallel for </td><td>  1000k </td><td>  5.11801 </td><td>  2.95908 </td></tr></tbody></table><br>  With ‚Äúreal‚Äù computations, we see that parallel algorithms provide good performance.  For such operations on two of my Windows machines, I achieved acceleration with an almost linear dependence on the number of cores. <br><br>  For all tests, I also showed results from OpenMP and two implementations: MSVC and OpenMP work in a similar way. <br><br>  <b>Conclusion</b> <br><br>  In this article, I examined three cases of the use of parallel computing and parallel algorithms.  Replacing the standard algorithms with the version of std :: execution :: par may seem very tempting, but this is not always worth it!  Each operation you use inside the algorithm may work differently and be more dependent on the processor or memory.  Therefore, consider each change separately. <br><br>  What is worth remembering: <br><br><ul><li>  parallel execution usually does more than sequential, since the library must prepare for parallel execution; </li><li>  not only the number of elements is important, but also the number of instructions the processor is occupied with </li><li>  it is better to take tasks that are independent of each other and other shared resources; </li><li>  parallel algorithms offer an easy way to divide work into separate threads; </li><li>  if your operations are memory dependent, you should not expect performance improvements, and in some cases, the algorithms may be slower; </li><li>  to get a decent performance improvement, always measure the timings of each problem, in some cases the results may be completely different. </li></ul><br>  Special thanks to JFT for helping with the article! <br><br>  Also note my other sources about parallel algorithms: <br><br><ul><li>  A fresh chapter in my book <a href="https://leanpub.com/cpp17indetail">C ++ 17 In Detail</a> on Parallel Algorithms; </li><li>  <a href="https://www.bfilipek.com/2018/07/files-word-count.html">Parallel STL And Filesystem: Files Word Count Example</a> ; </li><li>  <a href="https://www.bfilipek.com/2018/06/parstl-tests.html">Examples of parallel algorithms from C ++ 17</a> . </li></ul><br>  Check out another article related to Parallel Algorithms: <a href="https://www.bfilipek.com/2018/11/pstl.html">How to Boost Performance with Intel Parallel STL and C ++ 17 Parallel Algorithms</a> <br><br>  THE END <br><br>  We are waiting for comments and questions that can be left here or with our <a href="https://otus.pw/vDjY/">teacher</a> at <a href="https://otus.pw/4n6O/">the open door</a> . </div><p>Source: <a href="https://habr.com/ru/post/433588/">https://habr.com/ru/post/433588/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../433576/index.html">Guide on the St. Petersburg IT movement</a></li>
<li><a href="../433578/index.html">"When art connects to craft": publishers of online media about technology, AI and life</a></li>
<li><a href="../433580/index.html">Roskomnadzor plans to introduce a new blocking system worth 20 billion rubles</a></li>
<li><a href="../433582/index.html">What if the 30/70 profit sharing ceases to be the gamedev standard?</a></li>
<li><a href="../433586/index.html">How we didn't win the hackathon</a></li>
<li><a href="../433592/index.html">Background: Yandex. Phone</a></li>
<li><a href="../433596/index.html">Magellan error: Buffer overrun or world expedition using SQLite FTS</a></li>
<li><a href="../433600/index.html">Phone Pixel 3 is learning to determine the depth in photos</a></li>
<li><a href="../433602/index.html">The basis of the rate of evolution may be mathematical simplicity.</a></li>
<li><a href="../433604/index.html">Comfortable work with Android Studio</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>