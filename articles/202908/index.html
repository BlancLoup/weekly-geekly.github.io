<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Automatic spell checker, model Noisy Channel</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Good day. The other day I had a task to implement the algorithm for post-processing the results of optical text recognition. To solve this problem, on...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Automatic spell checker, model Noisy Channel</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/getpro/habr/post_images/8c6/7d0/cc1/8c67d0cc19860840fc2f3a60635f98d7.jpg" align="right">  Good day.  The other day I had a task to implement the algorithm for post-processing the results of optical text recognition.  To solve this problem, one of the models for checking spelling in the text was not bad, although of course slightly modified under the context of the problem.  This post will be devoted to <a href="http://en.wikipedia.org/wiki/Noisy_channel_model">the Noisy Channel model</a> , which allows you to perform automatic spell checking, we will study the mathematical model, write some code on c #, train the model <a href="http://norvig.com/ngrams/">based on Peter Norvig</a> , and finally test what we will have. <br><br><a name="habracut"></a><br><br><h4>  Mathematical model - 1 </h4><br>  To begin with the formulation of the problem.  So you want to write some word <b>w</b> consisting of <b>m</b> letters, but in some way unknown to you on paper comes out the word <b>x</b> consisting of <b>n</b> letters.  By the way, you are the very <i>noisy channel</i> , the information transfer channel with noises, which distorted the correct word <b>w</b> (from the universe of correct words) to an incorrect <b>x</b> (the set of all written words). 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/getpro/habr/post_images/164/739/ac1/164739ac11d0aa25e31db1f31df3f1b9.png"><br><br>  We want to find the word that you most likely meant when you wrote the word <b>x</b> .  Let us write this thought mathematically, the model in its idea is similar to the model of the <a href="http://habrahabr.ru/post/184574/">naive Bayes classifier</a> , although even simpler: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/270/e97/d6b/270e97d6b378256fb0493d8b87b1679e.gif"><br><ul><li>  <b>V</b> is a list of all natural language words. </li></ul><br><br>  Next, using the Bayes theorem, we expand the cause and effect, we can remove the total probability <b>x</b> from the denominator, since  he <i>argmax</i> does not depend on <b>w</b> : <br><br><img src="https://habrastorage.org/getpro/habr/post_images/11f/4a5/3bd/11f4a53bd450c2b456c6ee18c829a7d6.gif"><br><br><ul><li>  <b>P (w)</b> is the a priori probability of the word <b>w</b> in the language;  this member is a statistical model of a natural language ( <i>language model</i> ), we will use <a href="http://en.wikipedia.org/wiki/Language_model">the</a> <a href="http://en.wikipedia.org/wiki/N-gram">unigram</a> <a href="http://en.wikipedia.org/wiki/Language_model">model</a> , although of course you have the right to use more complex models;  also note that the value of this member is easily calculated from the base of words of the language; </li><li>  <b>P (x | w)</b> is the probability that the correct word <b>w</b> was mistakenly written as <b>x</b> , this member is called the <i>channel model</i> ;  in principle, possessing a sufficiently large base, which contains all the ways to make a mistake when writing each word of a language, then the calculation of this term would not cause difficulties, but unfortunately there is no such large base, but there are similar smaller bases, so you have to get it out (for example <a href="http://norvig.com/ngrams/">here</a> is the base of 333333 words of the English language, and only for 7481 there are words with errors). </li></ul><br><br><h4>  Calculation of the probability value <b>P (x | w)</b> </h4><br>  This <a href="http://en.wikipedia.org/wiki/Damerau%25E2%2580%2593Levenshtein_distance">is where Damerau-Levenshtein distance</a> comes to help - this is a measure between two sequences of characters, defined as the minimum number of operations to insert, delete, replace and swap adjacent characters to bring the <i>source</i> string to the <i>target</i> string.  We will further use the <a href="http://en.wikipedia.org/wiki/Levenshtein_distance">Levenshtein distance</a> , which is distinguished by the fact that it does not support the operation of permuting neighboring symbols, so it will be easier.  <a href="http://habrahabr.ru/post/114997/">Both of these algorithms with examples are well described in here</a> , so I will not repeat, but I will immediately give the code: <br><br><div class="spoiler">  <b class="spoiler_title">Levenshtein distance</b> <div class="spoiler_text"><pre><code class="cs hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">static</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">int</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">LevenshteinDistance</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">string</span></span></span></span><span class="hljs-function"><span class="hljs-params"> s, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">string</span></span></span></span><span class="hljs-function"><span class="hljs-params"> t</span></span></span><span class="hljs-function">)</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">int</span></span>[,] d = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span>[s.Length + <span class="hljs-number"><span class="hljs-number">1</span></span>, t.Length + <span class="hljs-number"><span class="hljs-number">1</span></span>]; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> i = <span class="hljs-number"><span class="hljs-number">0</span></span>; i &lt; s.Length + <span class="hljs-number"><span class="hljs-number">1</span></span>; i++) { d[i, <span class="hljs-number"><span class="hljs-number">0</span></span>] = i; } <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> j = <span class="hljs-number"><span class="hljs-number">1</span></span>; j &lt; t.Length + <span class="hljs-number"><span class="hljs-number">1</span></span>; j++) { d[<span class="hljs-number"><span class="hljs-number">0</span></span>, j] = j; } <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> i = <span class="hljs-number"><span class="hljs-number">1</span></span>; i &lt;= s.Length; i++) { <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> j = <span class="hljs-number"><span class="hljs-number">1</span></span>; j &lt;= t.Length; j++) { d[i, j] = (<span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span>[] { d[i - <span class="hljs-number"><span class="hljs-number">1</span></span>, j] + <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-comment"><span class="hljs-comment">// del d[i, j - 1] + 1, // ins d[i - 1, j - 1] + (s[i - 1] == t[j - 1] ? 0 : 1) // sub }).Min(); } } return d[s.Length, t.Length]; }</span></span></code> </pre> <br></div></div><br><br>  This function tells us how many deletions, insertions and replacements need to be done to bring one word to another, but this is not enough for us, but I would like to receive a list of these very operations, let's call it the backtrace of the algorithm.  We need to modify the above code so that when calculating the distance matrix <b>d</b> , the operation matrix <i>b</i> is also recorded.  Consider an example for the words <b>ca</b> and <b>abc</b> : <br><br><table><tbody><tr><td>  <b>d</b> </td><td>  <b>b</b> (0 - delete from <i>source</i> , left; 1 - insert from <i>target</i> to <i>source</i> ; 2 - replace symbol in <i>source</i> with symbol from <i>target</i> ) </td></tr><tr><td><img src="https://habrastorage.org/getpro/habr/post_images/5fb/3a6/4a1/5fb3a64a1699fa04bd8823b151b49ca9.png"></td><td><img src="https://habrastorage.org/getpro/habr/post_images/45b/b3e/539/45bb3e5399e934de49bd726f87abd14d.png"></td></tr></tbody></table><br><br>  As you remember, the value of the cell <b>(i, j)</b> in the distance matrix <b>d is</b> calculated as follows: <br><br><pre> <code class="cs hljs">d[i, j] = (<span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span>[] { d[i - <span class="hljs-number"><span class="hljs-number">1</span></span>, j] + <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-comment"><span class="hljs-comment">// del - 0 d[i, j - 1] + 1, // ins - 1 d[i - 1, j - 1] + (s[i - 1] == t[j - 1] ? 0 : 1) // sub - 2 }).Min();</span></span></code> </pre><br><br>  It remains for us to write the operation index in the cell <b>(i, j) of the</b> matrix of operations <b>b</b> (0 for deletion, 1 for insertion and 2 for replacement), respectively, this piece of code is converted as follows: <br><br><pre> <code class="cs hljs">IList&lt;<span class="hljs-keyword"><span class="hljs-keyword">int</span></span>&gt; vals = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> List&lt;<span class="hljs-keyword"><span class="hljs-keyword">int</span></span>&gt;() { d[i - <span class="hljs-number"><span class="hljs-number">1</span></span>, j] + <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-comment"><span class="hljs-comment">// del d[i, j - 1] + 1, // ins d[i - 1, j - 1] + (s[i - 1] == t[j - 1] ? 0 : 1) // sub }; d[i, j] = vals.Min(); int idx = vals.IndexOf(d[i, j]); b[i, j] = idx;</span></span></code> </pre><br><br>  Once both matrices are filled, it is not difficult to calculate the backtrace (arrows in the pictures above).  This is the path from the lower right cell of the matrix of operations, along the path of the lowest cost matrix of distances.  We describe the algorithm: <br><ol><li>  let's denote the bottom right cell as the current one </li><li>  do one of the following <br><ul><li>  if deletion, then write the deleted character, and move the current cell up (red arrow) </li><li>  if insert, then write the inserted symbol and shift the current cell to the left (red arrow) </li><li>  if the replacement, as well as the replaced characters are <b>not</b> equal, then write the replaced characters and shift the current cell to the left and up (red arrow) </li><li>  if replacement, but replaceable characters are equal, then just move the current cell to the left and up (blue arrow) </li></ul><br></li><li>  if the number of recorded operations is not equal to the Levenshtein distance, then one point back, otherwise stop </li></ol><br><br>  As a result, we obtain the following function, which calculates the Levenshtein distance, as well as the backtrace: <br><br><div class="spoiler">  <b class="spoiler_title">Levenshtein distance with backtrace</b> <div class="spoiler_text"><pre> <code class="cs hljs"><span class="hljs-comment"><span class="hljs-comment">//del - 0, ins - 1, sub - 2 public static Tuple&lt;int, IList&lt;Tuple&lt;int, string&gt;&gt;&gt; LevenshteinDistanceWithBacktrace(string s, string t) { int[,] d = new int[s.Length + 1, t.Length + 1]; int[,] b = new int[s.Length + 1, t.Length + 1]; for (int i = 0; i &lt; s.Length + 1; i++) { d[i, 0] = i; } for (int j = 1; j &lt; t.Length + 1; j++) { d[0, j] = j; b[0, j] = 1; } for (int i = 1; i &lt;= s.Length; i++) { for (int j = 1; j &lt;= t.Length; j++) { IList&lt;int&gt; vals = new List&lt;int&gt;() { d[i - 1, j] + 1, // del d[i, j - 1] + 1, // ins d[i - 1, j - 1] + (s[i - 1] == t[j - 1] ? 0 : 1) // sub }; d[i, j] = vals.Min(); int idx = vals.IndexOf(d[i, j]); b[i, j] = idx; } } List&lt;Tuple&lt;int, string&gt;&gt; bt = new List&lt;Tuple&lt;int, string&gt;&gt;(); int x = s.Length; int y = t.Length; while (bt.Count != d[s.Length, t.Length]) { switch (b[x, y]) { case 0: x--; bt.Add(new Tuple&lt;int, string&gt;(0, s[x].ToString())); break; case 1: y--; bt.Add(new Tuple&lt;int, string&gt;(1, t[y].ToString())); break; case 2: x--; y--; if (s[x] != t[y]) { bt.Add(new Tuple&lt;int, string&gt;(2, s[x] + "" + t[y])); } break; } } bt.Reverse(); return new Tuple&lt;int, IList&lt;Tuple&lt;int, string&gt;&gt;&gt;(d[s.Length, t.Length], bt); }</span></span></code> </pre><br></div></div><br><br>  This function returns a tuple, in the first element of which the Levenshtein distance is written, and in the second one there is a list of &lt;operation id, string&gt; pairs, the string consists of one character for delete and insert operations, and two characters for replace operation (the first character is replaced by the second character ). <br><br>  PS: an attentive reader will notice that there are often several ways to move along the lowest cost path from the lower right cell, this is one of the ways to increase the sample, but we will also omit it for simplicity. <br><br><h4>  Mathematical model - 2 </h4><br>  Now we will describe the result obtained above in the language of formulas.  For two words <b>x</b> and <b>w,</b> we can calculate the list of operations necessary to bring the first word to the second, we denote the list of operations with the letter <b>f</b> , then the probability of writing the word <b>x</b> as <b>w</b> will be equal to the probability of producing the entire list of errors <b>f</b> , provided that we wrote exactly <b>x</b> , implied <b>w</b> : <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c6d/5b1/4e2/c6d5b14e2ff002a4fa50027465e7003c.gif"><br><br>  This is where simplifications begin, similar to those in the <a href="http://habrahabr.ru/post/184574/">naive Bayes classifier</a> : <br><ul><li>  the order of the error operations does not matter </li><li>  the error will not depend on what word we wrote and on what we meant </li></ul><br><br><img src="https://habrastorage.org/getpro/habr/post_images/6a0/401/02c/6a040102c941d06cc3ee057ca3a9347d.gif"><br><br>  Now, in order to calculate the error probabilities (no matter in which words they were made), it is enough to have on your hands any base of words with their erroneous writing.  Let's write the final formula, in order to avoid working with numbers close to zero, we will work in the log space: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/081/ac4/57e/081ac457eb5b09189f4465432db7d4d8.gif"><br><br>  So what do we have?  If we have enough texts in our hands, we can calculate a priori probabilities of words in a language;  also having on hand a base of words with their wrong spelling, we can calculate the error probabilities, these two bases are enough to implement the model. <br><br><h4>  Blur error probability </h4><br>  When running on all the base words with <i>argmax</i> , we never stumble on words with zero probability.  But when calculating editing operations to bring the word <b>x</b> to the word <b>w</b> , such operations may occur that were not encountered in our database of errors.  In this case, <a href="http://en.wikipedia.org/wiki/Additive_smoothing">additive smoothing or Laplace blur</a> will help us (it was also used in the <a href="http://habrahabr.ru/post/184574/">naive Bayes classifier</a> ).  Let me remind the formula in the context of the current task.  If some correction operation <b>f</b> occurs in the database <b>n</b> times, while the total errors are in the base <b>m</b> , and the correction types <b>t</b> (for example, to replace, not how many times does the replacement " <i>a</i> to <i>b</i> " occur, but how many unique pairs "* to * "), the fuzzy probability is as follows, where <b>k</b> is the blurring coefficient: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/1ce/536/093/1ce536093741ce9c13a3b665d4263cb9.gif"><br><br>  Then the probability of an operation that has never been met in the training database ( <b>n = 0</b> ) will be equal to: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/42f/afc/bf7/42fafcbf7e229fde5bf6c99efc6cee76.gif"><br><br><h4>  Speed </h4><br>  A natural question arises, what about the speed of the algorithm, because we will have to run through the entire database of words, and these are hundreds of thousands of calls to the Levenshtein distance calculation function with backtrace, and also to calculate the error probability for all words (the sum of numbers, if you keep in the database are precomputed logarithms).  Here comes the following statistical fact: <br><br><ul><li>  80% of all printed errors are within 1 editing operation, i.e.  Levenshtein distances equal to one </li><li>  almost all printing errors are within 2 editing operations </li></ul><br><br>  Well, then you can come up with various algorithmic tricks.  I used an obvious and very simple way to speed up the work of the algorithm.  Obviously, if I need only words in no more than t editing operations from the current word, then their length differs from the current one by no more than t.  When I initialize a class, I create a hash table, in which the keys are the length of words, and the values ‚Äã‚Äãare sets of words of this length, this allows us to significantly reduce the search space. <br><br><h4>  Code </h4><br>  I will give the code of the NoisyChannel class, which I got: <br><br><div class="spoiler">  <b class="spoiler_title">NoisyChannel</b> <div class="spoiler_text"><pre> <code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-keyword"><span class="hljs-keyword">class</span></span> <span class="hljs-title"><span class="hljs-title">NoisyChannel</span></span> { <span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">region</span></span></span><span class="hljs-meta"> vars private string[] _words = null; private double[] _wLogPriors = null; private IDictionary&lt;int, IList&lt;int&gt;&gt; _wordLengthDictionary = null; //length of word - word indices private IDictionary&lt;int, IDictionary&lt;string, double&gt;&gt; _mistakeLogProbs = null; private double _lf = 1d; private IDictionary&lt;int, int&gt; _mNorms = null; #</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">endregion</span></span></span><span class="hljs-meta"> #</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">region</span></span></span><span class="hljs-meta"> ctor public NoisyChannel(string[] words, long[] wordFrequency, IDictionary&lt;int, IDictionary&lt;string, int&gt;&gt; mistakeFrequency, int mistakeProbSmoothing = 1) { _words = words; _wLogPriors = new double[_words.Length]; _wordLengthDictionary = new SortedDictionary&lt;int, IList&lt;int&gt;&gt;(); double wNorm = wordFrequency.Sum(); for (int i = 0; i &lt; _words.Length; i++) { _wLogPriors[i] = Math.Log((wordFrequency[i] + 0d)/wNorm); int wl = _words[i].Length; </span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">if</span></span></span><span class="hljs-meta"> (!_wordLengthDictionary.ContainsKey(wl)) { _wordLengthDictionary.Add(wl, new List&lt;int&gt;()); } _wordLengthDictionary[wl].Add(i); } _lf = mistakeProbSmoothing; _mistakeLogProbs = new Dictionary&lt;int, IDictionary&lt;string, double&gt;&gt;(); _mNorms = new Dictionary&lt;int, int&gt;(); foreach (int mType in mistakeFrequency.Keys) { int mNorm = mistakeFrequency[mType].Sum(m =&gt; m.Value); _mNorms.Add(mType, mNorm); int mUnique = mistakeFrequency[mType].Count; _mistakeLogProbs.Add(mType, new Dictionary&lt;string, double&gt;()); foreach (string m in mistakeFrequency[mType].Keys) { _mistakeLogProbs[mType].Add(m, Math.Log((mistakeFrequency[mType][m] + _lf)/ (mNorm + _lf*mUnique)) ); } } } #</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">endregion</span></span></span><span class="hljs-meta"> #</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">region</span></span></span><span class="hljs-meta"> correction public IDictionary&lt;string, double&gt; GetCandidates(string s, int maxEditDistance = 2) { IDictionary&lt;string, double&gt; candidates = new Dictionary&lt;string, double&gt;(); IList&lt;int&gt; dists = new List&lt;int&gt;(); for (int i = s.Length - maxEditDistance; i &lt;= s.Length + maxEditDistance; i++) { </span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">if</span></span></span><span class="hljs-meta"> (i &gt;= 0) { dists.Add(i); } } foreach (int dist in dists) { foreach (int tIdx in _wordLengthDictionary[dist]) { string t = _words[tIdx]; Tuple&lt;int, IList&lt;Tuple&lt;int, string&gt;&gt;&gt; d = LevenshteinDistanceWithBacktrace(s, t); </span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">if</span></span></span><span class="hljs-meta"> (d.Item1 &gt; maxEditDistance) { continue; } double p = _wLogPriors[tIdx]; foreach (Tuple&lt;int, string&gt; m in d.Item2) { </span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">if</span></span></span><span class="hljs-meta"> (!_mistakeLogProbs[m.Item1].ContainsKey(m.Item2)) { p += _lf/(_mNorms[m.Item1] + _lf*_mistakeLogProbs[m.Item1].Count); } </span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">else</span></span></span><span class="hljs-meta"> { p += _mistakeLogProbs[m.Item1][m.Item2]; } } candidates.Add(_words[tIdx], p); } } candidates = candidates.OrderByDescending(c =&gt; c.Value).ToDictionary(c =&gt; c.Key, c =&gt; c.Value); return candidates; } #</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">endregion</span></span></span><span class="hljs-meta"> #</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">region</span></span></span><span class="hljs-meta"> static helper //del - 0, ins - 1, sub - 2 public static Tuple&lt;int, IList&lt;Tuple&lt;int, string&gt;&gt;&gt; LevenshteinDistanceWithBacktrace(string s, string t) { int[,] d = new int[s.Length + 1, t.Length + 1]; int[,] b = new int[s.Length + 1, t.Length + 1]; for (int i = 0; i &lt; s.Length + 1; i++) { d[i, 0] = i; } for (int j = 1; j &lt; t.Length + 1; j++) { d[0, j] = j; b[0, j] = 1; } for (int i = 1; i &lt;= s.Length; i++) { for (int j = 1; j &lt;= t.Length; j++) { IList&lt;int&gt; vals = new List&lt;int&gt;() { d[i - 1, j] + 1, // del d[i, j - 1] + 1, // ins d[i - 1, j - 1] + (s[i - 1] == t[j - 1] ? 0 : 1) // sub }; d[i, j] = vals.Min(); int idx = vals.IndexOf(d[i, j]); b[i, j] = idx; } } List&lt;Tuple&lt;int, string&gt;&gt; bt = new List&lt;Tuple&lt;int, string&gt;&gt;(); int x = s.Length; int y = t.Length; while (bt.Count != d[s.Length, t.Length]) { switch (b[x, y]) { case 0: x--; bt.Add(new Tuple&lt;int, string&gt;(0, s[x].ToString())); break; case 1: y--; bt.Add(new Tuple&lt;int, string&gt;(1, t[y].ToString())); break; case 2: x--; y--; </span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">if</span></span></span><span class="hljs-meta"> (s[x] != t[y]) { bt.Add(new Tuple&lt;int, string&gt;(2, s[x] + "" + t[y])); } break; } } bt.Reverse(); return new Tuple&lt;int, IList&lt;Tuple&lt;int, string&gt;&gt;&gt;(d[s.Length, t.Length], bt); } public static int LevenshteinDistance(string s, string t) { int[,] d = new int[s.Length + 1, t.Length + 1]; for (int i = 0; i &lt; s.Length + 1; i++) { d[i, 0] = i; } for (int j = 1; j &lt; t.Length + 1; j++) { d[0, j] = j; } for (int i = 1; i &lt;= s.Length; i++) { for (int j = 1; j &lt;= t.Length; j++) { d[i, j] = (new int[] { d[i - 1, j] + 1, // del d[i, j - 1] + 1, // ins d[i - 1, j - 1] + (s[i - 1] == t[j - 1] ? 0 : 1) // sub }).Min(); } } return d[s.Length, t.Length]; } #</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">endregion</span></span></span><span class="hljs-meta"> }</span></span></code> </pre><br></div></div><br><br>  The class is initialized with the following parameters: <br><ul><li>  <i>string [] words</i> - a list of words in a language; </li><li>  <i>long [] wordFrequency</i> - word frequency; </li><li>  <i>IDictionary &lt;int, IDictionary &lt;string, int &gt;&gt; mistakeFrequency</i> </li><li>  <i>int mistakeProbSmoothing = 1</i> - error rate blur rate </li></ul><br><br><h4>  Testing </h4><br>  For testing, we use <a href="http://norvig.com/ngrams/">Peter Norvig's database</a> , which contains 333333 words with frequencies, as well as 7481 words with erroneous spellings.  The following code is used to calculate the values ‚Äã‚Äãrequired for the initialization of the NoisyChannel class: <br><br><div class="spoiler">  <b class="spoiler_title">reading base</b> <div class="spoiler_text"><pre> <code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">string</span></span>[] words = <span class="hljs-literal"><span class="hljs-literal">null</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">long</span></span>[] wordFrequency = <span class="hljs-literal"><span class="hljs-literal">null</span></span>; <span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">region</span></span></span><span class="hljs-meta"> read priors </span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">if</span></span></span><span class="hljs-meta"> (!File.Exists("../../../Data/words.bin") || !File.Exists("../../../Data/wordFrequency.bin")) { IDictionary&lt;string, long&gt; wf = new Dictionary&lt;string, long&gt;(); Console.Write("Reading data:"); using (StreamReader sr = new StreamReader("../../../Data/count_1w.txt")) { string </span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">line</span></span></span><span class="hljs-meta"> = sr.ReadLine(); while (</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">line</span></span></span><span class="hljs-meta"> != null) { string[] parts = </span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">line</span></span></span><span class="hljs-meta">.Split('\t'); wf.Add(parts[0].Trim(), Convert.ToInt64(parts[1])); </span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">line</span></span></span><span class="hljs-meta"> = sr.ReadLine(); Console.Write("."); } sr.Close(); } Console.WriteLine("Done!"); words = wf.Keys.ToArray(); wordFrequency = wf.Values.ToArray(); using (FileStream fs = File.Create("../../../Data/words.bin")) { BinaryFormatter bf = new BinaryFormatter(); bf.Serialize(fs, words); fs.Flush(); fs.Close(); } using (FileStream fs = File.Create("../../../Data/wordFrequency.bin")) { BinaryFormatter bf = new BinaryFormatter(); bf.Serialize(fs, wordFrequency); fs.Flush(); fs.Close(); } } </span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">else</span></span></span><span class="hljs-meta"> { using (FileStream fs = File.OpenRead("../../../Data/words.bin")) { BinaryFormatter bf = new BinaryFormatter(); words = bf.Deserialize(fs) as string[]; fs.Close(); } using (FileStream fs = File.OpenRead("../../../Data/wordFrequency.bin")) { BinaryFormatter bf = new BinaryFormatter(); wordFrequency = bf.Deserialize(fs) as long[]; fs.Close(); } } #</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">endregion</span></span></span><span class="hljs-meta"> //del - 0, ins - 1, sub - 2 IDictionary&lt;int, IDictionary&lt;string, int&gt;&gt; mistakeFrequency = new Dictionary&lt;int, IDictionary&lt;string, int&gt;&gt;(); #</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">region</span></span></span><span class="hljs-meta"> read mistakes IDictionary&lt;string, IList&lt;string&gt;&gt; misspelledWords = new SortedDictionary&lt;string, IList&lt;string&gt;&gt;(); using (StreamReader sr = new StreamReader("../../../Data/spell-errors.txt")) { string </span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">line</span></span></span><span class="hljs-meta"> = sr.ReadLine(); while (</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">line</span></span></span><span class="hljs-meta"> != null) { string[] parts = </span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">line</span></span></span><span class="hljs-meta">.Split(':'); string wt = parts[0].Trim(); misspelledWords.Add(wt, parts[1].Split(',').Select(w =&gt; w.Trim()).ToList()); </span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">line</span></span></span><span class="hljs-meta"> = sr.ReadLine(); } sr.Close(); } mistakeFrequency.Add(0, new Dictionary&lt;string, int&gt;()); mistakeFrequency.Add(1, new Dictionary&lt;string, int&gt;()); mistakeFrequency.Add(2, new Dictionary&lt;string, int&gt;()); foreach (string s in misspelledWords.Keys) { foreach (string t in misspelledWords[s]) { var d = NoisyChannel.LevenshteinDistanceWithBacktrace(s, t); foreach (Tuple&lt;int, string&gt; ml in d.Item2) { </span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">if</span></span></span><span class="hljs-meta"> (!mistakeFrequency[ml.Item1].ContainsKey(ml.Item2)) { mistakeFrequency[ml.Item1].Add(ml.Item2, 0); } mistakeFrequency[ml.Item1][ml.Item2]++; } } } #</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">endregion</span></span></span></span></code> </pre><br></div></div><br><br>  The following code initializes the model and searches for the correct words for the word " <b>he ;; o</b> " (of course, <b>hello is</b> implied, <b>dotted</b> -comma is to the right of l and it was easy to make a mistake when typing, the word <b>hello</b> does not contain the word <b>he; ; o</b> ) at a distance of not more than 2, with the time detection: <br><br><pre> <code class="cs hljs">NoisyChannel nc = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> NoisyChannel(words, wordFrequency, mistakeFrequency, <span class="hljs-number"><span class="hljs-number">1</span></span>); Stopwatch timer = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Stopwatch(); timer.Start(); IDictionary&lt;<span class="hljs-keyword"><span class="hljs-keyword">string</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">double</span></span>&gt; c = nc.GetCandidates(<span class="hljs-string"><span class="hljs-string">"he;;o"</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>); timer.Stop(); TimeSpan ts = timer.Elapsed; Console.WriteLine(ts.ToString());</code> </pre><br><br>  In my opinion, such a calculation takes on average a little less than 1 second, although of course the optimization process is not exhausted by the above methods, but on the contrary, it only begins with them.  Take a look at the replacement options and their probabilities: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/7c9/78d/f90/7c978df90fbcf8a40845ce49569961ed.png"><br><br><h4>  Links </h4><br><ul><li>  <a href="https://class.coursera.org/nlp/class">course Natural Language Processing on the course</a> </li><li>  <a href="http://norvig.com/ngrams/">Natural Language Corpus Data: Beautiful Data</a> </li><li>  <a href="http://habrahabr.ru/post/114997/">good description of the algorithms of Levenshtein and Domerau-Levenshtein</a> </li></ul><br><br>  <a href="https://drive.google.com/file/d/0B4bl7YMqDnVicEhydkJRS0RVNEk/edit%3Fusp%3Dsharing">Archive code can be merged from here</a> . </div><p>Source: <a href="https://habr.com/ru/post/202908/">https://habr.com/ru/post/202908/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../202896/index.html">Continuous Integration in Selectle</a></li>
<li><a href="../202898/index.html">Wireless communications "smart home". Part two, practical</a></li>
<li><a href="../202900/index.html">KUB-BS - controller ‚Äúfor growth‚Äù for monitoring container-type objects, including Cellular base stations</a></li>
<li><a href="../202904/index.html">Budget VDS for training and development</a></li>
<li><a href="../202906/index.html">Livejack blackjack</a></li>
<li><a href="../202910/index.html">Automatic testing of iOS applications</a></li>
<li><a href="../202912/index.html">Electronic devices can be used in flight in the USA and Europe.</a></li>
<li><a href="../202914/index.html">Report on the launch of programs on users' computers</a></li>
<li><a href="../202918/index.html">November's new items in Opera: version for tablets and synchronization</a></li>
<li><a href="../202922/index.html">We extract gold from old electronics</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>