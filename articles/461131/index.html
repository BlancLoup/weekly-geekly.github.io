<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>The robot that will follow your smile. We make a cheap trolley for learning ROS. Part 2, software</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Moving on to the smile 
 Having collected the ‚Äúburger‚Äù according to the scheme from the last post , we will move on to the program content. 

 Since w...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>The robot that will follow your smile. We make a cheap trolley for learning ROS. Part 2, software</h1><div class="post__text post__text-html js-mediator-article"><h2>  Moving on to the smile </h2><br>  Having collected the ‚Äúburger‚Äù according to the scheme from the last <a href="https://habr.com/ru/post/460755/">post</a> , we will move on to the program content. <br><br>  Since we are collecting for an already completed project, it is logical to give the instructions indicated in it.  They are <a href="https://github.com/ROSbots/rosbots_setup_tools">here</a> . <br><br>  Everything is very convenient and in the same place you can download a ready-made image from Raspbian Stretch + ROS + OpenCV, write it to an sd card for raspberry.  (ROS Kinetic, OpenCV 3.4.1. Yes, there is a newer one, but sometimes it's better to take and go than to collect everything from the source). <br><a name="habracut"></a><br>  Nevertheless, despite the convenience, I still had to slightly correct the image.  As it turned out some uncomfortable details of the original image: 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <ul><li>  no GUI (graphical interface).  This is not critical, especially for ROS, but to ride on a line you need to calibrate the camera on the raspberry itself, and see how it (the camera) conveys colors (more on that below); </li><li>  OpenCV assembly does not display the image on the screen, even if you install the GUI yourself.  Obviously, in the rosbots project, opencv was built without this option. </li><li>  no small crutches (VNC, text editor for notes, mc). </li><li>  Therefore, OpenCV was rebuilt with support for image output in the GUI (compiled by openCV 3.4.3), a GUI was installed, small crutches. </li></ul><br>  The finished image is <a href="https://drive.google.com/file/d/1dhp38WYghUE1zNREnI5vbP5tLI5iCwMa/view%3Fusp%3Dsharing">here</a> , and further work will be built on its basis. <br><br><h2>  Configure the network (wi-fi) and ROS-master on raspberry pi </h2>  . <br>  I strongly recommend that you use a separate router with your wi-fi for experiments.  You can simply create an access point on the phone for these purposes.  This is due to the fact that a lot of packets will fly over wi-fi and, preferably, they do not sink in the general traffic. <br><br>  After uploading the image to the raspberry sd card, configure the network.  The initial network settings are as follows: <br><br><pre><code class="bash hljs">interface wlan0 static ip_address=192.168.43.174/24 static routers=192.168.43.1 static domain_name_servers=192.168.43.1</code> </pre> <br>  Contained in /etc/dhcpcd.conf <br><br>  Therefore, you can not connect the hoses to raspberry to change everything, but simply create an access point with the pathos name boss and password 1234554321. The address of raspberry will be 192.168.43.174.  Besides ssh, you can access this address via VNC: login - pi, password - 123qweasdzxcV. <br><br>  <b>Set up the ROS master</b> <br><br>  A small remark for those who have not encountered ROS (robotic operation system).  A ROS master is an intermediary through which different nodes communicate in ros (nodes, services, etc.) If the ros master is not running or is running at the wrong address, the nodes will not see each other. <br><br>  In our ROS system, the wizard starts automatically with the OS loading and all that is required of us is to specify the IP address for the ROS wizard in the corresponding system file. <br><br>  If you have not changed the network settings that are listed above, then you do not need to configure anything. <br><br>  Otherwise, edit bashrc: <br><br><pre> <code class="bash hljs">nano ~/.bashrc</code> </pre> <br>  At the very end of the file, correct the ip addresses (both) for your case: <br><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">export</span></span> ROS_MASTER_URI=http://192.168.43.174:11311 <span class="hljs-built_in"><span class="hljs-built_in">export</span></span> ROS_HOSTNAME=192.168.43.174</code> </pre><br>  Reboot. <br><br>  Now, when starting the terminal on a cart, the output will be like this (or whatever you specified in the settings): <br><br><pre> <code class="plaintext hljs">For all slaves, "export ROS_MASTER_URI=http://192.168.43.174:11311"</code> </pre> <br>  This means that the ROS master works at the specified ip address. <br><br><h2>  We control the trolley on wi-fi </h2><br>  We‚Äôll check from the beginning that the nodes work for us. <br><br>  In terminal: <br><br><pre> <code class="bash hljs">rosnode list</code> </pre> <br>  The output will be like this: <br><br>  / rosout <br>  / uno_serial_node <br><br>  If nothing came out, then check if you registered ROS-master in the settings as described above, whether you connected the usb hose to arduino, rebooted. <br><br>  After checking, run the 1st node responsible for the movement: <br><br><pre> <code class="bash hljs">rosrun rosbots_driver part2_cmr.py</code> </pre> <br>  * special ros command launches part2_cmr.py file from rosbots_driver python package <br><br>  The system will inform that the node is running: <br><br><img src="https://habrastorage.org/webt/fd/pi/bh/fdpibhvndu-d6cxfonymmdcklsu.png"><br><br>  Here you can see that the radius of the wheels and the distance between them are determined.  You can fix these values, as well as other ones related to movement in the robot.py file along the path <br><br><pre> <code class="bash hljs">/home/pi/rosbots_catkin_ws/src/rosbots_driver/scripts/examples/coursera_control_of_mobile_robots/part2/full/controller</code> </pre> <br>  since part2_cmr.py itself does not have these parameters.  Open the second terminal and enter the rostopic list: <br><br><img src="https://habrastorage.org/webt/5d/1v/4t/5d1v4tmlmyminhgqzkkciavcvq4.png"><br><br>  Here you can see that the topic / part2_cmr / cmd_vel has appeared.  In this topic, / part2_cmr "listens" to what other nodes will say to it and, depending on what they say, will control the movement.  What exactly ‚Äúlistens‚Äù, but not ‚Äúspeaks‚Äù can be understood using the command. <br><br><pre> <code class="bash hljs">rostopic info /part2_cmr/cmd_vel</code> </pre> <br><img src="https://habrastorage.org/webt/ts/bp/pj/tsbppjpegozrwhekno2hebxtwte.png"><br><br>  Here you can see that / part2_cmr subscriber (subscribed) to the topic and listens. <br><br>  * You can "say" something on the topic yourself, without nodes. <br><br>  For example: <br><br><pre> <code class="bash hljs">rostopic pub -1 /wheel_power_left std_msgs/Float32 <span class="hljs-string"><span class="hljs-string">'{data: 1.0}'</span></span></code> </pre> <br>  turn forward with the left wheel <br><br><pre> <code class="bash hljs">rostopic pub -1 /wheel_power_left std_msgs/Float32 <span class="hljs-string"><span class="hljs-string">'{data: 0.0}'</span></span></code> </pre> <br>  stop left wheel <br><br><pre> <code class="bash hljs">rostopic pub -1 /wheel_power_left std_msgs/Float32 <span class="hljs-string"><span class="hljs-string">'{data: -1.0}'</span></span></code> </pre> <br>  Turn back to back with a wheel <br><br><pre> <code class="bash hljs">rostopic pub -1 /wheel_power_left std_msgs/Float32 <span class="hljs-string"><span class="hljs-string">'{data: -0.5}'</span></span></code> </pre> <br>  Turn back with the left wheel slower. <br><br>  The syntax is: rostopic pub - desire to speak in topic, -1 - one-time desire, / wheel_power_left - topic where we speak, std_msgs / Float32 - language (message format), '{data: -0.5}' - what we say. <br><br>  Now run the one who will talk in the topic / part2_cmr / cmd_vel.  This will be the keyboard command sending node. <br><br>  Without closing the previous terminal with a working node, run another one and enter: <br><br><pre> <code class="bash hljs">rosrun teleop_twist_keyboard teleop_twist_keyboard.py /cmd_vel:=/part2_cmr/cmd_vel</code> </pre> <br>  * Since publication is by default in the topic / cmd_vel, we redirect it using <br>  / cmd_vel: = / part2_cmr / cmd_vel so that messages are poured into / part2_cmr / cmd_vel. <br><br>  The control node has started and you can train by pressing the keys on the keyboard: <br><br><img src="https://habrastorage.org/webt/fy/bz/fl/fybzflgbhdqykv-vvxhk72qy_hq.png"><br><br>  If it‚Äôs impossible to drive, or there is a subtle squeak from under the wheels, you need to increase the speed by clicking on ‚Äúw‚Äù in the terminal with the node running.  The same (increase or decrease) can be done with the rotation speed - the ‚Äúe‚Äù button.  It is also important to be in a terminal with a running node if the control buttons do not work if you switch to another terminal.  The ‚Äúk‚Äù button in the control terminal is a stop. <br><br>  In a separate terminal, let's look at the topic / part2_cmr / cmd_vel: <br><br><img src="https://habrastorage.org/webt/su/ab/cr/suabcrxmna11bzfmnxqsdzq0rxs.png"><br><br>  Now in the topic / part2_cmr / cmd_vel there is both a speaker and a listener. <br><br><h2>  Riding the line on OpenCV </h2><br>  Before you go somewhere, you need to make sure that the robot travels with keyboard control.  An important remark is needed here.  When controlling from the keyboard in the example above, a left turn should correspond to pressing j, right l (Latin l), forward i, back, (comma).  If this is not the case in your case, then there may be problems with the trip.  To bring everything back to normal, you need to change the wire pairs coming from the engine driver to the legs on arduino in our burger 4,5,6,7 arduino: 4,5 interchange with 6,7 or 4 and 5,6 and 7 each with another depending on where the wheels will spin.  You can also do this programmatically by adjusting the code for arduino along the path - /home/pi/gitspace/rosbots_driver/platformio/rosbots_firmware/examples/motor_driver/src/main.cpp <br><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#define M_LEFT_PWM 6 #define M_LEFT_FR 7 #define M_RIGHT_PWM 5 #define M_RIGHT_FR 4</span></span></code> </pre><br>  and reloading it on arduino with the command: <br><br><pre> <code class="bash hljs">upload_firmware ~/gitspace/rosbots_driver/platformio/rosbots_firmware/examples/motor_driver</code> </pre> <br>  <b>Let's work with flowers</b> <br><br>  Our gardening experience will be to highlight the line on the floor that the robot will travel along, to determine its color.  By default, the robot does not see it.  As the line, you can use either adhesive tape (yellow) or electrical tape or something else with a characteristic color and quite wide.  * Transparent adhesive tape is unlikely to work, because  it will be difficult to distinguish from the background. <br><br>  Let's go into the folder and run the script: <br><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> /home/pi/rosbots_catkin_ws/src/rosbots_driver/scripts/rosbots_driver python bgr-to-hsv.py</code> </pre> <br>  *Attention!  If you use the original image from rosbots, and not mine, this program is not there. <br><br>  Two windows will open: <br><br><img src="https://habrastorage.org/webt/_v/qy/lw/_vqylwcxaerfndl2h7fgomt2zcy.png"><br><br>  Here are the ranges of colors in HSV.  What is hsv and why not rgb, please google it yourself. <br><br>  h1, s1, v1 - lower and h2, s2, v2 - respectively, the upper range. <br><br>  Now you need to select a line with electrical tape (perhaps not tape but tape) on the floor by moving the sliders in the window.  Only the line of electrical tape should remain in the result window: <br><br><img src="https://habrastorage.org/webt/xv/4y/cs/xv4ycskbhskfqq-1pwzgc_-llgc.png"><br><br>  The line of electrical tape is unusually white, everything else is black.  This result is necessary. <br>  Record, remember the numbers of the HSV ranges.  My case is 56,155,40 and 136,255,255.  The HSV ranges will be different under different light conditions near the robot camera. <br><br>  Close the windows by entering ctrl + c in the terminal and add the HSV ranges to the follow_line_step_hsv.py file: <br><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> /home/pi/rosbots_catkin_ws/src/rosbots_driver/scripts/rosbots_driver nano follow_line_step_hsv.py</code> </pre> <br>  In the lines: <br><br><pre> <code class="plaintext hljs">lower_yellow = np.array([21,80,160]) upper_yellow = np.array([255,255,255])</code> </pre> <br>  We put the numbers of our HSV ranges. <br><br>  <b>Time to ride the line</b> <br><br>  We start the motor node in terminal 1: <br><br><pre> <code class="bash hljs">rosrun rosbots_driver part2_cmr.py</code> </pre> <br>  Launch the camera node in the second terminal: <br><br><pre> <code class="bash hljs">sudo modprobe bcm2835-v4l2 roslaunch usb_cam usb_cam-test.launch</code> </pre><br>  Run the opencv node in the third terminal: <br><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> /home/pi/rosbots_catkin_ws/src/rosbots_driver/scripts/rosbots_driver python follow_line_step_hsv.py</code> </pre><br>  If everything went well, then the robot will go along the line, and an additional window will appear: <br><br><img src="https://habrastorage.org/webt/bk/ug/aj/bkugajoo0itqwwkbn8zckbm2mvy.png"><br><br>  In this window, the electrical tape will be marked with a red circle. <br><br>  The general meaning of the code is to select a color segment at a certain distance from the camera, draw a red circle and go to this circle, trying to keep it in the center. <br><br><h2>  Finally, about the important - about cats and smiles </h2><br>  Since our goal is to go to the cat or to a smiling person, we will have to use something more complicated in our code.  We will also need cats and smiling people.  The second is now more difficult: few people smile at this difficult, alarming time.  So let's start with cats. <br><br>  For experiments, photos of cats in the face are suitable. <br><br>  Run the camera node in the 1st terminal: <br><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> /home/pi/rosbots_catkin_ws/src/rosbots_driver/scripts/rosbots_driver python pi_camera_driver.py</code> </pre> <br>  In the 2nd terminal, the motor node: <br><br><pre> <code class="bash hljs">rosrun rosbots_driver part2_cmr.py</code> </pre> <br>  In the 3rd terminal of the cat search node: <br><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> /home/pi/rosbots_catkin_ws/src/rosbots_driver/scripts/rosbots_driver python follow_cat2.py</code> </pre> <br>  The cart will gradually move to the cat: <br><br><img src="https://habrastorage.org/webt/xj/yr/fm/xjyrfmqyd4lw2gv_neuscw7aus0.png"><br><br>  Now you need a volunteer who knows how to smile.  Take a portrait of a little-known public figure in a small country. <br><br>  In the 3rd terminal of the cat‚Äôs search node, you can close - ctrl + c and instead of it start searching for a smile on the face of a little-known public person: <br><br><pre> <code class="bash hljs">python follow_smile.py</code> </pre> <br>  The cart will have to slowly, incredulously drive to the smile of a little-known person: <br><br><img src="https://habrastorage.org/webt/5z/01/tr/5z01tr6a1npd3gppcqotqn5item.png"><br><br>  As many may have already guessed, the scripts that we ran use Haar cascades.  By the same principle as with a trip along the line, a square of the desired area is highlighted and the program tries to keep it in the center by moving the robot. <br><br>  Unfortunately, the performance on raspberry 3b leaves much to be desired, despite the camera settings of 320x240 and 15 Fps.  Delays are noticeable with increasing time.  Not every cat can stand it. <br><br>  How can this be improved? <br><br>  Try rebuilding optimized opencv, as Adrian recommends (https://www.pyimagesearch.com/2017/10/09/optimizing-opencv-on-the-raspberry-pi/)?  Use external PC resources for image processing?  Try not to compress images in jpeg that fly to the Haar handler?  And one more big minus - cats should be big and in front.  15 cm spacing on A4 sheet.  When moving away from the camera, the cat is already unrecognizable and invulnerable.  Put raspberry monocle on camera with 8x magnification? <br><br>  PS: If you get your hands on experiments with the image that is given in the article, then you can still ride for different parts of the body, accordingly launching instead of the cat node: <br><br><pre> <code class="bash hljs">python follow_fullbody.py python follow_upperbody.py python follow_lowerbody.py</code> </pre><br>  face or eye: <br><br><pre> <code class="bash hljs">python follow_face.py python follow_right_eye.py</code> </pre> <br>  If there is interest in how to smoothly move away so that the robot does not spill tea, and also how to manage it not with raspberry itself, write. </div><p>Source: <a href="https://habr.com/ru/post/461131/">https://habr.com/ru/post/461131/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../461123/index.html">Welcome to the Medium Summer Meetup on August 3</a></li>
<li><a href="../461125/index.html">The task of creating sequential numeric codes for numbering messages in the source code in Visual Studio (ex. C #)</a></li>
<li><a href="../461127/index.html">VM performance analysis in VMware vSphere. Part 3: Storage</a></li>
<li><a href="../461129/index.html">About kote, wife, two sons, the idea ... and not only. Story with continuation</a></li>
<li><a href="../46113/index.html">20 million pages of history</a></li>
<li><a href="../461137/index.html">How we developed a device for monitoring the attention of drivers. Experience Yandex.Taxi</a></li>
<li><a href="../46114/index.html">Installing Linux from a virtual machine on a removable disk</a></li>
<li><a href="../461141/index.html">My first day with Haiku: she is unexpectedly good</a></li>
<li><a href="../461143/index.html">On current issues of game design and ways to resolve them. View from below</a></li>
<li><a href="../461145/index.html">What should a team lead: roles, responsibilities and skills</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>