<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Regular expression search with suffix array</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Back in January 2012, Russ Cox published a wonderful blog post explaining how Google Code Search works using the trigram index. 

 By this time, the f...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Regular expression search with suffix array</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/getpro/habr/post_images/f49/bb2/620/f49bb262046eed26721865e934005e06.png" alt="image"><br><br>  Back in January 2012, Russ Cox published a <a href="http://swtch.com/~rsc/regexp/regexp4.html">wonderful blog post</a> explaining how Google Code Search works using the trigram index. <br><br>  By this time, the first versions of my own source code search system called <a href="http://livegrep.com/">livegrep</a> , with a different indexing method, had already been released;  I wrote this system independently of Google, with the help of several friends.  In this article, I would like to present a slightly late explanation of the mechanism of its work. <br><a name="habracut"></a><br><h2>  <font color="#c75733">Suffix Arrays</font> </h2><br>  <a href="http://en.wikipedia.org/wiki/Suffix_array">Suffix array</a> is a data structure used for full-text search and for other applications, mainly in the field of bioinformatics. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      The concept of a suffix array is quite simple: it is a sorted array of all suffixes of a string.  So, for the string "here and there" <br><br><pre><code class="hljs">0 1 2 3 4 5 6 7 8 9 10     _  _    </code> </pre> <br>  we could build the following suffix array: <br><br> <code>  <br> 4 _   <br> 6 _  <br> 10  <br> 3    <br> 9  <br> 2    <br> 5   <br> 7  <br> 0    <br> 1    <br> 8 </code> <br> <br>  Note that there is no need to keep the suffix in each element of the array as a whole: you can store only the indices (left column) and the original row and, if necessary, search for the desired index in the row.  So this array will be stored as follows: <br><br><pre> <code class="go hljs">[<span class="hljs-number"><span class="hljs-number">4</span></span> <span class="hljs-number"><span class="hljs-number">6</span></span> <span class="hljs-number"><span class="hljs-number">10</span></span> <span class="hljs-number"><span class="hljs-number">3</span></span> <span class="hljs-number"><span class="hljs-number">9</span></span> <span class="hljs-number"><span class="hljs-number">2</span></span> <span class="hljs-number"><span class="hljs-number">5</span></span> <span class="hljs-number"><span class="hljs-number">7</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-number"><span class="hljs-number">8</span></span>]</code> </pre> <br>  <a href="http://en.wikipedia.org/wiki/Suffix_array">There are</a> algorithms that allow you to quickly build suffix arrays (in O (n) time) or convert the original array to suffix (using a constant amount of additional memory outside the array itself). <br><br><h3>  <font color="#c75733">Full-text search by substring</font> </h3><br>  One of the main applications of the suffix array is full-text search. <br><br>  If we are looking for a substring in the corpus of texts, then such a substring, if it exists, will be a prefix of some corpus suffix.  That is, if we build a suffix array, any hull substring must be the beginning of some element of the array.  For example, if we search for ‚Äúyes‚Äù in the ‚Äúto and fro‚Äù line, we will find that it appears twice in this line, and also that it starts with two lines in the array above. <br><br><pre> <code class="hljs">  2    9 </code> </pre><br>  But since the suffix array is sorted, we can quickly find these elements using the binary search method, and the indices will show us the place of the required substring in the source text. <br><br><h2>  <font color="#c75733">Towards a regular expression search</font> </h2><br>  Before you start searching by source code, let's learn how to use regular expressions. <br><br>  In the process of indexing, livegrep reads all sources and combines them into a huge buffer (livegrep builds a suffix array using the open library <a href="https://code.google.com/p/libdivsufsort/">libdivsufsort</a> ; older versions of livegrep used bitwise sorting (radix sort), which on some sets could have quadratic complexity - with the implementation of divsufsort build speed index increased significantly).  Then the so-called ‚Äúfile content map‚Äù is stored in memory - a sorted table of the form <code>( ,  ,   )</code> , which allows you to determine from which file certain bytes came to the buffer. <br><br>  (The mechanism is described simply, in fact, in livegrep, instead of one giant suffix array, several are used; in addition, we compress the input data by deduplicating identical strings, which complicates the file content map. We may consider these details in a future post). <br><br>  But how to apply this structure to quickly find matches for regular expressions? <br><br>  The first thing that comes to mind is the following idea: you can find literal substrings in a regular expression, find all such substrings in the suffix array, and then search for their location in the body. <br><br>  For example, take the regular expression <code>/hello.*world/</code> .  Obviously, all the required substrings will contain the word ‚Äúhello‚Äù, which means we can find all the strings with this word, and then check them with a regular expression. <br><br><h3>  <font color="#c75733">More complex search</font> </h3><br>  It turns out we can do better.  The structure of the suffix array is such that in addition to searching for a substring, you can perform at least two more basic queries on it: <br><br><ul><li>  Search by range: using binary search at both ends of the array, you can quickly find all occurrences from a range of characters.  If our range is <code>[AF]</code> , by binary search we find the first suffix starting at <code>A</code> and the last suffix starting at <code>F</code> , and, as we know, each element of the suffix array between them starts with a letter from the range between <code>A</code> and <code>F</code> <br><br></li><li>  Search chains: if there is a block of the suffix array, all elements have a common prefix, then the search can be narrowed down with the help of additional searches inside this block by the <i>next</i> character.  For example, if we search for <code>/hi(s|m)/</code> , we can find all the elements starting with <code>hi</code> , and we get a block of adjacent elements inside the array.  Since the elements inside the block are sorted, we can perform a couple more binary searches in this range, but now by the third character.  One search will look for <code>s</code> , the second - <code>m</code> , and in the end we get two smaller segments - for his and for him. </li></ul><br>  It is also possible to search for multiple items at once and combine the results.  For example, for the regular expression <code>/hello|world/</code> we will find matches for ‚Äúhello‚Äù separately, separately for ‚Äúworld‚Äù, and then we will look at the locations of both words in the text. <br><br>  In addition, we can apply a combination of all of these strategies.  For example, the search for the expression <code>/[af][0-9]/</code> will be performed as follows: <br><br><ol><li>  Binary search to find <code>af</code> </li><li>  Division into 6 blocks, one for <code>a, b, c, d, e</code> and <code>f</code> </li><li>  Inside each of the blocks, we perform a binary search on the second symbol and find those blocks where the second symbol belongs to the range <code>[0-9]</code> </li></ol><br><div class="spoiler">  <b class="spoiler_title">Example</b> <div class="spoiler_text">  one. <br>  ... <br>  A ... <br><br><br><br><br>  F ... <br>  ... <br>  2 <br>  ... <br>  A ... <br>  B ... <br>  C ... <br>  D ... <br>  E ... <br>  F ... <br>  ... <br>  3 <br>  ... <br>  A ... <br>  A [0-9] ... <br>  B ... <br>  B [0-9] ... <br>  C ... <br>  C [0-9] ... <br>  D ... <br>  D [0-9] ... <br>  E ... <br>  E [0-9] ... <br>  F ... <br>  F [0-9] ... <br>  ... <br></div></div><br>  As a result, we get a set of segments of the suffix array, whose elements indicate substrings corresponding to <code>/[AF][0-9]/</code> . <br><br>  This essentially means that responses to requests can have the following structure (in the Go language syntax): <br><br><pre> <code class="go hljs"><span class="hljs-keyword"><span class="hljs-keyword">type</span></span> IndexKey <span class="hljs-keyword"><span class="hljs-keyword">struct</span></span> { edges []<span class="hljs-keyword"><span class="hljs-keyword">struct</span></span> { min <span class="hljs-keyword"><span class="hljs-keyword">byte</span></span> max <span class="hljs-keyword"><span class="hljs-keyword">byte</span></span> next *IndexKey } }</code> </pre> <br>  In livegrep, <a href="">almost the same structure is</a> applied, with the exception of some additional fields that serve to analyze regular expressions. <br><br>  For each <code>edge</code> in the query, we find all suffixes starting with characters from this range, split the range into separate characters, and then recursively evaluate <code>next</code> and delve into the suffix by one character. <br><br>  Livegrep parses the regular expression and finds the <code>IndexKey</code> with the following property: any substring corresponding to the regular expression must match this <code>IndexKey</code> . <br><br>  In many cases, this is simple: a class of characters is easily converted into a set of ranges, an alphabetic string is a linear key chain of an <code>IndexKey</code> with ranges of one character, and so on.  Everything gets complicated when we see repetition or disjunction operators (|).  I hope to write about this in more detail in a future post, but for now, if you're curious, you can read <a href="">indexer.cc</a> or experiment with <a href="">analyze-re</a> , which has a <code>dot</code> output mode showing the result of a livegrep analysis. <br><br><h3>  <font color="#c75733">Application of results</font> </h3><br>  Passing through the suffix array in the manner described above, we get (possibly a very large) set of indices in the body that we need to find.  Instead of searching each one separately, livegrep takes all the matches and sorts them into memory.  When we go through the ordered list, and find several matches close to each other, we apply one regular expression to the entire segment at once. <br><br>  Livegrep matches regular expressions using Russ Cox's own <a href="https://code.google.com/p/re2/">RE2</a> library.  <code>RE2</code> not only works fast enough, but, unlike PCRE or most other libraries for working with regular expressions, converts a regular expression into a finite state machine, performing the task in guaranteed linear time. <br><br>  By grouping the found matches, we use the speed of RE2 to simultaneously process large chunks of text, which allows us not to manage queries at a low level and not to store a lot of redundant information. <br><br>  To determine the search range around a potential match, recall what the livegrep looks for in source code lines: we can use a simple <code>memchr</code> to find the nearest newline characters, and find exactly which line of code can contain the search expression. <br><br>  After we run <code>RE2</code> over all positions containing potential matches, we get the final list of matches found in the package.  For each match, using the file content map mentioned above, we find a file containing these bytes.  To determine the line number, pull out the entire contents of the file and count the line break characters. <br><br>  If we limit the search to a specific file (for example, <code>file:foo\.c</code> ), we go through the file content map at the same time as the list of results after passing through the indices, and remove records from it if the file containing them does not match the file from the query. <br><br>  An interesting feature of this approach is that the restriction on the file name actually reduces the search area slightly - the livegrep still goes through the entire suffix array and still considers every match found (although it could check the file content map much faster and not call RE2 ).  However, Livegrep is so productive that it does not have to take advantage of the restriction on the file name in order to produce results quickly - so it needs to be in order to be able to process requests without specifying a specific file. <br><br>  From this it follows that livegrep will process most slowly those requests that strictly limit the path to the file and at the same time inefficiently use the suffix array:.  <code>. file:zzzz</code> is probably one of the slowest requests to send to livegrep for today. <br><br><h2>  <font color="#c75733">To be continued</font> </h2><br>  We reviewed livegrep work only in general terms.  Next time, I‚Äôll tell you in more detail how we build the index query and transform the regular expression into the index query, and then I finally tell you how the suffix array and file-content structures work in livegrep compared to the simplified version described here.  In particular, livegrep actually significantly compresses the input data, which reduces memory consumption and speeds up the search, at the cost of complicating the construction of the index and the processing of results. <br><br><blockquote><div class="spoiler">  <b class="spoiler_title">Oh, and come to work with us?</b>  <b class="spoiler_title">:)</b> <div class="spoiler_text">  <a href="http://wunderfund.io/"><b>wunderfund.io</b></a> is a young foundation that deals with <a href="https://en.wikipedia.org/wiki/High-frequency_trading">high-frequency algorithmic trading</a> .  High-frequency trading is a continuous competition of the best programmers and mathematicians of the whole world.  By joining us, you will become part of this fascinating fight. <br><br>  We offer interesting and challenging data analysis and low latency tasks for enthusiastic researchers and programmers.  Flexible schedule and no bureaucracy, decisions are quickly made and implemented. <br><br>  Join our team: <a href="http://wunderfund.io/">wunderfund.io</a> </div></div></blockquote></div><p>Source: <a href="https://habr.com/ru/post/325036/">https://habr.com/ru/post/325036/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../325026/index.html">Infrastructure organization with the help of Kubernetes and Helm. Video recordings of reports from Kubernetes meetup March 22, 2017</a></li>
<li><a href="../325028/index.html">Web Scrolling: Primer</a></li>
<li><a href="../325030/index.html">7 questions that you ask at the interview for the position of UX designer</a></li>
<li><a href="../325032/index.html">How shops lure customers: electronic price tags</a></li>
<li><a href="../325034/index.html">IL2CPP: Garbage Collector Integration</a></li>
<li><a href="../325040/index.html">Good trigger, bad trigger: how we monitor hundreds of servers around the world</a></li>
<li><a href="../325042/index.html">Welcome to Go meetup April 14</a></li>
<li><a href="../325046/index.html">What would i change in go</a></li>
<li><a href="../325050/index.html">Digest AI Cup. Five strategies for Code Wizards 2016</a></li>
<li><a href="../325052/index.html">Technocup: results of the final round and task analysis</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>