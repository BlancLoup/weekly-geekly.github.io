<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>How to get started in Kaggle: a guide for beginners in Data Science</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Good day, dear habrovchane! Today I would like to talk about how, without having special experience in machine learning, you can try your hand at comp...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>How to get started in Kaggle: a guide for beginners in Data Science</h1><div class="post__text post__text-html js-mediator-article">  Good day, dear habrovchane!  Today I would like to talk about how, without having special experience in machine learning, you can try your hand at competitions held by <a href="http://www.kaggle.com/">Kaggle</a> . <br><br><img src="https://habrastorage.org/files/0eb/4ea/4bc/0eb4ea4bc8174cf8845fd5aca2cb1fc6.png" alt="image"><br><br>  As you probably already know, Kaggle is a platform for researchers at various levels, where they can try out their data analysis models for serious and relevant tasks.  The essence of such a resource is not only the ability to get a good cash prize if it is your model that turns out to be the best, but also (and this is probably more important) to gain experience and become a specialist in data analysis and machine learning. .  After all, the most important question often faced by such specialists is where to find real tasks?  Here they are enough. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      We will try to participate in a training competition that does not provide any incentives other than experience. <br><a name="habracut"></a><br>  To do this, I chose the problem of recognizing handwritten numbers from a <a href="http://www.kaggle.com/c/digit-recognizer">sample of MNIST</a> .  Some information from the <a href="http://en.wikipedia.org/wiki/MNIST_database">wiki</a> .  The MNIST (Mixed National Institute of Standards and Technology database) is the main base for testing image recognition systems, and is also widely used for teaching and testing machine learning algorithms.  It was created by rearranging images from the original NIST database, which was difficult enough to recognize.  In addition, certain transformations were performed (the images were normalized and smoothed to obtain gray gradations). <br><br>  The MNIST database consists of 60,000 images for learning and 10,000 images for testing.  A large number of articles were written on the MNIST recognition problem, <a href="http://people.idsia.ch/~juergen/cvpr2012.pdf">for example</a> (in this case, the authors used a hierarchical system of convolutional neural networks). <br><br>  The original sample is presented on the <a href="http://yann.lecun.com/exdb/mnist/">site</a> . <br><br>  Kaggle features a complete MNIST sample, organized a little differently.  Here, the training sample includes 42,000 images, and the test sample includes 28,000 images. However, they are equivalent in content.  Each MNIST image is represented by a 28X28 pixel image with 256 shades of gray.  An example of several ambiguous identifying numbers is shown in the picture below. <br><br><img src="https://habrastorage.org/files/26c/5f3/05b/26c5f305bbf24a7a806e21c6633cff24.jpg" alt="image"><br><br>  To create our own neural network model for digit recognition, we use the <a href="https://www.python.org/">Python</a> interpreter with the installed <a href="https://pythonhosted.org/nolearn/">nolearn 0.4</a> package, as well as numpy and scipy (to satisfy all dependencies). <br><br>  Here the introductory article written by Adrian Rosebrock in my <a href="http://www.pyimagesearch.com/2014/09/22/getting-started-deep-learning-python/">blog</a> helped me a lot.  It provides introductory information about neural networks of deep trust and their learning, although the author himself uses the usual multi-layered perceptron of the architecture 784-300-10 without any training before testing.  So do we.  By the way, the process of using the package on the <a href="https://pythonhosted.org/nolearn/dbn.html">nolearn</a> page is considered in great detail and by the example of various classical samples. <br><br>  So, following the instructions given in the above-mentioned articles, we will create our multi-layer perceptron, train it on the loaded and processed data, and then we will carry out testing. <br><br>  To begin with, let's create our double-layer perceptron of architecture 784-300-10: <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> nolearn.dbn <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> DBN net = DBN( [<span class="hljs-number"><span class="hljs-number">784</span></span>, <span class="hljs-number"><span class="hljs-number">300</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>], learn_rates=<span class="hljs-number"><span class="hljs-number">0.3</span></span>, learn_rate_decays=<span class="hljs-number"><span class="hljs-number">0.9</span></span>, epochs=<span class="hljs-number"><span class="hljs-number">10</span></span>, verbose=<span class="hljs-number"><span class="hljs-number">1</span></span>, )</code> </pre> <br>  This requires some explanation.  The first parameter of the neural network constructor is a list containing the number of inputs and neurons in each layer, <b>learn_rates</b> ‚Äî learning rate, <b>learn_rate_decays</b> ‚Äî a multiplier setting the change in learning rate after each epoch, <b>epochs</b> ‚Äî number of learning epochs, <b>verbose</b> ‚Äî output flag of a detailed report of the learning process. <br><br>  After executing this instruction, the required model will be created and we will only have to load the data.  Kaggle provides us with two files: <b>train.csv</b> and <b>test.csv</b> , containing samples for training and testing, respectively.  The file structure is simple - the first line contains the header, followed by the data.  For train.csv, each line with data is preceded by a corresponding label - a digit from 0 to 9, which defines the image.  There is no label in test.csv. <br><br>  The next step is to load the data into the arrays using the package for working with csv-files.  Do not forget to normalize: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> csv <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> open(<span class="hljs-string"><span class="hljs-string">'D:\\train.csv'</span></span>, <span class="hljs-string"><span class="hljs-string">'rb'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: data = list(csv.reader(f)) train_data = np.array(data[<span class="hljs-number"><span class="hljs-number">1</span></span>:]) labels = train_data[:, <span class="hljs-number"><span class="hljs-number">0</span></span>].astype(<span class="hljs-string"><span class="hljs-string">'float'</span></span>) train_data = train_data[:, <span class="hljs-number"><span class="hljs-number">1</span></span>:].astype(<span class="hljs-string"><span class="hljs-string">'float'</span></span>) / <span class="hljs-number"><span class="hljs-number">255.0</span></span></code> </pre><br>  After that we train our neural network on the prepared data: <br><br><pre> <code class="python hljs">net.fit(train_data, labels)</code> </pre><br>  The process itself takes some time, determined by the number of learning epochs specified in the construction of a neural network.  At each training epoch, the values ‚Äã‚Äãof loss and err (the value of the loss function and error) will be displayed (for a given verbose parameter). <br><br><img src="https://habrastorage.org/files/b5d/ccb/b2f/b5dccbb2f8fd4debb24628ffd045fdba.png" alt="image"><br><br>  After learning, all we have to do is to load the test data and save the predictions for each image from the test sample to a file with a csv extension: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">with</span></span> open(<span class="hljs-string"><span class="hljs-string">'D:\\test.csv'</span></span>, <span class="hljs-string"><span class="hljs-string">'rb'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: data = list(csv.reader(f)) test_data = np.array(data[<span class="hljs-number"><span class="hljs-number">1</span></span>:]).astype(<span class="hljs-string"><span class="hljs-string">'float'</span></span>) / <span class="hljs-number"><span class="hljs-number">255.0</span></span> preds = net.predict(test_data) <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> open(<span class="hljs-string"><span class="hljs-string">'D:\\submission.csv'</span></span>, <span class="hljs-string"><span class="hljs-string">'wb'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: fieldnames = [<span class="hljs-string"><span class="hljs-string">'ImageId'</span></span>, <span class="hljs-string"><span class="hljs-string">'Label'</span></span>] writer = csv.DictWriter(f, fieldnames=fieldnames) writer.writeheader() i = <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> elem <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> preds: writer.writerow({<span class="hljs-string"><span class="hljs-string">'ImageId'</span></span>: i, <span class="hljs-string"><span class="hljs-string">'Label'</span></span>: elem}) i += <span class="hljs-number"><span class="hljs-number">1</span></span></code> </pre><br>  Next, load the resulting file into the testing system (see figure) and wait. <br><br><img src="https://habrastorage.org/files/b45/ff3/d83/b45ff3d83e86426b8f8d97b5e890ecd5.png" alt="image"><br><br>  Done!  176 place out of more than 500 participants.  For a start, quite good.  Now we can try to improve the result obtained, for example, by applying our own developments or modifying and selecting parameters in nolearn.  The benefit of time is enough: the MNIST competition has been repeatedly extended and now it will run until 12/31/2015.  Good luck and thank you for reading this article. </div><p>Source: <a href="https://habr.com/ru/post/248395/">https://habr.com/ru/post/248395/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../248383/index.html">Gnuplot on homepage</a></li>
<li><a href="../248385/index.html">Named Function Arguments in C</a></li>
<li><a href="../248387/index.html">OAuth using JWT on salesforce</a></li>
<li><a href="../248391/index.html">Fighting 2D physics in Unity with the example of an endless game</a></li>
<li><a href="../248393/index.html">Another program PWM or rehabilitation Attiny13a with Zen</a></li>
<li><a href="../248397/index.html">It's time to replace Python as a language for learning.</a></li>
<li><a href="../248399/index.html">Maker - Your DIY Intel Product Guide</a></li>
<li><a href="../248401/index.html">Forewarned is forearmed. Part 2</a></li>
<li><a href="../248403/index.html">Forewarned is forearmed. Part 3</a></li>
<li><a href="../248405/index.html">Forewarned is forearmed. Part 1</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>