<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Parallel programming in Python using multiprocessing and shared array</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Introduction 
 Python is a great language. A bunch of Python + NumPy + Matplotlib, in my opinion, is now one of the best for scientific calculations a...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Parallel programming in Python using multiprocessing and shared array</h1><div class="post__text post__text-html js-mediator-article"><h4>  Introduction </h4><br>  Python is a great language.  A bunch of Python + NumPy + Matplotlib, in my opinion, is now one of the best for scientific calculations and fast prototyping algorithms.  But each instrument has its own light and dark sides.  One of the most discussed features of Python is GIL - Global Interpreter Lock.  I would attribute this feature to the dark side of the instrument.  Although many will disagree with me. <br><br>  In short, GIL does not allow more than one stream to be used effectively in a single Python interpreter.  GIL advocates claim that single-threaded programs with GIL are much more efficient.  But the presence of GIL means that parallel computing using multiple threads and shared memory is not possible.  And this is quite a strong limitation in the modern multi-core world. <br><br>  One of the ways to overcome GIL using threads in C ++ was recently reviewed in the article: <a href="http://habrahabr.ru/post/167261/">Using Python in a multi-threaded C ++ application</a> .  I want to consider another way to overcome the limitations of GIL, based on multiprocessing and shared array.  In my opinion, this method allows using processes and shared memory for transparent parallel programming in the style of multiple threads and shared memory quite simply and efficiently. <br><a name="habracut"></a><br><h4>  Task. </h4><br>  As an example, consider the following problem.  In the three-dimensional space, N points v0, v1, ..., vN are given.  It is required for each pair of points to calculate a function depending on the distance between them.  The result will be an NxN matrix with the values ‚Äã‚Äãof this function.  As a function, we take the following: f = r ^ 3/12 + r ^ 2 / 6. This test, in fact, is not so synthetic.  RBF interpolation, which is used in many areas of computational mathematics, is based on calculating such functions of distance. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h4>  Parallelization method. </h4><br><img src="https://habrastorage.org/getpro/habr/post_images/9bb/d1f/ac0/9bbd1fac0d10daaf008fc63654d24d2a.png" alt="image"><br>  In this problem, each row of the matrix can be calculated independently.  For every few rows of the matrix, we will form independent works and place them in the task queue (see fig. 1).  Run some processes.  Each process will take the next task from the queue for execution until it encounters a special task with the ‚Äúend‚Äù code.  In this case, the process ends its work. <br><br><h4>  Implementation in Python. </h4><br>  In the Python implementation, we will have two main methods: mpCalcDistance (nodes) and <br>  mpCalcDistance_Worker (nodes, queue, arrD).  The mpCalcDistance (nodes) method takes as input a list of nodes, creates a shared memory area, prepares a job queue, and starts processes.  The mpCalcDistance_Worker method (nodes, queue, arrD) is a computational method that runs in its own thread.  It takes as input a list of nodes, a job queue, and a shared memory area.  Consider the implementation of these methods in more detail. <br><br><h5>  Method mpCalcDistance (nodes) </h5><br>  Create a shared memory area: <br><pre><code class="python hljs">nP = nodes.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>] nQ = nodes.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>] arrD = mp.RawArray(ctypes.c_double, nP * nQ)</code> </pre> <br>  Create a job queue.  Each task is nothing but a simple range of rows of the matrix.  The special value None is a sign of the completion of the process: <br><pre> <code class="python hljs"> nCPU = <span class="hljs-number"><span class="hljs-number">2</span></span> nJobs = nCPU * <span class="hljs-number"><span class="hljs-number">36</span></span> q = nP / nJobs r = nP % nJobs jobs = [] firstRow = <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(nJobs): rowsInJob = q <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (r &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>): rowsInJob += <span class="hljs-number"><span class="hljs-number">1</span></span> r -= <span class="hljs-number"><span class="hljs-number">1</span></span> jobs.append((firstRow, rowsInJob)) firstRow += rowsInJob queue = mp.JoinableQueue() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> job <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> jobs: queue.put(job) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(nCPU): queue.put(<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>)</code> </pre><br>  We create processes and wait until the queue of tasks ends: <br><pre> <code class="python hljs"> workers = [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(nCPU): worker = mp.Process(target = mpCalcDistance_Worker, args = (nodes, queue, arrD)) workers.append(worker) worker.start() queue.join()</code> </pre><br>  From the area of ‚Äã‚Äãshared memory form a matrix with the results: <br><pre> <code class="python hljs"> D = np.reshape(np.frombuffer(arrD), (nP, nQ)) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> D</code> </pre><br><br><h5>  Method mpCalcDistance_Worker (nodes, queue, arrD) </h5><br>  Wrap the shared memory area in the matrix: <br><pre> <code class="python hljs"> nP = nodes.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>] nQ = nodes.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>] D = np.reshape(np.frombuffer(arrD), (nP, nQ))</code> </pre><br>  Until the queue of tasks is over, we take the following task from the queue and perform the calculation: <br><pre> <code class="python hljs"> <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> <span class="hljs-keyword"><span class="hljs-keyword">True</span></span>: job = queue.get() <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> job == <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">break</span></span> start = job[<span class="hljs-number"><span class="hljs-number">0</span></span>] stop = job[<span class="hljs-number"><span class="hljs-number">0</span></span>] + job[<span class="hljs-number"><span class="hljs-number">1</span></span>] <span class="hljs-comment"><span class="hljs-comment"># components of the distance vector p = nodes[start:stop] q = nodes.T Rx = p[:, 0:1] - q[0:1] Ry = p[:, 1:2] - q[1:2] Rz = p[:, 2:3] - q[2:3] # calculate function of the distance L = np.sqrt(Rx * Rx + Ry * Ry + Rz * Rz) D[start:stop, :] = L * L * L / 12 + L * L / 6 queue.task_done()</span></span></code> </pre><br><br><h4>  results </h4><br>  Runtime: dual-core processor, Ubuntu 12.04, 64bit. <br><img src="https://habrastorage.org/getpro/habr/post_images/31c/51b/0d5/31c51b0d57a9a4b7679622f8d5a0d921.png" alt="image"><br><img src="https://habrastorage.org/getpro/habr/post_images/449/e82/703/449e827032b85f6aa57149c26f97d19e.png" alt="image"><br>  The first picture shows the times of single-stream and two-stream calculations for different N. The second picture shows the ratio of single-stream to double-stream calculations.  It can be seen that starting from N = 500, we already receive a significant acceleration of the calculation. <br><br>  A very interesting result is obtained in the region of the number N = 2000. In the single-threaded version, we get a noticeable jump in the calculation time, and in a multi-threaded calculation, the acceleration factor even exceeds 2. I explain this with the cache effect.  In a multi-threaded version, the data for each task is completely cached.  And in the one-threaded no longer. <br><br>  So the use of processes and shared memory, in my opinion, simply allows you to bypass the limitations of GIL. <br><br>  Full code of the whole script: <br><pre> <code class="python hljs"><span class="hljs-string"><span class="hljs-string">""" Python multiprocessing with shared memory example. This example demonstrate workaround for the GIL problem. Workaround uses processes instead of threads and RawArray allocated from shared memory. See also: [1] http://docs.python.org/2/library/multiprocessing.html [2] http://folk.uio.no/sturlamo/python/multiprocessing-tutorial.pdf [3] http://www.bryceboe.com/2011/01/28/the-python-multiprocessing-queue-and-large-objects/ """</span></span> <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> time <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> ctypes <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> multiprocessing <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> mp <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.pyplot <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> plt <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">generateNodes</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(N)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">""" Generate random 3D nodes """</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> np.random.rand(N, <span class="hljs-number"><span class="hljs-number">3</span></span>) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">spCalcDistance</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(nodes)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">""" Single process calculation of the distance function. """</span></span> p = nodes q = nodes.T <span class="hljs-comment"><span class="hljs-comment"># components of the distance vector Rx = p[:, 0:1] - q[0:1] Ry = p[:, 1:2] - q[1:2] Rz = p[:, 2:3] - q[2:3] # calculate function of the distance L = np.sqrt(Rx * Rx + Ry * Ry + Rz * Rz) D = L * L * L / 12 + L * L / 6 return D def mpCalcDistance_Worker(nodes, queue, arrD): """ Worker process for the multiprocessing calculations """ nP = nodes.shape[0] nQ = nodes.shape[0] D = np.reshape(np.frombuffer(arrD), (nP, nQ)) while True: job = queue.get() if job == None: break start = job[0] stop = job[0] + job[1] # components of the distance vector p = nodes[start:stop] q = nodes.T Rx = p[:, 0:1] - q[0:1] Ry = p[:, 1:2] - q[1:2] Rz = p[:, 2:3] - q[2:3] # calculate function of the distance L = np.sqrt(Rx * Rx + Ry * Ry + Rz * Rz) D[start:stop, :] = L * L * L / 12 + L * L / 6 queue.task_done() queue.task_done() def mpCalcDistance(nodes): """ Multiple processes calculation of the distance function. """ # allocate shared array nP = nodes.shape[0] nQ = nodes.shape[0] arrD = mp.RawArray(ctypes.c_double, nP * nQ) # setup jobs #nCPU = mp.cpu_count() nCPU = 2 nJobs = nCPU * 36 q = nP / nJobs r = nP % nJobs jobs = [] firstRow = 0 for i in range(nJobs): rowsInJob = q if (r &gt; 0): rowsInJob += 1 r -= 1 jobs.append((firstRow, rowsInJob)) firstRow += rowsInJob queue = mp.JoinableQueue() for job in jobs: queue.put(job) for i in range(nCPU): queue.put(None) # run workers workers = [] for i in range(nCPU): worker = mp.Process(target = mpCalcDistance_Worker, args = (nodes, queue, arrD)) workers.append(worker) worker.start() queue.join() # make array from shared memory D = np.reshape(np.frombuffer(arrD), (nP, nQ)) return D def compareTimes(): """ Compare execution time single processing versus multiple processing. """ nodes = generateNodes(3000) t0 = time.time() spD = spCalcDistance(nodes) t1 = time.time() print "single process time: {:.3f} s.".format(t1 - t0) t0 = time.time() mpD = mpCalcDistance(nodes) t1 = time.time() print "multiple processes time: {:.3f} s.".format(t1 - t0) err = np.linalg.norm(mpD - spD) print "calculate error: {:.2e}".format(err) def showTimePlot(): """ Generate execution time plot single processing versus multiple processing. """ N = range(100, 4000, 4) spTimes = [] mpTimes = [] rates = [] for i in N: print i nodes = generateNodes(i) t0 = time.time() spD = spCalcDistance(nodes) t1 = time.time() sp_tt = t1 - t0 spTimes.append(sp_tt) t0 = time.time() mpD = mpCalcDistance(nodes) t1 = time.time() mp_tt = t1 - t0 mpTimes.append(mp_tt) rates.append(sp_tt / mp_tt) plt.figure() plt.plot(N, spTimes) plt.plot(N, mpTimes) plt.xlabel("N") plt.ylabel("Execution time") plt.figure() plt.plot(N, rates) plt.xlabel("N") plt.ylabel("Rate") plt.show() def main(): compareTimes() #showTimePlot() if __name__ == '__main__': main()</span></span></code> </pre></div><p>Source: <a href="https://habr.com/ru/post/167503/">https://habr.com/ru/post/167503/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../167493/index.html">Amazon Elastic Transcoder</a></li>
<li><a href="../167495/index.html">Google added North Korea and its "sights" to Maps</a></li>
<li><a href="../167497/index.html">Full-text search: how it is done in Mail.Ru Mail</a></li>
<li><a href="../167499/index.html">Sublime text 3 beta released</a></li>
<li><a href="../167501/index.html">Google glasses are banned in Ukraine</a></li>
<li><a href="../167507/index.html">Automatic calculation of column width</a></li>
<li><a href="../167509/index.html">Making a simple game with buttons, drawers and doors on Unity</a></li>
<li><a href="../167511/index.html">The first award in the new year and new applications</a></li>
<li><a href="../167515/index.html">Install Redmine 2.2.2 + Passenger on FreeBSD 9.1</a></li>
<li><a href="../167519/index.html">Hero H9500 + (OEM Zopo zp900) - a large smartphone at a low price</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>