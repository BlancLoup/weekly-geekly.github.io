<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Sequence-to-Sequence Part 1 models</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Good day everyone! 

 And we have again opened a new stream for the refined ‚ÄúData Scientist‚Äù course: another excellent teacher , a little refined, bas...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Sequence-to-Sequence Part 1 models</h1><div class="post__text post__text-html js-mediator-article">  Good day everyone! <br><br>  And we have again opened a new stream for the refined <a href="https://otus.pw/LlGz/">‚ÄúData Scientist‚Äù</a> course: another <a href="https://otus.pw/lH7g/">excellent teacher</a> , a little refined, based on the updates of the program.  Well, as usual interesting <a href="https://otus.pw/5Hen/">open lessons</a> and collections of interesting materials.  Today we will begin the analysis of seq2seq models from Tensor Flow. <br><br>  Go. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      As already discussed in the <a href="https://www.tensorflow.org/tutorials/sequences/recurrent">RNN tutorial</a> (we recommend reading it before reading this article), recurrent neural networks can be taught to model a language.  And an interesting question arises: is it possible to train the network on certain data to generate a meaningful answer?  For example, can we teach a neural network to translate from English to French?  It turns out that we can. <br><br>  This guide will show you how to create and train such an end-to-end system.  Copy the <a href="https://github.com/tensorflow/tensorflow">main Tensor Flow</a> <a href="https://github.com/tensorflow/models">repository</a> and <a href="https://github.com/tensorflow/models">the TensorFlow model repository from GitHub</a> .  Then, you can start by running the translation program: <br><br><pre><code class="python hljs">cd models/tutorials/rnn/translate python translate.py --data_dir [your_data_directory]</code> </pre> <br><img src="https://habrastorage.org/webt/ra/j0/rr/raj0rraitsp6itojzydkhrk2yoi.png"><a name="habracut"></a><br><br>  She will download the data for translation from English to French from <a href="http://www.statmt.org/wmt15/translation-task.html">the WMT'15 website</a> , prepare it for training and train.  This will require about 20 GB of hard disk space and quite a lot of time for downloading and preparation, so you can start the process now and continue reading this tutorial. <br><br>  The manual will refer to the following files: <br><br><table><tbody><tr><th>  File </th><th>  What is in it? </th></tr><tr><td>  tensorflow / tensorflow / python / ops / seq2seq.py </td><td>  Library for creating sequence-to-sequence models </td></tr><tr><td>  models / tutorials / rnn / translate / seq2seq_model.py </td><td>  Sequence-to-sequence model of neural translation </td></tr><tr><td>  models / tutorials / rnn / translate / data_utils.py </td><td>  Auxiliary functions for preparing translation data </td></tr><tr><td>  models / tutorials / rnn / translate / translate.py </td><td>  A binary that trains and runs a translation model </td></tr></tbody></table><br>  <b>The basics of sequence-to-sequence</b> <br><br>  The basic sequence-to-sequence model, as presented by <a href="">Cho et al., 2014</a> ( <a href="http://arxiv.org/pdf/1406.1078.pdf">pdf</a> ), consists of two recurrent neural networks (RNN): an encoder, which processes input data, and a decoder (decoder), which generates data output.  The basic architecture is shown below: <br><br><img src="https://habrastorage.org/webt/e-/df/cu/e-dfcuvlsbykvyxvzac9rc0nrow.png"><br><br>  Each box in the picture above represents a cell in the RNN, usually a GRU cell - a managed recurrent block, or an LSTM cell - a long short-term memory (read the <a href="https://www.tensorflow.org/versions/r1.2/tutorials/recurrent">RNN tutorial</a> for more details).  Encoders and decoders can have common weights or, more often, use different sets of parameters.  Multi-layered cells have been used successfully in sequence-to-sequence models, for example, to translate <a href="">Sutskever et al., 2014</a> ( <a href="http://arxiv.org/pdf/1409.3215.pdf">pdf</a> ). <br><br>  In the base model described above, each input must be encoded in a state of a fixed-size state, since this is the only thing that is transmitted to the decoder.  In order to give the decoder more direct access to input data, attention mechanism was introduced in <a href="">Bahdanau et al., 2014</a> ( <a href="http://arxiv.org/pdf/1409.0473.pdf">pdf</a> ).  We will not go into the details of the mechanism of attention (for this you can get acquainted with the work on the link);  suffice it to say that it allows the decoder to look into the input data at each decoding step.  A multi-layered sequence-to-sequence network with LSTM cells and the attentional mechanism in the decoder is as follows: <br><br><img src="https://habrastorage.org/webt/c4/ro/0z/c4ro0zvzu8m-y4qjlnfbhv9x4qa.png"><br><br>  <b>TensorFlow library seq2seq</b> <br><br>  As you can see above, there are different sequence-to-sequence models.  All of them can use different RNN cells, but all of them accept encoder input data and decoder input data.  This is the basis of the TensorFlow seq2seq library interface (tensorflow / tensorflow / python / ops / seq2seq.py).  This basic, RNN, codec, sequence-to-sequence model works as follows. <br><br><pre> <code class="python hljs">outputs, states = basic_rnn_seq2seq(encoder_inputs, decoder_inputs, cell)</code> </pre> <br>  In the call above, <code>encoder_inputs</code> is a list of tensors representing encoder input data, corresponding to the letters A, B, C from the image above.  Similarly, <code>decoder_inputs</code> are tensors representing decoder input data.  GO, W, X, Y, Z from the first picture. <br><br>  The <code>cell</code> argument is an instance of the <code>tf.contrib.rnn.RNNCell</code> class, which determines which cell will be used in the model.  You can use existing cells, for example, <code>GRUCell</code> or <code>LSTMCell</code> , or you can write your own.  In addition, <code>tf.contrib.rnn</code> provides a shell for creating layered cells, adding exceptions to cell input and output data, or other transformations.  Read the <a href="https://www.tensorflow.org/versions/r1.2/tutorials/recurrent">RNN Tutorial</a> for examples. <br><br>  Calling <code>basic_rnn_seq2seq</code> returns two arguments: <code>outputs</code> and <code>states</code> .  They both represent a list of tensors of the same length as <code>decoder_inputs</code> .  <code>outputs</code> corresponds to the output of the decoder at each time step, the first picture is W, X, Y, Z, EOS.  The returned <code>states</code> represents the internal state of the decoder at each time step. <br><br>  In many applications using the model's sequence-to-sequence, the decoder output at time t is transmitted back to input to the decoder at time t + 1.  When testing, during the decoding sequence, this is how a new one is constructed.  On the other hand, during training, it is customary to transmit to the decoder correct input data at each time step, even if the decoder was previously mistaken.  Functions in <code>seq2seq.py</code> support both modes with the <code>feed_previous</code> argument.  For example, analyze the following use of the nested RNN model. <br><br><pre> <code class="python hljs">outputs, states = embedding_rnn_seq2seq( encoder_inputs, decoder_inputs, cell, num_encoder_symbols, num_decoder_symbols, embedding_size, output_projection=<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>, feed_previous=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>)</code> </pre> <br>  In the <code>embedding_rnn_seq2seq</code> model, all input data (both <code>encoder_inputs</code> and <code>decoder_inputs</code> ) are integer tensors reflecting discrete values.  They will be embedded in a solid representation (for details on the attachment, refer to the <a href="https://www.tensorflow.org/versions/r1.2/tutorials/word2vec">Vector Representation Guide</a> ), but to create these attachments, you need to specify the maximum number of discrete characters: <code>num_encoder_symbols</code> on the coder side and <code>num_decoder_symbols</code> on the decoder side. <br><br>  In the call above, we set <code>feed_previous</code> to False.  This means that the decoder will use the <code>decoder_inputs</code> tensors as they are provided.  If we set <code>feed_previous</code> to True, the decoder will use only the first <code>decoder_inputs</code> element.  All other tensors from the list will be ignored, and the previous value of the decoder output will be used instead.  This is used to decode translations in our translation model, but can also be used during training, to improve the model‚Äôs resistance to its errors.  Approximately like <a href="http://arxiv.org/abs/1506.03099">Bengio et al., 2015</a> ( <a href="http://arxiv.org/pdf/1506.03099.pdf">pdf</a> ). <br><br>  Another important argument used above is <code>output_projection</code> .  Without clarification, the conclusions of the nested model will be the form tensors of the number of training samples on <code>num_decoder_symbols</code> , since they represent the logits of each generated symbol.  When training models with large dictionaries at the output, for example, with large <code>num_decoder_symbols</code> , storing these large tensors becomes impractical.  Instead, it is better to return smaller tensors, which will subsequently be projected onto a large tensor using <code>output_projection</code> .  This allows us to use our seq2seq models with sampled softmax losses, as described by <a href="">Jean et.</a>  <a href="">al., 2014</a> ( <a href="http://arxiv.org/pdf/1412.2007.pdf">pdf</a> ). <br><br>  In addition to the <code>basic_rnn_seq2seq</code> and <code>embedding_rnn_seq2seq</code> in <code>seq2seq.py</code> there are several more sequence-to-sequence models.  Pay attention to them.  All of them have a similar interface, so we will not go into their details.  For our translation model below, we use <code>embedding_attention_seq2seq</code> . <br><br>  Continuation will follow. </div><p>Source: <a href="https://habr.com/ru/post/430780/">https://habr.com/ru/post/430780/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../430768/index.html">Interview with ADOM creator Thomas Biscap</a></li>
<li><a href="../430770/index.html">Backup for Linux, or how to create snapshot</a></li>
<li><a href="../430774/index.html">Are you ready for AI in billboards?</a></li>
<li><a href="../430776/index.html">Check out the PI - the only way</a></li>
<li><a href="../430778/index.html">End-to-end process of designing electrical systems based on 3DEXPERIENCE</a></li>
<li><a href="../430784/index.html">From junior to director: one security officer</a></li>
<li><a href="../430788/index.html">My story of an interview at IB IT (Java developer, investment bank) in London with examples of typical tasks</a></li>
<li><a href="../430790/index.html">Ledger Nano S: key to the room where 710 tokens and cryptocurrencies can lie</a></li>
<li><a href="../430792/index.html">Creating an outline for LWRP in Unity</a></li>
<li><a href="../430794/index.html">Tale of coursework</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>