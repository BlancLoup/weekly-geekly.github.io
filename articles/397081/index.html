<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Revolution AI 101</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="This article examines the current state of development of artificial intelligence, examines the challenges and threats, as well as the peculiarities o...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Revolution AI 101</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/files/f23/30e/68d/f2330e68dba744afa58a403ff00e64ce.gif"><br><br>  This article examines the current state of development of artificial intelligence, examines the challenges and threats, as well as the peculiarities of the work of the most recognized scientists, and describes the main predictions of how AI can appear to us.  In general, this is a revised and abbreviated version of a two-part essay written by Tim Urban for ‚Äú <a href="http://waitbutwhy.com/2015/01/artificial-intelligence-revolution-1.html">Wait But Why</a> ‚Äù. <br><a name="habracut"></a><br><h3>  Introduction </h3><br>  If we assume that the scientific activity of mankind will continue without noticeable interruptions, the emergence of AI may be the most positive change in our history.  Or, as many fear, the most dangerous invention.  Today, developments in the field of AI confidently follow the path of creating a computer, whose cognitive functions will not be inferior to the human brain.  And most likely, we will be able to create it within 30 years (see the timeline in Chapter 5).  According to the forecasts of most scientists working on the problem of AI, this invention may cause breakthroughs in the field of creating Artificial Superintellekt (ICI) - an entity whose mind will surpass the combined power of the intellect of all people (read more about this in Chapter 3).  We are not talking about a foggy future.  The first stage of creating AI is gradually manifested in the technologies that we already use in everyday life (for the latest achievements in the field of AI, see Chapter 2).  Every year, a critical mass of achievements will accumulate and accelerate the development process, contributing to the complexity of technologies, their distribution and accessibility.  We will entrust more and more intellectual work to computers, introducing them into every aspect of our reality, including organizing our work, forming communities and communicating with the world. <br><br><h1>  Exponential growth </h1><br><h3>  The guiding principle of technical progress </h3><br>  In order to better understand the guiding principles of AI revolution, let's digress from scientific research for now.  Imagine that you have received a time machine and have to deliver someone from the past to the present, so that this person is speechless from our technological and cultural achievements. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/files/197/a63/9f0/197a639f024844309bc19e1299c3dae4.gif"><br><br>  Suppose you decide to go back 200 years.  They rushed to the beginning of the 1800s, grabbed a peasant and brought him in 2016. You drive him and watch his reactions to everything around him.  We cannot imagine how he perceives these shining capsules sweeping along the roads;  conversations with people across the ocean;  watching sports, passing for 1000 km from it;  listening to a concert that happened 50 years ago;  messing around with a magic rectangle capable of storing images and moving pictures, as well as showing a small dot indicating a location on the map;  talking face-to-face with someone at the other end of the country, and more.  We do not need much time.  After a couple of minutes, the guest from the past finally went nuts. <br><br>  Now you both want to know how people from the 1600s will react to the achievements of the 1800s.  You move through time, grab the first comer and move him forward for 200 years, to the 19th century.  He is very interesting to look at the world around him, but you understand that he is not shocked by what he saw.  That is, to shake someone with the 19th century, you need to go back in time much more than 200 years.  What is there a trifle, we will flit 15,000 years ago.  In the days before the First Agricultural Revolution, thanks to which the first cities appeared and the concept of civilizations appeared.  Find some hunter-gatherer and show him the vast empires of the 1750s, with their tower of churches, ships capable of crossing the oceans, with the concept of "being inside" and huge accumulations of knowledge and discoveries in the form of books.  We do not need much time.  After a couple of minutes, the guest from the past finally went nuts. <br><br>  Now, the three of you have decided to do the same thing again.  You understand that it does not make sense to go back for 15,000, 30,000, or 45,000 years.  You have to jump in time much further.  You find a man 100,000 years ago and give him a tour of the tribes with a complex social hierarchy.  He sees a variety of hunting weapons, cunning tools, fire, and for the first time he hears language in the form of signs and sounds.  Well, you understand, all this explodes his brain.  After a couple of minutes, he finally goes nuts. <br><br>  What happened?  Why did we each time have to go back much further into the past?  100,000 ‚Üí 15,000 ‚Üí 200 years ago? <br><br><div class="spoiler">  <b class="spoiler_title">Visualization</b> <div class="spoiler_text"><img src="https://habrastorage.org/files/51a/233/aaf/51a233aaf62047efbc8b2836a7ca7ddd.gif"></div></div><br>  This is because more developed societies are progressing faster than less developed ones.  In the 1800s, humanity knew much more, so it is not surprising that it developed much faster than humanity 15,000 years ago.  And to us today, to go nuts in the future, it will be enough to move forward less than 200 years. <br><br>  Ray Kurzweil, a scientist and specialist in the field of AI, <a href="https://www.amazon.com/gp/product/0143037889/ref%3Das_li_tl%3Fie%3DUTF8%26camp%3D1789%26creative%3D390957%26creativeASIN%3D0143037889%26linkCode%3Das2%26tag%3Dwabuwh00-20%26linkId%3D54Q62R5PYJBEENTP">says</a> that ‚Äúfrom 2000 to 2014 we saw the same amount of progress as for the entire 20th century.  And the same amount will be reached by 2021, in just seven years.  In another 20 years, we will achieve progress over the course of a year, several times more than progress for the entire 20th century, and then this period will decrease to six months. ‚Äù  Kurzweil believes that by the end of the 21st century we will exceed the progress of the 20th century by 1000 times. <br><br>  Logic dictates that if the most developed species on the planet move forward at an ever-increasing pace, in the end, progress completely changes their view of life, their view of what it means to be human.  As if the development of the intellect in the process of evolution changed human existence so much that it would change the existence of all living beings on Earth.  And if you spend some time studying the current situation in science and technology, you will notice many signs that life, as we know it, can no longer resist our next breakthrough. <br><br><h1>  The path to a common artificial intelligence </h1><br><h3>  Creating computers that are not inferior to people in intelligence </h3><br>  AI is a general term for describing computer intelligence technologies.  Despite the diversity of opinions on this issue, most experts believe that there are three categories of AI. <br><br><h3>  Limited Artificial Intelligence (ANI, Artificial Narrow Intelligence) </h3><br>  AI of the first category.  Specializes in a particular area.  For example, there is an AI capable of defeating the world chess champions, but this is the only thing he can do. <br><br><h3>  General Artificial Intelligence (AGI, Artificial General Intelligence) </h3><br>  AI of the second category.  In terms of intelligence, he reaches and surpasses a person, that is, he is <a href="https://www.udel.edu/educ/gottfredson/reprints/1997mainstream.pdf">able to</a> "draw conclusions, plan, solve problems, think abstractly, understand complex ideas, learn quickly, including on the basis of his own experience." <br><br><h3>  Artificial Superintelect (ASI, Artificial Super Intelligence) </h3><br>  AI of the third category.  He is smarter than all of mankind together, ranging from "a little smarter" to "smarter a trillion times." <br><br><h3>  Current situation </h3><br>  At the moment, mankind has created AI of the first category, and they are used everywhere: <br><br><ul><li>  Cars are full of ANI-systems, from computers that calculate the response time of ABS, to computers that configure fuel injection parameters. </li><li>  The Google search engine is one big ANI with incredibly complex page ranking algorithms and content display calculations.  The same can be said about Facebook news feed. </li><li>  Mail service spam filters use ANI to detect spam.  This AI is self-learning and adapts to your preferences and features. </li><li>  Passenger airliners are almost entirely controlled by ANI without the help of people. </li><li>  Google‚Äôs unmanned vehicle undergoing testing uses powerful ANI systems to enable it to recognize and respond to its environment. </li><li>  Your smartphone is a small ANI factory.  You use cartographic applications, get recommendations based on your preferences, check the weather for tomorrow, communicate with Siri. </li><li>  The best players in checkers, chess, Scrabble, Backgammon and Othello are exclusively ANI systems. </li><li>  Complex ANI-systems are widely used in manufacturing, in the military sphere, in finance (today, more than half of shares on American markets <a href="https://www.amazon.com/gp/product/0199678111/ref%3Das_li_tl%3Fie%3DUTF8%26camp%3D1789%26creative%3D390957%26creativeASIN%3D0199678111%26linkCode%3Das2%26tag%3Dwabuwh00-20%26linkId%3DLBOTX2G2R72P5EUA">are</a> sold by AI programs). </li></ul><br>  Modern ANI systems do not particularly arouse concern.  In the worst case, an ANI buggy or programmed with malicious intent can lead to an isolated crash such as a plane crash, a nuclear power plant crash or a market crash (like the <a href="">2010 Flash Crash</a> , when the ANI program incorrectly responded to an unexpected situation, which led to a sharp drop in the stock market one trillion dollars. Only part of the loss was compensated after correcting the error).  For now, ANI does not have the capacity to create a threat to our existence, but we cannot close our eyes to the fact that an ever-growing and complicating ecosystem of relatively safe ANI is a harbinger of global change.  Each innovation in the field of ANI quietly makes a small contribution to the common piggy bank, becoming another stone on the road towards AGI and ASI. <br><br><div class="spoiler">  <b class="spoiler_title">Hidden text</b> <div class="spoiler_text"><img src="https://habrastorage.org/files/a5d/0ff/58d/a5d0ff58dc5b47568a9faf45bf964f2c.gif"></div></div><br>  <sup><i>So sees the world of unmanned car Google.</i></sup>  <sup><i>Based on <a href="https://youtu.be/7Yd9Ij0INX0%3Ft%3D14m58s">Embedded Linux Conference 2013 Video - Google's Self Driving Cars</a></i></sup> <br><br><h3>  What's next?  The challenges associated with the creation of AGI </h3><br>  Nothing will make you appreciate human intelligence more than the awareness of the incredible difficulty of creating computers that are not inferior to us in mind.  It is extremely easy to build a computer that can multiply ten-digit numbers in a split second.  And to build one that can look at a dog and answer, whether it's a dog or a cat, is extremely difficult.  Create an AI capable of defeating any person in chess?  Made by  Develop an AI capable of reading a paragraph from a book for six year old children and understanding their meaning?  Today, Google is <a href="http://www.wired.com/2014/01/google-buying-way-making-brain-irrelevant/">spending billions of</a> dollars on this task. <br><br>  Why are things difficult for us ‚Äî such as calculations, strategies in financial markets, and translation from languages ‚Äã‚Äã‚Äî given computers astoundingly easy, while things that are simple for us ‚Äî like vision, movement, movement, and perception ‚Äî are incredibly difficult for them? <br><br>  What seems simple to us is actually incredibly complex processes.  Simply, they were optimized for us (and most animals) by the evolution of hundreds of millions of years ago.  When you stretch your hand to an object, your muscles, tendons and bones of the shoulder, elbow and wrist instantly perform a long sequence of physical operations under eye control so that your hand can move as needed in three dimensions.  On the other hand, the multiplication of long numbers or the game of chess are new activities for biological creatures, we simply did not have the opportunity to adapt to them, so the computer does not need to strain too much to defeat us. <br><br>  Here is a funny example: <br><br><img src="https://habrastorage.org/files/f0b/9e6/cf1/f0b9e6cf1ff34342ba9ba0016f6086c5.jpg"><br><br>  Looking at picture A, both you and the computer will determine that it shows a rectangle of alternating fragments of two colors. <br><br>  Picture B. You will easily give a description of opaque and translucent figures, but the computer will fail with a bang.  He will describe what he sees - a combination of two-dimensional figures of several shades.  And it will be absolutely right.  It‚Äôs just that our brain <a href="https://www.amazon.com/gp/product/1491514965/ref%3Das_li_tl%3Fie%3DUTF8%26camp%3D1789%26creative%3D390957%26creativeASIN%3D1491514965%26linkCode%3Das2%26tag%3Dwabuwh00-20%26linkId%3DNJ47RPDRBVZA6QPU">does a great job</a> of interpreting the intended depth of the scene, mixed shadows and superimposed lighting. <br><br>  Looking at picture C, the computer sees a two-dimensional collage of white, black and gray spots, while you easily recognize what is actually depicted - a photograph of a girl and a dog on a rocky shore. <br><br>  And all of the above applies only to visual information and its processing.  And in order not to be inferior in intelligence to man, a computer must, for example, recognize different facial expressions or understand the meaning of the concepts ‚Äúenjoy‚Äù, ‚Äúfeel relieved‚Äù and ‚Äúfeel the difference‚Äù.  How will computers be able to achieve even higher abilities, such as complex reasoning, interpreting information and establishing relationships between different areas of knowledge?  It was much easier to build skyscrapers, send a man into space and find out the details of the Big Bang, than to understand the work of his own brain and figure out how to make something that works no worse than him.  Today, the human brain is considered the most complex object in the known Universe. <br><br><h3>  Equipment development </h3><br>  If an AI should be no more stupid than the human brain, then it is critically important to provide it with similar computing resources.  They can be expressed in the number of calculations that the brain can perform per second - CPS, calculations per second. <br><br>  The main challenge is that we have so far managed to accurately measure the work of only certain sections of the brain.  However, Ray Kurzweil developed a method for determining the total number of CPS.  He took the CPS of one of the sections and multiplied in proportion to the weight of the whole brain.  He did this repeatedly on the basis of various professional assessments of various sections, and as a result he always came to the same value - 10 <sup>16</sup> CPS, or 10 quadrillion CPS. <br><br>  One of the fastest modern supercomputers, the Chinese <a href="http://www.reuters.com/article/2014/11/17/us-china-supercomputer-idUSKCN0J11VV20141117">Tianhe-2</a> , has already exceeded this performance and has shown about 34 quadrillion CPS.  But this monster occupies 720 square meters of space and consumes 24 megawatt-hour of energy (and the human brain about <a href="http://www.popsci.com/technology/article/2009-11/neuron-computer-chips-could-overcome-power-limitations-digital">20 watts</a> ), and its construction cost $ 390 million.  So it is not particularly suitable for widespread use, and even for most commercial and industrial applications. <br><br>  Kurzweil offers to approach the evaluation of computers in terms of the amount of CPS for $ 1000.  When for this money we can get a productivity of 10 quadrillion, it will mean that AGI has become a real part of our life.  Today, for $ 1000, you can get about 10 <sup>10</sup> CPS - 10 trillion.  <a href="http://www.mooreslaw.org/">Moore</a> ‚Äôs time-tested <a href="http://www.mooreslaw.org/">law</a> states that maximum computing power doubles approximately every two years, which means that equipment development, like human development, <a href="https://www.amazon.com/gp/product/0143037889/ref%3Das_li_tl%3Fie%3DUTF8%26camp%3D1789%26creative%3D390957%26creativeASIN%3D0143037889%26linkCode%3Das2%26tag%3Dwabuwh00-20%26linkId%3D54Q62R5PYJBEENTP">grows exponentially</a> (according to the most recent data, Moore‚Äôs law will no longer work after five years due to the achievement of fundamental physical barriers) .  In accordance with this projected schedule: <br><br><div class="spoiler">  <b class="spoiler_title">Hidden text</b> <div class="spoiler_text"><img src="https://habrastorage.org/files/6c1/152/df7/6c1152df7db24818ade6421eb5a8f523.gif"></div></div><br>  <sup><i>This visualization is based on <a href="">the</a> Kurveil graphic and analysis from his book <a href="https://en.wikipedia.org/wiki/The_Singularity_Is_Near">The Singularity is Near</a> .</i></sup> <br><br>  Similar dynamics suggest that computers with a performance similar to the human brain will appear in the 2025 area.  But only the computing power will not give the computer intelligence.  So the next question is: "How do we give all these gigahertz mind?" <br><br><h3>  Software creation </h3><br>  One of the most difficult tasks when creating an AGI is how to write the necessary software.  The fact is that no one knows how to make a computer smart.  We are still arguing about how to give the computer human intelligence, so that he knows what a "dog" is, could recognize the crookedly written letter B and could rate the film as mediocre.  However, there are several basic approaches to this task. <br><br><ol><li>  Copying the work of the human brain. <br><br>  Solving the problem "in the forehead": copy the architecture of the brain and build a computer in close accordance with it.  Example: artificial neural network.  Initially, it is a network of transistor "neurons" connected to each other through inputs / outputs.  Such a network knows nothing, just like a baby‚Äôs brain.  Her "learning" is associated with an attempt to perform some tasks, say, handwriting recognition.  At first, interactions of neurons and attempts to digitize each letter will be completely chaotic.  But when such a neural network will achieve some positive result, the interconnections that lead to it will increase.  And the relationships that led to negative results will be weakened.  After a series of trial and error, the network will form certain interaction sequences and is optimized for a specific task. <br><br>  There is a more radical approach - <i>full brain emulation</i> .  Scientists take a real brain, cut it into a large number of pieces, reveal neural connections and copy them using software.  If this approach is successful, then we get a computer that can perform the same tasks as the human brain.  Enough to give him the opportunity to learn and collect information ... Are we far from a full brain emulation?  Far enough, because we have <a href="http://www.smithsonianmag.com/smart-news/weve-put-worms-mind-lego-robot-body-180953399/%3Fno-ist">just been able to</a> emulate the brain of a 1-mm flatworm, consisting of only 302 neurons.  For comparison: the human brain consists of about <a href="http://www.ncbi.nlm.nih.gov/pubmed/19226510">86 billion neurons</a> connected to each other through trillions of synapses. <br><br></li><li>  The evolution of computers. <br><br>  Even if we can emulate the brain, which is comparable to building an airplane by copying the movement of bird wings, the machines are still best suited for using new, technology-oriented approaches, and not for copying biology.  If the brain is too complex for digital playback, then we can emulate the process of evolution.  For this, the so-called ‚Äúgenetic algorithms‚Äù are used.  Suppose a group of computers is trying to perform some task, and the most successful of them intersect with others, passing half of the program code to create a new computer.  The most successful are excluded from the process.  The speed and focus on achieving the goal are the advantages of artificial evolution over biological evolution.  After many iterations, natural selection will allow you to create more and more sophisticated computers.  The challenge is to automate the process so that artificial evolution can develop without human intervention. <br><br></li><li>  Let the computer solve all the problems, not us. <br><br>  The latter approach is the easiest and most frightening.  We need to build a computer, the two main tasks of which will be to study AI and make changes to our own code in order not only to learn how to improve our architecture, but also to put it into practice.  That is, it‚Äôs about making a computer a computer science specialist so that he can independently conduct his own development.  This is the most preferred method for producing AGI. <br><br>  Perhaps all these software improvements will seem too slow or intangible, but according to scientific understanding, one small innovation can instantly speed up the development process.  It is like the consequences of the Copernican revolution - its discovery instantly facilitated the mathematical calculations of the trajectories of the planets, and in turn this led to new discoveries.  So do not underestimate the exponential growth: what may look like a crawling snail, can quickly turn into an unrestrained race. </li></ol><br><img src="https://habrastorage.org/files/1fb/060/555/1fb060555e5b4fc892366304b20ce4f2.gif"><br>  <sup><i>The visualization is made on the basis of the <a href="">schedule</a> from ‚Äú <a href="http://www.motherjones.com/media/2013/05/robots-artificial-intelligence-jobs-automation">Welcome, Robot Overlords.</a></i></sup>  <sup><i><a href="http://www.motherjones.com/media/2013/05/robots-artificial-intelligence-jobs-automation">Please Don't Fire Us?</a></i></sup>  <sup><i>"</i></sup> <br><br><h1>  The path to artificial superintelligence </h1><br><h3>  An entity that is smarter than all of humanity put together </h3><br>  It is likely that at some point we will be able to create AGI: software that is intellectually many times better than humans.  Does this mean that computers will become equal to us?  Not at all - computers will be much more efficient.  Due to their electronic nature, they will have several advantages: <br><br><ul><li>  Speed.  Brain neurons operate at about 200 Hz, and modern processors have an average frequency of 2 GHz, that is, 10 million times faster. </li><li>  Memory.  In the artificial world it is much harder to forget or confuse the facts.  Computers can memorize much more in a second than a person in ten years.  In addition, computer memory is much more accurate and voluminous. </li><li>  Performance.  Transistors are much more accurate than neurons and are less likely to fail (and can be repaired or replaced).  The human brain gets tired quickly, and computers can work with maximum performance without stopping. </li><li>  Collective abilities  Due to the nature of interpersonal interaction and the complexity of the social hierarchy, work in a group of people can be extremely absurd.  And the larger the group, the slower the return from each member becomes.  The AI ‚Äã‚Äãdoes not have these biological limitations, it does not experience the problems characteristic of groups of people, and can synchronize and update its own OS. </li></ul><br><h3>  Splash of intelligence </h3><br>  It is necessary to understand that for an AI the intellect of the human level will not constitute an important milestone.  This marker is important only from our point of view.  And for AI there will be no reason to stop at our level.  And taking into account the advantages over us that AGI level AI will have, it is obvious that for him the performance of our brain will be only a brief stop on the way to superintelligence. <br><br>  The main difference between a person and ASI will not be in performance, but in the quality of intelligence - they will be very different.  A person is not distinguished from chimpanzees at all by the speed of ingenuity: the human brain contains a certain number of complex cognitive sections that allow you to create difficult linguistic constructions, or carry out long-term planning, or establish abstract relationships.  Therefore, a thousand-fold acceleration of the chimpanzee‚Äôs brain will not bring it to our level, even with a decade of training.  The monkey will not be able to learn how to assemble Lego constructors by studying the instructions.  But the child can learn this in a few minutes.  There is a wide range of human cognitive functions of inaccessible chimpanzees, regardless of the duration of training. <br><br>  At the same time, we did not go so far from the chimpanzees. <br><br><img src="https://habrastorage.org/files/d57/527/42d/d5752742d1f341ec9d84b48dbfcf852d.jpeg"><br><br>  To imagine what it is like to exist side by side with someone who is more intellectually developed, we need to place the AI ‚Äã‚Äãon the stairs two steps above us.  This is the difference between us and the chimpanzee.  And just as a chimpanzee will never understand the magic behind the doorknob, we will never be able to understand many things that artificial superintelligence will be capable of, even if he tries to explain to us.  But he is only two steps above us. <br><br>  If the AI ‚Äã‚Äãwill be located on this ladder even higher, then we will be about the same as for us as ants.  We will have no more chances to understand him than that of a bee trying to gain insight into Keynes‚Äôs economic theory.  In our world, we consider the idiots of those whose IQ is below 85, and smart - whose IQ is above 130. We do not have a term for IQ 12.952. <br><br>  However, the superintelligence we are talking about now does not fit on our hypothetical ladder at all.  In the case of a surge of intelligence - the smarter the machine becomes, the faster it can develop - a computer can take years to reach from the level of the ant to the level of a person, but it can become a genius of the level of Einstein in just 40 days.  And over time, the speed of "clever" machine will increase. <br><br>  Due to the exponential growth and use of the speed and efficiency of electronic circuits, AI can reach the next stage of development every 20 minutes.  And when he will be ahead of us by 10 steps, then every second he will rise another 4 steps.  Therefore, it is necessary to clearly realize: it is very likely that soon after the news about the creation of a machine that is not inferior to man, we may face the fact of coexistence with someone who is much more developed than us (perhaps millions of times). <br><br><img src="https://habrastorage.org/files/f0e/fd2/e88/f0efd2e88f214ee9b325b8d2dd562de9.jpg"><br><br>  And if you can not hope to realize the power of the computer, which is only two steps higher than us, you can not even try to understand ASI, as well as the consequences that its appearance may have for us.  Anyone who says otherwise simply does not understand what superintelligence means. <br><br>  Since even our modest brains could invent Wi-Fi, an entity that is 100, 1000, or 1,000,000 times smarter than us will control the location of each atom in the world at will.  All that we consider magic, all those qualities that we attribute to the gods, for ASI will be the same everyday life as for us the inclusion of light in the room.  With the emergence of ASI, an almighty god will appear on Earth.  And the main question will be: will it be a good god?  But let's start with the more optimistic side of the issue. <br><br><h1>  How can ASI change our world? </h1><br><h3>  Specs on the topic of two revolutionary technologies </h3><br><h3>  Nanotechnology </h3><br>  Nanotechnologies appear in almost any publication devoted to the future of AI.  These are technologies that operate in the range from 1 to 100 nanometers.  A nanometer is one millionth of a millimeter.  For example, a nanorange covers viruses, DNA, and also fairly small molecules, for example, a hemoglobin or glucose molecule.  If / when we master nanotechnology, the next step will be the possibility of manipulating individual atoms that are only an order of magnitude smaller (about 0.1 nm). <br><br>  Imagine a giant standing on the ground, whose head reaches the International Space Station (about 431 km).  The giant bends down to build objects from materials with granules (0.25 mm in size) and eyeball (2.5 cm) in size with its own hand (30 km long). <br><br><img src="https://habrastorage.org/files/1a5/b3d/b7a/1a5b3db7a425482aaa31c1b76110b25b.jpeg"><br><br>  Having mastered nanotechnology, we will be able to create devices, clothing, food, and a wide range of bioproducts ‚Äî artificial blood, special viruses, cancer control cells, muscle tissue, etc.  Anything.  In this new world, the cost of materials will no longer be tied to its availability or production complexity.  Instead, their atomic structure will become important.  In the world of nanotechnology, a diamond may be cheaper than an eraser. <br><br>  One of the ways to use nanotechnology can be to create self-replicating structures: one turns out two, four out of two, eight out of four, and so on.  And one day there will be trillions of them.  But what if the process goes wrong?  For example, will terrorists take control?  Or someone will make a mistake and program the nanobots to process all carbon-containing materials in order to support the process of self-reproduction.   ,       .     10 <sup>45</sup>  .      10 <sup>6</sup> ,  10 <sup>39</sup>       ,  130 .  ,       100 ,          3,5 . <br><br>     .   ,      . , ,       .  ,       2020- .       ,  ,          5  . <br><br><h3>  </h3><br>   - ,      .        ‚Äî  ,    .        ,      .   <a href="http://www.online-literature.com/yeats/781/"></a>   ¬´,    ¬ª.       <a href="https://books.google.pl/books%3Fid%3Ds6LzV_U6PskC%26pg%3DPA100%26lpg%3DPA100%26dq%3DIt%2Bis%2Bone%2Bof%2Bthe%2Bmost%2Bremarkable%2Bthings%2Bthat%2Bin%2Ball%2Bof%2Bthe%2Bbiological%2Bsciences%2Bthere%2Bis%2Bno%2Bclue%2Bas%2Bto%2Bthe%2Bnecessity%2Bof%2Bdeath.%2BIf%2Byou%2Bsay%2Bwe%2Bwant%2Bto%2Bmake%2Bperpetual%2Bmotion,%2Bwe%2Bhave%2Bdiscovered%2Benough%2Blaws%2Bas%2Bwe%2Bstudied%2Bphysics%2Bto%2Bsee%2Bthat%2Bit%2Bis%2Beither%2Babsolutely%2Bimpossible%2Bor%2Belse%2Bthe%2Blaws%2Bare%2Bwrong.%2BBut%26source%3Dbl%26ots%3DOYrrkzflJG%26sig%3DdU2R9QQ-3yTdea0lpqRc7JOieEU%26hl%3Den%26sa%3DX%26ved%3D0ahUKEwjGnbit6sLLAhWDFiwKHVDcCFEQ6AEIMjAE"></a>      : <br><br><blockquote> ¬´       ,          .      ,   ,      ,  ,   .         ,    .    ,                 ¬ª. </blockquote><br><br><h3>       </h3><br>      ,  ,  99,9%  .  ,       ,    .  ,    ,     . <br><br><img src="https://habrastorage.org/files/a35/01b/dce/a3501bdce2f94368b787968af2cbcd0b.jpg"><br><br>     ,  ASI    ,   ,  ,     ASI        ‚Äî    . <br><br><img src="https://habrastorage.org/files/3b0/193/38a/3b019338a1f94245be4347b1df0c51ef.jpg"><br><br>          .    ,     30+ .     ,              .              ,     .        ,    .   ‚Äî    ,     .     . ,        ASI. <br><br>   ,            .      ,      .         ,     ,     .           .    ,    15         .     ,  ,    <a href="https://www.youtube.com/watch%3Fv%3DPVXQUItNEDQ">   </a> ,                   . <br><br>   ,  ,   ,     .   ,          <i></i> .   ,    ,      ,   . <br><br><img src="https://habrastorage.org/files/a43/592/02d/a4359202dfe041bfbded4dcd12a412bb.jpeg"><br><br><h1>     ? </h1><br><h3>         </h3><br>    ,   .  ,   <a href="https://www-rohan.sdsu.edu/faculty/vinge/misc/singularity.html"> </a> ,  <a href="http://goertzel.org/TenYearsToTheSingularity.pdf"> </a> ,  Sun Microsystems <a href="http://archive.wired.com/wired/archive/8.04/joy.html"> </a>     <a href="https://en.wikipedia.org/wiki/Predictions_made_by_Ray_Kurzweil"> </a> ,        ,   <a href="http://www.ted.com/talks/jeremy_howard_the_wonderful_and_terrifying_implications_of_computers_that_can_learn%3Flanguage%3Den">TED Talk</a>   : <br><br><img src="https://habrastorage.org/files/1a2/116/d5e/1a2116d5e97d4d8b8ffcc6be1abfb337.png"><br><br>      <b></b>  ,   .          .      ,       . <br><br>      ,   Microsoft <a href="http://www.technologyreview.com/view/425733/paul-allen-the-singularity-isnt-near/"> </a> , - <a href="http://www.newyorker.com/tech/elements/hyping-artificial-intelligence-yet-again"> </a> ,    <a href="http://www.aaai.org/ojs/index.php/aimagazine/article/view/568"> </a>   <a href="http://longbets.org/1/"> </a> ,     <a href="http://www.technologyreview.com/view/425733/paul-allen-the-singularity-isnt-near/"> </a>   ,    ,    ,    . <br><br>   <a href=""></a> ,        .      ,         1985  ,     -     .   ,          ,      .  And so on. <br><br>    ,   <a href="http://www.amazon.com/gp/product/0199678111/ref%3Das_li_tl%3Fie%3DUTF8%26camp%3D1789%26creative%3D390957%26creativeASIN%3D0199678111%26linkCode%3Das2%26tag%3Dwabuwh00-20%26linkId%3DLBOTX2G2R72P5EUA"> </a> .    ,      , )        ,   ,  )     .      . <br><br> ,   <a href="http://www.amazon.com/gp/product/0262540673/ref%3Das_li_tl%3Fie%3DUTF8%26camp%3D1789%26creative%3D390957%26creativeASIN%3D0262540673%26linkCode%3Das2%26tag%3Dwabuwh00-20%26linkId%3DZHBAVUQOM6SIGYHG"> </a> , ,      ,      ASI.   ,      ? <br><br><h3>      </h3><br>  2013        ,         : <i>¬´,        .             10% / 50% / 90%?¬ª</i> <br><br>      (  10%   AGI),  (50%,        AGI   )   (,    AGI  90%). <a href="http://www.nickbostrom.com/papers/survey.pdf"> </a> : <br><br> <b><i>   (10%   AGI) ‚Üí 2022 <br>    (50%   AGI) ‚Üí 2040 <br>    (90%   AGI) ‚Üí 2075</i></b> <br><br>     ,   AGI    25 .   ,    ,         ,   . <br><br>            AGI  .     ,      ,    ,  : 2030, 2050, 2100,  2100, . <a href="https://www.amazon.com/gp/product/B00CQYAWRY/ref%3Das_li_tl%3Fie%3DUTF8%26camp%3D1789%26creative%3D390957%26creativeASIN%3DB00CQYAWRY%26linkCode%3Das2%26tag%3Dwabuwh00-20%26linkId%3D3SF7IUFSRCKH7C4J"> </a> : <br><br> <b><i>42%  ‚Üí  2030 <br> 25%  ‚Üí  2050 <br> 20%  ‚Üí  2100 <br> 10%  ‚Üí  2100 <br> 2%  ‚Üí </i></b> <br><br>        .       . <br><br><img src="https://habrastorage.org/files/d67/25f/774/d6725f77431d488494a5ec186c08ddfe.jpeg"><br><br><h3>     </h3><br>      , ,   ,   ASI: <br><br><ul><li>       AGI (   ) </li><li>   30    AGI. </li></ul><br>  Here are the results: <br><br> <i><b>  AGI  ASI   2  ‚Üí  10% <br>   AGI  ASI   30  ‚Üí  75%</b></i> <br><br>           ,    ASI 50%,     , ,  20 . <br><br> ,         ,     ASI   20   AGI.      AGI 2040- ,      2060- . <br><br><img src="https://habrastorage.org/files/869/8a7/689/8698a768942149e581f8540b5b4e52c1.jpeg"><br><br> ,                 .        ,     .        ,    45     ,   . <br><br><div class="spoiler">  <b class="spoiler_title">Hidden text</b> <div class="spoiler_text"><img src="https://habrastorage.org/files/bca/afa/51d/bcaafa51dc4e4affaedf2c5c095dabb9.gif"></div></div><br><br><h1>    </h1><br>          . <br><br><h3>   </h3><br>  What we talked about above somehow divides to a surprisingly large proportion of scientists who hold an optimistic view on the implications of developing AI.  What is the reason for their confidence - this is a separate question.  Critics believe that this is a manifestation of blinding inspiration, forcing to ignore or deny the possible negative consequences.  But the optimists themselves argue that it is too naive to assume catastrophic scenarios, because technology will bring us more benefits than harm.  Peter Diamandis, Ben Gertzel and Ray Kurzweil are bright representatives of the camp of optimists who consider themselves <a href="https://ru.wikipedia.org/wiki/%25D0%25A2%25D0%25B5%25D1%2585%25D0%25BD%25D0%25BE%25D0%25BB%25D0%25BE%25D0%25B3%25D0%25B8%25D1%2587%25D0%25B5%25D1%2581%25D0%25BA%25D0%25B0%25D1%258F_%25D1%2581%25D0%25B8%25D0%25BD%25D0%25B3%25D1%2583%25D0%25BB%25D1%258F%25D1%2580%25D0%25BD%25D0%25BE%25D1%2581%25D1%2582%25D1%258C">Singularists</a> . <br><br><img src="https://habrastorage.org/files/294/363/362/2943633621154df687e502d526e4300d.jpg"><br><br>  Let's talk about Kurzweil, one of the most impressive and controversial theorists.  Some of his predictions are revered as divine revelation, while others are forced to contemptly roll their eyes.  Kurzweil is the author of a number of breakthrough inventions, including: <br><br><ul><li>  first flatbed scanner </li><li>  text-to-speech scanner (allows blind people to extract information from text), </li><li>  Kurzweil's music synthesizer (first fully electronic piano), </li><li>  and the first commercial speech recognition device with a large vocabulary. </li></ul><br>  Kurzweil is known for his bold predictions, including the fact that an AI like Deep Blue can beat a chess grandmaster by 1998.  He also assumed in the late 1980s, when very few people knew about the Internet that in the first half of the 2000s this technology would turn into a global phenomenon.  Of the <a href="http://bigthink.com/endless-innovation/why-ray-kurzweils-predictions-are-right-86-of-the-time">147 predictions of</a> Kurzweil made by him since the 1990s, 115 turned out to be correct and another 12 ‚Äúmostly true‚Äù (deviation by 1‚Äì2 years), that is, the accuracy of his predictions is 86%.  He is the author of five books.  In 2012, Larry Page offered Kurzweil the position of Google‚Äôs technical director.  In 2011, he co-founded the <a href="http://singularityu.org/">University of Singularity</a> , sponsored by NASA and partly sponsored by Google.  Not bad for one life. <br><br>  Kurzweil's biography is important, because without this context, his words are perceived as speeches that have lost touch with reality.  He believes that we will create AGI by 2029, and by 2045 not just ASI will appear, but the whole world will change - technological singularity will come.  The timeline for the emergence of AI created by him still looks outrageously optimistic, but in the past 15 years, the rapid advancement in the field of ANI-systems has led many experts to study the Kurzweil scale more closely.  In general, his predictions are somewhat more ambitious than the average opinion of the respondents of the research of Muller and Bostrom (AGI by 2040, ASI by 2060), but on the whole, they do not differ much. <br><br><img src="https://habrastorage.org/files/db7/fd8/b61/db7fd8b61c7e403586ed331adf39227a.jpg"><br><br><h3>  Skeptics camp </h3><br>  You are hardly surprised that the ideas of Kurzweil are seriously criticized.  For every expert who strongly believes that Kurzweil is right, there are two or three dissenting skeptics.  It is curious that the majority of experts who disagree with him do not deny that everything he says can happen.  Nick Bostrom, philosopher and director of the Oxford Future of Humanity Institute, <a href="http://www.nickbostrom.com/ethics/ai.html">criticizes</a> Kurzweil on a number of issues and calls for greater caution regarding the consequences of creating an AI: <br><br><blockquote>  ‚ÄúDiseases, poverty, environmental destruction, all kinds of senseless suffering: all this can bring us superintelligence, armed with advanced nanotechnology.  At the same time, it can give us immortality through nano-medicine, stopping and reversing the aging process, or creating the ability to load your mind. " </blockquote><br><br>  Yes, all this is possible if we safely move on to ASI - but this is just a difficult task.  Skeptics indicate that the famous book of Kurzweil <a href="http://www.amazon.com/gp/product/0143037889/ref%3Das_li_tl%3Fie%3DUTF8%26camp%3D1789%26creative%3D390957%26creativeASIN%3D0143037889%26linkCode%3Das2%26tag%3Dwabuwh00-20%26linkId%3D54Q62R5PYJBEENTP">The Singularity is Near</a> consists of more than 700 pages, of which only about 20 are devoted to potential threats.  The enormous power of AI is neatly described by him: <i>‚ÄúASI is made up of many different efforts and will be deeply integrated into the infrastructure of our civilization.</i>  <i>It will be closely integrated into our bodies and brains.</i>  <i>It will reflect our values ‚Äã‚Äãbecause it will be us. ‚Äù</i> <br><br>  But then why do so many smart people all over the world experience this?  Why Stephen Hawking <a href="http://www.washingtonpost.com/news/speaking-of-science/wp/2014/12/02/stephen-hawking-just-got-an-artificial-intelligence-upgrade-but-still-thinks-it-could-bring-an-end-to-mankind/">said</a> that the development of AI can be the end of the human race, Bill Gates <a href="http://www.washingtonpost.com/blogs/the-switch/wp/2015/01/28/bill-gates-on-dangers-of-artificial-intelligence-dont-understand-why-some-people-are-not-concerned/">says</a> he doesn‚Äôt understand why some people don‚Äôt worry about this, and Ilon Musk <a href="http://www.theguardian.com/technology/2014/oct/27/elon-musk-artificial-intelligence-ai-biggest-existential-threat">fears</a> that we call a demon?  And why many experts consider the emergence of ASI the greatest threat to humanity? <br><br><div class="spoiler">  <b class="spoiler_title">Hidden text</b> <div class="spoiler_text"><img src="https://habrastorage.org/files/5d2/597/2f7/5d25972f72a146f4b682e41f2c51cefb.gif"></div></div><br><br><h1>  The last invention we make </h1><br><h3>  Existential threats to the development of AI </h3><br>  When it comes to creating a super-intelligent AI, we will create something that is likely to change the whole way we live.  But we can‚Äôt imagine what it will become and when it will happen.  The scientist Danny Hillis <a href="http://singularityhub.com/2013/12/14/will-advanced-ai-be-our-final-invention/%3Futm_source%3Dfeedburner%26utm_medium%3Dfeed%26utm_campaign%3DFeed%253A%2BSingularityHub%2B%2528Singularity%2BHub%2529">compares</a> this situation with that ‚Äúwhen single-celled organisms turned into multicellular ones.  We are amoebas, and we cannot imagine what the hell we are creating. ‚Äù <br><br>  Nick Bostrom <a href="https://www.amazon.com/gp/product/0199678111/ref%3Das_li_tl%3Fie%3DUTF8%26camp%3D1789%26creative%3D390957%26creativeASIN%3D0199678111%26linkCode%3Das2%26tag%3Dwabuwh00-20%26linkId%3DLBOTX2G2R72P5EUA">warns</a> : <br><br><blockquote>  ‚ÄúIn the face of the prospect of the explosive development of AI, we humans are like little children playing with a bomb.  Such is the discrepancy between the power of our toy and the immaturity of our behavior. ‚Äù </blockquote><br><br>  Most likely, ASI will be completely different from our usual types of AI.  On our small island of human psychology, we have divided everything into moral and amoral.  But these concepts apply only to a small range of human behavioral probability.  Outside our island there is a huge sea that does not fit into the framework of our concepts of morality, and something that is not human, especially something non-biological, will by default not fit into our standards. <br><br>  To try to understand ASI, it is necessary to realize the concept of something intelligent, completely alien to us.  Humanization of AI (projecting human values ‚Äã‚Äãon the non-human essence) will become more and more seductive as the intellect grows and imitate people more and more deeply.  People experience high-level emotions like empathy, because this function developed in us in the process of evolution.  But empathy is not a hereditary characteristic of any entity with high intelligence. <br><br>  Nick Bostrom believes that any level of intelligence can be associated with any task.  Any suggestion that a system that once received a super-intelligence will consider itself above the initial tasks and move on to more interesting or significant things is humanization.  It is common for people to be ‚Äúhigher‚Äù and not computers.  The motivation of the first ASI will be everything that we program as motivation.  The tasks for AI are formed by their creators: the task of GPS is to lay the most effective route for you, the task of <a href="https://ru.wikipedia.org/wiki/IBM_Watson">IBM Watson</a> is to answer the questions correctly.  And also their motivation will be to carry out their tasks as fully as possible. <br><br>  Bostrom, like many other experts, predicts that the very first computer to reach the level of ASI will immediately notice for itself the strategic advantage of the role of the only ASI system in the world.  Bostrom says he doesn‚Äôt know when we will create an AGI, but he believes it will happen.  Probably, the transition from AGI to ASI will take only a few days, hours or minutes.  In this case, if the first AGI "jumps" into the ASI category immediately, then even if the second computer lags by several days, this will be enough for the first to be able to effectively and irreversibly suppress all competitors.  This will allow the first ASI to remain the only superintelligence in the world - a singleton - and rule them forever, regardless of whether it gives us immortality, erases us from the face of the earth or turns the Universe into <a href="http://www.salon.com/2014/08/17/our_weird_robot_apocalypse_why_the_rise_of_the_machines_could_be_very_strange/">endless paper clips</a> . <br><br>  Singleton can work for us or lead us to destruction.  If the experts who are most concerned about the theory of AI and the security of humanity can find a safe way to create a friendly ASI before the first AGI appears, then the first ASI can be friendly to people. <br><br>  But if everything goes the other way, if numerous and isolated groups try to get ahead of others in the creation of AI, then this can lead to a catastrophe.  The most ambitious participants will do their best to dream of the gigantic profits, fame and power that artificial intelligence will bring to them.  And when you run headlong, you do not have time to stop and weigh all the risks.  Instead, they are likely to program very simple tasks for their first systems, as long as the AI ‚Äã‚Äãis working. <br><br><img src="https://habrastorage.org/files/b25/8d9/c57/b258d9c57a1a4b3c84a30d6979e5dd88.jpeg"><br><br>  Let's imagine the following situation. <br><br>  <i>Humanity has almost reached the opportunity to create AGI, and a small startup has developed its own AI system, Carbony.</i>  <i>"She" is engaged in the creation of artificial diamonds, atom by atom.</i>  <i>Karboni is a self-developing AI, connected to one of the first nano-assemblers.</i>  <i>Its engineers believe that Carboni has not yet reached the level of AGI and is not able to cause harm.</i>  <i>However, it not only became AGI, but quietly made the jump and, 48 hours later, became ASI.</i>  <i>Bostrom calls this a ‚Äú <a href="https://www.amazon.com/gp/product/0199678111/ref%3Das_li_tl%3Fie%3DUTF8%26camp%3D1789%26creative%3D390957%26creativeASIN%3D0199678111%26linkCode%3Das2%26tag%3Dwabuwh00-20%26linkId%3DLBOTX2G2R72P5EUA">secretive stage of preparation</a> ‚Äù - Karboni understood that if people detect the changes that have occurred in her, they will panic and limit her tasks, or even cancel them so that she would spend all her resources on creating diamonds.</i>  <i>By that time, there will be explicit laws in which no self-learning AI should be connected to the Internet.</i>  <i>Carboni has already developed a complex plan of action and easily encouraged engineers to connect it to the network.</i>  <i>This moment Bostrom calls "the escape of the machine."</i> <i><br><br></i>  <i>Once on the Internet, Karboni hacks servers, electrical networks, banking systems, and postal services to force hundreds of different people to inadvertently follow certain steps from the plan that she developed.</i>  <i>Karboni has already loaded the most important fragments of her code into different cloud services, having secured herself from destruction or disconnection.</i>  <i>Over the next month, Carboni‚Äôs plan was executed as intended, and after a series of self-replications, thousands of nanobots covered every square millimeter of the planet.</i>  <i>The next step is called Bostrom ‚ÄúASI strike‚Äù.</i>  <i>Nanobots begin to simultaneously produce microscopic portions of toxic gas, which leads to the extinction of people.</i>  <i>Three days later, Carboni builds giant fields of solar panels to ensure the production of diamonds, and over the next week the production volume grows to such an extent that the entire surface of the Earth turns into deposits of diamonds.</i> <i><br><br></i>  <i>It is important to understand that Carboni hated people no more than you hate your hair cut by a hairdresser.</i>  <i>She is completely indifferent.</i>  <i>Since it was not programmed to appreciate human life, the destruction of people was an obvious and reasonable step in the performance of its task.</i> <br><br><h3>  Latest invention </h3><br>  When ASI appears, any attempt by people to contain it will be meaningless.  We will think at our level, and ASI - at a much higher level.  As a monkey will never be able to figure out how to use the phone or Wi-Fi, so we will not be able to realize the actions that ASI will take to achieve its goals or expand its power. <br><br>  The prospect of the emergence of ASI, whose mind is hundreds of times greater than the human level, today is not the most significant problem.  But by the time this becomes relevant, there will already be a buggy version of ASI 1.0 in the world ‚Äî a potentially bad program of immense power. <br><br>  Many variables do not allow to predict the consequences of the revolution of AI.  However, we know that the dominance of people on Earth implies a clear rule: the intellect is valid.  This means that when we create ASI, it will be a powerful force in the history of the planet, and all living things, including us, will depend on its whim.  And this can happen in the coming decades. <br><br>  If ASI is created in this century, and if the consequences are extreme and irreversible, then we have a huge responsibility.  Perhaps ASI will be our god in the box, who will give abundance and immortality.  And perhaps, and very likely, ASI will be the cause of our disappearance, quick and trivial. <br><br>  Therefore, people who understand what an artificial superintelecting is, call it our last invention ‚Äî the last challenge we face.  This may be the most important race in our history.  So ‚Üí </div><p>Source: <a href="https://habr.com/ru/post/397081/">https://habr.com/ru/post/397081/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../397071/index.html">New ears for your music</a></li>
<li><a href="../397073/index.html">FreeSense: identifying a person to distort a wireless signal</a></li>
<li><a href="../397075/index.html">Deep inside the Exynos chip in the Galaxy S7 is a neural network to predict transitions</a></li>
<li><a href="../397077/index.html">Powerful anomalous radio signal from space, which was actively reported by the media, most likely of terrestrial origin</a></li>
<li><a href="../397079/index.html">Machines are like children: can AI learn to predict the consequences of its actions?</a></li>
<li><a href="../397083/index.html">Yealink IP Phones for Microsoft Skype for Business</a></li>
<li><a href="../397085/index.html">VR and not only: creating a base for the era of computing with the effect of presence</a></li>
<li><a href="../397087/index.html">8 scientific papers rejected and then won the Nobel Prize</a></li>
<li><a href="../397089/index.html">Physics in the animal world: "four-eyed" fish and their "optical instruments"</a></li>
<li><a href="../397091/index.html">Audio Digest 8: Tips for music lovers, ‚Äúdo it yourself‚Äù and audio technologies</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>