<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Automatic task assignment in Jira using ML</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hi, Habr! My name is Sasha and I am a backend developer. In my free time I study ML and have fun with the data of hh.ru. 

 This article is about how ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Automatic task assignment in Jira using ML</h1><div class="post__text post__text-html js-mediator-article">  Hi, Habr!  My name is Sasha and I am a backend developer.  In my free time I study ML and have fun with the data of hh.ru. <br><br>  This article is about how we automated the routine process of assigning tasks to testers using machine learning. <br><br>  In hh.ru there is an internal service for which tasks are created in Jira (within the company they are called HHS), if someone doesn‚Äôt work or doesn‚Äôt work correctly.  Further, these tasks are manually handled by the QA team leader, Alexey, and assigned to the team whose area of ‚Äã‚Äãresponsibility is the fault.  Lesha knows that robots should perform boring tasks.  Therefore, he turned to me for help on the part of ML. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <img src="https://habrastorage.org/webt/lf/kq/mb/lfkqmb1mywrx75vy3vgmbouegm4.jpeg"><br><a name="habracut"></a><br>  The chart below shows the amount of HHS per month.  We are growing and the number of tasks is growing.  Tasks are mainly created during working hours a few pieces per day, and this has to be constantly distracted. <br><br><img src="https://habrastorage.org/webt/uz/rj/3y/uzrj3y7f_horg-9oshdxgaurymo.jpeg"><br>  So, it is necessary to learn from historical data to determine the development team to which HHS belongs.  This is a multi-class classification task. <br><br><h4>  Data </h4><br>  In machine learning tasks, the most important thing is the quality data.  The outcome of the problem depends on them.  Therefore, any machine learning tasks must begin with examining the data.  Since the beginning of 2015, we have accumulated about 7,000 tasks that contain the following useful information: <br><br><ul><li>  Summary - title, short description </li><li>  Description - full description of the problem </li><li>  Labels - a list of tags associated with the problem </li><li>  Reporter - the name of the creator of HHS.  This feature is useful because people work with a limited set of functionalities. </li><li>  Created - date of creation </li><li>  Assignee - the one to whom the task is assigned.  From this feature, the target variable will be generated. </li></ul><br>  Let's start with the target variable.  First, each team has areas of responsibility.  Sometimes they intersect, sometimes one team may intersect in development with another.  The decision will be based on the assumption that assignee, which remained at the task at the time of closure, is responsible for its solution.  But we need to predict not a specific person, but a team.  Fortunately, we have in Jira the composition of all teams and can be smoked.  But with the definition of team by person there are a number of problems: <br><br><ul><li>  Not all HHS are related to technical problems, and we are only interested in those tasks that can be assigned to the development team.  Therefore, it is necessary to throw out tasks where assignee is not from the technical department </li><li>  sometimes teams cease to exist.  They are also removed from the training set. </li><li>  unfortunately, people do not work forever in the company, and sometimes move from team to team.  Fortunately, we managed to get a history of changes in the composition of all teams.  Having the creation date of HHS and assignee, you can find which team was engaged in the task at a certain time. </li></ul><br>  After screening out irrelevant data, the training sample was reduced to 4900 tasks. <br><br>  Let's look at the distribution of tasks between teams: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ch/rx/36/chrx36t-w61obwicvypihnu36jm.jpeg"></div><br>  Tasks need to be distributed between 22 teams. <br><br><h4>  Signs: </h4><br>  Summary and Description - text fields. <br><br>  First, they should be cleaned from unnecessary characters.  For some tasks, it makes sense to leave symbols in the lines that carry information, for example + and #, to distinguish between c ++ and c #, but in this case I decided to leave only letters and numbers, since  not found where other characters may be useful. <br><br>  Words need to be lemmatized.  Lemmatization is the reduction of a word to a lemma, its normal (vocabulary) form.  For example, cats ‚Üí cat.  I also tried stemming, but with lemmatization, the quality was slightly higher.  Stemming is the process of finding the stem of a word.  This basis is due to the algorithm (they are different in different implementations), for example, cats ‚Üí cats.  The meaning of the first and second is to match each other the same words in different forms.  I used Python wrapper for <a href="https://github.com/nlpub/pymystem3">Yandex Mystem</a> . <br><br>  Then the text should be cleared from stop words that do not carry the payload.  For example, "was", "me", "more."  I usually take stop words from <a href="https://www.nltk.org/">NLTK</a> . <br><br>  Another approach that I try in the tasks of working with text is character-by-word word splitting.  For example, there is a ‚Äúsearch‚Äù.  If you break it into components of 3 characters, then you get the words "poi", "ois", "lawsuit".  It helps to get additional connections.  Suppose there is the word "search."  Lemmatization does not lead to the ‚Äúsearch‚Äù and ‚Äúsearch‚Äù for the general form, but a division of 3 characters will highlight the common part - the ‚Äúlawsuit‚Äù. <br><br>  I made two tokenizers.  Tokenizer is a method that inputs text to the input, and the output is a list of tokens that make up the text.  The first highlights lemmatized words and numbers.  The second highlights only lemmatized words, which are broken down by 3 characters each, i.e.  at the exit he has a list of three-character tokens. <br><br>  Tokenizers are used in <a href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html">TfidfVectorizer</a> , which is used to convert text (and not only) data into a vector representation based on <a href="https://en.wikipedia.org/wiki/Tf%25E2%2580%2593idf">tf-idf</a> .  At the input it is given a list of lines, and at the output we get the matrix M by N, where M is the number of lines, and N is the number of signs.  Each sign is a frequency characteristic of a word in a document where the frequency is penalized if the given word occurs many times in all documents.  Thanks to the ngram_range TfidfVectorizer parameter, I added more <a href="https://ru.wikipedia.org/wiki/N-%25D0%25B3%25D1%2580%25D0%25B0%25D0%25BC%25D0%25BC%25D0%25B0">digrams and trigrams</a> as signs. <br><br>  I also tried to use word embeddings using Word2vec as additional signs.  Embedding is a vector representation of the word.  For each text I averaged the embeddings of all his words.  But it did not give any gain, therefore I refused these signs. <br><br>  For Labels was used <a href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html">CountVectorizer</a> .  At the input it receives the string with tags, and at the output we have a matrix, where the rows correspond to the tasks, and the columns - to the tags.  Each cell contains the number of occurrences of the tag in the task.  In my case, this is 1 or 0. <br><br>  For Reporter approached <a href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelBinarizer.html">LabelBinarizer</a> .  It binarizes the ‚Äúone-against-all‚Äù signs.  For each task there can be only one creator.  At the entrance to LabelBinarizer, a list of task creators is submitted, and the output is a matrix, where rows are tasks, and columns correspond to the names of task creators.  It turns out that in each line is ‚Äú1‚Äù in the column corresponding to the creator, and in the rest - ‚Äú0‚Äù. <br><br>  For Created, the difference in days between the task creation date and the current date is considered. <br><br>  The result was the following signs: <br><br><ul><li>  tf-idf for Summary in words and numbers (4855, 4593) </li><li>  tf-idf for Summary on three-character partitions (4855, 15518) </li><li>  tf-idf for Description in words and numbers (4855, 33297) </li><li>  tf-idf for Description on three-character partitions (4855, 75359) </li><li>  number of entries for Labels (4855, 505) </li><li>  binary signs for Reporter (4855, 205) </li><li>  task lifetime (4855, 1) </li></ul><br>  All these signs are combined into one large matrix (4855, 129478), which will be used for training. <br><br>  Separately, it is worth noting the names of signs.  Because  Some machine learning models are able to highlight the signs that have the greatest impact on class recognition, it is necessary to use this.  TfidfVectorizer, CountVectorizer, LabelBinarizer have methods get_feature_names that return a list of attributes, the order of which corresponds to the columns of matrices with data. <br><br><h4>  Prediction model selection </h4><br>  Very often <a href="https://dask-ml.readthedocs.io/en/stable/modules/generated/dask_ml.xgboost.XGBClassifier.html">XGBoost</a> gives good results.  With him and started.  But I generated a huge number of features, the number of which significantly exceeds the size of the training sample.  In this case, the probability of retraining XGBoost.  The result was not very.  High dimensionality digests well <a href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html">LogisticRegression</a> .  She showed higher quality. <br><br>  I also tried as an exercise to build a model on a neural network in Tensorflow for <a href="https://developers.google.com/machine-learning/guides/text-classification/">this</a> excellent tutor, but it turned out worse than the logistic regression. <br><br><h4>  Hyperparameter selection </h4><br>  I also played with XGBoost and Tensorflow hyperparameters, but leave it outside of the post, since  the logistic regression result was not surpassed.  In the latter, I twisted all the pens that you can.  All parameters in the result remained default, except for two: solver = 'liblinear' and C = 3.0 <br><br>  Another parameter that can affect the result is the size of the training sample.  Because  I deal with historical data, and in a few years the history can seriously change, for example, responsibility for something can be transferred to another team, then more recent data can bring more benefits, and old ones even lower the quality.  On this account, I came up with a heuristic - the older the data, the less contribution they have to make to the training model.  Depending on old age, the data is multiplied by a certain coefficient, which is taken from the function.  I generated a few functions to damp the data and used the one that gave the most boost in testing. <br><br><img src="https://habrastorage.org/webt/0v/sn/dv/0vsndvsl3honu6aq5rrpan7ffkc.jpeg"><br><br>  Due to this, the quality of classification increased by 3%. <br><br><h4>  Quality control </h4><br>  In classification tasks, you need to think about what is more important for us - <a href="https://en.wikipedia.org/wiki/Precision_and_recall">accuracy or completeness</a> ?  In my case, if the algorithm is wrong, then there is nothing terrible, we have very good knowledge between teams and the task will be transferred to the responsible ones, or to the main one in QA.  In addition, the algorithm is not mistaken randomly, but finds a command close to the problem.  Therefore, it was decided to take 100% for completeness.  And for the measurement of quality, the accuracy metric was chosen - the proportion of correct answers, which for the final model was 76%. <br><br>  As a validation mechanism, I first used cross-validation - when the sample is divided into N parts and the quality is checked on one part, and the others are trained, and so N times, until each part plays the role of a test.  The result is then averaged.  But in my case, this approach did not fit, because  the order of the data changes, and as it has already become known, the quality depends on the freshness of the data.  Therefore, I studied all the time in old ones, and validated in fresh ones. <br><br>  Let's see which commands are most often confused by the algorithm: <br><br><img src="https://habrastorage.org/webt/sa/j_/zh/saj_zhbvcyp2jwq5giaiqik1ad8.jpeg"><br><br>  In the first place is Marketing and Pandora.  This is not surprising, since  The second team grew out of the first one and took with it responsibility for a multitude of functionalities.  If you look at the rest of the teams, you can also see the reasons related to the company's internal cooking. <br><br>  For comparison, I want to look at random models.  If you assign a responsible person randomly, the quality will be about 5%, and if the most common class, then - 29% <br><br><h4>  The most significant signs </h4><br>  LogisticRegression for each class returns the coefficients of signs.  The greater the value, the greater the contribution this feature has made to this class. <br><br>  Under the spoiler output top tags.  Prefixes mean whence signs were received: <br><br><ul><li>  sum - tf-idf for Summary in words and numbers </li><li>  sum2 - tf-idf for Summary on three-character splits </li><li>  desc - tf-idf for Description in words and numbers </li><li>  desc2 - tf-idf for Description on three-character splits </li><li>  lab - Labels field </li><li>  rep - field Reporter </li></ul><br><div class="spoiler">  <b class="spoiler_title">Signs of</b> <div class="spoiler_text"> A-Team: sum_site (1.28), lab_reviews_and_inviting (1.37), lab_rejects to the employer (1.07), lab_web (1.03), sum_work (1.04), sum_work_site (1.59), lab_hhs (1.19), lab_feedback (1.06, a repentant (1.59), lab_hhs (1.19), lab_feedback (1.06,) (1.16), sum_window (1.13), sum_to break (1.04), rep_name_1 (1.22), lab_otkliki_coeker (1.0), lab_site (0.92) <br><br>  API: lab_accounting__account (1.12), sum_comment_surface (0.94), rep_name_sword (0.9), rep_name_3 (0.83), rep_name_4 (0.91) ), sum_view (0.91), desc_comment (1.02), rep_name_6 (0.85), desc_ summary (0.86), sum_api (1.01) <br><br>  Android: sum_android (1.77), lab_ios (1.66), sum_app (2.9), sum_hr_mobile (1.4), lab_android (3.55), sum_hr (1.36), lab_mobile_app (3.33), sum_mobile (1.4), rep_name_2 (1.34), sum2_ril ‚Äã‚Äã(1.27 ), sum_app_android (1.28), sum2_pri_ril_lo (1.19), sum2_pri_ril (1.27), sum2_ilo_lozh (1.19), sum2_ilo_lozh_ozh (1.19) <br><br>  Billing: rep_name_7 (3.88), desc_count (3.23), rep_name_8 (3.15), lab_billing_wtf (2.46), rep_name_9 (4.51), rep_name_10 (2.88), sum_count (3.16), lab_billing (2.41), rep_name_11 (2.27), lab_illing red ), sum_service (2.33), lab_payment_services (1.92), sum_act (2.26), rep_name_12 (1.92), rep_name_13 (2.4) <br><br>  Brandy: lab_totals_ of talents (2.17), rep_name_14 (1.87), rep_name_15 (3.36), lab_clickme (1.72), rep_name_16 (1.44), rep_name_17 (1.63), rep_name_18 (1.29), sum_page (1.24), sum_brand (1.JF),), rep, name_18 (1.29), sum_page (1.24), rep_name_17 (1.63), rep_name_18 (1.29) ), constructor sum (1.59), lab_brand.page (1.33), sum_description (1.23), sum_description_company (1.17), lab_article (1.15) <br><br>  Clickme: desc_act (0.73), sum_adv_hh (0.65), sum_adv_hh_en (0.65), sum_hh (0.77), lab_hhs (1.27), lab_bs (1.91), rep_name_19 (1.17), rep_name_20 (1.29), rep_name_21 (rep), rep_name_19 (1.17), rep_name_20 (1.29), rep_name_21 (1.9), rep_name_19 (1.17) ), sum_advertising (0.67), sum_deposition (0.65), sum_adv (0.65), sum_hh_ua (0.64), sum_click_31 (0.64) <br><br>  Marketing: lab_region (0.9) lab_tormozit_sayt (1.23) sum_rassylka (1.32) lab_menedzhery_vakansy (0.93) sum_kalendar (0.93), rep_name_22 (1.33), lab_oprosy (1.25), rep_name_6 (1.53), lab_proizvodstvennyy_kalendar (1.55), rep_name_23 (0.86 ), sum_andex (1.26), sum_distribution_vacancy (0.85), sum_distribution (0.85), sum_category (0.85), sum_error_transition (0.83) <br><br>  Mercury: lab_services (1.76), sum_capcha (2.02), lab_siterer_services (1.89), lab_lawyers (2.1), lab_autorization_counter (1.68), lab_production (2.53), lab_reply_sum (2.21), reps, 1.77, i, rep, name_ rep, (rep. Name), rep, name, rep, name, resume (2.21), rep, name, rep, name_24_; ), sum_user (1.57), rep_name_26 (1.43), lab_moderation_ of vacancies (1.58), desc_password (1.39), rep_name_27 (1.36) <br><br>  Mobile_site: sum_mobile_version (1.32), sum_version_site (1.26), lab_application (1.51), lab_statistics (1.32), sum_mobilny_version_say_site (1.25), lab_mobile_version (5.1), sum_version (1.41), rep_name_28 (cf.pdf), aus.eek. ), lab_jtb (1.07), rep_name_16 (1.12), rep_name_29 (1.05), sum_site (0.95), rep_name_30 (0.92) <br><br>  TMS: rep_name_31 (1.39), lab_talantix (4.28), rep_name_32 (1.55), rep_name_33 (2.59), sum_vacancy_talantix (0.74), lab_search (0.57), lab_search (0.63), rep_name_34 (0.64), lab_lender (0.56), lab_search (0.63), rep_name_34 (0.64), lab_lender (0.56), lab_search (0.63), lab_search (0.63), rep_name_34 (0.64), 0.66) ), lab_tms (0.74), sum_otklik_hh (0.57), lab_mailing (0.64), sum_talantix (0.6), sum2_mpo (0.56) <br><br>  Talantix: sum_system (0.86), rep_name_16 (1.37), sum_talantix (1.16), lab_mail (0.94), lab_xor (0.8), lab_talantix (3.19), rep_name_35 (1.07), rep_name_18 (1.33), lab_personal_dates (96), rep_name_35 (1.07), rep_name_18 (1.33), lab_personal_dates (96), rep_name_35 (1.07), rep_name_18 (1.33) ), sum_alantix (0.89), sum_because (0.78), lab_mail (0.77), sum_elect_set_view (0.73), rep_name_6 (0.72) <br><br>  WebServices: sum_vacancy (1.36), desc_pattern (1.32), sum_archive (1.3), lab_writing_ templates (1.39), sum_phone_number_phone (1.44), rep_name_36 (1.28), lab_lawyers (2.1), lab_inviting (1.27), lab_ing_accord_lawers (1.27), lab_lawyers (2.1), lab_lawyers (2.17), lab_lawyers (2.1), lab_lawyers (2.13) ), lab_eleased_sum (1.2), lab_keye_wab, (1.22), sum_to find (1.18), sum_telephone (1.16), sum_folder (1.17) <br><br>  iOS: sum_application (1.41), desc_application (1.13), lab_andriod (1.73), rep_name_37 (1.05), sum_ios (1.14), lab_mobile_app (1.88), lab_ios (4.55), rep_name_6 (1.41), rep_name_38 (1.35), mo_mobile_ ), sum_ mobile (0.98), rep_name_39 (0.74), sum_ summary_open (0.88), rep_name_40 (0.81), lab_duplication_vacancy (0.76) <br><br>  Architecture: sum_statistics_otklik (1.1), rep_name_41 (1.4), lab_graphic_setting_displaces, o and_otclik_vakanii (1.04), lab_developing_vacancy (1.16), lab_quot (1.0), sum_special offer (1.02), rep_name_42 (1.33), rep_name, 1.0_, sum_special proposal (1.02), rep_name_42 (1.33), rep_name, 1.0_, sum_special proposal (1.02), rep_name_42 (1.33), rep_name, 1.0_, sum_special proposal (1.02), rep_name_42 (1.33), rep_name, 1.0_, sum_special proposal (1.02), rep_name_42 (1.33), rep_name, 1.0, _ ), rep_name_43 (1.09), sum_zavisat (0.83), sum_statistika (0.83), lab_otkliki_ employer (0.76), sum_500ka (0.74) <br><br>  Bank Salary: lab_500 (1.18), lab_authorization (0.79), sum_500 (1.04), rep_name_44 (0.85), sum_500_site (1.03), lab_site (1.08), lab_visibility_subject (1.54), lab_specification (1.26), lab_specification_subject_subject (1.54), lab_profile (1.26), lab_setting_vizability_subject_ 1.9 sum_error (0.79), lab_post_ orders (1.33), rep_name_43 (0.74), sum_ie_11 (0.69), sum_500_error (0.66), sum2_say_ite (0.65) <br><br>  Mobile products: lab_mobile_application (1.69), lab_otklik (1.65), sum_hr_mobile (0.81), lab_applicant (0.88), lab_employer (0.84), sum_mobile (0.81), rep_name_45 (1.2), desc_d0 (0.87), rep_name_46 (4.46 (46), rep_name_45 (1.2), desc_d0 (0.84). 0.79), sum_wrong_work_search (0.61), desc_app (0.71), rep_name_47 (0.69), rep_name_28 (0.61), sum_work_search (0.59) <br><br>  Pandora: sum_to come (2.68), desc_to come (1.72), lab_sms (1.59), sum_statu (2.75), sum_education_otklik (1.38), sum_disable (2.96), lab_esto_recovery_password (1.52), lab_path_tasks (1.31),). ), lab_list (1.72), lab_list (3.37), desc_list (1.69), desc_mail (1.47), rep_name_6 (1.32) <br><br>  Peppers: lab_sohranenie_rezyume (1.43) sum_rezyume (2.02) sum_voronka (1.57) sum_voronka_vakansiya (1.66) desc_rezyume (1.19) lab_rezyume (1.39) sum_kod (1.2), lab_applicant (1.34), sum_indeks (1.47) sum_indeks_vezhlivost (1.47 ), lab_creation_summer (1.28), rep_name_45 (1.82), sum_weekness (1.47), sum_save_suminal (1.18), lab_index_fariness (1.13) <br><br>  Search 1 (1.62), sum_synonym (1.71), sum_sample (1.62), sum2_isk (1.58), sum2_tois_isk (1.57), lab_automatic update_sum (1.57) <br>  Search 2: rep_name_48 (1.13), desc_d1 (1.1), lab_premium_v_poiske (1.02) lab_prosmotry_vakansii (1.4), sum_poisk (1.4), desc_d0 (1.2), lab_pokazat_kontakty (1.17), rep_name_49 (1.12), lab_13 (1.09), rep_name_50 (1.05), lab_search_vocancies (1.62), lab_otkliki_ and_inviting (1.61), sum_otklik (1.09), lab_selected_subject (1.37), lab_filter_v__critical (1.08) <br><br>  SuperProducts: lab_contact_information (1.78), desc_address (1.46), rep_name_4es (1.84), sum_address (1.74), lab_socon__ vacancies (1.68), lab_assigned_sum (1.45), lab_otcli__worker (1.29), lab_otclik_worker (1.29), lab_otclik_worker (1.45), lab_otclik_worker (1.29), sum_right (1.164), lab_responses_ employer (1.29), sum_right (1.164), 45 (5.9), lab_otclik_worker (1.29), sum_right (1.4),  (5.4), 45 (45), (1.45), lab_otcli__customer (1.29), sum_right (1.4),  (5.4), 45 (45), lab_truck__custom (1.28), lab__call_reference (1.45), lab__response_ (0.93) ), sum_fault (1.33), rep_name_42 (1.32), sum_quot (1.14), desc_address_ofis (1.14), rep_name_51 (1.09) <br></div></div><br>  Signs roughly reflect what teams do <br><br><h4>  Use model </h4><br>  On this, the construction of the model is completed and it is possible to build a program on its basis. <br><img src="https://habrastorage.org/webt/9s/ij/sv/9sijsvxxgsk6vi9k1gx1erzolzk.jpeg"><br><br>  The program consists of two Python scripts.  The first builds the model, and the second fulfills the predictions. <br><br><ol><li>  Jira provides an API through which you can download already solved tasks (HHS).  Once a day the script is launched and downloads them. </li><li>  The downloaded data is converted into signs.  First, the data is beaten for training and test data and is fed into the ML model for validation in order to ensure that the quality does not start to fall from start to start.  And then the second time the model is trained on all data.  The whole process takes about 10 minutes. </li><li>  The trained model is saved to the hard disk.  I used the <a href="https://pypi.org/project/dill/">dill</a> utility to serialize objects.  In addition to the model itself, you must also save all the objects that were used to obtain the signs.  This is to get the signs in the same space for new HHS </li><li>  Using the same dill, the model is loaded into a prediction script, which runs every 5 minutes. </li><li>  Go to Jira for new HHS. </li><li>  We get the signs and transfer them to the model, which will return for each HHS class name - the name of the team. </li><li>  For the team we find the person in charge and assign him a task through the Jira API.  They may be a tester, if a team does not have a tester, then a team leader. </li></ol><br>  To make the program easy to deploy and have the same versions of libraries as during development, scripts are packaged in a Docker container. <br><br>  As a result, we have automated the routine process.  The accuracy of 76% is not too big, but in this case the misses are not critical.  All tasks find their performers, and the most important thing is that for this you no longer need to be distracted several times a day in order to delve into the essence of the tasks and look for those responsible.  Everything works automatically!  Hooray! </div><p>Source: <a href="https://habr.com/ru/post/457418/">https://habr.com/ru/post/457418/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../457408/index.html">Welcome to DINS Java EVENING June 26</a></li>
<li><a href="../45741/index.html">Laptop for life</a></li>
<li><a href="../457410/index.html">Acronis Foundation: schools have already been built in 8 countries. Are you with us?</a></li>
<li><a href="../457412/index.html">Cookie banners: how to quickly verify compliance with the GDPR</a></li>
<li><a href="../457414/index.html">Be remote: distributed teams - a trend in practice</a></li>
<li><a href="../45742/index.html">P4X: E4X Convenience in Python</a></li>
<li><a href="../457420/index.html">KPI technical support Miran</a></li>
<li><a href="../457422/index.html">Application architecture or how to spoil karma on Habr√©</a></li>
<li><a href="../457424/index.html">Set for playing laser tag. Dedicated to those who played the war</a></li>
<li><a href="../45743/index.html">Habraquest - issue number 1. The prize is an invite to habr! - completed</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>