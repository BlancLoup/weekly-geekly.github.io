<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ROS Workshop 2016: analysis of the task of safe robot control</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Good afternoon, dear habrachiteli! Last Friday, a practical workshop on the ROS platform - ROS workshop was held in our laboratory. The workshop was o...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>ROS Workshop 2016: analysis of the task of safe robot control</h1><div class="post__text post__text-html js-mediator-article">  Good afternoon, dear habrachiteli!  Last Friday, a practical workshop on the ROS platform - ROS workshop was held in our laboratory.  The workshop was organized for students of the Faculty of Information Technology of the Technical University of Brno, wishing to get acquainted with this platform.  Unlike previous years (the workshop has been held for 4 years), this time the ROS workshop was focused on independent practical work.  In the article I am going to talk about the task that was set for the participants of the workshop.  Who cares, I ask under the cat. <br><a name="habracut"></a><br><img src="https://habrastorage.org/files/adb/af3/ada/adbaf3ada3884849814224c24ca89ce7.JPG" alt="image"><br><br><h3>  Formulation of the problem </h3><br>  The participants were tasked to implement the safe control of the robot with a stop in front of obstacles.  The objective of the task is to control the speed of the robot moving forward.  The robot receives data from the depth sensor (in our case, ASUS Xtion in the simulator turtlebot_gazebo), finds the nearest obstacle in the direction of motion and determines three zones: <br><br><ul><li>  Safe - the robot at a safe distance, moving without slowing down </li><li>  Warning - the robot approaches an obstacle, issues a warning signal (for example, a sound signal) and slows down. </li><li>  Danger - the obstacle is very close, the robot stops </li></ul><br><h3>  Implementation </h3><br>  Immediately, I note that the workshop used ROS Indigo on Ubuntu 14.04 to complete the task.  I also used ROS Indigo for experiments. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      So, let's begin!  Create a package with roscpp, pcl_ros, pcl_conversions, sensor_msgs and geometry_msgs dependencies: <br><br><pre><code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> ~/catkin_ws/src catkin_create_pkg safety_control_cloud roscpp pcl_ros pcl_conversions sensor_msgs geometry_msgs <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> ~/catkin_ws</code> </pre> <br>  Add PCL dependencies to package.xml: <br><br><pre> <code class="xml hljs"><span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">build_depend</span></span></span><span class="hljs-tag">&gt;</span></span>libpcll-all-dev<span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">build_depend</span></span></span><span class="hljs-tag">&gt;</span></span> ... <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">run_depend</span></span></span><span class="hljs-tag">&gt;</span></span>libpcl-all<span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">run_depend</span></span></span><span class="hljs-tag">&gt;</span></span></code> </pre><br>  and in CMakeLists.txt: <br><br><pre> <code class="bash hljs">find_package(PCL REQUIRED) ... include_directories(<span class="hljs-variable"><span class="hljs-variable">${PCL_INCLUDE_DIRS}</span></span>)</code> </pre><br>  Add the safety_control.cpp script to the src folder: <br><br><div class="spoiler">  <b class="spoiler_title">safety_control.cpp</b> <div class="spoiler_text"><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">include</span></span></span><span class="hljs-meta"> </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">"ros/ros.h"</span></span></span><span class="hljs-meta"> #</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">include</span></span></span><span class="hljs-meta"> </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">"pcl_conversions/pcl_conversions.h"</span></span></span><span class="hljs-meta"> #</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">include</span></span></span><span class="hljs-meta"> </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;pcl/pcl_base.h&gt; #include &lt;sstream&gt; #include &lt;sensor_msgs/PointCloud2.h&gt; #include &lt;pcl/filters/passthrough.h&gt; #include &lt;pcl/common/common.h&gt; #include &lt;geometry_msgs/Twist.h&gt; typedef pcl::PointXYZ PointType; typedef pcl::PointCloud&lt;PointType&gt; PointCloud; typedef PointCloud::Ptr PointCloudPtr; ros::Publisher pcd_pub_, cmd_vel_pub_; void pcd_cb(const sensor_msgs::PointCloud2ConstPtr&amp; pcd) { ROS_INFO_STREAM_ONCE("Point cloud arrived"); PointCloudPtr pcd_pcl = PointCloudPtr(new PointCloud), pcd_filtered = PointCloudPtr(new PointCloud); PointType pt_min, pt_max; pcl::fromROSMsg(*pcd, *pcd_pcl); pcl::PassThrough&lt;PointType&gt; pass; pass.setInputCloud(pcd_pcl); pass.setFilterFieldName("y"); pass.setFilterLimits(-0.25,0.20); pass.filter(*pcd_filtered); pass.setInputCloud(pcd_filtered); pass.setFilterFieldName("x"); pass.setFilterLimits(-0.3,0.3); pass.filter(*pcd_pcl); pcl::getMinMax3D(*pcd_pcl, pt_min, pt_max); geometry_msgs::Twist vel; if (pt_min.z &gt; 1.0) { vel.linear.x = 0.2; ROS_INFO_STREAM("Safe zone"); } else if (pt_min.z &gt; 0.5) { vel.linear.x = 0.1; ROS_INFO_STREAM("Warning zone"); } else { vel.linear.x = 0.0; ROS_INFO_STREAM("Danger zone"); } cmd_vel_pub_.publish(vel); sensor_msgs::PointCloud2 pcd_out; pcl::toROSMsg(*pcd_pcl, pcd_out); pcd_pub_.publish(pcd_out); } int main(int argc, char **argv) { /** * The ros::init() function needs to see argc and argv so that it can perform * any ROS arguments and name remapping that were provided at the command line. * For programmatic remappings you can use a different version of init() which takes * remappings directly, but for most command-line programs, passing argc and argv is * the easiest way to do it. The third argument to init() is the name of the node. * * You must call one of the versions of ros::init() before using any other * part of the ROS system. */ ros::init(argc, argv, "safety_control_cloud"); /** * NodeHandle is the main access point to communications with the ROS system. * The first NodeHandle constructed will fully initialize this node, and the last * NodeHandle destructed will close down the node. */ ros::NodeHandle n; ros::Subscriber pcd_sub = n.subscribe("/camera/depth/points", 1, pcd_cb); pcd_pub_ = n.advertise&lt;sensor_msgs::PointCloud2&gt;("/output", 1); cmd_vel_pub_ = n.advertise&lt;geometry_msgs::Twist&gt;("/cmd_vel_mux/input/teleop", 1); ros::spin(); return 0; }</span></span></span></span></code> </pre><br></div></div><br>  Add the safety_control.cpp script to CMakeLists.txt: <br><br><pre> <code class="bash hljs">add_executable(safety_control_node src/safety_control.cpp) target_link_libraries(safety_control_node <span class="hljs-variable"><span class="hljs-variable">${catkin_LIBRARIES}</span></span> <span class="hljs-variable"><span class="hljs-variable">${PCL_LIBRARIES}</span></span>)</code> </pre><br>  In the node logic, we subscribe to the data from the topic / camera / depth / points, get a point cloud, calculate the coordinates of the nearest point to the depth sensor in the point cloud and, depending on the situation, publish a linear velocity such as geometry_msgs / Twister in the topic / cmd_vel_mux / input / teleop . <br><br>  We also need to cut a cloud of points in several axes in a certain range for more efficient processing.  In the following lines: <br><br><pre> <code class="cpp hljs">pcl::PassThrough&lt;PointType&gt; pass; pass.setInputCloud(pcd_pcl); pass.setFilterFieldName(<span class="hljs-string"><span class="hljs-string">"y"</span></span>); pass.setFilterLimits(<span class="hljs-number"><span class="hljs-number">-0.25</span></span>,<span class="hljs-number"><span class="hljs-number">0.20</span></span>); pass.filter(*pcd_filtered);</code> </pre><br>  we cut the cloud with the <a href="http://pointclouds.org/documentation/tutorials/passthrough.php">PassThrough</a> method 25 cm down and 20 cm up from the beginning of the coordinate system of the depth sensor (along the y axis). <br><br>  In the rows: <br><br><pre> <code class="cpp hljs">pass.setInputCloud(pcd_filtered); pass.setFilterFieldName(<span class="hljs-string"><span class="hljs-string">"x"</span></span>); pass.setFilterLimits(<span class="hljs-number"><span class="hljs-number">-0.3</span></span>,<span class="hljs-number"><span class="hljs-number">0.3</span></span>); pass.filter(*pcd_pcl);</code> </pre><br>  Cut the cloud by 0.3 m (30 cm) left and right from the beginning of the coordinate system of the sensor (z axis).  Then we look for the closest point in the point cloud along the z axis (axis from the center of the depth sensor in the direction of view) - this will be the point of the nearest object: <br><br><pre> <code class="cpp hljs">pcl::getMinMax3D(*pcd_pcl, pt_min, pt_max);</code> </pre><br>  The speed will also be published on the / mobile_base / commands / velocity topic.  Compile the package: <br><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> ~/catkin_ws catkin_make <span class="hljs-built_in"><span class="hljs-built_in">source</span></span> devel/setup.bash</code> </pre> <br><h3>  Testing in the simulator Turtle Bot in Gazebo </h3><br>  The second task was to test the robot control logic with the TurtleBot simulator in Gazebo.  For this you need to install <a href="http://wiki.ros.org/turtlebot_gazebo%3Fdistro%3Dindigo">turtlebot_gazebo</a> using apt-get: <br><br><pre> <code class="bash hljs">sudo apt-get install ros-indigo-turtlebot*</code> </pre><br>  <a href="http://wiki.ros.org/turtlebot_gazebo/Tutorials">Here</a> you can find some useful tutorials on using the simulator.  A simulator can be a good solution when you want to study the navigation packages in ROS and there is no real robot at hand.  Run the simulator: <br><br><pre> <code class="bash hljs">roslaunch turtlebot_gazebo turtlebot_world.launch</code> </pre><br>  The Gazebo window will open as in the picture: <br><br><img src="https://habrastorage.org/files/ba6/af9/a0a/ba6af9a0a6454d9bbe8013370a298b6f.png" alt="image"><br><br>  We can zoom in and out with the mouse wheel.  Using the left mouse button and the cursor, we can move the image left, right, up and down.  Using the mouse wheel and the cursor, you can change the vertical viewing angle.  Now we turn the robot to look directly at the cabinet.  In the top row of tools above the simulation viewing window, select the third icon: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/ea9/387/cf3/ea9387cf3f8f4444af77d1cfb6f34da4.png" alt="image"></div><br>  And click on it.  We will see something like this. <br><br><img src="https://habrastorage.org/files/c3e/a1d/0a8/c3ea1d0a89dd4377a1859b6837c5ac6f.png" alt="image"><br><br>  Rotate the robot by clicking and pulling the blue arc.  We get this picture: <br><br><img src="https://habrastorage.org/files/ff1/7a2/f95/ff17a2f9577c487aaeaa670eef731913.png" alt="image"><br><br>  Run rviz: <br><br><pre> <code class="bash hljs">rosrun rviz rviz</code> </pre><br>  Add a RobotModel display, as already described in the <a href="https://geektimes.ru/post/278864/">article</a> .  Add the PointCloud2 display and choose the topic / camera / depth / points.  As a result, we get the following picture: <br><br><img src="https://habrastorage.org/files/5cf/69e/48b/5cf69e48b16c4380bd29fdd02c0b5f94.png" alt="image"><br><br>  For the PointCloud2 display, select RGB8 for the Color Transformer field.  We get a cloud of dots in color: <br><br><img src="https://habrastorage.org/files/f16/3df/34e/f163df34e9934306a68294a4613293df.png" alt="image"><br><br>  Run our safety_control_node node: <br><br><pre> <code class="bash hljs">rosrun safety_control_cloud safety_control_node</code> </pre><br>  The output in the terminal will be: <br><br><pre> <code class="bash hljs">[ INFO] [1479229421.537897080, 2653.960000000]: Point cloud arrived [ INFO] [1479229421.572338588, 2654.000000000]: Warning zone [ INFO] [1479229421.641967924, 2654.070000000]: Warning zone</code> </pre><br>  Let's display the list of topics: <br><br><pre> <code class="bash hljs">rostopic list</code> </pre><br>  Among the topics we will see: <br><br><pre> <code class="bash hljs">/cmd_vel_mux/input/teleop ... /mobile_base/commands/velocity</code> </pre><br>  Show messages in the topic / mobile_base / commands / velocity: <br><br><pre> <code class="bash hljs">rostopic <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> /mobile_base/commands/velocity</code> </pre><br>  We get the speed of the robot: <br><br><pre> <code class="bash hljs">linear: x: 0.1 y: 0.0 z: 0.0 angular: x: 0.0 y: 0.0 z: 0.0 ---</code> </pre><br>  The robot will move towards the cabinet and finally stop next to the cabinet in the Danger zone.  In Gazebo we will see a complete stop of the robot: <br><br><img src="https://habrastorage.org/files/d73/5a0/f1b/d735a0f1b272435ca8214cbf3c4099e0.png" alt="image"><br><br>  In the output for the safety_control_node node, we see the messages <br><br><pre> <code class="bash hljs">[ INFO] [1479229426.604300460, 2658.980000000]: Danger zone [ INFO] [1479229426.717093096, 2659.100000000]: Danger zone</code> </pre><br>  And the topic / mobile_base / commands / velocity will now publish a message with zero speed: <br><br><pre> <code class="bash hljs">linear: x: 0.0 y: 0.0 z: 0.0 angular: x: 0.0 y: 0.0 z: 0.0 ---</code> </pre><br>  Add a PointCloud2 type display with a / output topic in rviz.  For the Color Transformer display, select the FlatColor value and the green color in the Color field.  This will be our cut of the point cloud from the safety_control_node node: <br><br><img src="https://habrastorage.org/files/963/734/27f/96373427fbbf4be18b5ae9d169beb3e4.png" alt="image"><br><br>  Move the robot further away, to a safe distance from the obstacle.  To do this, click the second icon at the top: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/c9a/2d9/1be/c9a2d91be85a470fb0bdb439154c10df.png" alt="image"></div><br>  and move the robot by dragging it with the cursor: <br><br><img src="https://habrastorage.org/files/d79/52b/a4f/d7952ba4fb704a5fa1b410dc5ace2c6c.png" alt="image"><br><br>  In rviz we will see the following: <br><br><img src="https://habrastorage.org/files/af5/c49/5fb/af5c495fb9784a638b9ef6e73a601e7e.png" alt="image"><br><br>  We will receive such messages from our site: <br><br><pre> <code class="bash hljs">[ INFO] [1479230429.902116395, 3658.000000000]: Safe zone [ INFO] [1479230429.992468971, 3658.090000000]: Safe zone</code> </pre><br>  The speed of the robot will be: <br><br><pre> <code class="bash hljs">--- linear: x: 0.2 y: 0.0 z: 0.0 angular: x: 0.0 y: 0.0 z: 0.0 ---</code> </pre><br>  Then everything described earlier will be repeated: a slowdown in the warning zone and a stop near the cabinet. <br><br>  Now our robot TurtleBot is able to stop in front of any obstacle that the depth sensor is able to detect (ASUS Xtion in the case of ROS Indigo).  You can try the control program on a real robot equipped with a Microsoft Kinect type sensor. <br><br>  That's all.  We wrote a simple program to control the speed of the robot in the forward direction using the data from the depth sensor - a cloud of points - and tested it on the simulator of the TurtleBot robot in Gazebo. <br><br>  Good luck in your experiments and see you soon! </div><p>Source: <a href="https://habr.com/ru/post/399151/">https://habr.com/ru/post/399151/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../399141/index.html">Will Amazon eat grocery stores for lunch?</a></li>
<li><a href="../399143/index.html">Berkshire Hathaway for the Internet</a></li>
<li><a href="../399145/index.html">Scientists have studied the connection between using a smartphone and worsening sleep.</a></li>
<li><a href="../399147/index.html">US military testing electrical brain stimulation to improve multitasking</a></li>
<li><a href="../399149/index.html">Wi-Fi monitors you, or Wi-Fi as a monitoring system</a></li>
<li><a href="../399153/index.html">PlayStation 4 Pro: ahead of the steam locomotive</a></li>
<li><a href="../399155/index.html">MegaFon shareholders and Mail.ru Group discuss the possibility of a merger</a></li>
<li><a href="../399157/index.html">Four industries that are about to change thanks to blockchain</a></li>
<li><a href="../399159/index.html">Backblaze has released a hard drive report for the third quarter of 2016.</a></li>
<li><a href="../399161/index.html">HyperX Cloud Stinger headset: comfort and great connectivity for reasonable money</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>