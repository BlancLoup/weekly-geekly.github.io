<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Apache Parquet performance</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="A bad example of a good test. 


 Recently, there have been frequent discussions in smoking rooms on the topic of comparing the performance of various...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Apache Parquet performance</h1><div class="post__text post__text-html js-mediator-article"><h3>  A bad example of a good test. </h3><br><p>  Recently, there have been frequent discussions in smoking rooms on the topic of comparing the performance of various data storage formats in Apache Hadoop - including CSV, JSON, Apache Avro and Apache Parquet.  Most participants immediately dismiss text formats as obvious outsiders, leaving the main intrigue to the contest between Avro and Parquet. </p><br><p>  The prevailing opinions were unconfirmed rumors that one format looked ‚Äúbetter‚Äù when working with the whole dataset, while the second ‚Äúbetter‚Äù handled requests for a subset of columns. </p><br><p>  Like any self-respecting engineer, I thought that it would be nice to conduct full-fledged performance tests to finally check on which side the truth is.  The result of the comparison is under the cut. </p><br><p><img src="https://habrastorage.org/files/f05/7a3/461/f057a3461573447fa4417ace4d78b5df.png" alt="Apache Parquet Logo"><a name="habracut"></a></p><br><blockquote>  <strong>Translator's Note:</strong> <br>  Initially, the article was conceived as a free translation of Don Drake's text ( <a href="https://twitter.com/dondrake">@dondrake</a> ) for the <a href="http://blog.cloudera.com/">Cloudera Engineering Blog</a> on the experience of comparing <a href="https://avro.apache.org/">Apache Avro</a> and <a href="https://parquet.apache.org/">Apache Parquet</a> using <a href="https://spark.apache.org/">Apache Spark</a> .  However, in the process of translation, I went deep into details and found a lot of controversial points in the tests.  I added a subtitle to the article, and the text provided comments with maliciously inaccuracies. </blockquote><br><h3>  Test dataset </h3><br><p>  I thought that for tests it would be correct to use real data and real requests.  In this case, it can be expected that the performance in the production environment will behave similarly to the test one.  In other words, for the test, it is not enough to count the lines on the surrogate data. </p><br><blockquote>  The choice of "real data" and "real requests" for the test seems to be a highly controversial idea, since  Everyone has different real data and requests.  To solve this problem, typical storage performance tests are synthesized, for example, <a href="http://www.tpc.org/">TPC Benchmarks</a> . </blockquote><br><p>  I rummaged through the datasets I recently worked with and found two excellent ones for the test.  The first of them, let's call it "narrow", consists of only three columns and contains 82.3 million lines, which in the CSV is 3.9 GB. </p><br><blockquote>  As will be seen below, this will result in 750-1000 MB of serialized data, and it will be processed into 50 workers.  Each worker will get 15-20 MB of data.  Most likely, the initialization of the worker will take longer than reading and processing data. </blockquote><br><p>  The second one, let's call it ‚Äúwide‚Äù, contains 103 columns and 694 million lines, which gives a CSV file of 194 GB in size.  I think this approach will allow us to assess which format works best with large and small files. </p><br><blockquote>  "Wide" dataset is not only 30 times wider, but 8 times longer.  And 49 times the original size.  It is more correct to call datasets "small" and "large". <br>  In addition, judging by the size ratio, it seems that columns of different types are represented in datasets.  In this paper, differences in data types are generally ignored.  Meanwhile, this is a key aspect of the storage format. </blockquote><br><h3>  Test Methodology </h3><br><p>  I chose Apache Spark 1.6 as a workhorse for tests.  Spark supports Parquet out of the box, support for Avro and CSV is connected separately.  All operations were performed on a CDH 5.5.x cluster of 100+ machines. </p><br><p>  I was interested in measuring the performance of formats on various types of processing - downloads, simple requests, non-trivial requests, processing of a whole dataset, as well as the amount of disk space used. </p><br><p> I ran tests through a <code>spark-shell</code> with the same configuration for both datasets (the only difference was in the number of executors).  Shell mode <code>:paste</code> saved my life by allowing me to copy the Scala code directly into the REPL, without worrying about multi-line commands that might confuse the interpreter. </p><br><pre> <code class="hljs tex">#!/bin/bash -x # Drake export HADOOP_CONF_DIR=/etc/hive/conf export SPARK_HOME=/home/drake/coolstuff/spark/spark-1.6.0-bin-hadoop2.6 export PATH=<span class="hljs-formula"><span class="hljs-formula">$SPARK_HOME/bin:$</span></span>PATH # use Java8 export JAVA_HOME=/usr/java/latest export PATH=<span class="hljs-formula"><span class="hljs-formula">$JAVA_HOME/bin:$</span></span>PATH # NARROW NUM_EXECUTORS=50 # WIDE NUM_EXECUTORS=500 spark-shell ‚Äîmaster yarn-client <span class="hljs-tag"><span class="hljs-tag">\</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name"> </span></span></span></span>‚Äîconf spark.eventLog.enabled=true <span class="hljs-tag"><span class="hljs-tag">\</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name"> </span></span></span></span>‚Äîconf spark.eventLog.dir=hdfs://nameservice1/user/spark/applicationHistory <span class="hljs-tag"><span class="hljs-tag">\</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name"> </span></span></span></span>‚Äîconf spark.yarn.historyServer.address=http://yarnhistserver.allstate.com:18088 <span class="hljs-tag"><span class="hljs-tag">\</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name"> </span></span></span></span>‚Äîpackages com.databricks:spark-csv_2.10:1.3.0,com.databricks:spark-avro_2.10:2.0.1 <span class="hljs-tag"><span class="hljs-tag">\</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name"> </span></span></span></span>‚Äîdriver-memory 4G <span class="hljs-tag"><span class="hljs-tag">\</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name"> </span></span></span></span>‚Äîexecutor-memory 2G <span class="hljs-tag"><span class="hljs-tag">\</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name"> </span></span></span></span>‚Äînum-executors <span class="hljs-formula"><span class="hljs-formula">$NUM_EXECUTORS </span><span class="hljs-tag"><span class="hljs-formula"><span class="hljs-tag">\</span></span><span class="hljs-name"><span class="hljs-formula"><span class="hljs-tag"><span class="hljs-name"> </span></span></span></span></span><span class="hljs-formula">...</span></span></code> </pre> <br><p>  I took the query execution time from the Job tab in the Spark Web UI.  I repeated each test three times and then calculated the average time.  Requests to a narrow dataset were performed on a relatively loaded cluster, while requests to a wide dataset were executed during the moments of complete cluster idleness.  It did not happen on purpose, rather, it is a coincidence. </p><br><blockquote>  Using different environments between tests (including a different number of workers and a different cluster workload) makes it impossible to compare absolute values. <br>  The use of a loaded cluster in itself negatively affects the reproducibility of the measurement results when it is restarted ‚Äî they simply cannot be trusted. <br>  A three-time repetition of the experiment looks statistically frivolous - the confidence interval of the assessment will be very large.  However, the author does not even mention the confidence intervals. </blockquote><br><h3>  Data preprocessing </h3><br><p>  When reading a narrow dataset from CSV, I didn‚Äôt draw diagrams, but I had to convert a <code>String</code> column to a <code>Timestamp</code> .  I did not include the time for this conversion in the result, since  it does not apply to storage formats.  When working with a wide dataset, I used the output of the circuit, but I also did not take into account the time for this. </p><br><blockquote>  The schema output (in the original - <em>infer schema</em> ) is implicit conversion from <code>RDD</code> to <code>DataFrame</code> using Reflection. </blockquote><br><p>  During the testing process, I was surprised to learn that you cannot save an Avro file with a Timestamp column.  In fact, Avro versions 1.7.x basically does not support either <code>Date</code> or <code>Timestamp</code> . </p><br><blockquote>  Avro 1.8 <a href="https://avro.apache.org/docs/current/spec.html">supports the</a> logical types <code>Date</code> , <code>Timestamp</code> and their derivatives.  In essence, they are just a wrapper over <code>int</code> or <code>long</code> . </blockquote><br><h3>  Test "narrow" dataset </h3><br><p>  To begin with, I estimated the time over which a narrow dataset can be written to disk in Avro or Parquet format.  I counted only the effective time to write, after the data was read into the data frame.  It turned out the difference within the statistical error.  Thus, the recording performance of a narrow dataset is approximately the same for both formats. </p><br><blockquote>  The serialization time was incredibly large, even taking into account the possible network overhead and so on - after all, one worker has less than 20 MB of output. <br>  It looks as if the author incorrectly separated the time for reading and processing and the time for writing.  In this case, it may well turn out that most of this time is reading a 4-gigabyte CSV file, perhaps even in one stream.  And everything else takes 5-10 seconds. </blockquote><br><p>  The recording time on a narrow dataset disk, in seconds (the smaller, the better): <br><img src="http://blog.cloudera.com/wp-content/uploads/2016/04/avro-parquet-f1.png" alt="narrow save as"></p><br><p>  After that, I looked at how long it took to calculate the number of rows in a narrow dataset.  Avro and Parquet worked equally fast [^ fast-row-count].  For comparison and to intimidate readers, I also calculated the time for counting uncompressed CSV. </p><br><blockquote>  Parquet files contain the number of objects in the block in the metadata.  With this ratio of data volume per worker each gets no more than one Parquet block.  Thus, for counting, it is enough for everyone to read one number, and then make a general reduce to get the total amount. <br>  For Avro, the task is much more complicated - Avro blocks also contain the number of objects in a block, but the blocks themselves are much smaller ( <a href="https://avro.apache.org/docs/1.7.6/api/java/org/apache/avro/io/EncoderFactory.html">64 KB by default</a> ), and the file contains many blocks.  Theoretically, the counting time for all objects in the avro file should be longer.  In practice, for such small files, the difference can be overlooked. <br>  To count the number of lines in a CSV file, you must fully read this file, as is the case with Avro.  If you shard a 4 GB file correctly, each worker has 80 MB of data, which can be read in a few seconds.  However, the author‚Äôs reading process takes 45 seconds, which testifies to the fact that the file is not parallelized enough. </blockquote><br><p>  The time of counting the number of rows in a narrow dataset, in seconds (the smaller, the better): <br><img src="http://blog.cloudera.com/wp-content/uploads/2016/04/avro-parquet-f2.png" alt="narrow row count"></p><br><p>  After I tried a more complex query with <code>GROUP BY</code> grouping.  One of the columns in this dataset is a time stamp, and I calculated the amount on another column for each day.  Since  Avro does not support <code>Date</code> and <code>Timestamp</code> , I had to correct the request in order to get a similar result. </p><br><p>  Parquet Request: </p><br><pre> <code class="hljs sql">val sums = sqlContext.sql("""<span class="hljs-keyword"><span class="hljs-keyword">select</span></span> <span class="hljs-keyword"><span class="hljs-keyword">to_date</span></span>(precise_ts) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> <span class="hljs-keyword"><span class="hljs-keyword">day</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">sum</span></span>(replacement_cost) <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> narrow_parq <span class="hljs-keyword"><span class="hljs-keyword">group</span></span> <span class="hljs-keyword"><span class="hljs-keyword">by</span></span> <span class="hljs-keyword"><span class="hljs-keyword">to_date</span></span>(precise_ts) <span class="hljs-string"><span class="hljs-string">""")</span></span></code> </pre> <br><p>  Request for Avro query: </p><br><pre> <code class="hljs sql">val a_sums = sqlContext.sql("""<span class="hljs-keyword"><span class="hljs-keyword">select</span></span> <span class="hljs-keyword"><span class="hljs-keyword">to_date</span></span>(from_unixtime(precise_ts/<span class="hljs-number"><span class="hljs-number">1000</span></span>)) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> <span class="hljs-keyword"><span class="hljs-keyword">day</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">sum</span></span>(replacement_cost) <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> narrow_avro <span class="hljs-keyword"><span class="hljs-keyword">group</span></span> <span class="hljs-keyword"><span class="hljs-keyword">by</span></span> <span class="hljs-keyword"><span class="hljs-keyword">to_date</span></span>(from_unixtime(precise_ts/<span class="hljs-number"><span class="hljs-number">1000</span></span>)) <span class="hljs-string"><span class="hljs-string">""")</span></span></code> </pre> <br><p>  For a request with the Parquet grouping, Avro turned out to be 2.6 times faster: <br><img src="http://blog.cloudera.com/wp-content/uploads/2016/04/avro-parquet-f3.png" alt="narrow group by"></p><br><p>  Next, I decided to perform a <code>.map()</code> <code>DataFrame</code> on a <code>DataFrame</code> e to simulate the processing of the entire dataset.  I chose a transformation that counts the number of columns in a row and collects all their unique values. </p><br><pre> <code class="hljs pgsql">def numCols(x: <span class="hljs-keyword"><span class="hljs-keyword">Row</span></span>): <span class="hljs-type"><span class="hljs-type">Int</span></span> = { x.length } val numColumns = narrow_parq.rdd.map(numCols).<span class="hljs-keyword"><span class="hljs-keyword">distinct</span></span>.collect</code> </pre> <br><blockquote>  The <code>.distinct()</code> operation significantly complicates the task.  For simplicity, we can assume that it adds the reduce phase to the process, which in itself means that not only the <code>.map()</code> is measured for the entire dataset, but also the overhead to the data exchange between the workers. </blockquote><br><p>  This is not exactly the task that will be performed during actual data processing, but nevertheless, it forces the entire dataset to process.  And again Parquet turns out to be almost 2 times faster Avro: <br><img src="http://blog.cloudera.com/wp-content/uploads/2016/04/avro-parquet-f4.png" alt="narrow map"></p><br><p>  The last thing that needs to be done is to compare the dimensions of the dataset on the disk.  The graph shows the size in bytes.  Avro was configured to use the Snappy compression codec, and the default settings were used for Parquet. </p><br><p>  Dataset in Parquet turned out to be less than 25% Avro. <br><img src="http://blog.cloudera.com/wp-content/uploads/2016/04/avro-parquet-f5.png" alt="narrow disk usage"></p><br><blockquote>  Using the default compression settings and not even looking at them is a very bad practice. <br>  However, Parquet <a href="http://spark.apache.org/docs/latest/sql-programming-guide.html">uses gzip by default</a> .  Gzip squeezes noticeably stronger than Snappy.  Suddenly the difference in size is due exclusively to different codecs?  For correct comparison, you need to calculate the dimensions of datasets using the same compression or without it at all. <br>  Also for fairness it should be noted that usually a text file can be compressed at times.  I admit that aggressively gzip-avanny source CSV-file will take no more than 1.5 GB.  So the advantage of binary formats will not be so dramatic. </blockquote><br><h3>  Test "wide" dataset </h3><br><p>  I performed similar operations on a large "wide" dataset.  Let me remind you that this dataset contains 103 columns and 694 million lines, which translates into 194 GB of uncompressed CSV file. </p><br><blockquote>  And I, running ahead, will inform you that this translates into 5 GB Parquet and 17 GB Avro.  With 500 workers, we have a load of 100 MB for Parquet or 340 MB for Avro.  By compact storage won, of course, Parquet.  But in Avro files more blocks came out, which means that their processing speed can be increased by increasing the number of workers.  So, if the cluster is not loaded into the ceiling and the number of workers is dynamically calculated, Avro can achieve better performance than in these tests. </blockquote><br><p>  First, I measured the time to save a wide dataset in both formats.  Parquet every time was faster Avro: <br><img src="http://blog.cloudera.com/wp-content/uploads/2016/04/avro-parquet-f6.png" alt="wide save as"></p><br><p>  In counting the number of lines, Parquet utterly crashed Avro, producing a result in less than 3 seconds: <br><img src="http://blog.cloudera.com/wp-content/uploads/2016/04/avro-parquet-f7.png" alt="wide row count"></p><br><blockquote>  Parquet by default uses a block size of <a href="https://github.com/Parquet/parquet-mr/commit/808a90d9a11a3f17caf3dcdbd461d5b6bfda15e7">128 MB</a> , which is larger than the average amount of data per worker.  Thus, when working with Parquet, the trick from the ‚Äúnarrow‚Äù dataset continues to operate, when to calculate the number of rows in a dataset, it suffices to read one number from the metadata. <br>  For Avro files, you have to do a full dataset reading, interpreting only the metadata of each block and skipping (without deserializing) the data itself.  This translates into a "real" disc work.  For CSV, the situation is even worse - there you have to parse every byte. </blockquote><br><p>  For more complex <code>GROUP BY</code> queries, Parquet again takes the lead: <br><img src="http://blog.cloudera.com/wp-content/uploads/2016/04/avro-parquet-f8.png" alt="wide group by"></p><br><blockquote>  Here it is worth remembering that it is possible to run 3.4 times more workers for Avro.  Will Parquet then keep the lead? </blockquote><br><p>  And even for <code>.map()</code> transformations of the entire dataset Parquet wins again with a convincing margin: <br><img src="http://blog.cloudera.com/wp-content/uploads/2016/04/avro-parquet-f9.png" alt="wide map"></p><br><blockquote>  And here it is also worth remembering that it is possible to run 3.4 times more workers for Avro.  And what share in the operation time of the operation does <code>.distinct()</code> , and which share is actually reading from the disk? </blockquote><br><p>  The last test, a test of disk utilization efficiency, showed impressive results for both participants.  Parquet was able to compress the original 194 GB to 4.7 GB, providing a grand compression above 97%.  Avro also showed impressive results, compressing data to 16.9 GB (91% compression).  Applaud to both participants: <br><img src="http://blog.cloudera.com/wp-content/uploads/2016/04/avro-parquet-f10.png" alt="wide disk usage"></p><br><h3>  Conclusion </h3><br><p>  As a result, Parquet showed at least not the worst performance on each test.  With increasing data volume, its advantage became apparent.  Parquet partially owes its good results to better compression efficiency, since Avro had to read 3.5 times more than Parquet.  And Avro did not show that high performance when reading the entire dataset, which attributed to him rumor. </p><br><p>  When you have to choose the storage format in Hadoop, you need to take into account many factors, such as integration with third-party applications, circuit evolution, support for specific data types ... But if you put performance at the forefront, then the tests above clearly show that Parquet is your best choice . </p><br><blockquote>  And from myself add.  This is a good measure of the performance of formats.  It is confirmed by numerous isolated observations from the industrial experience of our team.  Nevertheless, the testing methodology distorts measurements with outside actions (reading CSV, <code>GROUP BY', '.distinct()</code> , ...), and sometimes completely ignores important issues (compression, data formats, ...).  I realize that it is not easy to do a canonical test with "distilled" metrics.  But from Cloudera's blog, I was expecting that. </blockquote></div>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <p>Source: <a href="https://habr.com/ru/post/282552/">https://habr.com/ru/post/282552/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../282542/index.html">El-get, ELPA, MELPA and automatic package installation</a></li>
<li><a href="../282544/index.html">Garbage Collector & C ++</a></li>
<li><a href="../282546/index.html">Intel ME. How to avoid the uprising of cars?</a></li>
<li><a href="../282548/index.html">How to test antivirus software</a></li>
<li><a href="../282550/index.html">About coordination of changes in time zones</a></li>
<li><a href="../282556/index.html">Cocos creator</a></li>
<li><a href="../282558/index.html">We invite you to the conference on artificial intelligence and big data AI & BigData Lab June 4</a></li>
<li><a href="../282560/index.html">Big Data: Silver Bullet or another tool</a></li>
<li><a href="../282564/index.html">Driver anatomy</a></li>
<li><a href="../282566/index.html">Who is faster: "clouds" vs "IT market"?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>