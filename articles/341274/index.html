<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Graylog2 incremental setup</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="In the first article of this series, I explained how and why we chose open-sourced Graylog2 for the centralized collection and viewing of logs in the ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Graylog2 incremental setup</h1><div class="post__text post__text-html js-mediator-article"><img src="https://habrastorage.org/webt/jm/fy/ax/jmfyaxb3vmub3nmsckfux3iyu_w.png"><br><br>  In the <a href="https://habrahabr.ru/company/pixonic/blog/340168/">first</a> article of this series, I explained how and why we chose open-sourced Graylog2 for the centralized collection and viewing of logs in the company.  This time I will share how we deployed the greylog in production, and what problems we encountered. <br><br>  Let me remind you that the cluster will be located on the hosting site, logs will be collected from all over the world via TCP, and the average number of logs will be about 1.2 TB / day under normal conditions. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      We currently use CentOS 7 and Graylog 2.2, so all configurations and options will be described exclusively for these versions (in Graylog 2.2 and Graylog 2.3, a number of options are different). <br><a name="habracut"></a><br><h3>  Placement planning </h3><br>  According to our calculations, we need 6 servers.  Each server has 2 network interfaces;  the first is 100MB per world and 1GB private network.  On the external interface, it will listen to the web interface and on the part, the nodes will listen to HAproxy, but more on that later.  Private 1GB network is used to report the rest. <br><br>  In total, we have 6 Hp DL380p Gen8 servers, 2x Intel Octa-Core Xeon E5-2650, 64 GB RAM, 12x4TB SATA.  This is the standard host configuration.  We broke the disks like this: 1 disk for the system, Mongu and the log of the greyloga, the rest - 0 raid and for the elastic storage.  Since replication occurs at the level of the elastic itself, we do not need other raids very much. <br><br>  Servers are distributed as follows: <br><br><ul><li>  in the first 4: HAproxy, elasticsearch, graylog, mongod, keepalived, cerebro; </li><li>  on the remaining 2 only elasticsearch and graylog. </li></ul><br>  Schematically, it looks like this: <br><br><img src="https://habrastorage.org/webt/lr/_v/2w/lr_v2w3biugic7zzsbiipvputuk.png"><br><br>  Settings: <br><br><ul><li>  DNS shows 2 addresses, which are usually located on 1 and 2 nodes; </li><li>  Between 1-3 and 2-4, HAproxy is configured so that in the event of a node falling, the address rises on another node; </li><li>  then each node using HAproxy spreads traffic across all graillogs nodes; </li><li>  The greylog in turn also balances the processing of logs by nodes. </li></ul><br>  (We will not stop at setting up HAproxy and keepalived, as this is beyond the scope of this article.) <br><br><h3>  Initial setup </h3><br>  The initial setup of Graylog2 is quite simple and trivial, so I simply strongly advise everyone to act according to official instructions: <br><br><ul><li>  <a href="http://docs.graylog.org/en/2.2/pages/installation/operating_system_packages.html">docs.graylog.org/en/2.2/pages/installation/operating_system_packages.html</a> </li><li>  <a href="http://docs.graylog.org/en/2.2/pages/architecture.html">docs.graylog.org/en/2.2/pages/architecture.html#big-production-setup</a> </li><li>  <a href="http://docs.graylog.org/en/2.2/pages/configuration/multinode_setup.html">docs.graylog.org/en/2.2/pages/configuration/multinode_setup.html#configure-multinode</a> </li></ul><br>  There is a lot of useful information that will further help in understanding the principles of configuration and tuning.  During the initial setup, I have never had any problems, so let's move on to the configuration files. <br><br>  In the graillog server.conf, at the first stage, we specified: <br><br>  # Specify our time zone <br><br><pre><code class="bash hljs">root_timezone = Europe/Moscow</code> </pre> <br>  # Since there are not so many hosts, we indicate here all the elastic hosts <br><br><pre> <code class="bash hljs">elasticsearch_discovery_zen_ping_unicast_hosts = elasticsearch_discovery_zen_ping_multicast_enabled = <span class="hljs-literal"><span class="hljs-literal">false</span></span></code> </pre> <br>  # We allow starting the search from wildcard, because we all understand what it is and what it threatens <br><br><pre> <code class="bash hljs">allow_leading_wildcard_searches = <span class="hljs-literal"><span class="hljs-literal">true</span></span></code> </pre> <br>  # This refers more to tuning, but at the first stage we specified a ring_size equal to half of the L2 cache of the processor. <br><br>  # And specify the data to send letters with greylog (in the blank lines you need to insert your data). <br><br>  #Email transport <br><br><pre> <code class="bash hljs">transport_email_enabled = <span class="hljs-literal"><span class="hljs-literal">true</span></span> transport_email_hostname = smtp.gmail.com transport_email_port = 465 transport_email_use_auth = <span class="hljs-literal"><span class="hljs-literal">true</span></span> transport_email_use_tls = <span class="hljs-literal"><span class="hljs-literal">false</span></span> transport_email_use_ssl = <span class="hljs-literal"><span class="hljs-literal">true</span></span> transport_email_auth_username = transport_email_auth_password = transport_email_subject_prefix = [graylog] transport_email_from_email = transport_email_web_interface_url =</code> </pre> <br>  Next you need to try out the elastic elastic in the / etc / sysconfig / elasticsearch file (31 GB recommended in the dock): <br><br><pre> <code class="bash hljs">ES_HEAP_SIZE=31g</code> </pre> <br>  At the initial stage, we did not rule anything any more and for a while did not even know any problems.  Therefore, we proceed directly to launching and configuring the greilog itself. <br><br><h3>  Storage and assembly of logs, access rights </h3><br>  It's time to set up our greylog and start receiving data.  The first thing we need is to decide how we will get the logs.  We stopped at GELF TCP - it allows you to configure collectors via the web interface (I will show a little below). <br><br>  We set up our first input.  In the System / Inputs web interface at the top left, select GELF TCP and then Launch new input: <br><br><img src="https://habrastorage.org/webt/yw/db/hp/ywdbhpvdmdo-3xopqib4qhow5ds.png"><br><br>  A window opens: <br><br><img src="https://habrastorage.org/webt/wb/ad/ux/wbaduxjqfuzkjpzplo97qf9q4es.png"><br><br><ul><li>  Global.  Says that the input will be raised on all nodes. </li><li>  Title.  What will be called input. </li><li>  Bind address.  What address will our input be sent to (in our case it is 0.0.0.0, because there are different addresses on all the nodes). </li><li>  Port.  Here we must remember that HAproxy stands before our partners as a balancer, respectively, we enter here the port to which the balancer will be redirected. </li><li>  Receive Buffer Size, Decompressed size limit and Maximum message size.  It is selected on the basis of specific cases. </li><li>  Customize ssl as desired. </li></ul><br>  Now we have our first input, which will receive messages.  We proceed to setting up the storage of logs.  It is necessary to decide how many logs and how we will store them. <br><br>  We divided everything into projects and logically related services within projects, and then divided by the number of logs we need to store.  Personally, we store part of the logs for 14 days, and some - 140. <br><br>  Data is stored in graillog indexes.  Indices, in turn, are divided into shards.  Shards are Primary and Replica.  By default, data is written to the primeri shards and replicated to the replica.  We only replicate important indexes.  Large indexes have 2 primary shards and one replica, which guarantees the failure of 2 nodes without losing data. <br><br>  Let's create an index that will have 2 shards and 1 replica and will store their logs for 14 days. <br><br>  We go to System \ Indices, there we click Create index set: <br><br><img src="https://habrastorage.org/webt/fd/fc/91/fdfc91rmrz5moxhukiqz8baz38e.png"><br><br><ul><li>  Title and Description.  Everything is clear here - the name and description. </li><li>  Index prefix.  What prefix in the elastic will have indices (usually somehow reflects the name of the index itself in the greylog). </li><li>  Analyzer.  We do not change. </li><li>  Index shards.  The number of shards (we want to have 2 primari shards, so there must be 2). </li><li>  Index replicas.  The number of replicas of each shard is 1. </li><li>  Max.  number of segments.  Usually we do not optimize shards, so we leave 1. </li></ul><br>  The following items are responsible for the number of stored logs and by name it becomes clear that they can be stored by the number of messages, by time, and by the size of the index.  We want to store 14 days. <br><br><ul><li>  Select rotation strategy - Index Time. </li><li>  Rotation period (ISO8601 Duration).  There is in the documentation, we leave P1D, which says: one index - one day. </li><li>  Select retention strategy - Delete index.  We will delete the old indexes. </li><li>  Max number of indices.  The maximum number of indices, we put 14, which in this case means that 14 indices of 1 day will be stored. </li></ul><br>  Now we need to do the so-called stream.  Greylog provides rights at the level of these same streams.  The bottom line is this: in the stream we specify in which index to write data and on what conditions.  It is located in Sterams.  Setup takes place in 2 stages. <br><br>  1. Creating a stream. <br><br><img src="https://habrastorage.org/webt/cm/8i/fx/cm8ifxuxuk1imksatcfd5xruq0o.png"><br><br><ul><li>  Title and Description.  As usual - the name and description. </li><li>  Index Set.  In which index to write data, then choose the one that you created earlier. </li><li>  Remove matches from 'All messages' stream.  Delete messages from 'All messages'.  To avoid confusion - delete. </li></ul><br>  2. Further Manage Rules. <br><br>  Everything is simple there: we add the necessary rules by which the logs will get there. <br><br>  Now we have an input that accepts logs;  the index that stores them;  and stream, which essentially collects a lot of logs in one space. <br><br>  Further we set up sending logs to the greylog itself. <br><br><h3>  Agent configuration </h3><br>  The agent configuration path is described <a href="http://docs.graylog.org/en/2.2/pages/collector_sidecar.html">here</a> .  It all works in the following way: Graylog Collector Sidecar is installed on the client, which manages the log collector's backend (in our case for Linux and Windows, this is nxlog). <br><br>  Let's prepare the rules for assembling System \ Collectors \ Manage Configurations logs.  Create a configuration and go to its configuration, there immediately go to the tab NXLog.  We see 3 fields: Output, Configure NXLog Inputs and Define NXLog Snippets.  These are all pieces of NXLog's configs, which will be the collector to climb to the final nodes.  From here we will manage the fields and their values, as well as the files that we will be monitoring, etc. <br><br><img src="https://habrastorage.org/webt/wy/yd/em/wyydem-nawlkw8lp_-owrgs-bvi.png"><br><br>  Let's start with the tags.  We drive in tags according to which the client will understand which configuration he needs to pick up. <br><br>  Output field, there is one configuration: <br><br><img src="https://habrastorage.org/webt/wk/aj/tp/wkajtp4gmbsnn8fm4qrw8tkislc.png"><br><br><ul><li>  Name.  Everything is clear here - the name by which we understand what it is. </li><li>  Type.  In our case, this is TCP. </li><li>  Server IP.  Here we specify the address where to send the logs (in our case, this is the DNS, the name that is allowed in 2 addresses). </li><li>  Port.  As we remember, we use a balancer - at the entrance we indicate the port of the balancer, which in turn spreads on the greylogs nodes. </li><li>  Next, turn on the buffer on the host. </li><li>  And do not overwrite the hostname. </li><li>  Additional Fields.  Here we add additional fields that will be applied at the configuration level. </li><li>  Next field for manual configuration fields.  Details can be read <a href="http://nxlog-ce.sourceforge.net/nxlog-docs/en/nxlog-reference-manual.html">on the site</a> NXLog'a.  In our case, as an example, simply splitting the hostname into the required fields: </li></ul><br><pre> <code class="bash hljs">Exec <span class="hljs-variable"><span class="hljs-variable">$Hostname</span></span>= <span class="hljs-variable"><span class="hljs-variable">$collector_node_id</span></span>; Exec <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> ( <span class="hljs-variable"><span class="hljs-variable">$collector_node_id</span></span> =~ /^(\w+)\.(\w+).(\w+).(\w+).(\w+)/)\ { \ <span class="hljs-variable"><span class="hljs-variable">$name</span></span> = <span class="hljs-variable"><span class="hljs-variable">$1</span></span>;\ <span class="hljs-variable"><span class="hljs-variable">$datacenter</span></span> = <span class="hljs-variable"><span class="hljs-variable">$2</span></span>; \ <span class="hljs-variable"><span class="hljs-variable">$region</span></span> = <span class="hljs-variable"><span class="hljs-variable">$3</span></span>;\ <span class="hljs-variable"><span class="hljs-variable">$platform</span></span> = <span class="hljs-variable"><span class="hljs-variable">$5</span></span>;\ };</code> </pre><br>  This was a general configuration setting, where to send and how to sign each log.  Next in the Configure NXLog Inputs field, we indicate which files to monitor. <br><br><img src="https://habrastorage.org/webt/xf/dj/3d/xfdj3dybhjrlqclsu8x8h3mfz5k.png"><br><br><ul><li>  Name - ... </li><li>  Forward to (Required).  This is the above created output. </li><li>  Type.  There are quite a lot of types that NXLog can do, in this case we specify the file, which means that we will take the data from the file. </li><li>  Path to Logfile.  Path to file or files.  Regexps are supported, you just need to remember that in the case of Windows, the file must have an extension and all the files in the directory look like this: ‚Äú*. *‚Äù. </li><li>  Poll Interval.  How often to check changes in seconds. </li><li>  The next set of check boxes describes the behavior of working with a file and depends on the specifics of your logs. </li><li>  And then again, custom fields and raw field.  In this case, we select a field from the log and transfer it as severity. </li></ul><br>  Define NXLog Snippets, we usually do not touch. <br><br>  At this point, we assume that the default setting is complete, you can add more files, fields, etc. there. <br><br>  Let's proceed to the installation of the agent.  In general, it is very well described by <a href="http://docs.graylog.org/en/2.2/pages/collector_sidecar.html">reference</a> , so here we will not stop at the manual rolling of agents, but immediately proceed to automation.  We make it ansiblom. <br><br>  Under Linux, there is nothing complicated, and on Windows there is a problem in the automatic installation, so we simply unpack the file and generate unique UUIDs on the ansibla side.  Roles for ansibla: <br><br><ul><li>  Win: <a href="https://github.com/Hravn/grsidecar_win">github.com/Hravn/grsidecar_win</a> </li><li>  Lin: <a href="https://github.com/Hravn/grsidecar_lin">github.com/Hravn/grsidecar_lin</a> </li></ul><br>  At this setting can be considered complete and the first logs will begin to appear in the system. <br><br>  I would also like to talk about how we have tuned the system to fit our needs, but since the article has already turned out to be quite voluminous, it will be continued. </div><p>Source: <a href="https://habr.com/ru/post/341274/">https://habr.com/ru/post/341274/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../341262/index.html">The task of the page in three columns, one of them in a hundred pixels</a></li>
<li><a href="../341264/index.html">Keyword "mutable" in C ++</a></li>
<li><a href="../341266/index.html">Overcoming blocking in TTC (Transtelecom) with pf</a></li>
<li><a href="../341268/index.html">Mathematical model of financial market dynamics</a></li>
<li><a href="../341272/index.html">Created the first molecular computer based on synthetic polymers</a></li>
<li><a href="../341276/index.html">Safety Issues of Smart Energy</a></li>
<li><a href="../341278/index.html">What is good (and bad) Typescript: experience of UI-developers</a></li>
<li><a href="../341280/index.html">Shutdown PC anywhere in the world (JAVA)</a></li>
<li><a href="../341282/index.html">Google Analytics API for a marketer on a practical example</a></li>
<li><a href="../341288/index.html">‚ÄúSometimes you have to look into the Spark code‚Äù: Alexander Morozov (SEMrush) about using Scala, Spark and ClickHouse</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>