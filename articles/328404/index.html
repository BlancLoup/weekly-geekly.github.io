<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>How on Instagram disconnected the Python garbage collector and started living</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="By disabling the Python garbage collector (GC), which frees up memory by tracking and deleting unused data, Instagram started to work 10% faster. Yes,...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>How on Instagram disconnected the Python garbage collector and started living</h1><div class="post__text post__text-html js-mediator-article">  By disabling the Python garbage collector (GC), which frees up memory by tracking and deleting unused data, Instagram started to work 10% faster.  Yes, you heard it right!  By disabling the garbage collector, you can reduce the amount of memory consumed and increase the efficiency of the processor cache.  Want to know why this is happening?  Then fasten your seat belts! <br><img src="https://habrastorage.org/web/50a/374/689/50a37468992b4e4d80332d563481d537.jpg"><br><a name="habracut"></a><br><h2>  <font color="#c75733">How we run our web server</font> </h2><br>  The Instagram web server runs on Django in multiprocess mode, where the master process copies itself, creating dozens of workflows that accept requests from users.  As an application server, we use uWSGI in prefork mode to regulate the allocation of memory between the master process and workflows. <br><br>  To prevent Django from running out of memory, the uWSGI master process provides the ability to restart the workflow when its resident memory (RSS) exceeds a predetermined limit. <br><br><h2>  <font color="#c75733">How memory works</font> </h2><br>  First, we decided to find out why RSS workflows start to grow so quickly immediately after they are generated by the wizard.  We noticed that although RSS starts at 250 MB, the size of the shared memory used is reduced from 250 MB to almost 140 MB in a few seconds (the size of the shared memory can be viewed in <code>/proc/PID/smaps</code> ).  The numbers here are not very interesting, as they are constantly changing, but how quickly the allocated memory is released (almost 1/3 of the total memory) is of interest.  Then we decided to find out why this shared memory becomes the private memory of each process at the beginning of its life. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <h2>  <font color="#c75733">Our guess: Copy-on-Read</font> </h2><br>  In the Linux kernel, there is a copy <a href="https://en.wikipedia.org/wiki/Copy-on-write">-on-write</a> mechanism ( <a href="https://en.wikipedia.org/wiki/Copy-on-write">Copy-on-Write</a> , CoW), which serves to optimize the work of child processes.  The child process at the beginning of its existence shares each page of memory with its parent.  The page is copied to its own process memory only during recording. <br><br>  But in the world of Python, interesting things happen because of the reference counting.  Each time the Python object is read, the interpreter will increase its reference count, which is essentially a write operation to its internal data structure.  This causes CoW.  It turns out that with Python we actually use Copy-on-Read (CoR)! <br><br><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">define</span></span></span><span class="hljs-meta"> PyObject_HEAD \ _PyObject_HEAD_EXTRA \ Py_ssize_t ob_refcnt; \ struct _typeobject *ob_type; ... typedef struct _object { PyObject_HEAD } PyObject;</span></span></code> </pre> <br>  The question arises: do we perform copying while writing for immutable objects, such as code objects?  Since <code>PyCodeObject</code> is actually a ‚Äúsubclass‚Äù of <code>PyObject</code> , obviously, yes.  Our first idea was to turn off reference counting for PyCodeObject. <br><br><h2>  <font color="#c75733">Attempt number 1: disable reference counting for code objects</font> </h2><br>  We start with Instagram simple.  As an experiment, we added a small hack to the CPython interpreter, made sure that the reference count does not change for code objects, and then installed this CPython on one of the working servers. <br><br>  The result disappointed us: nothing has changed in the use of shared memory.  When we tried to figure out why this was happening, we realized that we could not find any reliable metrics to prove that our hack worked, and also we could not prove the connection between shared memory and a copy of the code object.  Obviously, we have missed something.  Conclusion: before you follow your theory, prove it. <br><br><h2>  <font color="#c75733">Paging Analysis</font> </h2><br>  A little googling on the topic of Copy-on-Write, we found out that Copy-on-Write is related to errors in the absence of pages in memory (page faults, or page breaks).  Each CoW operation causes a page break in the process.  The performance monitoring tools built into Linux allow you to record system events, including page breaks, and, when possible, even output a stack trace! <br><br>  We again went to the production server, rebooted it, waited until the master process spawned child processes, learned the PID of the workflow, and then executed the following command: <br><br><pre> <code class="bash hljs">perf record -e page-faults -g -p &lt;PID&gt;</code> </pre> <br>  With the help of stack-traces, we got an idea of ‚Äã‚Äãwhen page breaks occur in the process. <br><br><img src="https://habrastorage.org/web/dec/d17/a50/decd17a508fb4c1b820a3a0608d87e8b.png"><br><br>  The results were different from what we expected.  The main suspect was not the copying of code objects, but the <code>collect</code> method of <code>gcmodule.c</code> , which was called when the garbage collector was started.  After reading how GC works in CPython, we developed the following theory: <br><br>  The garbage collector in CPython is called deterministically based on a threshold value.  The default threshold is very low, so the garbage collector runs at very early stages.  It maintains linked lists containing information about the creation of objects, and linked lists are mixed during garbage collection.  Since the structure of the linked list exists along with the object itself (just like <code>ob_refcount</code> ), mixing these objects in linked lists will cause the CoW of the relevant pages, which is an annoying side effect. <br><br><pre> <code class="cpp hljs"><span class="hljs-comment"><span class="hljs-comment">/* GC information is stored BEFORE the object structure. */</span></span> <span class="hljs-keyword"><span class="hljs-keyword">typedef</span></span> <span class="hljs-keyword"><span class="hljs-keyword">union</span></span> _gc_head { <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">struct</span></span></span><span class="hljs-class"> {</span></span> <span class="hljs-keyword"><span class="hljs-keyword">union</span></span> _gc_head *gc_next; <span class="hljs-keyword"><span class="hljs-keyword">union</span></span> _gc_head *gc_prev; Py_ssize_t gc_refs; } gc; <span class="hljs-keyword"><span class="hljs-keyword">long</span></span> <span class="hljs-keyword"><span class="hljs-keyword">double</span></span> dummy; <span class="hljs-comment"><span class="hljs-comment">/* force worst-case alignment */</span></span> } PyGC_Head;</code> </pre> <br><h2>  <font color="#c75733">Attempt number 2: Let's try to disable the garbage collector</font> </h2><br>  Well, since the garbage collector treacherously betrayed us, let's turn it off! <br><br>  We added the <code>gc.disable()</code> call to our boot script.  Reboot the server and fail again!  If you look at perf again, we see that <code>gc.collect</code> is still being called, and copying to memory is still in progress.  After a little debugging in GDB, we found that one of the external libraries we used (msgpack) calls <code>gc.enable()</code> to revive the garbage collector, so <code>gc.disable()</code> was useless in the boot script. <br><br>  The msgpack patch was unacceptable for us, as it opened the way for other libraries to do the same without making us aware.  First, you need to prove that disabling the garbage collector really helps.  The answer again lies in <code>gcmodule.c</code> .  As an alternative to <code>gc.disable</code> we <code>gc.set_threshold(0)</code> , and this time no library returned this value to its place. <br><br>  Thus, we have successfully increased the amount of shared memory for each workflow from 140 MB to 225 MB, and the total amount of memory used on the host has dropped to 8 GB on each machine.  This saved 25% of RAM on all Django servers.  With such a reserve of free space, we can both run a lot more processes and raise the threshold for resident memory.  As a result, this increases the throughput of the Django layer by more than 10%. <br><br><h2>  <font color="#c75733">Attempt number 3: Disable garbage collector completely</font> </h2><br>  After experimenting with a variety of settings, we decided to test our theory in a wider context: on a cluster.  The results were not long in coming, and our continuous deployment process collapsed, because with the garbage collector turned off, the web server began to reboot much slower.  It usually took less than 10 seconds to restart, but when the garbage collector was turned off, it sometimes took up to 60 seconds. <br><br><pre> <code class="bash hljs">2016-05-02_21:46:05.57499 WSGI app 0 (mountpoint=<span class="hljs-string"><span class="hljs-string">''</span></span>) ready <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> 115 seconds on interpreter 0x92f480 pid: 4024654 (default app)</code> </pre> <br>  This bug was difficult to reproduce, since the behavior was not deterministic.  After a lot of experiments, we managed to determine the exact reproduction steps.  When this happened, the free memory on this host dropped to almost zero and jumped back, filling the entire cache.  Then there came a time when all the code or data had to be read from disk (DSK 100%), and everything worked slowly. <br><br>  This could signal that Python performs the final garbage collection while the interpreter is stopped, which can cause a huge jump in the amount of memory used in a very short period of time.  And again, I decided to first prove it, and then decide how to fix it.  So, I commented out the <code>Py_Finalize</code> call in the uWSGI plugin for Python, and the problem disappeared. <br><br>  Obviously, we could not just turn off <code>Py_Finalize</code> .  Many important cleaning procedures depended on this method.  In the end, we added a dynamic flag to CPython that completely turned off garbage collection. <br><br>  Finally, we needed to apply our solution on a larger scale.  We tried to use it on all servers, but this again broke the process of continuous deployment.  However, this time only the machines with old processor models (Sandy Bridge) suffered, and it was even harder to reproduce.  Conclusion: Always test old customers / equipment, as they are the easiest to break. <br><br>  Since our continuous deployment process is fast enough to understand what is happening, I added a separate <code>atop</code> utility to our installation script.  Now we could catch the moment when the cache was almost completely filled, and all uWSGI processes were throwing out a lot of MINFLT (minor errors in the absence of pages in memory). <br><br><img src="https://habrastorage.org/web/9e4/571/972/9e45719724f045cda5056b00adb2ed61.png"><br>  And again, performing performance profiling, we meet <code>Py_Finalize</code> .  When shutting down, except garbage collection, Python performs several operations related to cleaning: such as destroying type objects or unloading modules.  And this again harmed the shared memory. <br><br><img src="https://habrastorage.org/web/d60/6b3/55e/d606b355e7b248edaef98c8c1b38e44f.png"><br><br><h2>  <font color="#c75733">Attempt number 4: The final step to shutting down the garbage collector: no cleaning</font> </h2><br>  And why do something to clean?  The process will die and we will get a replacement for it.  What we should worry about is the atexit function handlers, which clean up behind our applications.  But do not worry about cleaning up Python.  Here is how we eventually changed our boot script: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># gc.disable() doesn't work, because some random 3rd-party library will # enable it back implicitly. gc.set_threshold(0) # Suicide immediately after other atexit functions finishes. # CPython will do a bunch of cleanups in Py_Finalize which # will again cause Copy-on-Write, including a final GC atexit.register(os._exit, 0)</span></span></code> </pre> <br>  The decision is based on the fact that the atexit functions are started from the register in the reverse order.  The atexit function completes the rest of the cleanup, and then calls <code>os._exit(0)</code> to complete the current process. <br><br>  Having changed only two lines, we finally rolled out the solution to all our servers.  By carefully setting the memory thresholds, we got a total performance increase of 10%! <br><br><h2>  <font color="#c75733">Look back</font> </h2><br>  When thinking about improving performance, we had a couple of questions: <br><br>  First, shouldn't Python memory overflow without garbage collection, since it is no longer cleared?  (Recall that there is no real stack in Python memory, since all objects are stored on the heap.) <br><br>  Fortunately, it is not.  The main mechanism for releasing objects in Python is reference counting.  When an object reference is deleted (when <code>Py_DECREF</code> called), Python always checks to see if the reference count for this object is zero.  In this case, the object allocator will be called.  The main task of garbage collection is to destroy cyclic dependencies when the reference counting mechanism does not work. <br><br><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">define</span></span></span><span class="hljs-meta"> Py_DECREF(op) \ do { \ </span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">if</span></span></span><span class="hljs-meta"> (_Py_DEC_REFTOTAL _Py_REF_DEBUG_COMMA \ --((PyObject*)(op))-&gt;ob_refcnt != 0) \ _Py_CHECK_REFCNT(op) \ </span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">else</span></span></span><span class="hljs-meta"> \ _Py_Dealloc((PyObject *)(op)); \ } while (0)</span></span></code> </pre> <br><h2>  <font color="#c75733">Let us see where the gain is</font> </h2><br>  The second question: where does the performance gain come from? <br><br>  Turning off the garbage collector gives a double win: <br><br><ul><li>  We freed up almost 8 GB of RAM on each server and were able to use them to create more working processes on servers with limited memory bandwidth, or to reduce the number of process restarts on servers with limited CPU power; </li><li>  The CPU throughput has also increased, as the number of instructions executed per cycle (IPC) increases by almost 10%. </li></ul><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># perf stat -a -e cache-misses,cache-references -- sleep 10 Performance counter stats for 'system wide': 268,195,790 cache-misses # 12.240 % of all cache refs [100.00%] 2,191,115,722 cache-references 10.019172636 seconds time elapsed</span></span></code> </pre> <br>  With the garbage collector disabled, the number of cache cache miss rates drops by 2‚Äì3%, which is the main reason for the 10% improvement in IPC.  Cash misses are expensive because they slow down the processor‚Äôs compute pipeline.  A small increase in the CPU cache hit rate can significantly improve IPC.  The fewer copy-on-write (CoW) operations are performed, the more cache lines with different virtual addresses (in different workflows) point to the same address in physical memory, which leads to an increase in cache hit rate. <br><br>  As you can see, not every component works as we think, and the results can sometimes be unexpected.  Therefore, continue research and be surprised at how everything is arranged in reality! <br><br><blockquote><div class="spoiler">  <b class="spoiler_title">Oh, and come to work with us?</b>  <b class="spoiler_title">:)</b> <div class="spoiler_text">  <a href="http://wunderfund.io/"><b>wunderfund.io</b></a> is a young foundation that deals with <a href="https://en.wikipedia.org/wiki/High-frequency_trading">high-frequency algorithmic trading</a> .  High-frequency trading is a continuous competition of the best programmers and mathematicians of the whole world.  By joining us, you will become part of this fascinating fight. <br><br>  We offer interesting and challenging data analysis and low latency tasks for enthusiastic researchers and programmers.  Flexible schedule and no bureaucracy, decisions are quickly made and implemented. <br><br>  Join our team: <a href="http://wunderfund.io/">wunderfund.io</a> </div></div></blockquote></div><p>Source: <a href="https://habr.com/ru/post/328404/">https://habr.com/ru/post/328404/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../328388/index.html">Business mail should be unlimited</a></li>
<li><a href="../328390/index.html">Loyalty programs: how shops heat up customer interest</a></li>
<li><a href="../328394/index.html">Google I / O Extended 2017 in 20 cities of Russia</a></li>
<li><a href="../328398/index.html">EPAM FRONT-END OPEN DAY</a></li>
<li><a href="../328402/index.html">Use Spring Groovy context to create a configurable, interactive graphical UI</a></li>
<li><a href="../328406/index.html">The tragedy of one hundred percent code coverage</a></li>
<li><a href="../328408/index.html">Essentialism and decision theory</a></li>
<li><a href="../328410/index.html">‚ÄúThey didn‚Äôt come up with anything, improvise‚Äù or Agile in information security</a></li>
<li><a href="../328412/index.html">Your idea is nonsense.</a></li>
<li><a href="../328416/index.html">Do not you send spam?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>