<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>How we scaled Nginx and save the world 54 years of waiting each day</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="‚ÄúThe @Cloudflare team has just made changes that significantly improved the performance of our network, especially for the slowest requests. How much ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>How we scaled Nginx and save the world 54 years of waiting each day</h1><div class="post__text post__text-html js-mediator-article">  <i>‚ÄúThe @Cloudflare team has just made changes that significantly improved the performance of our network, especially for the slowest requests.</i>  <i>How much faster?</i>  <i>We estimate that we are saving the Internet about 54 years of time <b>per day</b> , which otherwise would have been spent waiting for the sites to load</i> . <i>‚Äù</i>  - <a href="http://www.exactaudiocopy.de/en/index.php/other-projects/dae-quality/">Tweet by</a> Matthew Prince, June 28, 2018 <br><br>  10 million sites, applications and APIs use Cloudflare to speed up content downloads for users.  At the peak, we process more than 10 million requests per second in 151 data centers.  Over the years we have made many changes to our version of Nginx to cope with growth.  This article is about one of these changes. <br><a name="habracut"></a><br><h1>  How does nginx work </h1><br>  Nginx is one of the programs that uses event loops to solve <a href="http://www.kegel.com/c10k.html">the C10K problem</a> .  Each time a network event arrives (a new connection, request or notification to send more data, etc.), Nginx wakes up, processes the event, and then returns to another job (this may be processing other events).  When an event arrives, the data for it is already ready, which allows you to efficiently process many simultaneous requests without downtime. <br><br><pre><code class="hljs pgsql">num_events = epoll_wait(epfd, <span class="hljs-comment"><span class="hljs-comment">/*returned=*/</span></span>events, events_len, <span class="hljs-comment"><span class="hljs-comment">/*timeout=*/</span></span><span class="hljs-number"><span class="hljs-number">-1</span></span>); // events <span class="hljs-keyword"><span class="hljs-keyword">is</span></span> list <span class="hljs-keyword"><span class="hljs-keyword">of</span></span> active events // handle event[<span class="hljs-number"><span class="hljs-number">0</span></span>]: incoming request <span class="hljs-keyword"><span class="hljs-keyword">GET</span></span> http://example.com/ // handle event[<span class="hljs-number"><span class="hljs-number">1</span></span>]: send <span class="hljs-keyword"><span class="hljs-keyword">out</span></span> response <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> <span class="hljs-keyword"><span class="hljs-keyword">GET</span></span> http://cloudflare.com/</code> </pre> <br>  For example, here‚Äôs what a code snippet for reading data from a file descriptor might look like: 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <pre> <code class="hljs pgsql">// we got a <span class="hljs-keyword"><span class="hljs-keyword">read</span></span> event <span class="hljs-keyword"><span class="hljs-keyword">on</span></span> fd <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> (buf_len &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>) { ssize_t n = <span class="hljs-keyword"><span class="hljs-keyword">read</span></span>(fd, buf, buf_len); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (n &lt; <span class="hljs-number"><span class="hljs-number">0</span></span>) { <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (errno == EWOULDBLOCK || errno == EAGAIN) { // try later <span class="hljs-keyword"><span class="hljs-keyword">when</span></span> we <span class="hljs-keyword"><span class="hljs-keyword">get</span></span> a <span class="hljs-keyword"><span class="hljs-keyword">read</span></span> event again } <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (errno == EINTR) { <span class="hljs-keyword"><span class="hljs-keyword">continue</span></span>; } <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> total; } buf_len -= n; buf += n; total += n; }</code> </pre> <br>  If fd is a network socket, the bytes already received will be returned.  The last call will return <code>EWOULDBLOCK</code> .  This means that the local read buffer has ended and should no longer be read from this socket until the data appears. <br><br><h1>  Disk I / O is different from network </h1><br>  If fd is a regular file in Linux, then <code>EWOULDBLOCK</code> and <code>EAGAIN</code> never appear, and a read operation always waits to read the entire buffer, even if the file is opened using <code>O_NONBLOCK</code> .  As written in the <a href="http://man7.org/linux/man-pages/man2/open.2.html">open (2)</a> manual: <br><br><blockquote>  Please note that this flag is not valid for regular files and block devices. </blockquote><br>  In other words, the code above is essentially reduced to this: <br><br><pre> <code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">read</span></span>(fd, buf, buf_len) &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>) { <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> buf_len; }</code> </pre> <br>  If the handler needs to read from disk, then it blocks the event loop until reading is completed, and subsequent event handlers wait. <br><br>  This is normal for most tasks, since disk reading is usually fast enough and much more predictable compared to waiting for a packet from the network.  Especially now, when everyone has SSD, and all our caches are on SSD.  In modern SSDs, there is a very small delay, usually in tens of microseconds.  In addition, you can run Nginx with multiple workflows, so that a slow event handler does not block requests in other processes.  Most of the time, you can rely on Nginx to process requests quickly and efficiently. <br><br><h1>  SSD performance: not always as promised </h1><br>  As you might have guessed, these bright assumptions are not always true.  If each reading always takes 50 Œºs, then reading 0.19 MB in blocks of 4 KB each (and we read in even larger blocks) takes only 2 ms.  But tests have shown that the time to the first byte is sometimes much worse, especially in the 99th and 999th percentile.  In other words, the slowest reading out of every 100 (or 1000) readings often takes much longer. <br><br>  Solid state drives are very fast, but known for their complexity.  They have computers inside that queue and reorder I / O, and also perform various background tasks, such as garbage collection and defragmentation.  From time to time requests slow down noticeably.  My colleague <a href="https://twitter.com/ibobrik">Ivan Bobrov</a> launched several I / O benchmarks and registered read delays of up to 1 second.  Moreover, some of our SSDs have more such bursts of performance than others.  In the future, we are going to take this figure into account when purchasing an SSD, but now we need to develop a solution for existing equipment. <br><br><h1>  Uniform load sharing with <code>SO_REUSEPORT</code> </h1><br>  It‚Äôs hard to avoid one slow response per 1000 requests, but what we really don‚Äôt want is blocking the remaining 1000 requests for a full second.  Conceptually, Nginx is able to process many requests in parallel, but it runs only 1 event handler at a time.  Therefore, I added a special metric: <br><br><pre> <code class="hljs pgsql">gettimeofday(&amp;<span class="hljs-keyword"><span class="hljs-keyword">start</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">NULL</span></span>); num_events = epoll_wait(epfd, <span class="hljs-comment"><span class="hljs-comment">/*returned=*/</span></span>events, events_len, <span class="hljs-comment"><span class="hljs-comment">/*timeout=*/</span></span><span class="hljs-number"><span class="hljs-number">-1</span></span>); // events <span class="hljs-keyword"><span class="hljs-keyword">is</span></span> list <span class="hljs-keyword"><span class="hljs-keyword">of</span></span> active events // handle event[<span class="hljs-number"><span class="hljs-number">0</span></span>]: incoming request <span class="hljs-keyword"><span class="hljs-keyword">GET</span></span> http://example.com/ gettimeofday(&amp;event_start_handle, <span class="hljs-keyword"><span class="hljs-keyword">NULL</span></span>); // handle event[<span class="hljs-number"><span class="hljs-number">1</span></span>]: send <span class="hljs-keyword"><span class="hljs-keyword">out</span></span> response <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> <span class="hljs-keyword"><span class="hljs-keyword">GET</span></span> http://cloudflare.com/ timersub(&amp;event_start_handle, &amp;<span class="hljs-keyword"><span class="hljs-keyword">start</span></span>, &amp;event_loop_blocked);</code> </pre> <br>  The 99th percentile (p99) <code>event_loop_blocked</code> exceeded 50% of our TTFB.  In other words, half the time when servicing a request is the result of blocking the event loop by other requests.  <code>event_loop_blocked</code> measures only half of the blocking (because deferred <code>epoll_wait()</code> calls <code>epoll_wait()</code> not measured), so the actual ratio of the blocked time is much higher. <br><br>  Each of our machines starts Nginx with 15 workflows, that is, one slow I / O will block no more than 6% of requests.  But the events are unevenly distributed: the main worker receives 11% of requests. <br><br>  <code>SO_REUSEPORT</code> can solve the problem of uneven distribution.  Marek Maykovsky previously wrote about the <a href="https://blog.cloudflare.com/the-sad-state-of-linux-socket-balancing/">lack of</a> such an approach in the context of other Nginx instances, but here it can be largely ignored: upstream connections in the cache are durable, so you can ignore the slight increase in delay when opening a connection.  This one configuration change with <code>SO_REUSEPORT</code> activation improved the peak p99 by 33%. <br><br><h1>  Moving read () to thread pool: not silver bullet </h1><br>  The solution to the problem is to make read () not blockable.  In fact, this function is <a href="https://www.nginx.com/blog/thread-pools-boost-performance-9x/">implemented in the usual Nginx</a> !  When using the following configuration, read () and write () are executed in the thread pool and do not block the event loop: <br><br><pre> <code class="hljs nginx"><span class="hljs-attribute"><span class="hljs-attribute">aio</span></span> threads; <span class="hljs-attribute"><span class="hljs-attribute">aio_write</span></span> <span class="hljs-literal"><span class="hljs-literal">on</span></span>;</code> </pre> <br>  But we tested this configuration and instead of improving the response time by 33 times, we noticed only a small change in p99, the difference is within the margin of error.  The result we were very discouraged, so we have postponed this option for a while. <br><br>  There are several reasons why we have not had significant improvements, like the developers of Nginx.  They used in the test 200 simultaneous connections to request files of 4 MB on the HDD.  On hard drives, there is much more I / O latency, so optimization has a greater effect. <br><br>  In addition, we are mainly concerned with the performance of p99 (and p999).  Optimizing average latency does not necessarily solve the problem of peak emissions. <br><br>  Finally, in our environment, typical file sizes are much smaller.  90% of our cache hits are less than 60 KB.  The smaller the files, the smaller the cases of blocking (usually we read the entire file in two readings). <br><br>  Let's look at disk I / O when getting into cache: <br><br><pre> <code class="hljs ruby">/<span class="hljs-regexp"><span class="hljs-regexp">/     https:/</span></span><span class="hljs-regexp"><span class="hljs-regexp">/example.com    0xCAFEBEEF fd = open("/cache</span></span><span class="hljs-regexp"><span class="hljs-regexp">/prefix/dir</span></span><span class="hljs-regexp"><span class="hljs-regexp">/EF/</span></span>BE/CAFEBEEF<span class="hljs-string"><span class="hljs-string">", O_RDONLY); //    32    //    ,  "</span></span>aio threads<span class="hljs-string"><span class="hljs-string">"  read(fd, buf, 32*1024);</span></span></code> </pre> <br>  Not always read 32 KB.  If the headers are small, then you only need to read 4 KB (we do not use I / O directly, so the kernel rounds up to 4 KB).  <code>open()</code> seems harmless, but actually takes resources.  At a minimum, the kernel must check if the file exists and if the calling process has permission to open it.  He needs to find an inode for <code>/cache/prefix/dir/EF/BE/CAFEBEEF</code> , and for this you have to look for <code>CAFEBEEF</code> in <code>/cache/prefix/dir/EF/BE/</code> .  In short, in the worst case, the kernel performs the following search: <br><br><pre> <code class="hljs pgsql">/<span class="hljs-keyword"><span class="hljs-keyword">cache</span></span> /<span class="hljs-keyword"><span class="hljs-keyword">cache</span></span>/prefix /<span class="hljs-keyword"><span class="hljs-keyword">cache</span></span>/prefix/dir /<span class="hljs-keyword"><span class="hljs-keyword">cache</span></span>/prefix/dir/EF /<span class="hljs-keyword"><span class="hljs-keyword">cache</span></span>/prefix/dir/EF/BE /<span class="hljs-keyword"><span class="hljs-keyword">cache</span></span>/prefix/dir/EF/BE/CAFEBEEF</code> </pre> <br>  These are 6 separate readings that <code>open()</code> produces, compared to 1 reading <code>read()</code> !  Fortunately, in most cases, the search falls into the <a href="https://www.kernel.org/doc/Documentation/filesystems/vfs.txt">dentry cache</a> and does not reach the SSD.  But it is clear that processing <code>read()</code> in the thread pool is only half of the picture. <br><br><h1>  Final chord: non-blocking open () in thread pools </h1><br>  Therefore, we made a change to Nginx so that <code>open()</code> is mostly executed inside the thread pool and does not block the event loop.  And here is the result of non-blocking open () and read () at the same time: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d70/b1a/84b/d70b1a84b46934921ffd5a1fd7e7182a.png"><br><br>  On June 26, we rolled changes to the 5 busiest data centers, and the next day - to all the other 146 data centers around the world.  The total peak p99 TTFB decreased 6 times.  In fact, if we sum up all the time from processing 8 million requests per second, then we save the Internet 54 years of waiting each day. <br><br>  Our cycle of events has not completely got rid of locks.  In particular, the lock still occurs when the file is first cached (both <code>open(O_CREAT)</code> and <code>rename()</code> ) or when the revalidation is updated.  But such cases are rare compared to cache accesses.  In the future, we will consider the possibility of moving these elements out of the event loop to further improve the delay rate p99. <br><br><h1>  Conclusion </h1><br>  Nginx is a powerful platform, but scaling extremely high I / O loads on Linux can be a daunting task.  Standard Nginx offloads reading in separate streams, but on our scale it is often necessary to go a step further. </div><p>Source: <a href="https://habr.com/ru/post/419023/">https://habr.com/ru/post/419023/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../419011/index.html">Jinja2 in the world of C ++, part two. Rendering</a></li>
<li><a href="../419013/index.html">Funnel-based attribution for SaaS B2B businesses - as we considered the value of all marketing efforts</a></li>
<li><a href="../419017/index.html">What's new in ConstraintLayout 1.1</a></li>
<li><a href="../419019/index.html">AlterEgo: a device that can read (some) thoughts</a></li>
<li><a href="../419021/index.html">The main types of printing and their features</a></li>
<li><a href="../419025/index.html">Compilation @pythonetc, July 2018</a></li>
<li><a href="../419027/index.html">Information security of bank non-cash payments. Part 6 - Analysis of banking crimes</a></li>
<li><a href="../419029/index.html">Fortnite has become a social phenomenon. Parents increasingly hire trainers for their children and play with them</a></li>
<li><a href="../419033/index.html">A quick note on running vue.js in the kubernetes cluster</a></li>
<li><a href="../419035/index.html">The book "Head First Agile. Flexible project management ¬ª</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>