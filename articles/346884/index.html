<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>How we chose between Elastic and Tarantool, and made our (fastest) in-memory database. With Join and Full-Text Search</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hello. 


 Since mid-2016, we have been designing and developing a new generation of platform. The principal difference from the first generation is t...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>How we chose between Elastic and Tarantool, and made our (fastest) in-memory database. With Join and Full-Text Search</h1><div class="post__text post__text-html js-mediator-article"><p>  Hello. </p><br><p>  Since mid-2016, we have been designing and developing a new generation of platform.  The principal difference from the first generation is the support of the thin-client API.  If the old platform assumes that when the client starts, meta-information about all the content that is available to the subscriber is loaded, then the new platform should render the data slices filtered and sorted for display on each screen / page. </p><br><p>  High-level architecture at the level of data storage within the system - permanent storage of all data in centralized relational SQL storage.  The choice fell on Postgres, there are no revelations.  As the main language for development, I chose golang. </p><br><p>  The system has about 10m users.  We figured that given the tele-viewing profile, 10M users can give hundreds of thousands of RPS to the entire system. </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/698/064/3c1/6980643c15941b8d350dc541892b16dd.jpg"></p><br><p>  This means that requests from clients and close should not be allowed to relational SQL database without caching, and between the SQL database and customers should be a good cache. </p><br><p>  We looked at existing solutions - we drove prototypes.  There is little data by modern standards, but the filtering parameters (read business logic) are complex and, most importantly, personalized - depending on the user session, i.e.  using query parameters as a caching key in KV cache will be very expensive, especially since nobody canceled paging and a rich set of sorts.  In fact, a completely unique set of filtered records is formed for each request from the user. </p><a name="habracut"></a><br><p>  Following the results of the finished solutions, nothing came up.  Simple KV bases of the Redis type were dropped almost immediately: it does not fit in functionality - all filtering and aggregation will have to be implemented at the Application Level, and this is expensive.  I looked at Tarantool.  <a href="https://habrahabr.ru/company/bitrix/blog/309000/">also did not fit functionally</a> </p><br><p>  We looked at Elastic - functionally approached.  But the performance of issuing content according to the requirements of business logic came out in the region of 300-500 RPS. </p><br><p>  With the expected load, even in 100K RPS, you need 200-300 servers for elastic butt.  In the money - it is several million dollars. </p><br><p>  When they figured it out, my plan was already almost ripe in my head - to write my own great, in-memory cache engine in C ++ and conduct our tests on it.  No sooner said than done.  The prototype was implemented almost a couple of weeks.  Run tests. <br>  Wow  Received 15k RPS on the same gland, with the same conditions where Elastic gave 500. </p><br><p>  The difference is 20 times.  More than an order of magnitude, Karl! </p><br><p>  The first, not Proof-Of-Concept, version of the backend with its in-memory cache appeared at the end of 2016.  By mid-2017, Reindexer had already formed into a fully-featured database, acquired its own repository and full-text search engine, at the same time we published it on <a href="https://github.com/restream/reindexer">github</a> . </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/de8/03b/bb4/de803bbb46c2fe38fcb17ee61da365bb.jpg"></p><br><h1 id="tehnicheskie-detali">  Technical details </h1><br><p>  Reindexer is a general purpose NoSQL in-memory database.  According to the data storage structure, Reindexer combines all the main approaches: </p><br><ul><li>  optimized binary JSON representation with addition from a table row with indexable fields </li><li>  optional column storage of selected index fields </li></ul><br><p>  This combination allows you to achieve maximum speed of access to field values, and on the other hand not to require the application to define a rigid data scheme. </p><br><h2 id="indeksy">  Indices </h2><br><p>  There are 4 types of index for query execution: </p><br><ul><li>  hash table, the fastest index for sampling by value </li><li>  binary tree, with the possibility of quick samples by the conditions '&lt;', '&gt;' and sorting by field </li><li>  column, the minimum overhead memory, but the search is slower than the binary tree and hash </li><li>  full-text index, or rather even two: fast, not memory-demanding, and advanced based on trigrams </li></ul><br><p>  When inserting records into tables, the ‚Äúlazy‚Äù index construction method is used.  regardless of the number of indexes, the insertion occurs almost instantly, and the indexes are completed only at the moment when they are required to fulfill the query. </p><br><h2 id="diskovoe-hranilische">  Disk storage </h2><br><p>  In general, Reindexer is a completely in-memory database, that is, all the data with which Reindexer works must be in RAM.  Therefore, the main purpose of disk storage is to load data at the start. </p><br><p>  When adding entries to Reindexer, data is written to the disk in the background, with almost no delays in the insertion process. </p><br><p>  Reindexer uses leveldb as a backend of disk storage. </p><br><h2 id="polnotekstovyy-poisk">  Full text search </h2><br><p>  For full-text search, Reindexer has two engines of its own: </p><br><ul><li> <code>fast</code> , with minimum memory requirements, based on suffixarray, with support for morphology and typos. </li><li>  <code>fuzzy</code> , trigram - gives a better search quality, but of course it requires more memory and runs slower.  While he is in experimental status. </li></ul><br><p>  In both engines there is support for search by transliteration and search with the wrong keyboard layout.  The ranking of search results takes into account statistical probabilities (BM25), the accuracy of the match, and about 5 more parameters.  The ranking formula can be flexibly configured depending on the tasks to be solved. </p><br><p>  Also, there is the possibility of full-text search in several tables, with the output of results sorted by relevance. </p><br><p>  For the formation of requests for full-text search using a special DSL. </p><br><h2 id="join">  Join </h2><br><p>  Reindexer can do Join.  To be precise, in the world of NoSQL, as a rule, there is no Join operation in its pure form, but there is a functional that allows you to insert into each response result a field containing entities from the joined table.  For example, in Elastic this functionality is called <code>nested queries</code> , in mongo - <code>lookup aggregation</code> . </p><br><p>  In Reindexer, this functionality is called Join.  The left join and inner join mechanics are supported. </p><br><h2 id="kesh-deserializovannyh-obektov">  Cache deserialized objects </h2><br><p>  The data in Reindexer is stored in the memory area of ‚Äã‚Äãa managed C ++, and when a sample is received in a golang application, the results are deserialized into a golang structure.  In general, by the way, the golang part of the Reindexer has a very fast deserializer: about 3-4 times faster than JSON, and 2 times faster than BSON.  But even with this in mind, deserialization is a relatively slow operation that creates new objects on the heap and loads GC. </p><br><p>  The object cache in the golang part of Reindexer solves the problem of reusing already deserialized objects, without spending too much time on slow re-de-serialization. </p><br><h1 id="ispolzovanie-reindexer-v-golang-prilozhenii">  Using Reindexer in the Golang application </h1><br><p>  It's time to move from words to action, and see how to use Reindexer in the golang application. </p><br><p>  The interface for Reindexer is implemented as a Query builder, for example, queries are written to tables in this way: </p><br><pre> <code class="hljs pgsql">    db := reindexer.NewReindex("builtin")    db.OpenNamespace("items", reindexer.DefaultNamespaceOptions(), Item{})    it := db.Query ("media_items").WhereInt ("year",reindexer.GT,<span class="hljs-number"><span class="hljs-number">100</span></span>).WhereString ("genre",reindexer.<span class="hljs-keyword"><span class="hljs-keyword">SET</span></span>,"action","comedy").Sort ("ratings")    <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> it.Next() {    fmt.Println (it.<span class="hljs-keyword"><span class="hljs-keyword">Object</span></span>())    }</code> </pre> <br><p>  As you can see from the example, it is possible to construct complex samples for many filtering conditions and with arbitrary sorts. </p><br><div class="spoiler">  <b class="spoiler_title">Reindexer usage example</b> <div class="spoiler_text"><pre> <code class="go hljs"><span class="hljs-keyword"><span class="hljs-keyword">package</span></span> main <span class="hljs-comment"><span class="hljs-comment">//   import (    "fmt"    "math/rand"    "github.com/restream/reindexer" //    Reindexer   (   `builtin`,      )    _ "github.com/restream/reindexer/bindings/builtin" ) //     ,    'reindex' type Item struct {    ID int64 `reindex:"id,,pk"` // 'id'      Name string `reindex:"name"` //      'name'    Articles []int `reindex:"articles"` //      'articles'    Year int `reindex:"year,tree"` //  btree    'year' Descript string //    ,   } func main() {    //  ,    'builtin'    db := reindexer.NewReindex("builtin")    //    ( )    db.EnableStorage("/tmp/reindex/")    //    (namespace)   'items',       'Item'    db.OpenNamespace("items", reindexer.DefaultNamespaceOptions(), Item{})    //       for i := 0; i &lt; 100000; i++ {        err := db.Upsert("items", &amp;Item{            ID: int64(i),            Name: "Vasya",            Articles: []int{rand.Int() % 100, rand.Int() % 100},            Year: 2000 + rand.Int()%50,            Descript: "Description",        })        if err != nil {            panic(err)        }    }    //     'items' -  1 ,    id == 40    elem, found := db.Query("items").        Where("id", reindexer.EQ, 40).        Get()    if found {        item := elem.(*Item)        fmt.Println("Found document:", *item)    }    //     'items' -       query := db.Query("items").        Sort("year", false). //    'year'           WhereString("name", reindexer.EQ, "Vasya"). //   'name'   'Vasya'        WhereInt("year", reindexer.GT, 2020). //   'year'     2020        WhereInt("articles", reindexer.SET, 6, 1, 8). //   'articles'       [6,1,8]        Limit(10). //    10-         Offset(0). //  0         ReqTotal() //       ,       //        iterator := query.Exec()    //    Iterator    defer iterator.Close()    // ,         if err := iterator.Error(); err != nil {        panic(err)    }    fmt.Println("Found", iterator.TotalCount(), "total documents, first", iterator.Count(), "documents:")    //        for iterator.Next() {        //               elem := iterator.Object().(*Item)        fmt.Println(*elem)    } }</span></span></code> </pre> </div></div><br><p>  In addition to the Query Builder, Reindexer has built-in support for queries in SQL format. </p><br><h1 id="proizvoditelnost">  Performance </h1><br><p>  One of the main motivating reasons for the emergence of Reindexer was the development of the most productive solution, significantly surpassing existing solutions.  Therefore, the article would not be complete without specific figures - measurements of performance. </p><br><p>  We conducted comparative load testing of the performance of Reindexer and other popular SQL and NoSQL databases.  The main object of comparison is historically <code>Elastic</code> and <code>MongoDB</code> , which are functionally closest to Reindexer. </p><br><p>  <code>Tarantool</code> and <code>Redis</code> are <code>Tarantool</code> involved in the tests, which are functionally more modest, but nevertheless are also often used as a hot data cache between SQL DB and the API client. </p><br><p>  For completeness, a couple of SQL solutions were included in the list of tested databases - <code>Mysql</code> and <code>Sqlite</code> . </p><br><p>  <code>Reindexer</code> has a full-text search, so we could not deny ourselves the temptation to compare performance with <code>Sphinx</code> </p><br><p>  And the last participant is <code>Clickhouse</code> .  In general, <code>Clickhouse</code> is a database sharpened for other tasks, but nevertheless, periodically questions come to us, ‚Äúwhy not Clickhouse‚Äù, so we decided to add it to the tests. </p><br><h2 id="benchmarki-i-ih-rezultaty">  Benchmarks and their results </h2><br><p>  Let's start with the results, and the technical details of the tests, the description of the methodology and the data immediately after the graphs. </p><br><ul><li>  Get a record by primary key.  This functionality is in all databases participating in the test. </li></ul><br><p><img src="https://habrastorage.org/getpro/habr/post_images/d99/6ef/9b1/d996ef9b1e5c72640653280b45f0a87a.png"></p><br><ul><li>  Get a list of 10 entities filtered by one field, not primary key </li></ul><br><p><img src="https://habrastorage.org/getpro/habr/post_images/d25/66d/261/d2566d26159306480bd842ba0de180ab.png"></p><br><ul><li>  Get a list of 10 entities filtered by two fields </li></ul><br><p><img src="https://habrastorage.org/getpro/habr/post_images/07a/76f/1a8/07a76f1a8c1b434b79ec14e463c762ff.png"></p><br><p>  Redis dropped out of this test, and there is a possibility of emulating the <code>secondary index</code> , however, this requires additional actions from the application when saving / loading records in <code>Redis</code> . </p><br><ul><li>  Overwrite entity in db </li></ul><br><p><img src="https://habrastorage.org/getpro/habr/post_images/9d8/bcc/de5/9d8bccde5cd251c13e058634f393c5b5.png"></p><br><p>  Clickhouse dropped out of this test because  it does not support Update.  Low rewriting speeds in many databases are most likely the result of having a full-text index in the table into which the data is inserted.  <code>Tarantool</code> and <code>Redis</code> do not have full-text search. </p><br><ul><li>  Full-text search for exact word forms </li></ul><br><p><img src="https://habrastorage.org/getpro/habr/post_images/298/109/23f/29810923fa80eb591edcf1adf33d22b9.png"></p><br><ul><li>  Full-text search for inaccurate word forms (prefixes and typos) </li></ul><br><p><img src="https://habrastorage.org/getpro/habr/post_images/8b9/058/fb8/8b9058fb8442b031cd4efd23e5bd81fe.png"></p><br><h2 id="sreda-testirovaniya">  Testing environment </h2><br><p>  All tests were performed in a docker container running on MacBookPro 15 ", 2016. Guest OS - Ubuntu 16.04 LTS. To minimize the impact of the network stack, all databases, test micro-backend and shelling were launched inside the shared container and all network connections were localhost. <br>  8GB of RAM and all 8 CPU cores are allocated to the container. </p><br><h2 id="testovyy-bekend">  Test backend </h2><br><p>  For testing, we made a micro-backend on golang, processing a request for urls of the form: <a href="http://127.0.0.1:8080/">http://127.0.0.1:8080/</a> &lt;test name&gt; / &lt;database name&gt; </p><br><p>  The micro-backend structure, though very simple, but repeats the structure of a real application: there is a repository layer with connectors to the test database and the http API layer, giving answers to the client in JSON format. </p><br><p>  The fasthttp package is used to process http requests, and the standard encoding / json package is used for serialization of responses. </p><br><p>  Working with SQL DB through the <code>sqlx</code> package.  Connection Pool - 8 connections.  A little running ahead, this number was obtained experimentally - with these settings, the SQL databases gave the best result. </p><br><p>  <code>gopkg.in/olivere/elastic.v5</code> used to work with Elastic - I had to conjure a bit with it.  Regularly, he didn‚Äôt want to work in the keep alive mode - the problem was solved only by transferring http.Client to it with the <code>MaxIdleConnsPerHost:100</code> setting <code>MaxIdleConnsPerHost:100</code> . </p><br><p>  The Tarantool, Redis, Mongo connectors didn‚Äôt cause any troubles - they work out of the box efficiently in a multithreaded mode and there were no settings to significantly speed them up. </p><br><p>  Sphinx connector <code>github.com/yunge/sphinx</code> delivered the most trouble - it doesn‚Äôt support much threading.  And testing in one stream is obviously not a valid test. </p><br><p>  Therefore, we had no choice but to do how to implement our connection pool for this connector. </p><br><h2 id="testovye-dannye">  Test data </h2><br><p>  In the test data set 100k records.  There are 4 fields in the record: </p><br><ul><li>  <code>id</code> unique identifier of the record, a number from 0 to 99999 </li><li>  <code>name</code> name.  a string of two random names.  ~ 1000 unique keys </li><li>  <code>year</code> year.  integer from 2000 to 2050 </li><li>  <code>description</code> random text 50 words from a dictionary in 100k words </li></ul><br><p>  The size of each entry in the format Json ~ 500 bytes.  Write example </p><br><pre> <code class="hljs json">{    <span class="hljs-attr"><span class="hljs-attr">"id"</span></span>: <span class="hljs-number"><span class="hljs-number">73</span></span>,    <span class="hljs-attr"><span class="hljs-attr">"name"</span></span>: <span class="hljs-string"><span class="hljs-string">"welcome ibex"</span></span>,    <span class="hljs-attr"><span class="hljs-attr">"description"</span></span>: <span class="hljs-string"><span class="hljs-string">"cheatingly ... compunction "</span></span>,    <span class="hljs-attr"><span class="hljs-attr">"year"</span></span>: <span class="hljs-number"><span class="hljs-number">2015</span></span> }</code> </pre> <br><h2 id="obstrel">  Shelling </h2><br><p>  Shelling was carried out by the wrk utility in 50 competing compounds.  For each test of each base, 10 attacks were conducted and the best result was selected.  Between tests, a pause of a few seconds to prevent the processor from overheating and going into throttling. </p><br><h2 id="itogi-testov">  Test results </h2><br><p>  As part of the tests, it was important to build a solution that is similar in structure to a production solution, without the 'triks', `hacks', and under equal conditions for all the databases in the test. </p><br><p>  Benchmarks do not claim to be 100% complete, but they reflect the main set of cases of work with the base. </p><br><p>  I posted the microback-up and Dockerfile source codes on <a href="https://github.com/Restream/reindexer/tree/master/benchmarks">github</a> , and if you wish, they are not difficult to reproduce. </p><br><h2 id="chto-dalshe">  What's next </h2><br><p>  Now the core functionality of Reindexer is stabilized and Production Ready.  The Golang API is stabilized, and it does not expect breaking changes in the foreseeable future. </p><br><p>  However, Reindexer is still a very young project, it is just over a year old, not everything has been implemented in it yet.  It is actively developing and improving and, as a result, the internal C ++ API is not fixed yet and sometimes it changes. </p><br><p>  Three options for connecting Reindexer to the project are now available: </p><br><ul><li>  library to golang </li><li>  C ++ library </li><li>  standalone server running http protocol </li></ul><br><p>  The plans have a binding implementation for Python and a binary protocol implementation in the server. </p><br><p>  Also, at the moment, data replication between nodes at the Reindex level is not implemented.  For the main case, using Reindexer as a fast cache between SQL and clients is not critical.  Nodes replicate data from SQL at the Application level, and this seems to be quite enough. </p><br><h2 id="vmesto-zaklyucheniya">  Instead of conclusion </h2><br><p>  It seems that it turned out to realize a beautiful and, not afraid of this word, unique solution that combines the functionality of complex databases and performance by several times, or even an order of magnitude superior to the existing solution. </p><br><p>  Most importantly, Reindexer allows you to save millions of dollars on hardware right now, without increasing the development costs of the Application Level - after all, Reindexer has a high-level API, the use of which is no more difficult than regular SQL or ORM. </p><br><p>  Ps.  The comments asked to add a link to github at the end of the article.  Here she is: <br>  <a href="https://github.com/Restream/reindexer">Reindexer repository on github</a> . </p></div>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
    <p>Source: <a href="https://habr.com/ru/post/346884/">https://habr.com/ru/post/346884/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../346872/index.html">Things that cause mistrust and alienate your customers from the site</a></li>
<li><a href="../346876/index.html">How to take notes as a programmer</a></li>
<li><a href="../346878/index.html">Which diagram to use?</a></li>
<li><a href="../346880/index.html">Flask Mega-Tutorial, Part 7: Error Handling (Edition 2018)</a></li>
<li><a href="../346882/index.html">Autopilot simulation on a flight simulator</a></li>
<li><a href="../346888/index.html">Azure ML Workbench: Getting Started</a></li>
<li><a href="../346890/index.html">Writing code in the docker environment</a></li>
<li><a href="../346892/index.html">Lua. Brief introduction to metatables for dummies</a></li>
<li><a href="../346896/index.html">Experiment to account for time, or What I learned by analyzing a whole month of my life</a></li>
<li><a href="../346898/index.html">School of speakers: analysis of the speech of Evgeny Rossinsky, ivi</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>