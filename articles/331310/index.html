<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>LSTM ‚Äî Long Short-Term Memory Networks</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Recurrent Neural Networks 
 People don't start thinking from scratch every second. Reading this post, you understand each word based on the understand...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>LSTM ‚Äî Long Short-Term Memory Networks</h1><div class="post__text post__text-html js-mediator-article"><div style="text-align:center;"><img src="https://habrastorage.org/web/5f3/60f/ec1/5f360fec1bc24f9f973f7d1d3bded6c6.jpg"></div><br><h2>  <font color="#c75733">Recurrent Neural Networks</font> </h2><br>  People don't start thinking from scratch every second.  Reading this post, you understand each word based on the understanding of the previous word.  We do not throw everything out of our heads and do not start thinking from scratch.  Our thoughts are consistent. <br><br>  Traditional neural networks do not have this property, and this is their main drawback.  Imagine, for example, that we want to classify events occurring in a film.  It is not clear how a traditional neural network could use reasonings about previous events of the film to get information about subsequent ones. <br><br>  Recurrent neural networks (RNN) help solve this problem.  These are networks that contain feedback and allow you to store information. <br><a name="habracut"></a><br><div style="text-align:center;"><img src="https://habrastorage.org/web/a9b/1e6/40f/a9b1e640f6264b0a902e851eb5f29e08.png" width="150" height="230"></div><br>  <b>Recurrent neural networks contain feedbacks.</b> 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      In the diagram above, a fragment of the neural network <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-1-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>A</mi></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.743ex" height="2.057ex" viewBox="0 -780.1 750.5 885.9" role="img" focusable="false" style="vertical-align: -0.246ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/wunderfund/blog/331310/&amp;xid=17259,15700022,15700043,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjGx8rxka6v1Q4YbDfCA8IfxuegbA#MJMATHI-41" x="0" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>A</mi></math></span></span><script type="math/tex" id="MathJax-Element-1"> A </script>  accepts input value <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-2-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>x</mi><mi>t</mi></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.156ex" height="1.817ex" viewBox="0 -520.7 928.1 782.1" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/wunderfund/blog/331310/&amp;xid=17259,15700022,15700043,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjGx8rxka6v1Q4YbDfCA8IfxuegbA#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/wunderfund/blog/331310/&amp;xid=17259,15700022,15700043,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjGx8rxka6v1Q4YbDfCA8IfxuegbA#MJMATHI-74" x="809" y="-213"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>x</mi><mi>t</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-2"> x_t </script>  and returns the value <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-3-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>h</mi><mi>t</mi></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.165ex" height="2.419ex" viewBox="0 -780.1 932.1 1041.5" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/wunderfund/blog/331310/&amp;xid=17259,15700022,15700043,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjGx8rxka6v1Q4YbDfCA8IfxuegbA#MJMATHI-68" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/wunderfund/blog/331310/&amp;xid=17259,15700022,15700043,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjGx8rxka6v1Q4YbDfCA8IfxuegbA#MJMATHI-74" x="815" y="-213"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>h</mi><mi>t</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-3"> h_t </script>  .  The presence of feedback allows you to transfer information from one network step to another. <br><br>  Feedbacks give recurrent neural networks some mystery.  However, if you think about it, they are not so different from ordinary neural networks.  A recurrent network can be considered as several copies of the same network, each of which transmits the information of the subsequent copy.  Here is what happens if we expand the feedback: <br><br><img src="https://habrastorage.org/web/5c8/0fa/c22/5c80fac224d449209d888d18ea1111a8.png"><br>  <b>Recurrent neural network in scan</b> <br><br>  The fact that RNN resemble a chain suggests that they are closely related to sequences and lists.  RNN is the most natural architecture of neural networks for working with data of this type. <br><br>  And of course, they are used for such tasks.  Over the past few years, RNN has been incredibly successfully applied to a variety of tasks: speech recognition, language modeling, translation, image recognition ... The list goes on.  About what can be achieved with the help of RNN, tells the excellent blog post by Andrei Karpatoy (Andrej Karpathy) <a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/">The Unreasonable Effectiveness of Recurrent Neural Networks</a> . <br><br>  A significant role in these successes belongs to LSTM - an unusual modification of the recurrent neural network, which in many cases significantly exceeds the standard version.  Almost all of the impressive RNN results were achieved with LSTM.  Our article is devoted to them. <br><br><h2>  <font color="#c75733">The problem of long-term dependencies</font> </h2><br>  One of the attractive ideas of RNN is that they are potentially able to associate previous information with the current task, for example, knowledge of the previous frame of the video can help in understanding the current frame.  If the RNN had this ability, they would be extremely useful.  But do RNNs really give us that opportunity?  It depends on certain circumstances. <br><br>  Sometimes for the current task we need only recent information.  Consider, for example, a language model trying to predict the next word based on previous ones.  If we want to predict the last word in the sentence ‚Äúclouds float across the <i>sky</i> ‚Äù, we do not need a broader context;  in this case, it is pretty obvious that the last word is ‚Äúheaven‚Äù.  In this case, when the distance between the actual information and the place where it was needed is small, the RNN can learn how to use information from the past. <br><br><img src="https://habrastorage.org/web/5f5/c67/ec7/5f5c67ec76a043f1877a5ffe5e1561cc.png"><br>  But there are times when we need more context.  Suppose we want to predict the last word in the text ‚ÄúI grew up in France ... I speak fluent <i>French</i> .‚Äù  The immediate context suggests that the last word will be the naming of a language, but in order to establish which particular language we need the context of France from a more distant past.  Thus, the gap between the actual information and the point of its application can become very large. <br><br>  Unfortunately, as this distance grows, RNNs lose their ability to bind information. <br><br><img src="https://habrastorage.org/web/9c3/a0c/bb3/9c3a0cbb38ac499f8a52305e58eab2d9.png"><br>  In theory, RNN should not have problems with handling long-term dependencies.  A person can carefully select network parameters for solving artificial tasks of this type.  Unfortunately, in practice it is impossible to teach RNN to these parameters.  This problem was investigated in detail by Sepp Hochreiter ( <a href="http://people.idsia.ch/~juergen/SeppHochreiter1991ThesisAdvisorSchmidhuber.pdf">Sepp Hochreiter, 1991</a> ) and <a href="http://www-dsi.ing.unifi.it/~paolo/ps/tnn-94-gradient.pdf">Yoshua Bengio et al. (1994)</a> ;  they have found compelling reasons why this can be difficult. <br><br>  Fortunately, LSTM does not know such problems! <br><br><h2>  <font color="#c75733">LSTM networks</font> </h2><br>  Long short-term memory (LSTM) is a special kind of recurrent neural network architecture capable of learning long-term dependencies.  They were introduced by <a href="http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf">Sepp Hochreiter and J√ºrgen Schmidhuber in 1997</a> , and then refined and popularized in the works of many other researchers.  They perfectly solve a number of diverse tasks and are now widely used. <br><br>  LSTMs are specifically designed to avoid the problem of long-term dependency.  Memorizing information for long periods of time is their usual behavior, and not something that they are struggling to learn. <br><br>  Any recurrent neural network has the form of a chain of repeating modules of a neural network.  In a typical RNN, the structure of one such module is very simple, for example, it can be a single layer with an activation function tanh (hyperbolic tangent). <br><br><img src="https://habrastorage.org/web/47d/ee6/2c3/47dee62c3af8498c946befa1f3330d90.png"><br>  <b>The repeating module in a standard RNN consists of a single layer.</b> <br><br>  The LSTM structure also resembles a chain, but the modules look different.  Instead of a single layer of the neural network, they contain as many as four, and these layers interact in a special way. <br><br><img src="https://habrastorage.org/web/67b/04f/73b/67b04f73b4c34ba38edfa207e09de07c.png"><br>  <b>The repetitive model in the LSTM network consists of four interacting layers.</b> <br><br>  We will not be puzzled by the details yet.  Consider each step of the LSTM scheme later.  While we get acquainted with the special symbols that we use. <br><br><img src="https://habrastorage.org/web/bd0/43e/027/bd043e027a5c4454a735d43c651d7975.png"><br>  <b>Neural network layer;</b>  <b>pointwise operation;</b>  <b>vector transfer;</b>  <b>Union;</b>  <b>copying.</b> <br><br>  In the diagram above, each line carries a whole vector from the output of one node to the input of another.  Pink circles indicate pointwise operations, such as vector addition, and the yellow rectangles are the trained layers of the neural network.  Merging lines mean merging, and branching arrows indicate that the data is copied and copies go to different components of the network. <br><br><h2>  <font color="#c75733">LSTM main idea</font> </h2><br>  The key component of LSTM is the cell state ‚Äî a horizontal line that runs along the top of the circuit. <br><br>  The state of the cell resembles a conveyor belt.  It passes directly through the whole chain, participating only in a few linear transformations.  Information can easily flow through it without changing. <br><br><img src="https://habrastorage.org/web/db4/e23/6e1/db4e236e1d834c96949f17e94e8900c7.png"><br><br>  However, LSTM can remove information from the cell state;  this process is governed by structures called filters (gates). <br><br>  Filters allow you to skip information based on certain conditions.  They consist of a layer of a sigmoidal neural network and a pointwise multiplication operation. <br><br><img src="https://habrastorage.org/web/c79/2d4/f1b/c792d4f1bc1e4bb9829b6cbb41cdec59.png"><br><br>  The sigmoidal layer returns numbers from zero to one, which indicate how much of each block of information should be passed further along the network.  Zero in this case means ‚Äúdo not skip anything‚Äù, unit - ‚Äúskip all‚Äù. <br><br>  There are three such filters in LSTM to protect and monitor cell health. <br><br><h2>  <font color="#c75733">LSTM Walkthrough</font> </h2><br>  The first step in LSTM is to determine what information to throw out of the cell state.  This decision is made by a sigmoidal layer called the ‚Äúforget gate layer‚Äù.  He looks at <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-4-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>h</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi><mo>&amp;#x2212;</mo><mn>1</mn></mrow></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="4.265ex" height="2.539ex" viewBox="0 -780.1 1836.5 1093.4" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/wunderfund/blog/331310/&amp;xid=17259,15700022,15700043,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjGx8rxka6v1Q4YbDfCA8IfxuegbA#MJMATHI-68" x="0" y="0"></use><g transform="translate(576,-150)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/wunderfund/blog/331310/&amp;xid=17259,15700022,15700043,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjGx8rxka6v1Q4YbDfCA8IfxuegbA#MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/wunderfund/blog/331310/&amp;xid=17259,15700022,15700043,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjGx8rxka6v1Q4YbDfCA8IfxuegbA#MJMAIN-2212" x="361" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/wunderfund/blog/331310/&amp;xid=17259,15700022,15700043,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjGx8rxka6v1Q4YbDfCA8IfxuegbA#MJMAIN-31" x="1140" y="0"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>h</mi><mrow class="MJX-TeXAtom-ORD"><mi>t</mi><mo>‚àí</mo><mn>1</mn></mrow></msub></math></span></span><script type="math/tex" id="MathJax-Element-4"> h_ {t-1} </script>  and <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-5-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>x</mi><mi>t</mi></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.156ex" height="1.817ex" viewBox="0 -520.7 928.1 782.1" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/wunderfund/blog/331310/&amp;xid=17259,15700022,15700043,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjGx8rxka6v1Q4YbDfCA8IfxuegbA#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/wunderfund/blog/331310/&amp;xid=17259,15700022,15700043,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjGx8rxka6v1Q4YbDfCA8IfxuegbA#MJMATHI-74" x="809" y="-213"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>x</mi><mi>t</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-5"> x_t </script>  and returns a number from 0 to 1 for each number from the state of the cell <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-6-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>C</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi><mo>&amp;#x2212;</mo><mn>1</mn></mrow></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="4.588ex" height="2.539ex" viewBox="0 -780.1 1975.5 1093.4" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/wunderfund/blog/331310/&amp;xid=17259,15700022,15700043,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjGx8rxka6v1Q4YbDfCA8IfxuegbA#MJMATHI-43" x="0" y="0"></use><g transform="translate(715,-150)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/wunderfund/blog/331310/&amp;xid=17259,15700022,15700043,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjGx8rxka6v1Q4YbDfCA8IfxuegbA#MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/wunderfund/blog/331310/&amp;xid=17259,15700022,15700043,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjGx8rxka6v1Q4YbDfCA8IfxuegbA#MJMAIN-2212" x="361" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/wunderfund/blog/331310/&amp;xid=17259,15700022,15700043,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjGx8rxka6v1Q4YbDfCA8IfxuegbA#MJMAIN-31" x="1140" y="0"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>C</mi><mrow class="MJX-TeXAtom-ORD"><mi>t</mi><mo>‚àí</mo><mn>1</mn></mrow></msub></math></span></span><script type="math/tex" id="MathJax-Element-6"> C_ {t-1} </script>  .  1 means ‚Äúfully preserve‚Äù and 0 means ‚Äúcompletely discard‚Äù. <br><br>  Let us return to our example - a language model that predicts the next word based on all the previous ones.  In this case, the state of the cell must preserve the noun in order to then use pronouns of the corresponding gender.  When we see a new noun, we can forget the genus of the old. <br><br><img src="https://habrastorage.org/web/a5f/31a/104/a5f31a104b184217aca105de9ab6d320.png"><br><br>  The next step is to decide which new information will be stored in the cell state.  This stage consists of two parts.  First, a sigmoid layer called ‚Äúinput layer gate‚Äù determines which values ‚Äã‚Äãshould be updated.  Then the tanh layer builds a vector of new candidate values. <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-7-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mtext>&amp;#xA0;</mtext><mi>t</mi><mi>i</mi><mi>l</mi><mi>d</mi><mi>e</mi><msub><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>C</mi></mrow><mi>t</mi></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="7.703ex" height="2.419ex" viewBox="0 -780.1 3316.6 1041.5" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/wunderfund/blog/331310/&amp;xid=17259,15700022,15700043,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjGx8rxka6v1Q4YbDfCA8IfxuegbA#MJMATHI-74" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/wunderfund/blog/331310/&amp;xid=17259,15700022,15700043,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjGx8rxka6v1Q4YbDfCA8IfxuegbA#MJMATHI-69" x="611" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/wunderfund/blog/331310/&amp;xid=17259,15700022,15700043,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjGx8rxka6v1Q4YbDfCA8IfxuegbA#MJMATHI-6C" x="957" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/wunderfund/blog/331310/&amp;xid=17259,15700022,15700043,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjGx8rxka6v1Q4YbDfCA8IfxuegbA#MJMATHI-64" x="1255" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/wunderfund/blog/331310/&amp;xid=17259,15700022,15700043,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjGx8rxka6v1Q4YbDfCA8IfxuegbA#MJMATHI-65" x="1779" y="0"></use><g transform="translate(2245,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/wunderfund/blog/331310/&amp;xid=17259,15700022,15700043,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjGx8rxka6v1Q4YbDfCA8IfxuegbA#MJMATHI-43" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/wunderfund/blog/331310/&amp;xid=17259,15700022,15700043,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjGx8rxka6v1Q4YbDfCA8IfxuegbA#MJMATHI-74" x="1011" y="-213"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtext>&nbsp;</mtext><mi>t</mi><mi>i</mi><mi>l</mi><mi>d</mi><mi>e</mi><msub><mrow class="MJX-TeXAtom-ORD"><mi>C</mi></mrow><mi>t</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-7"> \ tilde {C} _t </script>  that can be added to the cell state. <br><br>  In our example with the language model in this step, we want to add the gender of the new noun, replacing the old one. <br><br><img src="https://habrastorage.org/web/248/bf4/a75/248bf4a75ab74bf180b9c0e2e2cc5a58.png"><br><br>  It is time to replace the old cell state. <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-8-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>C</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi><mo>&amp;#x2212;</mo><mn>1</mn></mrow></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="4.588ex" height="2.539ex" viewBox="0 -780.1 1975.5 1093.4" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/wunderfund/blog/331310/&amp;xid=17259,15700022,15700043,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjGx8rxka6v1Q4YbDfCA8IfxuegbA#MJMATHI-43" x="0" y="0"></use><g transform="translate(715,-150)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/wunderfund/blog/331310/&amp;xid=17259,15700022,15700043,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjGx8rxka6v1Q4YbDfCA8IfxuegbA#MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/wunderfund/blog/331310/&amp;xid=17259,15700022,15700043,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjGx8rxka6v1Q4YbDfCA8IfxuegbA#MJMAIN-2212" x="361" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/wunderfund/blog/331310/&amp;xid=17259,15700022,15700043,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjGx8rxka6v1Q4YbDfCA8IfxuegbA#MJMAIN-31" x="1140" y="0"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>C</mi><mrow class="MJX-TeXAtom-ORD"><mi>t</mi><mo>‚àí</mo><mn>1</mn></mrow></msub></math></span></span><script type="math/tex" id="MathJax-Element-8"> C_ {t-1} </script>  on a new state <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-9-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>C</mi><mi>t</mi></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.488ex" height="2.419ex" viewBox="0 -780.1 1071.1 1041.5" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/wunderfund/blog/331310/&amp;xid=17259,15700022,15700043,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjGx8rxka6v1Q4YbDfCA8IfxuegbA#MJMATHI-43" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/wunderfund/blog/331310/&amp;xid=17259,15700022,15700043,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjGx8rxka6v1Q4YbDfCA8IfxuegbA#MJMATHI-74" x="1011" y="-213"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>C</mi><mi>t</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-9"> C_t </script>  .  What we need to do - we have already decided on the previous steps, it remains only to complete it. <br><br>  We multiply the old state by <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-10-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>f</mi><mi>t</mi></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.965ex" height="2.419ex" viewBox="0 -780.1 846.1 1041.5" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/wunderfund/blog/331310/&amp;xid=17259,15700022,15700043,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjGx8rxka6v1Q4YbDfCA8IfxuegbA#MJMATHI-66" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/wunderfund/blog/331310/&amp;xid=17259,15700022,15700043,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjGx8rxka6v1Q4YbDfCA8IfxuegbA#MJMATHI-74" x="693" y="-213"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>f</mi><mi>t</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-10"> f_t </script>  , forgetting what we decided to forget.  Then add <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-11-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>i</mi><mi>t</mi></msub><mo>&amp;#x2217;</mo><mtext>&amp;#xA0;</mtext><mi>t</mi><mi>i</mi><mi>l</mi><mi>d</mi><mi>e</mi><msub><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>C</mi></mrow><mi>t</mi></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="11.526ex" height="2.419ex" viewBox="0 -780.1 4962.7 1041.5" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/wunderfund/blog/331310/&amp;xid=17259,15700022,15700043,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjGx8rxka6v1Q4YbDfCA8IfxuegbA#MJMATHI-69" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/wunderfund/blog/331310/&amp;xid=17259,15700022,15700043,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjGx8rxka6v1Q4YbDfCA8IfxuegbA#MJMATHI-74" x="488" y="-213"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/wunderfund/blog/331310/&amp;xid=17259,15700022,15700043,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjGx8rxka6v1Q4YbDfCA8IfxuegbA#MJMAIN-2217" x="923" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/wunderfund/blog/331310/&amp;xid=17259,15700022,15700043,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjGx8rxka6v1Q4YbDfCA8IfxuegbA#MJMATHI-74" x="1896" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/wunderfund/blog/331310/&amp;xid=17259,15700022,15700043,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjGx8rxka6v1Q4YbDfCA8IfxuegbA#MJMATHI-69" x="2257" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/wunderfund/blog/331310/&amp;xid=17259,15700022,15700043,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjGx8rxka6v1Q4YbDfCA8IfxuegbA#MJMATHI-6C" x="2603" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/wunderfund/blog/331310/&amp;xid=17259,15700022,15700043,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjGx8rxka6v1Q4YbDfCA8IfxuegbA#MJMATHI-64" x="2901" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/wunderfund/blog/331310/&amp;xid=17259,15700022,15700043,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjGx8rxka6v1Q4YbDfCA8IfxuegbA#MJMATHI-65" x="3425" y="0"></use><g transform="translate(3891,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/wunderfund/blog/331310/&amp;xid=17259,15700022,15700043,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjGx8rxka6v1Q4YbDfCA8IfxuegbA#MJMATHI-43" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/wunderfund/blog/331310/&amp;xid=17259,15700022,15700043,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjGx8rxka6v1Q4YbDfCA8IfxuegbA#MJMATHI-74" x="1011" y="-213"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>i</mi><mi>t</mi></msub><mo>‚àó</mo><mtext>&nbsp;</mtext><mi>t</mi><mi>i</mi><mi>l</mi><mi>d</mi><mi>e</mi><msub><mrow class="MJX-TeXAtom-ORD"><mi>C</mi></mrow><mi>t</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-11"> i_t * \ tilde {C} _t </script>  .  These are new candidate values ‚Äã‚Äãmultiplied by <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-12-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>t</mi></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="0.84ex" height="1.937ex" viewBox="0 -728.2 361.5 834" role="img" focusable="false" style="vertical-align: -0.246ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://habr.com/ru/company/wunderfund/blog/331310/&amp;xid=17259,15700022,15700043,15700186,15700191,15700248,15700253&amp;usg=ALkJrhjGx8rxka6v1Q4YbDfCA8IfxuegbA#MJMATHI-74" x="0" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>t</mi></math></span></span><script type="math/tex" id="MathJax-Element-12"> t </script>  - how much we want to update each of the state values. <br><br>  In the case of our language model, this is the moment when we throw out information about the gender of the old noun and add new information. <br><br><img src="https://habrastorage.org/web/30e/ffa/7f9/30effa7f98274deaa65cf2e293f18365.png"><br><br>  Finally, you need to decide what information we want to receive at the output.  The output will be based on our cell status, and some filters will be applied to them.  First, we apply a sigmoidal layer that decides what information from the state of the cell we will output.  Then the state values ‚Äã‚Äãof the cell pass through the tanh-layer to get the output values ‚Äã‚Äãfrom the range from -1 to 1, and are multiplied with the output values ‚Äã‚Äãof the sigmoidal layer, which allows you to display only the required information. <br><br>  We may want our language model, finding a noun, to display information that is important for the verb following it.  For example, she can deduce whether the noun is singular or plural in order to correctly determine the form of the subsequent verb. <br><br><img src="https://habrastorage.org/web/16d/5b5/783/16d5b5783ba34244afcf0f240133fb28.png"><br><br><h2>  <font color="#c75733">LSTM variations</font> </h2><br>  We have just reviewed the regular LSTM;  but not all LSTM are the same.  In general, it seems that each new work on LSTM uses its own version of LSTM.  The differences between them are minor, but some of them are worth mentioning. <br><br>  One of the popular variations of LSTM, proposed by <a href="">Gers &amp; Schmidhuber (2000)</a> , is characterized by the addition of so-called ‚Äúpeephole connections‚Äù.  With their help, filter layers can see the state of the cell. <br><br><img src="https://habrastorage.org/web/867/730/01d/86773001dcfe4fa5bb2a5e4959c00752.png"><br><br>  In the diagram above, each layer has ‚Äúeyes‚Äù, but in many papers they are added only to certain layers. <br><br>  Other modifications include combined forgetting filters and input filters.  In this case, decisions about which information should be forgotten, and which to remember, are not taken separately, but jointly.  We forget any information only when it is necessary to write something in its place.  We add new information with the state of the cell only when we forget the old one. <br><br><img src="https://habrastorage.org/web/832/da7/1b7/832da71b713b4664baac512f6efecefa.png"><br><br>  Managed recurrent neurons (Gated recurrent units, GRU), first described in <a href="http://arxiv.org/pdf/1406.1078v3.pdf">Cho, et al (2012),</a> differ slightly from the standard LSTM.  In it, the ‚Äúforgetting‚Äù and entry filters are combined into one ‚Äúupdate gate‚Äù filter.  In addition, the state of the cell is combined with the hidden state, there are other small changes.  The resulting model is simpler than the standard LSTM, and its popularity is steadily increasing. <br><br><img src="https://habrastorage.org/web/799/9b4/b17/7999b4b17bb448f694edfebd2f1b762a.png"><br><br>  We looked at just a few of the most remarkable variations of LSTM.  There are many other modifications, such as deep controlled recurrent neural networks (Depth Gated RNNs), presented in <a href="http://arxiv.org/pdf/1508.03790v2.pdf">Yao, et al (2015)</a> .  There are other ways to solve the problem of long-term dependencies, for example, <a href="http://arxiv.org/pdf/1402.3511v1.pdf">Jan Kutnik's</a> Clockwork RNN <a href="http://arxiv.org/pdf/1402.3511v1.pdf">(Koutnik, et al., 2014)</a> . <br><br>  What is the best option?  What is the role of the differences between them?  <a href="http://arxiv.org/pdf/1503.04069.pdf">Klaus Greff (Klaus Greff) and colleagues</a> give a good comparison of the most popular variations of LSTM and in their work come to the conclusion that they are all approximately the same.  <a href="http://jmlr.org/proceedings/papers/v37/jozefowicz15.pdf">Rafal Jozefowicz, et al,</a> in his 2015 work, tested more than ten thousand RNN architectures and found several solutions that work on certain tasks better than LSTM. <br><br><h2>  <font color="#c75733">Conclusion</font> </h2><br>  We have previously mentioned outstanding results that can be achieved using RNN.  In essence, all these results were obtained on LSTM.  On most tasks, they actually work better. <br><br>  LSTMs written in the form of a system of equations look pretty frightening.  We hope that the step by step analysis of LSTM in this article made them more accessible. <br><br>  LSTM is a big step in the development of RNN.  This raises a natural question: what will be the next big step?  According to the general opinion of researchers, the next big step is ‚Äúattention‚Äù (attention).  The idea is this: each RNN step takes data from a larger repository of information.  For example, if we use RNN to generate a caption for an image, then that RNN can view the image in parts and generate individual words based on each part.  The work of <a href="http://arxiv.org/pdf/1502.03044v2.pdf">Kelvin Xu (Xu, et al., 2015)</a> , devoted to just such a task, can serve as a good starting point for those who want to study such a mechanism as ‚Äúattention‚Äù.  Researchers have already managed to achieve impressive results using this principle, and it seems there are still many discoveries ahead ... <br><br>  Attention is not the only interesting area of ‚Äã‚Äãresearch in RNN.  For example, the Grid LSTM described in <a href="http://arxiv.org/pdf/1507.01526v1.pdf">Kalchbrenner, et al.</a>  <a href="http://arxiv.org/pdf/1507.01526v1.pdf">(2015)</a> seem very promising.  Studies on the use of RNN in generative models ( <a href="http://arxiv.org/pdf/1502.04623.pdf">Gregor, et al. (2015)</a> , <a href="http://arxiv.org/pdf/1506.02216v3.pdf">Chung, et al. (2015)</a> or <a href="http://arxiv.org/pdf/1411.7610v3.pdf">Bayer &amp; Osendorfer (2015) are</a> also extremely interesting. The last few years are the heyday of recurrent neural networks, and the next years promise to bring even greater fruits. <br><br><blockquote><div class="spoiler">  <b class="spoiler_title">Oh, and come to work with us?</b>  <b class="spoiler_title">:)</b> <div class="spoiler_text">  <a href="http://wunderfund.io/"><b>wunderfund.io</b></a> is a young foundation that deals with <a href="https://en.wikipedia.org/wiki/High-frequency_trading">high-frequency algorithmic trading</a> .  High-frequency trading is a continuous competition of the best programmers and mathematicians of the whole world.  By joining us, you will become part of this fascinating fight. <br><br>  We offer interesting and challenging data analysis and low latency tasks for enthusiastic researchers and programmers.  Flexible schedule and no bureaucracy, decisions are quickly made and implemented. <br><br>  Join our team: <a href="http://wunderfund.io/">wunderfund.io</a> </div></div></blockquote></div><p>Source: <a href="https://habr.com/ru/post/331310/">https://habr.com/ru/post/331310/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../331300/index.html">Vulnerability Stack Clash allows you to get root-privileges in Linux and other operating systems</a></li>
<li><a href="../331302/index.html">Birobidzhan on the bright side: how we have lit up the city for our money</a></li>
<li><a href="../331304/index.html">How do neural networks help us with technical support</a></li>
<li><a href="../331306/index.html">Modern convergent technologies on the market in the Russian Federation - let's try to compare? Import Substitution, Ceph + OpenStack, Nutanix</a></li>
<li><a href="../331308/index.html">Xamarin.Forms for WPF and UWP developers</a></li>
<li><a href="../331312/index.html">How to win in Vkontakte repost contests?</a></li>
<li><a href="../331314/index.html">An example of the synthesis of asynchronous SI circuits in a two-way element base: C-element</a></li>
<li><a href="../331316/index.html">CSS: introduction to the unit of length 'fr'</a></li>
<li><a href="../331318/index.html">Announcement DotNext 2017 Moscow: a double portion of .NET</a></li>
<li><a href="../331324/index.html">Oracle I / O Life: Tracing logical and physical I / O using SystemTap</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>