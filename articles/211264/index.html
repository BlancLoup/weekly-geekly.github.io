<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Counting Hamming distances on a large dataset</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="This article will discuss the HEngine algorithm and the implementation of the solution to the problem of calculating the Hamming distance on large dat...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Counting Hamming distances on a large dataset</h1><div class="post__text post__text-html js-mediator-article">  This article will discuss the HEngine algorithm and the implementation of the solution to the problem of calculating the Hamming distance on large data volumes. <br><a name="habracut"></a><br><h4>  Introduction </h4><br>  Hamming distance is the number of different positions for rows with the same length.  For example, HD ( <b>1</b> 0 <b>0</b> , <b>0</b> 0 <b>1</b> ) = 2. <br><br>  For the first time, the problem of calculating the Hamming distance was posed by Minsky and Papert in 1969 [1], where the task was to search for all the rows from the database that are within the specified Hamming distance to the requested one. <br><br>  Such a task is unusually simple, but the search for its effective solution still remains on the agenda. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Hamming distance is already quite widely used for various tasks, such as finding close duplicates, pattern recognition, document classification, error correction, virus detection, etc. <br><br>  For example, Manku and associates proposed a solution to the problem of clustering duplicates when indexing web documents based on Hamming distance [2]. <br>  Also, Miller and friends suggested the concept of searching songs for a given audio fragment [3], [4]. <br>  Similar solutions were used for the task of image search and recognition of the retina [5], [6], etc. <br><br><h4>  Description of the problem </h4><br>  There is a database of binary strings <i>T</i> , of size <i>n</i> , where the length of each string is <i>m</i> .  The requested string <i>a</i> and the required Hamming distance <i>k</i> . <br><br>  The task is reduced to finding all the lines that are within the distance <i>k</i> . <br><br>  In the original concept of the algorithm, two variants of the problem are considered: static and dynamic. <br><br>  - In the static task, the distance k is predefined. <br>  - In dynamic, on the contrary, the required distance is not known in advance. <br><br>  The article describes the solution only static problem. <br><br><h5>  Description of the HEngine algorithm for a static task </h5><br>  This implementation focuses on finding strings within <i>k</i> &lt;= 10. <br><br>  There are three solutions to the static problem: linear search (linear scan), query expansion (query expansion) and database expansion (table expansion). <br><br>  In this case, the <i>expansion of the request</i> means the generation of all possible variants of lines that fit into a given distance for the original line. <br>  <i>Expanding a</i> database involves creating multiple copies of this database, where either all possible options are generated that meet the requirements of the required distance, or the data is processed in some other way (more on this in more detail.). <br><br>  HEngine [8] uses a combination of these three methods to effectively balance memory and execution time. <br><br><h5>  Some theory </h5><br>  The algorithm is based on a small theorem that says the following: <br><br>  If for two lines <i>a</i> and <i>b the</i> distance HD ( <i>a</i> , <i>b</i> ) &lt;= <i>k</i> , then if you divide the lines <i>a</i> and <i>b</i> into substrings using the <i>rcut</i> method using <i>the segmentation factor</i> <br>  <i>r</i> &gt; = ‚åä <i>k</i> / 2‚åã + 1 <br>  there must be at least <i>q</i> = <i>r</i> - ‚åä <i>k</i> / 2‚åã substrings when their distance does not exceed one, HD ( <i>a</i> i, <i>b</i> i) &lt;= 1. <br><br>  The selection of substrings from the base line using the <i>rcut</i> method <i>is</i> performed according to the following principles: <br>  A value called <i>a segmentation factor</i> that satisfies the condition is selected. <br>  <i>r</i> &gt; = ‚åä <i>k</i> / 2‚åã + 1 <br><br>  The length of the first <i>r</i> - ( <i>m</i> mod <i>r</i> ) substrings will have a length ‚åä <i>m</i> / <i>r</i> ‚åã, and the last <i>m</i> mod <i>r</i> substrings ‚åà <i>m</i> / <i>r</i> ‚åâ.  Where <i>m</i> is the length of the string, ‚åä is rounding to the nearest below, and ‚åâ rounding to the nearest above. <br><br>  Now the same thing, just for example: <br><br>  Two binary strings with length <i>m</i> = 8 bits are given: A = 11110000 and B = 11010001, the distance between them is <i>k</i> = 2. <br>  Select the segmentation factor <i>r</i> = 2/2 + 1 = 2, i.e. there will be 2 substrings of length <i>m</i> / <i>r</i> = 4 bits. <br><br>  a1 = 1111, a2 = 0000 <br>  b1 = 1101, b2 = 0001 <br><br>  If we now calculate the distance between the corresponding substrings, then at least ( <i>q</i> = 2 - 2/2 = 1) one substring will coincide or their distance will not exceed one. <br><br>  What we see: <br>  HD (a1, b1) = HD (1111, 1101) = 1 <br>  and <br>  HD (a2, b2) = HD (0000, 0001) = 1 <br><br>  The substrings of the base string were called <i>signatures</i> . <br>  Signatures or substrings a1 and b1 (a2 and b2, a3 and b3 ..., a <i>r</i> and b <i>r</i> ) are called <i>compatible</i> with each other, and if their number of differing bits is not greater than one, then these signatures are called <i>coincident</i> . <br><br>  And the main idea of ‚Äã‚Äãthe HEngine algorithm is to prepare the database in such a way as to find matching signatures and then select those lines that are within the required Hamming distance. <br><br><h5>  Database Preprocessing </h5><br>  We already know that if you correctly divide a string into substrings, then at least one substring will coincide with the corresponding substring, or the number of different bits will not exceed one (the signatures will match). <br><br>  This means that we do not need to perform a full search through all the rows from the database, but it is required to first find those signatures that match, i.e.  substrings will differ by a maximum of one. <br><br>  But how to search by substrings? <br><br>  The binary search method should do a good job of this.  But it requires the list of strings to be sorted.  But we get several substrings from one string.  To perform a binary search on a list of substrings, it is necessary that each such list is sorted in advance. <br>  Therefore, this suggests a method for expanding the database, that is, creating several tables, each for its own substring or signature.  (Such a table is called <i>a signature table</i> . And the totality of such tables is a <i>set of signatures</i> ). <br><br>  In the original version of the algorithm, the permutation of substrings is described so that the selected substrings come first.  This is done more for ease of implementation and for further optimization of the algorithm: <br><br>  There is a string A, which is divided into 3 substrings, a1, a2, a3, the full list of permutations will be respectively: <br>  a1, a2, a3 <br>  a2, a1, a3 <br>  a3, a1, a2 <br><br>  These signature tables are then sorted. <br><br><h5>  Implementation of the search </h5><br>  At this stage, after preliminary processing of the database, we have several copies of the sorted tables, each for its own substring. <br><br>  Obviously, if we want to first find the substrings, it is necessary to obtain signatures from the requested string in the same way that was used when creating signature tables. <br><br>  We also know that the required substrings differ by a maximum of one element.  And to find them you need to use the query expansion method (query expansion). <br><br>  In other words, it is required for the selected substring to generate all the combinations including this substring itself, at which the difference will be a maximum of one element.  The number of such combinations will be equal to the length of the substring + 1. <br><br>  And then perform a binary search in the corresponding signature table for a full match. <br><br>  Such actions should be made for all substrings and for all tables. <br><br>  And at the very end, you will need to filter those lines that do not fit into the specified Hamming distance.  Those.  perform a linear search on the found lines and leave only those lines that meet the condition HD ( <i>a</i> , <i>b</i> ) &lt;= <i>k</i> . <br><br><h5>  Bloom filter </h5><br>  The authors suggest using the Bloom filter [7] to reduce the number of binary searches. <br>  The Bloom filter can quickly determine if a substring is in the table with a small percentage of false positives.  What works faster than a hash table. <br><br>  If before a binary search for substrings in a table, the filter returns that this substring is not in this table, then there is no point in searching. <br><br>  Accordingly, you must create one filter for each signature table. <br><br>  The authors also note that using the Bloom filter in this way reduces the request processing time by an average of 57.8%. <br><br><h5>  Now the same thing, just by example </h5><br>  There is a binary string database with a length of 8 bits: <br>  11111111 <br>  10,000,001 <br>  00111110 <br><br>  The task is to find all the lines where the number of different bits does not exceed 2 to the target line 10111111. <br>  So the required distance is <i>k</i> = 2. <br><br>  1. Choose a segmentation factor. <br>  Based on the formula, we choose the segmentation factor <i>r</i> = 2 and it means that there will be two substrings from one string in all. <br><br>  2. Create a set of signatures. <br>  Since the number of substrings is 2, then only 2 tables need to be created: <br>  T1 and T2 <br><br>  3. Save the substrings in the corresponding tables with the reference to the source. <br><br>  T1 T2 <br>  1111 1111 =&gt; 11111111 <br>  1000 0001 =&gt; 10000001 <br>  0011 1110 =&gt; 00111110 <br><br>  4. Sort the tables.  Each separately. <br>  T1 <br>  0011 =&gt; 00111110 <br>  1000 =&gt; 10000001 <br>  1111 =&gt; 11111111 <br><br>  T2 <br>  0001 =&gt; 10000001 <br>  1110 =&gt; 00111110 <br>  1111 =&gt; 11111111 <br><br>  This completes the pre-processing.  And proceed to search. <br><br>  1. Get the signatures of the requested string. <br>  The search string 10111110 is broken into signatures.  It turns out 1011 and 1100, respectively, the first for the first table, and the second for the second. <br><br>  2. We generate all combinations differing on unit. <br>  The number of options will be 5. <br><br>  2.1 For the first substring 1011: <br>  1011 <br>  <b>0</b> 011 <br>  1 <b>1</b> 11 <br>  10 <b>0</b> 1 <br>  101 <b>0</b> <br><br>  2.2 For the second substring 1100: <br>  1100 <br>  <b>0</b> 100 <br>  1 <b>0</b> 00 <br>  11 <b>1</b> 0 <br>  110 <b>1</b> <br><br>  3. Binary search. <br><br>  3.1 For all generated variants of the first substring 1011, we perform a binary search in the first table for a full match. <br><br>  1011 <br>  0011 == 0011 =&gt; 00111110 <br>  1111 == 1111 =&gt; 11111111 <br>  1001 <br>  1010 <br><br>  Found two substrings. <br><br>  3.2 Now for all variants of the second substring 1100 we perform a binary search in the second table. <br><br>  1100 <br>  0100 <br>  1000 <br>  1110 == 1110 =&gt; 00111110 <br>  1101 <br><br>  Found one substring. <br><br>  4. Combining results into one list: <br>  00111110 <br>  11111111 <br><br>  5. Linearly check for compliance and filter out unsuitable by the condition &lt;= 2: <br><br>  HD (10111110, 00111110) = 1 <br>  HD (10111110, 11111111) = 2 <br><br>  Both strings satisfy the condition of difference of no more than two elements. <br><br>  Although a linear search is being performed at this stage, it is expected that the list of candidates will not be large at all. <br>  Under conditions when the number of candidates will be large, it is proposed to use the recursive version of HEngine. <br><br><h5>  Visually </h5><br>  Figure 1 shows an example of the search algorithm. <br>  For line length 64 and the distance limit is 4, the segmentation factor is 3, respectively, only 3 substrings per line. <br>  Where T1, T2 and T3 are signature tables that contain only substrings B1, B2, B3, 21, 21 and 22 bits long. <br><br>  The requested string is divided into substrings.  Next, a signature range is generated for the corresponding substrings.  For the first and second signatures, the number of combinations will be 22. And the last signature gives 23 variants.  And finally a binary search is performed. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/fd9/49b/53d/fd949b53db342573e3712014a19c6cd2.png"><br>  <i>Figure 1. Simplified version of processing requests to signature tables.</i> <br><br><h5>  results </h5><br>  The complexity of this algorithm is, on average, <i>O</i> ( <i>P</i> * (log <i>n</i> + 1)), where <i>n</i> is the total number of rows in the database, log <i>n</i> + 1 is a binary search, and <i>P</i> is the number of binary searches: in our case, it is considered the number of combinations per table cleared by the number of tables: <i>P</i> = (64 / <i>r</i> + 1) * <i>r</i> <br><br>  In extreme cases, the complexity may exceed the linear. <br><br>  It is noted that this approach uses 4.65 less memory and is 16% faster than the previous work described in [2].  And is the fastest way from now known to find all the lines in a given limit. <br><br><h4>  Implementation </h4><br>  All this of course is tempting, but until you touch it in practice, it is difficult to assess the scale. <br>  A prototype of HEngine [9] was created and tested on the available real data. <br><br><pre><code class="bash hljs">tests$ ./matches 7 data/db/table.txt data/query/face2.txt Reading the dataset ........ <span class="hljs-keyword"><span class="hljs-keyword">done</span></span>. 752420 db hashes and 343 query hashes. Building with 7 hamming distance bound ....... <span class="hljs-keyword"><span class="hljs-keyword">done</span></span>. Building time: 12.964 seconds Searching HEngine matches ....... found 100 total matches. HEngine query time: 0.1 seconds Searching linear matches ....... found 100 total matches. Linear query time: 6.828 seconds</code> </pre> <br><br>  The results were pleasing, because the search for 343 hashes from the 752420 database takes ~ 0.1 seconds, which is 60 times faster than the linear search. <br><br>  It would seem that one could stop there.  But I really wanted to try to use it somehow in a real project. <br><br><h5>  One click to real use </h5><br>  There is a database of image hashes, and backend in PHP. <br>  The task was to somehow link the functionality of HEngine and PHP. <br>  It was decided to use FastCGI [10], in this I was greatly helped by posts <a href="http://habrahabr.ru/post/154187/">habrahabr.ru/post/154187</a> and <a href="http://habrahabr.ru/post/61532/">habrahabr.ru/post/61532</a> . <br><br>  From PHP, just call: <br><pre> <code class="php hljs">$list = file_get_contents( <span class="hljs-string"><span class="hljs-string">'http://fcgi.local/?'</span></span> . $hashes );</code> </pre><br>  That in ~ 0.5 seconds returns the result.  When a linear search takes 9 seconds, and through MySQL queries it takes at least 20 seconds. <br><br>  Thanks to everyone who mastered. <br><br><h4>  Links </h4><br>  [1] M. Minsky and S. Papert.  Perceptrons.  MIT Press, Cambridge, MA, 1969. <br>  [2] GS Manku, A. Jain, and AD Sarma.  Detecting nearduplicates for web crawling.  In Proc.  16Th WWW, May 2007. <br>  [3] ML Miller, MA Rodriguez, and IJ Cox.  Audio fingerprinting: The nearest binary search in high-dimensional binary space.  In MMSP, 2002. <br>  [4] ML Miller, MA Rodriguez, and IJ Cox.  Audio fingerprinting: high resolution binary spaces.  Journal of VLSI Signal Processing, Springer, 41 (3): 285‚Äì291, 2005. <br>  [5] J. Landr ÃÅe and F. Truchetet.  Image retrieval with binary hamming distance.  In Proc.  2nd VISAPP, 2007. <br>  [6] H. Yang and Y. Wang.  A hammock distance constraint.  In Proc.  Fourth ICIG, 2007. <br>  [7] B. Bloom.  Space / time trade-offs in hash coding with allowable errors.  Communications of ACM, 13 (7): 422‚Äì426, 1970. <br>  [8] Alex X. Liu, Ke Shen, Eric Torng.  Large Scale Hamming Distance Query Processing.  ICDE Conference, pages 553 - 564, 2011. <br>  [9] <a href="https://github.com/valbok/HEngine/">github.com/valbok/HEngine</a> My implementation of HEngine in C ++ <br>  [10] <a href="">github.com/valbok/HEngine/blob/master/bin/fastcgi.cpp</a> Example wrapper program for searching hashes through FastCGI. </div><p>Source: <a href="https://habr.com/ru/post/211264/">https://habr.com/ru/post/211264/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../211246/index.html">What features does a student need in a mobile phone?</a></li>
<li><a href="../211248/index.html">Moto G Review: The Last True "Motor"</a></li>
<li><a href="../211256/index.html">Baboom: Kim Dotcom New Project</a></li>
<li><a href="../211260/index.html">Example of jQuery UI + PHP and GD. Application of the image</a></li>
<li><a href="../211262/index.html">HP will pay a record $ 150K for an exploit at Pwn2Own 2014</a></li>
<li><a href="../211266/index.html">Save health% username%: sports search engine</a></li>
<li><a href="../211270/index.html">NERSC launches Edison supercomputer with 2.4 petaflops performance</a></li>
<li><a href="../211272/index.html">Part 3. Meet - laser called Amaris. Moving and first awakening of VisuMax</a></li>
<li><a href="../211278/index.html">Utopia replace Silk Road?</a></li>
<li><a href="../211282/index.html">Difficulties of choice</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>