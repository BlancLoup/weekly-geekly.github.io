<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Finding and solving scalability problems using the example of multi-core Intel Core 2 processors (part 4)</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Article continuation: part 1 , part 2 , part 3 


 Probably the simplest example is the parallel summation algorithm for the values ‚Äã‚Äãof array element...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Finding and solving scalability problems using the example of multi-core Intel Core 2 processors (part 4)</h1><div class="post__text post__text-html js-mediator-article">  Article continuation: <a href="http://habrahabr.ru/blogs/hi/107620/">part 1</a> , <a href="http://habrahabr.ru/blogs/hi/107621/">part 2</a> , <a href="http://habrahabr.ru/blogs/hi/107622/">part 3</a> <br><a name="habracut"></a><br><br>  Probably the simplest example is the parallel summation algorithm for the values ‚Äã‚Äãof array elements.  In this case, each thread would add its own set of elements.  This algorithm might look like this: <br><pre><code class="cpp hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">int</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">sum</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params">* data, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params">* sum, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> size, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> tid)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> i; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span>(i=<span class="hljs-number"><span class="hljs-number">0</span></span>; i &lt; size; i++) *sum += data[i]*data[i]; <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> *sum; }</code> </pre> <br>  If the pointer ‚Äúsum‚Äù is declared as a simple array with an index that is a thread identifier, then we may encounter competition of parallel threads for the cache line containing the array element.  Generally speaking, the compiler could sum the array values ‚Äã‚Äãin the register-accumulator (eliminating the need for the variable ‚Äúsum‚Äù), and thus avoid the problem, which is actually what the Intel compiler does. <br><br>  However, not all compilers are as smart.  If the function is declared like this: <br> <code>int sum(int* data, volatile int* sum, int size, int tid)</code> <br>  then the compiler is forbidden to transfer "sum" to the register memory, which guarantees the battle for the cache line.  The above events will flow the river. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      As a second example, let's take a very simple three-fold nested loop of permutations in an array, which is excellent for our discussion. <br><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">define</span></span></span><span class="hljs-meta"> MAXTHR 4 #</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">define</span></span></span><span class="hljs-meta"> ITERS 1000 #</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">define</span></span></span><span class="hljs-meta"> SIZE 1000 int aa[MAXTHR][SIZE]; volatile int i[MAXTHR], j[MAXTHR], k[MAXTHR], n[MAXTHR], tmp[MAXTHR]; int sort(int *a, int size, int tid) </span><span class="hljs-comment"><span class="hljs-meta"><span class="hljs-comment">//a = aa[tid][0] { n[tid] = 0; for (k[tid]=0; k[tid] &lt; ITERS/2; k[tid]++){ for (i[tid] = 0; i[tid] &lt; size-1; i[tid]++){ for (j[tid] = i[tid]+1; j[tid] &lt; size; j[tid]++){ if (a[i[tid]] &gt; a[j[tid]]){ tmp[tid] = a[i[tid]]; a[i[tid]] = a[j[tid]]; a[j[tid]] = tmp[tid]; n[tid]++; } } } for (i[tid] = 0; i[tid] &lt; size-1; i[tid]++){ for (j[tid] = i[tid]+1; j[tid] &lt; size; j[tid]++){ if (a[i[tid]] &lt; a[j[tid]]){ tmp[tid] = a[i[tid]]; a[i[tid]] = a[j[tid]]; a[j[tid]] = tmp[tid]; n[tid]++; } } } } return n[tid]; }</span></span></span></span></code> </pre><br>  Looking at the code, it becomes obvious that the index arrays i, j, k and the tmp array are most likely to be in the same cache line, for which the threads will fight on each iteration of each loop.  They are specifically declared as volatile to prevent the compiler from placing them in registers, which is basically allowed by the language standard.  The language standard generally allows you to do a lot with data access for optimization purposes.  If you do not apply something like volatile to them, the compiler itself will not begin to think that this function should be executed by several threads. <br><br>  The current Intel compiler (10.0) for the Intel 64 architecture will create an executable completely free of false sharing of the cache line when optimizing O3, if the volatile ad is removed from the above function.  None of the local cycles, none of the temporary variables will ever be unloaded into memory, existing only in registers.  The appearance of non-blocking false line sharing is generally very dependent on the compiler.  There are innumerable variations on this topic when a programmer starts using optimizations like inline functions, splitting functions into parts, and so on. <br><br>  Suppose we collected data using the VTune Analyzer, then we look at the dependencies between the event quantities.  The number of EXT_SNOOP.ALL_AGENTS_HITM is approximately equal to BUS_HITM_DRV.  Pay attention to how the application behaves from launch to launch, what happens to the events.  MEM_LOAD_RETIRED.L2_MISS is much more than MEM_LOAD_RETIRED.L2_LINE_MISS.  The number of MEM_LOAD_RETIRED.L2_LINE_MISS is much less than the number of cache lines transmitted on the bus, judging by BUS_TRANS_BURST.SELF.  The greatest contribution is made to requests for exclusive use (RFO), measured by the BUS_TRANS_RFO.SELF event.  Evaluate the RFO contribution to the bus traffic, measured by BUS_TRANS_BURST.SELF. <br><br>  The balance is estimated in total readings, measured by BUS_TRANS_BRD.SELF.  The L2_LD.SELF event is useful for finding out the state of the cache line, especially if the influence of hardware prefetch blocks is very strong. <br><br>  Consequently, in order to determine whether there is a competition for cache lines, it would be reasonable to collect data with a single-threaded count in order to determine the baseline values, and only then with a multi-threaded one.  To identify spurious line sharing, it is probably best to look at MEM_LOAD_RETIRED.L2_MISS by comparing the numbers and locations of the peaks of this event when viewing the source code in the VTune Analyzer.  Usually, everything becomes immediately clear, if you also pay attention to EXT_SNOOPS.ALL_AGENTS.HITM. <br><br>  Finding access lock conflicts is also quite simple.  The L2_LOCK.SELF.E_STATE event occurs whenever an access lock (other than the xchg instruction) is used to create a mutex lock.  If the locked item has been modified, then the L2_LOCK.SELF.M_STATE event will also occur.  Due to the IP prefetch block, the MEM_LOAD_RETIRE.L2_LINE_MISS event is not efficient for our search.  In this case, the peaks MEM_LOAD_RETIRED.L2_MISS together with L2_LD.LOCK.E_STATE when viewing the source code in the VTune Analyzer clarify the picture of the incident.  EXT_SNOOP.HITM.ALL_AGENTS is again present in these cases. <br><br>  Competition for a locked cache line is often driven by the use of a synchronization API.  The above primitive analysis of the collected data will probably show that the application spends an arbitrary part of the time in the synchronization wait cycle.  In this case, it is necessary to find where this API is called in order to understand whether it is possible to reduce the execution sequence caused by variable locks by changing the code.  The location of these bottlenecks can be quickly determined using the call graph in the VTune Analyzer or Intel Thread Profiler. <br><br>  While competition for cache lines is characteristic of the shared memory parallelization model, an excessive drop in scalability is also possible due to the abuse of synchronization operations in MPI.  Synchronous messaging, MPI_Wait, and MPI global operations (MPI_Allreduce for example) can have a similar effect on performance, as in the cases described above.  Intel Trace Analyzer and Collector was created just to find such MPI problems.  Using this program is simply necessary to achieve the best MPI scaling in a large cluster environment based on Intel Core 2 processors. <br><br><h4>  Conclusion </h4><br>  The Intel Core 2 processor has a fairly well developed hierarchy of performance events, which is very effective in analyzing problems with low speed performance.  Many reasons for poor scaling in a multi-core environment can be quickly and easily identified using the Intel VTune Performance Analyzer.  To resolve more complex thread synchronization issues, there is the Intel Thread Profiler.  For MPI, Intel Trace Analyzer and Collector is recommended. </div><p>Source: <a href="https://habr.com/ru/post/107624/">https://habr.com/ru/post/107624/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../107614/index.html">War for the social graph</a></li>
<li><a href="../107619/index.html">Canobuvosti, 64th edition</a></li>
<li><a href="../107620/index.html">Finding and solving scalability problems using the example of multi-core Intel Core 2 processors (part 1)</a></li>
<li><a href="../107621/index.html">Finding and solving scalability problems using the example of multi-core Intel Core 2 processors (part 2)</a></li>
<li><a href="../107622/index.html">Finding and solving scalability problems using the example of multi-core Intel Core 2 processors (part 3)</a></li>
<li><a href="../107625/index.html">Registration of your company with your own hands, tudu list</a></li>
<li><a href="../107627/index.html">A few words about usability and keyboard layout</a></li>
<li><a href="../107628/index.html">Trend Micro raises scandal over MS Security Essentials through Windows Update</a></li>
<li><a href="../107629/index.html">Nicaraguan military wandered into the territory of another country because of Google</a></li>
<li><a href="../107630/index.html">Wikileaks CEO intends to live and work in Switzerland</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>