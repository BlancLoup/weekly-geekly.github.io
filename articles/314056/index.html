<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Optimization by example. Ant algorithm (ACS) vs Annealing Method. Part 2</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="I continue the series of articles ‚ÄúOptimization by Example‚Äù. This article compares two heuristic algorithms on the hackneyed symmetric traveling sales...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Optimization by example. Ant algorithm (ACS) vs Annealing Method. Part 2</h1><div class="post__text post__text-html js-mediator-article">  I continue the series of articles ‚ÄúOptimization by Example‚Äù.  This article compares two heuristic algorithms on the <strike>hackneyed</strike> symmetric traveling salesman problem.  Today, we delve deeper into this topic and analyze a specific modification of the ant algorithm. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/303/89e/e87/30389ee873a5456c8c5e186ba226bb48.jpg"></div><br><a name="habracut"></a><br>  This article does not prove which method is better in general, since both algorithms have many modifications as well as many potential modifications.  Here, only the winner is determined on a specific modification and on certain parameters.  The purpose of this article is to expand the readers ‚Äôoutlook in the field of discrete optimization, and, I hope, suggestions for improving the work of both algorithms. <br><br>  The modification of the ant algorithm was chosen by ACS (Ant Colony System), which was proposed by Marco Dorigo and Luca Gambardella in 1997.  The main differences from AS (Ant System) are: 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      1) a balance is set between the most attractive city, and the choice as in an ordinary AS <br><br>  arg max {[œÑ (r, u)] ^ Œ± * [œâ (r, u)] ^ Œ≤} if q &lt;= q0 (Formula 1) <br>  u œµ Jk "r" <br><br>  In the opposite case, select the transition to AS <br><br>  where [œÑ (r, u)] is the pheromone level on the edge (r, u), [œâ (r, u)] is the inverse weight of the distance on the edge (r, u), Œ≤ is an adjustable parameter than it is higher however, the algorithm will be inclined to choose a city that has a smaller distance, Œ± is equal to 1, q is a randomly chosen number, q0 is the probability of choosing that the transition from one vertex to another will follow the formula 1, u are cities not yet visited <br><br>  2) besides the global update of pheromones, a local one also occurs.  The level of pheromones changes as each ant passes at an iteration (closer to the natural habitat of the ants) <br><br>  œÑ (r, s) = (1-p) * œÑ (r, s) + p * œÑ0 (Formula 2) <br><br>  where p is the local update level, œÑ0 = the value of the initial pheromone, which is calculated as follows: œÑ0 = (n * Lnn) ^ - 1, where Lnn is an approximate optimal value that can be obtained by another optimization method. <br><br>  3) when the pheromone is updated globally, the addition occurs only to the edges, either the best ones since the start of the algorithm (global best), or to the best edges on the iteration (local best).  I applied to the edges of the global best. <br><br>  œÑ (r, s) = (1-e) * œÑ (r, s) + e * (Lbest ^ -1) (Formula 3) <br><br>  where e is the global update level, Lbest is the best route length (shortest), either at the k-th iteration, or global best. <br><br>  These modifications gave significant performance to the algorithm.  The annealing method is the same as in the previous article, except for an increase in speed.  Thanks to the reader <a href="https://habrahabr.ru/users/zartdinov/" class="user_link">zartdinov</a> for a simple and very effective proposal to increase the speed. <br><br>  Now we will compare the tasks on known coordinates, such as Oliver30, Eli51, Eli101, on which the best solution is found.  We also derive approximate formulas for the time dependence of the two algorithms on the number of cities, and, finally, we will try to determine the winner for today, taking into account all these factors. <br><br>  Let's start with the task Oliver30 the best solution - 423,7406 <br><br>  ACS Parameters: <br><br><ul><li>  The number of iterations (generations) - 2500 * </li><li>  The number of ants in the generation - 7 * </li><li>  Number of cities - 30 * </li><li>  alpha (coefficient of orientation to pheromones) - 1 </li><li>  beta (coefficient of orientation to the length of the path) - 2 </li><li>  p (pheromone local update rate) - 0.09 </li><li>  e (pheromone global update rate) - 0.09 </li><li>  q (selection factor of the most attractive city) - 0.9 </li><li>  the initial location of the ants - random </li></ul><br>  * - variable parameters from the dimension of the task <br><br>  A few words about the number of ants.  It would be a mistake to believe that the more ants the better.  With a large number of ants in the colony productivity drops significantly.  Firstly, the running time of the algorithm is greatly increased.  Secondly, there is a surplus of pheromones, which leads to an analogy in the natural environment, called the circle of death of ants.  Thus, the algorithm gets stuck at a local optimum. <br><br>  There is no exact determination of the number of ants in a colony, there is an approximate calculation as in [1].  Immediately I tried to find a point of optimum at which an increase in the number of ants did not improve the solution, and their reduction reduced the result.  Also, if simplified, I experimented with one ant colony at certain iterations.  As soon as the average level of pheromone began to rise - it took it as the basis for the optimal number of ants. <br><br>  So the results of the Oliver30 task: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/6bb/62c/fbe/6bb62cfbecad4c2f8cfbdc6d7b3ed6f0.png"></div><br>  Pair of charts: <br><div style="text-align:center;"><img src="https://habrastorage.org/files/839/e67/e0a/839e67e0ae2c41b58ad2b5311c4fff4c.png"></div><br>  The fourth graph shows that the algorithm continues to look for alternative ways, not stopping at what has been accomplished.  With an increase in the number of ants up to 50-100, the spread of the average generation distance decreases within the range of 20-30, which leads to sticking. <br><br>  A complete search for the symmetric traveling salesman problem is (n-1)! / 2 or <br>  4 420 880 996 869 850 977 271 808 000 000 for this task <br><br>  100% result, excellent work ACS <br><br>  Let's look at the annealing method. <br><br>  Options: <br><br><ul><li>  Number of cities - 30 * </li><li>  Initial temperature - 35,000 * </li><li>  Final temperature - 0.1 </li><li>  Temperature formula - initial temperature / kth iteration </li><li>  Number of iterations - 350,000 * </li><li>  Acceptance probability function - exp (-ŒîE / T) </li><li>  Determination of a potential route (generating family) - reversal of a part of a vector (current route) from two randomly selected numbers with a uniform distribution </li></ul><br>  * - variable parameters from the dimension of the task <br><br>  Results: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/bf3/6e7/72b/bf36e772bd8a49079c92223d3b7cb0f4.png"></div><br>  In both time and quality, in 30 cities wins by a large margin of ACS.  Tested two algorithms not only on this task, but also on the other 30 - ACS certainly wins the simple method of annealing. <br><br>  Now the challenge for Eil51 is 51 cities, the best solution is 426, 7000 iterations, number of ants 9 <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/6c5/10a/e5e/6c510ae5ee374810b6492f7eb5bf99dd.png"></div><br>  Pair of charts: <br><div style="text-align:center;"><img src="https://habrastorage.org/files/bf1/d39/8eb/bf1d398eba91467992a57ff4ae7a86d0.png"></div><br>  On the 4th graph, a regression line is added.  In general, the Eil51 problem in many foreign studies has been tested on a much larger number of iterations.  Maybe that‚Äôs why the global optimum was not found; frankly, it also tested at large iterations and the maximum that was found was 427. <br><br>  Taking this opportunity, let's look ‚Äúin real mode‚Äù at the change of pheromones from the number of iterations, I rather liked this picture. <br><br>  Without global update and with the addition of a total evaporation rate as in AS, for greater effect. <br><br><img src="https://habrastorage.org/files/8ec/e1d/53d/8ece1d53da364e579e4b24c630330f14.gif" alt="image"><br><br>  We look at the annealing method at 2 500 000 iterations <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/694/f7c/79a/694f7c79a0684b6290faa77b2cdaf559.png"></div><br>  Quite a good result, but still ACS is still ahead. <br><br>  Now the task of Eil101 is 101 cities, the best distance is 629, 9000 iterations, the number of ants is 11 <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/1df/98f/77c/1df98f77c5c74e0596d13f81f3674227.png"></div><br>  Pair of charts: <br><div style="text-align:center;"><img src="https://habrastorage.org/files/b1b/054/25c/b1b05425cc4b4f0b9b16906d17759b2e.png"></div><br>  Here, there are 9000 iterations, quite a few for the 100th problem, however, we compare this result with annealing at the same time interval at 7,000,000 iterations. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/12d/470/ae5/12d470ae5bab4ff1bce035c2fe9a0b51.png"></div><br>  Quite a stable result, better than ACS showed.  But ACS allows you to make the search more manageable than the usual annealing (although in the latter one could at least introduce a stop criterion, but more on that in the following articles).  Therefore, today up to 100 vertices in all parameters wins ACS.  Moreover, it is most likely that the annealing method will not be greatly accelerated, while it is still possible to optimize the ACS code.  (In this case, the code is poorly optimized). <br><br>  I repeat that the main plus of ACS (as well as other modifications of the ant algorithm), in searching for a global optimum, with an infinite number of iterations, the probability of finding the global best tends to 1. The question is of course in time.  Fast, but about, or long, but for sure.  Therefore, I propose to construct the dependence of time (for identical numbers of iterations on each algorithm) on the number of cities. <br><br>  The number of ACS iterations is 10,000, ants - 10; <br>  The number of iterations of SA is 7,000,000. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/8c9/f4c/a5c/8c9f4ca5c9664d1c852d133d7ce82aba.png"></div><br>  Wow!  We see that the annealing method takes constant time, regardless of the number of vertices.  By constructing a regression, we determine the time complexity for ACS. <br><br>  t = 0.0044939x ^ 2 + 0.72097x + 3.8225 (Formula 4) <br><br>  where x is the number of cities, t is the ACS runtime <br><br>  If the two algorithms up to 100 vertices were approximately equal in both time and quality (with a slight advance in ACS), then we can very roughly assume that in 1,000 cities, 10,000 iterations per ACS and 7,000,000 iterations per SA result should be similar. <br><br>  Check it out. <br><br>  ACS 200 cities (random cities), time - 311.54 s. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/b17/b81/26f/b17b8126fe0c4cf9af2e046c113bed93.png"></div><br>  SA 200 cities (the same as above), time 103.19 s. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/94b/1a7/cc3/94b1a7cc3d974a41a4e56d2e16a83c72.png"></div><br>  Launched sequentially.  What is the probability that both will show the same result?  An interesting moment came, maybe even hundredths of the match?  But this is no longer known to you or me) <br><br>  In general, a series of tests, and 300 vertices come out about the same result, with an increase above, plus the annealing method leaves. <br><br>  With a time limit and the number of vertices more than one hundred, the simple method of annealing is better than ACS.  I repeat that it is ACS, not MMAS, ACS local search, or another modification. <br><br>  But sometimes you need to find the global optimum, there are few who can contend with ant algorithms. <br><br>  Now a few words about the acceleration of the method of imitation annealing. <br>  As the <a href="https://habrahabr.ru/users/daiver19/" class="user_link">daiver19</a> reader <a href="https://habrahabr.ru/users/daiver19/" class="user_link">suggested</a> , then, of course, you should not recalculate the route at each iteration. <br><br>  There is a conditional route: <br><br>  1 <b>2</b> 3 4 <b>5</b> 6 7 8 9 <br><br>  Randomly selected two numbers, let it be (2.5) <br><br>  Now it is enough to calculate the distance (1.2) and (5.6) and calculate the distance (1.5) and (2.6) <br><br>  However, this will not work on an asymmetric task. <br><br>  Due to this, the number of cities does not affect the execution time of the algorithm, plus it removed the functions fliplr, which took a decent amount of time.  Arrays of random numbers were also formed in advance.  All this at times increased the speed of the algorithm with the previous article. <br><br>  Also, one of the readers would be interested in the result when rearranging two vertices, rather than inverting the path between them.  Let's see the result on 101 cities of Eil101 per 1,000,000 iterations. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/116/ced/cc1/116cedcc1b2f4ab8b52b07df12594f32.png"></div><br>  Inversion path is much better. <br><br>  I would like to show and tell a lot of things, but the article is also quite long.  In the following publications we will ‚Äúfiddle‚Äù with the annealing method, we will try to make it more manageable.  We may also consider other modifications of the ant algorithm, dive a little deeper, and then move on to genetics. <br><br>  Now I propose to see how the undisputed leader (so far up to 100 peaks) goes to the global best path. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/f45/82f/995/f4582f99589a4add8e5406f5dcadf10b.gif"></div><br>  Also, I propose to look at the leader in time and number of SA peaks, which gives an approximate solution of 1000 peaks in 4,000,000 iterations in 34 seconds.  If in the last article 2,000,000 iterations for 500 vertices was 90 seconds, now it is only 14.6! <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/545/26d/8fb/54526d8fb45746ab879f7ad97d6ec9c4.gif"></div><br>  Something like this.  Sources with comments attached.  I tried to keep a balance between the readability of the code and speed.  I advise you to review them, even for those who are not at all familiar with MatLab, as this will greatly help to get into the essence of the algorithms. <br><br><div class="spoiler">  <b class="spoiler_title">Imitation annealing.</b>  <b class="spoiler_title">Full code with comments</b> <div class="spoiler_text"><pre><code class="matlab hljs"><span class="hljs-comment"><span class="hljs-comment">%   (     ) %-------------------------------------------------------------------------- tic % clearvars -except cities clearvars % ----------------------------------------------------------------- % -  m = 1000000; % ---------------------------------------------------------------- %   Tstart = 100000; %   Tend = 0.1; %     T = Tstart; %  S = inf; %   n = 500; %  ? g = 1; % ------------------------------------------------------------------- %   dist = zeros(n,n); % ------------------------------------------------------------------------- %   (x,y) cities = rand(n,2)*100; %      RANDONE = rand(m,1); %      D = randi(n,m,2); %    ROUTE = randperm(n); %    for i = 1:n for j = 1:n % dist (  ) dist(i,j) = sqrt((cities(i,1) - cities(j,1))^2 + ... (cities(i,2) - cities(j,2))^2); end end %  ,   -  for k = 1:m %    Sp = 0; %     , ROUTEp - %   %   ROUTEp = ROUTE; %    transp = D(k,[1,2]); %    ,      . if transp(1) &lt; transp(2) if transp(1) ~= 1 &amp;&amp; transp(2) ~= n S = dist(ROUTE(transp(1)-1),ROUTE(transp(1))) + ... dist(ROUTE(transp(2)),ROUTE(transp(2)+1)); elseif transp(1) ~= 1 &amp;&amp; transp(2) == n S = dist(ROUTE(transp(1)-1),ROUTE(transp(1))) + ... dist(ROUTE(transp(2)),ROUTE(1)); elseif transp(1) == 1 &amp;&amp; transp(2) ~= n S = dist(ROUTE(end),ROUTE(transp(1))) + ... dist(ROUTE(transp(2)),ROUTE(transp(2)+1)); end else if transp(2) ~= 1 &amp;&amp; transp(1) ~= n S = dist(ROUTE(transp(2)-1),ROUTE(transp(2))) + ... dist(ROUTE(transp(1)),ROUTE(transp(1)+1)); elseif transp(2) ~= 1 &amp;&amp; transp(1) == n S = dist(ROUTE(transp(2)-1),ROUTE(transp(2))) + ... dist(ROUTE(transp(1)),ROUTE(1)); elseif transp(2) == 1 &amp;&amp; transp(1) ~= n S = dist(ROUTE(end),ROUTE(transp(2))) + ... dist(ROUTE(transp(1)),ROUTE(transp(1)+1)); end end %------------------------------------------------------------------------- if transp(1) &lt; transp(2) ROUTEp(transp(1):transp(2)) = ROUTEp(transp(2):-1:transp(1)); if transp(1) ~= 1 &amp;&amp; transp(2) ~= n Sp = dist(ROUTEp(transp(1)-1),ROUTEp(transp(1))) + ... dist(ROUTEp(transp(2)),ROUTEp(transp(2)+1)); elseif transp(1) ~= 1 &amp;&amp; transp(2) == n Sp = dist(ROUTEp(transp(1)-1),ROUTEp(transp(1))) + ... dist(ROUTEp(transp(2)),ROUTEp(1)); elseif transp(1) == 1 &amp;&amp; transp(2) ~= n Sp = dist(ROUTEp(end),ROUTEp(transp(1))) + ... dist(ROUTEp(transp(2)),ROUTEp(transp(2)+1)); end else ROUTEp(transp(2):transp(1)) = ROUTEp(transp(1):-1:transp(2)); if transp(2) ~= 1 &amp;&amp; transp(1) ~= n Sp = dist(ROUTEp(transp(2)-1),ROUTEp(transp(2))) + ... dist(ROUTEp(transp(1)),ROUTEp(transp(1)+1)); elseif transp(2) ~= 1 &amp;&amp; transp(1) == n Sp = dist(ROUTEp(transp(2)-1),ROUTEp(transp(2))) + ... dist(ROUTEp(transp(1)),ROUTEp(1)); elseif transp(2) == 1 &amp;&amp; transp(1) ~= n Sp = dist(ROUTEp(end),ROUTEp(transp(2))) + ... dist(ROUTEp(transp(1)),ROUTEp(transp(1)+1)); end end %-------------------------------------------------------------------------- if Sp &lt; S ROUTE = ROUTEp; iter = k; else %    P = exp((-(Sp - S)) / T); if RANDONE(k) &lt;= P ROUTE = ROUTEp; end end %   T = Tstart / k; %    if T &lt; Tend break; end; end %   citiesOP(:,[1,2]) = cities(ROUTE(:),[1,2]); plot([citiesOP(:,1);citiesOP(1,1)],[citiesOP(:,2);citiesOP(1,2)],'-r.') msgbox ('!') %   clearvars -except cities ROUTE S iter %   toc</span></span></code> </pre> <br></div></div><br><br><div class="spoiler">  <b class="spoiler_title">Ant algorithm.</b>  <b class="spoiler_title">Full code with comments</b> <div class="spoiler_text"><pre> <code class="matlab hljs"><span class="hljs-comment"><span class="hljs-comment">%   (     ) % ------------------------------------------------------------------------- tic % clearvars -except cities clearvars % ----------------------------------------------------------------- % -  (  ) age = 2000; % -    countage = 10; % -  n = 50; % ----------------------------------------------------------------- %  -  ,  0     %   a = 1; %  -  ,  0  %      b = 2; %  ,  e = 0.1; %  ,  p = 0.1; %    Q = 1; %        AS q = 0.9; %   ph = Q/(n*2000); % ------------------------------------------------------------------- %   dist = zeros(n,n); %    returndist = zeros(n,n); %       ROUTEant = zeros(countage,n); %       DISTant = zeros(countage,1); %       bestDistVec = zeros(age,1); %    bestDIST = inf; %   ROUTE = zeros(1,n+1); %     (    ) RANDperm = randperm(n); %   P = zeros(1,n); %    val = zeros(1); %    getcity = zeros(1); %     indexP = zeros(1); %  minDISTiterration = zeros(1); % ------------------------------------------------------------------------- %   (x,y) cities = rand(n,2)*100; %    tao = ph*(ones(n,n)); tao(logical(eye(size(tao)))) = 0; %        for i = 1:n for j = 1:n % dist (  ) dist(i,j) = sqrt((cities(i,1) - cities(j,1))^2 + ... (cities(i,2) - cities(j,2))^2); % nn (   ) if i ~= j returndist(i,j) = 1/sqrt((cities(i,1) - cities(j,1))^2 + ... (cities(i,2) - cities(j,2))^2); end end end %  for iterration = 1:age %  (  ) for k = 1:countage % ******************    ****************** %    %     ROUTEant(k,1) = randi([1 n]); %       (   ), - %   -       % ROUTEant(k,1) = RANDperm(k); %           1- % ROUTEant(k,1) = 1; %       ,    %  ,     ,      %   % if iterration == 1 % ROUTEant(k,1) = randi([1 n]); % % ROUTEant(k,1) = RANDperm(k); % % ROUTEant(k,1) = 1; % else % ROUTEant(k,1) = lastROUTEant(k); % end % ********************************************************************* %   ,   ,     for s = 2:n %     ir = ROUTEant(k,s-1); %    (  ) ,     % : tao^a*(1/S)^b % 1/S - returndist. %      (-  *  %  * - ) ,       , %      .    %   .     : % for c = 1:n % P(1,c) = tao(ir,c).^a * returndist(ir,c).^b; % end P = tao(ir,:).^a .* returndist(ir,:).^b; %   (     k- ) %  n ,      ,   %  %     ,   ,  %    0,     %       P(ROUTEant(k,1:s-1)) = 0; %       RANDONE = rand; if RANDONE &lt;= q [val, getcity] = max(P); else %    (     = 1 ) P = P ./ sum(P); getcity = find(cumsum(P) &gt;= RANDONE, 1, 'first'); end %  s-    k-  ROUTEant(k,s) = getcity; end %   k-  ROUTE = [ROUTEant(k,1:end),ROUTEant(k,1)]; %   S = 0; %   k-  for i = 1:n S = S + dist(ROUTE(i),ROUTE(i+1)); end %  k- ,   k-  age-  DISTant(k) = S; %     S if DISTant(k) &lt; bestDIST bestDIST = DISTant(k); bestROUTE = ROUTEant(k,[1:end,1]); iter = iterration; end %  ""  k-  (    %      ,    %  ) % lastROUTEant = ROUTEant(1:end,end); %   ,    for tL = 1:n xL = ROUTE(tL); yL = ROUTE(tL+1); %    tao(xL,yL) = (1-p)*tao(xL,yL) + p*ph; tao(yL,xL) = (1-p)*tao(yL,xL) + p*ph; end end % -------------------------- -------------------------- %   ""   -   tao(tao &lt; 2.500000000000000e-150) = 2.500000000000000e-150; %    for t = 1:n xG = bestROUTE(t); yG = bestROUTE(t+1); %    tao(xG,yG) = tao(xG,yG) + e*(Q/bestDIST); tao(yG,xG) = tao(yG,xG) + e*(Q/bestDIST); end end %   citiesOP(:,[1,2]) = cities(bestROUTE(:),[1,2]); plot([citiesOP(:,1);citiesOP(1,1)],[citiesOP(:,2);citiesOP(1,2)],'.r-') disp (num2str(bestDIST)) msgbox ('!') clearvars -except cities bestDIST bestROUTE iter toc</span></span></code> </pre><br></div></div><br><br>  Thanks for attention.  Until new meetings. <br><br>  <i>Articles of foreign authors:</i> <br><br>  [1] - M. Dorigo, LM Gambardella, Ant Colony System: A Cooperative Learning Problem // IEEE Transactions on Evolutionary Computation Vol.  1, 1, pp. 53-66, 1997 <br><br>  [2] T. St√ºtzle, H. Hoos, ‚ÄúIEEE International Conference on Evolutionary Computation,‚Äù p. 309-314, 1997. <br><br>  [3] T. St√ºtzle, M. L√≥pez-Ib√°√±ez, P. Pellegrini, M. Maur, M. de Oca, M. Birattari, Michael Maur, M. Dorigo, ‚ÄúParameter Adaptation in Ant Colony Optimization‚Äù // Technical Report, IRIDIA, Universit√© Libre de Bruxelles, 2010 </div><p>Source: <a href="https://habr.com/ru/post/314056/">https://habr.com/ru/post/314056/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../314044/index.html">Finding errors in the LLVM project code using the PVS-Studio analyzer</a></li>
<li><a href="../314046/index.html">How I went to the first in Russia "Testathon", hackathon for testers</a></li>
<li><a href="../314048/index.html">Safety when using PostgreSQL</a></li>
<li><a href="../314050/index.html">As I wrote the application on Elm</a></li>
<li><a href="../314054/index.html">Editing a hopeless support letter</a></li>
<li><a href="../314058/index.html">Grouping Sednit uses bootkit in cyber attacks</a></li>
<li><a href="../314060/index.html">TextBlock with backlit text (WPF)</a></li>
<li><a href="../314062/index.html">How the Python parser works, and how to reduce memory consumption by three times</a></li>
<li><a href="../314068/index.html">ASO optimization. Compiling a semantic core for app stores</a></li>
<li><a href="../314072/index.html">Simple and convenient notifications</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>