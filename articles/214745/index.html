<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>How can using randomness help make your code faster? Lecture of Michael Sluggish in Yandex</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="And the strength and weakness of modern computers is how accurate they are. Today in our series of lectures from Yandex, there is a story about how th...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>How can using randomness help make your code faster? Lecture of Michael Sluggish in Yandex</h1><div class="post__text post__text-html js-mediator-article">  And the strength and weakness of modern computers is how accurate they are.  Today in our series of lectures from Yandex, there is a story about how the use of accidents can help make calculations more efficient. <br><br>  Probabilistic algorithms allow solving some problems of theoretical informatics for which deterministic algorithms do not work.  The most interesting question is to what extent does the use of randomness reduce the running time of the algorithm?  In part, this question can already be answered: under some assumptions, true randomness can be replaced by a false one and deterministically simulate any probabilistic algorithm with a slight loss in operating time.  Verification of these assumptions is likely to be one of the central themes of theoretical informatics of the 21st century. <br><br><iframe src="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=en&amp;u=https://video.yandex.ru/iframe/ya-events/m-59958-150443fd9cf-1ab33139b8135456/&amp;xid=17259,15700023,15700186,15700190,15700253&amp;usg=ALkJrhgHjU7TJhzClSwUJIkv663VtWEpWA" width="450" height="147" frameborder="0" scrolling="no" allowfullscreen="1"></iframe>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      <a href="http://tech.yandex.ru/education/m/shad/talks/1621/">The lecture is</a> read by a senior researcher at the Computing Center named.  A.A.  Dorodnitsyna RAS, Associate Professor of the Department of Mathematical Foundations of Management MIPT, Ph.D. in Physics and Mathematics Mikhail Vyalyy. <br><br>  Let's start with the simplest.  Imagine that we have two calculators.  One is normal, and the second has an extra button that, when pressed, gives an extra bit.  Let's try to answer the question, will such a function be useful? <br><a name="habracut"></a><br><img src="https://habrastorage.org/getpro/habr/post_images/bf3/70a/e4c/bf370ae4c1c40ce82d47ab08dc8556c9.png"><br><br>  Such a statement, of course, is too general.  We will try to clarify it in terms of theoretical informatics.  To do this, we first introduce the concept of the algorithm.  The algorithm is an instruction so precise that it can be executed mechanically.  The main property of deterministic algorithms is that each next state is uniquely determined by the current state.  Probabilistic algorithms are different in that at any moment they can determine the value of a random bit (flip a coin), which with equal probability will be 0 or 1. In the process of executing a probabilistic algorithm, this can occur repeatedly, and different flips will be independent. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f77/649/d5d/f77649d5dccb927c8b846dc5c9a86472.png"><br><br>  As shown in the picture above, with a deterministic step, the calculations occur as usual.  However, when tossing a coin, the calculation forks.  Instead of a linear sequence, a computation tree is obtained.  Each branch of this tree is called a calculation path.  The path is characterized by the values ‚Äã‚Äãof random bits.  Each time, throwing a coin, we choose one of two directions of movement.  Thus, we allow some liberty: we allow the algorithm to work correctly not on all paths, but only on some.  Before proceeding to assessing the error possibilities of probabilistic algorithms, we will discuss some technical details. <br><br>  First, a coin flip can have many sides (outcomes).  Secondly, the probabilities of loss of all possible outcomes do not have to be equal.  However, the sum of all possible outcomes is always 1. <br><br><h4>  Counting the error probability </h4><br>  When calculating the probability of error of a probabilistic algorithm, two rules must be considered: <br><ul><li>  The probabilities of independent events are multiplied. </li><li>  The probabilities of incompatible events add up. </li></ul><br><img src="https://habrastorage.org/getpro/habr/post_images/af9/42d/778/af942d778ef109ccfc09f9c3eaf45ece.png" alt="image"><br>  How generally to concern algorithms which can be mistaken?  In the end, you can simply ask some question that requires the answer ‚Äúyes‚Äù / ‚Äúno‚Äù, flip a double-sided coin, and with a probability of 1/2 get the correct answer.  So what is the probability of making a mistake for us?  For example, is the probability of an error high at 9/10?  If the error can be detected, and the algorithm allows for repeated execution, then not so much. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/80e/02a/ab0/80e02aab0451ced983601c35aa7e8211.png"><br><br>  If the correct answer is unknown to us, the task becomes more difficult.  The algorithm gives us the answer "yes" or "no."  If the error probability Œµ &lt;1/2, then repeating the algorithm allows you to quickly reduce the probability of error.  Those.  you need to repeat the algorithm <i>k</i> times, and give the answer that met more often.  Let the error probability be 1/3.  The probability of error in voting for <i>k</i> independent performances is calculated as follows: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f06/b28/4c9/f06b284c916d400b1b8cd72112a76e7e.png" alt="image"><br><br>  If the error probability is also equal to 1/3, if 100 independent performances vote, the error probability can be calculated as follows: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/258/4ad/0ca/2584ad0cac41978f5a19747e524d78b6.png" alt="image"><br><br>  As <i>k</i> increases, the probability of error will decrease very quickly: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/620/e6f/207/620e6f207947a896bb52180db1e88b64.png" alt="image"><br><br><h4>  The task of establishing contact </h4><br>  Suppose we have two players.  They know nothing about each other, and they have no opportunity to agree.  There are two points through which they can make contact.  Time is discrete.  At each moment the participant chooses a place (upper or lower).  Contact is established if at some point in time both participants chose the same place. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a44/5e3/b22/a445e3b2256c84d9ba3cb4ccc34e7f67.png"><br><br>  There is no deterministic way to make contact.  At the same time, the probabilistic algorithm for establishing contact is very simple: at each step, one must choose a place randomly, equiprobably, and independently of the previous steps.  Let's analyze this algorithm.  The probability of error at each step is 1/2.  After <i>t</i> steps, the probability of error will be 2 <i><sup>-t</sup></i> , which can be a very small value. <br><br><h4>  The task of verifying equality by an arbitrator </h4><br>  Consider a problem with a more complex condition.  Alice knows the binary word <i>x of</i> length <i>n</i> .  Bob knows the word y of the same length.  They have the ability to transfer Charlie some information (the words <i>u</i> and <i>v</i> ), according to which Charlie must decide whether the words <i>x</i> and <i>y</i> are equal.  Goal: send as few bits as possible, provided Charlie responds correctly to any <i>x, y</i> .  Alice with Bob can not communicate with each other. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/91e/ea6/4dc/91eea64dc658936f47d1cd379aa7834b.png"><br><br>  If u and v are determined by x and y deterministically, i.e.  <i>u = f (x), v = g (y)</i> , then to solve the equality problem, at least 2 <i>n</i> bits must be transmitted.  Path length u is less than <i>n</i> .  Then the possible values ‚Äã‚Äãof <i>u are</i> less than 2 <i><sup>n</sup></i> , i.e.  less than the number of possible <i>x</i> values. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/258/37b/815/25837b81590ebdcf075dae7455de08f9.png"><br><br>  For Charlie, <i>x <sub>1</sub></i> and <i>x <sub>2 are</sub></i> indistinguishable. <br><br><h4>  Accident as a "communication channel" </h4><br>  Let's try to solve the same problem, but now imagine that Alice and Bob have access to a common source of chance.  Say, to the same edition of the book "Table of random numbers."  The goal: to transmit as few bits as possible, provided that the probability of a Charlie error is small on any <i>x, y</i> . <br><br><img src="https://habrastorage.org/getpro/habr/post_images/541/f2f/0af/541f2f0af65b979e78f48833af470cbe.png"><br><br>  Let us try to solve this problem and determine whether fewer bits can be transmitted in this way than with a deterministic algorithm. <br><br>  Alice and Bob choose a random prime number <i>p</i> (the same, commonness for both of them) in the range from <i>n</i> to 2 <i>n</i> . <br><br>  Alice computes <i>U = X</i> mod <i>p</i> , where <i>X</i> is a number whose binary notation is the same as Alice's <i>x</i> .  Bob does the same and calculates <i>V = Y</i> mod <i>p</i> .  Then they both send binary records of Charlie's <i>U</i> and <i>V</i> numbers.  Charlie says that the words <i>x</i> and <i>y</i> are equal if <i>u = v</i> . <br>  Since 0 ‚â§ <i>U, V &lt;p ‚â§</i> <i>2n</i> , the message length ‚â§ 2 + log <i>n</i> . <br><br>  In the case of <i>x = y,</i> Charlie always gives the correct answer.  If x ‚â† y the probability of Charlie‚Äôs error is no more than 3/4.  Let us prove this with the help of a theorem from number theory. <br><br>  There are a lot of prime numbers.  For all sufficiently large <i>n, the</i> number <i>œÄ (n) of</i> primes from 1 to <i>n</i> satisfies the inequalities: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a2c/85a/f6f/a2c85af6fedc43f4ce4ca90bef9add5a.png" alt="image"><br><br>  If <i>X - Y ‚â†</i> 0 is divisible by simple <i>n ‚â§ p <sub>1</sub> &lt;... &lt;p <sub>k</sub> ‚â§ 2n</i> , then <br><br><img src="https://habrastorage.org/getpro/habr/post_images/8a7/91c/251/8a791c251f32e010356a21769bc0b578.png" alt="image"><br><br><h4>  Reduction in error probability </h4><br>  The error of the proposed protocol is one-way.  This allows you to reduce the likelihood of error by repeatedly running the protocol.  If Alice and Bob choose s simple modules (randomly and independently), the probability of error becomes less than (3/4) <i><sup>s</sup></i> .  Taking a sufficiently large <i>s</i> , the probability of error can be made arbitrarily small. <br><br>  If there is general randomness for any <i>Œµ</i> &gt; 0, there is a way to select messages that guarantees the solution of the equality problem with an error probability less than Œµ and transmits <i>O</i> (log <i>n</i> ) bits.  Writing <i>g (n) = O (f (n))</i> means that there are numbers <i>C</i> and <i>n <sub>0</sub></i> such that for all <i>n&gt; n <sub>0</sub></i> , <i>g (n) &lt;Cf (n)</i> holds. <br><br><h4>  Protocols in the absence of general randomness </h4><br>  How to prove that there is a way to select messages <i>u, v</i> in the problem of equality, in which Alice and Bob do not know the random bits of each other, <i>O (‚àön</i> log <i>n</i> ) bits are transmitted, and the error probability is less than 1/3? <br>  Two random subsets of size 2 <i>‚àön</i> in the <i>n-</i> element set intersect with a probability of&gt; 4/5 (approximately 1 - 1 / <i>e <sup>2</sup></i> ).  And it turns out that this is almost all that we can achieve.  Consider a special case of the Babai ‚Äì Kimmel theorem, from which it follows that with any method of probabilistic selection of messages in the equality problem, which guarantees the probability of error is less than 1/3, the length of the transmitted messages is <i>Œ© (‚àön)</i> .  Writing <i>g (n) = Œ© (f (n))</i> means that there are numbers <i>C</i> and <i>n <sub>0</sub></i> such that for all <i>n&gt; n <sub>0</sub></i> , <i>g (n)&gt; Cf (n)</i> holds. <br><br>  After watching the lecture to the end, you will learn how, thanks to the introduction of randomness, you can speed up the work of the algorithm, as well as the concept of fake randomness. </div><p>Source: <a href="https://habr.com/ru/post/214745/">https://habr.com/ru/post/214745/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../214731/index.html">REG.RU rebranding: easier, more convenient, more efficient</a></li>
<li><a href="../214733/index.html">Detailed analysis of the Linux / Ebury backdoor</a></li>
<li><a href="../214735/index.html">A single interface for managing advertising on the site</a></li>
<li><a href="../214737/index.html">RussianCodeCup 2014 - very soon!</a></li>
<li><a href="../214743/index.html">Google maps auto travel planning</a></li>
<li><a href="../214755/index.html">Using DSP SB Live! for the benefit of radio amateurs (KX Driver's) - Part [1/2]</a></li>
<li><a href="../214759/index.html">We program robots on Windows 8. We control Sphero from a tablet using an accelerometer and a collision sensor</a></li>
<li><a href="../214761/index.html">Only developers of the 90s remember this.</a></li>
<li><a href="../214763/index.html">The story of Ruby on Windows Azure</a></li>
<li><a href="../214765/index.html">Prudence</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>