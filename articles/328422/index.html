<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Introduction to OpenCV in relation to the recognition of road marking lines</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hi, Habr! We publish graduate material from our Deep Learning program and Big Data Program Coordinator, Cyril Danyluk, about his experience of using t...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Introduction to OpenCV in relation to the recognition of road marking lines</h1><div class="post__text post__text-html js-mediator-article">  Hi, Habr!  We publish graduate material from our <a href="http://newprolab.com/ru/deeplearning%3Futm_source%3Dhabr%26utm_campaign%3Ddaniluyk">Deep Learning</a> program and Big Data Program Coordinator, Cyril Danyluk, about his experience of using the OpenCV computer vision framework to determine road marking lines. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/web/1f6/aa0/172/1f6aa01729634b76b79329df6806fd4e.png" width="600" alt="image"></div><a name="habracut"></a><br>  Some time ago I started the program from Udacity: <a href="https://www.udacity.com/drive">‚ÄúSelf-Driving Car Engineer Nanodegree‚Äù</a> .  It consists of many projects on various aspects of building a driving system on autopilot.  I present to you my decision to the first project: a simple linear road marking detector.  To understand what happened in the end, watch the video first: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/gWK9x5Xs_TI" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      The goal of this project is to build a simple linear model for frame-by-frame recognition of lanes: at the input we get a frame, a series of transformations, which we will discuss later, process it, we get a filtered image that can be vectorized and trained two independent linear regressions: one for each band.  The project is intentionally simple: only a linear model, only good weather conditions and visibility, only two marking lines.  Naturally, this is not a production-solution, but even such a project allows plenty to play with OpenCV, filters and, in general, helps to feel the difficulties that autopilot developers face in cars. <br><br><h2>  The principle of the detector </h2><br>  The process of building a detector consists of three basic steps: <br><br><ol><li>  Data pre-processing, noise filtering and vectorization of the image. </li><li>  Update road marking lines from data from the first step. </li><li>  Drawing updated lines and other objects on the original image. </li></ol><br>  First, a 3-channel image of the RGB format is fed to the input of the <code>image_pipeline</code> function, which is then filtered, converted, and the <code>Line</code> and <code>Lane</code> objects are updated inside the function.  Then all the necessary elements are drawn over the image itself, as shown below: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/web/a27/01a/527/a2701a527e084f748ab900d556809e48.png" width="700" alt="image"></div><br>  I tried to approach the task in the OOP style (unlike most analytical tasks): so that each of the steps turned out to be isolated from the others. <br><br><h2>  Step 1: Pretreatment and Vectoring </h2><br>  The first stage of our work is well known to the data scientist and to all those who work with ‚Äúraw‚Äù data: first we need to do data preprocessing, and then vectorize it into a form that is understandable for algorithms.  The general pipeline for pre-processing and vectorization of the original image is as follows: <br><br><pre> <code class="hljs pgsql"><code class="python">blank_image = np.zeros_like(image) hsv_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV) binary_mask = get_lane_lines_mask(hsv_image, [WHITE_LINES, YELLOW_LINES]) masked_image = draw_binary_mask(binary_mask, hsv_image) edges_mask = canny(masked_image, <span class="hljs-number"><span class="hljs-number">280</span></span>, <span class="hljs-number"><span class="hljs-number">360</span></span>) # Correct initialization <span class="hljs-keyword"><span class="hljs-keyword">is</span></span> important, we cheat <span class="hljs-keyword"><span class="hljs-keyword">only</span></span> once here! <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> Lane.lines_exist(): edges_mask = region_of_interest(edges_mask, ROI_VERTICES) segments = hough_line_transform(edges_mask, <span class="hljs-number"><span class="hljs-number">1</span></span>, math.pi / <span class="hljs-number"><span class="hljs-number">180</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>,</code></code> </pre><br>  Our project uses OpenCV - one of the most popular frameworks for working with images at the pixel level using matrix operations. <br><br>  First, we convert the original RGB image to HSV ‚Äî it is in this color model that it is convenient to select specific color ranges (and we are interested in shades of yellow and white to determine lanes). <br><br>  Pay attention to the screenshot below: it is much more difficult to select ‚Äúall yellow‚Äù in RGB than in HSV. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/web/54c/778/f7b/54c778f7b2b54e9887fd0207a1b230a9.png" width="400" alt="image"></div><br>  After transferring the image to HSV, some recommend applying a Gaussian blur, but in my case it reduced the quality of recognition.  The next stage is binarization (image conversion into a binary mask with colors of interest to us: shades of yellow and white). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/web/797/b2f/821/797b2f8210ea4191a3b1991ced99406e.png" width="600" alt="image"></div><br>  Finally, we are ready to vectorize our image.  Apply two transformations: <br><br><ol><li>  <a href="https://medium.com/%40tempflip/lane-detection-with-numpy-56b923245fc9">Canny Boundary Detector</a> : an optimal boundary detection algorithm that calculates image intensity gradients, and then removes weak boundaries using two thresholds, leaving the desired ones (we use <code>(280, 360)</code> ) as threshold values ‚Äã‚Äãin the <code>canny</code> function. </li><li>  Hough Transformation: after obtaining the boundaries using the Canny algorithm, we can connect them using lines.  I do not want to go into the mathematics of the algorithm - it is worthy of a separate post - this link or the link above will help you if you are interested in the method.  The main thing is that by applying this transformation, we get a set of lines, each of which, after a little additional processing and filtering, becomes an instance of the Line class with a known angle of inclination and a free member. </li></ol><br><div style="text-align:center;"><img src="https://habrastorage.org/web/7ad/ce3/743/7adce37434c64315bf04fe2a84587373.png"></div><br>  Obviously, the upper part of the image is unlikely to contain markup lines, so it can be ignored.  There are two ways: either immediately paint the top of our binary mask with black, or think over more clever line filtering.  I chose the second method: I considered that everything that is above the horizon line cannot be a marking line. <br><br>  The horizon line (vanishing point) can be determined by the point at which the right and left lanes converge. <br><br><h2>  Step 2: Update Road Marking Lines </h2><br>  Road marking lines will be updated using the <code>update_lane(segments)</code> function in <code>image_pipeline</code> , which at the input receives <code>segments</code> objects from the last step (which are actually <code>Line</code> objects from the Hough transformation). <br><br>  In order to facilitate the process, I decided to use OOP and present the road marking lines as instances of the <code>Lane</code> class: <code>Lane.left_line, Lane.right_line</code> .  Some students limited themselves to adding the `lane` object to global namespace, but I'm not a fan of global variables in code. <br><br>  Let's take a closer look at the <code>Lane</code> and <code>Line</code> classes and their instances: <br><br>  Each instance of the <code>Line</code> class is a separate line: a road marking piece or just any line that will be defined by the Hough Transform, while the main purpose of <code>Lane</code> objects is to identify whether this line is a road marking segment.  To do this, we will be guided by the following logic: <br><br><ol><li>  The line can not be horizontal and should have a moderate slope. </li><li>  The difference between the slopes of the road marking line and the candidate line cannot be too high. </li><li>  The candidate line must not be far from the road marking to which it belongs. </li><li>  Candidate line should be below the horizon </li></ol><br>  Thus, to determine the belonging to the marking line, we use a rather trivial logic: we make decisions based on the slope of the line and the distance to the marking.  The method is not perfect, but it worked for my simple conditions. <br><br>  The <code>Lane</code> class is a container for the left and right marking lines (refactoring just asks).  The class also presents several methods related to working with markup lines, the most important of which is <code>fit_lane_line</code> .  In order to create a new markup line, I represent suitable markup segments as points, and then I approximate them with a first-order polynomial (that is, a line) using the usual <code>numpy.polyfit</code> function <br><br>  <b>The stabilization of the obtained road marking lines is</b> very important: the original image is very noisy, and the determination of the stripes occurs frame-by-frame.  Any shadow or heterogeneity of the pavement immediately changes the color of the markup to one that our detector cannot detect ... In the process, I used several methods of stabilization: <br><br><ol><li>  <i>Buffers</i>  The resulting marking line stores the N previous states and successively adds the state of the marking line on the current frame to the buffer. </li><li>  <i>Additional line filtering taking into account data in the buffer.</i>  If, after transformation and cleaning, we could not get rid of the noise in the data, then there is a possibility that our line will be an outlier, and, as we know, the linear model is sensitive to outliers.  Therefore, for us, the fundamentally high value of accuracy is even at the expense of a significant loss of completeness.  Simply put, it is better to filter the correct line than to add an outlier to the model.  Especially for such cases, I created a <code>DECISION_MAT</code> ‚Äî a ‚Äúdecision maker‚Äù matrix that decides how to relate the current slope of the line to the average of all the lines in the buffer. </li></ol><br>  For example, for <code>DECISION_MAT = [ [ 0.1, 0.9] , [1, 0] ]</code> we consider the choice of two solutions: to consider the line unstable (ie, a potential outlier), or stable (its slope corresponds to the average slope of the lines of this band in the buffer plus / minus threshold).  If the line is unstable, we still want not to lose it: it can carry information about the real turn of the road.  We will simply take it into account with a small coefficient (in this case, 0.1). For a stable line, we will simply use its current parameters without any weighting from previous data. <br><br>  The stability indicator of the marking line in the current frame is described by objects of the <code>Lane</code> class: <code>Lane.right_lane.stable</code> and <code>Lane.left_lane.stable</code> , which are Boolean.  If at least one of these variables is set to <code>False</code> , I render it as a red polygon between two lines (below you can see how it looks). <br><br>  As a result, we get fairly stable lines: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/web/0d0/142/4d0/0d01424d02af4444a82f395884ef25d9.gif"></div><br><br><h2>  Step 3: Draw and update the original image </h2><br>  In order for the lines to be drawn correctly, I wrote a fairly simple algorithm that calculates the coordinates of the horizon point, which we have already talked about.  In my project, this point is needed for two things: <br><br><ol><li>  Limit the extrapolation of marking lines to this point. </li><li>  Filter all Hough lines above the horizon. </li></ol><br>  To visualize the entire strip definition process, I made a small <code>image augmentation</code> : <br><br><pre> <code class="hljs lua"><code class="python">def draw_some_object(what_to_draw, background_image_to_draw_on, **kwargs): # do_stuff_and_return_image # Snapshot <span class="hljs-number"><span class="hljs-number">1</span></span> out_snap1 = np.zeros_like(image) out_snap1 = draw_binary_mask(binary_mask, out_snap1) out_snap2 = draw_filtered_lines(segments, out_snap1) snapshot1 = cv2.resize(deepcopy(out_snap1), (<span class="hljs-number"><span class="hljs-number">240</span></span>,<span class="hljs-number"><span class="hljs-number">135</span></span>)) # Snapshot <span class="hljs-number"><span class="hljs-number">2</span></span> out_snap2 = np.zeros_like(image) out_snap2 = draw_canny_edges(edges_mask, out_snap2) out_snap2 = draw_points(Lane.left_line.points, out_snap2, Lane.COLORS[<span class="hljs-string"><span class="hljs-string">'left_line'</span></span>]) out_snap2 = draw_points(Lane.right_line.points, out_snap2, Lane.COLORS[<span class="hljs-string"><span class="hljs-string">'right_line'</span></span>]) out_snap2 = draw_lane_polygon(out_snap2) snapshot2 = cv2.resize(deepcopy(out_snap2), (<span class="hljs-number"><span class="hljs-number">240</span></span>,<span class="hljs-number"><span class="hljs-number">135</span></span>)) # Augmented image <span class="hljs-built_in"><span class="hljs-built_in">output</span></span> = deepcopy(image) <span class="hljs-built_in"><span class="hljs-built_in">output</span></span> = draw_lane_lines([Lane.left_line, Lane.right_line], <span class="hljs-built_in"><span class="hljs-built_in">output</span></span>, shade_background=True) <span class="hljs-built_in"><span class="hljs-built_in">output</span></span> = draw_lane_polygon(<span class="hljs-built_in"><span class="hljs-built_in">output</span></span>) <span class="hljs-built_in"><span class="hljs-built_in">output</span></span> = draw_dashboard(<span class="hljs-built_in"><span class="hljs-built_in">output</span></span>, snapshot1, snapshot2) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-built_in"><span class="hljs-built_in">output</span></span></code></code> </pre><br>  As can be seen from the code, I superimpose two images on the original video: one with a binary mask, the second with the lines of Hough (transformed into dots) passed through all our filters.  I apply two lanes to the original video itself (linear regression over the points from the previous image).  The green rectangle is an indicator of the presence of "unstable" lines: if they exist, it becomes red.  The use of such an architecture makes it quite easy to change and combine frames that will be displayed as a dashboard, allowing you to simultaneously visualize many components and all this without any significant changes in the source code. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/web/c80/511/b78/c80511b780d344c3990ec6d1631177d0.gif"></div><br><br><h2>  What's next? </h2><br>  This project is still far from complete: the more I work on it, the more things that need improvement, I find: <br><br><ul><li>  To make the detector nonlinear so that it can work successfully, for example, in the mountains, where turns are at every turn. </li><li>  Make a projection of the road as a ‚Äútop view‚Äù - this will greatly simplify the definition of lanes. </li><li>  Recognition of the road.  It would be great to recognize not only the markup, but also the road itself, which will greatly facilitate the work of the detector. </li></ul><br>  All project source code is available on GitHub by <a href="https://github.com/dnkirill/carnd/blob/master/p1_lane_lines_detection/P1.ipynb">reference</a> . <br><br><h2>  PS And now we break everything! </h2><br>  Of course, this post should be the fun part.  Let's see how miserable the detector becomes on a mountain road with frequent changes in direction and light.  At first, everything seems to be normal, but in the future the error in the definition of the bands accumulates, and the detector no longer has time to monitor them: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/web/a9c/9a4/f9d/a9c9a4f9d68e48eea1953ac5d5d9b370.gif"></div><br>  And in the forest, where the light changes very quickly, our detector completely failed the task: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/web/984/cd0/72d/984cd072d00a4db38e83d7cec97bfcf4.gif"></div><br>  By the way, one of the following projects is to make a non-linear detector that will cope with the ‚Äúforest‚Äù task.  Follow new posts! <br><br>  ‚Üí <a href="https://medium.com/towards-data-science/carnd-project-1-lane-lines-detection-a-complete-pipeline-6b815037d02c">The original post in Medium in English</a> . </div><p>Source: <a href="https://habr.com/ru/post/328422/">https://habr.com/ru/post/328422/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../328408/index.html">Essentialism and decision theory</a></li>
<li><a href="../328410/index.html">‚ÄúThey didn‚Äôt come up with anything, improvise‚Äù or Agile in information security</a></li>
<li><a href="../328412/index.html">Your idea is nonsense.</a></li>
<li><a href="../328416/index.html">Do not you send spam?</a></li>
<li><a href="../328418/index.html">Realistic Realm. 1 year experience</a></li>
<li><a href="../328424/index.html">Deep Learning against cancer. Intel Contest</a></li>
<li><a href="../328426/index.html">How to become a web developer in 2017 - an action plan</a></li>
<li><a href="../328428/index.html">Welcome to MOSDROID May Meetup May 20</a></li>
<li><a href="../328430/index.html">New tools for organizing effective teamwork</a></li>
<li><a href="../328432/index.html">How we published an iOS video chat app on the App Store</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>