<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Hacker's guide to neural networks. Chapter 2: Machine Learning. Network learning based on support vector machine (SVM)</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Content: 
 Chapter 1: Real Value Schemes  Part 1: 


 : ‚Ññ1:   
 Part 2: 


  ‚Ññ2:  
 Part 3: 


  ‚Ññ3:  
 Part 4: 


   
 Part 5: 


  ¬´¬ª " " 
 Part 6: ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Hacker's guide to neural networks. Chapter 2: Machine Learning. Network learning based on support vector machine (SVM)</h1><div class="post__text post__text-html js-mediator-article">  Content: <br><div class="spoiler">  <b class="spoiler_title">Chapter 1: Real Value Schemes</b> <div class="spoiler_text">  <a href="http://habrahabr.ru/company/paysto/blog/244723/">Part 1:</a> <br><pre><code class="html hljs xml">  :        ‚Ññ1:   </code> </pre> <br>  <a href="http://habrahabr.ru/company/paysto/blog/244935/">Part 2:</a> <br><pre> <code class="html hljs xml">  ‚Ññ2:  </code> </pre><br>  <a href="http://habrahabr.ru/company/paysto/blog/245051/">Part 3:</a> <br><pre> <code class="html hljs xml">  ‚Ññ3:  </code> </pre><br>  <a href="http://habrahabr.ru/company/paysto/blog/245403/">Part 4:</a> <br><pre> <code class="javascript hljs">        </code> </pre><br>  <a href="http://habrahabr.ru/company/paysto/blog/246093/">Part 5:</a> <br><pre> <code class="javascript hljs">   ¬´¬ª   <span class="hljs-string"><span class="hljs-string">" "</span></span></code> </pre><br>  <a href="http://habrahabr.ru/company/paysto/blog/246397/">Part 6:</a> <br><pre> <code class="javascript hljs">     </code> </pre><br></div></div><br><div class="spoiler">  <b class="spoiler_title">Chapter 2: Machine Learning</b> <div class="spoiler_text">  <a href="http://habrahabr.ru/company/paysto/blog/246523/">Part 7:</a> <br><pre> <code class="javascript hljs">  </code> </pre><br>  <a href="http://habrahabr.ru/company/paysto/blog/246849/">Part 8:</a> <br><pre> <code class="javascript hljs">        (SVM)</code> </pre><br>  <a href="http://habrahabr.ru/company/paysto/blog/246973/">Part 9:</a> <br><pre> <code class="javascript hljs">  SVM   </code> </pre><br>  <a href="http://habrahabr.ru/company/paysto/blog/247033/">Part 10:</a> <br><pre> <code class="javascript hljs">   :  </code> </pre><br></div></div><br><br>  As a concrete example, let's look at SVM.  SVM is a very popular linear classifier.  Its functional form has exactly the same form as I described in the previous section - <b>f (x, y) = ax + by + c</b> .  At this stage, if you saw the description of SVM, you probably expect that I will determine the loss function of SVM and dive into explanations of free variables, geometric concepts of large fields, kernels, duality, etc. But here I would like to use a different approach. <br><a name="habracut"></a><br>  Instead of defining loss functions, I would like my explanation to be based on the characteristic of force (by the way, I have just invented this term) of the support vector machine, which I personally consider much more understandable.  As we will see later, the characteristic of force and the function of losses are the same ways of solving the same problem.  In general, it looks like this: <br><br>  " <b>Characteristic of force</b> ": <br>  If we pass a positive data entry point through the SVM scheme, and the output value is less than 1, we need to pull the scheme with a force of +1.  This is a positive example, so we need its value to be higher. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      On the other hand, if we pass a negative data entry point through the SVM, and the output value is greater than -1, then the circuit gives this data entry point a dangerously high value: You must pull the circuit down with a force of -1. <br><br>  In addition to pulling up, you should always add a little tension for parameters a, b (note, not c!), Which will pull them in the direction of zero.  You can imagine that a, b are tied to a physical spring that is tied to zero.  As in the case of a physical spring, this will make the tension proportional to the value of each element a, b (Hooke's law in physics, does anyone know?).  For example, if a takes on too high a value, it will experience strong tension with the value of | a |  back to zero.  This tension is what we call regularization, and it ensures that none of our parameters a or b become disproportionately large.  This may be undesirable, since both parameters a and b are multiplied by the input characteristics x, y (remember that our equation is a * x + b * y + c), so if any of them is too high , our classifier will be too sensitive to these parameters.  This is not a very good property, since the characteristics can often be inaccurate in practice, so we need our classifier to change relatively smoothly if they swing sideways. <br><br>  Let's quickly go through a small but concrete example.  Suppose we started with setting an arbitrary parameter, say, a = 1, b = -2, c = -1.  Then, if we feed the point [1.2, 0.7], the SVM will calculate the value 1 * 1.2 + (-2) * 0.7 - 1 = -1.2.  This point is marked as +1 in the training data, so we want the value to be greater than 1. The gradient at the top of the circuit will then be positive: +1, and will propagate the backward error to a, b, c.  In addition, there will be a regularization tension on a with a force of -1 (to make it smaller) and a regularization tension on b with a force of +2 to make it larger, in the direction of zero. <br><br>  Instead, suppose we supply the data entry point [-0.3, 0.5] to the SVM.  It calculates 1 * (-0.3) + (-2) * 0.5 - 1 = -2.3.  The label for this point has a value of -1, and since -2.3 is less than -1, we understand that, according to our strength characteristic, SVM should be happy: the calculated value will be extremely negative and will correspond to the negative label in this example.  At the end of the scheme there will be no tension (i.e. it will be zero), since no changes are needed.  However, there will still be a regularization tension on a with a strength of -1 and on b with a strength of +2. <br><br>  In general, too much text.  Let's write the SVM code and take advantage of the schema mechanism discussed in Chapter 1: <br><br><pre> <code class="javascript hljs"><span class="hljs-comment"><span class="hljs-comment">//   5  (x,y,a,b,c),     //            var Circuit = function() { //     this.mulg0 = new multiplyGate(); this.mulg1 = new multiplyGate(); this.addg0 = new addGate(); this.addg1 = new addGate(); }; Circuit.prototype = { forward: function(x,y,a,b,c) { this.ax = this.mulg0.forward(a, x); // a*x this.by = this.mulg1.forward(b, y); // b*y this.axpby = this.addg0.forward(this.ax, this.by); // a*x + b*y this.axpbypc = this.addg1.forward(this.axpby, c); // a*x + b*y + c return this.axpbypc; }, backward: function(gradient_top) { //    this.axpbypc.grad = gradient_top; this.addg1.backward(); //    axpby  c this.addg0.backward(); //    ax  by this.mulg1.backward(); //    b  y this.mulg0.backward(); //    a  x } }</span></span></code> </pre><br><br>  This is a circuit that simply computes a * x + b * y + c and can also calculate a gradient.  It uses the logic element code we created in Chapter 1. Now let's write down the SVM, which does not depend on the actual circuit.  For it, only the values ‚Äã‚Äãthat go out of it are important, and it tightens the circuit. <br><br><pre> <code class="javascript hljs"><span class="hljs-comment"><span class="hljs-comment">// SVM  var SVM = function() { //     this.a = new Unit(1.0, 0.0); this.b = new Unit(-2.0, 0.0); this.c = new Unit(-1.0, 0.0); this.circuit = new Circuit(); }; SVM.prototype = { forward: function(x, y) { // ,  x  y   this.unit_out = this.circuit.forward(x, y, this.a, this.b, this.c); return this.unit_out; }, backward: function(label) { //   +1  -1 //    a,b,c this.a.grad = 0.0; this.b.grad = 0.0; this.c.grad = 0.0; //     ,     var pull = 0.0; if(label === 1 &amp;&amp; this.unit_out.value &lt; 1) { pull = 1; //    :   } if(label === -1 &amp;&amp; this.unit_out.value &gt; -1) { pull = -1; //       ,   } this.circuit.backward(pull); //    x,y,a,b,c //     :       this.a.grad += -this.a.value; this.b.grad += -this.b.value; }, learnFrom: function(x, y, label) { this.forward(x, y); //   ( .value   ) this.backward(label); //   ( .grad   ) this.parameterUpdate(); //     }, parameterUpdate: function() { var step_size = 0.01; this.a.value += step_size * this.a.grad; this.b.value += step_size * this.b.grad; this.c.value += step_size * this.c.grad; } };</span></span></code> </pre><br><br>  Now let's use SVM using the stochastic gradient descent: <br><pre> <code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">var</span></span> data = []; <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> labels = []; data.push([<span class="hljs-number"><span class="hljs-number">1.2</span></span>, <span class="hljs-number"><span class="hljs-number">0.7</span></span>]); labels.push(<span class="hljs-number"><span class="hljs-number">1</span></span>); data.push([<span class="hljs-number"><span class="hljs-number">-0.3</span></span>, <span class="hljs-number"><span class="hljs-number">-0.5</span></span>]); labels.push(<span class="hljs-number"><span class="hljs-number">-1</span></span>); data.push([<span class="hljs-number"><span class="hljs-number">3.0</span></span>, <span class="hljs-number"><span class="hljs-number">0.1</span></span>]); labels.push(<span class="hljs-number"><span class="hljs-number">1</span></span>); data.push([<span class="hljs-number"><span class="hljs-number">-0.1</span></span>, <span class="hljs-number"><span class="hljs-number">-1.0</span></span>]); labels.push(<span class="hljs-number"><span class="hljs-number">-1</span></span>); data.push([<span class="hljs-number"><span class="hljs-number">-1.0</span></span>, <span class="hljs-number"><span class="hljs-number">1.1</span></span>]); labels.push(<span class="hljs-number"><span class="hljs-number">-1</span></span>); data.push([<span class="hljs-number"><span class="hljs-number">2.1</span></span>, <span class="hljs-number"><span class="hljs-number">-3</span></span>]); labels.push(<span class="hljs-number"><span class="hljs-number">1</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> svm = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> SVM(); <span class="hljs-comment"><span class="hljs-comment">// ,     var evalTrainingAccuracy = function() { var num_correct = 0; for(var i = 0; i &lt; data.length; i++) { var x = new Unit(data[i][0], 0.0); var y = new Unit(data[i][1], 0.0); var true_label = labels[i]; // ,       var predicted_label = svm.forward(x, y).value &gt; 0 ? 1 : -1; if(predicted_label === true_label) { num_correct++; } } return num_correct / data.length; }; //   for(var iter = 0; iter &lt; 400; iter++) { //      var i = Math.floor(Math.random() * data.length); var x = new Unit(data[i][0], 0.0); var y = new Unit(data[i][1], 0.0); var label = labels[i]; svm.learnFrom(x, y, label); if(iter % 25 == 0) { //  10 ... console.log('training accuracy at iter ' + iter + ': ' + evalTrainingAccuracy()); } }</span></span></code> </pre><br><br>  This code displays the following result: <br><br><pre> <code class="javascript hljs">training accuracy at iteration <span class="hljs-number"><span class="hljs-number">0</span></span>: <span class="hljs-number"><span class="hljs-number">0.3333333333333333</span></span> training accuracy at iteration <span class="hljs-number"><span class="hljs-number">25</span></span>: <span class="hljs-number"><span class="hljs-number">0.3333333333333333</span></span> training accuracy at iteration <span class="hljs-number"><span class="hljs-number">50</span></span>: <span class="hljs-number"><span class="hljs-number">0.5</span></span> training accuracy at iteration <span class="hljs-number"><span class="hljs-number">75</span></span>: <span class="hljs-number"><span class="hljs-number">0.5</span></span> training accuracy at iteration <span class="hljs-number"><span class="hljs-number">100</span></span>: <span class="hljs-number"><span class="hljs-number">0.3333333333333333</span></span> training accuracy at iteration <span class="hljs-number"><span class="hljs-number">125</span></span>: <span class="hljs-number"><span class="hljs-number">0.5</span></span> training accuracy at iteration <span class="hljs-number"><span class="hljs-number">150</span></span>: <span class="hljs-number"><span class="hljs-number">0.5</span></span> training accuracy at iteration <span class="hljs-number"><span class="hljs-number">175</span></span>: <span class="hljs-number"><span class="hljs-number">0.5</span></span> training accuracy at iteration <span class="hljs-number"><span class="hljs-number">200</span></span>: <span class="hljs-number"><span class="hljs-number">0.5</span></span> training accuracy at iteration <span class="hljs-number"><span class="hljs-number">225</span></span>: <span class="hljs-number"><span class="hljs-number">0.6666666666666666</span></span> training accuracy at iteration <span class="hljs-number"><span class="hljs-number">250</span></span>: <span class="hljs-number"><span class="hljs-number">0.6666666666666666</span></span> training accuracy at iteration <span class="hljs-number"><span class="hljs-number">275</span></span>: <span class="hljs-number"><span class="hljs-number">0.8333333333333334</span></span> training accuracy at iteration <span class="hljs-number"><span class="hljs-number">300</span></span>: <span class="hljs-number"><span class="hljs-number">1</span></span> training accuracy at iteration <span class="hljs-number"><span class="hljs-number">325</span></span>: <span class="hljs-number"><span class="hljs-number">1</span></span> training accuracy at iteration <span class="hljs-number"><span class="hljs-number">350</span></span>: <span class="hljs-number"><span class="hljs-number">1</span></span> training accuracy at iteration <span class="hljs-number"><span class="hljs-number">375</span></span>: <span class="hljs-number"><span class="hljs-number">1</span></span></code> </pre><br><br>  We see that initially the accuracy of our classifier‚Äôs training was only 33%, but by the end of the training the examples are correctly classified as the parameters a, b, c adjust their values ‚Äã‚Äãin accordance with the applied tension force.  We just trained SVM!  But please, never use this code in practice :) We will see how you can do everything much more efficiently when we figure out what, in fact, is happening. <br><br>  The number of repetitions is necessary.  With the data of this example, with the initialization of this example, and with the adjustment of the used step size, 300 repetitions were required to train the SVM.  In practice, they may be much larger or much smaller, depending on how difficult or large the problem is, how you initialize, normalize the data, what step size you use and so on.  This is a model example, but later I will go through all the best techniques for the actual training of these classifiers in practice.  For example, it appears that setting the step size is extremely important and difficult.  A small step size will make your model slow in learning.  A large step size will train faster, but if it is too large, it will make your classifier jump randomly and this will not lead to a good end result.  In the end, we will use deferred data verification for more precise tuning in order to take the most advantageous position for your data. <br><br>  One thing I want you to appreciate is that the circuit can be an arbitrary expression, and not just a linear prediction function, which we used in this example.  For example, it can be a whole neural network. <br><br>  By the way, I specifically structured the code in a modular way, but we could demonstrate SVM with much simpler code.  This is what all these classes and calculations actually boil down to: <br><br><pre> <code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">var</span></span> a = <span class="hljs-number"><span class="hljs-number">1</span></span>, b = <span class="hljs-number"><span class="hljs-number">-2</span></span>, c = <span class="hljs-number"><span class="hljs-number">-1</span></span>; <span class="hljs-comment"><span class="hljs-comment">//   for(var iter = 0; iter &lt; 400; iter++) { //      var i = Math.floor(Math.random() * data.length); var x = data[i][0]; var y = data[i][1]; var label = labels[i]; //   var score = a*x + b*y + c; var pull = 0.0; if(label === 1 &amp;&amp; score &lt; 1) pull = 1; if(label === -1 &amp;&amp; score &gt; -1) pull = -1; //      var step_size = 0.01; a += step_size * (x * pull - a); // -a     b += step_size * (y * pull - b); // -b     c += step_size * (1 * pull); }</span></span></code> </pre><br><br>  This code produces the exact same result.  Probably at the moment you can just take a look at the code and see how these equations came out. <br><br>  Let's make a small note about this: You may have noticed that the tension is always 1.0 or -1.  You can imagine other options, for example, tension is proportional to how serious the error was.  This leads to a variation on the SVM, which some people call the square piecewise linear SVM loss function, why - you will understand a little later.  Depending on the different characteristics of your data set, it may work better or worse.  For example, if you have very poor data performance, for example, a negative data entry point that has a value of +100, its effect on the classifier will be relatively insignificant, since we will simply pull with a force of -1 regardless of how serious mistake.  In practice, we perceive this property of the classifier as resistance to indicators. <br><br>  Let's briefly repeat.  We introduced the problem of binary classification, where we are given N D-dimensional vectors and a label + 1 / -1 for each.  We have seen that we can combine these characteristics with a set of parameters inside the circuit with real values ‚Äã‚Äã(for example, the schema Mach of support vectors, as in our example).  Then we can repeatedly carry out our data through the scheme and each time change the parameters so that the output value of the scheme corresponds to the specified labels.  The change depends, most importantly, on our ability to perform backward propagation of gradient errors through the circuit.  Ultimately, the final scheme can be used to predict the values ‚Äã‚Äãof unknown examples! </div><p>Source: <a href="https://habr.com/ru/post/246849/">https://habr.com/ru/post/246849/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../246837/index.html">Introducing Pop-up Events</a></li>
<li><a href="../246839/index.html">Why employees of large companies use ‚Äúleft‚Äù software for professional communication and what to do about it</a></li>
<li><a href="../246841/index.html">Windows 8.1 Kernel Patch Protection - PatchGuard</a></li>
<li><a href="../246843/index.html">Why great achievements will not make you happier (and what to do about it!)</a></li>
<li><a href="../246845/index.html">Not another evalboard for STM32 - we do it right in XFR-L3 "KYRNN"</a></li>
<li><a href="../246851/index.html">Do not make icons, make live tiles</a></li>
<li><a href="../246853/index.html">School call to .NET Micro Framework with remote control</a></li>
<li><a href="../246855/index.html">Bluetooth and other ways to hack handcuffs</a></li>
<li><a href="../246861/index.html">Embedding electronic signatures in systems with a WEB interface using a browser plugin and openssl</a></li>
<li><a href="../246865/index.html">10 key strategic technologies of 2015 according to Gartner</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>