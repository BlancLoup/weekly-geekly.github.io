<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>OpenAI demonstrates the transfer of complex manipulations from simulations to the real world.</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="After adding random factors to a relatively simple simulation, a robot from OpenAI learned how to perform complex handheld operations. 


 Handheld op...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({
            google_ad_client: "ca-pub-6974184241884155",
            enable_page_level_ads: true
       });
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly.github.io/index.html"></a>
    <div class="page-header-text">Geekly Articles each Day</div>
  </header>
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>OpenAI demonstrates the transfer of complex manipulations from simulations to the real world.</h1><div class="post__text post__text-html js-mediator-article"><h2>  After adding random factors to a relatively simple simulation, a robot from OpenAI learned how to perform complex handheld operations. </h2><br><img src="https://habrastorage.org/getpro/habr/post_images/738/6d2/94b/7386d294b784c826ee4cc4144187e9a8.jpg"><br><br>  Handheld operations are one of those actions that are at the top of the list of "skills that do not require efforts from people and are extremely difficult for robots."  Without thinking, we are able to adaptively control the fingers, opposing them with the thumb and palm, taking into account friction and gravity, manipulating objects with one hand, without using the other - during this day you must have done this trick many times, even with your phone. <br><br>  It takes years of training for people to learn how to work reliably with their fingers, but robots do not have that much time to learn.  Such complex tasks are still solved through practical training and experience, and the task is to find a way to train the robot faster and more efficiently than just to give the robotic arm something that can be manipulated again and again until it realizes that it works, and what does not;  it may take a hundred years. <br><a name="habracut"></a><br>  Instead of waiting a hundred years, the researchers from <a href="https://blog.openai.com/learning-dexterity/">OpenAI</a> used reinforcement training to train the <a href="https://ru.wikipedia.org/wiki/%25D0%25A1%25D0%25B2%25D1%2591%25D1%2580%25D1%2582%25D0%25BE%25D1%2587%25D0%25BD%25D0%25B0%25D1%258F_%25D0%25BD%25D0%25B5%25D0%25B9%25D1%2580%25D0%25BE%25D0%25BD%25D0%25BD%25D0%25B0%25D1%258F_%25D1%2581%25D0%25B5%25D1%2582%25D1%258C">convolutional neutron network</a> to control the five-fingered hand of the Shadow robot to manipulate objects ‚Äî and in just 50 hours.  They managed to do this through a simulation, a technique that is notorious as ‚Äúdoomed to success‚Äù ‚Äîbut they neatly introduced random factors into it in order to bring it closer to the mutability of the real world.  The real Shadow hand was able to successfully carry out handheld manipulations with real objects without any re-training. 
      <br>
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
        <ins class="adsbygoogle"
          style="display:block; text-align:center;"
          data-ad-layout="in-article"
          data-ad-format="fluid"
          data-ad-client="ca-pub-6974184241884155"
          data-ad-slot="8945601208"></ins>
        <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
      <br>
      Ideally, all robots need to be trained in simulations, because simulations can be scaled without creating lots of real robots.  Do you want to train dofigillion robots dofigillion hours in one dofigilionnoy of a second?  This can be done - if you get enough computing power.  But try to do this in the real world - and the problem that no one knows exactly how much it will be, ‚Äúdofigillion‚Äù, will be the least of your problems. <br><br>  The problem with training robots in simulations is that the real world cannot be simulated for sure - and it is even more difficult to accurately simulate such minor annoyances as friction, compliance and the interaction of several objects.  Therefore, it is generally accepted that simulation is fine, but there is a big and terrible gap between the success of simulation and success in the real world, which in a certain way diminishes the value of simulations.  The fact that the very things that it would be nice to simulate (for example, handheld manipulations) at the same time prove to be the most difficult for accurate simulations, because of how physically sophisticated they are, does not improve the situation. <br><br>  A common approach to this problem is to try to make the simulation as accurate as possible, and hope that it will be close enough to the real world so that you can extract some useful behavior from it.  Instead, OpenAI puts in the first place not accuracy, but variability, supplying its moderately realistic simulations with a multitude of small tweaks so that the resulting behavior is reliable enough to work outside the simulation. <br><br>  The randomization process is the key to what makes the system (called Dactyl) able to effectively move from simulation to the real world.  OpenAI understands perfectly well that the simulations they use are not complex enough to simulate the whole mountain of the most important things, from friction to wear on the tips of the fingers of a real roboruki.  In order for the robot to summarize what it learns, OpenAI contributes random variables to all possible aspects of the simulation in order to try to cover all the variability of the world that cannot be modeled well.  This includes the mass, all measurements of the object, the friction of its surface and the fingers of the robot, damping of the fingers of the robot, the force of the impact of the motors, limitation of joints, play and noise of the motor, and so on.  Small random effects are attached to the object in order for the simulation to cope with dynamics that cannot be modeled.  And this is just the process of manipulation itself - there are quite a few random variables in RGB cameras that evaluate the position of an object, which, however, are a bit easier to visualize. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f43/c8a/ca3/f43c8aca35d57d0138fc77edb9a56f90.jpg"><br>  <i>Rows show pictures from the same camera.</i>  <i>Columns correspond to images with random changes - all of them are simultaneously fed to the neural networks.</i> <br><br>  OpenAI calls this ‚Äúenvironment randomization,‚Äù and in the case of handheld manipulations, they ‚Äúwanted to see if the scale up of environment randomization could solve the problem that is not available in today's robotics techniques.‚Äù  And so, what happened as a result of two independently trained systems (one visual, the second for manipulation), which visually recognize the position of the cube and turn it into different positions. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/jwSbzNHGflM" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><br>  All these turns of the cube (and the system is capable of at least 50 successful successive manipulations) were made possible thanks to 6144 processors and 8 GPUs that gained 100 years of simulated robot experience in just 50 hours.  The only feedback available to the system (both in the simulation and in reality) is the location of the cube and fingers, while the system began without having any specific concepts about how to hold or rotate the cube.  She had to independently deal with all of this - including rotating her fingers, simultaneously coordinating several fingers, using gravity, coordinating the application of forces.  The robot invented the same techniques that people use, however, with small (and interesting) modifications: <br><br>  To accurately capture an object, the robot usually uses the little finger instead of the index or middle fingers.  This may be due to the presence of the Shadow Dexterous Hand in the little finger of an additional degree of freedom compared to the index, middle and ring fingers, which makes it more mobile.  People more mobile usually have an index and middle finger.  This means that our system is able to independently invent the grasping technique that people have, but it is better to adapt it to their own limitations and capabilities. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/772/55d/44e/77255d44ebc0a126fc20780d91d34ee3.jpg"><br>  <i>Different types of cleats that the system has learned.</i>  <i>From left to right and from top to bottom: grabbing with your fingertips, grabbing with your palm, grabbing with three fingers, four, five-finger grabbing, and powerful gripping.</i> <br><br>  We observed another interesting parallel in the work of people's fingers and our robot.  According to this strategy, the hand holds the object with two fingers and rotates around this axis.  It turned out that young children do not have time to develop similar motility, so they usually rotate objects with the help of proximal or middle <a href="https://ru.wikipedia.org/wiki/%25D0%25A4%25D0%25B0%25D0%25BB%25D0%25B0%25D0%25BD%25D0%25B3%25D0%25B0_(%25D0%25B0%25D0%25BD%25D0%25B0%25D1%2582%25D0%25BE%25D0%25BC%25D0%25B8%25D1%258F)">phalanges of the fingers</a> .  And only later in life do they switch to the distal phalanges, as most adults do.  Interestingly, our robot usually relies on the distal phalanxes to rotate an object. <br><br>  Plus, the technology is that, as it turned out, robots can still be trained on complex physical actions in simulations, and then immediately use the accumulated skills in reality - and this is really a great achievement, because training in simulations goes much faster than in reality . <br><br>  We contacted Jonas Schneider, a member of the OpenAI technical team, to ask more about this project. <br><br>  <b>Edition</b> : Why is hand-manipulation in robotics so difficult? <br><br>  <b>Jonas Schneider</b> : Manipulations take place in a very limited space, and a large number of degrees of freedom are available to the robot.  Successful manipulation strategies require proper coordination in all these degrees of freedom, and this reduces the size of the error in comparison with ordinary interactions with objects, such as simple capture, for example.  During handheld manipulations, a lot of contact with the object is recorded.  Modeling these contacts is a difficult task, prone to errors.  Runtime errors have to be controlled while the arm is working, which causes problems in the traditional approach, based on the planning of movements in advance.  For example, a problem may arise when you have <a href="https://ru.wikipedia.org/wiki/%25D0%259B%25D0%25B8%25D0%25BD%25D0%25B5%25D0%25B9%25D0%25BD%25D0%25BE-%25D0%25BA%25D0%25B2%25D0%25B0%25D0%25B4%25D1%2580%25D0%25B0%25D1%2582%25D0%25B8%25D1%2587%25D0%25BD%25D1%258B%25D0%25B9_%25D1%2580%25D0%25B5%25D0%25B3%25D1%2583%25D0%25BB%25D1%258F%25D1%2582%25D0%25BE%25D1%2580">linear</a> feedback that does not register the non-linear dynamics of what is happening. <br><br>  <b>Apparently, random variables are the key to ensuring that the skills obtained in the simulation can be reliably applied in reality.</b>  <b>How do you decide which parameters to make random, and how?</b> <br><br>  During calibration, we roughly estimate which parameters may change, and then decide which ones will most importantly be reproduced in the simulation.  Then we set the values ‚Äã‚Äãof these parameters to be equal to the calibration ones, and add random variations in the region of the mean value.  The amplitude of variations depends on our confidence - for example, we did not vary the size of the object very much, because we can measure it accurately. <br><br>  Some random variations were based on empirical observations.  For example, we observed how our robot sometimes dropped an object, dropping a brush, and not having time to pick it up until the object rolled off it.  We found that due to problems with a low-level controller, our actions could sometimes be delayed by several hundred milliseconds.  And we could, of course, spend the effort to make the controller more reliable, but instead we simply added randomization to the response time of each controller.  It seems to us that at a higher level this may be an interesting approach to the development of future robots;  for some tasks, the development of very accurate equipment may be unacceptably expensive, and we have demonstrated how these deficiencies of equipment can be corrected with the help of more advanced algorithms. <br><br>  <b>How do you think your results would improve if you waited not 100 years of simulated time, but, for example, 1000?</b> <br><br>  On the example of a specific task, it is difficult to estimate, since we have never performed tests more than 50 turns.  It is not yet clear how exactly the asymptotic curve of characteristics looks, but we consider our project to be complete, since even one successful turn is far beyond the limits of the possibilities of the best teaching methods existing today.  In fact, we chose a figure of 50 turns, because we decided that 25 turns would definitely show that the problem was solved, and then added another 25, for 100% of the stock.  If your task is to optimize for very long sequences of actions and high reliability, then an increase in workouts is likely to help.  But at some point, as we think, the robot will start to adapt more to the simulation, and work worse in the real world, and then you have to add more randomizations to complicate the simulation, which, in turn, will increase the reliability of the final system. <br><br>  <b>How well are your results summarized?</b>  <b>For example, how much effort would you have to re-work to rotate a smaller cube, or a cube that would be soft or slippery?</b>  <b>What about a different camera arrangement?</b> <br><br>  By the way, for the sake of interest, we <a href="">tried to</a> carry out manipulations with soft cubes, and smaller cubes, and it turned out that the quality of work is not greatly reduced compared to the rotation of a solid cube.  In the simulation, we also experimented with cubes of different sizes, and this also worked well (although we didn‚Äôt try this with a real robot).  In the simulation, we also used random variations of the size of the cube.  We did not try to do this, but I think that if we simply increase the spread of random variations in the size of the cube in the simulation, the hand will be able to manipulate the cubes of various sizes. <br><br>  As for the cameras, the visual model was trained separately, and while we make only small random variations in the camera position, therefore, with each change in the camera position, we start training again.  One of our interns, Xiao-Yu Fish Tan, is just working to make the visual model completely independent of the camera location, using the same basic technique of randomly varying the position and orientation of the camera within large limits. <br><br>  <b>How does training in simulation differ from the ‚Äú <a href="https://spectrum.ieee.org/automaton/robotics/artificial-intelligence/google-large-scale-robotic-grasping-project">brute force</a> ‚Äù approach, where a bunch of real robots are used?</b> <br><br>  Interestingly, our project began with the fact that we questioned the idea of ‚Äã‚Äãusing simulations to promote robotics.  For many years now we have been <a href="https://blog.openai.com/roboschool/">observing</a> how in simulations robotics achieves impressive results using reinforced training.  However, in conversations with researchers engaged in classical robotics, we are constantly confronted with the distrust that such methods can work in the real world.  The main problem is that simulators are not entirely accurate from a physical point of view (even if they look good for the human eye).  Adding problems and the fact that more accurate simulations require more computational power.  Therefore, we decided to establish a new standard that requires working with a very complex platform in terms of equipment, which has to deal with all the limitations of simulations. <br><br>  As for the ‚Äúwrist farm‚Äù approach, the main limitation in the training of physical robots is the low scalability of the acquired skills for more complex tasks.  This can be done by arranging everything so that you have a lot of objects in a self-stabilizing environment that does not have different states (for example, a basket of balls).  But it will be very difficult to do it the same way for the task of assembling something, when after each run your system is in a new state.  Again, instead of setting up the entire system once, you will have to set it up N times, and keep it in working condition after it, for example, how the robot rushed and broke something.  All this is much simpler and easier to do in simulations with elastic computing power. <br><br>  As a result, our work supports the idea of ‚Äã‚Äãtraining in simulations, since we have shown how to solve the transfer problem even in the case of very complex robots.  However, this does not negate the idea of ‚Äã‚Äãlearning a real robot;  It would be very difficult to circumvent the limitations of simulations when working with deformable objects and liquids. <br><br>  <b>Where is your system the thinnest place?</b> <br><br>  At the moment - this is a random variation, developed by hand and sharpened for a specific task.  In the future, it may be possible to try to learn these variations by adding another layer of optimization, which is the process that we are doing manually today (‚Äútry several randomizations and see if they help‚Äù).  You can also go even further, and use the game between the learning agent and his opponent, who are trying to hinder (but not strongly) his progress.  This dynamic can lead to the emergence of very reliable sets of rules for the work of robots, because the better an agent turns out to be, the cleverer an opponent has to be to interfere with him, which improves the agent's work even more, and so on.  This idea has already been <a href="https://arxiv.org/pdf/1703.02702.pdf">studied by</a> other researchers. <br><br>  <b>You say that your main goal is to create robots for the real world.</b>  <b>What else needs to be done before it becomes possible?</b> <br><br>  We are trying to expand the capabilities of robots to work in an environment without strict restrictions.  In such environments, it is impossible to foresee everything in advance and to prepare a model for each object.  It is also inconvenient to put any tags on objects outside the laboratory.  It turns out that our robots will have to learn how to act in a variety of situations, how to make a reasonable choice in a situation that they have never encountered before. <br><br>  <b>What will you work on next?</b> <br><br>  We will continue to create robots with more and more complicated behavior.  It is too early to say exactly how.  In the long run, we hope to give robots general manipulation skills with objects, so that they can learn to interact with their environment in the way a baby does ‚Äî playing with existing objects, not necessarily under adult supervision.  We think that intelligence is tied to interaction with the real world, and in order to accomplish our task of creating safe general-purpose artificial intelligence, we need to be able to learn from sensory data from the real world, and from simulations. </div><p>Source: <a href="https://habr.com/ru/post/420209/">https://habr.com/ru/post/420209/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../420197/index.html">Creation of AI by the method of "coarse kuzdra". Intellectual Odyssey</a></li>
<li><a href="../420199/index.html">Automation of monitoring system based on Icinga2 and Puppet</a></li>
<li><a href="../420201/index.html">Why are Westerners afraid of robots, but Japanese are not?</a></li>
<li><a href="../420203/index.html">Serious success in quantum computing prevented teen</a></li>
<li><a href="../420205/index.html">DNA ROM, nucleic acid memory and substrate for OxRAM</a></li>
<li><a href="../420211/index.html">Magical thinking about machine learning will not bring the appearance of real AI</a></li>
<li><a href="../420213/index.html">An overview of the affordable large 3D printer WANHAO D9</a></li>
<li><a href="../420215/index.html">Console, switches and a lot of coffee: one day in the life of VDS hosting</a></li>
<li><a href="../420219/index.html">Overview of Techniques for Implementing a Game AI</a></li>
<li><a href="../420221/index.html">Attackers hacked thousands of D-link routers and redirected their owners to malicious resources</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

  <footer class="page-footer">
    <div class="page-footer-legal-info-container page-footer-element">
      <p>
        Weekly-Geekly | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
      </p>
    </div>
    <div class="page-footer-counters-container page-footer-element">
      <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=6iCFw7uJz0zcOaoxz5k5PcLCJUzv2WG8G5V8M3U6Rc4&co=3a3a3a&ct=ffffff'/></a>
    </div>
  </footer>
</body>

</html>